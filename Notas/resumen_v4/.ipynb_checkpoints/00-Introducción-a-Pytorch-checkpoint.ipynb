{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se dará una breve introducción al framework [Pytorch](https://pytorch.org/tutorials/) que nos va a servir a nosotros para estudiar y crear modelos utilizados en *machine Learning* y *deep learning*. Se supone para el tutorial que se tienen los conocimientos básicos de teoría de aprendizaje y decisión, y que se conocen los algoritmos básicos como regresión por cuadrados mínimos, regresión logística, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores y GPUs\n",
    "\n",
    "A diferencia de otros frameworks conocidos como *Tensorflow*, la idea de trabajar con *Pytorch* es utilizar una librería numérica (como Numpy) sobre una o más GPUs. Tan simple como eso. Es decir, este módulo intenta que no haya que pensar en el grafo computacional que está siendo ejecutado detrás de escena, en el cálculo de gradientes o en otras cosas como estas. Como regla general: Pytorch es Numpy + GPUs.\n",
    "\n",
    "De esta manera, puedo definir y manipular tensores con instrucciones simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0.8500, 1.0369, 0.0511])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([1,2,3]) # Tensor de tamaño 3\n",
    "x2 = torch.zeros(3,3) # Tensor de tamaño 3x3\n",
    "x3 = torch.rand(3) * x1 # Producto componente a componente de dos tensores de tamaño 3\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En [este](https://pytorch.org/docs/stable/torch.html) link se encuentran las opciones para construir tensores y las operaciones numéricas para realizar entre ellos. Otras funcionalidades muy utilizadas en la práctica son:\n",
    "\n",
    "Operaciones de construcción:\n",
    "* `torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "* `torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "* `torch.from_numpy(ndarray)`\n",
    "\n",
    "Operaciones de manipulación:\n",
    "* `torch.squeeze(input, dim=None, out=None)`\n",
    "* `torch.transpose(input, dim0, dim1)`\n",
    "\n",
    "Operaciones de sampleo:\n",
    "* `torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "* `torch.randint(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`\n",
    "\n",
    "Operaciones matemáticas y de reducción:\n",
    "* `torch.exp(input, out=None)`\n",
    "* `torch.logsumexp(input, out=None)`\n",
    "* `torch.argmax(input)`\n",
    "\n",
    "Operaciones propias de la clase `torch.Tensor`:\n",
    "* `torch.Tensor.view(*shape)`\n",
    "* `torch.Tensor.size()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar algún ejemplo chiquitito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, en todas las operaciones anteriores la creación y manipulación de los tensores se hizo sobre la CPU, dado que es el dispositivo predeterminado en Pytorch. Es posible (una vez [instalado CUDA](https://docs.nvidia.com/cuda/index.html) apropiadamente) crear y manipular tensores en la GPU, lo cual acelera el proceso enormemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cpu. Cantidad de repeticiones: 1. Duración: 1514.93ms + 943.54ms = 2458.47ms\n",
      "Dispositivo: cpu. Cantidad de repeticiones: 100. Duración: 1607.23ms + 103207.04ms = 104814.27ms\n",
      "Dispositivo: cuda. Cantidad de repeticiones: 1. Duración: 2088.54ms + 151.04ms = 2239.59ms\n",
      "Dispositivo: cuda. Cantidad de repeticiones: 100. Duración: 0.20ms + 0.81ms = 1.01ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def test_speed(device_name,rep=1):\n",
    "    device = torch.device(device_name)\n",
    "    tic1 = time.time()\n",
    "    x = torch.randn(1024,10000,device=device)\n",
    "    w = torch.randn(10000,30000,device=device)\n",
    "    tic2 = time.time()\n",
    "    for i in range(rep):\n",
    "        y = torch.matmul(x,w)\n",
    "    tic3 = time.time()\n",
    "    print('Dispositivo: {}. Cantidad de repeticiones: {}. Duración: {:.2f}ms + {:.2f}ms = {:.2f}ms'\\\n",
    "          .format(device_name,rep,(tic2-tic1)*1e3,(tic3-tic2)*1e3,(tic3-tic1)*1e3))\n",
    "\n",
    "test_speed('cpu',1)\n",
    "test_speed('cpu',100)\n",
    "test_speed('cuda',1)\n",
    "test_speed('cuda',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos, en primer lugar, que el tiempo de creación de tensores en CPU es más o menos cada vez que se llama a la función `test_speed()`, mientras que para la GPU hay una diferencia abismal. Por otra parte, en la CPU, el tiempo que tarda en realizar 100 repeticiones de la misma cuenta es aproximadamente 100 veces el tiempo que tarda en realizar 1 vez la cuenta. Por otra parte, en la GPU no hay una relación tan directa... de hecho, es más rápido hacer 100 repeticiones que 1 sola! Esto no es así siempre, pero es evidente que el paralelismo de la GPU se encarga de alinealizar la complejidad algorítmica :)\n",
    "\n",
    "Por otra parte, hay que tener cuidado con la creación de tensores en la GPU, puesto que a veces es mayor el *overhead* para la GPU que para la CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferenciación automática\n",
    "\n",
    "Además de poder realizar operaciones en GPUs, Pytorch permite armar funciones tensoriales y calcular gradientes de manera automática. Con esto, es posible crear todo tipo de modelos y aplicar algún algoritmo de gradiente descendiente para estimar sus parámetros. \n",
    "\n",
    "### Grafos computacionales\n",
    "\n",
    "Un grafo computacional no es más que un conjunto de funciones tensoriales representadas por medio de nodos y de flechas que ingresan (entradas) y que salen (salidas) de él. A su vez, estas funciones se conectan entre sí mediante sus entradas y sus salidas para formar un grafo, que a su vez tendrá una entrada y una salida global. De esta manera, un grafo no es más que una función tensorial compuesta. \n",
    "\n",
    "Por ejemplo, supongamos que definimos un modelo de regresión logística con una entrada $\\mathbf{x}$ y un conjunto de parámetros $\\{ \\mathbf{w}, b \\}$:\n",
    "\n",
    "$$\n",
    "h_{\\mathbf{w},b}(\\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x} + b)\n",
    "$$\n",
    "\n",
    "La salida del modelo es un número escalar entre 0 y 1, que representa la probabilidad de que $\\mathbf{x}$ pertenezca a la clase 1. Además, podemos definir el costo de un conjunto de muestras $\\{ \\mathbf{x}_i, y_i\\}_{i=1}^N$ cuando se utilizaron los parámetros $\\mathbf{w}$ y $b$ para calcular la salida. Supongamos, a modo de ejemplo, que el costo está definido en este caso por la cross entropy para dos clases:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "loss(\\mathbf{w},b) &= \\sum_{i=1}^N y_i \\log\\left(\\sigma(\\mathbf{w}^T \\mathbf{x}+b)\\right) + (1-y_i) \\log\\left(1-\\sigma(\\mathbf{w}^T \\mathbf{x}+b)\\right)\\\\\n",
    "&=\\sum_{i=1}^N y_i \\log\\left(h_{\\mathbf{w},b}(\\mathbf{x})\\right) + (1-y_i) \\log\\left(1-h_{\\mathbf{w},b}(\\mathbf{x})\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "De esta manera, puede definirse un grafo computacional con la siguiente estructura:\n",
    "\n",
    "![alt text](Imagen del grafo para logistic regression con cross-entropy)\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "La ventaja de pensar al cómputo de la cross-entropy mediante un grafo como el que se mostró anteriormente es que es posible obtener una forma de calcular automáticamente el gradiente de la función $loss(\\mathbf{w},b)$ con respecto a las variables $\\mathbf{w}$ y $b$. Esto se utilizará posteriormente para encontrar los parámetros del modelo que hacen mínimo al costo.\n",
    "\n",
    "**Continuar desde acá...**\n",
    "\n",
    "fuentes:\n",
    "\n",
    "* [Tutorial básico](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
    "* [Tutorial de Justin Johnson](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)\n",
    "* [Tutorial un poco más avanzado](https://pytorch.org/docs/stable/notes/autograd.html)\n",
    "* También puede ser que haya algo útil [acá](https://pytorch.org/docs/stable/index.html) y [acá](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "* [Explicación de Manning](https://www.youtube.com/watch?v=yLYHDSv-288&feature=youtu.be) (muy buena!!) minuto 45, diapositiva 42 de la lecture 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "tensor([[-20.9590],\n",
      "        [-13.3563],\n",
      "        [-20.9906],\n",
      "        [ -1.8482],\n",
      "        [ 13.0636]])\n",
      "tensor([[-62.4839]])\n"
     ]
    }
   ],
   "source": [
    "d = 5       # Dimensión del espacio de las muestras\n",
    "N = 100     # Cantidad de muestras\n",
    "\n",
    "x = torch.randn(N,d)   # Muestras de entrada\n",
    "y = torch.randint(1,(N,1)) # Muestras de salida\n",
    "\n",
    "w = torch.randn(d,1,requires_grad=True) # Parámetros\n",
    "b = torch.randn(1,1,requires_grad=True)\n",
    "\n",
    "u_1 = torch.matmul(x,w) + b   # Función 1 del grafo\n",
    "u_2 = torch.sigmoid(u_1)      # Función 2 del grafo\n",
    "\n",
    "loss = (y * torch.log(u_2) + (1-y) * torch.log(1-u_2)).sum() # Costo de las muestras\n",
    "print(w.grad)\n",
    "print(b.grad)\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
