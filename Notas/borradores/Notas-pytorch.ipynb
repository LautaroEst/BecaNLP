{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas sobre cómo usar Pytorch\n",
    "\n",
    "---\n",
    "\n",
    "Para estas notas se usa el dataset CIFAR-10 que se encuentra en la carpeta `cs231n-Computer-Vision/assignments/2019/assignment2/cs231n/datasets/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento del dataset y división en tran / val / test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000 # Cantidad de muestras del training set.\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('../assignments/2019/assignment2/cs231n/datasets/', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('../assignments/2019/assignment2/cs231n/datasets/', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('../assignments/2019/assignment2/cs231n/datasets/', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seteo de algunas constantes útiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de GPU:\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "# Tipo numérico a usar:\n",
    "dtype = torch.float32 \n",
    "\n",
    "# Constante para controlar cada cuánto se imprime el valor de la función loss:\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1: Red de dos capas fully-connected\n",
    "\n",
    "Para cualquiera de los ejemplos que vamos a ver, se implementa una función que reciba el tensor de entrada, los parámetros de la red y devuelva la salida (es decir, ejecute el forward pass).\n",
    "\n",
    "En este ejemplo vamos a hacer una red de dos capas fully connected. Para eso, hacemos una función `TwoLayerFullyConnected()` que reciba un minibatch de muestras `x` y una lista `params` que contenga las variables del gráfico que hacen de parámetros. Tanto la entrada como los parámetros son instancias de la clase `torch.Tensor()` y tienen el flag `requires_grad=True` para crear el computational graph en background automáticamente. En esta función se utilizan funciones pre-armadas de `torch.nn.functional` como la activación ReLU.\n",
    "\n",
    "Por último, testeamos la función que creamos con `two_layer_fc_test()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "def TwoLayerFullyConnected(x, params):\n",
    "    \"\"\"\n",
    "    A fully-connected neural networks; the architecture is:\n",
    "    NN is fully connected -> ReLU -> fully connected layer.\n",
    "    Note that this function only defines the forward pass; \n",
    "    PyTorch will take care of the backward pass for us.\n",
    "    \n",
    "    The input to the network will be a minibatch of data, of shape\n",
    "    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n",
    "    and the output layer will produce scores for C classes.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n",
    "      input data.\n",
    "    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n",
    "      w1 has shape (D, H) and w2 has shape (H, C).\n",
    "    \n",
    "    Returns:\n",
    "    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n",
    "      the input data x.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtenemos la entrada \"flatted\".\n",
    "    batch_size = x.shape[0]\n",
    "    x = x.view(batch_size,-1)\n",
    "    \n",
    "    # Extraemos los parámetros.\n",
    "    w1, w2 = params # w1.requires_grad=True, w2.requires_grad=True\n",
    "    \n",
    "    # Ejecutamos el forward pass. Esto crea en background un computational graph\n",
    "    # que tiene toda la información de cómo hacer backpropagation.\n",
    "    x = F.relu(x.mm(w1)) # Multiplicación matricial tradicional + ReLu\n",
    "    x = x.mm(w2) # Multiplicación matricial tradicional\n",
    "    return x\n",
    "    \n",
    "\n",
    "def two_layer_fc_test():\n",
    "    hidden_layer_size = 42\n",
    "    x = torch.zeros((64, 50), dtype=dtype, requires_grad=True)  # minibatch size 64, feature dimension 50\n",
    "    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype, requires_grad=True)\n",
    "    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype, requires_grad=True)\n",
    "    scores = TwoLayerFullyConnected(x, [w1, w2])\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "\n",
    "two_layer_fc_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Red convolucional de 3 capas\n",
    "\n",
    "Ahora vamos a hacer lo mismo pero con una arquitectura más elaborada:\n",
    "\n",
    "1. A convolutional layer (with bias) with `channel_1` filters, each with shape `KW1 x KH1`, and zero-padding of two\n",
    "2. ReLU nonlinearity\n",
    "3. A convolutional layer (with bias) with `channel_2` filters, each with shape `KW2 x KH2`, and zero-padding of one\n",
    "4. ReLU nonlinearity\n",
    "5. Fully-connected layer with bias, producing scores for C classes.\n",
    "\n",
    "Seguimos usando las funciones pre-armadas de `torch.nn.functional`.\n",
    "\n",
    "Recordamos cómo son los hiperparámetros de las redes convolucionales:\n",
    "\n",
    "**Summary**. To summarize, the Conv Layer:\n",
    "\n",
    "* Accepts a volume of size $C_{in} \\times W_{in} \\times H_{in}$\n",
    "\n",
    "* Requires four hyperparameters:\n",
    "\n",
    "    * Number of filters $K$,\n",
    "    * their spatial extent $F_W \\times F_H$,\n",
    "    * the stride $S_W \\times S_H$,\n",
    "    * the amount of zero padding $P_W \\times P_H$.\n",
    "    \n",
    "* Produces a volume of size $C_{out} \\times W_{out} \\times H_{out}$ where:\n",
    "\n",
    "    * $W_{out}=(W_{in}−F_W+2P_W)/S_W+1$\n",
    "    * $H_{out}=(H_{in}−F_H+2P_H)/S_H+1$ (i.e. width and height are computed equally by symmetry)\n",
    "    * $C_{out}=K$\n",
    "\n",
    "* With parameter sharing, it introduces $F_W \\cdot F_H \\cdot C_{in}$ weights per filter, for a total of $(F_W \\cdot F_H \\cdot C_{in}) \\cdot K$ weights and $K$ biases.\n",
    "\n",
    "* In the output volume, the d-th depth slice (of size $W_2 \\times H_2$) is the result of performing a valid convolution of the d-th filter over the input volume with a stride of S, and then offset by d-th bias.\n",
    "\n",
    "A common setting of the hyperparameters is $F_H=F_W=3$,$S_H=S_W=1$,$P_H=P_W=1$. However, there are common conventions and rules of thumb that motivate these hyperparameters. See the ConvNet architectures section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def ThreeLayerConvNet(x,params):\n",
    "    \n",
    "    # Obtenemos las dimensiones de la entrada.\n",
    "    batch_size, C, H, W = x.shape\n",
    "    \n",
    "    # Obtenemos los parámetros.\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    \n",
    "    # Forward pass. \n",
    "    x = F.conv2d(x,conv_w1,conv_b1,padding=2) # layer convolucional\n",
    "    x = F.relu(x) # activación ReLU\n",
    "    x = F.conv2d(x,conv_w2,conv_b2,padding=1) # layer convolucional\n",
    "    x = F.relu(x) # activación ReLU\n",
    "    x = x.view(batch_size,-1).mm(fc_w) + fc_b # fully-connected layer\n",
    "    \n",
    "    return x\n",
    "    \n",
    "    \n",
    "def three_layer_convnet_test():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "\n",
    "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b1 = torch.zeros((6,))  # out_channel\n",
    "    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b2 = torch.zeros((9,))  # out_channel\n",
    "\n",
    "    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n",
    "    fc_w = torch.zeros((9 * 32 * 32, 10))\n",
    "    fc_b = torch.zeros(10)\n",
    "\n",
    "    scores = ThreeLayerConvNet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "three_layer_convnet_test()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función útil: check accuracy\n",
    "\n",
    "Definimos una función que calcula la cantidad de aciertos en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckAccuracy(loader, model, params, device='cpu', dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Check the accuracy of a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - loader: A DataLoader for the data split we want to check\n",
    "    - model: A function that performs the forward pass of the model,\n",
    "      with the signature scores = model(x, params)\n",
    "    - params: List of PyTorch Tensors giving parameters of the model\n",
    "    \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print('Checking accuracy on the %s set' % split)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "            scores = model(x, params)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weight(shape):\n",
    "    \"\"\"\n",
    "    Create random Tensors for weights; setting requires_grad=True means that we\n",
    "    want to compute gradients for these Tensors during the backward pass.\n",
    "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
    "    # randn is standard normal distribution generator. \n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params, learning_rate, loaders, device='cpu', dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A Python function that performs the forward pass of the model.\n",
    "      It should have the signature scores = model(x, params) where x is a\n",
    "      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
    "      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
    "      scores for the elements in x.\n",
    "    - params: List of PyTorch Tensors giving weights for the model\n",
    "    - learning_rate: Python scalar giving the learning rate to use for SGD\n",
    "    \n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    loader_train, loader_val = loaders\n",
    "    \n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "        \n",
    "        # Move the data to the proper device (GPU or CPU)\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass: compute scores and loss\n",
    "        scores = model(x, params)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        # Backward pass: PyTorch figures out which Tensors in the computational\n",
    "        # graph has requires_grad=True and uses backpropagation to compute the\n",
    "        # gradient of the loss with respect to these Tensors, and stores the\n",
    "        # gradients in the .grad attribute of each Tensor.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters. We don't want to backpropagate through the\n",
    "        # parameter updates, so we scope the updates under a torch.no_grad()\n",
    "        # context manager to prevent a computational graph from being built.\n",
    "        with torch.no_grad():\n",
    "            for w in params:\n",
    "                w -= learning_rate * w.grad\n",
    "\n",
    "                # Manually zero the gradients after running the backward pass\n",
    "                w.grad.zero_()\n",
    "\n",
    "        if t % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "            CheckAccuracy(loader_val, model, params, device=device, dtype=dtype)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.4100\n",
      "Checking accuracy on the val set\n",
      "Got 149 / 1000 correct (14.90%)\n",
      "\n",
      "Iteration 100, loss = 1.8748\n",
      "Checking accuracy on the val set\n",
      "Got 371 / 1000 correct (37.10%)\n",
      "\n",
      "Iteration 200, loss = 2.1303\n",
      "Checking accuracy on the val set\n",
      "Got 377 / 1000 correct (37.70%)\n",
      "\n",
      "Iteration 300, loss = 1.9884\n",
      "Checking accuracy on the val set\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Iteration 400, loss = 1.7753\n",
      "Checking accuracy on the val set\n",
      "Got 412 / 1000 correct (41.20%)\n",
      "\n",
      "Iteration 500, loss = 1.7512\n",
      "Checking accuracy on the val set\n",
      "Got 414 / 1000 correct (41.40%)\n",
      "\n",
      "Iteration 600, loss = 1.7685\n",
      "Checking accuracy on the val set\n",
      "Got 427 / 1000 correct (42.70%)\n",
      "\n",
      "Iteration 700, loss = 2.3982\n",
      "Checking accuracy on the val set\n",
      "Got 439 / 1000 correct (43.90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n",
    "w2 = random_weight((hidden_layer_size, 10))\n",
    "loaders = [loader_train, loader_val]\n",
    "\n",
    "train(TwoLayerFullyConnected, [w1, w2], learning_rate, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "\n",
    "channel_1, KW1, KH1 = 32, 32, 32\n",
    "channel_2, KW2, KH2 = 16, 32, 32\n",
    "\n",
    "conv_w1 = random_weight((channel_1, KW1, KH1))\n",
    "conv_b1 = zero_weight((channel_1, KW1 * KH1))\n",
    "conv_w2 = random_weight((channel_2, KW2, KH2))\n",
    "conv_b2 = zero_weight((channel_2, KW2 * KH2))\n",
    "fc_w = random_weight((3 * 32 * 32, hidden_layer_size))\n",
    "fc_b = zero_weight((hidden_layer_size, 10))\n",
    "\n",
    "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "train_part2(three_layer_convnet, params, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
