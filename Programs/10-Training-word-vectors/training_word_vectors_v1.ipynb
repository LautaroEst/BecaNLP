{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando word vectors desde un corpus plano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='\\n\\n'>\n"
     ]
    }
   ],
   "source": [
    "with open('hp1.txt','r') as file:\n",
    "    corpus = file.read()\n",
    "    corpus = re.sub(r'\\n+\\d+\\n+\\x0c',r'\\n',corpus)\n",
    "    corpus = re.sub(r'\\n+\\d+\\n+\\b',r'\\n\\n',corpus)\n",
    "    corpus = re.sub(r'[^\\.:?!]\\n+',corpus) # ???\n",
    "    with open('hp1_v2.txt','w') as file2:\n",
    "        file2.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengo el corpus con el que se va a trabajar. El mismo consiste en una lista de documentos (strings) que no están separados en tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(token_series):\n",
    "    return token_series.split(' ')\n",
    "\n",
    "corpus = ['El niño que vivió','El señor y la señora Dursley, que vivían en el número 4 de Privet Drive, estaban orgullosos de decir que eran muy normales, afortunadamente. Eran las últimas personas que se esperaría encontrar relacionadas con algo extraño o misterioso, porque no estaban para tales tonterías.','El señor Dursley era el director de una empresa llamada Grunnings, que fabricaba taladros. Era un hombre corpulento y rollizo, casi sin cuello, aunque con un bigote inmenso. La señora Dursley era delgada, rubia y tenía un cuello casi el doble de largo de lo habitual, lo que le resultaba muy útil, ya que pasaba la mayor parte del tiempo estirándolo por encima de la valla de los jardines para espiar a sus vecinos. Los Dursley tenían un hijo pequeño llamado Dudley, y para ellos no había un niño mejor que él.']\n",
    "corpus = [tokenizer(par) for par in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengo el vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLPDataUtils import Vocabulary\n",
    "\n",
    "vocabulary = Vocabulary()\n",
    "for doc in corpus:\n",
    "    for token in doc:\n",
    "        vocabulary.add_token(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "words = pd.Series([token for doc in corpus for token in doc])\n",
    "contexts = pd.Series([doc[max(0,i-window_size):i]+doc[i+1:min(i+window_size+1, len(doc))] for doc in corpus for i in range(len(doc))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hago todo eso pero adentro de la clase Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipGramModel(\n",
       "  (emb): Embedding(101, 100, padding_idx=100)\n",
       "  (out): Linear(in_features=100, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Word2VecSamples(Dataset):\n",
    "    \n",
    "    no_token = '<NT>'\n",
    "    \n",
    "    def __init__(self, corpus, window_size=2):\n",
    "        \n",
    "        # Obtengo el vocabulario a partir del corpus ya tokenizado:\n",
    "        self.corpus = corpus\n",
    "        self.vocabulary = Vocabulary()\n",
    "        for doc in corpus:\n",
    "            for token in doc:\n",
    "                self.vocabulary.add_token(token)\n",
    "                \n",
    "        # Obtengo el contexto a partir del corpus:\n",
    "        self.window_size = window_size\n",
    "        self.data = pd.DataFrame({'word': [token for doc in corpus for token in doc],\n",
    "                                  'context': [[self.no_token for j in range(i-window_size, max(0,i-window_size))] + \\\n",
    "                                              doc[max(0,i-window_size):i] + \\\n",
    "                                              doc[i+1:min(i+window_size+1, len(doc))] + \\\n",
    "                                              [self.no_token for j in range(min(i+window_size+1, len(doc)),i+window_size+1)] \\\n",
    "                                              for doc in corpus for i in range(len(doc))]\n",
    "                                 })\n",
    "        self.padding_idx = len(self.vocabulary)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        if type(idx) == torch.Tensor:\n",
    "            idx = idx.item()\n",
    "        \n",
    "        word_vector = torch.tensor(self.vocabulary.token_to_index(self.data['word'].iloc[idx]), dtype=torch.long)\n",
    "        context_vector = torch.zeros(2 * self.window_size, dtype=torch.long)\n",
    "        for i, token in enumerate(self.data['context'].iloc[idx]):\n",
    "            if token == self.no_token:\n",
    "                context_vector[i] = self.padding_idx\n",
    "            else:\n",
    "                context_vector[i] = self.vocabulary.token_to_index(token)\n",
    "            \n",
    "        return word_vector, context_vector        \n",
    "        \n",
    "        \n",
    "class CBOWModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOWModel,self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size)\n",
    "        self.out = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.out(self.emb(x))\n",
    "    \n",
    "    def loss(self,scores,target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        return lf(scores,target)\n",
    "        \n",
    "class SkipGramModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel,self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size+1, embedding_dim, padding_idx=vocab_size)\n",
    "        self.out = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.out(self.emb(x))\n",
    "    \n",
    "    def loss(self,scores,target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        if target.size() != torch.Size([2]):\n",
    "            context_size = target.size(1)\n",
    "            scores = scores.view(-1,self.vocab_size,1).repeat(1,1,context_size)\n",
    "            print(scores)\n",
    "            print(target)\n",
    "        return lf(scores,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-be45de14d605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m train_dataloader, val_dataloader, test_dataloader = generate_data_batches(train_dataset, \n\u001b[0m\u001b[1;32m     12\u001b[0m                                                                           \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from TorchDataUtils import *\n",
    "\n",
    "def tokenizer(token_series):\n",
    "    return token_series.split(' ')\n",
    "\n",
    "\n",
    "# FALTA HACER UNA FUNCIÓN TrainWord2Vec(..., model='SkipGram') QUE NO SIGA EL FORMATO DE UN PROBLEMA\n",
    "# DE CLASIFICACIÓN COMÚN.\n",
    "corpus = ['El niño que vivió','El señor y la señora Dursley, que vivían en el número 4 de Privet Drive, estaban orgullosos de decir que eran muy normales, afortunadamente. Eran las últimas personas que se esperaría encontrar relacionadas con algo extraño o misterioso, porque no estaban para tales tonterías.','El señor Dursley era el director de una empresa llamada Grunnings, que fabricaba taladros. Era un hombre corpulento y rollizo, casi sin cuello, aunque con un bigote inmenso. La señora Dursley era delgada, rubia y tenía un cuello casi el doble de largo de lo habitual, lo que le resultaba muy útil, ya que pasaba la mayor parte del tiempo estirándolo por encima de la valla de los jardines para espiar a sus vecinos. Los Dursley tenían un hijo pequeño llamado Dudley, y para ellos no había un niño mejor que él.']\n",
    "corpus = [tokenizer(par) for par in corpus]\n",
    "dataset = Word2VecSamples(corpus, window_size=2)\n",
    "vocab_size = len(samples.vocabulary)\n",
    "embedding_dim = 100\n",
    "model = SkipGramModel(vocab_size, embedding_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
