{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000lines [00:06, 19259.70lines/s]\n",
      "120000lines [00:11, 10141.52lines/s]\n",
      "7600lines [00:00, 9775.71lines/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_data', '_labels', '_vocab'])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import text_classification\n",
    "NGRAMS = 2\n",
    "import os\n",
    "if not os.path.isdir('./AG_NEWS'):\n",
    "    os.mkdir('./AG_NEWS')\n",
    "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
    "    root='./AG_NEWS', ngrams=NGRAMS, vocab=None)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(train_dataset.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.', 'wall st', 'st .', '. bears', 'bears claw', 'claw back', 'back into', 'into the', 'the black', 'black (', '( reuters', 'reuters )', ') reuters', 'reuters -', '- short-sellers', 'short-sellers ,', ', wall', 'wall street', \"street '\", \"' s\", 's dwindling\\\\band', 'dwindling\\\\band of', 'of ultra-cynics', 'ultra-cynics ,', ', are', 'are seeing', 'seeing green', 'green again', 'again .']\n",
      "{0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "label, text = train_dataset[0]\n",
    "print([train_dataset._vocab.itos[idx] for idx in text])\n",
    "print(train_dataset._labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_data', '_labels', '_vocab'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['freqs', 'itos', 'unk_index', 'stoi', 'vectors'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._vocab.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset._vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000lines [00:06, 18986.18lines/s]\n",
      "120000lines [00:12, 9830.98lines/s] \n",
      "7600lines [00:01, 6956.23lines/s] \n",
      "120000lines [00:06, 19395.22lines/s]\n",
      "120000lines [00:12, 9637.79lines/s] \n",
      "7600lines [00:00, 10519.38lines/s]\n",
      "120000lines [00:06, 17637.29lines/s]\n",
      "120000lines [00:12, 9850.71lines/s] \n",
      "7600lines [00:00, 10292.33lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import text_classification\n",
    "NGRAMS = 2\n",
    "import os\n",
    "if not os.path.isdir('./AG_NEWS'):\n",
    "    os.mkdir('./AG_NEWS')\n",
    "\n",
    "\n",
    "class AgNewsDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, n_grams=2, train=True):\n",
    "        \n",
    "        super(AgNewsDataset, self).__init__()\n",
    "        train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
    "            root='./AG_NEWS', ngrams=n_grams, vocab=None)\n",
    "        \n",
    "        if train:\n",
    "            self.samples = train_dataset._data\n",
    "            self.vocabulary = list(dict(train_dataset._vocab.freqs).keys())\n",
    "            self.freqs = dict(train_dataset._vocab.freqs)\n",
    "        else:\n",
    "            self.samples = test_dataset._data\n",
    "            self.vocabulary = list(dict(test_dataset._vocab.freqs).keys())\n",
    "            self.freqs = dict(test_dataset._vocab.freqs)\n",
    "            \n",
    "        self.vocabulary.insert(0,'UNK_TOKEN')\n",
    "        self.vocabulary.insert(1,'PAD_TOKEN')\n",
    "        self.word_to_index = {w: idx for (idx, w) in enumerate(self.vocabulary)}\n",
    "        self.index_to_word = {idx: w for (idx, w) in enumerate(self.vocabulary)}\n",
    "        self.size_of_longest_sentence = max([len(sample[1]) for sample in self.samples])\n",
    "        self.categories = ['World', 'Sports', 'Business', 'Sci/Tec']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label, text = self.samples[idx]\n",
    "        text = torch.nn.functional.pad(text, pad=(0,self.size_of_longest_sentence - len(text)),mode='constant', value=0)\n",
    "        return text, label\n",
    "\n",
    "train_dataset = AgNewsDataset(n_grams=2, train=True)\n",
    "val_dataset = AgNewsDataset(n_grams=2, train=True)\n",
    "test_dataset = AgNewsDataset(n_grams=2, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "val_size = .02\n",
    "NUM_TRAIN = int((1 - val_size) * len(train_dataset))\n",
    "NUM_VAL = len(train_dataset) - NUM_TRAIN\n",
    "sampler = lambda start, end: torch.utils.data.SubsetRandomSampler(range(start, end))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=batch_size, \n",
    "                                               sampler=sampler(0, NUM_TRAIN))\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                             batch_size=batch_size, \n",
    "                                             sampler=sampler(NUM_TRAIN, NUM_TRAIN+NUM_VAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
