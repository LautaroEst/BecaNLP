{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pickle \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./sk_trainers.bin', 'rb') as trainerfile:\n",
    "    sk_trainers = pickle.load(trainerfile)\n",
    "    \n",
    "with open('./cbow_trainers.bin', 'rb') as trainerfile:\n",
    "    cbow_trainers = pickle.load(trainerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = sk_trainers[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = './promptsl40.test'\n",
    "with open(test_filename, 'rb') as testfile:\n",
    "    test_text = testfile.readlines()\n",
    "    \n",
    "test_corpus = [['<s>'] + re.split(r'[\\t \\n]',l.decode('iso-8859-1'))[2:-1] + ['</s>'] for l in test_text]\n",
    "test_corpus = [token for line in test_corpus for token in line]\n",
    "\n",
    "output_file = './lm_train_corpus_test_vocab2'\n",
    "GetARPAFile(trainer, test_filename, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</s>': tensor(8.3430e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " '<s>': tensor(-8.1956e-08, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'a': tensor(-7.6834e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abajo': (tensor([-0.1810, -0.8899, -1.0474, -0.6912,  0.2812, -0.5244,  0.0606,  1.2552,\n",
       "           0.7112, -0.4764, -1.0618, -0.0129, -0.5282,  0.0050,  0.1958, -0.0674,\n",
       "           0.9452,  1.3584,  1.5953,  0.6555,  1.3833,  0.7740, -1.2991,  0.3094,\n",
       "          -0.8814, -0.1037,  1.1682, -1.8618, -0.0631,  0.3105,  0.7339, -0.7794,\n",
       "           0.7623,  0.9310,  0.9216, -0.0511, -1.9860,  0.3733, -1.3024, -0.0413,\n",
       "           1.9797, -1.0360, -0.6007,  0.3736, -1.2942, -0.9886, -0.7774, -1.3826,\n",
       "          -1.7762, -0.4799]),\n",
       "  tensor([ 0.9560,  1.0033,  1.4417,  0.4846,  0.2170, -1.6857, -2.1488,  1.8250,\n",
       "          -0.8176,  0.1793, -0.3157, -0.1217, -0.7121, -1.9062,  0.4175,  0.5692,\n",
       "           0.7243, -0.6129, -0.8558, -0.4048,  0.8371,  1.1215,  0.5434, -0.0496,\n",
       "          -1.2617,  0.2532, -0.1614,  0.7517,  2.1238,  0.9551, -0.5140,  0.4445,\n",
       "           0.6474,  1.5940, -0.6228,  0.0629,  0.5339,  1.7094,  1.9732, -0.3026,\n",
       "          -0.0441, -0.8107,  0.0672,  0.3399, -2.0038, -0.3695,  0.7733, -1.8454,\n",
       "          -0.0669,  1.2343])),\n",
       " 'abandonada': (tensor([ 1.8988,  1.0077, -2.7080, -1.9203,  0.0780, -1.5014, -0.0710, -0.2655,\n",
       "           0.1668, -1.0095,  1.1785, -0.0380, -0.6025, -0.2112,  0.7254,  1.7486,\n",
       "          -0.5866, -0.5764, -2.6812,  1.1268, -2.5325,  1.0014,  0.3571,  0.6761,\n",
       "           0.0778,  1.4271,  0.0871,  0.4089,  0.0163, -3.9327,  0.7104,  1.9479,\n",
       "           0.4607,  0.5190, -1.3708,  1.2320, -0.3715, -3.3963,  0.3606, -1.0172,\n",
       "          -0.1448, -0.7104, -0.0608, -0.4185,  2.3177,  0.0236, -0.3831, -1.4777,\n",
       "          -0.5728, -0.3947]),\n",
       "  tensor([-0.1269,  1.4793, -0.2096, -0.0892, -1.5061, -2.2370,  0.4020, -1.8484,\n",
       "          -0.1353, -0.6909,  0.5343,  1.1051,  1.8827, -0.2275, -0.4433, -0.1027,\n",
       "          -1.4338,  0.9622, -0.5503,  1.8387, -0.2913,  1.2074, -0.7334, -0.3892,\n",
       "           1.3294,  0.5709,  1.0949,  1.6714, -0.1184, -0.2198, -0.0937,  0.3363,\n",
       "          -0.7210, -2.3463,  1.3813, -1.7702,  0.2623,  0.4413,  0.5424, -1.5273,\n",
       "          -0.7702, -0.2752,  1.8081, -1.2377, -2.1281,  0.5253,  0.2648,  1.6719,\n",
       "          -0.7286, -0.3405])),\n",
       " 'abandonado': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abarcan': (tensor([ 0.1884,  0.0910, -1.0291,  0.1900, -0.4829,  1.4466,  0.7272, -0.3968,\n",
       "          -0.3693, -1.5546, -0.7545, -1.5211,  0.5247, -0.3660, -0.9207,  0.0307,\n",
       "          -0.6288, -0.7492,  0.6742, -2.0880,  0.4258,  0.6131,  0.2346,  0.4689,\n",
       "           0.7868,  0.3456,  0.5902,  0.3434,  0.0695,  1.3412,  0.6360,  1.3854,\n",
       "          -0.6404, -1.1918,  0.6100, -0.0811,  1.6519, -0.1700, -0.5733, -0.6381,\n",
       "           0.6198, -0.2931,  0.7775, -0.8219,  0.4035, -0.4314,  0.2275,  0.1950,\n",
       "           1.8753, -0.4662]),\n",
       "  tensor([-1.5309, -1.1420,  0.5095, -0.5471,  1.8435,  0.5868, -0.0049,  1.2839,\n",
       "          -0.9244,  1.3261,  1.2429, -0.0100,  0.4799,  0.6955, -1.4249, -0.5260,\n",
       "           0.6458, -1.1080,  0.3183,  0.9835,  1.1809, -2.0691, -0.3969,  0.9765,\n",
       "           0.2830, -1.1695,  1.1297, -0.8195,  1.9630, -1.5471,  0.5464,  1.5927,\n",
       "           0.9514,  1.2699, -0.9646,  0.9705,  0.4892, -0.6420, -0.5332, -0.4450,\n",
       "          -1.0092,  0.1913, -1.9172,  0.8988,  0.2849, -1.4453,  0.0633,  1.7945,\n",
       "           0.0809, -1.5773])),\n",
       " 'abastecimiento': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abatir': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abierta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abiertas': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abierto': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abra': (tensor([ 0.1440,  0.8059,  0.1800, -1.2003,  0.6908, -0.8125,  0.9407, -0.1628,\n",
       "          -1.1311, -1.7240,  0.1217, -1.3201,  0.3297, -0.2474, -0.2323,  0.4927,\n",
       "          -1.4508, -1.2892, -0.8482,  0.3110, -0.4038,  0.7459, -1.6130, -0.7333,\n",
       "          -1.8849,  0.8472,  0.6985,  0.4155,  1.8095, -1.2220, -1.1427,  0.1704,\n",
       "           0.3690,  0.9830, -0.0804,  0.4721,  0.6137, -0.5163, -0.1256, -0.6590,\n",
       "           1.4313,  0.2371, -0.6306,  0.3655,  0.6285, -0.4127, -2.1662, -0.5352,\n",
       "          -0.7636,  0.5377]),\n",
       "  tensor([-0.3026,  0.6218, -0.7736, -0.5029,  0.8351, -1.0919, -1.2234, -1.4985,\n",
       "           1.6184, -1.2625,  0.6922,  0.0805, -0.5600,  0.7471,  1.1547, -1.5330,\n",
       "          -1.0280,  0.6666,  0.4336, -0.6516, -0.8969, -0.5225, -1.3275,  0.2309,\n",
       "          -2.3553,  1.3927, -1.5725, -1.0088,  0.5522,  0.3301,  2.4318,  0.2982,\n",
       "           0.9620,  0.9566,  1.7994,  1.2256,  2.0845,  0.0103, -1.6187, -0.3775,\n",
       "           0.2423, -1.0633,  1.0662,  1.9304,  0.0339, -0.5411,  2.6417,  1.8437,\n",
       "           0.2205, -0.6127])),\n",
       " 'abrigamos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abril': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abri√≥': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'abstracto': (tensor([ 1.4397, -1.8225, -1.2962, -0.3344,  0.5002, -0.4192, -0.5031, -0.4991,\n",
       "           0.8153,  0.4469,  0.4644, -1.1480,  1.4808,  2.4263,  0.5045,  0.1549,\n",
       "          -0.9837, -1.0969, -0.8007,  1.2469,  0.1889,  0.4799,  1.1829, -1.3649,\n",
       "          -0.3142, -0.2330,  0.6647, -0.5822, -1.4824,  0.3421, -1.8063, -0.8156,\n",
       "           0.6739,  0.2843,  0.3629, -0.4947,  0.3125,  0.3760, -0.0961, -0.3162,\n",
       "          -0.3380, -1.7901, -0.5862, -1.2972, -1.3738, -2.1381, -0.0356,  1.5193,\n",
       "           0.0552,  1.4594]),\n",
       "  tensor([ 0.1386,  0.3219, -0.5514, -0.7978, -0.8326, -0.9604,  2.2156, -1.0581,\n",
       "           0.3652, -1.8014,  0.4802,  0.6877,  0.5289,  1.2013, -0.1346, -2.1958,\n",
       "           1.2024,  0.6497, -1.8878,  0.4106,  0.9765, -0.0352,  0.8075, -0.6673,\n",
       "           0.0058, -1.1945, -0.6186, -0.5144,  0.5532, -0.4859, -1.5273,  0.9163,\n",
       "           0.1442, -0.6384, -0.7125, -0.5466,  1.1028, -0.8419, -0.1782,  0.5498,\n",
       "           2.2430,  2.2021,  0.4413, -1.4895, -1.1179, -0.3363,  1.1930,  0.8797,\n",
       "          -1.4836,  0.8865])),\n",
       " 'abundan': (tensor([-1.2424e+00,  8.6817e-01, -1.1107e-01,  2.4247e-01, -2.6819e-02,\n",
       "          -5.5637e-01,  4.6212e-01,  7.6606e-02,  2.3862e-01, -5.9627e-01,\n",
       "          -1.0593e+00,  5.5245e-01, -1.5939e-01,  2.4046e-01,  2.1359e+00,\n",
       "          -6.1753e-01, -7.9108e-01, -5.7005e-01, -1.1039e+00, -1.5459e+00,\n",
       "          -4.3003e-01, -2.1348e-03, -8.9099e-01, -4.7312e-01, -5.5141e-01,\n",
       "          -8.5176e-02,  5.4215e-01,  8.1583e-01,  6.6209e-01,  5.2600e-01,\n",
       "           7.1040e-01,  9.6385e-04,  4.2111e-01,  1.1590e-01, -1.9835e+00,\n",
       "           6.3595e-01, -2.8932e+00,  1.0862e+00,  1.0206e+00,  2.4331e+00,\n",
       "          -8.0429e-02,  1.7556e+00,  9.4548e-01, -6.2214e-01,  4.0941e-01,\n",
       "          -6.7479e-01,  3.4026e-01,  1.0756e+00,  1.1857e+00,  2.0272e+00]),\n",
       "  tensor([ 0.5994,  0.0315, -1.1685,  0.0548,  0.5140, -0.4418, -1.2620, -0.6989,\n",
       "           1.5480, -1.6600, -1.3154,  0.6859, -1.1567,  0.0769, -1.3353,  1.1606,\n",
       "          -2.4206, -1.1435,  0.6197, -1.0598,  0.5346, -0.5521, -0.7420,  0.1517,\n",
       "          -0.9127,  0.2895,  1.0316, -1.4926,  1.0125, -0.1735, -0.8593,  1.1972,\n",
       "           1.2297,  0.7435,  0.6129,  0.5519, -2.0092,  0.8895,  1.8336,  0.5075,\n",
       "           1.1142,  0.8530,  0.1166, -0.6492, -1.1918, -0.0120, -1.2778,  1.6342,\n",
       "           1.3224,  0.8122])),\n",
       " 'aburrida': (tensor([-0.0535, -0.7496, -1.2829, -0.8851, -0.0408, -0.7116, -1.1351, -0.4756,\n",
       "           1.6295,  0.4987, -0.2756, -1.1717, -1.3410, -1.5019, -0.9764, -0.3604,\n",
       "          -0.3452, -3.1410, -2.1207, -0.7678,  0.6188, -2.1980,  0.8303,  0.2267,\n",
       "          -0.5329, -0.3962, -0.2273,  0.1586,  0.2141, -1.5566, -0.8229,  1.5662,\n",
       "          -1.9666, -0.9914,  2.1151, -0.7258,  0.4961, -0.2954,  0.2947,  0.1698,\n",
       "           1.4184,  0.7386, -1.0027,  0.0032,  1.6788,  1.4186, -2.3292,  0.8169,\n",
       "          -1.5127,  1.2634]),\n",
       "  tensor([-0.3118,  1.2724,  1.6800, -0.4490,  0.7657,  1.7887, -1.5486, -1.4081,\n",
       "           0.8579,  0.9656, -0.5757,  0.8491,  0.3269,  1.7408,  0.2379,  1.2495,\n",
       "           0.9261, -0.1221, -0.3791,  0.1994,  0.0417, -1.7780, -3.0413,  0.2650,\n",
       "           0.0221, -1.1195, -1.1894,  0.1830,  0.5760, -1.6073,  1.0514, -1.2311,\n",
       "          -0.8932,  0.7685,  2.0556,  0.5134,  0.7775, -0.3203,  1.5186,  0.5532,\n",
       "           0.0602, -2.3003, -0.0454, -0.8832, -0.2849,  0.3764,  0.3442,  0.6492,\n",
       "          -0.9017, -0.1011])),\n",
       " 'acaba': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acaben': (tensor([ 7.9076e-01, -4.6277e-01,  5.4953e-01,  7.5261e-01,  8.4100e-01,\n",
       "           1.9134e-01, -7.5278e-01, -1.4375e-01, -2.8077e-01, -4.6470e-01,\n",
       "          -5.4530e-01,  1.3938e-03,  1.5464e-01, -5.3044e-01,  5.0396e-01,\n",
       "          -3.8471e-01, -1.2775e+00, -1.3661e+00,  1.8259e+00, -2.2785e+00,\n",
       "           3.7556e-01, -2.1465e-01, -1.8528e-01,  4.5803e-01, -1.7565e-01,\n",
       "           1.6681e-01,  8.5155e-01, -1.5968e+00,  1.0157e+00, -9.3372e-01,\n",
       "           2.1378e-01, -6.4956e-01, -8.5333e-01, -8.0266e-01, -2.9875e+00,\n",
       "          -1.0678e+00, -1.3259e+00,  3.1944e+00,  8.3184e-01, -5.3805e-01,\n",
       "           1.4618e+00,  1.9184e-01,  1.3796e-01, -1.0841e+00, -2.2582e+00,\n",
       "          -6.4705e-01, -2.5890e-01,  1.5286e-01,  1.8202e+00, -4.6933e-01]),\n",
       "  tensor([ 0.9945,  1.2051,  0.7399,  1.5306, -1.2870, -0.8134, -0.2171,  0.4523,\n",
       "           0.8356, -0.6435,  0.1842, -0.1084,  0.1581,  0.4223, -0.5472,  0.1092,\n",
       "          -0.7894,  1.8954, -0.4711,  1.1288,  0.0491, -1.5161, -0.7209, -0.8322,\n",
       "          -1.7052, -0.2834, -1.2057,  0.2131, -0.1867,  0.5935,  0.8568, -0.7538,\n",
       "          -0.6257, -0.6097, -0.9301,  0.1155, -0.2657, -0.7323, -0.9697,  0.3204,\n",
       "          -1.1123,  1.4933,  0.3966,  0.2516, -0.8452,  2.3686,  1.2089, -0.6185,\n",
       "          -0.5753,  0.5545])),\n",
       " 'acaso': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acatamiento': (tensor([-3.8017e-02, -1.5952e+00, -3.4239e-02, -1.1603e-01, -4.5407e-01,\n",
       "          -4.1094e-01,  1.2895e-01,  4.5771e-01,  5.1530e-01,  2.5161e+00,\n",
       "           1.8030e+00, -1.2324e+00,  9.0410e-01, -1.1295e+00, -2.5722e-01,\n",
       "           1.1762e+00,  8.4941e-01,  4.6562e-01, -1.5542e-01, -9.5981e-01,\n",
       "          -1.0024e-01, -3.8112e-02,  9.7549e-01,  1.6505e+00,  2.2877e-01,\n",
       "           3.5465e-01,  1.2613e+00,  1.4843e-01,  1.1300e+00, -2.6247e-01,\n",
       "          -3.7771e-01,  9.1660e-02,  9.8677e-01, -9.0252e-01, -4.1784e-01,\n",
       "           5.7894e-01, -1.6114e+00,  6.6375e-01,  1.4776e+00, -2.3241e-01,\n",
       "          -5.3380e-01,  1.4525e-03, -7.3557e-02, -8.8276e-01, -1.4845e+00,\n",
       "           1.0915e+00, -1.0462e+00,  1.1913e+00,  1.5940e-01, -1.0134e+00]),\n",
       "  tensor([ 0.0806, -0.9189, -0.4377, -0.4839,  0.1074, -0.2905,  0.0161,  1.2527,\n",
       "           1.1505, -0.6548,  1.3203, -0.6006,  0.9019,  0.4859,  0.0205, -2.1329,\n",
       "          -1.0758,  1.6561,  1.5427, -1.2519, -0.5427,  1.5970,  0.3834, -0.0221,\n",
       "           1.1600,  0.8302, -0.5690,  0.9308, -0.4987, -0.6400, -1.0372, -0.0472,\n",
       "           0.1336, -0.0145, -1.2319,  0.3118,  0.7254,  0.3052,  0.2552,  0.9139,\n",
       "          -0.0376,  0.1582, -0.6323, -1.0731,  0.8909,  1.2296,  0.2638, -1.4536,\n",
       "          -0.7394,  1.2275])),\n",
       " 'acceder': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acceso': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'accidente': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acciones': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acelerar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acento': (tensor([-1.8615,  0.0070,  0.3160, -1.0061,  1.6565, -0.9284, -0.2713,  0.4768,\n",
       "           0.1518, -1.3647, -0.5564,  3.0559,  0.2136, -0.7561, -0.3982, -1.7191,\n",
       "           0.0581, -0.7639, -0.9411, -0.0170, -0.0314, -0.3562,  0.5748, -0.3969,\n",
       "           0.7484, -0.6379,  0.1727,  0.2506,  1.8257, -0.5990, -0.8740,  0.6363,\n",
       "          -0.4610, -0.3119, -1.6773,  0.1134,  1.1696, -1.7330,  1.2003, -1.3146,\n",
       "           1.2741, -0.8072, -0.6030,  1.3180,  0.2235, -1.2155, -0.0125, -0.2519,\n",
       "          -1.0668, -0.6585]),\n",
       "  tensor([ 0.4008, -0.9775,  0.9900,  0.1522, -1.1928, -0.0696, -0.3204,  0.0745,\n",
       "           0.0419,  0.3988, -1.5544, -0.0487, -1.2445, -0.2922, -1.3882, -0.1440,\n",
       "          -0.2724,  0.8482,  0.6535,  1.4507,  0.9814, -0.5061,  0.0520, -0.1070,\n",
       "           2.3057, -1.4584,  0.1798,  0.4353, -0.6882, -1.1529, -0.0536, -1.6555,\n",
       "          -0.0202, -0.1650, -1.3609, -0.4531,  0.6168, -0.2579,  0.4323, -1.1605,\n",
       "          -1.8948, -0.6852, -0.3909,  1.0001, -0.8828, -0.2914, -0.6074, -1.8476,\n",
       "           2.1202,  2.0914])),\n",
       " 'aceptable': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aceptar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aceptarla': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acepto': (tensor([ 1.0073, -0.2648,  0.4877, -0.8209,  0.0878,  2.8863,  0.4441, -0.7334,\n",
       "           1.1217, -0.1278, -0.3027,  0.5424,  0.4565, -1.4044, -0.7416,  0.1708,\n",
       "          -1.0982, -0.8341,  0.7140,  1.6252,  0.4915, -0.2119,  2.3366,  0.0085,\n",
       "          -2.5240,  1.1517,  0.1299, -0.4948, -0.4305, -0.9150,  0.3990, -0.1100,\n",
       "          -1.0466,  0.5240,  0.6994,  0.4899,  0.3614, -2.4340, -0.5044, -0.9180,\n",
       "          -1.3733, -0.4093, -0.2184, -0.1020,  0.2266,  1.3783,  0.1260, -0.2110,\n",
       "           1.1612,  0.4284]),\n",
       "  tensor([ 0.1454, -1.4212, -1.3607,  0.2392,  1.4580,  0.4441,  0.2569, -0.9159,\n",
       "           1.2296, -0.7646, -0.6028, -0.1292, -0.2347, -0.2545, -0.7396,  0.0503,\n",
       "           1.0050,  1.4551,  1.5060, -0.1554,  0.3460,  0.1806, -0.9526,  0.0796,\n",
       "           2.0907, -1.3491, -1.8208,  0.2303,  0.9266,  0.2678, -0.6652,  0.4878,\n",
       "           1.7156, -0.8904, -1.1931,  0.0149, -0.4374,  0.0819, -0.6144, -0.2552,\n",
       "           1.1051,  1.0069,  0.0213,  1.5091, -0.6547,  1.0785,  0.4798, -0.5626,\n",
       "          -1.1277, -1.6866])),\n",
       " 'acept√≥': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aclara': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aclararlo': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acomete': (tensor([-0.3155, -0.9729,  0.9984,  0.1429, -0.9499,  0.6483,  0.9604, -1.1609,\n",
       "          -0.0279,  0.0778,  1.1588, -1.9369, -0.6961, -0.9736,  0.8802, -0.3171,\n",
       "          -0.2885,  0.1415,  0.2935,  0.2692, -0.5281,  0.3313,  0.3658, -1.6938,\n",
       "          -0.2485,  1.2076,  1.2991,  0.6498,  3.5401,  0.0991, -0.6903, -0.6206,\n",
       "          -0.7178,  0.1787,  0.5578,  1.0386, -0.5446, -0.1347,  0.8060,  1.7839,\n",
       "           1.4150,  1.8684,  0.0175,  0.1487,  0.0115,  0.2152,  0.8218,  1.4419,\n",
       "          -0.1366, -1.0766]),\n",
       "  tensor([ 2.4016e+00,  3.0558e-01, -7.5460e-01, -5.4950e-01,  2.8254e-01,\n",
       "          -4.9974e-01,  1.1417e+00,  1.8308e+00,  2.4468e+00, -4.0886e-01,\n",
       "          -1.3320e+00, -1.1308e+00,  1.5045e+00, -1.3722e+00, -1.4913e-01,\n",
       "          -5.8954e-01, -2.6671e+00, -9.9024e-01, -4.8159e-01,  1.0670e+00,\n",
       "          -9.7363e-02, -1.9638e+00, -1.7199e+00,  1.3411e+00, -4.6968e-02,\n",
       "          -2.6427e-03,  8.0589e-01, -1.2125e+00, -1.5245e+00,  1.0788e-01,\n",
       "           3.7674e-01, -3.2326e-01,  9.4692e-01, -9.8666e-01, -2.3553e-03,\n",
       "           1.0743e+00,  1.3276e+00, -1.6992e-01, -1.8031e+00,  3.3847e-01,\n",
       "          -3.2784e-01, -1.1646e+00,  4.9937e-01,  5.5961e-01, -1.7508e-01,\n",
       "           9.0274e-01,  3.1602e-01,  2.8949e-01, -6.9445e-01,  1.4459e-01])),\n",
       " 'acontecimiento': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acopla': (tensor([-0.4714, -1.0364,  0.5087, -0.6487,  0.3716,  2.0938, -0.6103,  0.4667,\n",
       "           1.5171, -3.6144, -0.3022, -0.6723,  0.4918, -1.7663, -1.0032,  1.6241,\n",
       "          -1.2664, -0.2470,  0.5796,  0.4453, -0.4843,  0.4037, -0.9502,  1.0508,\n",
       "          -2.4304,  0.2104,  0.0227,  0.9090,  0.2386, -2.0864, -0.0104,  0.3213,\n",
       "           2.3198, -1.8177, -0.7775,  0.5858,  1.5921, -0.4160,  0.2977,  0.3166,\n",
       "           0.5510,  0.2076, -1.2653,  0.6565, -0.0732,  0.3958, -0.9801, -0.4443,\n",
       "          -0.9150, -0.0834]),\n",
       "  tensor([ 0.6703,  0.3910,  0.3342,  0.1154,  0.3988,  0.1806,  0.6920,  1.4087,\n",
       "          -1.3068,  0.1502, -0.3128, -1.1123,  0.4041,  0.8599,  0.6166, -0.7397,\n",
       "          -0.6532,  0.5428,  0.0426,  0.9170, -0.2357,  0.1941,  0.8497,  1.9535,\n",
       "           0.0554,  0.1205, -0.8165,  0.9155,  0.4636,  0.7862, -0.5832,  0.6379,\n",
       "           0.3423, -0.7715,  1.4033, -0.5742, -0.4483,  0.9875,  1.4625,  1.4412,\n",
       "          -0.2079, -1.1716, -0.9061,  0.7191, -0.4291,  0.1837, -1.1102,  1.2331,\n",
       "           1.6687, -0.2543])),\n",
       " 'acordaron': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acord√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acortar√°n': (tensor([ 0.4492,  1.7650,  0.3357,  0.7755, -0.1784,  0.5311, -0.4403, -1.2263,\n",
       "          -0.6324, -0.2122, -0.4790,  0.0493, -1.4730, -0.3743, -0.0239, -0.0875,\n",
       "          -0.4165, -0.2527, -1.7251, -0.6581, -1.1616, -0.9453,  0.3312, -1.4712,\n",
       "           0.2295, -0.6072, -0.9451,  0.5747,  0.3189,  1.0452, -0.5495, -0.3623,\n",
       "          -1.5153, -0.7310, -0.0863, -0.0373, -0.1101, -1.4649, -0.8253, -1.4094,\n",
       "          -0.4775, -0.0709, -0.4101,  0.4801,  1.2438,  1.0189, -1.3478,  0.3282,\n",
       "          -0.2815,  0.4729]),\n",
       "  tensor([-0.8106, -0.8685, -0.3108,  1.3565,  1.0867, -1.6899,  0.8459, -1.1848,\n",
       "           1.5868, -1.2111,  0.6642,  0.8038, -0.8260, -1.1301,  0.0759,  1.2183,\n",
       "           0.7593, -1.5712, -0.6247,  0.8061,  0.5299,  0.6183,  0.4266, -1.3004,\n",
       "           0.5949,  0.9395, -1.0352,  1.5584, -1.2736,  0.5700,  0.5089, -0.5343,\n",
       "          -0.9452,  1.2128,  1.5216,  2.2601, -0.1619,  2.2232,  0.6694, -0.0326,\n",
       "          -1.3264, -0.4439, -2.1331, -1.8033, -0.8817, -0.4744,  0.2199, -0.4321,\n",
       "           1.1730, -0.9081])),\n",
       " 'acosta': (tensor([-0.1656, -1.7793, -1.9016, -0.7547, -0.9376, -0.4099,  1.9054,  0.4420,\n",
       "          -0.4525,  0.5502, -1.4397, -1.7781,  0.8431, -0.1177, -0.3557,  1.6018,\n",
       "           0.5353, -0.1484, -0.6069, -0.5994,  1.4997, -0.7737, -0.8563,  1.3633,\n",
       "          -0.9291,  0.4820, -1.7961,  1.0468,  0.5809, -0.2535, -1.5937,  0.2375,\n",
       "           0.7438,  0.8322, -1.3970,  0.9633,  0.8703, -0.6714,  0.7903,  1.2146,\n",
       "          -2.5755,  0.5884,  1.2535, -1.2005,  2.6010,  1.9194, -0.8863,  0.6442,\n",
       "          -0.0914, -2.7701]),\n",
       "  tensor([-0.8697,  0.4498,  0.1734, -0.7626,  0.2505, -0.5609,  1.4442,  0.3208,\n",
       "          -0.8007, -1.2641,  0.7669, -0.6339, -0.2619,  0.8067,  0.5290,  0.6282,\n",
       "          -0.0216, -0.7730,  1.6696, -0.2890, -1.6217, -1.0713,  0.5162, -0.2847,\n",
       "          -0.2323,  0.9951, -0.8896, -1.0556,  0.4155, -2.0070, -0.4804, -0.2174,\n",
       "          -0.2611, -2.3619, -0.2030,  1.3578,  0.5563, -1.0201, -1.2318, -0.7387,\n",
       "           0.9858,  0.2630,  0.4937,  1.6694, -0.5853, -1.0362, -2.0683, -2.3315,\n",
       "           0.1224, -0.9073])),\n",
       " 'actitud': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actividad': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actividades': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'activo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'activos': (tensor([ 1.4347, -1.8109, -1.0906,  0.0739, -0.3565,  1.1425, -0.0689,  0.9159,\n",
       "          -0.7792,  0.0825,  0.8256,  0.4090,  1.3758,  0.0947,  0.6707,  1.2937,\n",
       "           1.5501,  0.0042,  1.2185,  1.1368, -1.2443,  0.9725, -0.1222, -1.3500,\n",
       "           0.6213, -0.3991,  1.2828, -0.9394, -0.5814, -0.5918, -0.1830, -0.7623,\n",
       "          -0.2190, -1.1306, -0.5797,  1.2647, -1.8450, -0.6329, -1.7144, -1.0195,\n",
       "           1.9621,  0.6854, -0.1696,  1.3093, -1.2540,  1.5622, -1.2158, -0.1526,\n",
       "           0.6135, -0.4717]),\n",
       "  tensor([ 0.5776,  1.8988,  1.7079, -0.4677, -0.6018, -1.5804,  0.6384, -0.3984,\n",
       "           0.0316,  0.7288,  0.0792, -0.3571, -0.0561, -0.3325, -0.7236,  2.0451,\n",
       "          -0.2517, -0.0638,  0.1415,  1.3369, -1.4647,  0.1452, -1.0855, -0.4706,\n",
       "           1.6361, -0.4789,  1.7642, -0.7239, -1.0314,  0.6083, -0.0358,  0.6016,\n",
       "          -0.4232, -0.0337, -1.1620,  1.1013,  1.3659,  1.0517, -0.2329,  0.6861,\n",
       "          -1.8459, -0.1851, -0.0565,  0.6060, -0.4679,  0.2854,  0.4372,  0.8412,\n",
       "          -1.4362, -0.9234])),\n",
       " 'acto': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actor': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actuaciones': (tensor([-1.1662,  0.1661,  1.1923, -0.6113,  0.6539, -1.2909, -0.9916,  1.5996,\n",
       "          -0.2801, -0.8229, -0.4485,  0.0569,  0.7761, -0.3513,  1.6988,  1.5110,\n",
       "          -1.0401, -0.2182,  2.0745, -0.7201,  1.2233,  1.2535,  0.4310, -0.7786,\n",
       "           1.0794,  0.1663,  0.3575, -0.3517, -0.1572, -0.6557,  0.5346, -2.3399,\n",
       "          -0.1482, -2.1715, -1.0410, -0.2713,  1.5757, -0.8882,  0.1677, -1.0603,\n",
       "           0.9680, -0.2249, -0.5484, -0.6513, -0.7439, -0.0333,  1.7599, -0.8943,\n",
       "          -1.0633,  1.5150]),\n",
       "  tensor([ 4.4140e-02, -3.7475e-01,  1.0670e-01,  9.5806e-01, -3.0103e-01,\n",
       "           6.3211e-01,  6.5426e-01,  2.1614e+00,  1.7272e-01,  3.4589e-01,\n",
       "           1.8722e+00,  7.4942e-02, -1.5402e+00,  1.0936e-01, -1.0312e-02,\n",
       "           3.1250e-01,  1.3724e+00, -1.6541e+00,  1.2103e+00,  7.2128e-01,\n",
       "           6.7006e-01,  6.7555e-01,  3.3595e-01, -2.0027e-01, -3.7356e-01,\n",
       "           1.0878e+00, -7.9910e-01,  7.7382e-01,  6.2243e-01, -9.8327e-01,\n",
       "           9.0709e-01,  7.6663e-01, -2.0837e+00, -1.2068e+00,  8.0505e-02,\n",
       "           1.2973e-01,  5.7081e-01,  2.9141e-01, -1.3859e+00, -1.4511e-03,\n",
       "          -4.1711e-01,  1.7298e+00, -1.5386e+00,  9.7837e-01,  6.7251e-01,\n",
       "          -9.4656e-01,  1.7696e+00, -8.6750e-01,  1.1384e+00, -8.0423e-01])),\n",
       " 'actual': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actualidad': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actualizan': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actualizar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actualmente': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actuando': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actuar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'actuar√©': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acude': (tensor([-0.2343, -1.2886,  2.0446,  1.0040,  0.6809,  0.2564, -1.0569, -1.3020,\n",
       "           0.5341, -2.0254,  1.4743,  0.0095,  1.2765,  0.6504, -0.1080, -1.0002,\n",
       "           0.3681,  1.1994,  0.4385,  0.0886, -2.3345,  0.9501, -0.4647,  0.2987,\n",
       "          -0.2767,  0.1758,  1.3055,  2.0168,  1.5736,  1.5756, -0.3257, -0.7180,\n",
       "           0.3090, -0.7115,  0.1326, -0.9005,  1.7782,  0.0094,  1.2544,  0.5311,\n",
       "           0.6200, -1.6694, -0.6920, -0.2357, -0.2028, -2.0315,  0.6143, -1.9838,\n",
       "          -1.0283, -0.3479]),\n",
       "  tensor([-0.0788,  0.0762,  0.1441,  0.4065,  1.4102, -0.0761, -0.5602,  1.1440,\n",
       "          -1.8625, -0.3969,  0.4843,  1.1963, -2.7462, -0.0242, -0.0585, -0.4874,\n",
       "           2.3688, -2.1172,  0.5821, -0.1955,  0.3373, -0.7686, -0.5016, -0.3408,\n",
       "           0.1760, -0.2960, -0.4464,  1.1430, -0.2545,  0.5518, -0.2273,  0.4824,\n",
       "          -0.2039,  1.3504,  1.2454, -0.8309, -1.5027,  0.1963,  0.5356, -0.3758,\n",
       "          -0.6987,  0.6331,  0.5814, -0.3847,  0.6109, -0.1895, -0.5511, -2.6317,\n",
       "          -1.2869, -1.4136])),\n",
       " 'acuerdan': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acuerdo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acusaciones': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'acusados': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adelante': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adelanto': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adem√°s': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adicionales': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adi√≥s': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adjudica': (tensor([-0.2335, -0.6580, -1.1504, -0.0486, -1.4558,  0.2307,  1.3990,  0.5330,\n",
       "           0.9969,  0.0342,  1.0208, -2.1290,  2.0073,  0.6184,  0.9788,  0.3869,\n",
       "          -0.8998,  2.0731,  2.5909,  1.7812, -1.4575,  1.8517,  1.2434,  0.1496,\n",
       "          -0.9368, -1.8540, -1.8165,  1.3990, -0.3540, -1.3378,  0.4723,  0.1610,\n",
       "           0.2438,  1.7615, -0.3354,  0.3397,  0.5924, -0.8738,  1.2025, -2.1608,\n",
       "          -0.6293, -0.0921,  1.9665,  1.9389,  0.5691,  1.1824,  2.5517, -1.7682,\n",
       "           0.9882, -1.2222]),\n",
       "  tensor([ 0.0666,  1.2301, -0.1594, -0.9526, -0.0077,  0.8434,  0.7526,  1.5255,\n",
       "           0.6374,  0.0502, -0.6305, -0.0725,  1.1929,  0.2482,  0.1837,  0.8813,\n",
       "          -1.5360,  0.3137, -2.3794, -2.2970,  1.0025, -0.6298,  1.9726, -0.0631,\n",
       "           0.9197, -0.5153,  1.6044,  0.8980,  0.2871, -0.9017,  0.5869,  2.3956,\n",
       "           0.5398,  1.4247, -0.0808, -0.4592, -0.4831, -1.0523,  0.9593, -0.2131,\n",
       "           0.1867, -0.0282, -0.7339, -2.4326, -1.2971, -1.2574,  0.3346,  0.5731,\n",
       "          -0.6697, -1.0440])),\n",
       " 'adjudicada': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adjunta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adjuntan': (tensor([-1.0172,  0.2950,  0.0804, -0.7393,  0.7820,  0.8222,  1.5926,  0.3474,\n",
       "           0.5646, -1.4158, -1.2400,  0.1151,  0.6857, -0.9494, -0.7831,  0.0443,\n",
       "           0.1330, -0.4207,  1.3006, -0.9579,  1.1278,  0.2085, -0.7059,  1.0296,\n",
       "          -1.1516, -0.8541,  0.1385, -0.2560,  0.1565,  0.5095, -2.1681,  0.5888,\n",
       "           0.0869,  0.6468, -1.3758, -0.0111, -0.4529,  0.4750, -1.5462, -0.6429,\n",
       "           0.3337, -1.2477,  0.6789, -1.6137,  0.8508, -1.9404, -0.0392, -0.6312,\n",
       "           0.0382, -0.8042]),\n",
       "  tensor([ 1.0407,  0.5456, -0.4645, -2.0241, -0.2883, -0.9141, -1.0535,  0.7672,\n",
       "           0.1722, -1.5069, -0.3729, -0.4430,  0.2094, -2.1724, -1.7083, -1.4284,\n",
       "           0.5226, -1.2450,  0.6886, -1.4741,  1.8643, -1.0011,  0.0078, -1.0277,\n",
       "           0.0119, -1.0399, -0.4992,  1.1350, -1.1781,  1.0220,  1.3273, -0.3561,\n",
       "          -0.4369,  0.9313,  0.0874,  1.7074,  0.0245, -2.1285,  0.1664,  0.8183,\n",
       "           0.6134, -1.2307, -2.2668, -0.2163, -0.3892,  0.2812, -0.7741,  1.5126,\n",
       "           0.4951, -0.5543])),\n",
       " 'adjunto': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'admite': (tensor([ 1.3376, -0.6137,  0.8516,  2.3291, -1.3968, -1.6336, -0.0092, -0.5635,\n",
       "           0.1914,  0.4568, -2.1066,  0.9447,  0.2751, -2.8072,  0.6115, -1.7779,\n",
       "          -1.4122, -1.7323, -0.0754, -0.9266, -1.1871,  0.4255,  0.8242, -0.6710,\n",
       "           0.0933, -1.4889, -0.6180,  0.3958,  1.5384,  0.3228, -0.7514,  1.4187,\n",
       "           1.1443,  0.6161,  0.0404,  0.4397,  0.2278, -0.8811,  1.2717, -0.2070,\n",
       "          -0.9383, -0.5052,  0.0758, -1.4183,  1.0216,  1.6186,  0.3345, -0.0951,\n",
       "          -1.1330,  1.2925]),\n",
       "  tensor([ 0.4293, -1.4615, -1.7370,  0.2009, -0.0724, -0.7658,  0.5339,  0.4115,\n",
       "           2.1415,  0.8012,  0.9410,  0.7100,  0.6722, -0.7446,  0.8683,  0.5237,\n",
       "          -0.4412,  0.0940,  1.0556,  1.6946,  1.1740,  1.9169,  0.5070,  0.2458,\n",
       "          -0.2517,  0.5258, -2.4623,  0.1240, -0.0071,  1.3877, -0.9770, -0.9770,\n",
       "          -1.2411, -0.2878, -0.0676,  0.4801,  1.3278,  1.0027,  0.3091, -1.1537,\n",
       "           1.2414,  0.5750, -0.7708, -0.3755,  1.5010, -0.3584,  0.4752,  0.3159,\n",
       "          -1.1294,  1.0038])),\n",
       " 'adoptado': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adoptar√°': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'adoptar√°n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aduc√≠a': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'advirti√≥': (tensor([ 0.4758, -0.6142,  1.2764,  1.8809, -1.1366, -1.5082, -0.5107, -0.5929,\n",
       "          -0.0163,  1.5148,  1.3420, -1.1498,  1.0749, -1.1280,  1.0571, -1.6995,\n",
       "           0.8519,  1.4610,  0.6890,  0.3105, -1.4327,  1.0785,  1.7805,  1.4502,\n",
       "           0.3477,  0.1906, -0.1956, -0.6353,  0.4558,  0.7621, -2.3045,  1.5298,\n",
       "          -1.2341, -1.7249,  0.6241, -1.3467,  0.4620, -1.1456, -1.2296,  2.0851,\n",
       "           2.6041,  0.5660,  1.6827,  0.0887,  0.9610,  0.3905, -0.2687, -0.6608,\n",
       "          -0.2115, -1.5503]),\n",
       "  tensor([-4.2265e-01,  8.9394e-01,  2.4651e-01, -4.8132e-01,  6.1411e-01,\n",
       "          -6.9965e-01, -2.2402e-01,  8.8389e-01, -9.7082e-02, -3.0685e-02,\n",
       "           9.0754e-01, -1.7506e+00, -2.0851e+00,  1.2745e+00, -9.4410e-01,\n",
       "          -1.2728e+00,  1.2991e-01, -8.6000e-01, -1.5500e+00,  8.6390e-02,\n",
       "          -1.9923e-03, -9.2927e-01, -2.7256e-01, -6.5608e-01,  7.7782e-01,\n",
       "          -6.9227e-01, -7.2340e-01,  2.4110e-01, -2.1793e-01,  1.9727e-01,\n",
       "           5.3870e-01,  2.1450e+00, -3.3025e-01,  3.3545e-02,  7.6730e-01,\n",
       "          -6.7477e-01, -2.2028e+00,  5.7068e-02, -6.4687e-01,  2.4430e-01,\n",
       "           2.9139e-01,  2.7619e-01, -7.6050e-02, -3.4061e-01, -2.0624e+00,\n",
       "          -1.1252e+00,  1.4413e+00,  1.0914e+00,  1.1433e+00,  3.0706e-01])),\n",
       " 'aeropuerto': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aeropuertos': (tensor([ 0.0029,  2.1590,  1.0250,  0.0381, -1.7410,  1.0710, -1.4482,  1.3406,\n",
       "           0.1582, -0.5870, -0.8748, -1.4544, -0.4686,  1.1190, -0.0685,  1.5826,\n",
       "           1.0895, -0.1925,  1.1430, -0.2064,  0.7775,  1.0509,  0.4865, -0.4394,\n",
       "          -0.2711,  0.8775,  0.1376,  0.6176, -0.5571, -0.8755, -0.8369,  1.2830,\n",
       "           0.6691, -0.2937,  1.1082,  0.5499, -0.4047,  0.4286, -0.2406, -0.2447,\n",
       "           2.2919,  0.1454, -0.2129,  0.3733, -0.8628,  0.3954, -0.2818, -1.7056,\n",
       "           0.2725,  0.3449]),\n",
       "  tensor([ 0.1616,  0.4722,  1.6474, -0.1386,  0.0740,  1.2427,  0.6782, -2.3996,\n",
       "           0.3127,  0.6532, -0.6557, -1.3925, -1.4552, -0.3335, -3.6191, -0.3329,\n",
       "          -0.8763,  0.3019,  0.2222,  0.8548,  0.9488,  0.1504, -0.8894,  1.0151,\n",
       "          -0.0835,  0.3850, -0.9401, -0.9815, -0.5457,  0.7345,  1.3023,  0.1758,\n",
       "           0.6940, -1.0174, -0.0900,  0.8683,  0.0725,  0.8496,  0.3215, -2.6707,\n",
       "          -1.7599, -0.3023,  0.7096,  1.0860,  0.2328,  1.0711,  0.1882,  0.8798,\n",
       "           1.4053,  1.2439])),\n",
       " 'afectados': (tensor([ 1.1198, -1.1167, -0.2157, -1.9028,  0.2679, -0.5318,  0.8746,  1.3004,\n",
       "           0.4128, -0.1776, -1.0538, -0.2143, -0.3045,  1.5991, -0.1658, -0.9280,\n",
       "           0.0296, -0.7768,  0.2541, -1.0466, -0.5601,  0.5393, -0.3738, -0.5161,\n",
       "           1.5000, -2.0773,  1.0067,  0.1122, -1.0316, -0.9212,  0.7066,  0.5708,\n",
       "          -0.5229,  2.2927, -1.7665,  1.4024, -0.0288, -0.1765, -1.3337,  0.8808,\n",
       "           0.2119, -0.3511, -0.8635, -0.4948,  1.1019, -1.4965, -1.0578,  0.4406,\n",
       "          -0.0426, -1.6331]),\n",
       "  tensor([ 0.9017,  1.4091,  0.3592, -1.1731,  0.4008, -0.1716, -0.3279, -0.1291,\n",
       "          -0.1435, -1.4031, -0.9316,  0.9382,  0.1512,  0.7550,  0.4462,  0.6885,\n",
       "          -1.6200, -0.6386,  0.2827,  1.0638, -0.4747,  0.8956,  0.7535, -1.1743,\n",
       "          -1.7991,  2.5596,  1.3346, -0.4420,  0.6871,  1.9636,  1.1737,  0.1224,\n",
       "          -0.9308,  0.8041, -0.2490,  1.6489, -0.3635,  1.7954,  0.2367, -0.3265,\n",
       "          -1.3186, -0.4643,  0.3953, -0.1457,  1.9392,  0.5837,  0.2155,  0.4628,\n",
       "          -0.6104, -0.5450])),\n",
       " 'afiliaci√≥n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'afirma': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'afirmativo': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'afirm√≥': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agencia': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agente': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agradecemos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agradeceremos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agradecerle': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agradezco': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agrava': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agrav√≥': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agreg√≥': tensor(-4.1723e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agresi√≥n': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agrupaci√≥n': (tensor([-1.6023,  1.4281, -0.1175, -0.8542,  1.0461, -0.4559,  0.3794, -0.4868,\n",
       "          -0.2609, -0.7770,  0.1278,  0.0071, -0.2158,  0.8226,  0.3135,  1.0610,\n",
       "           2.3014, -0.1141,  0.0658, -0.7138, -0.3875,  0.3857,  2.5865, -1.8252,\n",
       "          -1.9641,  0.2383, -0.7015, -0.2452, -1.6523,  1.2190,  0.1122,  1.2900,\n",
       "          -0.0391, -0.2722, -2.2072, -0.4177,  0.6943,  0.5801, -0.4013,  1.7021,\n",
       "          -0.3532, -1.4470, -1.7362,  0.6385, -0.6829, -0.4280,  0.0124,  0.4868,\n",
       "           0.5373,  0.3466]),\n",
       "  tensor([ 0.6086, -1.0326,  0.1797, -0.5376,  2.2253,  1.0751, -0.1625, -0.2912,\n",
       "          -0.3330,  1.4280, -1.1943, -0.1976,  0.4417,  1.5067, -1.2715, -0.4145,\n",
       "          -0.8385,  1.5837,  0.2310,  0.3189,  0.4771, -0.1146, -1.0769, -0.5058,\n",
       "          -0.0645, -0.1134,  0.8411, -0.3570,  0.8216,  0.6388,  1.2619, -0.6237,\n",
       "           0.8849,  0.1430,  2.4619,  0.4166,  1.1134,  1.4674,  0.0803, -1.0342,\n",
       "          -1.5175, -0.2660,  0.3885, -2.3694,  0.2829, -0.5211,  1.0389, -0.3990,\n",
       "          -0.2282,  0.1544])),\n",
       " 'agr√≠cola': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'agua': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aguarda': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aguarme': (tensor([ 0.0579, -1.3233, -0.5311,  0.4318,  1.5725,  0.0340, -0.1898, -0.7266,\n",
       "           0.1403, -1.1668, -1.4812, -0.3616,  0.0965, -0.5411,  0.3882, -1.0738,\n",
       "          -0.5872,  1.0174, -0.3820,  1.1616,  0.3918,  1.3684, -1.5548, -1.5913,\n",
       "          -0.9925, -0.4202, -0.8495,  0.1288, -1.6065, -0.8819, -1.4543, -1.6236,\n",
       "          -0.9518,  0.0835, -0.1400,  0.6163, -0.6116,  0.6713,  0.2991,  2.5165,\n",
       "           0.9735, -0.4266, -1.4582, -0.5193,  0.5117,  0.8307, -0.6959, -0.2116,\n",
       "           0.6993,  1.8233]),\n",
       "  tensor([-0.5754, -0.2510, -0.1388,  0.2889,  0.0358, -0.2029,  0.3456,  0.0691,\n",
       "           2.2060,  0.7130,  0.5571,  0.4049, -0.9206,  1.6750, -0.7896, -1.5736,\n",
       "          -1.3594, -0.6221, -0.8789,  0.3901, -1.7162, -0.7195, -1.6258,  0.6421,\n",
       "           0.4494, -1.3378,  0.4251, -0.5367, -0.0289,  0.0165, -2.3476,  0.8555,\n",
       "          -1.0243,  1.1416,  0.1677, -0.1273, -0.7770,  0.3959, -0.2034,  1.1000,\n",
       "          -1.2693, -0.7364,  0.0635,  0.1936, -1.2301, -0.5248,  0.8651,  0.3969,\n",
       "           0.6071,  0.1782])),\n",
       " 'aguas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ahondar': (tensor([-1.8901,  0.3862, -0.5748, -1.7082, -0.9345,  1.3586,  0.0576,  0.0219,\n",
       "           0.0392,  0.5522, -0.2220, -0.0486,  3.0362,  1.1122, -0.5616,  0.7149,\n",
       "           0.4162, -0.8213,  1.0717,  0.2408, -0.5677,  0.0880, -0.4242, -1.2791,\n",
       "          -0.1588, -0.8668, -0.5078, -0.4070, -0.5928,  0.5115,  0.7612, -0.2943,\n",
       "           0.3994,  0.8883,  0.5253,  1.0383,  0.0585,  0.4728, -0.4301, -0.2855,\n",
       "           0.4624, -0.9408, -1.0954,  1.1076,  0.7061, -0.2322,  1.0623,  0.2217,\n",
       "          -1.3124, -0.5541]),\n",
       "  tensor([-1.0413, -0.7093,  1.3039,  0.6200, -1.4717, -1.5877, -0.0976,  0.8274,\n",
       "           1.1060, -0.7724, -0.0586,  0.4182,  0.4633,  2.2033,  0.6865,  2.2926,\n",
       "           0.0094,  0.6274,  0.1095, -0.3513,  0.4063,  0.5476, -1.5345,  0.4314,\n",
       "           0.1497, -1.6797, -0.0899,  0.7031,  0.5867, -0.5341,  0.3424,  1.6875,\n",
       "          -0.2011,  0.2923,  0.5252, -0.3773,  0.7038,  1.1359,  0.7942, -2.6897,\n",
       "           0.0409,  0.7836,  0.9042, -0.9224,  1.9956,  0.0634,  1.4063,  0.4988,\n",
       "           0.5204, -0.3478])),\n",
       " 'ahora': tensor(-3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ahorra': (tensor([-0.0605,  1.9078,  0.3384,  0.2102,  0.2861,  0.0497, -0.8960,  0.7092,\n",
       "           0.6052,  0.1713, -0.6905,  0.5386, -0.1100, -1.6920,  0.5685, -0.5212,\n",
       "           0.6650,  0.6579, -0.8584,  1.5382,  0.3552,  0.5742, -0.5486,  0.1593,\n",
       "          -1.0470, -0.2331,  0.8665, -0.2028,  0.6377,  0.3212, -1.0449, -0.2452,\n",
       "           0.0933,  0.8656, -0.5432, -0.7128, -0.2135, -1.2439,  1.5269, -1.9926,\n",
       "           0.3404, -0.0447,  0.3416,  0.9261,  0.1381,  0.7526, -0.3971, -0.0854,\n",
       "          -0.9048, -0.2378]),\n",
       "  tensor([ 2.2585, -0.8899, -0.0049, -0.0363,  0.1655, -0.0424, -0.1533, -0.4476,\n",
       "          -0.9716, -0.8249,  0.1941, -1.8965,  0.5150,  1.0230,  0.0048, -0.2164,\n",
       "          -2.8542,  0.3401,  0.5133,  1.0230,  1.3221,  0.9154, -1.2180, -1.7294,\n",
       "          -1.4502, -0.2769, -1.7224,  0.0296,  0.7292, -0.6206,  0.5129,  0.3957,\n",
       "           1.3667, -0.3374,  0.4801, -1.2033,  1.6108,  0.6001, -0.2870, -0.5633,\n",
       "          -0.5853,  0.7878,  0.2870,  0.2483, -0.4533,  0.1737, -1.4187, -0.0122,\n",
       "           0.9082, -0.1504])),\n",
       " 'ah√≠': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aislamiento': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ajustar√°': (tensor([-0.5677, -1.8696, -1.4153, -1.4529,  1.0983, -2.9502, -0.7580,  0.1381,\n",
       "           1.0281,  0.9371,  0.2277,  0.3456,  1.2401,  1.3851, -0.0057, -0.3948,\n",
       "           2.2131, -0.6154, -1.0944, -1.6867,  0.7334, -1.2113, -0.7495,  1.2752,\n",
       "           0.2254, -0.1943, -0.3890,  1.1507, -1.6630, -0.9887,  1.8696,  0.5689,\n",
       "          -1.1536,  0.4718, -0.1293, -1.9585, -0.5779, -1.7702, -0.0132,  0.6217,\n",
       "           0.3456, -0.2048,  0.8075,  1.7959,  0.3283,  0.4047,  0.1084,  1.8704,\n",
       "           1.6823,  1.1480]),\n",
       "  tensor([ 0.5777, -0.4789,  0.4349, -0.3556,  0.4268, -0.1225,  1.6940, -1.0059,\n",
       "           2.1719, -0.0846,  1.3748,  0.9485,  0.8086,  1.5334, -0.3326,  0.4578,\n",
       "           1.3418, -0.5339, -1.7677, -1.2899, -1.2541,  0.7164, -0.7935,  1.4378,\n",
       "          -1.2275,  0.4283, -1.2306,  0.6629, -0.6347,  1.8530, -0.1478,  0.4635,\n",
       "          -0.6040,  1.3196,  0.0137, -0.9163, -0.1318, -1.1391,  0.2586,  1.2288,\n",
       "           1.0013,  1.8949, -0.0072, -0.5449, -0.3093, -2.0744, -0.1537, -1.6867,\n",
       "           0.5561, -0.0043])),\n",
       " 'al': tensor(-1.8999e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'albacora': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aldeas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alegatos': (tensor([-0.2171,  0.8559, -2.0163,  0.7096, -0.3802,  1.4199,  1.5348, -1.3991,\n",
       "           0.9642, -0.5032, -0.2469,  0.5473,  1.3753, -1.6985,  1.3628, -0.6448,\n",
       "          -0.1287,  0.3860, -0.3868,  0.3391,  2.8378,  0.2727, -0.4608,  0.7325,\n",
       "          -2.3130,  1.9000,  0.5418, -0.2917,  0.8071,  0.7725, -0.0254, -0.2831,\n",
       "           0.7690,  0.6103,  0.2210, -0.8016,  0.1003,  1.9452, -0.7138, -0.8551,\n",
       "           1.9952, -0.6752,  2.1913, -0.6560, -0.6886, -0.9419, -0.3288, -0.9009,\n",
       "           0.6208,  0.7716]),\n",
       "  tensor([ 0.8619, -0.2112, -0.5546,  0.1933, -0.9509,  0.0642,  0.5877, -0.8194,\n",
       "          -0.6783, -2.3116,  0.6495, -0.8509, -0.5865,  0.1692, -1.2372,  1.6201,\n",
       "           0.4577, -1.5963, -0.7282, -0.8268,  0.9744, -0.4478,  0.0280, -0.6922,\n",
       "           0.5059, -1.9368,  0.3217,  0.2826,  1.0549,  0.0351, -0.3821,  0.7528,\n",
       "          -0.9691,  0.0133,  0.4914,  0.5316, -1.2789, -1.4099, -0.3766, -0.7305,\n",
       "           0.2106,  0.8557, -0.3410, -0.8533,  1.1620, -0.4309,  1.1028, -0.2371,\n",
       "          -1.4890, -0.2344])),\n",
       " 'alemania': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alem√°n': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alfons√≠n': tensor(9.5367e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'algo': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alguna': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'algunas': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alguno': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'algunos': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alimentaria': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alla': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'allen': (tensor([ 0.4762,  0.7393,  1.1270,  0.0898,  0.3389,  0.7854, -1.3470,  3.1125,\n",
       "           2.0307, -2.7149,  0.0889, -0.4093, -0.2264,  0.0456,  1.6304, -0.7485,\n",
       "          -1.8253,  2.0907,  0.6545, -0.1929,  1.2799, -1.4268, -1.3179, -2.0228,\n",
       "           0.7276,  1.9990, -0.1555, -1.9125,  0.1593,  0.5229,  0.4929, -0.7048,\n",
       "          -0.1006, -1.0532, -0.6638, -0.2989,  0.9361, -0.3321, -0.9754,  0.8024,\n",
       "           0.4148,  1.1701,  0.5081, -1.1920,  1.8547,  2.2255, -0.1646,  0.4183,\n",
       "           0.7677,  0.4114]),\n",
       "  tensor([ 1.0819,  0.5760, -0.0219, -0.5180, -0.9079,  0.5313, -0.1050,  1.4005,\n",
       "          -0.6209, -2.6705,  1.5202, -1.2365,  0.7531,  0.4369,  1.0245,  0.2853,\n",
       "           0.6796,  0.1193,  0.4822, -0.7135,  1.1207,  0.9365, -0.2259,  0.4872,\n",
       "           0.6539,  0.1902,  1.8024,  0.1370, -1.1337, -0.8038, -0.7297, -1.8903,\n",
       "          -0.8680, -0.0515,  0.5665,  0.5162, -0.4172, -0.1113, -0.9959,  0.3767,\n",
       "           0.3034, -1.5635,  1.0691,  0.8071, -0.4617,  1.6676,  1.1985,  1.1161,\n",
       "          -0.4898, -0.8072])),\n",
       " 'all√°': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'all√≠': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alrededor': (tensor([ 0.2531,  0.0817,  0.6177, -0.1256, -0.6955,  0.0030,  0.1131,  1.3672,\n",
       "           0.1296,  1.1504, -0.0212,  0.5455, -1.1279, -1.1574, -0.5539, -1.2723,\n",
       "           0.4569, -0.5618, -1.8571,  1.5889, -0.0938, -0.3901, -0.1769,  2.0374,\n",
       "           0.3416,  1.5188, -1.1035,  0.0549,  0.1418, -1.6319,  0.7850, -0.7118,\n",
       "           0.5846,  0.3740, -0.5875, -0.4861,  1.8866, -0.8343, -0.2941,  0.6712,\n",
       "          -0.2662,  0.0077, -0.8629,  0.1930, -0.2218,  0.3190, -0.4520, -0.6152,\n",
       "           0.5463,  1.2188]),\n",
       "  tensor([-0.1154, -0.6737, -1.6777, -0.3809,  0.3415, -0.2215, -1.2557,  1.4076,\n",
       "          -0.1901, -1.7772, -0.1612, -0.0265, -1.8329,  0.3093,  0.8980, -0.5449,\n",
       "          -0.1657,  0.2796,  0.7205,  0.2072,  0.2481,  2.2118, -0.4170, -0.1444,\n",
       "           0.1407, -2.0943, -2.0519, -0.9899, -1.3333,  1.3502,  1.6517,  0.1824,\n",
       "           0.1080,  2.3210, -1.1418,  0.6937,  0.5427,  0.0413,  0.4968,  1.4227,\n",
       "           1.9225,  0.5679, -0.6794, -1.3547,  0.5858,  0.3902,  1.2532,  2.2736,\n",
       "           0.7103, -0.5670])),\n",
       " 'alta': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'altibajos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alto': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alvaro': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'alza': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'amable': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'amaz√≥nico': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ambas': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ambos': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'amplia': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ampliado': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ampliamente': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ampliar': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ampliarse': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'amplio': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'amplitud': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'am√©rica': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'analfabetos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'analista': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'analizado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'analog√≠a': (tensor([ 0.3241,  1.0485, -0.0736, -0.2119,  0.1050, -1.0246,  0.1558,  0.5464,\n",
       "           0.7947, -1.0252, -1.6082, -0.1908,  1.9424, -0.2800,  0.3776, -1.0395,\n",
       "           0.0232, -0.8433, -0.8801,  1.0456,  0.0041,  0.6611, -0.6650,  0.0527,\n",
       "           0.6450, -1.5683, -2.0639, -0.3779,  0.5226, -1.2850, -0.9155, -0.1892,\n",
       "          -0.0753,  1.1351, -0.8768, -0.0169,  1.3491, -0.9976,  0.3524, -0.2661,\n",
       "          -0.7874, -0.7001,  1.3384,  1.4989,  0.0232, -1.8092,  0.3459, -0.1234,\n",
       "           0.2315,  0.5611]),\n",
       "  tensor([ 1.3914,  1.5577, -0.8550,  0.3973, -2.5317,  1.2782, -0.6092,  0.0502,\n",
       "          -0.3110, -0.8383, -1.2907, -0.8943, -0.4895,  0.1689,  0.1475, -0.5727,\n",
       "          -0.1678,  1.0457, -1.0356, -0.6252,  0.1282,  1.2360,  1.3846, -0.2860,\n",
       "          -1.0545,  1.1257, -0.0355, -0.4453,  0.6672,  0.6667, -1.2854, -1.3218,\n",
       "           1.6839, -1.7794,  0.8215, -0.2970, -0.1178,  1.8082,  2.2112,  1.3780,\n",
       "           1.7713, -0.1374,  1.4255,  1.0257, -1.7279,  0.2918, -0.0914, -1.9972,\n",
       "           0.9128,  0.5920])),\n",
       " 'anexo': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anexos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anonadado': (tensor([-1.2348e+00,  7.3914e-01,  6.8276e-01,  2.0216e+00,  1.9895e+00,\n",
       "           9.0415e-01, -6.4726e-01, -2.4112e+00, -2.8238e-01,  3.2010e+00,\n",
       "          -2.2586e-01, -1.6008e+00,  1.3037e+00,  1.3094e-03,  6.8290e-01,\n",
       "           2.1577e+00,  1.0251e+00, -1.0233e+00, -6.0138e-02, -2.6555e-01,\n",
       "           6.8660e-01,  1.3902e+00,  5.2354e-03, -6.7039e-01, -7.4293e-01,\n",
       "          -6.2404e-02, -2.9736e-01,  2.1214e-01,  1.5241e+00, -6.8194e-01,\n",
       "          -3.7033e-01, -1.1976e+00,  7.5189e-01, -1.3411e-01, -9.5112e-01,\n",
       "           1.0800e+00, -5.5649e-02,  1.9656e+00, -7.2559e-02,  4.2812e-01,\n",
       "          -2.3601e-02, -1.8522e+00,  1.3071e+00,  1.8990e-01, -5.2506e-01,\n",
       "           1.3571e+00,  2.4149e+00, -1.3610e-01,  2.9880e-01,  2.5879e-01]),\n",
       "  tensor([ 1.6077e+00,  1.3152e+00, -1.9580e-01, -6.2730e-02,  7.4815e-01,\n",
       "          -4.7863e-01,  4.4986e-01, -4.7886e-01,  7.8039e-01, -2.6948e+00,\n",
       "          -2.3610e-02,  1.7973e-01, -2.0064e-01,  7.5182e-01,  1.7792e+00,\n",
       "           2.7496e-01,  6.5675e-03, -7.4750e-01, -2.4548e-01,  1.5339e-01,\n",
       "          -1.3593e+00, -9.4215e-01,  1.3546e+00,  2.3514e-01, -3.6713e-01,\n",
       "          -7.9934e-01,  1.9082e+00, -5.6200e-01, -3.2287e-01, -3.9449e-01,\n",
       "           5.1192e-01, -6.5305e-02,  3.8933e-01,  7.8103e-01, -1.1252e+00,\n",
       "           1.6089e+00, -7.6188e-01, -3.8071e-01, -3.6189e-02,  2.1154e-03,\n",
       "          -7.2701e-01,  1.0897e+00, -1.2560e+00, -4.9987e-01,  7.5318e-01,\n",
       "          -7.2126e-01,  4.5919e-01,  3.9995e-01,  5.9654e-02,  1.2674e+00])),\n",
       " 'anonimato': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ante': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'antemano': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'antenas': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anterior': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anticipado': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anticip√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'antolog√≠a': (tensor([-0.8440, -0.1869, -2.1305, -0.5443, -0.3244, -0.2234, -1.3397, -0.5955,\n",
       "          -0.2120,  0.8463, -1.2964, -0.3205,  1.9503,  0.5473,  0.7325,  1.3149,\n",
       "          -0.1529, -1.4197, -0.4946,  1.2154, -0.5772,  0.5487, -0.2231, -1.1815,\n",
       "           0.4122,  0.5064,  0.9534, -1.1592, -0.2178, -1.4668, -0.7894, -1.7220,\n",
       "          -0.2027, -0.7385, -0.4523,  1.1289,  1.6767,  0.2274, -1.6370,  0.3806,\n",
       "           0.1638, -0.1566, -0.0357,  0.9968,  0.4120,  0.7377, -1.3328,  0.6957,\n",
       "          -0.1496,  0.1220]),\n",
       "  tensor([ 1.2941,  0.5387, -1.1998, -0.1013, -0.5082,  0.3802,  0.3198, -0.0113,\n",
       "          -0.7717, -0.4281,  0.2445,  0.7022,  0.5998, -1.0298, -0.0932, -1.1377,\n",
       "           0.6674,  0.1570, -0.0096, -0.5918,  0.0509, -1.9503,  0.6052, -0.6635,\n",
       "           0.1026, -0.2631,  0.9659, -0.1667,  1.1274,  1.8730, -1.0276, -0.3463,\n",
       "           2.2666, -0.0414, -0.0080,  1.1408,  0.6735, -1.3006, -0.5746,  0.4246,\n",
       "           0.5530,  0.8802,  0.4922, -0.1113, -1.8265,  1.4240,  1.1057, -1.0037,\n",
       "          -0.7908,  0.1649])),\n",
       " 'anual': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anunciado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anunciados': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'anunciar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'an√°lisis': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'apagones': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aparecen': (tensor([ 1.9089, -0.2878,  0.0361,  0.3313, -1.1492,  1.7030, -1.1663,  0.6156,\n",
       "          -0.9201,  0.6904,  0.6496, -1.0007,  0.3060,  2.6164,  0.2277,  1.0525,\n",
       "           1.4642, -0.0664, -0.2703,  0.5358,  1.7513, -1.4205,  1.0256, -0.8465,\n",
       "           0.5890,  1.9389, -1.4073,  0.4571, -1.8622,  0.8604, -0.4151, -1.3746,\n",
       "           0.9283, -1.4254,  1.9272, -0.8546,  1.5205, -0.5450, -0.6783,  0.8841,\n",
       "          -0.5901, -0.4269, -1.2777,  1.6213, -0.8165,  1.5901,  1.8945, -0.0801,\n",
       "           0.1176, -0.5698]),\n",
       "  tensor([ 0.6720,  2.4975,  0.7794, -1.8933,  1.0991, -2.2518, -0.4595, -0.4488,\n",
       "          -0.1936,  0.5006,  1.1271,  0.3985, -1.4871,  0.9235,  0.0789,  0.6617,\n",
       "          -0.6775,  0.5919, -2.5275, -0.3880, -1.1918, -0.4738,  0.4894,  2.2016,\n",
       "           1.2518, -0.0617, -1.4770,  0.8763, -0.6250, -0.4379,  0.5787,  1.3218,\n",
       "          -0.5212, -0.8197, -0.3501, -0.5045,  1.6871, -0.1624,  0.7524, -1.2242,\n",
       "          -1.3557, -1.6383,  0.3997, -0.2370,  0.3434,  0.7394, -0.7571,  0.2234,\n",
       "          -1.0435,  1.0950])),\n",
       " 'aparentemente': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'apelables': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'apelaci√≥n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'apelado': (tensor([-0.9142,  0.1381, -0.5916, -0.9884, -1.1227, -0.6800, -1.2510, -0.6038,\n",
       "          -0.5970, -0.5712,  2.1845,  0.0247, -0.6714,  1.2149,  0.6825,  0.7488,\n",
       "           0.3500,  1.2059,  0.4563, -1.5301,  0.7277,  0.8722,  0.2165, -1.3845,\n",
       "           0.8228,  1.5262,  0.1857, -1.6882, -1.8742,  1.2005, -0.7176, -1.2777,\n",
       "           0.4498,  1.5011,  1.0660,  1.5678,  1.2678,  0.2841,  0.5656, -0.2827,\n",
       "          -0.4430,  0.5740,  3.5910, -0.1956, -0.9850, -1.0698, -1.2019,  0.5127,\n",
       "          -1.1839, -1.4945]),\n",
       "  tensor([ 0.4045, -0.5304, -0.4090,  0.7546,  0.1192,  0.6618,  0.5967, -0.5446,\n",
       "          -0.9882, -1.1292, -0.7036, -0.8103, -1.8769,  0.0618, -1.8378, -0.4846,\n",
       "          -0.4419,  0.1191, -0.5319, -0.2672,  1.5826, -0.4944, -0.6170, -0.1954,\n",
       "          -0.8512,  0.1253, -2.7725, -1.7634,  1.3401,  0.2472, -0.3497,  1.1106,\n",
       "          -0.9280,  0.7651, -0.3636, -1.3547, -1.2619, -0.0697,  1.4263, -0.6521,\n",
       "          -1.7832, -0.9915, -1.4005, -1.3591, -0.5711,  0.0551,  1.7671,  1.6586,\n",
       "          -0.0101,  1.8000])),\n",
       " 'apertura': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aplicaci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aplicar': (tensor([-0.3478,  1.2756, -0.8083, -1.4916,  1.2726,  1.0000,  1.2337,  1.9945,\n",
       "          -0.1316, -0.2974, -0.3048,  1.2584,  0.0288, -1.4791,  1.4907,  0.5836,\n",
       "          -1.3321,  0.3723, -1.0209,  0.8318, -1.4605,  0.0197, -1.6703,  0.4058,\n",
       "           1.0023,  0.4956,  0.3368, -0.4603, -0.0253, -0.5965,  0.2399, -0.4867,\n",
       "           0.4934, -0.4927,  0.4406,  0.9272, -0.1272, -0.1752,  0.5850,  1.9075,\n",
       "          -0.8892,  0.0334, -2.0381,  0.9904, -0.2348,  0.4724,  0.9333,  0.4839,\n",
       "           0.1489, -0.2850]),\n",
       "  tensor([-2.4388, -0.5534, -1.1712, -0.6848, -1.1103,  0.8449,  0.8032, -0.6203,\n",
       "           2.1547, -0.0170, -1.2964, -1.1543,  0.0330, -0.1046,  0.0603,  0.6951,\n",
       "          -0.6321, -1.1224, -1.5375,  0.8362,  0.4010,  1.2778,  0.2501, -0.9976,\n",
       "           1.0661, -0.3965,  0.8966,  1.2972, -2.7313,  1.3210,  1.2997, -1.2915,\n",
       "          -0.5562, -0.5692,  1.2044,  1.1125,  1.1093,  2.0360, -1.1604, -0.1754,\n",
       "          -0.1245,  1.5071,  1.0864, -0.1173,  0.9923,  0.7781, -0.9015, -0.7741,\n",
       "          -1.3608, -0.4955])),\n",
       " 'aportaciones': (tensor([ 1.1152e+00, -6.4199e-01, -2.2121e-01, -9.8916e-01,  2.6362e-01,\n",
       "          -2.3267e-03,  6.5668e-01,  2.1364e-01, -1.2858e-01,  1.0695e+00,\n",
       "           1.4645e+00, -4.9032e-01, -1.7056e+00,  6.7732e-01, -4.9776e-02,\n",
       "          -4.5377e-01, -7.9023e-01,  4.4248e-01, -1.6975e-01, -5.1241e-02,\n",
       "           1.4223e+00,  6.0330e-01,  1.4264e+00,  8.1976e-01, -1.0321e+00,\n",
       "          -4.8584e-01, -2.0974e+00,  1.7810e-01, -3.9057e-01,  2.0260e+00,\n",
       "           5.2249e-01, -1.0798e+00,  1.2627e+00,  6.0983e-01,  5.9367e-02,\n",
       "          -9.0620e-01, -3.5378e+00, -2.0738e+00, -1.7432e+00,  4.6699e-01,\n",
       "           8.5476e-01, -1.3519e+00,  3.3771e-01,  1.3174e-01,  1.6930e+00,\n",
       "           1.9590e+00,  7.3464e-01, -5.9254e-01,  5.5683e-01,  7.5167e-01]),\n",
       "  tensor([-0.7542, -0.4901, -0.2867, -0.9463,  1.0598,  0.3983,  0.7769,  1.2409,\n",
       "          -1.0466,  1.5673, -1.0220, -1.2444, -2.5421,  0.6866,  1.4098, -0.2479,\n",
       "          -0.1567, -0.8757,  0.3747,  0.3304, -0.2556,  0.3736, -0.3447, -0.3978,\n",
       "           0.4776, -0.8849,  0.2326, -0.7932,  1.0884, -0.8678,  1.5549,  1.6068,\n",
       "          -0.5345,  1.2733, -1.8790,  0.4631, -0.3130,  1.2893, -1.3224, -0.3014,\n",
       "          -0.1953,  1.0176, -0.7634, -0.2245,  0.7443,  0.6835, -0.8272,  0.2883,\n",
       "          -0.9774,  0.2535])),\n",
       " 'apoyo': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'apremio': (tensor([-1.8430,  0.2689, -1.9477,  0.0412, -0.4137, -0.1006, -0.5333,  0.2797,\n",
       "          -0.8343,  0.8336,  0.7791, -0.9708,  0.0559,  0.5419, -1.3260,  0.7993,\n",
       "           1.1345,  1.5428,  0.2576, -0.6560, -0.3154,  0.5347, -0.3545, -0.6215,\n",
       "           0.2205,  0.1041, -0.9263, -0.0152,  0.1189, -0.2097,  0.8149, -0.5270,\n",
       "           0.0877, -1.5308, -0.0908,  0.6485,  0.1100,  0.6946,  0.6240, -0.3362,\n",
       "           0.2199, -0.1790,  0.5546, -1.7227,  0.2132, -0.1219, -0.2296,  0.7466,\n",
       "          -0.0606,  0.8813]),\n",
       "  tensor([-0.4459, -0.5229,  0.1864, -0.1791, -0.5101,  0.5862, -0.4743,  0.7591,\n",
       "           1.8173, -0.9901, -0.7477,  0.5025,  0.2236, -0.7496, -0.5446,  1.0176,\n",
       "           0.3671,  0.4298, -0.5257,  0.2014, -0.0067, -1.0686, -2.3019, -0.2922,\n",
       "           0.6333,  0.5502,  0.6310,  1.5109, -0.3551, -0.5222,  0.5904,  0.0709,\n",
       "          -0.8813, -0.5546,  1.1530, -1.2061,  2.1010,  0.7044, -0.9783,  0.0991,\n",
       "           0.8011, -1.4939, -0.6372, -0.4133, -0.1587,  0.5110,  1.1829,  0.3965,\n",
       "           1.0544, -0.2078])),\n",
       " 'aprobaci√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aprobado': (tensor([ 0.7916, -0.7789, -0.0466, -0.2997, -2.3462,  1.5135,  1.3521,  1.3690,\n",
       "           1.5037, -0.3977,  0.6362, -1.1254, -0.2153, -1.0024,  1.1009, -0.7329,\n",
       "          -1.3289, -0.1118,  0.7101,  1.6067,  0.0594, -0.5264, -1.1532, -2.2308,\n",
       "          -1.1399, -1.4129,  2.8138,  0.2108, -0.4060,  2.3567, -1.2628,  0.4480,\n",
       "          -1.7464, -0.0331, -2.0567,  2.0361, -3.0305, -0.8971,  0.1732, -0.6481,\n",
       "           1.1189,  0.5618,  0.7265, -1.7822,  0.7473, -0.3185, -0.1474,  0.6858,\n",
       "          -0.0964,  1.5771]),\n",
       "  tensor([ 0.5108, -0.2700,  0.8183,  0.9394,  0.1991,  0.1710, -0.7048, -0.2233,\n",
       "          -0.9205, -0.7562,  2.7995, -1.0786,  0.1144, -0.8223, -0.5554,  0.8686,\n",
       "           0.0762,  0.5483, -1.0989, -0.8304, -0.2199, -0.1116, -0.8918, -0.8712,\n",
       "           0.6929, -0.2423,  0.7055,  1.0671,  0.7046, -1.8239,  0.0293,  0.9222,\n",
       "          -1.6224,  0.2666,  0.8398, -1.1908,  0.5691,  1.2406,  0.4270,  0.2629,\n",
       "          -0.0425, -1.2516, -1.5398, -1.1136, -1.1009,  0.5595,  0.2145,  2.4261,\n",
       "           0.1801,  0.3540])),\n",
       " 'aprobar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aprobaron': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aprob√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aproximadas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aprueba': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'apuntar√°n': (tensor([ 0.4529, -1.2394,  0.4028, -0.7301,  0.2839,  1.3813, -0.2394,  0.5783,\n",
       "          -0.9377, -1.0047,  1.0859,  0.2451, -0.8077,  0.4004,  0.5537,  0.8453,\n",
       "           0.0252, -1.8861,  1.1618,  0.0227, -0.8693, -0.2217, -0.0169, -0.0579,\n",
       "           0.3787,  1.6841, -0.4667,  1.5315, -0.7252,  0.1031,  1.3157,  0.8657,\n",
       "          -1.0120,  0.4290,  1.2981,  0.3976,  1.2701, -1.7068,  1.9798,  0.9293,\n",
       "           1.4351, -0.4599, -0.2716,  0.8684, -0.2685,  1.4976, -1.1791, -1.6342,\n",
       "           0.2751, -0.1375]),\n",
       "  tensor([-0.4896, -0.6778,  1.1388, -0.1772,  1.0026, -0.5328,  0.7829,  0.6465,\n",
       "           0.0084,  1.2781,  1.4376,  0.7118,  1.1451, -0.4206,  1.0384,  0.6692,\n",
       "           1.1761,  0.4909,  0.5509,  1.1274,  2.0729,  0.0610,  0.8273,  0.6860,\n",
       "          -0.1160,  1.2551,  0.1822, -0.8325, -1.1591, -0.7747, -0.1100, -1.3390,\n",
       "          -1.3244, -2.0784, -0.0179,  0.6715, -0.6976,  0.7056,  0.9182, -0.9232,\n",
       "           1.1882,  0.1956, -0.7730,  0.2636, -1.9283,  1.0335, -0.0941,  0.8302,\n",
       "           0.2397, -0.2069])),\n",
       " 'aquella': (tensor([-0.4079,  0.8716,  1.1710, -0.2327,  0.1461, -0.8161,  0.4135, -0.4439,\n",
       "          -0.4435,  2.0316,  0.6388,  0.5040,  0.3596,  0.6999,  0.3227, -0.3004,\n",
       "          -0.9265, -1.4188, -0.3834, -0.8607,  0.2997,  1.6181, -1.6412,  0.0969,\n",
       "           2.0960, -0.3598, -0.2225, -0.8254,  1.5227,  0.1775, -0.2016,  1.4706,\n",
       "          -0.9414, -1.5520,  0.1953,  0.1805, -0.8194,  0.2105,  0.4438, -0.2219,\n",
       "          -0.2328, -0.1805,  0.2658, -0.1755,  0.6240, -0.5697,  0.9302, -0.2963,\n",
       "          -0.8332,  0.4973]),\n",
       "  tensor([-0.2372, -1.1023, -0.8237, -1.1130, -0.2982,  0.9867, -1.7656,  1.1648,\n",
       "          -0.6756, -1.8433,  1.0880, -1.2263, -0.2016, -0.4048,  0.1768, -2.2206,\n",
       "           0.6349, -1.1617, -0.1266, -1.1869, -1.4486, -0.6968,  1.5780,  0.1892,\n",
       "          -0.2177,  0.7651,  0.5982, -1.6132, -0.3155,  0.1319, -1.7744, -0.9688,\n",
       "           0.8515, -0.6429, -0.5668,  0.7301, -2.4329, -0.1277, -0.0417,  0.3503,\n",
       "           0.3003,  0.6420, -1.1178, -0.3788, -0.5092,  1.0443,  1.6403, -0.3246,\n",
       "           0.1603, -1.3429])),\n",
       " 'arag√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'arbitraje': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aremisos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'argentina': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'argentino': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'arias': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aristide': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'arma': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'armamento': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'armas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'arrecian': tensor(7.1526e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'arreglo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'arrestado': (tensor([-0.6194,  0.8145, -1.1960, -0.0663,  1.3267, -0.3270,  0.7981,  1.2140,\n",
       "          -0.8099,  0.4166,  1.3047,  1.3000,  2.5127,  0.0776, -0.7199, -1.2344,\n",
       "          -0.3438,  1.5421,  0.5552, -1.5134, -1.2058, -0.4155, -0.1434,  0.3204,\n",
       "          -0.3754, -0.3020, -0.1528,  0.2098,  0.4445, -0.2509, -0.2672, -0.1541,\n",
       "          -1.1232,  0.1982,  0.2288,  1.1677, -0.9809,  1.0709, -1.1392,  0.4029,\n",
       "          -0.2109,  0.3421,  0.9218,  0.4593, -0.2382,  0.7089,  0.4961, -0.0474,\n",
       "           0.4506,  0.3614]),\n",
       "  tensor([ 1.3368,  0.6585, -0.4094,  1.1896, -0.4843,  1.4000, -1.2119, -1.0839,\n",
       "          -0.4011,  0.1646, -1.5062,  2.3324,  1.5544, -0.1234,  0.5950,  0.2575,\n",
       "          -1.2406,  0.1303,  1.0402, -0.2858,  1.0105, -1.0829, -0.9482, -0.0547,\n",
       "           0.1058, -0.1041, -1.2306,  0.6087,  1.2000,  0.0609, -0.2298,  0.4375,\n",
       "           0.0501, -0.3813, -0.0722, -0.9488,  2.4853,  0.3642, -0.7738,  0.6146,\n",
       "          -1.0226, -0.1675, -0.3619,  0.6497,  0.6871, -0.1802,  0.1878,  0.5248,\n",
       "          -0.3026, -0.2758])),\n",
       " 'arroz': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'arte': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'artistas': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'art√≠culo': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'art√≠culos': (tensor([ 0.9479,  0.7567, -1.5956,  0.2673,  1.2705,  0.7473, -0.7042, -0.4862,\n",
       "          -0.2038,  0.8657,  0.8499, -0.0337,  0.7612, -0.1401, -1.8151,  0.2732,\n",
       "           0.6445, -0.0442,  1.4923, -0.7359, -1.4576, -0.0667, -0.0368,  0.4189,\n",
       "          -2.1259, -0.3946,  0.3716, -0.5164,  0.7768, -0.2752,  0.6315,  1.5451,\n",
       "           0.2049,  1.2615,  1.3973,  1.0370,  1.7407,  0.9018,  0.5749, -0.1124,\n",
       "           2.3683, -0.8544, -0.8502,  1.3262, -0.0962,  0.5359, -1.6276, -0.3577,\n",
       "          -1.0842, -2.1912]),\n",
       "  tensor([-8.9175e-01,  3.1084e-01, -2.4888e-01,  1.2728e+00, -9.2490e-01,\n",
       "          -4.0966e-01, -2.5403e+00, -1.6101e+00, -1.0949e+00, -8.4174e-01,\n",
       "           8.0127e-01,  1.0742e+00,  5.9712e-01, -4.6437e-01, -4.8708e-01,\n",
       "          -1.0273e+00, -7.7568e-01,  3.4189e-01,  1.0698e+00, -1.7600e+00,\n",
       "           1.6312e+00,  2.3214e-03,  2.2830e-01,  6.3437e-01, -3.9727e-01,\n",
       "          -1.8312e+00,  7.2542e-01, -8.4676e-01,  2.7288e-01, -3.0185e-01,\n",
       "          -2.4926e+00, -8.2124e-01, -8.6413e-01, -1.5230e+00, -8.4067e-01,\n",
       "          -1.1038e+00, -6.7149e-01, -3.4596e-01,  4.6264e-01,  8.3190e-01,\n",
       "          -8.7576e-01, -7.6986e-01,  5.7338e-01,  9.4458e-01,  4.5897e-01,\n",
       "          -2.6335e+00,  2.2071e-02, -2.2040e-01,  6.4982e-01,  6.6835e-01])),\n",
       " 'asalariados': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asamblea': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ascenso': (tensor([ 0.5323,  1.7240,  1.0077,  0.6264, -0.5569, -0.4425,  0.9325, -1.1017,\n",
       "          -0.0906,  1.3632, -1.2711,  1.3007, -0.6789, -0.8039,  0.3953, -0.5683,\n",
       "           0.2657,  0.7567,  0.2133,  1.0115, -0.0859, -0.4359, -0.0519,  0.5356,\n",
       "           1.0595, -1.0472, -0.1617,  0.7362,  0.3587, -0.5441,  0.7372,  1.3912,\n",
       "           0.6690, -0.1233, -1.5002, -1.2856, -0.9688,  1.4059,  0.3943,  0.6511,\n",
       "          -0.8618, -0.4779, -1.5464, -0.5699, -0.2725, -0.8587,  2.1717, -0.8416,\n",
       "          -0.0626, -0.6258]),\n",
       "  tensor([ 2.0296,  0.4124,  0.5204,  0.4133,  1.0314, -2.1503,  1.0604, -1.6984,\n",
       "          -0.7415, -0.3014, -0.3214,  0.3393,  0.1786, -0.1924,  0.9292, -0.3248,\n",
       "          -3.6985,  0.3679,  0.1899, -0.6799,  0.1944, -0.0301, -1.5495, -0.7402,\n",
       "          -0.0980,  2.2313,  0.5175,  0.8421,  0.0284,  0.1644, -2.3854, -0.6890,\n",
       "          -1.0489,  0.8903, -0.9875,  0.8231,  1.7249,  0.8869, -0.5016, -0.2524,\n",
       "           1.1598, -0.9269,  0.2832,  0.4564, -0.6775, -1.5175, -0.2602, -0.4635,\n",
       "           0.7020, -0.3580])),\n",
       " 'asegurado': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asesinar': (tensor([-0.0254,  1.0289, -0.6293, -0.2878, -0.4245, -0.7083,  0.6304, -1.1701,\n",
       "           1.0116, -0.5036, -0.1388,  0.3658, -1.2463, -1.2799, -0.7657,  0.0158,\n",
       "          -1.2090,  1.1328,  0.6079,  1.0264, -0.1040, -1.9109,  0.6699, -0.1234,\n",
       "          -0.1528, -0.8909,  1.4409, -0.0818, -0.4158, -0.5467,  0.7143,  1.2254,\n",
       "           0.5450,  1.0940, -0.4560, -0.7448,  0.2312,  0.5010,  0.4990,  1.1033,\n",
       "          -0.0953,  0.5902,  1.5411, -0.9249,  2.0151, -1.2711,  1.5316, -0.5600,\n",
       "           1.1554, -0.0752]),\n",
       "  tensor([ 0.3243, -0.3293,  0.3827, -0.5860, -0.1292,  0.4996, -0.0896, -0.0465,\n",
       "           1.1658, -0.6877, -0.9303, -0.7562,  0.9174,  0.3735, -0.4253,  0.4549,\n",
       "           0.2255, -1.5124,  0.4400, -0.2239, -0.3841, -0.3845,  1.5339,  1.3221,\n",
       "          -1.1409, -2.9671,  0.2880, -0.4396, -0.3124, -1.5856,  0.7926, -0.0711,\n",
       "           0.0130, -0.5899, -0.7095,  0.0578, -1.9964,  0.8904,  1.5595, -0.1779,\n",
       "          -1.5157, -0.4218, -0.4595, -2.0041, -1.2319, -1.4407,  1.4982, -2.1180,\n",
       "           1.0634,  0.4418])),\n",
       " 'asever√≥': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asignaci√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asimismo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asisten': (tensor([-0.2218,  1.0736, -0.1369,  0.5815,  0.8696,  0.8701,  2.1482,  0.9557,\n",
       "          -0.0572,  0.7219, -0.3104,  1.2684,  0.3880,  0.6795,  0.2226,  0.8430,\n",
       "           1.1819, -0.4729, -0.6930,  0.4767,  0.0559, -0.3383, -1.1875,  0.2190,\n",
       "           2.2689, -0.8934, -0.1678,  0.3365,  0.0639, -0.3894, -1.6453,  0.3947,\n",
       "           1.3951,  0.6593,  1.9267, -0.3413,  0.0726,  0.1084,  1.2388,  0.0120,\n",
       "           1.2480,  0.4955,  0.8935, -0.8604,  0.6987,  1.1408, -3.1278,  3.3837,\n",
       "          -0.2027,  0.5944]),\n",
       "  tensor([-0.2577,  0.6490,  0.8418,  0.0831,  0.4761, -0.3109, -0.3887,  1.3577,\n",
       "          -0.2365,  1.6561,  1.4316,  1.9529,  0.8519, -1.1759, -0.9295,  0.8015,\n",
       "           0.7510, -1.2464,  2.4482,  0.0748,  2.3824, -0.4369, -0.1729,  1.0988,\n",
       "           0.9873, -1.6098, -0.3186, -2.1089,  2.1762, -0.3559,  0.9359, -0.0671,\n",
       "          -1.0226,  0.0938, -1.3805, -1.4556, -0.6373,  0.4672,  0.8326,  1.3777,\n",
       "          -1.9054,  0.7908, -0.3145, -0.0844, -0.9001,  1.6436,  0.0322,  0.9220,\n",
       "          -0.0965,  0.8484])),\n",
       " 'asistencia': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asociado': (tensor([-0.1978,  0.5461, -0.4124, -0.3460, -0.1791,  0.0056, -1.4928, -1.6252,\n",
       "           0.8251, -0.2443, -0.7936, -1.0799, -0.2281,  0.6848, -1.2311, -1.3340,\n",
       "          -0.5014,  0.6766,  1.2377, -0.6268, -1.0991,  0.6084,  0.3471,  0.7467,\n",
       "           0.4188,  0.4570, -0.8753, -1.5803,  1.3540,  0.4843, -0.1759, -0.8184,\n",
       "          -0.2832,  0.2723,  0.1755,  0.5310,  1.1198,  1.0258,  0.4365, -0.6080,\n",
       "          -0.1840,  0.8854, -2.4332,  0.3483, -0.6834, -2.6614,  0.4729,  0.6908,\n",
       "          -2.1586, -0.4696]),\n",
       "  tensor([ 1.2783, -0.4305, -0.1662, -1.6662, -0.8818,  0.8507, -0.0335, -0.6305,\n",
       "           0.3545,  0.6562,  0.3058, -1.0559,  0.8016, -2.6965, -0.8614,  1.1266,\n",
       "           1.0013, -0.6554,  0.3511,  0.8539,  0.7493, -0.3012,  1.6753,  0.5480,\n",
       "           0.4832,  2.2305,  1.4498, -0.2953, -1.6790,  1.0274,  0.6620,  0.0661,\n",
       "           0.7924,  1.3408,  1.8289, -0.7133,  1.2203,  0.9730,  0.6722,  0.6987,\n",
       "          -0.7806,  1.4693,  0.1477,  0.6630,  1.8096, -0.3261, -0.6756, -0.7526,\n",
       "           0.4000,  0.2961])),\n",
       " 'asombro': (tensor([-0.6877, -0.9130, -0.1414,  0.2726, -0.1056,  0.2397,  0.5786,  0.7731,\n",
       "          -0.5828, -0.0040, -0.0522,  1.0974,  1.7789,  0.4054,  0.5308, -0.1774,\n",
       "           0.5422,  1.6824, -1.9684, -1.4451, -0.7244, -1.1054,  1.5846, -0.3744,\n",
       "          -1.8253,  0.6209,  1.4653, -1.1524, -0.7792,  2.0634, -0.7770,  0.7781,\n",
       "           0.5045,  0.1621, -0.6224,  0.2610, -0.5826, -1.9371, -1.2853, -1.0654,\n",
       "          -0.2206, -0.6944, -0.1143, -1.0667, -0.6713, -0.5827,  0.3160,  0.8918,\n",
       "          -1.1958, -0.6213]),\n",
       "  tensor([-1.4711,  0.8069,  0.4048, -0.5866,  1.4421,  1.6042,  0.1216, -0.7804,\n",
       "          -0.0803, -0.0582,  0.5867,  1.0289, -1.2247, -0.9304, -0.7618, -0.5151,\n",
       "           0.2210,  0.3197, -0.5019, -1.0627, -2.0314, -1.0616,  1.2210, -1.2528,\n",
       "           0.4336, -0.4164,  0.4068, -0.3587, -1.4609, -0.2333,  1.7960, -0.2841,\n",
       "           0.4036,  0.6964, -1.8279, -1.7004, -2.1817, -0.1480, -0.2753,  0.5323,\n",
       "          -0.8118,  1.9228,  0.4120, -0.9216,  1.1465,  1.6004, -1.0484, -0.7228,\n",
       "           0.3686, -0.7199])),\n",
       " 'aspecto': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aspectos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aspin': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'assad': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'astronautas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asumir√≠a': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asunto': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'asuntos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'as√≠': tensor(3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atacar': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ataque': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ata√∫d': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atenci√≥n': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atender': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atentado': tensor(9.5367e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aterriz√≥': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atlanta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atraer': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atraviesan': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atribu√≠rlo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atr√°s': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'atuendo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'audaz': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'audiencias': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aumenta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aumentado': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aumentaron': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'aumentos': (tensor([ 1.3726, -0.9911, -0.0124,  1.2631,  0.0112, -0.8842, -0.9425, -0.4916,\n",
       "           0.0089,  0.0167, -0.7829,  1.4121, -0.7612, -0.6318, -0.8349,  0.3927,\n",
       "          -0.2892,  0.6169,  0.7654, -0.9305, -2.8808, -0.2655, -0.1446, -1.4082,\n",
       "           1.8877,  0.9310, -0.5995,  1.6999,  1.0612, -0.7718,  0.4095,  1.3557,\n",
       "          -0.4839,  0.4828, -1.0624, -0.7635,  0.2210,  0.1650, -0.5446,  0.5525,\n",
       "          -0.5483, -1.6089,  1.3583, -0.0252,  0.7792,  0.3322, -0.3595, -1.8389,\n",
       "          -0.7741, -0.1275]),\n",
       "  tensor([ 0.2680,  0.6508, -0.7989, -0.3387, -0.9172,  0.3135, -0.2571,  2.2709,\n",
       "          -0.3472, -1.0250, -1.4736, -1.8232,  0.2287, -0.3059,  1.0762, -0.8460,\n",
       "           0.2731, -0.3744,  0.9933, -2.1965,  0.4945,  0.2379, -1.5057,  1.1187,\n",
       "          -0.0167,  1.0582,  0.5548, -0.0062,  0.0471, -0.8757, -2.4531, -0.7126,\n",
       "           0.1026,  0.5884,  0.3838,  0.0998,  0.1793, -2.3628, -0.1609,  0.7096,\n",
       "           0.6558,  0.9637, -1.3318,  0.7354,  0.5429,  0.2315, -2.3287, -0.2155,\n",
       "           0.4506, -2.5588])),\n",
       " 'aument√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ausencia': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'australiano': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'autob√∫s': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'autoevaluaciones': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'autom√≥vil': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'autom√≥viles': (tensor([-0.2554,  0.0611, -0.5780,  0.5933,  0.6217,  1.9419,  1.2020, -0.0681,\n",
       "           2.0133,  0.7511,  1.0881, -2.7509, -0.3520, -0.5799,  0.1142,  0.5651,\n",
       "          -0.1398,  0.1534,  0.0276, -1.3183, -0.1094,  1.9431,  0.6371,  0.5663,\n",
       "          -0.2675,  0.0779,  0.1546,  0.9196,  2.5611, -1.3537, -0.3335, -0.0351,\n",
       "          -1.1469, -0.6486,  0.6218, -0.2188,  0.8755, -0.9206,  0.6379, -0.4585,\n",
       "          -0.2189, -1.3286,  0.7591, -0.3840, -2.3561, -1.6942, -1.4276,  0.9224,\n",
       "          -0.1440,  1.5784]),\n",
       "  tensor([-2.0341,  0.2316,  3.2083, -0.9671, -0.3817, -0.4901, -1.1929,  1.2954,\n",
       "           1.0745,  0.6244, -0.3329,  0.2378,  0.5317,  0.5781,  1.4604,  0.6393,\n",
       "           0.5533,  1.9201, -1.8872, -0.5605, -0.0406,  1.9363, -0.2795, -1.7625,\n",
       "           0.7770, -1.1148, -0.1245, -1.6233, -1.9444,  0.2628,  1.3209, -1.3376,\n",
       "           0.5632, -1.1653, -0.7287, -0.7604,  1.0854, -1.6822,  0.0698, -0.2007,\n",
       "          -0.8951, -0.8921,  0.1903,  1.1131, -0.4315, -1.0857,  1.0803, -0.8585,\n",
       "           1.5498, -0.0691])),\n",
       " 'autor': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'autoridades': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'avance': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'avancen': (tensor([ 0.5445,  0.5275, -0.9282,  0.3025,  0.7192,  0.0885,  0.4391,  0.1374,\n",
       "           0.5513, -0.8394, -0.5383,  0.7214,  0.0748, -0.3597, -0.5459, -0.3159,\n",
       "          -0.9223, -0.2975, -0.3649, -1.3945, -0.0282, -0.2336, -1.0826,  0.1295,\n",
       "           0.7732,  0.6083, -0.5856, -0.3205, -0.9996,  0.5723, -0.2335, -0.2576,\n",
       "           0.5021, -1.8277, -1.8667, -1.0201,  1.4296, -1.3830,  0.3782, -2.6690,\n",
       "           0.5064,  1.9643,  0.1593,  0.0901,  0.5052, -0.1496,  0.2702, -2.1675,\n",
       "           1.8243, -0.7996]),\n",
       "  tensor([ 1.0538e-01,  1.1699e+00,  6.7421e-01,  3.6407e-01, -5.7274e-01,\n",
       "          -1.8882e-01,  1.1469e+00,  4.0712e-01,  3.5921e-01,  1.6766e+00,\n",
       "           6.2470e-01, -8.9095e-01, -5.7689e-01,  1.3293e+00,  1.0003e+00,\n",
       "          -8.9910e-01, -5.4970e-01,  1.6829e+00,  6.8248e-01,  4.6009e-01,\n",
       "          -3.4038e-01, -1.2578e+00, -8.6892e-01, -7.9525e-02,  3.8615e-05,\n",
       "          -6.8090e-02, -4.3149e-03, -1.9938e+00,  8.7132e-01, -1.4528e-02,\n",
       "          -1.6924e+00,  9.0734e-02,  2.2255e-01,  5.6654e-01,  1.2221e+00,\n",
       "          -1.7409e+00, -7.3093e-01,  5.6596e-01,  1.3652e+00,  9.8372e-01,\n",
       "           6.7656e-02, -2.0974e+00, -1.0964e+00, -4.0588e-01,  1.7534e+00,\n",
       "           1.0589e-02, -5.3209e-02, -1.3457e-01,  1.3292e+00, -2.2530e-01])),\n",
       " 'avances': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'avanza': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'avanzado': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'avaro': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'avenda√±o': (tensor([-0.6134,  1.2400, -0.2021, -0.5134, -0.7735, -0.9567,  0.4109, -1.2244,\n",
       "           1.4984,  0.3249,  0.1186, -0.9387,  0.3318,  0.6330, -0.0259,  0.3417,\n",
       "          -0.3441,  1.3972, -0.9313, -0.9420,  0.1947, -1.3243,  0.9851,  0.9485,\n",
       "          -0.5722,  0.9133,  1.6427,  1.0709, -0.2734,  0.1018,  1.0389,  0.1132,\n",
       "          -0.2894, -0.0141, -1.4240, -1.4387,  1.1085,  1.4662, -0.3732, -0.6730,\n",
       "           1.0428, -0.8404,  1.6556, -0.4634, -0.4604,  0.5621, -0.6093, -0.4287,\n",
       "           2.2505, -1.6865]),\n",
       "  tensor([-1.1414,  0.7222, -0.1422, -0.2890,  1.0936, -0.4734,  1.3178,  1.3213,\n",
       "           2.0210, -0.5150, -0.4770,  0.1915,  0.0847,  0.6505,  1.5795, -1.3762,\n",
       "          -0.5030, -0.2738,  1.3987,  0.3746,  0.8919, -0.0483,  1.0900,  0.4687,\n",
       "           1.3852, -0.3200, -0.0591, -1.2020,  1.2743, -0.4723,  0.2666,  0.6627,\n",
       "          -0.3569, -0.5538, -0.0750,  0.4869,  1.2295,  0.3803,  0.6391, -1.0109,\n",
       "           0.1153, -0.3158, -0.2346,  0.9284,  1.6496,  1.1180,  2.5470, -3.0789,\n",
       "           2.1647, -1.4508])),\n",
       " 'avisaremos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'avi√≥n': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ayer': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ayuda': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ayudar√°': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'a√©rea': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'a√©reos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'a√±adi√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'a√±o': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'a√±os': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'a√∫n': tensor(3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'baja': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bajaron': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'baje': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bajo': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bajos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'balladur': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bancario': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'banco': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bancolombia': (tensor([ 1.9996, -1.1713, -1.4773, -0.8346, -0.8552,  1.4284,  1.2670,  0.1805,\n",
       "           0.5262, -0.5886,  0.7153, -1.4242, -0.8529, -2.4151,  0.1267, -1.9066,\n",
       "          -0.9303,  0.6940, -3.1894, -0.2273, -1.4110, -0.6827,  0.3750,  0.2415,\n",
       "           1.6571, -0.5293,  1.4416,  0.5373,  2.2738, -1.3344,  0.1655,  1.7467,\n",
       "          -0.5127,  0.5784, -1.7888, -0.4770, -0.5120,  0.0968, -2.6015, -0.4250,\n",
       "          -1.6113,  0.7164,  0.5276,  1.1598, -0.8919, -0.3012, -0.5114, -1.4932,\n",
       "          -0.1502, -0.7802]),\n",
       "  tensor([-0.4978, -0.7668, -1.5308,  0.2736, -0.2918, -1.2680, -0.5693, -1.1871,\n",
       "           0.5410,  0.5014, -0.3447, -0.1666,  0.8947,  2.7589, -0.4750, -1.4970,\n",
       "          -0.1068, -0.3443,  0.0765,  0.2853,  0.2930, -1.8545,  1.0884, -0.2219,\n",
       "           0.6374, -0.8540, -0.1461, -0.4029,  0.0495,  0.4656,  0.2427,  1.1215,\n",
       "           1.9479, -0.4988, -0.7192, -2.5050,  0.2605,  0.2913,  1.1469,  1.2741,\n",
       "           2.9150, -0.1059,  0.4833, -1.0773, -0.8721, -1.0573, -0.0343, -1.2018,\n",
       "           0.3414, -0.8248])),\n",
       " 'bancos': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'basa': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'basado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'base': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bastante': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bas√°ndose': (tensor([ 1.4385, -0.2980, -2.4560, -1.4192,  0.7569, -2.0833, -1.4041,  0.7146,\n",
       "           1.6428, -0.0059,  1.2737, -2.3405, -0.7070, -0.2663,  1.0674,  1.0094,\n",
       "          -0.3928, -0.1470, -0.7970,  0.3109, -0.9067,  1.0811, -0.0384, -0.1025,\n",
       "          -0.2235, -0.9379,  0.2418, -0.5256, -0.8436, -2.0145, -1.3208,  1.0392,\n",
       "          -1.5497, -0.0625,  0.3860, -0.9709,  0.0711, -0.1700, -1.0898, -1.3189,\n",
       "          -0.0176, -0.0398, -0.2179,  0.3617,  0.5628,  0.3813, -0.1475,  0.1726,\n",
       "           0.3679,  0.7299]),\n",
       "  tensor([ 0.7577, -0.0376,  0.5184,  1.2768,  0.5864, -1.1219, -0.7359,  1.3002,\n",
       "           0.7770, -0.5889, -0.0955, -0.0398, -0.0918,  1.0707,  0.0264, -0.6901,\n",
       "           0.2582, -0.6870, -0.0748, -1.9908, -0.3764, -0.8954, -0.2998,  1.5267,\n",
       "          -0.8542,  0.6988,  0.2385, -0.3209, -0.0024,  0.4240,  0.4180, -0.4196,\n",
       "           1.0318,  1.6876,  0.0489,  0.1315,  0.6233,  1.1663, -0.6122,  0.9528,\n",
       "          -1.3940, -0.9767, -0.5706, -0.4453, -1.1978, -0.2789,  0.8918, -0.6573,\n",
       "           1.2043,  0.4301])),\n",
       " 'batalla': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'batallones': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'baviera': (tensor([-0.7892, -1.2143,  0.8890, -0.0500, -0.7419,  1.3269,  0.4598,  0.7557,\n",
       "          -0.2876, -2.4522,  1.6883, -0.8806,  2.2346,  1.1410, -0.2246,  0.7718,\n",
       "           1.0702, -0.7796,  0.2042, -0.7199,  0.1868, -0.7275, -0.0649,  0.2090,\n",
       "          -0.4008,  1.9108,  1.3675,  0.0542,  0.0813, -0.5636, -0.5215,  0.7980,\n",
       "          -0.4439, -0.1491, -1.6504,  0.9908, -0.4326, -0.2668,  1.0862,  0.2081,\n",
       "           1.0810,  1.1332,  0.3773,  0.8055, -0.7322, -0.1384,  0.8820, -0.4373,\n",
       "           0.9620, -0.4704]),\n",
       "  tensor([ 0.4008, -1.8062, -0.3919, -0.3460, -0.9487, -0.7096, -0.4611,  0.6323,\n",
       "          -0.9545,  0.1534, -0.7101, -0.7459, -0.3252, -0.1493,  0.8472, -0.3945,\n",
       "          -1.0855, -1.0465,  0.5884, -0.5768, -1.0189,  1.6782, -0.6546, -1.3673,\n",
       "           0.3409, -1.1570, -0.4489,  0.8570,  0.7762,  1.0743,  0.7585,  1.0592,\n",
       "          -0.0827, -0.4044,  0.3829,  0.8357,  0.1065,  0.6912, -1.2951,  0.7766,\n",
       "          -1.5619,  0.2361,  0.0915, -0.2784,  0.0492, -0.3592, -0.1507,  0.2082,\n",
       "          -0.7601, -0.3546])),\n",
       " 'beca': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bena': (tensor([-0.6086, -0.0537,  0.7555,  0.6916, -0.6323,  1.3581, -0.0526,  1.4854,\n",
       "          -0.7858,  1.2357, -0.4807, -1.1833,  0.1591,  1.4790,  0.5665,  0.4438,\n",
       "          -0.8009, -1.3356, -0.9834, -0.3933,  3.0484, -1.5327, -0.1763, -0.1059,\n",
       "          -0.4280,  1.0205, -0.0525, -1.0150, -1.9377,  1.5745,  1.7267, -0.8069,\n",
       "          -0.3483, -0.7410,  0.2919,  0.5663, -0.9352, -1.2717, -0.1921, -1.3430,\n",
       "          -1.3260,  0.0940, -0.6709,  1.6704, -0.9335,  0.9550, -1.2671,  0.1989,\n",
       "          -0.3030, -0.4236]),\n",
       "  tensor([-0.2886,  0.9168,  0.0505, -0.1759, -2.1254, -0.5276, -1.0080, -1.2001,\n",
       "           1.0429, -0.2328,  2.7441,  1.0135,  0.2416, -0.0483, -0.0068,  2.6756,\n",
       "          -0.3539, -1.1907,  0.2364,  0.8180,  0.7100, -0.6541, -0.5381, -0.7557,\n",
       "           0.3236,  0.5992,  1.6943,  2.0858, -1.2469, -1.8479, -0.5961, -0.7521,\n",
       "           0.9093, -0.4084, -0.9555, -0.6481, -0.9353,  0.6749,  0.7726, -1.9566,\n",
       "           0.7147, -0.1392,  1.9265,  0.3022,  0.7214,  0.2907,  0.5591,  0.6134,\n",
       "           0.1786,  0.7297])),\n",
       " 'bendiga': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ben√≠tez': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'berl√≠n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bernardin': (tensor([ 0.2134,  1.7200,  0.4052, -1.2933,  0.0271,  0.8844,  0.7466, -0.2228,\n",
       "          -0.8448,  1.1108,  0.3753, -0.3091,  0.5950, -0.0242, -0.9616, -0.3640,\n",
       "          -1.6755, -1.6172, -0.6829, -1.0117, -0.8725,  0.9989, -0.7499, -1.8942,\n",
       "           0.6787, -0.2834, -1.3751,  0.8633, -0.0660,  0.0959, -1.0405,  0.7728,\n",
       "          -1.7046,  0.6480,  0.3988,  0.7767, -2.1390, -0.4692,  0.9204, -2.1087,\n",
       "          -0.8135, -0.4738, -1.5858, -0.4969,  1.2786,  0.5695, -1.3557, -1.7068,\n",
       "          -1.1659, -2.1360]),\n",
       "  tensor([ 0.8888,  0.0827, -1.3005, -0.8870, -0.7593,  1.1288,  1.4303, -0.6079,\n",
       "          -2.0119, -1.5361,  0.0874, -0.7899, -0.9697,  1.2007,  0.4034,  1.7709,\n",
       "          -1.2442,  0.0467,  0.0519, -1.0642, -0.9550,  0.7908, -1.5239, -0.3500,\n",
       "          -0.8406, -0.7877, -0.3145, -0.7848,  1.4231, -0.3065, -0.9092,  0.1457,\n",
       "          -1.2241,  0.2687,  1.1334,  2.1459,  0.4411, -2.1580, -0.7013, -0.9068,\n",
       "           0.3272,  1.0911, -0.5165,  1.7259, -0.2852, -0.9759, -1.1558,  1.4752,\n",
       "           1.1516,  1.0590])),\n",
       " 'bernardo': (tensor([-0.0518, -0.7190, -0.7866,  0.0565,  0.4277,  0.1585, -0.0485,  1.3142,\n",
       "          -0.4613, -2.1765,  0.8034, -1.1407,  0.2669, -1.0166,  0.1869, -0.6443,\n",
       "           1.0425, -0.9729,  0.0768, -1.9548,  0.8201,  0.1399,  2.0667,  2.1948,\n",
       "           0.3374,  0.8639,  0.5314,  1.0687, -1.1706,  0.7041, -0.1958,  0.0027,\n",
       "          -1.2364, -0.0801, -1.9631, -0.0617,  1.5644,  0.7470,  0.3158,  0.9177,\n",
       "          -0.6997,  1.2185,  0.3199, -0.0118,  0.1205, -0.8823, -0.5499, -1.1744,\n",
       "           0.2748, -0.8377]),\n",
       "  tensor([ 0.9966, -1.1772, -0.4562,  0.1632,  0.0658,  0.3303,  0.0433,  2.0587,\n",
       "           0.4181, -1.2352, -0.0808, -0.4117,  0.0327,  0.4788,  0.0613, -1.0264,\n",
       "           1.8780,  1.2827,  0.5878,  0.2853,  1.2496, -0.2131,  0.7423, -0.4620,\n",
       "          -0.0893, -0.9126,  0.6218,  0.2829, -0.7170,  0.6654, -1.4529,  0.0798,\n",
       "          -0.4491,  1.2232, -1.0786, -0.2324,  0.5983,  0.0455,  1.4921,  0.8562,\n",
       "           1.3050,  1.0193, -1.0362,  0.8332,  0.8108,  0.3269,  0.2039, -0.7575,\n",
       "          -0.4273, -0.0551])),\n",
       " 'bielorrusia': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bien': tensor(3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bienvenida': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'blancos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'blum': (tensor([ 0.0583, -0.0085, -0.4939, -0.1587, -0.5475,  0.1937,  1.4208,  0.4455,\n",
       "          -1.8636, -1.0736,  0.4473, -1.4801,  0.7687, -0.7550, -0.2965,  0.1958,\n",
       "           0.6278,  2.1410,  1.8776,  1.0909,  0.0652,  0.5944, -0.7161, -1.0975,\n",
       "          -0.8092,  0.8130,  0.4661, -0.2859,  0.5988, -0.1900,  0.7446,  2.0185,\n",
       "          -1.9348,  0.3882, -0.6035, -0.6509,  0.0168,  0.0045,  2.7542, -0.8817,\n",
       "          -0.4140,  0.8037, -0.6498, -0.2257, -0.6751, -1.7470, -1.1091,  0.8897,\n",
       "          -1.1753, -1.5466]),\n",
       "  tensor([-3.4917e-01, -7.7599e-01,  1.3072e-02,  2.5652e+00,  2.3281e+00,\n",
       "           6.9631e-01,  8.7303e-01,  1.0045e+00, -2.2507e+00,  1.3338e-01,\n",
       "           2.1505e-01, -2.0760e-01, -7.1642e-01,  8.1325e-01, -1.0200e+00,\n",
       "          -6.6460e-01, -1.5567e+00,  1.0561e-01, -7.1268e-01, -1.4813e+00,\n",
       "          -5.5408e-01, -1.0783e-01, -2.1568e-01, -1.0402e+00,  1.5096e+00,\n",
       "          -4.6546e-01,  1.1290e+00,  6.3627e-01,  1.3360e-01,  1.0943e+00,\n",
       "          -1.9331e+00,  5.8173e-01,  1.6830e-01,  1.9948e-01,  9.1134e-01,\n",
       "           2.4411e-03,  2.0391e+00, -2.2846e+00,  4.5249e-01,  9.2662e-01,\n",
       "           3.2848e-01, -8.6271e-01, -3.0012e-01,  2.8809e-01,  1.0063e-01,\n",
       "           2.3568e+00,  4.5107e-01,  1.2137e+00,  1.6242e+00,  1.1319e-01])),\n",
       " 'bogot√°': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bola': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bomba': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bondes': (tensor([-0.5330, -0.6772,  2.0833, -1.1236,  0.5481, -0.6804, -0.0290, -1.5338,\n",
       "          -0.5007,  0.7201,  0.8591,  0.4801,  2.0148, -1.3017,  0.8478,  0.8155,\n",
       "           0.1736,  0.3384,  1.1446,  0.7813,  0.8547,  1.0092, -0.0339, -0.5804,\n",
       "          -0.0366, -0.6165, -0.3463, -1.0351, -1.0862, -0.6954, -1.1665, -0.4305,\n",
       "          -1.2666,  1.7608,  0.0254, -0.2033,  0.1396,  1.1370,  0.7208, -0.1710,\n",
       "          -0.2521,  1.2662,  0.1124,  0.6405,  0.0067, -1.0985,  1.0232, -0.4531,\n",
       "           0.3911, -0.4199]),\n",
       "  tensor([ 1.4922e+00,  7.2959e-01,  9.1756e-01,  5.8318e-01, -7.5051e-01,\n",
       "           5.1155e-01,  6.5168e-02, -1.5068e+00, -9.2163e-01, -5.7301e-01,\n",
       "          -1.8364e-01,  6.8024e-01, -1.4776e+00,  3.2386e-01, -6.1028e-01,\n",
       "          -3.2605e-01, -4.2431e-01, -7.5533e-02,  8.5457e-01,  6.3141e-01,\n",
       "           4.1027e-01,  6.3395e-01,  1.9807e-01,  1.3865e+00,  2.3224e-01,\n",
       "          -5.1702e-01,  1.1251e+00, -2.5497e+00,  8.2165e-01,  7.0007e-01,\n",
       "          -4.8697e-01,  3.0472e-01, -4.2780e-01, -5.5891e-01, -2.9362e-01,\n",
       "           1.0767e+00,  5.0583e-01, -7.8883e-01,  5.2563e-01, -2.7877e-01,\n",
       "          -4.6551e-01,  2.3191e-01,  3.0262e+00, -4.8224e-01, -1.6724e+00,\n",
       "          -2.4114e-01, -9.8657e-01,  4.5892e-01,  1.5397e-03, -1.6163e+00])),\n",
       " 'bonn': (tensor([-0.5389, -0.7079,  1.7922,  1.4296, -0.4898,  0.5958, -0.0182,  0.9524,\n",
       "          -1.4701, -0.7971,  0.1851, -1.2576, -2.9793,  0.0159,  0.1325, -0.7244,\n",
       "          -0.3703, -0.0082, -0.1577, -0.4228,  0.0502, -2.3097, -0.8098, -1.5792,\n",
       "          -1.3563, -0.1584, -0.3670,  0.3585, -1.0367, -0.6532, -1.2785,  1.8889,\n",
       "          -0.9607, -0.0400, -0.6522,  0.2712,  0.7116,  0.8636, -0.6879, -0.3736,\n",
       "          -1.1154, -0.5621, -0.2742, -0.8237, -0.5426, -0.6483, -0.5138, -1.4071,\n",
       "           0.1499,  0.9706]),\n",
       "  tensor([ 1.1508,  0.5598,  1.8206,  0.8290, -0.0036,  0.6915,  0.8438, -1.1598,\n",
       "          -0.4100, -1.0036, -0.2340, -0.4214,  0.6720, -0.2165,  0.9083, -0.0811,\n",
       "          -0.2080, -1.4900, -0.9727, -0.4722, -1.8741, -0.2687, -0.5430, -1.3765,\n",
       "           0.4487,  1.2056,  0.1576, -1.2339, -0.3611,  0.7762, -0.1812, -1.9504,\n",
       "           0.6901, -1.5996, -1.7090, -2.1939, -1.5078, -0.1559, -0.1864, -0.2556,\n",
       "           2.4447,  0.3108, -0.4767, -0.5356,  0.1280,  1.6830,  0.3978, -0.4421,\n",
       "           0.4678, -1.6801])),\n",
       " 'bonos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'boquete': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'borrador': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'borrados': (tensor([ 0.6894, -1.6763,  1.0702, -1.2380, -2.4354,  3.0096,  0.1505,  1.8176,\n",
       "          -0.1456, -0.2750,  0.4534, -1.4656,  0.2509,  0.3898,  0.8663,  0.6091,\n",
       "          -0.5024, -0.3154, -1.0553,  0.1687, -1.6478,  0.3191,  0.0185, -0.6888,\n",
       "           0.9656,  0.4558, -0.9686, -0.0123, -0.1423, -2.0767,  1.1559, -0.3995,\n",
       "          -0.0824, -1.0825, -0.0601,  0.8707, -1.8577,  2.2430,  0.3119,  1.6308,\n",
       "          -1.4986, -0.5017, -1.1049,  0.2779, -0.8160, -0.2211, -0.5310, -0.3309,\n",
       "           0.3355,  1.1003]),\n",
       "  tensor([-3.4331e-01, -1.6745e+00,  1.4130e-01, -1.3460e+00,  1.6682e+00,\n",
       "           4.0969e-01, -1.2691e+00, -5.8765e-01, -1.4993e+00, -1.1645e+00,\n",
       "           1.6571e+00, -1.1328e+00,  1.7347e+00, -1.5760e-01, -2.6466e-01,\n",
       "           2.6406e-02,  2.0703e-01,  9.9270e-01,  9.1411e-01, -1.9761e+00,\n",
       "          -7.3777e-01, -6.6725e-02, -1.0028e+00, -1.0236e+00, -2.4153e-01,\n",
       "          -6.7176e-01, -8.7730e-01,  1.8286e+00, -5.5531e-01, -1.2193e-01,\n",
       "          -4.4992e-01,  6.2024e-01,  9.8823e-01, -8.2296e-02, -8.8713e-01,\n",
       "           4.1973e-01, -1.5056e+00,  9.9523e-01,  7.1257e-02,  7.3500e-01,\n",
       "          -1.3069e+00,  1.1004e-01, -1.3109e+00,  5.1745e-01, -9.4969e-01,\n",
       "          -6.4943e-01, -1.1148e-02,  3.2431e-01,  9.0557e-05,  5.6515e-01])),\n",
       " 'bosnia': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bosques': (tensor([ 0.0040, -0.0958,  0.7773,  0.9021,  0.6943,  0.7412, -0.9119,  0.3948,\n",
       "           1.4951,  0.4595, -0.2094, -1.0127,  0.4391,  0.9724, -1.2321,  0.1330,\n",
       "          -0.7684,  2.5506, -0.5273,  0.4104,  1.6645,  0.5274, -0.1675, -0.4518,\n",
       "           0.3535,  0.2007, -1.1363,  0.3022, -0.3662,  0.4941, -0.1681,  0.6476,\n",
       "          -0.1306, -1.1522, -0.6602,  0.9738, -0.0924,  0.7270, -0.5690, -0.8521,\n",
       "          -1.0120,  0.7899, -0.8849, -1.5049,  0.5216, -1.0349, -0.8768, -1.3736,\n",
       "           0.6833,  1.0180]),\n",
       "  tensor([-1.6676,  0.4362, -0.5210, -1.4599, -0.0987,  0.8416,  0.2463, -3.5481,\n",
       "          -0.4398,  1.6093,  0.9673,  0.9750,  0.3639, -0.9537, -0.5073,  0.0148,\n",
       "          -1.0517,  0.2481,  0.5031,  1.2906,  1.2934,  1.7642, -0.3680,  0.3999,\n",
       "          -0.5329,  1.0145, -0.0633,  0.2389,  0.6616,  2.2304, -0.6414,  0.1502,\n",
       "           0.7935, -0.7250,  0.0261,  0.7376, -0.5183, -1.4668, -1.0431,  1.4012,\n",
       "           0.4177,  0.4461,  0.4208, -0.0755, -0.4470, -0.7364,  0.4099,  0.5465,\n",
       "           0.6819,  0.2800])),\n",
       " 'brasil': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'brasile√±o': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'breve': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'brevemente': tensor(2.9802e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bruselas': (tensor([ 0.8910,  1.0473,  0.6359,  0.0078, -0.9962,  0.5207, -1.3539, -0.3744,\n",
       "          -0.5952,  1.7170, -1.3345, -0.3191,  0.5688, -1.4954, -0.9840,  0.4396,\n",
       "          -1.0621, -0.0338,  1.0579,  0.5181, -2.1111, -0.1702, -0.0568,  2.1279,\n",
       "           2.2595,  2.5887,  0.9234,  0.0613, -0.3171, -0.0532, -1.3208, -0.8248,\n",
       "          -0.1864,  0.9907, -0.4584,  2.1824, -0.5971,  0.1768,  0.9313, -0.0083,\n",
       "           1.5245, -0.4963, -0.7009,  0.0244,  0.1287,  0.0384, -0.8573, -0.4373,\n",
       "          -0.1376, -0.4460]),\n",
       "  tensor([-0.1002, -0.1711,  1.0738,  0.4547, -1.3293,  0.1514,  1.8139, -0.1631,\n",
       "           0.6354,  1.1531, -0.3625,  0.2895, -0.3253, -2.3959,  1.0614,  0.4029,\n",
       "          -0.4167, -0.9819,  1.5028,  1.7711,  0.0618,  0.1347,  0.4428,  0.7993,\n",
       "           0.4833,  0.0671, -0.1129,  0.6267, -1.3737,  0.8506,  0.4725,  1.1102,\n",
       "           1.3307, -0.5760, -0.3886,  0.3687, -0.5431,  0.1027,  1.6737,  1.2782,\n",
       "          -0.3532,  1.7840, -1.1792, -0.5143, -0.5287,  0.4676, -1.3535,  0.5616,\n",
       "          -1.4589,  0.8089])),\n",
       " 'buceador': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'buen': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'bueno': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'busca': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'buscamos': (tensor([-0.6480,  0.7874,  1.2006,  1.2652,  0.1359, -0.1170, -0.4725,  0.2718,\n",
       "           0.6740, -0.4907, -0.6493, -1.7296, -0.3469, -0.9070, -0.6811, -0.4644,\n",
       "          -0.1101,  0.2330, -0.4790,  1.5167, -1.1834,  0.6838, -0.8806,  0.5832,\n",
       "          -0.1636,  0.5942,  1.8675,  0.1037,  1.8104,  0.3914,  1.2675,  0.4818,\n",
       "           0.7597,  2.1112, -1.6762,  0.7812,  0.0326,  1.9146,  0.2062,  0.7955,\n",
       "          -1.0782, -1.7244, -0.1627,  0.4837, -0.5871, -0.6382, -0.3931,  1.3239,\n",
       "          -0.6133, -0.5020]),\n",
       "  tensor([-1.0104e+00,  8.3914e-01, -5.7019e-01, -2.3691e+00,  9.0609e-01,\n",
       "          -1.6683e+00,  1.0631e+00,  1.3515e+00, -4.6250e-01, -1.1145e+00,\n",
       "           8.0328e-01,  6.3648e-02, -6.6509e-01,  3.2487e-01,  1.4553e+00,\n",
       "          -5.1581e-01, -1.4446e+00,  5.6613e-01,  2.0970e+00, -1.0114e+00,\n",
       "          -1.6611e-01, -5.6800e-01, -8.9035e-01,  1.3137e-01,  2.5791e+00,\n",
       "          -2.1650e-01, -9.6455e-04,  7.1414e-01, -5.3026e-02, -2.0906e+00,\n",
       "           3.1425e-01,  3.9339e-01, -1.5496e-02, -6.3336e-01, -1.3726e+00,\n",
       "           1.1296e-01, -5.7813e-01,  9.2078e-01, -5.2838e-01, -4.3688e-01,\n",
       "           2.7570e-01, -8.7967e-01,  8.1260e-01, -1.5792e+00,  2.4021e+00,\n",
       "          -5.6491e-01, -1.2459e-01,  5.6278e-01, -7.2886e-02,  5.8297e-01])),\n",
       " 'buscar': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'b√°sicos': (tensor([-2.7849e-01,  3.3490e-01,  3.2466e-01,  1.4719e+00, -7.8924e-01,\n",
       "           9.7950e-01, -1.1147e-01,  5.3987e-01,  6.5412e-01,  6.6212e-01,\n",
       "           1.6971e+00,  1.0448e+00,  3.9219e-01,  2.1272e-01, -1.7749e+00,\n",
       "           1.9652e-01, -3.5938e-01,  2.1947e+00,  1.6335e-03,  1.0023e-01,\n",
       "          -1.9393e+00, -1.2933e+00,  2.1316e-01,  1.5484e+00,  2.5940e-01,\n",
       "           8.0732e-01, -1.1736e+00, -6.5203e-01,  1.0433e+00,  3.0385e-01,\n",
       "           1.1322e+00, -6.9595e-02,  3.8071e-01, -1.3934e-01, -1.5226e+00,\n",
       "           1.6250e+00, -8.7144e-01, -1.4211e+00,  5.1411e-01, -9.9214e-01,\n",
       "          -1.6391e-01,  3.2704e-01, -6.3316e-01, -2.2987e-01, -5.8182e-01,\n",
       "           1.3055e-02,  4.0591e-01, -9.6976e-01,  3.8534e-01, -1.9146e-02]),\n",
       "  tensor([ 4.3974e-01, -3.0512e-01, -1.3989e-01, -4.2122e-01, -2.0286e+00,\n",
       "          -1.6011e+00, -5.4172e-01,  8.7654e-01, -6.4054e-01, -7.0847e-01,\n",
       "           1.6737e+00, -1.5934e+00,  5.7838e-01,  3.1300e-01,  1.1348e+00,\n",
       "           3.3831e-02, -1.4872e+00, -4.2752e-01, -8.7847e-01, -2.7257e-01,\n",
       "          -4.7813e-01,  4.4747e-01,  5.1310e-01,  7.3145e-01,  3.9571e-01,\n",
       "           1.0054e+00,  8.1467e-02, -6.9566e-01,  2.2109e+00,  6.0017e-01,\n",
       "          -3.9420e-01,  2.4233e-01,  1.6399e-02,  7.2791e-01,  1.2501e-01,\n",
       "          -8.3511e-04,  1.5606e+00, -1.7577e+00,  6.4691e-01,  9.1380e-01,\n",
       "           7.2588e-02,  5.8308e-01, -8.6980e-01,  1.0468e+00, -3.4485e-01,\n",
       "          -2.7664e-02,  3.2250e-01,  2.6667e-01, -4.1382e-01,  6.8920e-01])),\n",
       " 'b√≥sforo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cabe': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cabo': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cabr√≠a': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cachemira': (tensor([ 0.7978, -0.5299,  0.0555, -0.6005, -0.5930, -0.3411, -0.4696,  1.7997,\n",
       "          -0.2101,  1.0945,  0.9020,  0.6821,  0.8947,  1.8927,  1.1184, -1.5241,\n",
       "           1.6982, -0.3125,  1.2194, -0.5538,  1.7782, -1.6895, -1.1171,  0.5431,\n",
       "          -0.2902, -0.1837, -1.6044,  0.1307, -1.1502, -0.0429,  1.3243, -0.6505,\n",
       "          -1.5301,  0.4328, -1.6926, -1.4070,  1.1967,  0.1393, -1.3446,  1.4261,\n",
       "          -1.1107,  0.4283,  2.0852,  1.2864,  1.3959,  0.5518,  0.2908, -1.6331,\n",
       "          -0.9891,  1.4938]),\n",
       "  tensor([ 0.6547, -0.2195,  0.1711,  0.1726, -2.6542, -0.8066, -1.6958,  0.7920,\n",
       "          -0.1666, -0.6527,  2.0040, -1.2840, -0.0028, -1.1868, -1.4174, -0.6802,\n",
       "           0.5501,  0.4142,  0.3242,  0.7999,  1.4804, -0.0872, -0.5431, -1.9150,\n",
       "          -1.4639,  1.3503,  0.5998, -0.7438, -0.3473, -1.1285, -0.2622, -1.1708,\n",
       "           0.0630,  1.6700, -1.0592,  0.7842,  0.2263,  0.1295,  0.5153, -1.0853,\n",
       "           0.4589,  1.5216, -0.4381,  0.4633, -0.4732, -0.9494,  0.5254, -0.0927,\n",
       "           0.3846, -2.0642])),\n",
       " 'cada': tensor(5.9605e-08, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cadena': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'caer': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cafeter√≠a': (tensor([-0.5520, -0.9762,  1.1823,  1.5780, -0.4606,  0.6409,  0.2515,  1.0086,\n",
       "           0.8609, -0.6987,  0.3173,  0.7319, -0.1222, -0.3415, -0.6428, -0.5820,\n",
       "          -0.0532, -1.1998,  1.3092, -0.4824, -0.2765,  0.4669, -0.0883, -1.2459,\n",
       "           0.3503, -0.0672, -1.7839,  0.0742, -0.0398, -2.0368, -0.4112, -0.9151,\n",
       "           0.2949, -0.0665,  1.7362,  0.0692,  0.1370, -1.0494, -0.2531,  0.2178,\n",
       "          -0.0954,  1.5975, -1.3134,  0.8463,  0.6506,  1.3735, -0.1964, -0.8126,\n",
       "           0.9459, -0.3146]),\n",
       "  tensor([ 0.4967, -0.1537,  0.6610,  0.3464, -1.0076,  0.6747, -1.4429, -0.0533,\n",
       "           2.6205,  0.1293, -0.0328, -0.3099,  0.0742, -0.2044, -0.6017, -1.0354,\n",
       "          -1.8891,  1.8838,  0.3595, -0.7197, -1.5528,  1.0400,  2.0144,  0.2450,\n",
       "           0.2219,  2.0808,  0.7964,  1.9806,  1.0892,  1.2689, -0.3312,  0.3799,\n",
       "           2.6046,  2.6014, -0.0290, -1.2944, -1.3774,  0.3954,  1.5114, -0.2260,\n",
       "           0.2731, -0.8081,  0.4021, -0.6301,  0.3957,  0.0158,  1.5790,  0.2589,\n",
       "          -1.7308,  0.8810])),\n",
       " 'caja': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'caldera': tensor(3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'calefacci√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'calidad': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'camacho': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cambiado': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cambio': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cambios': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cambi√≥': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'campamento': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'campa√±a': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'campeones': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'campo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'canaliz√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'canciller': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'canciller√≠a': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'candidato': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'candidatos': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cantante': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cantidad': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'capacidad': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'capaz': (tensor([ 1.0419, -1.9271, -1.0864,  1.8730,  0.5405,  0.6206, -0.7875, -0.2866,\n",
       "          -1.1298, -0.5016,  0.3041, -0.2483,  1.3716, -0.9312,  0.3202,  1.0510,\n",
       "          -1.8494,  1.3639,  1.5496, -0.2992,  2.2214,  0.4273, -0.0988, -0.4596,\n",
       "           0.6372, -1.4460,  0.9203,  0.7292, -0.1551,  0.0477,  1.8823, -1.7919,\n",
       "          -0.6393,  0.4013,  0.6930,  1.1243,  0.5243, -0.9325,  0.6355, -0.8399,\n",
       "          -0.9381,  0.5810, -0.7646, -0.1083, -0.9506, -0.1291, -1.2273,  0.5281,\n",
       "          -0.5860, -3.3616]),\n",
       "  tensor([ 1.1123e+00,  3.6545e-05, -1.0564e+00, -7.5134e-02, -1.0304e-01,\n",
       "          -2.6071e-02, -2.9307e-01, -1.1221e+00, -1.1180e+00, -1.8737e-01,\n",
       "           7.7001e-01, -1.8399e+00,  5.3157e-01, -3.7162e-01,  3.0283e-01,\n",
       "          -1.7437e+00,  2.0698e-01,  3.0546e-01, -4.1532e-01,  1.0794e+00,\n",
       "           5.6502e-02,  2.5484e-01,  3.3882e-02,  1.2603e+00,  1.1228e+00,\n",
       "          -7.5536e-01,  5.4675e-01, -5.7577e-01, -2.3862e-01, -4.9058e-01,\n",
       "          -2.2254e-01,  1.2539e+00,  3.7258e-02, -1.2849e-01,  1.2083e+00,\n",
       "           4.5526e-01,  2.6767e-01,  1.0707e-01, -3.6730e-01, -1.6148e+00,\n",
       "          -5.0551e-01, -1.0102e+00,  8.7953e-01,  3.5483e-01,  2.9474e-01,\n",
       "           6.7528e-01,  1.3632e-01, -1.4437e+00, -3.1540e-01,  3.0493e-01])),\n",
       " 'capital': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'captura': (tensor([-0.7735,  0.7822,  0.3669, -0.0445, -0.6373, -0.8261,  1.0221,  1.0208,\n",
       "           0.3364, -0.7869,  0.9344,  0.5154, -0.2594, -1.7490,  0.1169, -0.3262,\n",
       "          -1.5858,  0.0343, -2.1036, -0.3776, -0.9251,  0.4678,  0.6212,  0.0178,\n",
       "          -2.0658, -0.6361, -0.3016, -0.1785,  2.9442,  0.6713, -0.2340, -0.1185,\n",
       "           1.8034,  0.2655,  2.6460, -2.3745, -0.2064,  0.0520,  0.0551,  0.6572,\n",
       "           1.4286, -0.8510, -1.1430, -2.5796, -0.6075, -0.9739, -2.0437,  2.1197,\n",
       "           0.2408, -1.2128]),\n",
       "  tensor([ 0.1686,  0.7472,  2.2349, -0.7670,  0.0520,  0.6280,  0.8390,  0.6415,\n",
       "           0.1248, -0.2548,  1.2007, -1.2187,  0.8877, -0.7495,  0.9302,  0.5896,\n",
       "          -0.7432, -2.1956, -1.0080,  1.1233, -1.5154, -1.4158,  0.6957, -0.9516,\n",
       "          -1.7600,  0.2111, -0.1399,  0.8771,  0.1233, -3.0605,  0.2450, -0.5922,\n",
       "          -0.3055,  0.7311, -0.8166, -1.2468, -1.4725,  1.9884, -0.3021, -0.6563,\n",
       "          -1.9319, -0.3059, -0.3287, -1.1719,  0.3972, -0.4201,  1.0915, -0.4905,\n",
       "           0.2617, -0.1926])),\n",
       " 'cap√≠tulo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cara': (tensor([ 2.2306,  2.3563, -0.0197, -0.1416, -1.4159,  0.7001, -0.9234, -0.6293,\n",
       "           0.0207,  0.6123, -1.1257,  2.2383,  0.6379,  0.4248,  1.1621,  0.4608,\n",
       "          -1.0343,  0.8985, -1.3281, -0.1628, -0.5653, -0.7977,  0.7421, -2.0834,\n",
       "          -0.2482, -0.8163, -0.7931,  1.1507,  0.5619,  1.4007, -0.4549,  0.1652,\n",
       "          -0.2277,  0.7210, -1.9703,  2.3804, -1.6351,  0.1759, -1.4572, -0.9270,\n",
       "          -0.2275,  1.0207, -0.3581,  0.2556, -1.2553,  1.0195, -0.6564,  1.1209,\n",
       "           0.8738, -0.0872]),\n",
       "  tensor([-4.4306e-01, -2.5982e-01, -5.5938e-02,  4.8816e-01,  4.3207e-01,\n",
       "          -1.4331e-01,  1.1807e+00, -1.7084e+00, -6.2894e-01, -1.8157e-03,\n",
       "           1.1363e+00,  1.2259e+00,  1.0774e-01,  1.8000e+00, -1.4587e+00,\n",
       "           7.3225e-01,  2.0497e-02,  7.1216e-01, -9.2369e-01, -2.8042e-01,\n",
       "           3.2696e-01,  4.4617e-01, -3.2213e-02,  8.5943e-01,  1.2407e+00,\n",
       "           1.3996e+00, -4.1150e-02,  1.6464e+00, -6.7447e-01,  1.2172e+00,\n",
       "          -9.1358e-01, -6.8654e-02,  2.2031e+00,  9.6382e-01,  6.0568e-02,\n",
       "           5.7265e-01,  3.0064e-02,  2.9478e-01, -2.2283e+00,  1.6090e+00,\n",
       "           1.3569e+00, -8.0172e-01,  1.0621e+00, -8.3553e-01, -4.9365e-02,\n",
       "          -1.6989e+00, -4.7043e-01, -2.2517e-01,  8.9675e-01, -2.4633e-01])),\n",
       " 'caracas': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'caravana': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'carb√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cardona': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'carece': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'carga': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cargo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'carlos': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'carnaval': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'caro': (tensor([-0.1692, -0.7364,  2.2597,  1.0279, -0.1551, -0.3256,  0.5475,  0.5292,\n",
       "          -0.7192, -2.0282, -0.0903, -0.4444, -0.0328, -0.7767,  0.0435,  1.0678,\n",
       "           0.1092,  0.0556, -0.1195, -0.1801, -0.7096,  0.9068, -0.3044,  1.4676,\n",
       "           0.5305, -0.0508,  0.0503,  1.8745,  1.2285,  1.2325, -0.3581,  1.0939,\n",
       "          -0.4600,  0.2007, -0.4698,  0.9518, -1.1939,  0.3484, -0.4835,  0.1716,\n",
       "          -0.0878, -0.5810,  0.4413, -1.8440, -0.1668,  1.0636,  0.6753,  0.7226,\n",
       "           2.0223,  0.5761]),\n",
       "  tensor([ 0.3307,  1.6549, -1.6548, -0.9105, -1.4156, -1.0006, -1.7637, -0.3719,\n",
       "          -0.8102,  0.5679,  0.6220,  1.0734, -0.1410,  2.0814, -0.1202, -1.1275,\n",
       "           1.9127,  0.1986, -2.1839,  1.5456,  0.6688,  0.1596, -0.1491,  1.2876,\n",
       "           1.1378, -0.0751, -0.7321, -0.6357,  0.2929,  0.8969,  0.9508,  0.4193,\n",
       "           0.3678, -0.5784,  2.9243, -0.2172, -1.3784,  0.3394, -0.9550,  0.6984,\n",
       "          -0.0255,  0.1079,  0.8250, -1.3201, -1.6607,  1.2889,  0.5734,  1.0008,\n",
       "           0.2121, -0.2801])),\n",
       " 'carrera': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'carta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cartas': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'carteles': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'casa': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'casas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'casi': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'casino': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'caso': tensor(-3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'casos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cas√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'catedral': (tensor([-0.4801,  1.1705,  0.6165,  0.2476,  0.1085,  3.1910, -0.3620,  0.8782,\n",
       "          -0.9429, -1.1716, -0.5578,  1.2577,  0.6526,  0.2339, -0.6456, -1.5613,\n",
       "           2.0146, -1.3471,  0.5497, -0.5725,  0.2123, -0.2593, -0.7440,  0.4129,\n",
       "           0.1381, -1.3503,  0.3308, -0.1828,  1.7448,  0.3106,  0.7405,  0.3127,\n",
       "          -0.7382,  2.2120, -1.4591, -0.3506, -0.8042,  1.3329,  0.3530,  0.2199,\n",
       "           1.2074,  0.3802,  0.4121,  2.4826,  0.2696, -0.5373,  1.3651,  1.0998,\n",
       "           1.4629, -1.4196]),\n",
       "  tensor([-0.8478,  0.0426,  0.5048,  0.0914,  0.2343, -0.4671, -0.4515,  1.1602,\n",
       "          -0.0948,  0.1746,  0.2367,  0.2662, -0.0581,  0.2476,  2.8351, -0.1086,\n",
       "           1.3367,  0.8608,  0.4826,  0.0552, -0.6403,  0.5480,  0.5735,  1.0919,\n",
       "           0.3801, -1.3556,  1.7907, -0.7790,  0.0335, -0.8599,  0.0831, -0.0923,\n",
       "           0.8141, -1.8992,  0.3592, -1.2904, -0.1268,  0.7607, -0.7127,  0.1104,\n",
       "          -1.9562,  0.2308, -0.3911, -0.2583, -1.6064, -2.2444,  2.0303, -0.4552,\n",
       "          -0.5316,  0.0704])),\n",
       " 'catorce': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cat√≥lica': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'causa': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'causas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'caus√≥': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cavallo': (tensor([ 2.0340, -1.0742,  1.4715, -0.0630,  1.1691,  0.2923, -0.6207, -0.0702,\n",
       "          -1.7022, -0.1121, -0.4752, -0.4026,  1.0676,  0.0265, -1.9842,  0.5523,\n",
       "           0.0074,  0.0268, -0.2816,  0.5822, -0.3928,  0.5823, -0.9344, -0.0309,\n",
       "           0.3077,  0.2244,  0.5713, -0.0678,  0.1731,  0.3108, -0.0437, -0.1099,\n",
       "           0.7863, -1.4121, -0.6015,  0.3913,  1.2337, -0.3583, -0.3041,  0.0043,\n",
       "           0.8797,  0.4135,  1.9207, -1.0552, -0.4433, -0.8156, -1.2020,  0.5418,\n",
       "          -1.9102,  0.3570]),\n",
       "  tensor([ 1.3002,  0.4497, -1.6624,  1.1259, -1.2054,  0.8166,  0.6906,  1.0855,\n",
       "          -0.6604, -0.8399,  0.5808, -0.6407, -0.0776, -0.5723, -2.6179,  0.6976,\n",
       "           0.6291, -1.5410, -0.0042, -0.2536,  2.5146, -0.1658,  0.1141, -0.3999,\n",
       "           1.5743, -1.0669, -0.4723, -0.2455, -0.3268,  1.4412,  0.2306,  0.5167,\n",
       "          -1.2469,  0.8505, -0.1996, -2.6218,  1.1967, -1.0855, -1.9536, -2.2658,\n",
       "          -1.0462, -1.6508,  1.1646,  0.3109, -1.3068,  0.4575, -0.2985,  0.6515,\n",
       "          -0.3420,  0.0641])),\n",
       " 'cayeron': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ca√±oneos': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ceda': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ceder√≠a': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'celebraci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cenizas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'central': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'centro': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'centroam√©rica': (tensor([ 0.4537,  0.4388, -0.5556, -0.5119,  0.5780, -1.9149,  0.7128, -0.4987,\n",
       "          -0.0080,  2.2021,  0.8723,  1.5770,  1.3944,  0.2822,  2.0871,  0.5244,\n",
       "          -0.0586, -1.2552, -0.2870, -0.9345,  0.3420,  0.2412,  0.4564,  0.2853,\n",
       "           0.5786,  0.1489, -1.4259, -1.4814,  0.1195,  1.8781,  0.2178,  0.8148,\n",
       "           1.1236, -0.3803,  0.3024,  0.3706, -0.1046, -0.4624, -0.6659,  1.3227,\n",
       "           0.9001, -0.7888,  0.2312,  0.0476,  0.7183,  0.9285, -0.0826,  0.4566,\n",
       "          -0.4489,  0.4864]),\n",
       "  tensor([-0.1420,  2.0074, -0.5172,  0.5430, -0.4992,  2.6087, -0.2606, -0.3944,\n",
       "           0.3913, -1.6886,  0.2008,  0.2953,  1.0024,  1.5328, -1.6478, -0.1614,\n",
       "          -1.5163,  0.5284,  0.9909, -1.6077, -0.8354, -0.9432,  1.6607, -1.2228,\n",
       "           0.5277, -0.6582, -0.8483, -1.0455,  0.1791,  1.4215, -0.0692,  1.9490,\n",
       "          -0.4749, -1.7608, -0.6950,  1.2426,  0.4278, -0.2877,  1.5375,  1.4053,\n",
       "          -0.9730, -1.5437, -0.7046, -0.6498, -0.5751, -0.6921, -0.1059,  0.7357,\n",
       "          -1.6583,  0.5084])),\n",
       " 'cerca': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cero': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cerrados': (tensor([-0.3046, -0.9188,  0.5254,  0.0278,  2.0412, -0.8391, -0.8728,  0.1172,\n",
       "          -0.4741, -1.7658, -0.2096,  0.3361,  0.4206,  1.5666,  1.1259, -0.1527,\n",
       "           0.2150, -0.3441,  0.0996, -0.1569, -0.9275,  0.4933,  1.0819, -0.4062,\n",
       "           0.4898, -0.5807,  0.5266,  1.6450, -0.1786, -1.1408, -0.3844,  0.7692,\n",
       "           0.0506, -1.1840,  0.6057,  0.0500, -0.5607,  0.5596,  0.3602,  0.1930,\n",
       "           1.5070, -0.2364, -0.4241, -0.5180,  0.9654, -0.5774,  1.0173, -0.0279,\n",
       "          -0.0597, -0.4452]),\n",
       "  tensor([-1.3297, -0.9519,  1.5309,  0.1000, -1.1020, -0.4622, -0.1749, -0.0223,\n",
       "          -0.9823, -0.2091, -2.3560, -0.1783,  2.1569,  0.1471, -1.1910,  1.0501,\n",
       "          -0.2323, -0.9315, -0.2308, -1.9280, -0.6080, -0.8910,  0.8898, -0.2859,\n",
       "           0.7170, -1.1601, -0.7453,  0.9615,  1.4278, -1.6695,  0.8458,  0.3913,\n",
       "           0.2847,  0.8271,  0.8714, -0.2384,  0.1395,  1.1572, -2.3745, -0.2615,\n",
       "          -0.3106,  0.1179, -1.6342, -0.7019,  1.1753,  0.1724,  1.5502,  1.6485,\n",
       "          -0.0870,  0.3138])),\n",
       " 'cerrar': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cerraron': (tensor([ 0.5792, -1.3112,  0.2134, -0.9754, -0.9668, -0.2810,  0.0369,  0.7905,\n",
       "           0.5854, -0.3598,  0.4797,  0.5239,  0.6681, -0.1402, -0.0847, -1.5819,\n",
       "          -0.0351, -0.0330, -1.2316,  0.2592,  0.3175, -0.0611,  0.6960, -1.8682,\n",
       "           0.7844, -0.1401, -1.9740,  0.8411,  0.1185,  1.7921, -0.7259, -0.2223,\n",
       "          -0.8190, -0.1814, -1.6686,  0.4761,  1.1063, -0.2316,  1.0316,  0.0213,\n",
       "          -0.1471, -0.5641, -0.4161, -0.3314,  0.1691,  0.7443,  1.0614, -0.2859,\n",
       "          -0.0228, -0.3291]),\n",
       "  tensor([-0.0426,  0.3850,  0.3610,  0.1907,  0.2162,  0.5603,  1.3515, -0.9807,\n",
       "           1.3323, -0.0365, -0.5394,  0.8145,  0.0647, -1.1999, -0.9337,  0.5683,\n",
       "          -1.4797, -0.3766,  0.8832,  0.1553, -2.0686,  1.3810,  0.9970, -1.6047,\n",
       "          -0.2111,  0.2648,  1.3435, -0.1368,  0.0063,  1.4922, -0.4808,  0.9444,\n",
       "           1.0627,  0.4740,  0.1059,  1.0135,  2.1446,  1.0402, -0.7045,  2.2779,\n",
       "           1.0071,  0.1003,  0.0155,  0.5967,  0.6389,  0.2535, -0.1492, -0.5480,\n",
       "           0.4184, -2.2802])),\n",
       " 'cerrar√°': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cerveza': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cesaci√≥n': (tensor([ 0.6783, -0.4266,  1.2419, -0.1636, -0.3995,  0.2499, -1.1052, -0.7398,\n",
       "          -2.2666,  1.0155, -0.6955, -0.5244, -0.2164,  0.0480,  0.0875, -0.7389,\n",
       "          -0.4755,  0.9246, -0.0996, -0.1858, -1.4250, -0.0499,  1.5999, -0.3846,\n",
       "           0.6649,  0.7674, -0.7157, -1.1136,  0.0369, -0.7002, -1.3196, -1.4306,\n",
       "           0.1104, -1.1240, -1.2420,  0.1458,  1.0336, -0.4964,  0.3112, -1.3145,\n",
       "          -0.5956, -0.5638, -0.3515, -1.1434,  0.8665, -2.0595, -0.8818, -0.0154,\n",
       "          -0.7765,  0.7812]),\n",
       "  tensor([ 1.1544,  1.9774, -0.2459,  0.0795,  0.0773, -0.4874, -0.5375,  0.2768,\n",
       "           0.6408,  0.3080, -0.3890, -1.0238, -0.3276, -1.0716, -0.1457,  0.7788,\n",
       "           0.0101, -1.6297,  0.1098, -0.1543, -0.2187, -2.3570, -0.3603,  1.1247,\n",
       "           0.4063, -0.7773,  0.4104,  0.1961, -1.8940, -0.9637, -1.3608, -2.3999,\n",
       "          -0.9756, -0.0156, -0.1685, -0.5664,  1.0004,  0.6902, -1.1693,  0.4786,\n",
       "           0.1291, -1.0141, -1.1660, -0.5412, -0.9454, -0.0215,  0.8891, -0.0075,\n",
       "          -0.7401,  0.3655])),\n",
       " 'cesar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cese': (tensor([ 1.0670, -0.9247,  0.4804,  0.3915, -0.2834, -0.4041, -1.6837,  0.4999,\n",
       "          -0.0795, -0.8936, -2.3743,  1.2317,  1.2078,  0.2289, -0.3280, -0.4612,\n",
       "           0.0730, -0.4724, -1.2510, -0.0053,  0.1214, -0.2118,  1.1597, -0.2852,\n",
       "           0.7629, -0.9221, -1.5162, -0.0161, -0.6231,  1.5610, -1.5759,  0.8459,\n",
       "           2.7338, -0.1395,  0.2983, -1.3294,  0.2194, -0.6947, -1.2516, -1.0577,\n",
       "           0.6689, -0.7741, -0.5729,  0.3940, -0.5246,  0.0464,  0.0400,  1.9179,\n",
       "          -0.3417, -0.2355]),\n",
       "  tensor([ 1.7528,  0.7350,  1.5723, -0.2083,  2.0516,  0.2714, -1.0039,  1.3557,\n",
       "          -0.4440,  0.3746, -0.2667,  0.7746, -0.1189,  1.0580,  0.5121,  0.5957,\n",
       "           0.7052, -0.9088,  0.1178,  0.5138,  0.8981, -0.4547,  0.1062, -0.8953,\n",
       "          -0.2835, -0.1529,  1.2224,  1.2483, -0.0065, -0.3140,  1.0350, -0.3149,\n",
       "          -1.0162,  0.6522, -0.6310,  0.4413, -0.1854,  0.0683,  0.3560,  1.1807,\n",
       "          -0.4659,  0.2613, -0.4191, -0.9398,  2.4299,  1.8087, -0.5552, -0.9912,\n",
       "          -0.2832,  0.5707])),\n",
       " 'cet√°ceos': (tensor([ 0.8640,  0.6623,  0.3273, -0.5509, -0.7551, -0.0196,  0.0239,  0.2346,\n",
       "           0.7293,  1.0312, -0.3551, -1.0291,  0.0559,  0.5730, -1.1665, -1.0997,\n",
       "           0.0732,  0.3873, -0.6467,  0.9678, -0.6836,  0.7794,  0.7739,  0.1861,\n",
       "          -0.7964, -0.4839, -0.6926,  0.4204, -0.0257,  1.0929, -1.1926, -1.4634,\n",
       "           0.5152,  0.8007, -1.0431, -2.3532, -0.4629,  0.4471, -0.5220, -0.3997,\n",
       "          -1.6769, -1.2343,  1.8569,  1.4139,  1.2736, -0.5254, -0.0610, -2.7207,\n",
       "          -2.2460,  0.1756]),\n",
       "  tensor([-1.6648,  0.7412,  0.9492,  1.1294,  0.0192,  2.0441,  0.6042, -0.4320,\n",
       "           0.1261, -0.3900, -0.2394,  1.5406, -1.2604, -0.0154, -1.0417,  0.3178,\n",
       "          -1.0371,  1.1635,  0.5065, -0.0750, -0.3655, -0.5720,  1.3679,  0.0933,\n",
       "           1.2816,  0.0456,  1.2598, -0.0703, -0.1532, -0.9735,  0.3453,  1.9254,\n",
       "          -0.0741,  1.2981,  0.9775, -0.0510, -2.1764,  0.0751, -0.8468, -1.1162,\n",
       "           0.6227, -1.5371,  0.3409, -0.4397, -1.8016, -1.0812, -0.0454, -0.1011,\n",
       "          -0.3537, -0.5461])),\n",
       " 'chiapas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'chile': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'chileno': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'china': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'choc√≥': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'choferes': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'choques': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ciega': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cielo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ciento': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cient√≠ficos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ciernen': (tensor([ 0.6850, -0.2930,  0.7508,  1.3061, -0.2267,  0.2475, -0.3619,  1.4683,\n",
       "          -1.4822, -0.5999, -0.0322, -0.4360, -1.8048, -0.0973,  0.8349, -0.6692,\n",
       "          -0.5944,  0.0759, -1.0120,  0.1170, -0.1199,  0.0516, -0.5702,  0.7363,\n",
       "           1.4933, -0.3777,  2.3081,  1.7904, -0.8782,  0.7195,  0.0663,  0.8823,\n",
       "           0.4065,  1.5421, -0.4015, -0.4499,  0.9719, -0.3413,  1.2338, -0.2181,\n",
       "           0.9773,  0.1864, -0.3000, -0.4618,  0.9197,  0.6539, -0.3232,  0.5408,\n",
       "           0.5373,  2.1565]),\n",
       "  tensor([ 1.3303,  0.4672,  0.4518, -0.8950, -0.1646, -0.9990, -0.2677, -0.1421,\n",
       "          -0.1694, -0.4601, -0.2694, -0.0442, -0.4342,  0.6809,  1.2588, -0.8949,\n",
       "           0.4617, -0.1155, -0.5643,  0.8132,  1.5860,  2.7479, -0.3532, -0.0577,\n",
       "          -0.4948,  0.1700,  0.4853, -0.1519,  0.2221, -0.6733,  1.1159,  0.1449,\n",
       "          -1.0211,  0.2012, -0.2315, -0.8012, -0.7446, -1.7684, -0.5027, -2.1110,\n",
       "           0.0510,  1.2640,  0.6239, -1.0048, -0.0686, -0.8521, -0.2395,  1.9959,\n",
       "          -0.9169, -2.0925])),\n",
       " 'cierra': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cierre': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cierto': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cifra': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cifras': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cinco': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ciudad': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'civiles': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'civilizados': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'claro': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'clase': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'clasificaci√≥n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'claudio': (tensor([ 0.2909,  0.9829,  0.3764, -0.0885,  0.4593, -0.0225, -1.1472,  1.2477,\n",
       "           0.7281, -0.1428, -0.1028, -0.9765,  0.7722, -0.3035, -1.1373,  1.9044,\n",
       "          -1.3606,  0.7612,  0.8934,  0.5000,  0.4964,  0.3500, -0.0388, -0.1976,\n",
       "           0.2745, -0.8198,  0.0327, -0.3614, -0.2247,  0.9121, -0.3902,  0.3774,\n",
       "           0.6223, -0.3735, -0.0451, -0.0785,  1.1667,  0.1338, -0.7720,  1.8445,\n",
       "          -0.0983, -0.9049, -1.5612,  1.8588,  0.8387,  1.3972, -2.3102,  1.1813,\n",
       "          -0.3608,  0.2243]),\n",
       "  tensor([-0.2037, -1.1607,  0.2254,  1.6608,  1.3632,  1.5940, -0.8905,  1.6739,\n",
       "          -0.1186,  0.5184,  0.3350,  0.7611, -1.3670,  0.4513,  0.5067,  1.3770,\n",
       "           0.0353,  0.8414, -0.1902,  0.0376,  0.0881,  0.7187,  1.0887, -1.3341,\n",
       "           1.2906, -0.7687,  0.0811, -1.0326, -0.3282, -0.6765, -0.7460,  0.0487,\n",
       "          -3.0012,  0.3843,  0.7846,  0.6248, -0.4925,  1.3861,  0.3840,  0.5593,\n",
       "           0.6797, -1.0020,  0.4815, -1.0607, -1.9479,  0.0860, -0.5853, -0.8214,\n",
       "           0.2550, -0.1853])),\n",
       " 'clausura': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'clausuran': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'claves': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'clim√°ticos': (tensor([ 0.2485,  0.1984, -1.2916, -1.2291,  0.8874, -0.5106, -0.8735,  0.1030,\n",
       "          -1.2316, -1.0134, -1.7484,  0.3016,  1.9579, -0.1206, -0.4759, -2.1030,\n",
       "           0.0223, -0.3456,  1.2028, -0.1764,  1.1804,  1.6423, -1.0807,  0.0118,\n",
       "          -0.0280, -0.6506, -1.7681, -0.8909,  1.1878, -0.3852, -0.5462, -0.5311,\n",
       "          -0.5008,  0.8625, -0.5748,  0.0666,  0.6089, -0.3974,  0.9549,  0.3115,\n",
       "          -0.0065,  0.4218, -0.7946,  0.7991, -2.5900,  0.2138, -0.2188, -1.9938,\n",
       "          -0.3496,  0.9480]),\n",
       "  tensor([ 2.4184e-01,  6.6182e-01,  8.8603e-01, -9.2257e-01,  1.2230e+00,\n",
       "          -1.9641e-01,  6.6291e-01, -2.3566e-01, -9.2395e-01, -8.5403e-02,\n",
       "          -2.3020e-03,  1.0378e+00, -1.1915e+00, -1.0545e-01, -8.8028e-01,\n",
       "          -1.9221e-01,  9.3902e-01,  2.7737e-01,  1.5357e+00,  2.4572e-01,\n",
       "          -3.0880e-01,  2.9156e-01,  1.4748e+00, -2.3971e+00,  4.6111e-01,\n",
       "           8.4719e-01,  2.6296e+00,  7.4528e-01,  1.1500e+00,  1.1165e-01,\n",
       "          -1.7599e-01, -7.5883e-01,  5.1535e-02, -1.8342e-01,  7.0299e-01,\n",
       "           1.1245e+00, -1.4255e+00, -9.8842e-01,  5.9868e-01, -1.6951e+00,\n",
       "           3.6285e-01,  1.4631e+00,  3.4824e-01, -6.2404e-02, -2.7963e-01,\n",
       "           2.7094e-01,  3.2137e-01, -9.2570e-01, -2.0915e-01,  2.3236e-01])),\n",
       " 'clinton': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'coalici√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'coherencia': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'colaboraci√≥n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'colaborar': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'coleman': (tensor([-1.8459e+00,  6.2979e-01, -4.3691e-01,  6.0831e-01, -2.2590e-01,\n",
       "          -1.5234e+00, -9.5618e-01, -6.8434e-01, -2.8144e-01,  1.1873e+00,\n",
       "           8.9632e-01,  1.0472e+00, -2.0490e-01,  4.8768e-01, -6.7096e-01,\n",
       "          -3.6899e-02,  7.9824e-01, -1.7249e+00, -9.8606e-02, -1.9332e+00,\n",
       "           1.8419e-01, -2.5175e-02, -1.1890e+00, -2.1355e-01,  1.4966e+00,\n",
       "          -1.0419e+00,  7.4358e-01, -1.0533e+00,  3.9354e-01, -9.1047e-01,\n",
       "          -2.1936e-03,  1.6368e+00, -8.2828e-01, -1.1029e+00, -2.6102e-01,\n",
       "          -1.9754e-01,  5.0139e-01, -1.2809e+00,  5.5451e-01, -6.0785e-01,\n",
       "           2.6288e+00, -5.9751e-01, -1.6839e+00, -1.9512e+00,  3.1752e-01,\n",
       "           7.1028e-01,  6.8928e-01, -6.9353e-01, -1.7335e-01, -9.0421e-01]),\n",
       "  tensor([ 1.4650, -0.6959,  0.3522, -1.0898,  1.7683,  1.0350,  0.4257,  0.2187,\n",
       "           0.3095,  0.8911,  1.3966,  0.4929,  0.5597, -0.0122, -0.4711, -1.7844,\n",
       "           0.6437,  1.0196,  2.4091,  1.3770, -0.6875, -1.6397,  1.3681, -0.8768,\n",
       "           0.8755, -0.0176, -1.0196,  0.6637,  0.0609, -0.0391, -0.3971, -0.8745,\n",
       "           0.0737,  0.6975,  0.8892, -0.9833, -0.4278, -1.3220,  0.3118,  0.2591,\n",
       "           0.4267, -0.1561,  1.2497, -0.0873, -0.2782, -0.1938,  0.1021,  0.7448,\n",
       "           0.3044,  1.0887])),\n",
       " 'colombia': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'colombo': (tensor([-1.8820,  1.0205,  0.0609, -0.2614,  0.3213, -2.2587,  0.4134,  0.2974,\n",
       "           0.6982,  1.2290, -0.1204,  0.0798, -1.5090,  1.7873,  1.5658, -0.0128,\n",
       "          -1.0224,  0.2456,  0.7225, -0.0775, -2.5421,  0.8175,  0.7159,  0.7212,\n",
       "          -0.4121,  1.0968,  0.5391,  1.2281,  0.7280,  0.6903, -1.4703,  0.3311,\n",
       "           0.4218, -0.2215,  1.1042,  0.4720,  0.7903, -1.1930, -0.5091, -2.6289,\n",
       "           0.0503, -0.3074, -0.1277,  0.4970,  1.3671, -0.9386,  0.5928,  1.0963,\n",
       "           0.5555,  1.2938]),\n",
       "  tensor([ 1.5081,  0.2904,  0.0327, -0.7021,  0.5348, -1.0925, -0.3654,  0.2817,\n",
       "          -0.0965, -0.4206,  0.7889,  0.1707,  1.6590,  0.3114,  1.1763,  0.1209,\n",
       "          -1.5435,  0.7239,  1.1827, -2.9830,  1.0791,  1.8441, -1.1023, -0.8391,\n",
       "          -1.2940, -0.3674, -0.0615,  0.8800,  1.3465, -0.2385,  0.6201,  0.4267,\n",
       "           0.4846,  0.0380, -0.1849,  1.3918,  0.6028,  0.3665, -2.4385, -0.6690,\n",
       "          -0.1983, -2.1543,  0.4857, -0.4481, -1.3804, -0.4646, -0.4382, -0.4076,\n",
       "          -0.2238, -0.2090])),\n",
       " 'colonos': (tensor([ 1.1086,  0.6365,  0.7084,  1.8132,  1.2996,  0.0551, -1.6045,  1.2239,\n",
       "           1.0524,  0.1499,  0.4883,  0.9813, -0.7617,  0.0927,  1.0624, -1.8116,\n",
       "           0.2048,  0.2730,  0.9900,  2.1422,  0.5490,  0.2814,  0.4119,  0.6140,\n",
       "          -0.3123,  1.2667, -1.5120, -1.0376,  0.2318,  0.2533, -0.5874,  0.1060,\n",
       "          -0.4244, -0.2596,  0.8192,  0.6169, -0.2026,  0.7997,  0.9703, -0.2824,\n",
       "           1.1438,  0.4495, -0.6588,  1.2360, -0.4263,  0.8510, -0.4938, -0.1713,\n",
       "          -0.6974, -0.4978]),\n",
       "  tensor([-1.0054,  1.6833,  0.2650, -1.1756,  0.5086, -1.4899,  0.5731, -0.5530,\n",
       "          -1.1848, -1.0730,  0.3950, -1.6998, -0.6942,  0.5035,  0.0280,  0.5873,\n",
       "          -0.2573, -1.0178,  0.9877, -2.4289, -1.2766,  1.8073,  1.4038, -0.3000,\n",
       "           0.8550, -1.6553, -0.0633, -1.0990, -0.3582,  0.6759,  0.3622, -1.1596,\n",
       "           0.1781, -0.6777, -0.0204,  0.9973,  1.0494, -1.3790, -0.6796,  0.0825,\n",
       "          -1.6014,  1.3706, -1.0509,  0.1576,  0.7853, -1.4246,  0.1794,  1.0179,\n",
       "          -0.4679,  1.0682])),\n",
       " 'columna': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'combates': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'combatir': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'combustible': (tensor([-0.9513, -0.1088,  1.0390,  1.4331, -0.9233, -1.3044, -0.7467,  0.3638,\n",
       "           1.0108, -0.4610,  1.7221,  0.9531, -1.1643, -0.5963,  0.5418, -0.6645,\n",
       "           0.3916, -0.6975,  0.3774, -0.0697, -0.7468, -0.2337,  0.4887, -0.6213,\n",
       "           0.2355, -0.2837, -1.1942, -0.0049, -1.0408,  1.3417, -1.2382, -1.2593,\n",
       "          -1.7925,  0.3937,  1.2302,  0.4822,  0.2264, -0.6101,  0.7240,  0.6933,\n",
       "          -0.6335,  1.2197,  0.1255,  0.2024, -2.1487, -0.8994, -0.0956,  1.3769,\n",
       "          -0.8543,  0.2540]),\n",
       "  tensor([-1.3739,  0.7048, -1.6026, -0.6194, -0.7121, -0.3159, -0.5776, -2.9528,\n",
       "          -0.6154,  1.3512, -1.9961,  0.8852, -0.1341, -1.9912,  0.6436, -0.6358,\n",
       "           0.4510, -1.1340,  0.7207,  0.8556,  0.5269, -0.3141,  0.1477,  0.7762,\n",
       "           0.8471,  1.4190, -0.5201, -0.0368,  1.5785, -0.0296, -0.0595,  3.0066,\n",
       "          -0.2160, -0.4747, -0.6668, -0.9745,  1.8807,  1.4408, -0.8251,  0.7763,\n",
       "           2.0021, -0.1072,  1.0134, -1.8917,  0.9020, -0.0070,  0.1700, -0.6557,\n",
       "           0.0901, -1.0976])),\n",
       " 'comedia': (tensor([ 0.5929,  0.4764, -0.8803,  0.3067, -1.1583,  1.9913,  1.6427,  0.5433,\n",
       "           0.7349,  1.4700,  0.3414, -0.4956,  0.0346, -0.5536, -0.2868, -0.2373,\n",
       "          -0.9776, -1.5787,  1.6124, -0.7321, -1.1930,  0.0044, -0.4231,  1.1109,\n",
       "           1.2401, -0.2778,  0.8044,  1.0668, -0.9191, -1.2740,  0.7691,  1.0315,\n",
       "           1.3930, -0.0806, -0.5428,  1.2960, -1.3439,  0.5835,  1.5112, -0.9033,\n",
       "          -0.8381, -0.2986, -2.1653,  0.0415,  0.3894,  2.6612,  0.9345,  0.1073,\n",
       "           1.1646,  1.1416]),\n",
       "  tensor([ 0.3087,  0.6384, -0.0393,  0.8916,  0.1012, -0.8981, -1.5737, -1.4787,\n",
       "           1.0640, -0.8324, -0.9846,  0.8710, -0.9890,  0.1029, -2.4733,  0.0711,\n",
       "          -1.0683, -0.6123,  0.4143,  0.2060, -0.3984, -0.5589, -0.0515, -0.7042,\n",
       "          -0.4787,  0.4414, -0.4503,  0.1149, -0.7855, -0.8325, -0.1575,  1.1725,\n",
       "           1.0378,  0.0098,  0.7152, -2.0677, -1.0271,  0.6435,  1.9358,  2.3781,\n",
       "          -1.3642,  2.2004,  1.1307,  1.5399, -0.7498, -2.0575, -0.5797,  0.0075,\n",
       "           1.2530, -0.7473])),\n",
       " 'comentado': (tensor([-0.0277,  0.7447, -1.3042, -0.3047, -0.7615,  0.5090, -0.7606,  0.2872,\n",
       "          -0.3903, -1.7310, -1.9130, -0.8346, -0.9059, -0.6164, -0.7413,  0.8274,\n",
       "           0.1116, -0.3712,  0.7428,  0.0142, -0.3254,  0.4965, -0.4254,  0.0783,\n",
       "           0.7186,  0.3857,  1.3674,  0.3073,  1.3179, -1.3716, -0.8370, -0.1685,\n",
       "           1.3936, -0.1193,  1.0349, -1.4192,  0.4381, -0.7912,  0.3293,  0.7746,\n",
       "           1.5170, -2.5792, -0.2009,  1.0422, -1.2418, -1.4812,  0.9710, -1.0022,\n",
       "          -0.3474,  0.1760]),\n",
       "  tensor([-1.0083, -1.2449,  0.0995, -0.3908, -1.5877, -0.0634,  0.6065,  0.0748,\n",
       "          -0.6760, -1.0272, -0.1721, -0.2184, -1.3276,  0.5986,  2.1427,  0.5509,\n",
       "           0.6236, -0.6118,  0.8478,  1.0444,  3.2709,  0.0452,  0.4568, -1.8688,\n",
       "           0.6668,  1.3457,  1.6817,  0.3577,  1.6336,  0.3558, -0.0457,  0.1567,\n",
       "          -0.7011,  0.4916, -1.2222, -1.2355, -0.6836, -0.6139,  1.3205, -0.1839,\n",
       "           1.7005, -0.2966,  0.8906,  0.0357, -1.1341,  0.4475,  0.3257,  0.0420,\n",
       "          -0.8743, -0.4641])),\n",
       " 'comentar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comentario': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comentarios': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'coment√≥': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comenzar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comenzar√°': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comenzar√°n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comerciales': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comercializ√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comercio': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comienza': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comienzo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comisionista': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comisi√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comit√©': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comit√©s': tensor(-7.1526e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'como': tensor(-4.1723e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compara': (tensor([-1.0420,  0.7240,  0.1431, -1.4743, -0.1811, -1.3576,  1.5185,  0.2004,\n",
       "           0.7800, -2.7244,  0.1659,  0.2616, -1.1175,  1.3796, -1.4081, -1.0318,\n",
       "          -0.4309, -0.5120, -0.0112, -1.1990,  0.1444,  0.1312,  0.3067,  0.2595,\n",
       "          -0.1927, -0.7869, -0.3137,  3.1710,  0.3838,  0.7362,  0.2865,  1.9158,\n",
       "           0.8686, -0.1368, -1.3859, -0.1475, -0.7757,  1.5776,  0.4939,  0.0985,\n",
       "          -0.5845, -0.2417, -0.3297, -2.0865,  0.3857,  0.6268, -0.1796, -0.1682,\n",
       "           0.9358, -0.9465]),\n",
       "  tensor([-0.6590,  0.2223,  0.5244,  0.8284, -1.8097,  0.9131, -0.3326, -1.1103,\n",
       "           1.9516,  1.0910,  0.1393,  1.1213, -0.8407,  1.1206,  0.1283, -0.4838,\n",
       "          -0.3813, -0.9010,  0.4901, -0.7626, -0.4279,  1.0388, -0.5141, -0.2120,\n",
       "          -0.8939, -1.2877, -1.3080,  0.4458, -0.9222, -0.4974,  1.1433,  1.1368,\n",
       "          -0.0997, -0.5533,  0.7874,  1.3052, -0.0379, -0.4817,  0.3269,  0.4870,\n",
       "          -0.7604,  0.2539,  1.2460,  2.5924,  0.5996,  1.0887, -0.6875,  2.1064,\n",
       "           0.2932, -1.0087])),\n",
       " 'comparte': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comparten': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compartieron': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compar√≥': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compasi√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compatible': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compa√±√≠a': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compensatorias': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'competitiva': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'complace': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'complaciente': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'complejo': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'complejos': (tensor([ 1.8324, -0.5879,  1.5433, -1.2420,  0.0688,  1.0058, -0.2611,  0.1374,\n",
       "          -1.0610,  0.5738, -0.1495, -0.8122,  0.1711, -0.1919,  0.3077,  0.9459,\n",
       "           0.1804,  0.8228, -1.2404,  0.4816, -1.1633,  0.6757, -0.7187,  0.3763,\n",
       "          -1.4966,  0.3048, -0.0314, -1.5438, -1.5985, -0.2721, -0.5898, -0.1471,\n",
       "          -0.3504,  0.2277,  1.4597, -0.9941, -0.7364,  0.8685, -1.3826,  0.8479,\n",
       "          -0.3417, -0.4886, -0.4814, -0.6026,  0.9541, -0.1992, -0.3140,  0.9182,\n",
       "           0.0286, -1.0364]),\n",
       "  tensor([ 0.2777, -0.8864,  1.2903, -1.6212, -0.4654,  0.3961, -1.7343, -0.8174,\n",
       "           0.4669, -0.0171, -0.5344, -0.0799,  0.8633,  1.8010, -1.3744,  0.2593,\n",
       "          -0.0104,  0.3504, -0.6573,  0.1729,  0.2189,  0.8971, -0.7054, -0.0420,\n",
       "           0.9657,  1.3926, -1.9419, -0.2937,  0.5614,  0.6529,  0.1481, -1.2150,\n",
       "          -1.5687,  0.3447,  1.4282,  0.5124,  1.5681, -0.6981, -0.9581, -0.0504,\n",
       "          -1.1605,  0.2739, -1.1351, -0.9032,  0.4002,  0.2309, -0.3575, -0.3037,\n",
       "          -0.2788,  0.2769])),\n",
       " 'completa': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'completan': (tensor([ 0.3413,  0.6799,  0.3029, -0.5798, -0.6242,  0.5378,  1.1636,  0.5344,\n",
       "           1.2699,  1.2440, -1.9633,  1.7862,  0.1057,  1.6436, -1.1627, -1.9084,\n",
       "           0.8011, -0.8505,  0.8144,  0.1317,  0.2390, -0.7346,  0.7462, -0.5121,\n",
       "           1.0527,  1.0776,  0.2071, -0.5876,  0.1955, -0.4250,  0.3574,  0.4538,\n",
       "           0.9497, -0.0520,  0.8349,  1.8002, -1.5369, -0.3081,  0.5628, -0.0798,\n",
       "           1.3627, -0.2685,  1.3928,  1.3238, -0.5697, -0.4460,  1.2935, -1.9841,\n",
       "          -0.1276, -0.9523]),\n",
       "  tensor([ 1.7766,  0.4194,  1.2759,  0.2645, -0.0504, -1.1129, -0.3292, -0.9603,\n",
       "          -0.4829,  0.2956, -0.1684,  0.2986, -1.8591,  0.7978, -0.8285, -2.4765,\n",
       "          -1.9429, -0.5237,  1.2452,  0.0904, -0.2954,  0.4112, -0.0376,  1.6127,\n",
       "           0.0540, -0.0054,  0.0686, -0.4992, -0.4553, -0.4658,  0.2977, -0.0253,\n",
       "           1.1540,  1.2745,  0.4067, -0.2282,  0.8726,  0.1170, -0.1547, -1.1787,\n",
       "          -1.9463,  1.0294,  1.1502, -1.4698, -0.1028, -0.2793,  0.8811, -0.1744,\n",
       "           0.7252, -0.5173])),\n",
       " 'completo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'completos': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'complet√≥': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'complicadas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'composici√≥n': (tensor([ 0.6835,  0.7885, -0.8154, -0.6715,  1.0591,  0.2741, -0.4164,  0.8225,\n",
       "          -1.0927,  1.4728, -0.2361, -0.6532,  0.3004, -0.0143,  0.5129, -0.1912,\n",
       "           1.0119,  0.4367,  0.5537,  0.4562, -0.6381, -0.4009, -0.0938,  0.0196,\n",
       "           1.1613,  1.4198, -1.0687,  0.1694,  1.0085,  0.9939,  0.6915,  0.7825,\n",
       "           0.4150,  0.1124, -0.8035, -0.6478, -0.5611, -0.0583, -0.9463,  0.0900,\n",
       "          -0.7240,  1.1823, -0.0580, -0.6409,  0.6867, -1.2793, -1.3696, -1.1619,\n",
       "           0.1138,  1.1675]),\n",
       "  tensor([-1.0199, -0.2530, -0.0481,  1.0378,  0.4942,  0.9197, -0.0353,  0.2462,\n",
       "           0.4076, -0.6250, -0.4595,  0.3214,  0.0528, -0.1740, -0.5898,  0.7719,\n",
       "          -0.4184,  0.4866, -0.3063,  0.5957,  1.3009, -2.6196,  0.4353, -0.5471,\n",
       "           0.4963, -0.4713, -0.1272, -0.3948,  1.1713,  0.2216, -0.6149,  0.1647,\n",
       "          -0.4660, -2.2588, -0.5860,  2.0771,  0.1428, -0.5338, -1.4167,  0.0193,\n",
       "          -0.5164,  0.0890,  0.4682,  0.2927, -0.3624, -0.8722, -0.0730,  1.0174,\n",
       "          -0.6800, -0.3873])),\n",
       " 'compras': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comprende': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comprendemos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comprender': (tensor([ 0.5411, -0.3459, -0.6096,  0.9679,  0.8265,  0.0820, -0.8650, -0.4003,\n",
       "          -1.8239,  0.6427,  0.8428, -0.9327, -1.6981, -0.1815, -0.7700, -3.0965,\n",
       "          -0.8655,  0.2770, -0.9388, -0.4335, -0.8391,  0.9235,  0.8458, -0.2637,\n",
       "           0.0233, -0.3677, -0.5661, -0.1118,  2.0544,  0.2926, -0.8626,  0.2442,\n",
       "          -0.2705, -1.3320, -0.9147, -0.6192,  0.3051, -1.4277,  0.1024, -0.6251,\n",
       "           1.7501, -1.3730,  0.3732,  1.0962,  0.6537, -0.0591, -0.0701, -1.2773,\n",
       "           0.5175, -0.8237]),\n",
       "  tensor([-2.7361e-01,  9.3456e-01, -1.9029e+00, -1.8829e+00,  1.9375e+00,\n",
       "           3.2280e-01, -1.0430e+00, -1.5973e+00,  1.5359e+00,  1.1220e+00,\n",
       "          -8.2379e-01, -2.6695e-01, -1.4157e+00,  8.3620e-01,  1.3688e-01,\n",
       "           1.2054e+00, -4.6136e-01,  3.2409e-01,  1.9548e+00,  7.0396e-01,\n",
       "           6.3236e-02,  4.0075e-02, -2.8960e-01, -2.0514e+00,  5.2307e-01,\n",
       "           8.0047e-01,  1.8262e+00, -6.1364e-01,  2.9004e-01,  7.4688e-01,\n",
       "           5.6495e-01, -1.6743e+00, -1.3226e+00,  7.5009e-01,  7.8251e-01,\n",
       "          -2.8602e-01, -7.3765e-02,  5.6769e-01,  4.2926e-01, -2.5329e+00,\n",
       "           4.9256e-01,  1.3287e+00, -1.2200e+00, -1.0494e-01,  3.5832e-01,\n",
       "          -2.5262e-01, -3.3234e-04,  5.8402e-01, -5.9275e-01,  5.2170e-01])),\n",
       " 'comprenderse': (tensor([ 1.4286,  1.5708, -0.9912, -0.4504,  0.1123, -2.3829, -1.0421, -0.6771,\n",
       "          -0.9744,  0.5885, -0.5122,  1.1403, -0.9930,  1.2933,  0.5902,  1.2626,\n",
       "           0.7075,  0.9721,  1.4063,  1.6784,  0.4839, -1.0610, -1.4905, -0.8730,\n",
       "           0.3007, -1.3476,  1.0255,  0.5764, -0.8349,  0.0318,  1.3452, -0.3613,\n",
       "           0.6129, -1.0595,  0.1175, -0.9023, -0.5872, -0.4026, -0.4703, -1.1248,\n",
       "          -0.1837,  2.1374,  1.8612, -0.2181, -0.1738, -0.7869,  0.7052, -1.3050,\n",
       "           0.8086, -0.8421]),\n",
       "  tensor([-0.7820, -0.3036, -1.4205, -1.0443,  0.3986,  1.4617,  0.3173,  0.2448,\n",
       "          -0.2274, -0.1905,  1.9475,  1.0162, -1.1091,  0.0605,  0.7335, -0.2627,\n",
       "          -0.9797, -0.9526,  1.1915,  1.0313,  1.8499,  0.6150,  1.8695,  1.2971,\n",
       "           0.5782, -0.8059,  0.1172, -0.8300,  0.2076,  1.7543,  0.7202,  0.2701,\n",
       "          -0.8606, -0.5589,  1.8054,  0.8170, -0.1729, -1.0117, -0.2060, -1.7869,\n",
       "           1.7575,  1.3186,  0.2368, -1.5425,  0.3353,  1.2996,  0.8779, -1.6938,\n",
       "          -0.8639, -2.2779])),\n",
       " 'comprender√°': (tensor([ 0.4244,  1.0686,  0.0520,  1.0956,  2.3122,  1.3091, -0.1967, -1.4560,\n",
       "          -0.0898, -0.0147,  1.9571,  0.8798, -1.1765,  0.3329,  0.6301, -0.4509,\n",
       "          -1.5620,  1.1384, -0.5464, -0.0807, -0.2274, -1.0822, -0.8082,  1.5257,\n",
       "           0.5359,  0.1769,  1.0564,  1.6284, -0.1372, -1.7007,  1.2492,  0.4709,\n",
       "          -0.4495, -1.2139,  1.2360,  0.9664, -0.2250,  0.1729, -0.7055,  0.5191,\n",
       "           0.1555, -1.9043,  0.6099, -0.0431, -1.3525,  0.8274,  0.0829, -1.6333,\n",
       "          -0.1544,  0.0237]),\n",
       "  tensor([ 2.7405e-01, -3.6293e-01, -1.0760e+00, -1.1008e-01, -6.1131e-01,\n",
       "          -4.0212e-02,  1.0688e+00, -4.0966e-01,  1.1040e+00, -6.3452e-01,\n",
       "          -1.0869e+00, -2.0057e-01,  3.7071e-01,  1.3873e+00,  8.0841e-01,\n",
       "          -7.7992e-01, -2.6182e-01,  9.3053e-01, -1.7817e+00, -4.7040e-01,\n",
       "          -5.8313e-01,  1.1907e+00,  1.1925e+00, -6.9534e-01,  5.2741e-01,\n",
       "           6.4731e-01, -1.9066e-03, -2.2081e+00, -3.6992e-01,  2.0851e-01,\n",
       "          -3.9380e-01,  1.3796e+00,  1.5642e+00, -8.7202e-01,  1.6097e+00,\n",
       "          -2.4053e-01, -1.7266e+00,  2.3527e-01,  7.0571e-01,  4.8324e-01,\n",
       "          -2.1512e+00, -9.1480e-01,  3.2107e-01, -3.0366e-01, -3.8602e-01,\n",
       "           1.2726e+00, -3.3309e-01,  1.8368e-01,  1.6721e+00,  2.3845e-01])),\n",
       " 'comprendi√≥': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comprensi√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'comprometido': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'compromiso': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'com√∫n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'con': tensor(2.9802e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'concebido': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'concepto': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conciencia': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conclusiones': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conclusi√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'concluye': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conclu√≠das': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conclu√≠do': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'concreta': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'concretos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'concuerda': (tensor([-1.0173,  1.3451,  0.1503, -0.3769, -0.3198,  0.6269, -1.9681, -0.0716,\n",
       "           0.3633,  0.7289,  1.0343, -0.7147, -1.2626,  0.8840, -0.8187, -0.8163,\n",
       "           1.6851,  2.0078,  1.5716,  0.5583, -1.4063, -0.4142,  0.8301, -1.4949,\n",
       "          -1.1744, -0.4091, -0.0194, -2.2173,  1.4084,  1.2092,  0.9507, -0.8947,\n",
       "          -1.0012, -1.4034,  1.1962, -1.0809,  0.1956, -0.2620, -0.1868,  0.4259,\n",
       "           0.2562,  0.6241, -1.3184,  0.6093, -0.5472,  0.1022, -0.6193,  2.2494,\n",
       "           0.2857, -0.1159]),\n",
       "  tensor([-0.9064,  0.9992,  1.5305,  2.0233, -1.2420, -0.1435, -1.1311,  0.4201,\n",
       "           0.9322, -0.2515,  0.7388, -1.7555, -0.8092,  2.7740,  1.3618, -0.2703,\n",
       "          -0.1032,  0.7436,  0.2878, -0.5991, -1.8304,  1.4712,  0.2353, -0.9017,\n",
       "          -0.2076,  1.5995,  0.5495,  0.1114,  1.1898, -0.9719,  1.1026,  0.7886,\n",
       "           1.0796, -0.2474,  1.6531,  0.8763, -2.8260, -0.0826, -1.4806,  0.1650,\n",
       "          -0.2795, -2.1003,  0.0499,  0.8091,  0.3777, -2.2130, -0.0404,  0.6913,\n",
       "          -0.0607, -0.5060])),\n",
       " 'conc√©ntrese': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'condena': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'condenatorio': (tensor([ 0.0692,  1.3186, -0.0216, -0.9051, -0.8657,  0.1030, -1.1029,  0.8916,\n",
       "          -0.1393, -0.4353,  0.6549, -0.0561, -0.2458,  0.6188, -1.1740, -1.7000,\n",
       "          -0.1423, -0.3865,  0.3544,  0.2661, -1.2735,  0.3831,  0.6319, -0.9725,\n",
       "           0.2277, -0.1861,  1.1210,  0.6934,  0.2312, -0.3612,  0.2078, -0.0838,\n",
       "           0.0499, -1.9634,  0.9589, -0.2341,  0.9654,  2.7791, -0.7902, -0.2784,\n",
       "           0.3636, -1.0532,  1.7595, -1.6288, -0.4967,  0.3453,  0.4038,  1.1816,\n",
       "           0.1089,  0.3361]),\n",
       "  tensor([ 1.1931, -0.8897,  0.8356, -1.1394, -0.8231, -0.3519,  0.1339, -1.4788,\n",
       "           0.2292,  0.0929, -0.5030, -1.7592, -1.5535,  0.6903,  1.5578,  0.7061,\n",
       "          -0.0436, -0.7508,  0.3536, -0.2754, -0.3315, -0.4278, -1.5318, -1.8217,\n",
       "           0.6807, -0.1784, -0.9905,  0.9848,  1.9914, -3.2347, -1.5010,  1.6620,\n",
       "           0.4141, -0.9377, -0.3714,  0.5807, -0.1813,  0.9055,  0.5118, -0.6286,\n",
       "           0.4899, -0.3865,  0.0765,  0.9448,  0.2743, -0.2604, -0.1133,  1.7663,\n",
       "          -1.4864,  0.3409])),\n",
       " 'condiciones': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'condici√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conductor': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'condujo': (tensor([-0.4790,  1.6097, -0.6526,  0.1594,  0.2918,  0.3205,  0.9402, -0.7871,\n",
       "           1.1519, -1.4195,  1.9918,  0.1577, -0.2569, -0.9156,  2.9759, -0.5675,\n",
       "          -0.1051,  0.9933, -0.4678, -1.0390,  1.8800,  1.0590,  0.1634, -0.6284,\n",
       "          -0.2058,  1.1724, -0.0702,  0.2503, -0.1185, -0.4095, -0.0684,  1.0450,\n",
       "          -1.4702,  0.5564,  2.0828,  1.5627,  0.9069, -0.9003,  1.5553,  0.4809,\n",
       "          -0.2970,  1.3735,  2.1010,  0.5390,  0.2456, -1.3379, -2.2027, -0.8097,\n",
       "           0.6342,  0.4564]),\n",
       "  tensor([ 2.1092, -0.9815, -0.3992,  0.8605,  1.1423,  0.3741,  0.4122, -0.7319,\n",
       "          -0.3736,  1.7269, -1.1280, -0.0708, -0.1684, -0.4368,  0.1891,  0.9453,\n",
       "           0.0568,  1.7068,  0.8517,  0.9714,  0.6636, -1.1814, -1.5115, -0.4676,\n",
       "          -0.5502,  0.3056,  1.0605,  1.0626, -0.6086,  0.3966, -0.5910, -0.3401,\n",
       "          -0.1276, -0.4211, -0.9476,  1.3884,  0.7761,  0.3450,  0.0350,  0.2132,\n",
       "          -1.0938,  1.1110,  0.3126, -0.6597, -2.1304, -0.9315,  0.4813,  1.5595,\n",
       "          -0.1871, -1.2022])),\n",
       " 'conexi√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conferencia': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'confianza': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'confidenciales': (tensor([-0.1903, -0.1975, -1.3502,  0.6076, -0.2699,  0.8249,  0.6698, -1.4433,\n",
       "          -1.5976,  0.3775, -0.1745, -0.7781, -0.8324, -0.2964, -0.6374,  0.2869,\n",
       "           1.6892, -1.0002, -2.3728, -0.0962,  0.0171,  0.0960,  1.4809,  0.4885,\n",
       "           0.4993,  0.3148, -0.0132, -0.0198, -0.4693,  0.9493, -0.7722, -1.2346,\n",
       "           0.2569, -0.7322, -0.6090, -1.6362, -0.1597,  2.5070, -0.8218,  0.4101,\n",
       "           0.4952, -0.3656, -0.0720, -0.8681, -0.2524,  0.7723,  1.6577,  0.1992,\n",
       "           1.3573,  0.6713]),\n",
       "  tensor([-0.6652, -0.0840, -2.1228,  0.8951,  2.0051, -0.4628, -1.1583,  0.0604,\n",
       "          -0.1974,  0.2695, -1.3951,  0.4131, -1.3948, -1.3650, -1.1569, -1.1565,\n",
       "          -0.7014, -0.7822, -0.2166,  1.1629,  1.9755,  0.5820, -0.6417, -0.8151,\n",
       "          -0.6038,  1.5995,  0.6645, -0.0278, -0.8891,  0.5534, -0.3125, -0.5266,\n",
       "           0.5316,  0.3767, -0.9974, -0.2918,  1.9105,  0.2375, -0.2118,  1.2339,\n",
       "           0.2816,  0.2271,  1.2744,  0.7235,  0.1096, -0.6621, -0.3582, -0.9959,\n",
       "          -0.3237, -0.1480])),\n",
       " 'confirmado': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conflictos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conforme': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'confuso': (tensor([-4.4518e-01, -9.6880e-02,  5.3719e-01,  1.2908e+00, -6.0662e-01,\n",
       "          -1.2636e+00, -5.9163e-01, -4.0377e-01,  1.4663e-01,  6.0559e-01,\n",
       "           4.8365e-01,  7.2427e-01, -1.0085e+00, -1.1009e-01,  1.0699e+00,\n",
       "           1.2880e-01, -1.0146e+00, -4.4267e-01,  1.4173e+00,  5.9414e-01,\n",
       "          -6.3126e-01, -1.4374e+00, -9.4287e-01, -7.6358e-01, -1.1021e+00,\n",
       "          -2.6050e-01, -5.0038e-01, -1.2774e+00,  1.7775e+00, -1.4297e+00,\n",
       "          -7.2016e-01,  7.6364e-01, -3.4544e-01,  1.3450e+00, -1.1946e+00,\n",
       "          -6.9238e-01,  2.6612e+00,  9.2067e-02, -1.7388e+00, -3.7831e-01,\n",
       "          -3.3246e-01,  2.2711e-03,  4.9210e-01,  2.0266e+00,  5.1400e-01,\n",
       "           2.1542e-01, -9.4718e-02, -1.7465e+00,  3.3352e-01, -8.2518e-01]),\n",
       "  tensor([ 1.2571,  1.1354, -0.4011, -0.3422, -0.4449,  0.0640, -0.2088,  0.9036,\n",
       "          -0.8152,  0.8521, -1.9931,  0.8926,  1.1583, -1.0026,  0.8430, -0.1612,\n",
       "           0.0769,  0.8050,  0.9688,  0.3103, -1.8794, -1.8842, -0.2940,  1.1241,\n",
       "          -0.1788, -0.1779, -0.6553,  0.3699,  1.7580, -0.5268, -1.7278, -0.3586,\n",
       "           0.5026,  0.1742,  0.3419,  1.4812, -0.2017, -1.2019,  0.1908, -0.0521,\n",
       "           0.4535, -1.6439, -0.6216,  0.0458,  0.6611, -0.6899,  0.3279,  0.5035,\n",
       "          -0.3550,  1.0488])),\n",
       " 'congelar√≠an': (tensor([-1.0788e+00,  5.5379e-01,  1.3988e+00, -1.6918e+00, -5.2936e-01,\n",
       "           2.2689e+00,  7.3797e-01,  2.1117e+00, -2.0160e-01,  6.1175e-01,\n",
       "          -1.3387e+00, -1.8727e-01, -1.8739e-03,  9.6356e-04,  2.5488e+00,\n",
       "          -1.0158e+00,  7.1613e-01, -3.6160e-01, -2.0936e-02, -1.6986e-02,\n",
       "           5.9227e-01, -6.8197e-02, -1.2771e+00,  9.8505e-02, -1.3362e-01,\n",
       "          -1.9218e-01, -8.0737e-03, -5.5795e-01,  4.8262e-01, -3.2712e-01,\n",
       "          -1.0715e+00,  6.1754e-01,  1.0342e+00,  2.6121e-01, -5.1889e-01,\n",
       "          -1.2804e+00,  5.6161e-01,  4.6339e-01,  2.3745e-01,  5.7087e-01,\n",
       "           1.1174e-01,  4.2522e-01, -1.7004e-01,  2.8015e-02,  1.5658e+00,\n",
       "           5.9629e-01, -1.3666e+00, -3.7419e-02, -1.7008e+00, -1.7678e+00]),\n",
       "  tensor([-1.3222e+00, -6.4925e-01, -1.0713e+00,  6.6458e-01,  1.1242e+00,\n",
       "          -1.5940e-01, -1.3682e+00, -6.9881e-02, -7.8676e-01,  5.3033e-01,\n",
       "           2.2335e-01, -1.2525e+00, -1.5133e+00, -1.9354e+00,  6.1443e-01,\n",
       "          -4.4396e-01,  5.2251e-02,  1.0407e+00,  4.0735e-01, -8.5369e-01,\n",
       "          -8.5872e-01, -1.2150e+00, -7.0129e-01, -1.0695e+00,  9.7312e-01,\n",
       "           6.7359e-01, -4.1219e-01, -9.5221e-01,  3.9970e-01,  2.8752e-02,\n",
       "           6.0742e-01,  2.5808e-01, -2.0757e-03, -2.2207e-01, -2.9899e-01,\n",
       "           1.2946e-01, -8.6754e-01,  1.5858e+00, -1.3635e+00, -1.4201e+00,\n",
       "          -4.9481e-01, -4.3365e-01,  1.0229e+00,  1.5162e-01, -6.0230e-01,\n",
       "          -9.0201e-02, -2.0835e+00,  1.3348e+00,  1.1008e+00, -1.4879e+00])),\n",
       " 'congreso': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conoce': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conocen': (tensor([ 0.0628,  0.1408, -0.7608, -1.0194, -1.4522, -0.6329,  0.6309, -3.0020,\n",
       "           0.2683, -1.7556, -0.4080,  2.1668, -0.3996,  0.5734,  1.4699, -0.1549,\n",
       "           0.1339, -0.3961,  1.8983,  0.0915,  0.1815,  0.0889, -0.1021,  1.0845,\n",
       "           0.7382, -0.3179, -1.1380, -0.2879,  1.0415, -0.1339, -0.0463,  1.4107,\n",
       "           1.3052, -0.3960,  1.0614, -0.2864, -0.3439, -0.4924, -0.8006,  1.3592,\n",
       "          -0.9356, -0.8643,  0.0690,  1.8543,  1.3043,  0.3417,  0.3537, -0.2079,\n",
       "          -0.6040,  0.2963]),\n",
       "  tensor([ 1.0025, -0.8490,  0.0583, -0.7849, -1.3762,  0.5426,  0.6738,  0.1664,\n",
       "           0.7112, -1.0283,  1.0450, -0.4882,  0.2083, -0.9591, -0.9618,  0.0884,\n",
       "          -0.8509, -0.4407, -0.6578, -1.1341, -0.2454, -1.0101, -0.1060, -0.2568,\n",
       "          -0.3494,  0.1538,  0.2263, -0.3786, -0.8938, -0.0965, -0.5495, -1.9546,\n",
       "           0.6785, -1.7130, -0.8379,  0.0567, -0.7419,  0.4917,  0.4107,  0.3004,\n",
       "           0.8907,  0.3541,  0.2040,  0.9541,  0.7748, -0.2964,  1.8401,  0.4448,\n",
       "          -0.8653,  0.3463])),\n",
       " 'conocer': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conocerla': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conocida': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conocido': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conocimiento': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consecuencia': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consecutivos': (tensor([-1.5711,  0.2191, -0.9472, -0.0392,  0.1206,  0.0698,  0.4577,  0.4305,\n",
       "           0.4639, -0.7087, -2.5330, -0.7736,  1.6389, -0.5043, -0.4241,  0.4589,\n",
       "          -0.7485, -0.9406, -0.4366,  0.9501,  0.5911, -1.1807, -1.6496, -0.0042,\n",
       "           1.1578,  0.2828, -0.1119,  0.6506,  0.5562,  0.5447, -1.1203, -1.1887,\n",
       "           0.1441, -0.6883, -0.6954,  1.2067,  0.4625, -1.5522,  1.4238, -1.1201,\n",
       "           0.7061,  0.2606,  0.5538,  0.7205, -0.2583,  0.5392, -1.2123,  0.4415,\n",
       "          -0.4490,  0.9934]),\n",
       "  tensor([ 4.4167e-01, -5.0906e-01,  1.4158e-01,  1.2050e+00,  1.8528e-01,\n",
       "          -2.2693e-01,  5.2029e-01,  7.8067e-04,  1.0509e+00,  3.1740e-01,\n",
       "          -1.0420e+00, -2.1179e-01, -3.0875e-01,  1.7529e-01,  1.5237e+00,\n",
       "          -8.7502e-01,  1.8446e+00, -3.0990e-01,  7.1443e-01,  9.8203e-01,\n",
       "           2.3204e+00, -3.5169e-01,  5.4094e-01, -1.6306e+00, -2.1296e-02,\n",
       "           5.8089e-01, -4.0492e-01,  2.8199e-01, -1.4579e+00, -1.4307e+00,\n",
       "          -7.2279e-01, -1.5661e+00,  1.0604e+00, -1.2682e-01, -7.0265e-01,\n",
       "          -1.4972e+00,  1.8358e+00, -2.4054e+00,  2.2173e+00,  3.7920e-01,\n",
       "          -4.9898e-01, -2.6605e-01,  1.0134e+00,  1.3894e+00, -2.6966e-02,\n",
       "           2.2250e+00, -5.4056e-01,  2.3010e-01, -2.3600e+00,  4.4297e-01])),\n",
       " 'conseguir': (tensor([ 0.8374,  1.6989,  0.8031,  1.2056,  1.5733,  0.5671, -0.1078, -0.2936,\n",
       "           0.5699, -0.8694, -0.0603, -0.7824,  0.9764,  0.2407, -1.4323,  1.5817,\n",
       "           0.9209, -0.5754, -0.2830, -0.4315,  0.0601,  0.0653,  0.2135,  0.3501,\n",
       "           1.1879, -0.5366, -0.9549, -0.5612,  1.0631,  2.0972,  1.0196,  0.7308,\n",
       "          -1.2626, -0.1457,  2.1132,  1.6474, -0.3984,  0.6229,  0.9948,  1.3634,\n",
       "          -1.0180, -0.4916,  0.5664, -0.0909,  0.6547,  0.6667,  0.7354, -0.9901,\n",
       "          -0.7242,  0.6872]),\n",
       "  tensor([ 2.6416,  0.4143,  2.1712,  0.9117, -0.8110, -0.0395, -0.8264, -0.3356,\n",
       "          -0.7868,  0.6316, -0.5220,  0.1774, -0.8271,  0.3720, -1.3234,  2.1063,\n",
       "           0.0521, -0.6553, -1.1644,  0.1397,  0.4633, -1.9617, -0.7899,  0.8523,\n",
       "           0.7218,  0.8473,  0.0189,  0.2055, -1.2298, -0.5115, -0.4485,  0.8338,\n",
       "           1.5243, -1.3081,  0.6850,  0.4130, -1.7782, -0.8401, -0.6638, -0.8141,\n",
       "          -1.1760, -0.1437, -0.7079,  0.5542,  0.5166, -0.9631, -0.1159,  0.2634,\n",
       "          -0.1218, -1.1721])),\n",
       " 'consejo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consenso': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conservaci√≥n': (tensor([ 0.0438,  0.5671, -0.6078, -0.8385,  0.6052,  0.4102, -0.3661, -0.6271,\n",
       "           0.3287,  0.2169,  0.7946, -0.2518,  0.0467, -0.3333, -0.1716,  1.0774,\n",
       "           1.5806,  0.4461, -0.3962, -0.7164,  0.1692,  1.0124, -0.3216,  0.2095,\n",
       "           1.5777,  0.0648, -1.1298,  0.7579, -0.5134,  1.1524,  0.3467,  0.5991,\n",
       "          -0.1419, -0.8105,  0.7992,  1.1926,  1.5213,  1.5024,  0.1707, -0.7884,\n",
       "           0.2252, -0.8359,  0.3111, -2.5408, -0.5882, -0.3539,  0.2485, -0.1457,\n",
       "           1.3025,  0.7184]),\n",
       "  tensor([ 0.4078, -1.3959,  0.8148, -0.3491, -1.2443, -0.5100,  2.0432, -1.2597,\n",
       "          -2.3178,  0.2643, -0.6051, -1.9571, -0.6670, -1.2264,  0.2376, -1.9383,\n",
       "          -2.5280, -0.2761,  0.4130,  0.3296, -1.9535, -1.3782, -0.3960, -1.0012,\n",
       "          -0.3684,  1.2612, -0.7371,  0.0489,  2.7046,  1.5458, -1.1005,  0.4674,\n",
       "           1.9592, -0.6417, -1.7484, -0.0576, -0.0113,  0.0552, -0.7003,  0.6512,\n",
       "          -0.1464,  0.2335,  1.9570, -0.8558, -0.9536,  0.5342, -0.5139,  0.7726,\n",
       "           1.1123,  1.1053])),\n",
       " 'considera': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'considerablemente': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consideraci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consider√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consignaciones': (tensor([-0.3090, -0.8350,  0.3692, -0.4408,  1.3608,  1.2677,  0.4587,  1.1600,\n",
       "           0.0552, -0.0107,  1.1930,  0.2956, -0.4244,  2.1896,  0.1602,  1.2395,\n",
       "           1.3202,  0.3875,  1.5887, -0.2311,  1.2344,  1.0202, -0.5327,  0.3615,\n",
       "          -1.5697, -0.5370, -0.9989,  2.0881,  0.1891, -0.1874, -1.3486, -0.7734,\n",
       "          -0.1660,  1.4202, -1.1002,  3.5046, -0.0211, -1.7046, -1.7114, -2.2879,\n",
       "           0.3692, -1.3895, -0.4710,  0.9318,  0.1755,  1.2869, -0.6135,  1.1576,\n",
       "          -1.5831,  0.6026]),\n",
       "  tensor([ 3.6301e-01,  4.1632e-01, -4.6268e-01,  7.2176e-01,  6.1936e-01,\n",
       "           1.1098e+00,  4.2390e-01,  9.5897e-01, -1.2528e+00, -9.3275e-04,\n",
       "           3.1382e-01, -8.9005e-01,  1.1614e-01,  9.1929e-01, -8.7434e-01,\n",
       "          -1.1095e+00, -4.5046e-02,  5.5960e-01,  1.0372e+00,  6.6493e-01,\n",
       "          -2.5397e-01,  1.8408e+00, -4.0037e-01, -6.0786e-01, -1.9508e+00,\n",
       "           4.2736e-01, -6.8595e-01,  5.9329e-01,  5.0520e-01,  1.9549e-01,\n",
       "          -2.0346e+00,  1.3220e+00,  3.4865e-01, -6.0055e-02, -1.1495e-01,\n",
       "          -1.3399e+00, -1.1427e+00,  5.4700e-01,  4.3902e-01, -1.9910e+00,\n",
       "          -5.8458e-01, -5.6482e-01,  7.5414e-02, -4.5604e-02,  1.6075e-01,\n",
       "           1.7053e+00, -6.1975e-01,  2.5376e-01, -5.7387e-01, -3.1055e-01])),\n",
       " 'consiguiente': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consta': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'constante': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'constantemente': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'constituir√°n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'constituye': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'construcciones': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'construir': (tensor([-0.2672, -0.6180,  0.5958,  0.9764, -0.7827,  0.9889,  2.5804,  1.1059,\n",
       "          -0.5343,  2.4650,  0.9178, -1.5028,  0.3389, -0.0699, -0.7077,  0.0760,\n",
       "           0.8838, -1.1108,  0.9670,  0.1930,  1.1024,  0.4657, -1.0002, -1.3772,\n",
       "           0.8904, -1.6023, -0.0969,  0.0917,  0.5541, -0.3627, -1.8595,  0.6378,\n",
       "          -0.8886,  0.4568,  0.6973, -0.0621,  1.7402, -0.8316,  0.2238, -1.2778,\n",
       "          -0.0319, -0.4244, -0.8191,  0.2383, -0.6078,  1.0261,  0.0650,  1.9934,\n",
       "           1.3736,  1.6869]),\n",
       "  tensor([-0.1344,  0.0908,  0.7663, -0.1961, -0.0660, -1.3477, -1.1539,  1.0819,\n",
       "          -1.1884, -0.0563, -0.6476, -0.5969,  0.3005, -0.6192, -0.0330, -0.2987,\n",
       "          -0.1558, -0.5950, -0.2036, -0.4438,  1.3088,  0.2484, -1.0533,  0.3873,\n",
       "           0.5613,  1.6588,  0.9202, -1.2212,  1.0936,  1.9791, -0.2890, -0.6350,\n",
       "           1.1808, -1.1540,  2.1795,  0.3774,  0.5433,  0.5712, -1.2807, -0.3603,\n",
       "          -0.3166, -0.4639, -1.4307, -0.7038,  0.7008, -0.4418, -1.3328, -1.0002,\n",
       "           0.9594, -0.1963])),\n",
       " 'consulta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consumado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'consumo': (tensor([ 0.0714,  0.5116, -0.6094,  0.0063, -0.0809,  0.5991,  0.7640, -0.6377,\n",
       "          -0.2248,  1.6251, -0.5694,  1.0326,  0.1637, -0.5028, -2.2696, -1.9734,\n",
       "          -0.8513,  1.4681, -3.1469, -0.2554, -2.3051,  0.4299, -0.7565,  1.7704,\n",
       "           0.6093, -0.1875, -1.3264,  0.7035, -1.1731,  2.3705,  0.3759,  0.4936,\n",
       "          -0.8746,  1.4232, -1.0605,  1.1987, -0.0633, -1.8988,  0.3912,  0.9614,\n",
       "           2.4736,  0.5754, -1.0658, -0.5097, -0.7640,  0.7131,  0.4757,  3.4695,\n",
       "           1.3815, -0.2233]),\n",
       "  tensor([-0.3145,  0.0380,  2.3358,  1.0032,  0.2016,  1.2181,  0.4921, -1.0329,\n",
       "          -0.7961,  1.2272,  0.0796,  0.4335,  0.4498, -0.0598, -2.8250,  0.8953,\n",
       "          -1.1650, -0.4242, -0.1900,  1.3501,  0.8027,  0.9573,  0.4105,  1.7429,\n",
       "           0.1265,  0.7996,  1.9033, -0.5760, -0.0726,  0.6945,  1.9309,  1.3589,\n",
       "           1.1347, -0.3820, -0.2111, -0.1243, -1.1014, -0.1398, -1.3024,  0.0431,\n",
       "           0.9815, -0.5027, -0.0995,  0.6721, -0.1517, -1.7738, -0.1276,  0.9588,\n",
       "          -0.5935, -0.4008])),\n",
       " 'contactado': (tensor([-1.2430, -0.8409, -1.1772,  1.2546, -1.0499, -0.7797,  0.6255,  1.3739,\n",
       "          -1.2711,  0.9149, -0.6372, -0.6852, -0.0842,  1.2363,  0.4796,  0.1113,\n",
       "           0.5909,  0.1393, -0.0905, -0.0096,  0.8868,  0.0190, -0.4494,  0.0495,\n",
       "          -1.4301,  0.5025,  1.2355, -0.4445, -0.4819, -0.0483,  2.0316,  1.8773,\n",
       "           2.0801, -1.8824, -0.7457,  1.0084,  0.1869, -0.2317, -0.6747, -1.6325,\n",
       "           0.1611, -0.0899, -0.5660, -2.2917, -2.5578, -1.1338,  1.6424, -0.5007,\n",
       "           0.2257,  0.1684]),\n",
       "  tensor([ 0.5385,  1.0354,  0.3238,  1.1857, -0.1360,  1.5068,  0.7163, -0.3848,\n",
       "          -0.7950, -0.9050,  0.4860,  1.0343,  1.1943,  0.7361, -0.0435, -0.2518,\n",
       "           0.5000,  0.3339, -1.8431,  0.1770,  0.7369, -1.5851, -0.2797, -1.2417,\n",
       "           1.0181,  0.3614, -1.0894, -0.1212,  1.2405, -1.0801,  0.6757,  0.2530,\n",
       "          -0.5473,  0.9449,  0.7158,  1.2561, -0.8617, -1.7201, -0.3350, -0.7128,\n",
       "           0.7267,  1.9832, -0.3444, -0.3404,  0.8297, -1.5407, -1.1225,  1.6014,\n",
       "          -1.1368, -1.4648])),\n",
       " 'contacto': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contadur√≠a': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contemplaba': (tensor([-0.7498, -0.3022,  1.5273,  0.2122,  2.3742, -2.1268,  0.9539, -0.7794,\n",
       "          -1.5039,  0.4818, -1.2685, -0.1003,  0.3728, -0.1190, -0.6710, -1.6887,\n",
       "          -0.9735,  0.3240,  0.3052, -1.7532,  1.9617,  1.2701, -0.6238, -1.9689,\n",
       "           1.1399, -0.8633, -1.6483, -1.2869,  1.5877, -0.3506,  1.9374,  1.9770,\n",
       "          -0.5386,  0.1633,  0.8764, -0.1039, -1.1622, -0.3727, -1.0629, -0.6196,\n",
       "          -0.5939,  1.6468, -0.3010,  0.4727, -0.8759, -1.1755, -1.1870,  0.5163,\n",
       "          -0.5712, -0.5246]),\n",
       "  tensor([-3.3307e-01, -2.2849e-01,  1.2817e+00,  1.2351e-01, -1.2204e+00,\n",
       "          -5.5302e-01, -3.9779e-01, -4.0738e-01, -1.7371e-01,  1.1339e+00,\n",
       "           6.5577e-01,  1.2195e+00,  2.6105e-01,  5.8718e-01,  6.0153e-02,\n",
       "           1.6013e+00,  2.4745e+00,  1.4294e+00,  5.3038e-01,  2.2795e+00,\n",
       "          -2.5232e+00,  1.1256e+00, -6.3977e-01,  1.0305e+00, -2.6983e-01,\n",
       "          -6.0669e-01, -9.2211e-01, -8.0392e-02,  1.1996e+00, -4.5702e-01,\n",
       "           1.0188e-01,  1.6668e+00,  4.4615e-01,  1.0943e+00, -8.3914e-01,\n",
       "          -1.1977e+00, -2.4095e-01, -1.8945e-01, -1.1604e+00, -1.1676e+00,\n",
       "          -1.2258e+00,  6.0204e-01, -4.4075e-01, -5.2288e-01, -6.7186e-04,\n",
       "          -1.4978e+00, -3.6502e-01, -1.4126e-02,  8.7576e-01, -5.6928e-01])),\n",
       " 'contenido': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conteo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contestaron': (tensor([-0.0530, -0.0126, -1.3636,  1.0451, -0.1283, -1.8369,  0.7887,  0.7842,\n",
       "           0.0151,  0.1334,  1.0266,  3.9846,  1.2499, -0.6260,  0.8003, -1.9025,\n",
       "           0.2314, -1.4399,  0.6294, -0.4026, -0.5117, -0.1075, -0.5560,  0.3236,\n",
       "          -1.5873,  0.4359,  0.9252,  0.1538,  1.8568,  0.2182, -1.3824,  1.0485,\n",
       "           0.9233,  0.9993,  0.5339, -0.9281,  0.8480,  0.4794, -1.7852,  2.4016,\n",
       "          -1.0658, -1.4925, -0.3127, -1.0377,  0.8874,  0.3619, -0.9427, -0.4873,\n",
       "          -0.3089,  1.3129]),\n",
       "  tensor([ 0.9823, -1.1230,  0.3461, -0.4624, -0.8168, -2.2071,  0.4270, -0.2880,\n",
       "           1.3786, -0.1910,  1.3922, -0.5573,  0.0803,  0.0622,  1.2800, -1.0074,\n",
       "          -0.2568, -1.9685, -0.5060,  1.9065, -0.5120, -0.8145,  1.6231,  1.0419,\n",
       "          -0.1477,  1.4343, -0.9413,  0.5035,  1.1385, -1.9162, -0.2427,  0.1246,\n",
       "           1.1449, -0.1423,  2.3264, -0.3135, -0.9549, -0.2693,  1.7580,  0.0622,\n",
       "          -0.4984, -1.2152,  1.1676, -1.4032, -0.1753,  0.7514,  0.9855, -0.1174,\n",
       "           1.6019, -1.0176])),\n",
       " 'contextos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'continuaban': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'continuaci√≥n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'continuado': (tensor([-1.7993, -0.1438,  0.0867,  1.2291, -0.8223, -0.4704,  0.2954, -1.0242,\n",
       "          -0.0407, -0.0339,  0.0144,  0.7388,  0.5989,  0.9708, -0.3626, -0.0189,\n",
       "           0.4943,  0.4295,  0.6922,  0.5406,  0.4553, -0.8504, -0.4376, -1.2887,\n",
       "          -0.0317,  0.0581, -0.5067,  0.5781, -0.0409, -1.3732,  1.6216,  1.0013,\n",
       "           0.0266,  1.5517,  0.0222, -1.0729,  0.1852, -1.2948, -1.4481, -1.3107,\n",
       "          -1.1506,  0.2266, -1.1398, -0.4526,  0.9481, -0.7931, -1.0663, -0.8392,\n",
       "           2.1286,  0.5296]),\n",
       "  tensor([ 1.2838e-01,  1.3270e-03, -2.1486e+00,  1.6168e+00,  8.7507e-01,\n",
       "          -1.0514e+00, -2.9405e-01, -2.2638e-01,  4.4158e-01,  2.1729e-01,\n",
       "          -1.2043e+00, -2.0513e+00, -8.5882e-01, -3.6299e-01,  8.6025e-01,\n",
       "           6.1952e-02, -1.7736e+00, -1.7460e+00,  1.9041e+00, -4.7972e-01,\n",
       "           3.0925e-01, -1.8019e+00, -5.2882e-01,  1.5673e+00,  1.7125e+00,\n",
       "          -1.0465e+00, -1.2209e+00, -4.7297e-01, -8.7765e-01, -1.3643e+00,\n",
       "           1.5835e-01, -3.9493e-01, -4.6656e-01, -9.2557e-01, -4.2222e-01,\n",
       "          -5.4792e-01, -5.7404e-01, -2.6601e-01, -1.4837e+00, -1.1549e-01,\n",
       "          -6.2033e-01, -9.4886e-01,  5.5806e-01,  2.2047e-01, -3.4206e-01,\n",
       "          -6.4604e-01,  3.8118e-01, -1.4441e+00,  1.0126e+00, -2.1107e+00])),\n",
       " 'continuar': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'continuaran': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'continuaremos': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'continuar√°n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contin√∫a': tensor(3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contin√∫e': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contin√∫en': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contra': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'contradicciones': (tensor([-1.4851, -0.9092, -0.5928,  0.0830,  0.3943, -0.3080,  0.5667,  0.7283,\n",
       "          -1.1902, -0.8231, -0.5142,  1.9225,  1.8265,  0.2428, -0.7120, -0.3530,\n",
       "           0.2924, -1.0391,  1.5095,  1.1099,  1.1794, -0.1718, -1.5440,  1.4711,\n",
       "           0.4489,  0.1565, -0.8773, -2.4297, -0.9953, -1.1942,  0.6127,  1.8095,\n",
       "          -1.2381,  0.3176, -1.6513, -0.6449, -0.1277,  0.4380,  2.0728,  0.1907,\n",
       "          -2.5902,  0.2619, -0.5831,  0.4388, -0.3236, -0.3144,  2.3283,  1.0103,\n",
       "           0.2186, -0.5378]),\n",
       "  tensor([-0.4474,  0.3769,  0.1700,  1.2395, -0.9879,  0.2382,  1.8411,  1.0957,\n",
       "           0.0066,  0.0216, -0.8264,  0.2598,  1.5212,  1.2970, -0.3536, -0.2501,\n",
       "          -0.6763,  0.3509, -0.2136, -1.5647, -1.2382, -1.7372,  1.7631,  0.7548,\n",
       "           1.2082,  0.2612,  0.5440, -0.3210, -0.1693,  1.1208,  0.2658,  0.7636,\n",
       "           0.5659, -1.2178,  0.7166, -0.4917, -0.6352, -0.3185,  0.6665, -0.5542,\n",
       "          -0.3019,  0.7110, -0.0434,  0.0383,  2.2444,  0.0391, -1.1990,  1.4566,\n",
       "           1.4139,  0.3310])),\n",
       " 'contrario': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'control': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'controlado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'convencidos': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'convenci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conveniente': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'conversaciones': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cooperaci√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'coordinaci√≥n': (tensor([ 0.6665, -0.8350, -0.6340, -0.8921,  0.7304, -0.3699, -0.7417, -0.3329,\n",
       "           1.5790,  1.0389, -1.2728,  2.0830,  0.6692,  0.9859, -1.6385,  0.3168,\n",
       "          -0.0786, -1.2826,  0.4330, -1.1985, -0.1809,  0.3230,  0.6427, -1.4257,\n",
       "           0.5942,  0.0673,  0.9432,  0.0384, -1.7039,  1.3091, -0.1656,  1.8754,\n",
       "           0.6549,  0.4924, -1.4419,  0.0067,  0.9538,  0.7829,  0.5952,  0.4576,\n",
       "          -0.7017, -0.3538,  0.8405, -0.0495,  0.3430,  0.8965, -0.2381, -0.2832,\n",
       "          -0.7819, -0.0616]),\n",
       "  tensor([-2.0406, -1.4871, -1.5472,  1.3727, -0.1693, -0.0807, -0.1491, -0.2236,\n",
       "           0.8350,  0.8552,  1.0751, -0.4583, -2.2716,  0.6643, -1.5885, -0.4666,\n",
       "          -0.4432,  0.7965,  1.1949,  1.2579,  0.4024, -0.1081,  1.5250, -1.1651,\n",
       "          -1.8106, -0.1186,  0.6175, -0.7604, -0.1666,  0.6702,  0.3300,  1.3421,\n",
       "           0.3427,  0.1837, -0.1816,  0.6137, -0.9598, -0.2606, -0.7495,  1.1582,\n",
       "           0.9694,  0.1266, -0.4570,  1.7347, -0.6952,  0.7365,  0.9457, -1.1165,\n",
       "          -0.0888, -0.9777])),\n",
       " 'copa': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'copia': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'copiar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'copias': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cordinar': (tensor([-0.8516,  0.6609, -1.0871,  0.1459, -0.3929,  0.1994, -1.0084,  1.6643,\n",
       "          -0.6870,  1.6555,  0.0392,  0.3806, -0.5650, -1.5257, -1.9501,  1.5258,\n",
       "          -0.1183,  0.4001, -0.6940, -0.2327,  0.1457,  0.8387,  0.7686,  0.0653,\n",
       "           0.2769,  0.3888, -0.8305, -0.2082, -0.8786,  0.6513,  1.1303, -1.8048,\n",
       "           0.6021,  0.2572, -1.0508, -0.6407, -0.2138, -0.1052,  0.7575,  1.0677,\n",
       "           0.2984, -1.2722, -0.3277,  0.1850, -0.0461, -1.4450, -0.3000,  1.5992,\n",
       "           1.6936, -0.4933]),\n",
       "  tensor([-0.1334,  0.1515,  1.2600,  0.8122, -0.1127,  0.3180, -0.6055, -0.6493,\n",
       "           0.2216, -0.0927,  1.5387, -1.4394,  0.7328,  1.4543, -0.3549,  1.1029,\n",
       "           2.3387, -0.9507, -0.2402,  0.7280,  0.1634, -0.1209, -0.2306,  1.2083,\n",
       "           1.8702,  0.1060,  0.3635,  2.0561, -0.8986, -0.9452, -0.4601,  0.7995,\n",
       "          -0.6266, -0.8467,  0.8567, -0.3882, -0.6568, -0.6826, -1.2666, -0.2355,\n",
       "          -0.2422, -0.6190, -1.8926, -0.0113, -1.0924, -0.6803, -1.4330,  2.3652,\n",
       "           0.1195, -0.4655])),\n",
       " 'correa': tensor(2.9802e-08, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'correcta': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'correctas': (tensor([-1.0110, -1.2055, -0.8646,  0.8460,  1.5055, -0.8179,  2.8661,  0.1412,\n",
       "           1.7061,  1.7422,  0.2926, -1.2532,  0.5690,  0.4372, -0.0566,  1.3916,\n",
       "           0.0082,  2.5492, -0.5027, -0.6777, -0.4334, -1.0059,  0.2124,  1.0348,\n",
       "          -0.0346,  1.4538,  1.1038, -1.1015,  0.7890,  0.9501,  0.4335, -3.3898,\n",
       "          -0.8167,  0.0360, -0.3908,  1.2748,  0.3849,  0.5305, -0.6389,  1.9981,\n",
       "           0.6371,  0.0873, -0.1253,  0.2312, -0.0750,  1.6262,  0.4119,  0.9769,\n",
       "           1.4723, -0.3191]),\n",
       "  tensor([ 0.4550,  1.9624, -1.1398,  0.6379, -2.1687, -1.2059, -0.9505,  0.6974,\n",
       "           1.5088, -1.1653,  0.4662, -0.9227,  0.3767, -0.4873,  0.0116, -1.2505,\n",
       "           0.5949, -0.2394,  0.6334, -0.7658, -0.2205,  0.0504,  0.2174,  3.6867,\n",
       "          -2.4102,  1.1950, -0.9151, -0.5328, -0.2730,  0.3303,  0.1491, -1.1304,\n",
       "           2.0223, -0.8571, -0.9121, -0.0072, -1.9546,  0.8687,  0.3081,  0.9776,\n",
       "          -0.3344, -0.8331, -0.8300,  0.4087,  0.2403,  0.6488,  0.3821, -0.1970,\n",
       "          -0.6401, -0.3478])),\n",
       " 'correcto': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'corregirse': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'correr': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'correspondientes': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'correspond√≠a': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'corro': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'corros': (tensor([ 0.8835, -0.9012, -0.5258, -0.1260, -0.4436, -1.6747, -1.0689,  0.2165,\n",
       "           0.5623, -1.4092,  0.0178, -1.9604, -0.4914, -0.2145,  1.5129,  0.8126,\n",
       "          -0.6794,  0.0903, -1.4215,  1.0622, -1.1628, -0.4050, -0.4128, -0.4394,\n",
       "          -1.3324, -1.2776,  0.5893, -0.7118,  1.7908, -1.7838, -0.4335,  0.4256,\n",
       "           0.1257, -0.5343, -0.0864,  1.7356, -2.8569,  0.5249, -0.4477,  0.0812,\n",
       "          -1.0056, -1.6577, -1.7523,  1.2406, -1.3558,  0.7396,  0.8713, -2.5940,\n",
       "          -0.1904, -0.4671]),\n",
       "  tensor([ 0.0730,  0.0447,  0.0939, -0.4281, -0.7399,  0.6432,  0.2369, -1.6227,\n",
       "           0.0317, -0.7034,  0.5021,  0.0290, -0.7784,  0.4499,  1.0478, -0.8029,\n",
       "           0.3367,  0.0022,  0.1682, -1.0838,  1.5216,  0.0749, -1.2631, -0.1724,\n",
       "          -0.5667,  0.4818,  2.0611, -1.1222, -0.1444,  1.1482,  1.3851, -1.5562,\n",
       "          -0.4376,  0.0828,  0.6585, -0.2163,  0.5727,  0.2606, -0.4060, -0.3324,\n",
       "          -0.2011, -1.0691, -0.5937, -1.7708, -0.8333,  1.6648,  0.3408, -0.6727,\n",
       "           1.1847, -0.0026])),\n",
       " 'corrupci√≥n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cortar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'corte': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cortes': (tensor([ 1.6063,  0.7059,  1.4764,  0.0525, -1.0988,  1.6072,  0.3370,  0.1969,\n",
       "           0.8292, -0.1354,  0.9102,  1.0659, -0.5291,  0.7595, -0.3087, -0.6078,\n",
       "          -0.9665,  0.0464,  0.2256,  0.5540, -0.7350, -0.6005, -0.2273, -0.0112,\n",
       "           1.5663, -0.3142,  0.7180, -0.4869, -0.0193, -0.3915,  1.9687,  1.6889,\n",
       "          -0.1348, -0.3266,  1.4891, -0.6504, -1.7435,  0.1085, -0.0386,  0.7685,\n",
       "          -1.6433, -0.8099,  0.7563,  2.1056, -0.9815,  0.7345,  0.0383, -0.9783,\n",
       "           1.4694, -0.6496]),\n",
       "  tensor([-0.1908, -0.5008, -1.0696,  0.4166,  0.0348,  1.6416,  2.0988,  1.1585,\n",
       "           0.7432, -0.9124,  0.7129,  1.4085, -0.8297, -0.7717, -0.2261,  0.0040,\n",
       "          -0.1161, -1.0426, -0.9769, -0.1409,  1.0916, -0.8105, -0.5442,  0.0631,\n",
       "           1.5699,  0.8368,  1.6235, -1.2721, -1.0451,  0.6367, -0.3466, -0.6189,\n",
       "          -0.8562,  1.6496, -0.9836, -1.7019,  0.1044,  0.0804, -0.7439,  0.0137,\n",
       "           1.1281, -0.1397,  0.4013,  0.2279,  0.1440, -0.1970,  0.1013, -0.5771,\n",
       "          -0.4060, -0.9017])),\n",
       " 'corto': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cosa': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cosas': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'costa': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'costo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'costosas': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cotizaci√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cotiz√≥': (tensor([ 8.8331e-01, -7.2211e-01, -1.2698e+00,  4.0961e-01,  7.9674e-01,\n",
       "          -9.2493e-01,  2.3776e-02,  3.2802e-01,  1.0271e+00, -2.0724e+00,\n",
       "          -1.0814e+00,  7.6203e-01,  1.0820e+00,  9.1641e-01,  1.0347e+00,\n",
       "           2.1719e-04,  8.9019e-01, -5.6332e-01,  1.3548e+00,  3.8837e-01,\n",
       "           1.4340e+00, -3.7712e-01,  6.3887e-02,  1.5116e+00,  1.5459e+00,\n",
       "          -8.8586e-01,  9.9706e-01, -1.1270e+00,  9.4071e-01,  1.7102e+00,\n",
       "           1.1366e+00,  2.2329e+00, -9.2550e-02, -8.9234e-01,  5.3432e-01,\n",
       "          -2.0087e-01, -1.6551e+00, -3.9659e-01, -2.1490e-01,  7.8145e-01,\n",
       "          -1.5246e+00,  6.7221e-01,  7.2341e-01,  5.9717e-01, -1.5780e+00,\n",
       "           2.1385e+00,  7.3458e-01,  1.3974e-01,  6.3810e-01, -1.1002e+00]),\n",
       "  tensor([ 0.0517,  0.1066, -0.3538,  0.4461,  0.6092, -0.5987,  0.6897, -0.6377,\n",
       "          -0.5742, -0.5765,  1.1363,  0.2773, -0.1459, -1.2095, -0.8077, -0.9759,\n",
       "           0.2416,  0.3795,  0.6985,  0.6567,  1.1044, -0.7273,  0.7783, -0.4049,\n",
       "           0.5741,  0.1355,  0.1583,  0.0227, -0.8831,  0.9074, -0.3273, -0.0918,\n",
       "          -0.9587,  0.3938, -0.3801,  0.1806,  0.2899,  0.2939, -1.5400, -1.5227,\n",
       "           0.6758, -1.1211, -0.1855, -1.3560,  1.0487, -0.0726, -0.8114,  2.9203,\n",
       "          -0.3079, -1.1690])),\n",
       " 'creado': (tensor([ 0.4183,  0.8800, -1.0023,  0.9147,  0.4306, -0.6868,  0.4770, -1.0125,\n",
       "          -0.4336,  0.3905, -0.8245, -0.8913,  0.4046, -1.0698,  0.5834, -0.1969,\n",
       "          -0.0896, -1.8476,  0.1627,  1.4917,  0.4086, -1.4061,  1.3013, -0.3424,\n",
       "           2.0684,  0.5211, -0.0916,  1.2095,  1.4808, -0.3934, -0.3338, -0.3313,\n",
       "          -0.2199,  2.3189,  0.2642,  0.1447,  2.0746, -0.9523,  1.8084, -0.7696,\n",
       "           1.1942,  1.3405, -0.2815,  0.1188,  0.7527, -0.5089,  0.9888, -1.0289,\n",
       "           0.5636,  1.2623]),\n",
       "  tensor([ 2.0336,  1.7425,  0.4804,  2.5221,  0.2581, -0.1416,  1.5528, -1.3266,\n",
       "           0.2257, -1.1869, -0.7996,  0.5566, -0.6529, -0.5413,  0.3049, -0.3969,\n",
       "          -1.0761,  0.7957,  1.9818,  0.0383,  0.6852,  3.1415, -0.7298,  0.2284,\n",
       "          -1.8301, -0.3789, -1.5758,  1.2758, -0.5797,  0.0054, -0.5667,  0.4766,\n",
       "           1.4907,  0.8054, -0.4166, -1.3200,  0.0656,  0.1838,  0.3920,  0.2840,\n",
       "           0.4413, -0.8746, -1.4519, -0.7339, -2.5676,  0.8164,  1.8312, -1.4203,\n",
       "           1.1959, -0.1945])),\n",
       " 'crean': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'creciente': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'crecimiento': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cree': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'creen': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'creo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cre√≠amos': (tensor([ 0.1649, -1.1665,  0.2506, -0.2862, -2.1133,  0.3024,  1.1562,  0.0843,\n",
       "          -1.0387, -0.1635,  0.5793, -0.1370, -0.5957,  1.7154, -0.1206, -0.5955,\n",
       "           1.3161,  0.0400, -0.1388,  0.2682,  0.7667, -0.1791, -0.1591,  0.3430,\n",
       "          -1.2682, -0.0272,  0.2405, -0.0389, -0.1918, -1.6596,  1.2544,  0.0979,\n",
       "           1.4129,  0.7408, -0.1517, -1.3649, -0.2184,  0.3987,  1.2897,  0.2568,\n",
       "          -0.4842,  1.5749,  0.6581, -2.2248, -2.8013, -1.3926, -0.5928, -0.1189,\n",
       "          -0.1684, -0.8648]),\n",
       "  tensor([ 1.0863, -2.8686,  0.0457,  2.4077, -0.1497, -0.4681,  0.2914, -0.8458,\n",
       "           0.5911,  0.6198, -0.3562, -0.6897,  0.3293, -0.4831, -0.3896, -0.7720,\n",
       "           1.1860, -0.4702, -0.0894,  0.1177,  0.4399, -0.7351, -0.5760,  0.5247,\n",
       "          -0.3066,  1.2201, -1.5318, -0.5342, -0.2816, -0.7732,  0.8065, -1.9020,\n",
       "           1.1435,  2.1810, -1.2410, -1.1979,  1.1741,  1.2383,  0.3198, -0.7720,\n",
       "          -0.0633, -2.0291, -0.3915, -0.2495, -0.3803, -1.7972,  0.5244, -0.6014,\n",
       "           2.0852,  0.6148])),\n",
       " 'cre√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'crisis': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cristal': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'criterios': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'critica': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'criticar√°': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'crucial': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'crudo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cruzada': (tensor([-0.1412,  0.2204, -0.2636, -0.4879,  0.3917,  0.1836,  1.0063, -1.0543,\n",
       "          -0.3183,  1.0390,  0.7155, -2.0324, -1.3500,  0.6467, -1.1691,  1.0072,\n",
       "          -1.3798,  0.6648, -2.2448,  0.5641,  0.4616, -0.3119,  0.3572, -0.6679,\n",
       "          -0.5956,  0.7595, -1.3113, -0.0091,  0.6935, -1.8978,  1.0844,  0.7021,\n",
       "          -0.3584, -0.6962, -0.1690, -0.8797, -0.2112, -2.1413,  0.1785, -0.2125,\n",
       "          -1.3384,  0.5913,  0.5365,  0.9295,  0.4207, -0.5656, -0.1214,  0.0427,\n",
       "           1.2257,  0.6080]),\n",
       "  tensor([ 0.0974, -1.3855,  0.8572,  0.0817, -0.4790, -1.3576, -0.2611,  0.7818,\n",
       "          -0.3172,  1.8643,  1.2453, -1.5304,  0.0529,  0.3583, -0.6235,  0.0384,\n",
       "           1.4580,  0.8282,  0.3796, -0.2787, -1.0789, -0.3935,  0.4981, -0.6110,\n",
       "          -0.6343,  1.3739, -1.6600,  1.1521,  1.3441, -0.4349, -0.8903, -0.8546,\n",
       "           0.2462, -0.3281, -0.8736,  0.7155, -0.0652, -0.1660,  0.5070, -0.0530,\n",
       "           0.4326,  0.3571, -1.5863,  0.8577,  0.8420,  0.3723,  0.5574,  0.9355,\n",
       "           1.5180,  0.3066])),\n",
       " 'cr√©dito': (tensor([ 0.7639,  0.0578, -1.1989,  1.0055, -1.8907,  0.3740,  1.5814,  1.4492,\n",
       "          -1.0971,  0.3631, -1.7845, -1.6145, -0.5471,  0.7170,  0.7888, -1.9542,\n",
       "          -0.4111, -0.9105,  0.3282,  0.6580, -1.2987,  0.7690, -1.1408, -1.1256,\n",
       "           1.0121,  0.5386,  0.7476, -0.3579, -0.9330,  1.0891,  0.3322, -1.2291,\n",
       "           1.4628, -1.8502, -1.6809, -0.0058,  0.1188,  0.2516, -0.2156, -1.5649,\n",
       "          -2.3557,  1.2471, -0.5761, -1.5645, -0.2487,  0.2703, -0.4539,  1.0808,\n",
       "          -0.2200, -0.5537]),\n",
       "  tensor([ 0.1406,  0.5287, -0.1100, -0.3692, -0.7052,  0.9616, -2.1380, -1.3425,\n",
       "           0.4507,  0.6395,  1.8834, -0.6521,  0.1898, -0.1671,  0.2951, -2.1996,\n",
       "           0.3169, -1.1168,  1.5392, -0.3100,  0.3731,  1.4686, -0.3871, -0.3176,\n",
       "          -1.3514, -0.1167, -2.6649,  0.1679,  1.3895, -1.7252,  2.0433,  0.5979,\n",
       "           0.8456,  0.0221, -0.1852,  0.4598,  0.0931, -0.6871, -1.9832,  0.9505,\n",
       "          -0.6617, -0.3176, -1.7167,  0.0980,  0.0205, -1.8753,  1.0219,  0.3724,\n",
       "           0.8047, -0.3219])),\n",
       " 'cr√≠ticas': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cr√≠ticos': (tensor([-1.3971,  0.9352,  1.0696,  0.7977, -0.8870, -0.4922,  0.8056,  0.1393,\n",
       "           0.9185,  0.5009, -1.5270, -0.0237, -0.6545, -1.3089,  0.2922,  1.2542,\n",
       "           1.8619, -0.3296,  0.1323,  0.8825, -0.5199, -1.0187, -2.1373, -0.4678,\n",
       "           0.3925, -0.8278, -0.9503,  0.0972, -0.8303,  0.7923, -0.8118, -0.1964,\n",
       "          -0.2753, -1.1314, -0.7538, -1.4803, -2.1822, -0.7664, -1.3398,  0.5421,\n",
       "          -0.2524, -1.0663, -0.4712,  0.4524,  0.4939, -0.1906,  0.8711,  0.5205,\n",
       "           1.2371,  0.5768]),\n",
       "  tensor([ 0.5597,  0.2123, -0.3542, -0.3388,  0.2747, -0.1980, -0.3944, -0.4906,\n",
       "           2.5045, -1.2142, -0.7640, -2.2453,  0.4093, -0.7009, -0.1700,  1.8464,\n",
       "          -0.8516, -0.2835, -0.9138, -0.6022,  0.3372, -0.0669, -0.6486,  0.5158,\n",
       "          -0.3238,  1.1174,  1.3982, -1.0262, -0.4810, -1.1616, -0.0339,  1.5212,\n",
       "          -1.9555,  1.0937,  0.9159,  0.4950, -0.4535,  1.4619, -0.9177,  2.3538,\n",
       "           0.6403, -2.0375, -0.0872, -0.7043,  1.0335, -0.4192, -0.9036, -1.4085,\n",
       "           0.1171, -0.1200])),\n",
       " 'cuadro': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuadros': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cual': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cualquier': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuando': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuanto': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuantos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuarenta': (tensor([ 1.6877, -0.9226,  0.5959,  0.7029,  0.8495,  0.5441,  0.3717, -0.5633,\n",
       "          -1.2094, -0.7790, -0.2243,  0.9409, -0.2504, -0.9228, -1.0907, -1.0315,\n",
       "          -0.7138,  1.3608,  1.4127,  2.0207, -0.3865, -0.3737, -1.0455, -0.1049,\n",
       "           1.6106,  2.7943,  1.2331,  0.6943, -0.8557, -0.2702, -0.5420, -0.1940,\n",
       "           0.1016, -0.0567,  1.1273,  1.0111,  0.3068,  2.5853,  0.4757,  1.0919,\n",
       "          -1.4810,  0.7170, -0.3920, -0.4671,  0.7425, -0.3278,  0.4381, -0.9585,\n",
       "           0.2201, -0.7768]),\n",
       "  tensor([-1.5698,  0.0366, -0.3828, -0.4907, -0.6201, -0.4151,  0.0106,  0.8700,\n",
       "          -0.7281,  0.8129, -1.6603, -0.2521, -0.9539,  0.5348,  1.0539, -0.6105,\n",
       "           0.2018,  0.5017, -1.4170, -0.4518,  1.5482, -0.5269,  1.2751, -1.4889,\n",
       "           0.6466, -1.3948, -0.8017,  1.3710, -1.7645, -0.4060, -1.1671,  1.1663,\n",
       "           1.2161, -1.4339,  1.3853,  0.8956,  0.6947, -0.1269,  1.0184,  0.8199,\n",
       "          -0.2307,  0.7485, -0.4937, -1.0217,  0.4361,  1.0182, -0.7364,  1.2903,\n",
       "           1.4783, -0.2757])),\n",
       " 'cuarta': (tensor([ 0.6027,  0.2591, -0.2656,  0.6852,  0.0733,  0.1780,  1.1358,  2.3854,\n",
       "          -0.0563,  1.7426, -0.6767,  0.3477,  1.7901, -0.3605, -0.3580,  0.4568,\n",
       "           1.6001,  0.0031,  0.8290, -1.0980,  1.1580, -0.5180, -0.7680, -1.4789,\n",
       "           0.9018,  0.2673, -0.9692,  1.2000,  2.6224, -0.0824,  0.8101, -0.2230,\n",
       "          -0.5067, -1.2255,  0.1800, -0.7439,  1.2125, -0.2077,  0.3222, -0.3106,\n",
       "          -0.6976, -0.5735,  1.1429, -0.3191, -0.3756,  0.2473,  0.4597,  0.4949,\n",
       "           1.2218, -1.3623]),\n",
       "  tensor([ 1.3754e+00, -1.4990e+00,  7.2504e-01,  1.0720e+00,  1.6805e+00,\n",
       "          -7.8856e-01,  4.4657e-01, -7.6517e-01,  2.4835e-01, -2.1520e-01,\n",
       "          -1.7886e-02, -9.4717e-02, -7.8129e-01, -9.4362e-02,  7.9480e-01,\n",
       "           8.1264e-01,  1.2467e+00,  1.5892e-01, -8.5096e-01, -1.9618e+00,\n",
       "          -6.7653e-01, -1.3511e+00,  7.6441e-01, -2.7243e-01, -5.8729e-01,\n",
       "           1.7013e+00,  1.1678e-01, -2.6798e-01, -4.0239e-01,  4.8016e-02,\n",
       "          -7.0825e-01, -4.5899e-01, -5.2175e-01,  7.2247e-02, -5.9786e-01,\n",
       "          -1.2685e+00,  3.8579e-01,  2.9350e-03, -2.9760e+00, -3.7207e-01,\n",
       "           1.1738e-01,  1.0429e-01,  6.4575e-02,  3.2040e-01,  1.1284e+00,\n",
       "           5.1838e-01,  6.8821e-01,  1.6729e-01,  6.0926e-01,  2.6737e-01])),\n",
       " 'cuatro': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuba': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cubierta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuenta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuentas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuesta': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuestionario': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuestiones': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuesti√≥n': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuidadosamente': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuidadosos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cuidan': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'culpable': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'culpables': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cultura': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cumplen': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cumplimiento': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cumplir': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cumplir√°n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'curso': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cursos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cu√°l': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cu√°les': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cu√°ndo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'cu√°nta': (tensor([ 0.7364, -0.8794,  1.4000,  1.4635, -0.0137, -0.4165, -0.0551,  0.6358,\n",
       "          -1.0095, -0.2841, -0.3206,  0.0707,  0.9039,  0.5144, -1.4417,  1.4560,\n",
       "           0.9165,  0.1774, -1.7336,  0.8630, -1.9990,  1.3220, -0.8455, -0.4147,\n",
       "           1.2369, -1.7482,  0.8104, -0.8085, -0.3171,  0.1638, -0.4656,  0.4198,\n",
       "           0.0532,  1.0439,  0.9970, -0.4627, -0.4676, -0.1586, -0.0179, -0.2248,\n",
       "          -0.3814, -0.2495,  0.1901,  1.3912,  1.6409,  0.6309, -0.6560,  0.0644,\n",
       "          -0.5222,  0.6287]),\n",
       "  tensor([-1.2568, -1.6343,  1.6376,  1.5531, -0.5044,  0.9886,  0.7590,  0.5126,\n",
       "          -1.4113, -0.8542, -0.3984, -1.4088, -1.5377, -1.2261,  0.5653,  0.1990,\n",
       "           0.5650,  1.0518,  0.4858,  0.9936, -1.6207, -0.0650,  0.8531, -0.7125,\n",
       "           2.1667,  0.5054, -1.7404,  0.2545,  1.1008,  0.6742,  0.7463, -0.0335,\n",
       "          -0.1653,  0.5258, -0.0712,  2.2629,  0.0668,  2.6470, -1.1525, -0.1036,\n",
       "          -0.4418,  0.2268,  2.3507,  0.8335,  0.4353, -0.0428, -0.7081,  0.7150,\n",
       "          -1.1822,  0.5834])),\n",
       " 'c√°mara': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'c√©sar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'c√≥lera': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'c√≥mo': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'daba': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dadi': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dado': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dan': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dar': tensor(3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'da√±ados': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'da√±os': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'de': tensor(-5.8301e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debajo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debamos': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debate': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debatir': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debati√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debe': tensor(4.4703e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debemos': tensor(-3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deben': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deber': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deber√°': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deber√≠a': tensor(2.9802e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deber√≠an': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debido': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debieran': (tensor([ 0.3239, -1.9653, -0.4574,  1.0151, -0.7112, -1.0887,  0.2584,  0.4568,\n",
       "          -1.9340,  1.2517, -1.0965,  0.3444,  0.2707,  1.3783, -0.4056, -0.2270,\n",
       "           1.2270, -0.2342, -0.2473, -0.7561,  1.0405,  0.8030, -0.3155,  0.3462,\n",
       "           0.1597,  0.2091, -0.0764,  0.3825,  0.3958, -1.2492,  0.2177,  0.9156,\n",
       "           0.7860, -0.6081, -0.6283, -0.9944,  0.5516,  0.9298, -1.1803, -1.8651,\n",
       "          -0.0032, -1.0253,  0.7662, -1.5899, -0.1558,  0.3765, -0.2452,  0.8683,\n",
       "          -0.4006,  0.6937]),\n",
       "  tensor([ 0.5224,  1.2574,  0.9826,  0.7047, -0.6602, -0.7347,  0.9480,  0.1100,\n",
       "          -0.4702, -0.6171,  1.3451, -0.2558, -0.7120, -1.1863, -0.7050,  1.3947,\n",
       "           0.1633,  1.8501,  1.3589,  0.0334, -1.5335,  0.5532,  1.2075, -0.0734,\n",
       "           0.7114, -1.3346,  0.8715,  0.1423,  0.8216,  0.6445, -1.4503,  1.4394,\n",
       "          -0.5356,  1.5317,  0.3666, -0.5373, -0.6473, -0.7535,  0.6610, -0.6865,\n",
       "           0.5900, -0.9156,  1.2643,  0.8386, -0.1010, -1.9895,  0.6490,  1.2934,\n",
       "           2.7002,  0.7260])),\n",
       " 'debi√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'debo': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deb√≠an': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decenal': (tensor([-0.4967, -0.1267,  0.5516, -0.0465,  1.4118,  0.9313,  0.0451,  1.2503,\n",
       "           2.0040,  1.1477,  1.9005,  0.6312,  0.6259, -1.3116, -0.6269, -0.8686,\n",
       "           0.7692,  0.7557, -1.2580,  1.6202, -0.5275,  0.6785, -0.1911,  0.8234,\n",
       "          -0.3342,  1.2796, -0.5189, -0.2832,  1.8889,  0.6963, -0.8274,  0.0302,\n",
       "           0.4300, -0.9328,  0.7968,  0.1851,  1.0052,  1.4643, -1.0714,  0.5541,\n",
       "          -0.3228, -0.6449,  1.1000,  0.8856,  0.0120,  0.9984,  0.3515,  1.2469,\n",
       "          -0.6595, -0.2456]),\n",
       "  tensor([ 5.7341e-01, -1.2871e-01,  5.2594e-01, -5.8712e-01,  1.1444e+00,\n",
       "           7.1956e-01,  1.3463e+00, -1.3319e+00,  3.1509e-02,  1.0421e+00,\n",
       "           4.8126e-01,  1.2537e+00,  7.0841e-01,  1.4575e+00, -5.3292e-01,\n",
       "          -5.9812e-01,  2.2328e-01,  3.6553e-03, -1.2175e+00, -4.8543e-01,\n",
       "          -4.4334e-01, -8.6558e-01,  1.5854e+00,  1.9696e-02,  9.8457e-01,\n",
       "          -9.9580e-01, -1.4353e+00, -9.6532e-01,  5.6844e-01, -1.2014e+00,\n",
       "           1.4159e-01, -1.9820e-01,  4.3115e-01, -7.7558e-01, -9.0471e-01,\n",
       "           7.0266e-01,  1.4461e+00, -1.9606e+00,  3.3586e-01,  1.2253e+00,\n",
       "          -1.0779e+00, -8.6754e-01, -3.7710e-01, -2.1574e-01,  4.0429e+00,\n",
       "           1.1800e+00, -8.3935e-01, -1.8698e-01, -6.1044e-01, -7.2315e-01])),\n",
       " 'decepcionar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decida': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decide': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decidir': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decidir√°': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decidi√≥': tensor(-3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decir': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decisiones': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'decisi√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'declara': tensor(-4.1723e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'declaraciones': tensor(-5.9605e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'declaraci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'declar√≥': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'declin√≥': (tensor([ 8.1424e-01, -5.0190e-02,  7.9186e-01,  1.3544e+00,  1.0030e+00,\n",
       "           5.2809e-01, -1.5807e-01, -1.1230e+00, -1.5705e+00, -9.0687e-01,\n",
       "           8.4891e-01, -7.2668e-01, -4.6989e-01, -2.6952e-02,  2.6361e-02,\n",
       "          -1.4479e+00,  1.1233e+00, -2.4335e-04,  1.0611e-01,  1.9319e-01,\n",
       "          -1.1413e+00,  4.3776e-01, -6.0432e-01, -7.3302e-01,  4.6800e-01,\n",
       "           1.5771e+00,  1.1438e+00, -7.7269e-01,  1.8904e-01, -2.6560e-01,\n",
       "           5.4726e-01,  4.1978e-01, -2.1708e+00,  1.0355e+00,  1.0996e+00,\n",
       "           6.4246e-01,  7.8488e-01,  4.0166e-01,  1.0478e+00, -4.7407e-01,\n",
       "          -1.1805e+00,  1.0507e+00,  1.5649e+00,  1.5367e-01,  9.2747e-01,\n",
       "          -4.7493e-02, -1.4397e+00,  3.4285e-01,  4.5783e-01, -2.8194e-01]),\n",
       "  tensor([ 1.6861, -0.3004,  2.2533,  0.9819,  0.5340, -0.7710,  0.5243,  0.5961,\n",
       "          -0.8444, -0.6525, -0.5384,  1.5007, -0.7230, -0.8569,  1.5467,  0.1268,\n",
       "          -1.4898,  0.0448,  0.3020, -0.4827,  1.0781, -0.4678, -1.1332,  1.5018,\n",
       "           1.6507,  0.1896,  1.5010,  0.6680,  1.3828, -0.4642,  0.1202,  1.3560,\n",
       "           0.1050,  1.0409,  0.3091, -1.7104, -0.1770, -0.6875,  1.2043,  0.4336,\n",
       "          -0.6770, -0.2822, -0.5728,  1.0807, -0.9145,  0.5801,  0.4469,  0.9598,\n",
       "           1.8475, -0.1188])),\n",
       " 'decreto': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'defenderemos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'defenderse': (tensor([-0.1856, -0.1484,  1.2021,  1.6633, -1.5682, -1.2546,  0.8574, -0.6041,\n",
       "          -1.3375, -2.0070,  1.1839,  2.6606,  0.8330,  1.4120,  0.1862, -1.8110,\n",
       "          -0.0189,  0.3533,  0.3893,  0.1663, -0.0058, -1.2289, -0.6182,  0.5811,\n",
       "           0.5602,  0.1610,  0.5229,  0.8360,  1.1825, -1.1924,  0.2758,  0.8381,\n",
       "           0.7583, -0.0171,  0.0619, -1.7139, -2.8476, -0.4401,  0.1510,  0.8149,\n",
       "          -1.1486, -0.1379, -0.1164,  1.5522, -0.1435, -0.3506,  1.1681, -0.5734,\n",
       "          -1.8399, -0.7418]),\n",
       "  tensor([ 0.1099,  0.7642,  0.8525,  0.1331,  0.7119,  0.5680,  0.2983,  2.5310,\n",
       "          -1.2537,  0.4143, -0.0667, -0.3319,  0.5631,  0.3038,  3.3049,  0.4140,\n",
       "           0.6853,  0.3771, -0.1143,  2.6211,  1.4133, -1.5598,  0.7754, -0.9188,\n",
       "          -2.1356,  1.8644,  0.4847,  1.2980, -0.0924,  0.6893, -0.1251, -0.3941,\n",
       "           0.9244,  0.3144,  0.0468,  1.6734,  0.0805,  1.5527,  1.9675, -0.8284,\n",
       "          -0.7450,  1.8212,  0.5215, -0.2309, -1.0977,  1.3793,  0.1308,  2.2033,\n",
       "           0.8196,  0.0500])),\n",
       " 'defendi√≥': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'defensa': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'definiciones': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'definici√≥n': (tensor([-0.5474, -0.3274, -2.6249,  0.5390, -1.0381,  1.1218, -0.2462,  1.0073,\n",
       "          -2.1954, -0.2850,  0.3540,  1.0452,  1.0593, -0.1241,  1.5514, -0.2584,\n",
       "           0.2418,  2.0281, -1.0761,  0.4274, -0.6560, -0.2058,  0.8230, -0.2175,\n",
       "          -1.9829,  0.5734,  0.7291,  0.4013,  2.7064, -0.7625, -0.6328,  0.0653,\n",
       "           0.4433,  1.4876,  0.5128,  0.6841, -0.5562, -0.2420, -1.3654,  0.3360,\n",
       "           0.4856, -1.3112,  1.6152, -1.1161, -0.1759, -0.0260,  0.8165,  0.9781,\n",
       "           0.4960,  0.1436]),\n",
       "  tensor([-4.6838e-01,  4.9776e-01,  4.0853e-01,  4.8753e-01,  3.1922e-02,\n",
       "          -1.1270e+00,  1.0190e+00, -1.3528e+00, -1.6207e+00, -1.1165e+00,\n",
       "          -5.0756e-01, -1.4915e+00,  1.2185e+00, -2.0220e+00,  1.6057e+00,\n",
       "          -3.6127e-01, -1.2280e-01, -8.8856e-01, -1.7797e+00,  5.2789e-01,\n",
       "           9.5091e-01, -2.8893e+00,  1.1283e+00, -1.1309e+00, -2.4905e+00,\n",
       "           2.3719e-04,  2.2261e+00, -6.2571e-01, -1.8249e-01,  7.4944e-01,\n",
       "          -1.8892e+00, -4.8508e-01, -6.5352e-01,  8.5174e-01,  7.1346e-01,\n",
       "          -1.0230e+00, -2.2987e+00,  1.4333e-01,  4.7391e-01,  2.3137e-01,\n",
       "          -6.3490e-01, -1.6683e+00,  9.2713e-01,  8.7084e-01, -1.0749e+00,\n",
       "           7.1488e-01,  9.7933e-01, -7.1850e-01, -3.0444e-01,  2.0968e-02])),\n",
       " 'definitivamente': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'definitoria': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'defraudar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'degeneren': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dejaba': (tensor([-1.0744, -1.2058, -0.1325,  0.8028,  1.0000,  0.2863, -1.7564, -0.3945,\n",
       "          -0.4868,  1.1629, -0.9785,  1.1348, -1.4783, -0.8887,  1.1107,  0.7665,\n",
       "          -1.2776,  0.7023,  0.5942,  1.3933,  0.6754, -1.2530,  0.5344, -0.2806,\n",
       "           2.0833,  0.0627, -1.7824, -1.8270,  0.5224, -1.0970,  0.7049,  0.4805,\n",
       "           0.4804, -0.0796,  1.3443,  1.7109, -1.4024, -0.2577,  0.6382, -0.9733,\n",
       "           1.8364,  0.6193,  0.4430,  1.0046, -1.8986,  0.8183, -0.3700,  0.4077,\n",
       "          -0.3649, -0.8368]),\n",
       "  tensor([-1.5398,  1.5808,  0.9631,  0.7156, -0.6875,  0.7568,  2.0730,  0.5637,\n",
       "          -1.6416, -0.7604,  0.4941,  0.9756,  0.2483, -0.0084, -0.0219,  2.5729,\n",
       "           0.5259, -0.6201, -0.0801, -1.2724, -0.3755, -1.1480,  0.5221,  0.1880,\n",
       "          -1.3671, -0.8682,  1.6333,  0.3521,  0.0636, -0.2883, -0.8433, -0.3320,\n",
       "          -0.0530,  0.2532, -1.3226, -0.3675,  0.2673,  0.8282, -1.0334,  1.1473,\n",
       "          -0.6610, -1.3762,  1.3017, -0.4627, -1.4365, -1.2864,  0.1964,  3.4509,\n",
       "          -1.4969, -0.9769])),\n",
       " 'dejar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dejar√°': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dej√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'del': tensor(-3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'delegaciones': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'delegaci√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'delegados': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'demanda': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'demandado': (tensor([-0.9584, -0.1213,  0.7326, -1.2751,  1.0259,  1.4720,  0.5663, -0.5063,\n",
       "          -0.4999,  0.6360, -1.6033,  0.2184,  1.0907,  0.1091,  0.1702,  1.9139,\n",
       "           1.6410, -0.5397,  0.7724, -0.2526,  0.5065,  0.4762,  3.0030, -0.1853,\n",
       "          -0.0144,  0.6055,  1.2278, -0.0512,  0.1128,  1.0495,  0.2638,  0.5782,\n",
       "          -2.3374, -0.1050,  0.6766, -0.4502,  0.7191, -0.1225,  0.1491, -1.7797,\n",
       "          -0.7205, -2.0951, -0.6307,  1.4150,  1.9688, -1.5531, -0.3995, -0.3199,\n",
       "          -0.5254,  3.2806]),\n",
       "  tensor([-1.7315, -1.7432, -0.3461, -0.1436, -1.7714,  0.3594,  0.5746,  0.4934,\n",
       "          -0.2571,  0.7585,  0.8316,  0.2185,  0.9532,  0.1132, -1.0942,  1.0272,\n",
       "           0.4801, -0.3514,  1.1570, -0.0728,  0.0443,  0.0308, -0.9415,  0.7365,\n",
       "           0.3852,  1.7643,  0.6172, -1.6416, -1.6424, -0.3422,  0.3357,  0.9078,\n",
       "           1.7250,  1.4492,  0.7538, -0.6519,  0.2861, -0.4381, -0.1315, -0.4577,\n",
       "           0.5030, -1.2050,  2.2037, -0.2414, -0.8087,  1.6355, -0.1981,  0.4406,\n",
       "           0.6160, -0.5889])),\n",
       " 'demandante': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'demasiado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'democracia': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'democr√°ticamente': (tensor([ 0.1470, -1.2997,  2.0957,  0.2419,  1.4325,  0.7449,  0.1389, -0.3767,\n",
       "           0.4302, -0.6810, -0.3004, -0.5673, -0.8710,  0.2479,  0.6222,  1.4687,\n",
       "          -0.6374, -1.1946,  1.5084,  1.7720,  0.8852,  1.1499,  0.0999,  0.9865,\n",
       "          -0.0970, -0.1530,  0.1988,  1.1499, -1.0977, -1.1791,  1.0031,  1.7085,\n",
       "           0.1161, -0.0872,  1.1440, -1.1010, -1.0456, -0.8306, -0.5923, -0.0861,\n",
       "          -0.4889, -3.0303,  1.1675, -1.6150, -0.2221,  0.2872, -0.4668, -1.0018,\n",
       "          -0.5106,  0.3128]),\n",
       "  tensor([ 1.8843,  0.6465,  0.2193, -0.9101,  0.0601, -0.5873,  0.3785,  0.1982,\n",
       "           1.0623,  0.0257,  0.6923, -1.2211, -1.5992, -1.1120, -0.5530,  0.9657,\n",
       "           0.2416, -0.5691,  1.5151, -1.0242,  1.4896, -0.8822, -2.4901, -1.4110,\n",
       "          -1.2129, -0.5660,  1.4376, -0.0041,  0.7311, -0.1865, -1.7581,  0.7843,\n",
       "           1.1451, -0.5797, -1.6647,  1.8585,  0.5051, -0.8117, -0.9410,  0.1124,\n",
       "          -0.4621, -2.0199, -1.7456,  1.5837,  0.3328, -0.3566, -0.2987,  0.2339,\n",
       "           0.7680, -1.3851])),\n",
       " 'demora': tensor(3.5763e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dem√°s': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'denunciarlo': (tensor([-6.6278e-01,  4.3255e-01, -1.4212e+00,  2.9894e-01, -1.1335e+00,\n",
       "           9.2780e-01,  9.8508e-01,  4.6358e-01,  1.0527e+00, -3.1926e-01,\n",
       "           2.0152e-01, -9.7386e-02,  5.8679e-01, -1.7619e+00, -1.0695e+00,\n",
       "          -6.5136e-01, -3.7654e-01,  4.8905e-01, -5.7113e-01, -8.6788e-02,\n",
       "          -9.0398e-01,  1.0219e+00,  1.9343e-01, -1.1333e+00,  7.8930e-01,\n",
       "           2.2109e+00, -3.8395e-01,  1.0538e+00,  9.0852e-01, -2.5164e-01,\n",
       "           1.4943e+00,  5.5299e-02, -4.1494e-01,  3.4836e-01, -1.5356e+00,\n",
       "          -8.7686e-01, -5.2338e-01,  1.9631e-01, -1.4477e+00,  1.5025e+00,\n",
       "          -1.0198e+00,  2.1654e-03,  3.6883e-01, -4.1524e-01,  4.0205e-01,\n",
       "           9.2067e-02, -7.9300e-01, -3.8428e-01, -4.1109e-02, -3.9114e-01]),\n",
       "  tensor([ 0.8372,  0.2695, -0.4642, -0.3080,  0.4357, -0.6842, -0.3600, -0.2930,\n",
       "           0.7383,  2.0566,  0.6449, -0.7880, -0.8909, -0.6045,  0.5168,  0.3157,\n",
       "           0.3551,  0.0251,  0.5352,  1.2429, -1.3917,  0.7053,  0.2672, -1.1178,\n",
       "          -0.9244, -0.0170, -0.9380, -0.0275, -0.8480,  0.0713,  0.8633,  0.4131,\n",
       "           0.8215, -2.1655,  0.1530, -0.2684, -0.5165,  0.5635,  0.5734, -1.0506,\n",
       "          -0.2434, -1.6065,  0.1401, -0.4712, -0.3732, -0.4725, -0.2671, -0.5211,\n",
       "           0.5814,  0.7005])),\n",
       " 'departamento': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'departamentos': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'depende': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deportiva': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deprimido': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dep√≥sitos': (tensor([-0.2524, -0.2628,  0.4340,  0.3902, -0.4544,  0.2133,  1.6638, -0.1503,\n",
       "           0.0091, -0.2962, -0.3336, -0.2240, -0.7432,  0.5763,  0.7785,  0.7581,\n",
       "           0.7920,  0.5649,  0.0098, -0.3615, -0.6279,  1.0464, -0.7917, -0.9032,\n",
       "           0.4056,  1.7621,  2.4709,  0.4332,  0.4244,  0.7393,  0.1250, -0.6700,\n",
       "          -0.4116, -0.9825,  0.6056, -1.0847, -1.0291, -0.1641,  1.0503, -0.9322,\n",
       "          -0.8913,  0.0770,  0.7313, -0.6845,  1.0895, -0.9186,  0.8635, -0.0387,\n",
       "          -0.1053,  0.2174]),\n",
       "  tensor([ 0.3614, -0.7765,  0.1238, -2.4365, -0.3718, -0.7968,  0.4363,  0.8832,\n",
       "           1.6451, -1.1827,  1.2033,  1.4309,  0.8781, -1.2066, -1.0131,  0.0694,\n",
       "          -0.6753,  0.0246, -0.5689, -0.1157, -1.0824, -0.9920,  0.5242,  0.5246,\n",
       "           0.3592, -0.8006, -0.6294, -0.3155, -0.4640,  0.3940,  0.1946, -0.2221,\n",
       "          -1.6572,  0.2283, -0.0923, -0.6148, -0.3246,  0.3382, -0.2111, -0.6966,\n",
       "           0.1686,  0.5466, -0.9172, -0.9402,  0.5242,  0.6138, -0.0495, -0.6316,\n",
       "           1.3189,  0.2723])),\n",
       " 'derecha': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'derecho': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'derechos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'derrame': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'derrocamiento': (tensor([-1.5063,  1.2783, -0.1335,  1.4203,  0.1605, -2.1935, -0.8428, -0.1386,\n",
       "          -0.0331, -0.2546, -1.3419, -1.4287,  1.6657,  0.0683, -0.4271, -0.8724,\n",
       "           0.3479,  1.3734,  0.5917,  1.6368, -0.4558, -1.7641,  0.5183,  0.2367,\n",
       "           1.2833,  1.0633, -1.4150, -0.7092,  0.5654,  0.6187, -2.0646, -0.5880,\n",
       "           0.9880, -0.6679,  0.1255, -0.3454,  0.6402, -1.3200, -1.4260,  0.2324,\n",
       "           0.2713,  0.6998, -0.0437,  1.5397,  0.2053,  0.5173,  1.4870, -0.2729,\n",
       "           1.8153,  1.2770]),\n",
       "  tensor([ 0.4850,  0.5383, -0.3374,  0.1310, -0.6267, -0.7892, -0.3228, -0.6009,\n",
       "           0.0495,  0.2137,  0.1116,  0.3584, -1.8158, -1.0602, -0.0895, -1.0175,\n",
       "           1.0663, -0.7048,  0.3080, -2.4172, -0.2242,  0.9685,  1.7551, -2.0504,\n",
       "          -1.1062,  0.6965, -2.2267,  0.3598, -0.1447, -0.5243,  0.5482,  1.2142,\n",
       "           1.9111, -0.1107, -0.0248,  0.3258, -1.3368, -0.2225, -0.6771,  1.2233,\n",
       "          -0.0976,  1.1986, -0.2295,  0.9710,  0.5273, -0.7727, -1.3461,  1.4169,\n",
       "           0.3771, -1.4471])),\n",
       " 'desacuerdo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desalentadora': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desarmados': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desarmar': (tensor([-0.2476, -0.5166,  1.4893,  0.6403, -0.5401, -0.5428,  0.0107,  2.6587,\n",
       "           0.7214, -1.1989, -0.7960, -0.1713, -0.6188,  0.0660, -1.0483, -0.4671,\n",
       "           0.5890,  0.4041, -1.3532, -0.5706,  1.0184, -0.9045, -1.3638, -0.8323,\n",
       "           0.1914,  0.2555,  0.7020, -0.7997, -0.3185,  3.0174, -0.4775,  0.3840,\n",
       "          -0.7657, -1.4348,  0.3143,  0.9218, -0.8275,  2.2820, -0.2937, -0.9187,\n",
       "           1.8424, -0.8245, -1.4898, -1.0503, -0.6119, -0.5055, -0.4487,  0.3276,\n",
       "           0.6973, -0.4662]),\n",
       "  tensor([ 0.8035,  0.5191, -1.1901, -0.4560,  0.1263,  1.1649,  0.3974,  0.2527,\n",
       "          -0.4041, -0.1544,  1.7832, -0.5270,  0.2061,  0.7018,  0.4045, -0.1487,\n",
       "           0.8674, -0.0735,  1.0004, -0.1018,  0.0926,  2.4619, -0.5166,  1.0199,\n",
       "           0.0314, -1.1515,  0.3275, -0.9426, -0.5144, -0.5881, -1.0676, -0.1861,\n",
       "          -0.4523, -0.2622,  2.4529,  2.3558,  0.3271, -1.0149,  0.9826, -0.8084,\n",
       "          -0.6680, -0.8505,  1.8025,  0.1564,  0.4669,  0.3643,  0.3996, -0.6921,\n",
       "           1.0136,  1.2086])),\n",
       " 'desarrollando': (tensor([-1.2324,  1.1402,  0.2304, -1.3393,  1.0256, -0.4161, -0.8441,  3.1904,\n",
       "          -0.7890, -2.0876, -1.4196, -1.3499,  0.3627,  0.8355, -0.9385,  0.4136,\n",
       "          -0.1795, -0.8724,  2.3816,  0.1150, -0.9532,  1.4719, -0.4940,  1.2332,\n",
       "          -0.5299, -0.7338,  0.4088,  0.1861, -0.4604,  0.7998, -0.8628,  0.6036,\n",
       "           1.7352,  0.7473, -0.0993,  0.2975, -0.4187, -0.5818,  1.9570,  1.4203,\n",
       "           0.6588, -0.1729,  1.1994, -1.1979,  2.2558, -1.3686, -0.7487, -2.1629,\n",
       "          -0.4631,  0.4300]),\n",
       "  tensor([ 0.1007,  0.4493,  0.6389,  0.3822, -0.1585,  0.2614, -1.0713,  1.0069,\n",
       "           0.2541, -1.3392, -1.2244,  0.1594,  0.6641, -0.2884,  0.1375, -1.2368,\n",
       "          -1.7263, -1.0097, -0.0068, -0.0492, -0.1136,  1.6635,  1.1433,  0.6557,\n",
       "          -1.6242, -0.6759,  0.3094,  0.8516,  0.3649,  1.3318,  0.0281, -0.7498,\n",
       "          -0.3790, -0.5231, -0.4224, -1.4126, -0.4156,  0.2836,  1.2114,  1.8672,\n",
       "           1.6787,  1.0822, -0.6864, -1.0978, -0.6083, -1.2542, -0.7677,  0.1414,\n",
       "          -1.3144, -1.7106])),\n",
       " 'desarrollar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desarrollo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'descarrilar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'descartado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'descartar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desconoce': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'describen': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'describir': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'describi√≥': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'describ√≠a': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'descubrir': (tensor([ 0.8189, -0.8171,  0.9286, -0.1266, -0.2643,  0.3130,  1.6739,  0.3937,\n",
       "           0.8953, -0.7645,  0.6807,  1.9283,  0.0145, -0.1280, -0.8098, -0.4731,\n",
       "           0.4679, -0.1696, -0.2125,  0.2386, -0.7242,  1.4151, -0.0212, -0.0973,\n",
       "          -0.6201, -0.5917, -1.1323,  0.6277, -1.2392,  0.4864, -0.0830,  0.3933,\n",
       "          -2.0091,  0.8268,  0.1054,  0.8334,  1.5832,  1.0022,  0.8410, -0.1798,\n",
       "          -1.7096, -0.2929, -1.2942,  0.9985,  0.5118, -0.8190,  0.7340,  0.3804,\n",
       "           1.8525,  0.3184]),\n",
       "  tensor([-1.3971, -0.2989, -0.6752, -0.9090,  0.9672,  0.3969, -0.8678, -0.1061,\n",
       "          -1.1686, -0.5263,  1.5344, -0.3019,  0.3040, -0.3988,  0.4402, -0.1479,\n",
       "          -0.4904,  1.3095, -0.6278, -0.9945, -0.1725,  0.1207,  1.2454, -0.1042,\n",
       "           0.4445,  0.2049, -0.4814, -0.2239,  1.0524,  0.3809, -0.3146, -1.4726,\n",
       "          -1.1068, -1.3942, -1.6620,  0.4184,  0.1047, -0.3000,  0.1151,  0.1684,\n",
       "           0.0075,  1.1835, -1.0084, -0.7689,  0.1025,  1.1820,  2.0362, -0.0805,\n",
       "          -1.4379, -1.1166])),\n",
       " 'desde': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desea': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desempe√±a': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deseo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desfigurada': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desgarramiento': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desglosarse': (tensor([ 2.1369, -0.5354,  1.0349,  1.1517, -1.6731, -0.0545, -1.0608, -0.1963,\n",
       "          -0.8387, -0.5697, -1.5251,  0.0520,  1.1199,  1.0555, -0.6801, -1.8337,\n",
       "          -0.2124, -0.0942, -0.8211,  0.8563, -1.5124, -1.7528,  0.3498, -2.7073,\n",
       "           0.7796,  0.9652,  1.2965,  0.4182,  0.2050, -1.1735,  0.7855,  0.8335,\n",
       "           0.3712, -0.4354, -0.0156,  0.6246, -1.4971,  0.1946, -0.0760, -0.9618,\n",
       "           2.0226,  0.1904,  0.6744, -1.4796,  0.4687, -0.4173,  0.8752,  0.2228,\n",
       "          -0.7725,  0.2427]),\n",
       "  tensor([ 0.1369, -0.2262,  0.7102, -0.2906,  0.3583,  1.9776, -0.2905, -0.2155,\n",
       "          -0.5816,  0.9114,  1.6400, -0.0261, -1.5275, -0.4554, -0.3995,  0.2159,\n",
       "           0.7948,  2.4578, -0.3966, -0.6575,  0.4051,  0.4798,  0.7479,  1.0148,\n",
       "          -0.3494, -2.8245,  0.2295, -0.5067,  0.4131,  0.5578,  0.2206, -0.2891,\n",
       "          -1.5011, -0.4605, -1.7278,  2.2140, -1.1083,  1.2024,  1.1305,  0.7677,\n",
       "          -0.0193,  0.5550, -1.3421, -0.4648, -1.3681,  0.6406,  0.0644,  0.2019,\n",
       "           0.7609, -0.2994])),\n",
       " 'desgraciadamente': (tensor([-0.4008,  0.1168,  0.1257, -1.0169,  1.0318, -1.5499, -1.4905, -0.9340,\n",
       "          -0.1744, -0.9061, -0.8820, -1.0407,  0.3243, -0.3635,  0.4978,  1.2421,\n",
       "          -0.0418, -0.0737, -0.9107,  1.4932,  1.2322, -1.9722,  0.5728,  1.2073,\n",
       "          -0.1539,  0.2747, -0.4390,  0.7399, -2.6008,  1.8627,  0.2238, -1.1338,\n",
       "          -3.4657,  1.8389,  0.3468, -0.0404, -0.6703,  0.9637,  0.7691, -0.2342,\n",
       "          -0.0739, -0.9819,  0.5553, -0.2931,  1.1586, -0.7831, -0.4032, -0.3532,\n",
       "           1.1545, -1.9608]),\n",
       "  tensor([-2.2118, -1.6796, -0.3394,  0.3817,  1.3152,  0.1055, -0.8573, -0.8754,\n",
       "           0.9370,  1.2833,  0.0083,  0.2292,  1.4581,  0.1928, -1.0590, -1.5771,\n",
       "           0.6601,  1.1507,  0.1225, -0.4675, -0.8221, -0.1425, -1.8227,  1.1531,\n",
       "           1.4011,  0.2135,  0.2418, -1.0209, -1.8470,  1.0788, -0.1672,  1.1324,\n",
       "           1.4191,  1.3727, -2.1692,  0.5641,  1.5973, -2.5560, -0.8690, -0.9337,\n",
       "          -0.6085, -0.5138,  0.3326, -0.3030, -1.1180,  1.9181, -0.1152, -0.0696,\n",
       "           1.3824,  0.2077])),\n",
       " 'designar': (tensor([-0.2937, -0.1030, -0.2605, -1.0229, -1.6734, -1.5602,  0.2288,  0.3270,\n",
       "           0.6787, -0.6635,  0.5387,  0.5032,  1.0357, -0.4872, -1.0168, -0.5009,\n",
       "           0.6236,  0.7126,  0.7855,  2.1020, -0.2015,  0.3235,  1.7137,  0.5534,\n",
       "          -0.0982,  1.0873, -1.9963,  0.8641, -0.7617,  1.1475, -0.4309,  1.9958,\n",
       "           0.1464, -0.5250,  0.6294,  0.3104,  0.7265, -1.0263,  1.5338, -0.9279,\n",
       "           1.4640, -0.3242, -0.9390,  0.5500, -1.2118, -1.0670,  0.7234, -0.8788,\n",
       "           0.8573, -0.6951]),\n",
       "  tensor([ 0.5583,  1.4046,  0.0075,  0.0255, -1.5576,  0.0760,  0.3477, -0.5142,\n",
       "          -0.8538, -1.7285,  0.8030, -0.2119, -0.0076,  1.1381,  1.4065,  0.2308,\n",
       "           0.2846, -1.2696,  0.6389, -0.0199,  0.5006, -0.2716,  0.2969, -1.3874,\n",
       "          -0.1329,  0.1384,  1.7027,  0.3906, -1.8370, -0.0943, -0.6688,  0.3964,\n",
       "           0.6702, -0.7943,  0.1581,  1.7565,  0.0206,  1.6275, -0.5326, -1.3858,\n",
       "          -0.5960,  1.4763,  0.5706,  0.9360,  0.5205, -0.8509, -0.4768,  0.4614,\n",
       "           1.1856, -0.3149])),\n",
       " 'desmantelar': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'desparici√≥n': (tensor([ 0.3672, -0.1393, -0.5157, -0.6487,  1.3473, -1.1249,  0.1613, -1.2261,\n",
       "          -0.8666,  1.0147,  0.5180, -0.5692,  0.9500, -0.3580,  0.7861, -0.1061,\n",
       "           0.8479, -1.0244,  0.6923, -1.9264, -1.1938, -0.9956, -0.9957, -0.7207,\n",
       "           0.0356,  0.6222, -1.0177,  1.3173,  0.2366,  0.6660,  0.3366, -0.6935,\n",
       "           0.5128,  1.1596, -0.6995, -0.5849, -0.7266,  0.7023, -0.7882, -0.5267,\n",
       "           0.3026, -0.4068,  0.9816,  0.9345, -0.6367, -0.7695, -0.8393,  0.0571,\n",
       "          -1.2225,  0.5636]),\n",
       "  tensor([-6.2138e-02,  1.4577e+00,  1.2644e+00,  2.4530e-02, -1.1989e+00,\n",
       "          -1.9429e+00, -2.5550e-01,  7.8992e-01,  2.0759e+00, -8.1131e-01,\n",
       "           1.6788e+00, -3.1070e-01, -6.9477e-01,  1.2751e+00, -2.2851e+00,\n",
       "          -6.7364e-01, -1.8168e-02,  9.2504e-01,  9.6976e-01,  1.7705e+00,\n",
       "           1.2821e+00,  1.2949e+00, -4.8316e-01,  8.8885e-01,  1.5561e-01,\n",
       "           2.0158e+00, -1.4436e-01,  1.5704e+00, -9.8621e-02, -4.7202e-01,\n",
       "           4.7141e-01,  3.0419e-01,  4.2869e-02, -6.0363e-01,  1.1475e+00,\n",
       "           6.8138e-01,  1.1207e+00, -5.6509e-01,  1.3892e-01,  2.0774e+00,\n",
       "           8.7494e-02,  8.0900e-01, -5.3288e-01,  8.3494e-01, -4.0947e-02,\n",
       "          -9.6857e-01,  2.5705e-01,  1.1761e+00, -2.5371e-01, -2.1065e-03])),\n",
       " 'desplazar√°n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'despojado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'despu√©s': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'destac√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'destino': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'destru√≠dos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'des√©e': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'detalle': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'detalles': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'detenciones': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'detenido': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'determinaci√≥n': (tensor([ 0.6804, -0.3296, -1.1548,  0.6858, -2.5472, -2.1370, -1.8140,  0.2151,\n",
       "           0.8759,  1.1131,  0.0064, -1.6879, -1.3047, -2.1652,  1.6139, -1.8447,\n",
       "           1.0714, -0.2586,  0.0939,  0.4526,  0.8879, -0.9239, -0.0173,  0.3831,\n",
       "           1.3099,  1.2761, -0.9435,  1.0428, -0.8399, -2.5052, -0.7806, -0.9419,\n",
       "           1.6972, -1.2683, -0.0968, -0.1983,  1.2533, -0.5011,  1.2528, -0.5117,\n",
       "           0.7589, -1.5155, -1.1528, -0.2564, -1.1175,  0.3796, -1.4165,  2.4273,\n",
       "          -0.0202, -1.7600]),\n",
       "  tensor([ 1.0233,  1.4444, -0.8367, -1.6963, -0.9765,  0.4023, -0.1513, -1.0933,\n",
       "           1.5401, -1.0957, -0.4242,  1.4990,  1.9820, -0.8020, -0.5161, -0.2569,\n",
       "          -1.8203, -0.8701, -0.0682,  0.6285, -1.3863,  0.6514, -0.8705,  0.7467,\n",
       "           1.1022,  0.0316,  0.7574,  0.6089, -1.3010, -2.4967, -0.9095,  0.2409,\n",
       "          -2.7221, -0.2482,  0.8402, -0.7464, -1.1242, -0.7171,  0.5691, -0.1765,\n",
       "          -0.2614,  0.7562,  1.1646, -1.7452, -0.1502,  0.4093,  1.9271, -0.8974,\n",
       "          -0.3174, -0.0429])),\n",
       " 'determinado': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'determinan': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'determinarse': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'determinar√°': (tensor([ 0.1479,  0.2098, -0.8491,  0.3488, -1.1927,  0.5875, -0.9569, -1.7041,\n",
       "          -0.5571, -0.6925, -0.8194,  1.1865, -0.0944,  0.1336, -0.8060,  0.2750,\n",
       "           1.4069, -0.5537, -0.2170, -0.0176, -0.5756, -0.1101, -1.6700,  0.3763,\n",
       "          -0.0470,  0.4232,  1.0937,  1.9092, -1.2900,  0.0844,  0.8656, -0.2504,\n",
       "          -1.8717,  0.8803,  0.8209, -0.2788,  0.9160,  0.0882, -1.7307, -1.3115,\n",
       "          -1.3116, -0.8573,  1.5061, -0.5335,  1.3041, -1.8700, -1.4557, -2.1361,\n",
       "          -0.6140,  0.8416]),\n",
       "  tensor([-0.7008, -0.4235, -0.2540,  0.4138,  1.6109, -0.8971, -0.3714, -0.3220,\n",
       "           1.2937,  0.8505,  0.2720, -0.4039,  0.0298,  0.4775, -0.9689,  1.4297,\n",
       "          -0.2114,  0.0164,  0.5947, -0.7627,  1.9424, -0.7099,  0.5964, -0.0344,\n",
       "          -0.9179,  0.5138, -0.6727, -0.6265,  0.5610,  1.4174,  1.4845,  0.8036,\n",
       "          -0.0713, -0.0523,  0.0785, -0.0152, -1.2992,  1.4798,  0.3799,  0.2175,\n",
       "           1.5226, -1.7187,  0.8513,  0.4330,  0.9328, -0.7827, -0.5242,  0.9177,\n",
       "           0.1393,  0.6287])),\n",
       " 'detrimento': tensor(9.5367e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'detuvo': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'deuda': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diario': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diarrea': (tensor([-1.3897,  1.5406, -0.5434,  1.2210, -0.2384, -1.4497, -0.7945,  0.0846,\n",
       "          -1.9978, -0.4537,  0.7823, -0.2017, -0.9146,  0.4218, -2.0964,  0.6503,\n",
       "           0.3231,  0.5146,  1.2741, -0.1000, -0.5735, -0.2675,  0.9189, -1.3974,\n",
       "          -0.1276,  0.9370,  2.1001,  1.0828,  0.4415,  0.6692,  0.0682, -1.2775,\n",
       "          -0.7737,  2.0090, -0.1578, -1.6711,  0.0619,  0.2817, -0.1038,  0.9766,\n",
       "          -0.8211, -1.0038,  2.9315, -0.8607, -0.4378, -1.0863, -1.4269,  0.9988,\n",
       "          -0.3856,  0.2263]),\n",
       "  tensor([ 0.1606,  0.3918,  0.7020,  1.0228,  0.5268, -0.0134, -0.0885, -0.3353,\n",
       "          -0.6081,  1.7483,  1.7245, -0.8955, -1.1941, -0.2228, -0.7308, -0.2753,\n",
       "          -0.2478, -0.4740, -0.4002,  0.2373, -0.6242,  1.1315, -0.3599,  0.8512,\n",
       "           0.4972,  0.4467, -1.6456,  1.5252, -0.0230,  0.3273,  0.2187,  0.8068,\n",
       "          -0.4182,  1.2765,  0.2361, -0.0768, -0.3274, -0.9802,  0.2466,  0.7037,\n",
       "          -0.0330,  1.2032, -0.7247, -0.2753, -0.4681,  0.5105,  0.4554, -1.6576,\n",
       "           0.1172, -0.5656])),\n",
       " 'dice': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dicen': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dichas': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dicho': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dichos': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diecis√©is': (tensor([ 1.7956e+00, -5.9413e-01, -8.9610e-02, -1.5958e+00,  1.1873e+00,\n",
       "          -4.1833e-01, -7.4071e-01, -2.9162e-02,  2.3438e+00,  1.0178e+00,\n",
       "          -4.0248e-02,  3.8190e-01, -6.4443e-01,  1.0091e+00, -2.7913e-01,\n",
       "          -4.4006e-01,  1.4174e+00,  6.5450e-01, -6.6207e-01, -5.0204e-02,\n",
       "           2.3875e-01,  7.5246e-01, -8.1445e-01,  9.0959e-01, -1.1292e+00,\n",
       "           2.1856e+00,  1.5608e-01,  1.4380e+00,  2.0266e-01, -1.1003e+00,\n",
       "          -5.1875e-01,  1.4192e-02,  1.2169e+00,  2.3595e-01,  5.8886e-01,\n",
       "           8.8218e-01,  9.5080e-01, -2.9993e-02,  2.2746e-01, -1.2837e-01,\n",
       "          -2.1604e-01,  1.1572e+00, -1.5962e-03,  8.3287e-01,  4.6319e-01,\n",
       "          -1.1951e+00,  1.4100e-01, -7.9969e-01, -1.2293e+00, -5.6558e-01]),\n",
       "  tensor([ 0.9256, -0.5951, -1.5362,  1.1721, -1.1198, -0.4286, -0.2266, -2.3991,\n",
       "           0.1738,  0.6228,  0.8031,  1.1564, -0.7649, -2.0811,  0.8007,  0.7633,\n",
       "          -2.2517,  0.9643,  0.4803, -0.8168, -1.3346,  0.4024,  0.4764, -0.5878,\n",
       "          -0.0060,  1.0925,  0.2815,  0.6841,  0.1457,  0.1423, -0.0969, -0.3347,\n",
       "          -0.1931,  2.6073, -0.9847,  1.1262,  0.6800,  0.3208,  0.5510, -0.7613,\n",
       "          -1.3422, -0.6889,  3.2126, -0.0339,  1.7359,  0.1390,  0.6885, -0.5953,\n",
       "           0.9494, -0.1616])),\n",
       " 'diez': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diezmada': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diferencias': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diferentes': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diferido': (tensor([ 0.1529, -0.1655,  1.8675, -0.2836, -0.7585,  0.8580, -3.0104,  0.6902,\n",
       "          -1.3123,  0.8894,  0.7093,  0.9492, -1.2912, -0.3738,  1.4869,  1.8129,\n",
       "           1.0052,  0.6250,  1.0257, -0.2765, -0.0683, -0.8876,  0.1389, -0.0696,\n",
       "           0.1132,  0.0795, -0.6022, -1.3425,  1.9222, -0.5176,  0.7281, -2.2553,\n",
       "          -1.2199, -1.0264, -0.8291,  0.1456, -0.3589, -0.9950, -0.1068,  0.2824,\n",
       "          -0.7730,  0.3747,  0.4593, -1.2200,  1.8919, -1.3934,  0.6558, -1.1283,\n",
       "           0.3701, -0.6375]),\n",
       "  tensor([ 0.5937,  0.2704,  1.7687, -1.7892, -1.2666,  1.4905,  1.2934, -0.3595,\n",
       "          -0.2172, -1.0809,  1.3932, -0.6008,  0.8397, -0.9018, -0.4590, -0.4745,\n",
       "           0.6146, -1.3127,  0.3442,  1.4066, -0.1635, -1.1810, -2.0536,  0.1270,\n",
       "           1.3434, -0.1976, -0.7024,  1.1173, -0.1198, -0.5678, -0.3240, -0.8476,\n",
       "          -0.0351,  0.2423,  1.1577,  0.2095,  0.3724,  1.7935,  0.1128, -0.5315,\n",
       "          -0.1780, -0.0952, -1.4435,  0.3768, -1.5693, -0.0637,  0.7853, -1.2918,\n",
       "          -0.5514, -2.9020])),\n",
       " 'dificultades': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dif√≠cil': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dif√≠ciles': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dije': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dijeron': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dijo': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dinero': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dio': tensor(5.9605e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dios': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diplom√°tica': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diplom√°tico': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diplom√°ticos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diputado': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'direcci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'director': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'directorio': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'directrices': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dirige': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dirigentes': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dirigi√≥': (tensor([ 5.3164e-01, -3.2162e-01,  3.1172e-01,  5.2516e-01,  1.5768e+00,\n",
       "           9.4547e-01, -6.6028e-01,  3.5304e-01,  1.6876e-01, -1.2959e+00,\n",
       "          -9.2573e-01, -5.6224e-02,  7.1362e-01, -2.8572e-01,  8.3735e-01,\n",
       "          -2.0581e+00,  4.1616e-01, -1.8193e+00, -7.9971e-01,  1.5512e+00,\n",
       "          -1.2293e+00, -1.1929e-03, -8.8031e-01,  5.8052e-01,  2.5755e-01,\n",
       "           1.2223e+00,  1.3401e+00,  1.1731e+00, -1.1238e+00, -7.5834e-01,\n",
       "           1.0619e-02,  1.4115e+00,  2.1003e+00,  6.9329e-01,  5.0675e-01,\n",
       "          -1.8165e-01,  1.2431e+00, -2.3197e-01, -1.5090e-01,  1.1428e+00,\n",
       "           1.3462e-01, -5.2688e-01, -6.3191e-02, -7.1254e-02, -1.7891e+00,\n",
       "           3.1289e+00,  4.6890e-01,  8.5502e-01, -5.9355e-01,  1.1804e+00]),\n",
       "  tensor([ 0.6741,  1.7655,  1.8637, -0.5672, -1.8848,  3.5163,  0.2627, -0.2363,\n",
       "          -2.3162, -1.2316,  0.7045, -1.0897, -1.3367,  1.1898, -0.2004,  0.3560,\n",
       "          -0.1943, -1.5815,  0.1246,  0.1083,  0.0485, -0.4366,  0.7296,  0.1898,\n",
       "           0.6702,  1.1386, -0.4984,  1.7533,  0.5910, -0.0445, -0.7171,  0.6673,\n",
       "          -1.1060, -0.2510,  1.2245, -0.0209, -0.0176, -0.6073, -2.7969, -1.7850,\n",
       "           0.2224,  1.3295, -0.6313,  0.5816,  1.3239,  0.9516,  0.1749, -1.8550,\n",
       "          -0.4303,  0.3643])),\n",
       " 'dirig√≠a': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'disculpen': (tensor([-0.0737, -0.8576, -1.2151, -0.2630, -0.7481,  2.0174,  1.3322, -0.2311,\n",
       "          -0.3351,  0.2622,  0.8931, -0.0839,  0.3567,  0.5162,  0.4074, -1.6811,\n",
       "          -1.6352,  0.4157, -1.2212, -0.3875, -0.5370,  0.4443, -0.2871,  0.2008,\n",
       "          -0.3929,  1.7072,  0.0062,  0.2913,  0.9451,  0.6668, -0.8494,  0.6653,\n",
       "          -1.8758,  1.0746, -0.1561, -1.3843,  0.2141, -0.6843, -0.9449, -1.6454,\n",
       "          -0.6677, -0.7582, -0.9750,  0.8449, -1.0023, -0.2611,  0.8219, -0.8714,\n",
       "           0.1364, -0.4394]),\n",
       "  tensor([ 0.5653, -0.6935,  0.4395, -0.4039, -1.1660,  1.3776,  0.1216,  0.9768,\n",
       "          -1.0282, -0.1795, -0.4262, -0.0839, -0.7875, -1.2240, -0.2464,  1.0711,\n",
       "           0.4734, -0.0941,  0.6520,  1.2743,  1.2923, -1.8821, -0.2575, -1.4419,\n",
       "          -0.1980, -2.4214, -0.9118,  1.0375,  0.7545, -0.1231,  0.8370, -0.9352,\n",
       "          -1.4765, -1.5467,  1.3117, -0.5973,  1.3823, -0.1231, -1.7821,  0.0317,\n",
       "          -0.5203, -0.8225,  1.0928, -0.0786,  0.5173, -1.3682,  1.4956, -1.2180,\n",
       "           1.6421, -0.3887])),\n",
       " 'discutir': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'discutiremos': (tensor([-3.2626e-01,  4.9350e-01,  7.5661e-01,  5.6881e-01,  2.8075e-02,\n",
       "          -1.9969e-01,  3.2517e-01,  4.3148e-01, -9.3215e-01, -1.0730e+00,\n",
       "          -5.0821e-01,  1.7588e+00,  1.0183e+00,  1.5938e-01,  6.8968e-01,\n",
       "          -1.3798e-02, -1.0552e+00, -4.6053e-01,  2.3687e-01, -9.5155e-01,\n",
       "          -8.3082e-01,  1.3228e+00, -6.8715e-01, -1.1750e+00, -5.2798e-02,\n",
       "           5.1123e-01,  9.6653e-01,  6.3927e-01, -6.8031e-01, -2.0007e-01,\n",
       "          -4.4258e-01, -6.0872e-01,  1.1805e+00,  4.1419e-02,  1.9265e-01,\n",
       "           4.5651e-02, -1.9864e+00, -9.0214e-01, -1.3595e+00,  1.1274e+00,\n",
       "          -1.6918e-02,  3.5700e-01, -2.6084e-01,  5.9325e-05, -6.6797e-01,\n",
       "          -1.4373e+00,  3.2224e-01, -9.1517e-01, -6.0059e-01, -1.0335e-01]),\n",
       "  tensor([ 0.9612,  0.2783,  0.6454, -1.7856,  0.4246,  0.5715,  0.2122, -0.3281,\n",
       "           2.6611,  0.1388, -0.1209, -1.9883, -0.2574, -0.2352,  0.2459, -1.0747,\n",
       "          -0.0824,  2.5709, -0.9741, -0.0566, -0.4969,  1.6696, -0.3179, -0.6866,\n",
       "           0.2613,  0.3264, -0.6085,  0.5325, -2.1702, -1.6099, -0.6486,  0.6522,\n",
       "           0.7485, -1.4725,  0.8363,  0.4508,  0.5351, -1.6476, -1.8386,  0.2705,\n",
       "           1.2625,  0.4359, -0.1008, -1.0543,  0.2431,  0.2573, -1.8337,  0.2853,\n",
       "           0.9926,  0.8248])),\n",
       " 'discutirlo': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'discuti√©ndolo': (tensor([-1.2267,  1.5304,  0.4671,  0.2497,  0.0778, -2.5734,  0.5678, -0.3257,\n",
       "          -0.5874,  0.6652, -0.3655,  0.9661,  1.6360, -0.6125, -0.1704,  1.1618,\n",
       "          -0.2933, -0.3129, -1.1051, -0.2711,  0.6372, -1.6029,  0.2339, -0.8970,\n",
       "          -2.8542,  0.1382,  0.7715, -1.3546, -0.4948, -1.8372, -1.3621, -0.3242,\n",
       "           0.6075, -0.2197,  0.1439,  0.4580, -1.0290,  1.8253, -0.4835,  0.2029,\n",
       "          -0.7566,  0.3999,  1.0736,  1.1894, -0.3171, -0.7105, -0.8370, -0.0796,\n",
       "           0.4641, -0.4163]),\n",
       "  tensor([-0.7295, -0.2801, -1.6047,  1.5707, -1.0282, -1.3064, -0.8712, -0.5492,\n",
       "          -1.9728,  0.5781, -1.9330,  0.4064,  1.1318,  0.5597, -0.3592, -0.2284,\n",
       "           0.9662,  0.4768, -1.8228, -0.0370, -0.2342,  0.9605,  0.2728,  0.5841,\n",
       "           0.9466,  0.1110,  0.5553,  0.9944,  0.7067, -0.0478, -3.4013, -1.1233,\n",
       "          -0.2090, -0.1594, -0.9713, -1.4309, -0.4136,  0.4506,  1.5610, -1.6086,\n",
       "           1.1235, -0.4328,  0.0570,  0.3755,  0.5709, -0.1887,  0.7851, -1.2166,\n",
       "          -0.4887, -0.4654])),\n",
       " 'dise√±o': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'disminuci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'disparos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dispensado': (tensor([-0.7101,  0.1762,  1.1022, -0.7013, -0.3444, -0.5603,  0.3511,  0.6416,\n",
       "           0.8428,  0.4432, -0.0943,  1.0571,  0.1167, -0.3164,  2.0231,  0.3077,\n",
       "           1.5174, -1.4593, -0.8851, -1.6525,  0.1113, -1.2161, -0.0358, -0.5365,\n",
       "           0.5678, -0.1109, -2.8945, -0.1832,  0.5729,  1.7209, -0.7641,  0.3741,\n",
       "          -1.4227, -0.2776,  0.7565,  2.6372,  1.6822, -0.8950, -0.6056, -2.0614,\n",
       "           0.9566,  0.4777,  0.8667,  0.8753,  0.4959, -1.4843, -1.2184,  0.5036,\n",
       "           1.0001, -0.0458]),\n",
       "  tensor([ 0.9431,  0.4438,  1.5110, -0.8907,  2.1702,  0.3795, -0.0847, -0.2020,\n",
       "           0.5200, -0.8269, -0.7206,  0.8789, -1.0018,  1.2307,  0.1979, -0.4237,\n",
       "          -0.5744, -0.7004,  1.3583, -0.9939,  0.1534,  1.9058, -0.2821, -1.3876,\n",
       "          -0.0690,  0.6877,  1.0945,  1.1358,  1.2697, -0.9088,  0.9218, -1.7415,\n",
       "          -1.8557,  0.5808, -1.9106,  0.8862,  0.7714,  1.5866, -0.6218,  1.0327,\n",
       "          -0.0428, -2.4673,  1.3773,  0.0090,  0.4950,  0.0551,  0.8513, -0.0259,\n",
       "          -1.4630, -0.3028])),\n",
       " 'dispone': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'disponible': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'disposici√≥n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dispuestos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'disputa': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dista': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'distinguido': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'distintos': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'distra√≠do': (tensor([ 0.0235,  0.1992, -0.5645, -0.7318,  0.6571,  0.4874,  0.7995, -0.2608,\n",
       "           0.8850,  0.6148, -1.0576,  0.0495,  1.7141, -1.7508, -1.6080, -0.9255,\n",
       "           1.5772, -1.5877, -0.4035, -0.3412, -0.0816,  1.9273,  1.0850,  0.0731,\n",
       "          -0.2476, -0.8011,  0.0982, -1.8283, -1.0922,  0.8338,  0.9709, -0.7060,\n",
       "           1.3582, -1.5935, -0.9486, -0.3750,  0.0780,  0.7325,  0.9646, -0.4799,\n",
       "           2.9175, -0.2853, -0.7369, -1.4265,  0.8198, -2.2067, -0.5299, -1.2919,\n",
       "          -0.6773, -0.3777]),\n",
       "  tensor([ 0.2299, -1.1670,  0.1485, -0.5007, -0.3234,  0.5113,  0.4042, -0.2396,\n",
       "           0.5894,  0.8803,  0.6313, -0.4895,  0.1408,  0.0771,  2.0976,  0.0051,\n",
       "          -0.3485, -0.4353,  0.5943,  0.1766,  1.4334, -0.7014,  2.4211,  3.9243,\n",
       "           0.8271,  0.7757,  1.6088,  1.1950, -0.4928, -0.5395, -0.8804, -1.6886,\n",
       "          -2.1029,  0.0155, -1.3227,  0.7148, -1.3645, -0.0163,  1.5152,  0.3540,\n",
       "          -1.0760,  2.1076, -0.3941,  0.2995, -0.9746,  0.1161,  0.0506, -0.7968,\n",
       "           0.1568, -0.0215])),\n",
       " 'distribuir√°': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'disturbios': (tensor([-1.0308, -1.4135,  0.4438, -1.1050,  0.4318, -0.1425,  2.6245,  0.5981,\n",
       "          -0.0557, -0.1902, -0.2328, -0.6593,  0.5521,  0.7328,  1.9234,  0.6411,\n",
       "           0.7769, -0.4423, -0.9139, -1.1225,  1.7395, -0.6128, -0.8577, -1.0024,\n",
       "          -0.0065, -0.4855, -0.3457, -1.6391,  1.2590, -0.3541,  0.0856,  0.5313,\n",
       "          -0.4062,  2.1142, -0.1039,  0.0667, -0.7184, -1.6222, -0.4436,  0.2390,\n",
       "           1.2319,  2.1551, -1.1866,  0.8683, -1.0589,  0.3045, -0.0366,  0.5214,\n",
       "           0.1121, -1.0878]),\n",
       "  tensor([ 0.5916,  0.7503,  0.5659, -0.4637, -1.8983, -0.9941,  1.6647,  0.0486,\n",
       "           0.5655,  0.9061,  0.5966, -0.2691,  0.7400,  1.0438,  0.8064,  1.2435,\n",
       "          -1.1136,  1.5211, -0.2573,  1.8053, -1.3120,  0.8542,  0.3532,  1.4953,\n",
       "          -0.7257,  2.5127,  1.6885,  1.7790,  0.9935,  1.6992, -0.8393,  0.6469,\n",
       "          -0.1156, -0.4974,  2.2296, -0.1186, -0.0305,  0.3826,  0.3670, -0.7336,\n",
       "          -0.5240, -1.1202,  0.1995, -1.1552, -0.8201,  0.0238, -0.2051,  0.7071,\n",
       "          -0.3591, -0.6970])),\n",
       " 'divergencias': (tensor([ 0.7840,  0.3515,  0.0271,  0.1905,  1.3231, -0.7368, -0.6034, -2.2686,\n",
       "          -0.7786,  0.4865, -0.8262,  0.4329, -0.5450,  1.0037, -1.0993, -0.6689,\n",
       "           0.3829, -0.0192,  0.7178, -0.0865, -1.2982, -0.6565,  1.1883, -0.8299,\n",
       "           0.4035, -2.6257, -0.5271,  0.8209,  0.8784,  0.8139,  1.8526,  0.7729,\n",
       "          -1.8484, -0.6284,  0.0096, -1.9241,  0.0362,  0.8620, -0.2659, -0.4169,\n",
       "           0.1936, -0.0443,  1.0935,  1.2063,  1.8196,  1.0359,  0.5309,  0.3202,\n",
       "           0.8222,  0.2440]),\n",
       "  tensor([ 0.0991, -2.2419,  0.7175,  0.5962,  0.4500, -0.2779,  0.8312,  0.2801,\n",
       "          -1.0110, -0.3888,  1.4897,  0.4033, -0.3920, -1.2838, -1.5216, -0.0653,\n",
       "          -0.4685,  1.3086, -0.5856, -0.0456,  2.5415,  2.0656,  0.3587, -0.4432,\n",
       "           0.3132,  0.6503,  0.2355, -0.7048, -0.4866, -0.8765,  0.8716,  0.2810,\n",
       "          -0.7195,  0.0302, -0.8694, -1.6511,  0.1449, -1.3628, -0.7174, -0.5488,\n",
       "           1.0904, -1.3191, -1.8600,  0.9421,  1.6598,  0.4613, -0.8880, -1.3094,\n",
       "           0.3215,  0.1516])),\n",
       " 'diversidad': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diversi√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'diversos': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'divida': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'divididas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dividido': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'divisi√≥n': (tensor([ 1.0553,  0.6650,  3.0101, -0.9639,  2.3805, -1.0431,  0.8372, -2.5170,\n",
       "           1.1040,  1.9538,  2.2927,  1.7663,  0.3628, -0.6117,  0.7657,  0.1702,\n",
       "          -0.4787, -1.5269, -1.6806, -0.0559, -1.0220,  0.6029,  0.6408, -0.3047,\n",
       "           1.5132,  2.0517,  1.3584, -0.4474,  1.4090,  0.8782, -0.0317, -1.2362,\n",
       "           1.0738,  0.3213,  1.2198,  0.7211, -0.5235,  1.7418,  0.3486,  0.0269,\n",
       "          -0.2186,  0.6430,  0.7008, -2.4798,  0.8883,  0.2031, -0.0462,  0.8662,\n",
       "           0.0047, -0.7901]),\n",
       "  tensor([ 1.3349,  0.8105,  1.2906,  0.5777,  1.2674,  0.4790, -2.4842, -0.7706,\n",
       "           2.0919, -0.3322,  1.3556,  0.6076, -2.0219,  0.8039,  0.8593, -0.4575,\n",
       "          -0.7860, -0.0331,  0.9923,  0.4527,  0.7630,  0.9884, -0.4029, -0.4219,\n",
       "          -1.9247, -0.7408, -0.9225,  0.4140,  0.3952, -0.9416, -0.4271,  0.3371,\n",
       "           0.1118, -0.5566, -1.1273, -0.3378,  0.2171,  0.0487,  0.6699, -1.0581,\n",
       "          -0.8377,  0.0569, -0.6112, -0.8212, -0.7473, -1.7503, -0.3628,  0.4648,\n",
       "          -0.5841,  1.7325])),\n",
       " 'divulgado': (tensor([-0.5068, -0.7926,  1.8236, -0.6167,  1.3778, -0.0043, -0.0821, -0.3119,\n",
       "          -0.2251, -0.1254, -0.4467,  0.8887,  1.4395,  2.0518,  0.7344,  0.4034,\n",
       "           0.3783, -2.2768,  0.1692,  0.7925,  0.2274, -1.2657,  0.9810,  0.3722,\n",
       "           0.5452, -0.4764,  0.8477, -0.6241,  0.0477, -0.3178, -2.2087,  0.7637,\n",
       "           0.0562,  0.1382,  0.3727, -0.4112, -0.5404, -0.2429,  0.2042,  0.6921,\n",
       "          -0.3343, -1.0561, -0.7631,  1.1134, -0.4154,  0.6725,  0.4018, -1.4108,\n",
       "           0.7826, -0.1555]),\n",
       "  tensor([ 0.9488,  0.3876,  1.9560,  0.3839,  0.4076,  0.9557, -0.5458, -0.4799,\n",
       "          -0.9632, -0.2768, -0.2178, -0.2940,  0.2399, -2.1529,  0.2907,  0.3447,\n",
       "           0.8974, -0.5740, -0.5417, -0.9612,  0.7844, -0.8835, -1.0407, -0.7653,\n",
       "          -0.3403, -0.0419, -0.1435, -0.4994,  0.9004,  0.3640,  0.4316, -0.6052,\n",
       "          -2.2074, -0.4398, -0.8049,  0.3349, -0.5807, -0.3050,  0.0164, -0.9326,\n",
       "           1.5982, -0.5908, -0.0968,  0.8614, -0.1604,  0.5622,  0.6277, -0.3736,\n",
       "          -0.3042, -0.2100])),\n",
       " 'divulgara': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'di√°logo': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'doce': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'doctrina': (tensor([-0.0441, -0.3425,  0.9221,  0.7605,  2.2722,  0.3693, -1.1596,  0.0523,\n",
       "          -0.9798,  1.6767,  0.1407, -2.4291,  0.6690, -1.8453, -0.7729, -0.1458,\n",
       "          -0.3672,  0.3229,  0.2299, -0.1370, -1.2248, -0.1854, -1.3346,  0.1046,\n",
       "           0.3609, -1.2116,  1.3863, -1.0230,  1.6227,  0.9301,  0.3949, -1.0811,\n",
       "           1.0039, -0.1524, -0.2458, -1.6957, -0.4480,  0.5741,  0.6681, -0.1429,\n",
       "           0.6794, -0.1616,  0.9662,  1.1094,  0.8656,  0.7000, -0.9976,  0.3535,\n",
       "          -1.4294, -1.9838]),\n",
       "  tensor([ 0.9199,  0.2927, -0.6218, -0.0734,  0.9681,  0.8687, -0.9189,  2.1429,\n",
       "           0.6695,  1.9349, -1.5238, -0.8233,  1.4226, -0.6607, -0.6837, -0.8951,\n",
       "          -0.4080, -1.9691, -0.1446,  0.8605, -1.9024,  1.1278,  0.1406,  1.0221,\n",
       "          -1.3901,  0.4402, -1.0848,  0.2907, -0.6937, -0.2268,  0.5734,  0.9053,\n",
       "          -1.0829, -0.1717,  0.1727, -0.6107,  0.7850,  0.1688, -0.1646,  0.7093,\n",
       "          -1.0250, -0.3555,  0.9782,  1.1212,  0.0999,  1.8049, -0.9318,  0.4150,\n",
       "           0.9314,  1.9334])),\n",
       " 'documento': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dolorosa': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dominar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dominaron': (tensor([ 0.4895, -0.2093,  0.7037, -1.8027,  1.1542,  0.0912, -0.7673,  0.6797,\n",
       "           0.4420,  0.6157,  0.1876, -0.1342, -0.0485, -1.5781, -1.2134, -1.3553,\n",
       "          -1.1339,  1.7493, -0.4414, -1.0636,  0.9069,  0.9575, -1.7636, -0.5222,\n",
       "           0.5575,  0.9126, -0.6239,  0.3487, -1.1648,  1.2633, -0.9583, -0.2036,\n",
       "          -1.9640, -0.3449, -0.4278,  1.1339, -0.8801,  2.2965,  0.9117, -0.6451,\n",
       "          -0.3364,  0.4210,  0.3447,  2.3503, -0.3395, -0.2144, -0.9319, -0.6231,\n",
       "           1.3204,  1.4422]),\n",
       "  tensor([-0.0917, -1.0603, -1.0686,  1.1562, -0.3366, -0.9065,  0.4398, -0.3390,\n",
       "           0.7437, -0.3599, -0.8271, -0.9881,  1.7272, -0.0215,  0.8942,  0.8071,\n",
       "           0.7789, -0.9815, -0.1121,  0.5815, -1.4781,  0.0123,  1.1790, -0.3223,\n",
       "           2.3058, -0.7212, -0.2871, -0.1870, -2.3816,  0.3770, -0.5861, -0.1366,\n",
       "          -0.8975,  1.0542, -1.4673,  0.4264,  1.4162, -0.0920, -0.2897,  1.1899,\n",
       "          -0.4246, -1.2096,  1.6121, -0.3602,  1.8450, -0.4107,  0.3897,  0.5457,\n",
       "           0.2078, -1.1055])),\n",
       " 'domingo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'domingos': (tensor([-0.4179, -0.3924,  0.2775, -1.2339, -1.2577, -0.8005,  0.3921, -1.2012,\n",
       "          -2.2590, -0.2816, -0.4758,  1.4541, -0.8653,  0.0254, -1.3630,  0.8054,\n",
       "          -0.4913,  1.8085, -2.4506,  0.8619, -1.8519, -0.0914, -0.5027,  0.9568,\n",
       "          -1.2523,  0.4691,  0.1698,  0.6886,  0.9271, -2.1767,  0.8259,  0.3873,\n",
       "          -0.5619, -1.3047,  1.4027,  0.0083,  0.4032, -0.2601,  1.6697, -0.0403,\n",
       "          -0.0092, -0.0891,  1.0715, -0.5611, -1.0159,  0.6677,  0.4255, -1.4030,\n",
       "           0.1683,  0.4679]),\n",
       "  tensor([ 0.7001,  0.5579,  0.1669,  0.7751, -1.5426, -0.9426,  0.2847,  0.1160,\n",
       "           1.8560,  0.9955, -0.4231,  0.2591,  0.5736, -1.8222,  0.8041,  1.4656,\n",
       "           0.6412,  0.4326,  0.3341, -0.5995,  1.5323, -0.1596,  1.7876,  0.5066,\n",
       "          -0.4846, -1.1086,  0.2344, -0.3348,  0.5945,  0.6144,  0.6938, -2.1338,\n",
       "           0.6649, -1.0374,  0.0388, -0.0191,  0.2758,  1.5101, -0.2459, -0.8928,\n",
       "          -0.3110,  0.6465,  1.4841,  1.9440,  1.3896,  1.2511,  0.8710,  0.3681,\n",
       "          -0.5329,  1.3624])),\n",
       " 'dominicano': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'donde': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dos': tensor(4.6194e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dosis': (tensor([ 1.7921, -1.3115,  1.0636, -1.0801,  0.0166,  1.0064,  0.4320,  0.4283,\n",
       "          -1.1924,  1.3036, -0.9907, -0.5208,  0.3572, -1.3841,  0.8291, -0.0241,\n",
       "           0.3390,  0.0505,  0.3111, -1.7685,  0.6485,  0.2869, -0.9046, -0.5475,\n",
       "          -0.2438,  0.7068, -0.3098, -0.2594,  1.5604,  1.1894, -2.3000, -0.8961,\n",
       "          -0.5709, -1.0314, -1.3619, -0.3941,  0.8135,  1.1221, -0.1032,  0.2679,\n",
       "          -0.1691, -1.4358, -1.0082,  0.8327, -0.5292, -0.3357, -0.2939, -0.0603,\n",
       "           0.2194,  0.7217]),\n",
       "  tensor([-0.8215, -1.2098,  1.4648,  0.9128,  0.7940,  0.6336, -0.4754,  1.7260,\n",
       "           0.9509,  0.5714,  0.2509, -0.4596, -0.4522, -0.3222,  0.4501,  0.4750,\n",
       "           0.7642,  1.4257,  0.0865,  1.5211,  0.0957,  1.4841,  0.3211, -1.0471,\n",
       "          -0.0156,  0.1818,  0.1080,  0.5567,  2.1240,  1.8288, -0.6821, -1.5697,\n",
       "          -1.2583,  1.3216, -0.3745,  0.0754,  0.6716, -0.6125, -0.3820, -1.1363,\n",
       "          -0.0111,  0.7862,  0.6232, -0.2492,  1.1883,  0.0257, -1.1322,  1.4506,\n",
       "           0.0494, -0.0710])),\n",
       " 'doy': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'drogas': (tensor([ 0.1561, -1.3337, -0.3159,  0.0034, -0.1427,  1.8494,  0.5567, -1.0954,\n",
       "          -1.6200,  1.7533,  0.3060, -1.6244, -1.5182, -0.6084,  0.0344,  0.8739,\n",
       "          -0.3086, -0.2870, -0.8206,  0.5351, -0.1888,  0.2498, -0.3878, -1.0420,\n",
       "          -0.1090, -1.9083,  0.2356, -1.0132,  1.1890, -1.8377, -1.3202,  0.4200,\n",
       "           0.3649, -0.8317, -0.4332,  0.4027,  1.9695,  1.0396, -0.5452, -0.5818,\n",
       "           0.5106,  0.9434, -0.3369, -1.3130, -1.1209, -0.7238, -0.2357, -1.5436,\n",
       "          -2.1623, -1.4080]),\n",
       "  tensor([-0.1845, -0.8326, -0.6670,  0.1623, -0.4512,  0.3985,  0.2255, -1.3980,\n",
       "           0.0132, -0.6628, -0.5754,  1.4097,  0.4557, -0.0441,  0.4060, -1.7677,\n",
       "           0.7221,  0.5278,  0.5678, -0.2599, -0.6476,  0.7800,  0.7289,  0.5602,\n",
       "           0.3992, -1.3728,  0.2220, -0.1132, -0.3989, -1.7063,  0.4543,  0.7193,\n",
       "           0.2775, -1.6746, -0.4559, -1.4764, -0.2189, -1.2283,  1.0009,  0.3498,\n",
       "          -0.4116,  0.3363, -0.5787,  0.0240, -0.1517, -1.4813, -0.4684, -0.8573,\n",
       "          -0.6404, -0.1809])),\n",
       " 'duda': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'dudamos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'duraci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'durante': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'duraron': (tensor([-0.5438,  1.0064,  0.3588, -0.7699,  0.2333, -0.3492, -0.8533,  0.7677,\n",
       "          -1.8569, -0.0729,  0.6781,  2.1682,  1.1479,  0.6486, -0.6879,  0.5247,\n",
       "           0.0981,  1.8147, -2.3532,  1.1941, -0.4118, -0.5054,  0.2520, -0.4958,\n",
       "           1.0602,  0.0779,  1.8207, -0.4185,  0.2585, -0.6207,  0.5523, -0.1961,\n",
       "           0.7204, -1.7125,  0.9174, -0.2727, -0.0610, -0.5916,  0.3247, -1.0747,\n",
       "           0.8862,  1.4765, -0.8519, -0.7477, -1.6246, -1.1694, -0.2067,  0.4928,\n",
       "          -0.4908, -0.6914]),\n",
       "  tensor([ 0.6121, -0.6738, -0.0917, -0.1237, -0.0491, -0.5773, -1.3583, -1.1046,\n",
       "           0.6868, -0.5909, -0.6484, -0.6008,  0.2200,  0.8637, -3.2340,  0.2621,\n",
       "           1.2863,  0.5507,  1.8934,  2.2644, -0.1692,  0.2027,  1.0152,  0.9510,\n",
       "          -0.0171, -0.4916,  1.4988,  0.4614,  1.5243,  0.9084, -0.1396,  0.1319,\n",
       "           0.5973,  0.0904,  0.4641,  0.4956,  1.4285, -0.4239, -0.0914,  1.5554,\n",
       "           0.1283, -0.9915, -0.5888, -0.2319, -0.4286,  1.3697, -2.8021, -0.8287,\n",
       "           0.6575, -0.7035])),\n",
       " 'durar√°n': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'd√°': (tensor([ 0.1099, -1.4468,  0.9062, -0.6530,  0.6301,  0.3144, -0.5222,  2.0284,\n",
       "          -1.6873, -1.8190,  0.6481,  0.4223,  1.3954, -1.2004, -0.7227,  1.1738,\n",
       "          -0.2966,  0.1453,  0.6929,  2.0820,  1.0782,  0.3155, -0.0535,  1.0193,\n",
       "          -1.1446,  0.7330, -0.0289,  1.1392,  0.9879, -0.3107, -0.2183,  0.2773,\n",
       "           1.8468,  0.6518, -0.3022, -0.0290, -0.3672, -0.3613,  0.9138,  0.5077,\n",
       "           0.9000, -0.0777, -0.1273, -2.3686, -0.5701,  0.0995,  0.1639,  0.2732,\n",
       "          -0.3441, -0.7285]),\n",
       "  tensor([-1.1336, -0.4649,  0.2472, -0.1044,  0.9624,  0.3166,  0.6708, -0.3059,\n",
       "           1.4130,  0.1156, -0.2358,  0.1686, -0.5340,  0.1899, -0.0156, -1.8087,\n",
       "          -0.1616,  1.4211,  0.6038,  0.2602, -0.1677,  1.4841,  0.8840, -1.2755,\n",
       "          -0.6859,  0.6792, -0.7294, -0.8338,  0.2475, -0.0907, -0.9792,  1.3211,\n",
       "          -1.4541, -0.5980,  0.7541, -0.7486,  0.5655,  0.2616,  0.2539,  0.6055,\n",
       "          -0.0095, -0.2575, -0.1705,  0.9745,  0.0895,  0.9321, -0.4900,  0.6142,\n",
       "           1.1855,  1.2229])),\n",
       " 'd√°ndose': (tensor([-1.1974, -1.3446,  0.0476,  0.0500,  0.3171, -0.8575,  0.0769,  0.5743,\n",
       "          -1.1630, -0.8365,  0.0493, -0.1124, -0.6981, -0.5530,  0.5477,  1.0936,\n",
       "           1.1774, -0.2039,  0.2480, -0.5006, -0.6717,  1.5833, -0.9634, -0.7582,\n",
       "           0.8515,  0.8456,  1.6755,  0.3821, -1.2547, -0.2675, -1.3646, -1.3229,\n",
       "           0.0539,  1.0555,  0.5390,  0.3776,  0.6383, -0.0081,  0.6519, -0.1094,\n",
       "          -0.3449, -0.9096,  1.1854,  0.5612,  0.4622, -0.8383,  1.2839, -0.3133,\n",
       "           1.7062, -0.4886]),\n",
       "  tensor([-1.7201,  0.7975, -0.6101,  0.4074, -0.3570, -0.2332,  0.2711, -1.2547,\n",
       "           0.8400, -0.5779, -0.1664, -0.1287,  0.4551, -0.1054, -0.3248, -0.1735,\n",
       "           1.0306, -0.2163,  0.6559,  1.5277,  1.4972,  0.1935,  1.1143,  0.1724,\n",
       "           0.0496,  0.9769, -0.2277,  1.9457,  0.8514, -0.3496, -0.4970,  0.0313,\n",
       "          -0.1028,  1.3496, -0.5338, -0.2298, -1.6014,  0.0197,  0.7899,  0.4535,\n",
       "          -0.2668,  2.2109,  2.1270,  0.2214, -0.9797, -1.2443,  0.3844,  0.2556,\n",
       "          -0.2938,  0.2602])),\n",
       " 'd√©': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'd√©bil': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'd√≠a': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'd√≠as': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'd√≥lar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'd√≥lares': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'd√≥nde': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'e': tensor(4.6194e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ech√≥': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'econom√≠a': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'econ√≥mica': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'econ√≥micamente': (tensor([-0.1827, -0.0902, -2.5220, -0.8484,  0.0655,  0.3167,  0.0521, -1.7498,\n",
       "          -0.7764,  0.3041, -0.2617,  0.3204,  0.0963, -0.9363, -0.8747,  0.6857,\n",
       "           0.1530,  0.4763, -0.9778,  0.2549,  0.4494, -0.6215, -0.0934,  0.8668,\n",
       "          -1.4920,  0.6760, -0.9569,  2.0370, -0.8380,  0.8671, -1.9908, -0.8101,\n",
       "          -0.4915,  1.2845,  1.4849,  0.7855,  0.4080, -0.6666, -0.2431,  0.3379,\n",
       "           1.1682,  1.8012,  0.9606, -0.9441,  0.9487, -2.4321,  0.0822, -1.9867,\n",
       "           1.8635,  0.3460]),\n",
       "  tensor([ 3.3411e-01, -8.4447e-01, -3.5402e-01,  3.8243e-01,  7.5212e-01,\n",
       "          -4.9211e-01, -9.4975e-01,  1.4604e+00, -1.1185e+00,  1.3469e+00,\n",
       "           2.4246e+00, -9.9345e-01,  8.8954e-01, -1.3358e+00, -8.8264e-02,\n",
       "          -4.2706e-01, -7.1869e-01,  1.4085e-01, -2.2681e-01, -5.2813e-01,\n",
       "          -2.0002e-01,  1.4239e+00, -6.1755e-01, -2.9007e-01,  1.1160e+00,\n",
       "           4.8024e-01,  4.7488e-01,  1.8179e-01,  1.0347e+00, -7.9624e-01,\n",
       "           2.1903e-04, -3.1881e-01,  1.5313e-01, -1.3126e-01,  5.2605e-01,\n",
       "          -1.1996e+00, -1.2400e+00, -4.5478e-01,  3.5132e-01, -1.9903e-01,\n",
       "          -3.0697e-01, -1.8482e-01,  1.6437e-01,  1.8240e+00,  2.7645e+00,\n",
       "          -1.6511e+00, -5.0499e-01,  7.7364e-01,  1.3455e+00, -1.5470e+00])),\n",
       " 'econ√≥mico': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'econ√≥micos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'edad': tensor(-9.5367e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'edici√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'edificio': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'edmundo': (tensor([-0.1722,  1.3203,  1.2825,  1.3483, -0.3930,  1.9883,  0.1629, -0.0845,\n",
       "          -0.4449,  0.8982, -1.2405,  0.3265, -0.4429, -0.6062,  1.2675, -0.3529,\n",
       "          -0.1561,  0.1201, -0.4225,  1.0012, -1.0313,  1.1324,  1.1077,  0.1450,\n",
       "           3.0423,  1.6901, -0.7523, -2.2494, -0.2825, -0.9971, -1.9619,  0.2365,\n",
       "          -0.5138, -0.3558,  1.3871,  1.3348,  0.1187,  0.2527,  0.5942,  0.3776,\n",
       "          -2.0658, -0.0404,  1.0577, -0.0820, -1.1624, -0.0603, -0.1558,  0.2181,\n",
       "          -2.0116, -1.5888]),\n",
       "  tensor([-2.6667e-01,  3.6943e-01,  1.7115e-02,  4.6480e-01,  1.6601e+00,\n",
       "           4.1943e-01, -4.1097e-01, -9.2404e-01, -6.6242e-01,  1.0060e+00,\n",
       "          -7.1436e-01, -8.1313e-01, -1.2607e+00, -3.2424e-01,  6.8281e-01,\n",
       "          -4.7780e-01, -5.4939e-02,  8.5000e-02,  3.7054e-01, -8.5897e-01,\n",
       "           5.2758e-01, -1.1297e+00, -1.4126e+00,  1.0700e+00,  1.9649e+00,\n",
       "          -1.8252e+00, -4.9511e-01,  1.0160e+00, -8.4198e-01,  5.9551e-02,\n",
       "          -1.1916e+00, -1.7217e-01, -6.6594e-01, -1.3444e+00, -1.5223e-01,\n",
       "          -1.1052e+00,  4.9201e-01,  1.0435e+00, -1.1119e+00,  1.0684e+00,\n",
       "          -1.2963e-03, -4.2613e-01, -5.2114e-01, -3.3758e-01, -1.9738e+00,\n",
       "          -1.0558e+00, -1.0862e-01, -3.7639e-01,  6.2617e-03,  5.8930e-01])),\n",
       " 'educaci√≥n': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'educadores': (tensor([-0.4709,  1.5743, -0.4969, -0.5711, -1.8865, -0.7550, -1.7683,  0.2947,\n",
       "           0.5420,  0.4409, -0.7040,  0.6282,  0.0111,  0.6550, -1.8857,  0.9568,\n",
       "           0.0108,  0.4021, -0.9865, -1.3998, -1.9591,  0.2228, -0.3133, -0.4120,\n",
       "          -0.9115,  1.6867,  1.1610, -1.2563, -2.1176, -0.0787, -1.1827, -0.4270,\n",
       "           0.0195, -1.1249, -1.3259, -0.9434, -1.5532,  0.5317,  0.1307, -0.5719,\n",
       "          -1.6527, -0.7679, -2.1234,  2.1809, -1.4733,  0.5032, -0.7331, -1.8715,\n",
       "           0.4646, -0.2444]),\n",
       "  tensor([ 0.6861, -1.5765, -1.2629, -1.1702,  1.1464,  0.7024, -0.1210, -2.0039,\n",
       "          -0.1424,  2.6860, -0.9778,  0.5574, -0.0692,  1.7993, -0.4820, -0.8195,\n",
       "           1.5889,  1.0611, -0.8422,  0.7297,  0.1833, -0.8646, -1.0211, -0.0558,\n",
       "          -1.5206, -0.8250, -0.0087, -1.6238,  1.3674, -0.7289,  1.1582, -0.9572,\n",
       "          -2.3766,  1.5612,  1.3562, -0.1849,  0.0088, -0.8363,  0.0884, -0.7574,\n",
       "          -0.3448,  0.7955, -0.6505,  0.2670,  0.1052,  0.1307, -0.1184,  0.7856,\n",
       "          -0.1475,  1.8187])),\n",
       " 'efectivamente': (tensor([-0.6727,  1.2712,  0.1610,  1.3764,  0.7358,  0.2730,  0.0991,  0.6810,\n",
       "          -0.0627,  1.3163, -1.5064, -2.7522, -0.0181, -0.6531, -1.5514,  0.8659,\n",
       "          -1.2386,  0.0175,  2.1310, -0.8443, -0.9659, -0.5251, -1.3006,  1.4879,\n",
       "          -1.5188, -0.1400,  0.0693,  0.5904, -0.9933, -0.7097, -0.5753,  1.7279,\n",
       "           0.0370, -2.0712,  0.6636, -0.6593, -0.7623,  1.0603,  1.1548, -0.0853,\n",
       "           0.1509, -0.1373, -0.1881,  0.2321,  0.6849,  1.1632, -0.7193,  2.1057,\n",
       "          -0.7358,  0.6684]),\n",
       "  tensor([ 1.6076,  0.1246,  1.3258,  1.8759, -1.1818, -0.0452,  0.3241,  0.9591,\n",
       "           0.8788,  1.3601,  0.8893,  0.0700, -0.0235,  1.5315, -1.3724,  2.0877,\n",
       "          -0.9487,  1.7045, -0.6200,  2.2965, -0.5554,  0.8537, -1.3212, -1.0591,\n",
       "           1.8508, -1.5506, -0.1686,  0.2387,  0.7066, -0.1902, -2.2166,  1.8611,\n",
       "          -0.1335, -0.6516,  1.3426, -0.2409,  0.2742, -0.0617,  1.3205, -1.4199,\n",
       "          -1.5095, -0.3956, -0.0976, -0.4897, -0.5492, -0.5624, -0.3055,  0.4422,\n",
       "           0.0487,  0.4260])),\n",
       " 'efectos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'efectuar√°': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'efectu√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ejecuci√≥n': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ejecutan': (tensor([-0.0768,  1.2395, -1.7518, -0.1912, -0.9396,  0.9139, -0.1732,  1.8008,\n",
       "          -0.4694,  0.6885,  0.4912,  0.2198,  0.2527,  0.0442,  0.9502, -0.0299,\n",
       "          -1.5511, -0.7966, -0.7250, -0.5108,  0.5086,  0.0934,  0.1375, -1.0746,\n",
       "           0.3309, -0.4501,  1.0040, -0.4833, -0.0072, -1.4198,  0.1060,  0.2947,\n",
       "           0.0726, -0.7025, -2.0731, -0.7803, -0.4724,  1.1518,  0.3111,  1.6535,\n",
       "          -0.3393,  0.5238,  2.1444,  2.1092,  0.5881, -0.4802, -1.1809,  1.5119,\n",
       "           1.6809,  0.3555]),\n",
       "  tensor([ 0.7342,  0.8902,  0.5669, -0.3539,  1.2350, -0.9620,  0.1520,  0.8071,\n",
       "          -0.8848, -0.5238, -0.3314,  1.7431,  1.0589,  0.8191,  0.6546,  0.0886,\n",
       "          -0.2900,  0.7424,  0.0620, -0.5943, -0.5526,  0.7571,  0.4207, -0.9757,\n",
       "          -1.4332, -1.9106,  0.8046, -0.9025, -1.1364, -0.5707,  2.8761, -1.4575,\n",
       "           0.3624,  1.1166, -1.0233,  1.6421,  0.4953,  1.5498, -0.6025,  0.6820,\n",
       "          -0.4839, -0.7283, -0.3466,  0.8348, -0.8002,  0.7892, -0.1898,  1.1496,\n",
       "           1.0787,  1.6107])),\n",
       " 'ej√©rcito': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ej√©rcitos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'el': tensor(-6.7055e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'elecciones': tensor(-1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'elecci√≥n': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'electores': (tensor([-1.0991,  1.2449,  0.4672, -0.3968,  0.6651, -0.7551,  0.7352,  0.3426,\n",
       "          -1.5452, -0.4283, -0.8256, -1.1194,  0.9179, -0.9830,  0.5854, -1.6150,\n",
       "          -2.1238,  0.1010,  0.8422, -0.7651,  1.8365,  1.8895, -1.0489,  0.3523,\n",
       "           0.5342, -0.1379, -0.5977, -2.9749, -0.7287, -0.0682,  0.3257,  0.8111,\n",
       "           0.0638, -0.5466, -1.3437, -0.8972,  1.1954, -1.0285, -0.0328,  1.0746,\n",
       "           1.4051, -1.1349,  0.6232,  0.0420, -0.2895, -0.7933,  0.8762, -0.1911,\n",
       "           0.0475,  0.1664]),\n",
       "  tensor([-1.0835,  1.2094, -0.3401, -0.2342,  0.5002, -0.2082, -0.2368,  0.4932,\n",
       "          -0.0556,  0.6099, -0.6122,  0.7487,  0.7018,  1.0690,  0.0767, -0.0310,\n",
       "           0.1186, -0.0573, -0.4183,  1.5189,  1.0067, -0.6998,  0.5441, -0.7076,\n",
       "          -1.3209, -0.8747,  0.6730,  0.8232, -0.5762,  0.0440,  1.4261,  0.4698,\n",
       "          -0.1069, -0.4227, -0.4885,  0.4574, -0.2964,  0.6243, -2.1931, -0.0921,\n",
       "           0.3056, -0.7995, -0.7907,  0.3212,  0.7127, -0.4597, -1.0618,  0.3607,\n",
       "          -0.5402,  1.6494])),\n",
       " 'electos': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'elegir': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'elemento': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'elgueta': (tensor([-2.1661,  1.5986, -0.8894,  0.3258,  0.6435,  0.1499,  0.6767,  0.3478,\n",
       "           0.0517,  0.6994,  1.1591,  0.3493,  0.1434,  0.0195,  0.2877,  0.1110,\n",
       "          -0.9655, -1.7034,  0.3004, -0.7481, -0.1692,  0.0741,  0.4293,  0.0262,\n",
       "          -1.5520,  0.3896,  0.0354, -0.3763, -0.9447, -0.4053,  0.3436, -2.6544,\n",
       "          -1.6630, -1.7591, -0.6236,  0.2837, -0.0730,  0.3941, -2.2406, -0.7598,\n",
       "          -0.0246,  0.2959, -1.1349, -0.8129, -1.8790,  0.2548,  0.7782, -1.7551,\n",
       "           0.5825, -0.7175]),\n",
       "  tensor([-1.5550, -0.0266, -1.9470,  0.0458, -2.2627,  1.2060, -1.5531,  0.2759,\n",
       "           0.6867, -0.8915,  0.6762,  1.3461,  1.2859,  0.3346,  1.0310, -0.8043,\n",
       "           0.7735,  0.4468, -0.0110,  2.1180,  0.6396, -0.0254, -1.0949,  2.3401,\n",
       "          -0.3863,  0.2055, -1.0810,  0.8938,  0.8785, -0.1351,  3.1280, -0.5914,\n",
       "           0.7845,  0.3812, -0.1943, -0.4869,  1.3255,  1.4738,  0.6356, -0.0966,\n",
       "           0.9736, -1.2207, -0.7055,  1.8502, -0.2427,  1.3554, -1.1580, -0.9811,\n",
       "           0.1084, -2.3029])),\n",
       " 'eligen': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'elijen': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ella': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ellas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ello': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ellos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'el√©ctrica': (tensor([ 0.8662, -1.0791, -0.7905,  1.3310,  0.6587, -0.2537,  0.2121,  0.9466,\n",
       "          -0.0156,  0.0928, -0.3338,  0.4253,  0.6958,  1.9998, -0.6591,  0.3755,\n",
       "          -0.6357,  1.1026,  0.9293, -1.2591, -0.3716,  0.5610, -1.6078,  1.3946,\n",
       "           0.1862, -0.7386,  1.6504,  0.1973,  0.4580,  0.8753, -0.4207, -0.9839,\n",
       "           1.9331, -0.6432, -0.1910,  0.5752, -0.8553, -0.0708,  0.2055, -0.0306,\n",
       "          -0.9009,  0.4323,  0.7112, -0.3460, -0.8828, -1.2334,  0.0651, -0.1753,\n",
       "          -1.2697,  0.8590]),\n",
       "  tensor([ 0.4581, -2.3884, -0.4371,  0.4988, -0.5605, -0.7864,  0.6995,  1.3616,\n",
       "          -1.3823, -0.8821, -0.5309, -0.6744, -0.9776,  0.7424, -0.1807, -1.0817,\n",
       "          -0.2886,  0.3908, -0.9179,  1.7230, -2.2077, -0.1922, -1.0044, -0.8488,\n",
       "          -1.9344,  0.5561,  0.2687,  1.1623, -0.3162, -0.3391, -0.8325,  0.1820,\n",
       "          -1.9017,  0.7530,  0.0857,  2.3395,  0.4226,  1.4341, -1.5637,  0.4074,\n",
       "           0.8033, -0.4594, -2.1849, -0.5429,  0.3904, -0.3751, -0.1933, -0.2626,\n",
       "           2.3873, -0.0993])),\n",
       " 'el√©ctricos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'el√≠as': (tensor([-2.3568,  0.1114,  0.1305, -0.9492,  1.9232, -0.5222, -2.4053, -0.7374,\n",
       "           0.6875, -0.1942,  0.1909,  0.5637,  0.9250, -0.8761,  2.8685, -0.4639,\n",
       "          -0.0216, -0.7128,  0.3448, -0.7187, -1.8152, -1.1608,  0.0073, -0.5388,\n",
       "          -1.9641, -1.9770, -0.0377,  1.4224,  0.6592, -1.0029,  0.7720,  0.1294,\n",
       "           1.3190, -1.0734,  1.6520,  0.3472, -0.6226, -0.0155,  0.0138, -0.4419,\n",
       "           1.0003,  0.2961, -0.8430,  0.1067,  1.3841,  0.6936,  0.4356,  0.8283,\n",
       "           0.3794,  0.2894]),\n",
       "  tensor([-0.0764, -0.0257,  0.2758,  0.1712, -1.1910, -0.8054,  0.1894,  0.6118,\n",
       "           1.3584,  1.3711, -0.3943, -0.1522, -0.5111,  0.8503,  0.5846,  2.2335,\n",
       "          -1.7263,  0.5119, -0.7199, -1.9071, -0.5996,  0.0263, -0.4160,  0.3744,\n",
       "           1.3222,  0.7727,  0.3876,  0.8545, -0.0816,  1.0512, -0.3708, -0.6915,\n",
       "          -0.5089,  0.0244,  0.4184,  0.7117,  0.7479, -1.4224, -1.3006,  1.2591,\n",
       "          -0.8554,  1.6672, -0.0246, -1.0209,  1.3189,  0.1210, -1.2229, -0.2061,\n",
       "          -0.1193,  1.4781])),\n",
       " 'embargo': tensor(1.1921e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'emigrar': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'emiten': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'emotivo': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'empates': (tensor([ 2.1040,  0.7908,  0.3508, -0.5048, -0.8607,  0.3187,  1.6275, -0.5188,\n",
       "           2.4507,  1.0503,  2.4144, -0.6995, -0.1584, -0.6923, -0.6478, -0.3091,\n",
       "           1.4926,  0.2250, -0.7780,  0.7739,  1.6952, -1.3457,  1.5399, -0.9863,\n",
       "          -0.9505,  0.1527,  0.0731,  1.4011,  1.5813, -0.3454,  0.3459, -0.9573,\n",
       "           0.0507, -0.1109, -1.5932,  0.0345, -0.1319, -0.6943,  0.0466, -3.0864,\n",
       "          -0.6613, -1.0501,  0.6662,  0.4397, -1.1255,  1.0737, -0.1729,  0.7097,\n",
       "           0.0517,  0.4998]),\n",
       "  tensor([-1.0428,  1.0883,  0.3539,  0.9069,  0.3112,  0.1496,  0.9772,  0.1366,\n",
       "          -0.0208, -0.7714,  1.2986,  1.0652, -0.6624,  1.8268,  0.1048,  0.0569,\n",
       "          -0.1863,  0.6774, -1.6663,  1.1140, -2.0628,  0.9025,  0.9804, -0.8351,\n",
       "           0.3431, -0.0820,  0.2507,  0.9061,  0.0932, -0.1904,  0.8013,  0.3459,\n",
       "           0.7881, -0.0382, -0.1294, -0.0725, -0.9781, -0.5041, -1.0840,  0.7726,\n",
       "          -1.4775,  0.4318,  0.4151,  0.8250,  0.5672,  0.7014,  0.2850, -0.3948,\n",
       "           0.6872,  2.1873])),\n",
       " 'empezado': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'empleadores': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'emplear√°': (tensor([-0.4033,  0.3800, -0.7023, -1.4789, -0.7696, -0.5148, -0.4045, -0.6882,\n",
       "          -0.7652,  1.2008,  0.8626, -0.1161, -0.1998,  0.9768, -0.9677, -0.8582,\n",
       "           1.8529, -0.9925, -0.5018, -0.3963,  1.0298, -1.2950, -0.1598,  1.2671,\n",
       "           0.1991,  0.3025, -0.3211, -0.8832,  0.8915, -0.4458, -0.2356,  0.6102,\n",
       "           0.6295, -0.3531, -0.6546,  1.1858, -1.2918, -1.3884,  1.3059,  0.3752,\n",
       "           0.0145, -0.2912,  1.0166, -0.9844,  0.5584,  1.1271, -2.5136,  0.5291,\n",
       "           1.4538, -0.5997]),\n",
       "  tensor([ 1.8971,  0.6172, -0.3736,  0.7839, -1.4046, -1.0901,  0.6186,  0.8562,\n",
       "          -0.9585, -1.9833,  1.0953,  2.6561,  0.5862, -0.8846, -0.3836,  0.0326,\n",
       "          -0.9901, -1.3115,  0.3502, -0.3065,  1.3862, -1.2729, -0.0280, -0.4528,\n",
       "           0.0917,  0.4598, -0.3269, -2.0466,  1.0402,  1.3568,  0.2122, -0.9680,\n",
       "          -1.0556, -1.1997,  0.5611,  0.1126, -1.0762, -0.3893, -2.1656, -1.5509,\n",
       "           0.0611,  0.4475, -0.4132,  0.6182, -0.2855,  0.2294,  0.4659, -0.4893,\n",
       "          -0.1388,  1.0233])),\n",
       " 'empresa': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'empresarios': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'empresas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'empuja': (tensor([ 1.4238,  0.2007, -1.7114,  1.3886, -1.8109, -0.0372,  1.0424,  0.9214,\n",
       "           0.1024, -1.0684,  0.6029,  0.3134, -0.8111,  0.1421, -0.0688, -0.3002,\n",
       "          -1.7091,  0.2456, -1.7536, -1.2636, -0.6761,  0.2392, -0.7638,  0.1458,\n",
       "           1.2642, -0.9338, -0.6180,  1.4854,  0.3788, -0.9692, -0.1209, -1.5421,\n",
       "          -0.5923, -0.4829,  1.0887, -1.2094,  0.0104, -0.4204,  0.4541,  0.7625,\n",
       "           1.0102, -0.3711,  0.0499,  0.9427,  0.5821, -0.1003, -0.7222,  0.1733,\n",
       "           1.4572,  1.3192]),\n",
       "  tensor([-0.0358, -0.4744,  1.1177,  1.3428,  2.2719, -1.1169, -0.5815,  0.0603,\n",
       "           0.7967,  0.6341,  0.4056,  0.0468,  0.3666, -0.2186, -0.4207,  1.1786,\n",
       "          -1.2221, -1.5090,  0.1751, -0.9073,  1.4165,  2.3093,  0.5264, -0.5007,\n",
       "          -2.1930, -0.6278, -1.4021,  0.4154, -0.6219,  1.2174, -0.7894, -0.0096,\n",
       "           1.1760,  0.9587, -0.7834, -0.3787, -0.1061, -0.1431,  1.5138,  1.1844,\n",
       "          -0.2062,  1.3215,  2.1151,  1.0634, -0.2889, -0.5310, -0.8568, -0.5334,\n",
       "          -0.7433,  0.5247])),\n",
       " 'en': tensor(-1.7881e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encarado': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encomendada': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encontraban': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encontrar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encontrarse': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encuentra': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encuentran': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encuentro': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'encuesta': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'energ√≠a': (tensor([-0.5103,  1.0761,  1.1692,  0.2205, -1.3557,  2.1101,  0.6235, -0.2239,\n",
       "          -0.1300,  0.3242,  0.2403,  0.4375,  1.3973,  0.8685,  0.4597,  0.8538,\n",
       "          -1.3618, -0.4831,  0.1633,  0.3574,  1.2242,  1.2276, -0.5780,  0.3420,\n",
       "           0.5612, -0.9678,  0.4177,  1.6528, -0.8238, -0.6127, -0.4912,  1.5972,\n",
       "           0.9492, -0.4780,  2.6543,  0.3253, -0.0318,  1.3000,  0.4366, -0.9825,\n",
       "          -0.0673,  0.7318,  1.4545,  0.3580, -0.7016, -0.2563,  1.7109, -0.6107,\n",
       "          -0.5068,  2.9370]),\n",
       "  tensor([ 1.3679, -1.2338, -1.0070, -0.3465,  0.8638,  2.0482, -2.0541,  0.2505,\n",
       "          -0.9933, -0.4191, -0.2419,  0.7553, -1.0081,  0.3814, -0.4287,  0.8494,\n",
       "           1.4468,  0.4728, -0.7701,  0.9847, -0.2359,  1.1040,  1.7930, -2.6407,\n",
       "          -2.1333, -0.8508,  0.2738,  0.9082,  0.7234,  0.5154,  1.1578,  0.9480,\n",
       "          -0.9496, -0.1132, -1.3883,  0.4270, -0.8084, -0.5496,  0.3445,  0.6676,\n",
       "           0.2978, -0.0527, -0.3547,  0.1446, -1.1792,  1.3876, -0.8366, -1.5665,\n",
       "           1.3147,  1.5473])),\n",
       " 'enero': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'enfatiz√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'enfoque': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'enfrenta': (tensor([ 0.9174, -1.3178,  1.1505,  1.2065,  1.7795,  0.7857,  1.0435,  1.6008,\n",
       "          -0.6980, -2.4255,  0.7885, -0.9667,  1.6517, -0.9229, -3.9691, -0.4807,\n",
       "          -0.0938, -0.2510,  0.1600,  0.6436, -0.6430,  1.4553, -1.8448, -0.9805,\n",
       "           0.0359,  0.7598,  1.6471, -1.4359, -0.0507,  0.0600,  1.4821, -1.0975,\n",
       "           0.4300,  0.5962, -1.6244, -0.7018, -0.3087, -0.6148, -0.9982,  1.4811,\n",
       "           1.6311, -1.0963, -0.8960, -1.8322,  0.5307,  0.0139, -1.3826,  0.5336,\n",
       "           0.1083, -0.3734]),\n",
       "  tensor([ 0.0289,  1.0818, -0.3824,  1.0607,  0.3286,  0.0808, -0.0569,  1.3600,\n",
       "           0.7548,  0.0978, -0.9281,  0.9873,  0.2882,  0.5808, -0.3234,  1.6113,\n",
       "          -1.5549, -0.8986,  0.2807,  1.2602,  0.6016, -1.0241,  0.2340,  0.4806,\n",
       "           1.0324,  0.4712,  0.6164,  1.8617,  0.2701,  0.3194, -0.3235,  0.5067,\n",
       "           1.6270,  1.3850,  0.7702,  1.2793, -0.8024, -1.3187, -0.1079,  0.6054,\n",
       "          -1.8634, -0.7037,  0.0502,  0.6267, -0.9073,  0.7175, -2.0321, -0.5872,\n",
       "          -1.0040, -1.2270])),\n",
       " 'enmienda': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'enmiendas': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ense√±anza': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ensucian': (tensor([-0.9489, -0.4240,  0.9361, -0.3130, -0.4356, -0.0535, -0.9292, -1.1129,\n",
       "           2.4106,  0.2595, -0.6756, -0.2149, -0.8063,  0.7954, -1.2671,  0.1141,\n",
       "          -0.0413,  0.5857,  1.1922,  0.7654, -0.4071,  0.6214, -0.2306,  0.5788,\n",
       "          -0.2498,  0.4721,  0.5379, -0.2288, -0.6358, -1.5227,  0.5331,  0.8933,\n",
       "          -1.7444, -0.3770, -0.2466, -0.1686, -1.9332,  0.6214, -0.0828,  0.2910,\n",
       "          -1.2602, -0.6457, -0.6211,  0.3640, -0.3784,  0.1912,  0.9044, -1.0824,\n",
       "           1.6932, -0.4306]),\n",
       "  tensor([-1.2802,  1.9210, -0.0679,  0.3264, -1.0983,  0.7232,  0.0303, -1.4459,\n",
       "          -0.8522,  0.9261,  0.9642,  3.2060, -1.4361, -0.1753, -0.2244, -0.6126,\n",
       "           1.9611,  1.3378,  0.6433, -1.3934,  1.3765,  0.5567, -0.2246, -0.5652,\n",
       "           0.6703,  0.5436, -0.2423,  0.5281,  1.1904, -0.4186,  0.2151, -1.2055,\n",
       "          -0.7182, -0.6708,  0.0206,  0.2734, -1.1128, -0.0158, -2.8282, -0.8549,\n",
       "           0.1976, -2.0186, -0.4853,  0.5784, -0.8820, -0.1276, -2.1640,  1.3978,\n",
       "           0.2127,  0.2530])),\n",
       " 'entel': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'entender': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'entendimiento': (tensor([ 1.9648, -1.6782, -1.2764, -0.9623,  1.0290,  1.2253, -0.6247,  1.7739,\n",
       "           0.8483, -0.9016, -0.9997,  0.4291, -1.0981,  0.9056,  0.2829, -0.9741,\n",
       "           0.1183, -0.7426,  0.9281,  0.4880, -0.6595, -0.0903, -0.8909, -0.5781,\n",
       "          -0.2975, -0.6726,  0.1529,  0.1393,  1.4849, -1.1013,  0.8550,  0.3886,\n",
       "          -1.5075, -0.0831,  0.4794, -1.0093,  1.0351,  0.0094, -0.5182, -0.6187,\n",
       "          -0.0475, -1.9204, -0.7249,  0.1444, -1.1222,  0.0725,  1.3477,  0.2301,\n",
       "          -0.1210, -0.3130]),\n",
       "  tensor([-0.1928,  1.4836,  2.0291,  0.2591, -0.1580, -1.0305, -1.4572, -0.4075,\n",
       "          -0.0339, -0.1584,  0.8150,  0.9997, -1.5063, -0.0261, -1.3539,  2.1071,\n",
       "           1.1417, -0.4300,  0.9961,  2.9374, -1.6741,  1.1111,  1.1819,  0.8893,\n",
       "           0.0648, -0.1546,  2.4870,  0.0574, -0.3619, -2.4029, -0.8081,  1.1531,\n",
       "           1.0101,  0.0829,  0.4951,  0.0350, -0.6817,  0.8130,  0.6530, -1.2028,\n",
       "           0.7407,  0.2024, -0.4787, -0.5646,  0.7027, -1.3641,  1.0288, -0.1005,\n",
       "          -1.5567, -1.0355])),\n",
       " 'entonces': tensor(2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'entre': tensor(2.9802e-08, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'entrega': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'entregar': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'entreg√≥': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'entren': (tensor([-1.1574,  0.7545, -0.0187, -1.4303, -0.7980,  0.3122,  1.0460,  1.5047,\n",
       "           0.6346, -1.0702,  0.3844, -0.2495,  0.4775, -1.6596,  1.0451,  0.4757,\n",
       "          -0.8041,  0.0449, -1.1209, -0.8104, -0.2099, -0.5775,  0.4886,  0.7808,\n",
       "           0.3745,  0.1098, -0.3953, -1.1214, -1.0722, -0.5684,  0.3154,  2.1493,\n",
       "           0.3991,  0.9496, -0.7406, -1.4796, -2.1202,  0.0774,  0.7282,  1.5939,\n",
       "          -2.1448, -0.9224,  0.0539, -0.6141,  2.1763,  1.7201, -0.1637, -0.5170,\n",
       "          -1.1819, -0.5496]),\n",
       "  tensor([-1.0458,  0.4459,  1.8192,  1.7400, -0.9688, -0.8100, -0.9133, -0.5878,\n",
       "          -0.9123, -0.1077, -2.2962, -0.6322, -1.0757,  1.0630, -0.6198, -0.4082,\n",
       "          -0.2492,  0.0605,  1.1359,  0.7455,  0.9856, -0.9281,  1.0420, -1.1565,\n",
       "           2.2146, -0.3529,  0.2258, -1.1390, -0.3875, -0.1035, -0.1322,  0.5390,\n",
       "          -0.1456, -0.3028, -0.7518, -1.3263, -0.0598, -0.4970,  0.3410,  0.0528,\n",
       "           0.2537,  0.2885, -0.5558,  0.9066, -0.7157,  1.1511,  0.8609, -0.2862,\n",
       "          -0.5535, -1.7219])),\n",
       " 'entrenador': (tensor([-0.8078, -0.4695, -0.0135, -0.3324, -1.2310, -0.4067, -0.3192,  0.5510,\n",
       "           0.5709,  1.2930,  1.3809, -0.3503, -0.5267, -0.5527,  0.9332, -0.0924,\n",
       "           0.8126,  1.2211, -0.9870, -1.5968, -0.7406,  0.7322, -0.5227,  0.7510,\n",
       "          -0.0760, -1.0128, -0.5998,  0.0983, -0.3525,  0.3031, -0.0928,  1.0567,\n",
       "          -1.4755,  0.1693,  1.0780, -0.2965,  0.1282, -0.5219,  0.9267,  1.2632,\n",
       "          -1.2067, -0.1421,  0.4640, -0.9730,  1.0692,  0.6303, -0.7633,  0.1244,\n",
       "           1.8940,  0.1137]),\n",
       "  tensor([-0.1543,  0.4850,  1.1668,  0.1267,  0.0355,  0.1773,  0.3076, -0.8577,\n",
       "           0.3206,  0.2574,  1.0180, -0.4894, -0.9745,  0.8734,  0.6974, -1.1762,\n",
       "           0.1321,  0.0719, -0.3420, -0.3034,  0.1244,  0.0580,  0.9943, -1.3563,\n",
       "           2.4747,  0.6892, -1.4706, -0.6505,  1.2492, -1.6259, -1.4749,  1.1357,\n",
       "           0.6456,  0.7023, -1.5206, -2.6524,  1.3044,  1.0175,  1.1007, -0.0847,\n",
       "           1.4325, -0.1957,  0.6304, -0.0887, -0.8724, -1.0205, -0.0802,  0.4991,\n",
       "          -1.1814,  0.8854])),\n",
       " 'envases': (tensor([ 0.8352,  0.2628,  1.6815, -0.5477,  1.9910, -2.1767, -0.4901, -0.6715,\n",
       "           0.1856, -1.5463,  0.0589, -0.8494,  0.1738, -0.6059,  0.5026, -2.0902,\n",
       "           0.5530,  1.2775, -0.0285, -0.0210,  0.6613, -0.1581,  1.0776, -1.2003,\n",
       "          -0.6479,  0.5372, -0.2916, -0.9470, -0.3697,  1.4115,  0.0754,  1.6310,\n",
       "          -1.0087,  0.6697, -0.4059, -1.0292,  0.3050,  0.5235, -2.1594,  0.7519,\n",
       "          -1.8102,  0.0925,  0.1301, -0.8421, -1.6798, -0.3093, -1.6421, -0.8558,\n",
       "          -0.0762, -0.1644]),\n",
       "  tensor([ 0.8891, -0.7791, -1.1853, -1.1769,  1.3494,  1.4861,  1.1531, -2.5498,\n",
       "          -0.8846, -0.3466, -1.8522,  1.1066,  0.5324, -0.3661, -0.0543, -0.4166,\n",
       "           1.7550,  1.0557,  1.0967,  2.1831, -0.0948,  0.9036,  0.4261, -0.5039,\n",
       "          -0.3563,  1.4887, -1.1170,  0.9752,  1.4218,  1.0014,  0.7140,  0.8983,\n",
       "          -0.0040,  0.1009, -0.1244,  1.0223,  1.8125,  2.8225,  0.6371,  0.7996,\n",
       "           0.2031,  0.8699,  0.1775, -2.1677,  0.2876, -1.9848, -0.1392,  0.7046,\n",
       "           0.7779,  0.4866])),\n",
       " 'env√≠amos': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'env√≠o': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'epicentro': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'epidemia': (tensor([-0.3950,  0.9903,  0.7031, -0.9882,  1.2596,  0.4985, -1.0713,  0.7421,\n",
       "           0.7251, -1.1386,  0.0805, -1.0994,  0.5235, -2.4729, -2.6484, -0.1357,\n",
       "           0.4144, -0.7809,  0.1727,  1.4240,  1.9115, -0.7721,  0.3589,  1.0195,\n",
       "          -0.1605,  0.5294, -0.0173, -1.0365, -1.8150,  0.5086, -0.3579,  0.4805,\n",
       "           2.6259, -0.5280,  2.7112, -0.1243, -0.4265, -0.7432, -0.2286, -0.1026,\n",
       "          -0.1888,  0.8355, -2.0736, -0.5597, -0.2739,  0.0920,  0.2670, -1.6709,\n",
       "           0.5516,  2.3671]),\n",
       "  tensor([ 0.3033, -1.6418,  0.7820,  2.3216,  0.3236, -2.1762,  0.3535,  0.2825,\n",
       "          -0.1208, -0.3948,  0.2189, -0.6324,  2.3312,  1.7435, -0.0459, -0.6541,\n",
       "          -1.2741,  0.1391, -0.0187, -0.6778, -0.9852,  0.3340,  0.0537, -0.0153,\n",
       "          -0.8463,  0.4669, -0.1858, -1.4236,  0.6542,  0.5046,  0.0296, -1.5047,\n",
       "          -1.9781, -0.0475,  0.4018,  0.6452, -0.7278, -0.7390, -0.2442,  0.5683,\n",
       "          -1.1713,  0.3613, -1.4146,  0.1621, -0.2865, -0.3456, -1.5595,  0.6675,\n",
       "           0.8351,  1.1818])),\n",
       " 'equipo': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'equipos': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'era': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'eramos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'error': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'es': tensor(-2.3842e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'esa': tensor(-2.6822e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'esas': tensor(1.7881e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'esbozan': (tensor([-0.8203, -0.1135,  0.1953, -1.3434,  0.6875, -0.1003, -0.8710,  1.1173,\n",
       "           0.4348,  0.3834,  0.1786,  0.4000, -0.2827,  0.4524, -0.4688,  0.9039,\n",
       "          -0.4152, -0.1700, -1.2094, -0.3032,  0.6135, -1.1924,  0.2374,  1.4174,\n",
       "          -0.1525,  1.1110, -0.0178,  1.2281, -0.6538, -0.0942,  1.9489, -0.2620,\n",
       "           0.1203, -0.3109,  1.5564, -1.2568, -0.1229, -0.4136, -0.6758, -1.3505,\n",
       "           2.0449,  0.6785,  0.9631, -1.3835,  0.5125,  0.4582,  0.1636, -1.2797,\n",
       "           1.8338, -1.5350]),\n",
       "  tensor([ 3.7493e-01,  2.7934e-01,  3.5823e-01, -7.6130e-01, -1.7070e+00,\n",
       "          -2.0419e-01,  6.7748e-01, -5.9870e-01, -4.9527e-01, -7.0316e-01,\n",
       "          -3.0108e-01, -2.8564e-01, -7.3551e-01, -8.7891e-01, -9.0906e-01,\n",
       "           7.4513e-02, -1.5428e+00, -3.2617e-01,  1.6887e-03, -3.9802e-01,\n",
       "           2.7060e+00, -1.2565e+00, -7.1177e-01,  3.3098e-01,  4.7046e-01,\n",
       "          -7.1556e-01,  1.0711e+00, -1.6860e+00, -6.7985e-01,  1.6213e-01,\n",
       "           1.1751e-01, -6.1143e-01, -1.1567e+00, -1.2306e+00,  1.3018e+00,\n",
       "          -1.1498e+00, -1.7472e+00, -9.7863e-01, -8.8170e-02,  4.4852e-01,\n",
       "           5.5717e-01, -2.1360e+00, -1.4074e+00, -2.2390e+00,  1.8034e-01,\n",
       "          -1.1472e+00, -5.9422e-01, -1.6124e-01, -9.6729e-01, -3.6455e-02])),\n",
       " 'escalas': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'escapa': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'escapar': (tensor([ 0.0736, -0.3990,  0.0082,  1.1737, -0.0162, -0.2465, -0.8170,  0.7205,\n",
       "           1.0936,  0.6347,  1.3503, -0.3111,  1.0434,  1.0314,  0.0124, -1.0264,\n",
       "          -1.1270,  0.2466, -0.7429, -0.1823, -0.9458,  0.9319, -0.3990,  1.0944,\n",
       "          -0.9233,  0.1459,  1.6324, -0.4193,  0.6052,  0.1196, -0.8781,  1.5356,\n",
       "           0.0371,  0.3648,  1.5245, -1.2197, -0.2595, -0.5188,  1.8073,  0.7955,\n",
       "          -1.5324,  0.1435, -0.9297,  0.2097, -0.6637, -2.4685,  0.8799, -0.9301,\n",
       "          -0.8288, -0.0916]),\n",
       "  tensor([-0.9052,  0.6141,  0.1449,  0.8417,  0.6890,  0.2120, -0.2099, -0.6150,\n",
       "          -0.8634,  0.5438, -0.0733,  0.4306, -0.8374,  1.5839, -0.2637, -0.3993,\n",
       "          -0.6395, -0.0948, -0.8549,  0.4346, -0.8862, -1.3749,  0.7750, -1.6561,\n",
       "           0.5888, -0.9467, -1.0063,  0.0816, -0.2792, -1.5244, -0.8642, -0.2858,\n",
       "          -0.3882,  0.2327, -2.2926, -1.2032,  0.4954, -0.2835, -0.8501,  0.6200,\n",
       "           0.1818,  1.7971, -0.2430,  1.2388, -1.2804,  1.1198, -0.0889,  0.2922,\n",
       "          -0.2900,  0.5204])),\n",
       " 'escasez': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'escaso': (tensor([ 0.4128,  2.3391,  0.9842, -1.7830, -0.1116, -1.6093,  0.7481,  0.8424,\n",
       "           0.9082,  1.0052, -1.1255, -0.3238, -2.4080,  0.2344,  0.3129,  0.6617,\n",
       "           1.3175, -0.8071,  0.6916, -0.3937,  2.0686,  2.5239, -0.6787, -1.2884,\n",
       "           0.0348, -0.4905, -0.8758,  0.3082, -1.8752, -1.3918,  0.0506,  0.1192,\n",
       "          -1.5936,  1.2842, -0.2045, -0.1632, -0.6983,  1.0210, -1.2125, -1.0354,\n",
       "          -0.1252, -1.3401,  0.8765, -0.3613, -0.2127, -0.9300,  0.2337,  0.5694,\n",
       "          -0.7970, -0.7311]),\n",
       "  tensor([ 1.1035, -1.5433,  1.1860, -0.8523, -0.0635,  0.4510,  1.3002,  0.1770,\n",
       "           2.3679,  0.7128,  0.5019, -0.8627,  1.0971,  1.2176, -0.0253,  1.2230,\n",
       "           0.2348, -1.0937, -0.9551,  0.7563, -0.3144, -0.2089, -1.5406,  0.6065,\n",
       "          -0.4753, -1.0534,  0.6664, -0.2503,  1.2910, -0.7514,  0.3964,  0.1145,\n",
       "          -1.0096,  0.8017,  0.3327, -2.1088,  1.2515, -1.0405, -0.5504, -0.5178,\n",
       "           0.6140,  0.0615,  1.5131,  0.1351, -0.2160,  0.0821,  1.3228,  0.0627,\n",
       "           1.3925, -0.2667])),\n",
       " 'escasos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'escogieron': (tensor([-0.2071,  0.9912,  2.3360,  0.4055,  0.7379,  1.6948, -1.0438,  0.6709,\n",
       "           0.6123,  0.0389,  0.5336,  1.8020,  0.3686,  1.1937, -1.4327, -0.5469,\n",
       "          -0.1878,  0.8724,  0.2003,  1.2986, -1.3655, -1.8053,  0.5654, -2.5186,\n",
       "          -1.2608,  0.2157, -0.9663, -0.4509,  1.3603, -0.0475, -0.3833,  0.9104,\n",
       "          -1.3033, -0.5246, -0.9575,  0.8470,  0.3813, -1.4018,  0.8702, -1.1648,\n",
       "           0.4626, -0.3161, -0.4911, -1.0511, -0.1426, -0.4077, -0.5655, -1.2246,\n",
       "          -1.9450, -0.2677]),\n",
       "  tensor([ 0.1048,  0.2284,  1.4744,  0.3545, -1.2444,  0.1993, -2.3380, -1.3981,\n",
       "          -0.1750, -0.7319,  0.3237,  0.3197, -1.1482,  0.4718, -0.6388,  1.2536,\n",
       "          -0.7103, -0.0841,  1.1243, -0.7761,  1.2409,  0.9976, -1.5905,  0.0626,\n",
       "           1.4290, -1.0286, -1.4566,  0.1106, -0.2541, -0.0269, -1.8326,  0.5012,\n",
       "           1.3287,  0.2809, -0.9906, -0.7953,  0.2316,  1.0910,  0.7759, -0.5416,\n",
       "          -0.0378,  1.1453,  0.7703, -0.8104,  0.0806, -0.1433,  0.9687, -1.3541,\n",
       "           2.4616, -0.8635])),\n",
       " 'escojo': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'escritor': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'escritora': (tensor([-1.0302,  1.8940, -0.4079,  0.4973, -0.6856,  0.6196,  0.8580, -0.3535,\n",
       "          -0.2102, -0.8849, -0.5205,  1.0962,  0.0342, -2.2166, -0.0865,  0.3779,\n",
       "           0.5144,  2.0945, -1.8446,  0.3292,  1.3278, -0.1071, -0.8322, -1.1840,\n",
       "          -1.0092,  0.4897,  0.0210,  0.1585, -0.7172,  0.1938,  0.9727, -0.4677,\n",
       "          -0.6629,  1.9826, -0.3865,  1.0206, -0.1450,  0.7422, -0.8491,  0.5036,\n",
       "          -0.5266,  0.1124, -0.9507,  0.2640, -1.4579, -0.7351,  0.7958,  0.4569,\n",
       "          -1.3695, -0.0138]),\n",
       "  tensor([-0.5927, -2.1592, -1.3944,  1.3137,  0.9085,  0.6796, -1.0091,  0.4440,\n",
       "           0.1853, -0.0917,  0.3122,  0.1992, -0.3807, -0.4346,  0.3050,  0.0570,\n",
       "          -0.2602,  0.5348, -2.3362,  0.3955,  0.2087, -3.4778,  0.5780,  0.9006,\n",
       "          -0.2791, -1.0736, -0.0910, -0.2006, -0.3806, -0.9729, -0.8906,  1.2786,\n",
       "           1.7754, -1.3548,  1.2520, -0.5763,  1.6606,  0.3080, -0.1123, -0.9271,\n",
       "           2.3306, -0.2887,  0.3173, -0.6874,  0.9293, -0.8704,  1.1940,  0.7953,\n",
       "           0.1050,  0.1471])),\n",
       " 'escuch√©': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'esc√©pticos': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'ese': tensor(4.1723e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'esencial': tensor(4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'esfera': tensor(0., device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " 'esfuerzos': tensor(-4.7684e-07, device='cuda:1', grad_fn=<LogsumexpBackward>),\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dict = GetEmbeddings('./promptsl40.test', trainer)\n",
    "embedding_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
