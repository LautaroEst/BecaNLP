{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('./sk_trainers.bin', 'rb') as trainerfile:\n",
    "    sk_trainers = pickle.load(trainerfile)\n",
    "    \n",
    "with open('./cbow_trainers.bin', 'rb') as trainerfile:\n",
    "    cbow_trainers = pickle.load(trainerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas\n",
    "\n",
    "* Yo necesito que las siguientes partes del trainer estén separadas:\n",
    "\n",
    "    * La generación de muestras (con batches?) y la definición del modelo\n",
    "    * La inicilización de los parámetros\n",
    "    * El traslado del modelo y/o las muestras al device\n",
    "    * El train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de lenguaje Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con las frases de Train de Latino40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 400\n"
     ]
    }
   ],
   "source": [
    "#corpus = [['w1', 'w2', 'w3', 'w4'], ['w1', 'w3', 'w3', 'w3'], ['w1'], ['w1', 'w2', 'w3', 'w4', 'w1', 'w2', 'w3', 'w4']]\n",
    "corpus = GetTrainCorpus('./promptsl40.train')\n",
    "cutoff_freq = 0\n",
    "window_size_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "batch_size = 512\n",
    "\n",
    "state_dict = None\n",
    "device = 'cuda:1'\n",
    "paralelize = False\n",
    "embedding_dim_list = [50, 100, 150, 200, 300, 400]\n",
    "\n",
    "sk_trainers = []\n",
    "for window_size in window_size_list:\n",
    "    embedding_dim_trainers = []\n",
    "    for embedding_dim in embedding_dim_list:\n",
    "        sk_trainer = SkipGramTrainer(corpus, cutoff_freq, window_size, batch_size)\n",
    "        sk_trainer.InitModel(state_dict=state_dict, device=device, paralelize=paralelize, embedding_dim=embedding_dim)\n",
    "        embedding_dim_trainers.append(sk_trainer)\n",
    "    sk_trainers.append(embedding_dim_trainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8030.67626953125\n",
      "Epoch: 2, Batch number: 24, Loss: 7778.5224609375\n",
      "Epoch: 3, Batch number: 48, Loss: 7660.98681640625\n",
      "Epoch: 4, Batch number: 72, Loss: 7413.61376953125\n",
      "Epoch: 6, Batch number: 20, Loss: 7072.8935546875\n",
      "Epoch: 7, Batch number: 44, Loss: 7066.8876953125\n",
      "Epoch: 8, Batch number: 68, Loss: 6857.48095703125\n",
      "Epoch: 10, Batch number: 16, Loss: 6450.0283203125\n",
      "Epoch: 11, Batch number: 40, Loss: 6592.77001953125\n",
      "Epoch: 12, Batch number: 64, Loss: 6526.9814453125\n",
      "Epoch: 14, Batch number: 12, Loss: 6293.771484375\n",
      "Epoch: 15, Batch number: 36, Loss: 6032.1875\n",
      "Epoch: 16, Batch number: 60, Loss: 6055.12646484375\n",
      "Epoch: 18, Batch number: 8, Loss: 5971.427734375\n",
      "Epoch: 19, Batch number: 32, Loss: 5938.4287109375\n",
      "Epoch: 20, Batch number: 56, Loss: 5773.2060546875\n",
      "Epoch: 22, Batch number: 4, Loss: 5810.70849609375\n",
      "Epoch: 23, Batch number: 28, Loss: 5572.33984375\n",
      "Epoch: 24, Batch number: 52, Loss: 5541.17822265625\n",
      "Epoch: 26, Batch number: 0, Loss: 5381.125\n",
      "Epoch: 27, Batch number: 24, Loss: 5354.6337890625\n",
      "Epoch: 28, Batch number: 48, Loss: 5342.388671875\n",
      "Epoch: 29, Batch number: 72, Loss: 5145.025390625\n",
      "Epoch: 31, Batch number: 20, Loss: 5106.45166015625\n",
      "Epoch: 32, Batch number: 44, Loss: 4910.5283203125\n",
      "Epoch: 33, Batch number: 68, Loss: 4941.44970703125\n",
      "Epoch: 35, Batch number: 16, Loss: 4954.43701171875\n",
      "Epoch: 36, Batch number: 40, Loss: 4888.822265625\n",
      "Epoch: 37, Batch number: 64, Loss: 4868.10595703125\n",
      "Epoch: 39, Batch number: 12, Loss: 4790.134765625\n",
      "Epoch: 40, Batch number: 36, Loss: 4671.8330078125\n",
      "Epoch: 41, Batch number: 60, Loss: 4691.77197265625\n",
      "Epoch: 43, Batch number: 8, Loss: 4681.60888671875\n",
      "Epoch: 44, Batch number: 32, Loss: 4756.85302734375\n",
      "Epoch: 45, Batch number: 56, Loss: 4816.7080078125\n",
      "Epoch: 47, Batch number: 4, Loss: 4490.31103515625\n",
      "Epoch: 48, Batch number: 28, Loss: 4553.6455078125\n",
      "Epoch: 49, Batch number: 52, Loss: 4503.18017578125\n",
      "Epoch: 51, Batch number: 0, Loss: 4292.8984375\n",
      "Epoch: 52, Batch number: 24, Loss: 4648.8232421875\n",
      "Epoch: 53, Batch number: 48, Loss: 4507.79638671875\n",
      "Epoch: 54, Batch number: 72, Loss: 4520.5693359375\n",
      "Epoch: 56, Batch number: 20, Loss: 4455.27783203125\n",
      "Epoch: 57, Batch number: 44, Loss: 4345.00732421875\n",
      "Epoch: 58, Batch number: 68, Loss: 4274.89599609375\n",
      "Epoch: 60, Batch number: 16, Loss: 4209.162109375\n",
      "Epoch: 61, Batch number: 40, Loss: 4319.732421875\n",
      "Epoch: 62, Batch number: 64, Loss: 4383.69921875\n",
      "Epoch: 64, Batch number: 12, Loss: 4256.9677734375\n",
      "Epoch: 65, Batch number: 36, Loss: 4258.31884765625\n",
      "Epoch: 66, Batch number: 60, Loss: 4181.224609375\n",
      "Epoch: 68, Batch number: 8, Loss: 4148.50439453125\n",
      "Epoch: 69, Batch number: 32, Loss: 4187.64892578125\n",
      "Epoch: 70, Batch number: 56, Loss: 4223.9716796875\n",
      "Epoch: 72, Batch number: 4, Loss: 4081.32275390625\n",
      "Epoch: 73, Batch number: 28, Loss: 4098.20556640625\n",
      "Epoch: 74, Batch number: 52, Loss: 4155.302734375\n",
      "Epoch: 76, Batch number: 0, Loss: 3962.1572265625\n",
      "Epoch: 77, Batch number: 24, Loss: 3958.1630859375\n",
      "Epoch: 78, Batch number: 48, Loss: 3930.902587890625\n",
      "Epoch: 79, Batch number: 72, Loss: 4108.2763671875\n",
      "Epoch: 81, Batch number: 20, Loss: 4023.053466796875\n",
      "Epoch: 82, Batch number: 44, Loss: 3958.932373046875\n",
      "Epoch: 83, Batch number: 68, Loss: 3945.128173828125\n",
      "Epoch: 85, Batch number: 16, Loss: 3874.9912109375\n",
      "Epoch: 86, Batch number: 40, Loss: 3888.8828125\n",
      "Epoch: 87, Batch number: 64, Loss: 3950.6396484375\n",
      "Epoch: 89, Batch number: 12, Loss: 3785.42236328125\n",
      "Epoch: 90, Batch number: 36, Loss: 3757.749267578125\n",
      "Epoch: 91, Batch number: 60, Loss: 3913.876708984375\n",
      "Epoch: 93, Batch number: 8, Loss: 3804.538330078125\n",
      "Epoch: 94, Batch number: 32, Loss: 3892.53173828125\n",
      "Epoch: 95, Batch number: 56, Loss: 3808.99609375\n",
      "Epoch: 97, Batch number: 4, Loss: 3837.760986328125\n",
      "Epoch: 98, Batch number: 28, Loss: 3760.7685546875\n",
      "Epoch: 99, Batch number: 52, Loss: 3802.89111328125\n",
      "Epoch: 101, Batch number: 0, Loss: 3791.451416015625\n",
      "Epoch: 102, Batch number: 24, Loss: 3750.664794921875\n",
      "Epoch: 103, Batch number: 48, Loss: 3780.292724609375\n",
      "Epoch: 104, Batch number: 72, Loss: 3732.308349609375\n",
      "Epoch: 106, Batch number: 20, Loss: 3780.322509765625\n",
      "Epoch: 107, Batch number: 44, Loss: 3824.185546875\n",
      "Epoch: 108, Batch number: 68, Loss: 3712.94384765625\n",
      "Epoch: 110, Batch number: 16, Loss: 3757.26171875\n",
      "Epoch: 111, Batch number: 40, Loss: 3699.35498046875\n",
      "Epoch: 112, Batch number: 64, Loss: 3718.945556640625\n",
      "Epoch: 114, Batch number: 12, Loss: 3643.82080078125\n",
      "Epoch: 115, Batch number: 36, Loss: 3640.858154296875\n",
      "Epoch: 116, Batch number: 60, Loss: 3718.76513671875\n",
      "Epoch: 118, Batch number: 8, Loss: 3682.51708984375\n",
      "Epoch: 119, Batch number: 32, Loss: 3618.052490234375\n",
      "Epoch: 120, Batch number: 56, Loss: 3682.720458984375\n",
      "Epoch: 122, Batch number: 4, Loss: 3730.364013671875\n",
      "Epoch: 123, Batch number: 28, Loss: 3514.564208984375\n",
      "Epoch: 124, Batch number: 52, Loss: 3570.629150390625\n",
      "Epoch: 126, Batch number: 0, Loss: 3424.301025390625\n",
      "Epoch: 127, Batch number: 24, Loss: 3622.466552734375\n",
      "Epoch: 128, Batch number: 48, Loss: 3528.28076171875\n",
      "Epoch: 129, Batch number: 72, Loss: 3552.92822265625\n",
      "Epoch: 131, Batch number: 20, Loss: 3637.2099609375\n",
      "Epoch: 132, Batch number: 44, Loss: 3682.784912109375\n",
      "Epoch: 133, Batch number: 68, Loss: 3802.80908203125\n",
      "Epoch: 135, Batch number: 16, Loss: 3552.494384765625\n",
      "Epoch: 136, Batch number: 40, Loss: 3656.853759765625\n",
      "Epoch: 137, Batch number: 64, Loss: 3525.908203125\n",
      "Epoch: 139, Batch number: 12, Loss: 3601.952880859375\n",
      "Epoch: 140, Batch number: 36, Loss: 3577.9970703125\n",
      "Epoch: 141, Batch number: 60, Loss: 3442.78857421875\n",
      "Epoch: 143, Batch number: 8, Loss: 3548.272705078125\n",
      "Epoch: 144, Batch number: 32, Loss: 3472.285400390625\n",
      "Epoch: 145, Batch number: 56, Loss: 3386.102294921875\n",
      "Epoch: 147, Batch number: 4, Loss: 3534.35595703125\n",
      "Epoch: 148, Batch number: 28, Loss: 3314.48828125\n",
      "Epoch: 149, Batch number: 52, Loss: 3501.5361328125\n",
      "Epoch: 151, Batch number: 0, Loss: 3541.681640625\n",
      "Epoch: 152, Batch number: 24, Loss: 3456.283935546875\n",
      "Epoch: 153, Batch number: 48, Loss: 3423.515869140625\n",
      "Epoch: 154, Batch number: 72, Loss: 3607.013671875\n",
      "Epoch: 156, Batch number: 20, Loss: 3439.2119140625\n",
      "Epoch: 157, Batch number: 44, Loss: 3423.197509765625\n",
      "Epoch: 158, Batch number: 68, Loss: 3480.110595703125\n",
      "Epoch: 160, Batch number: 16, Loss: 3360.38525390625\n",
      "Epoch: 161, Batch number: 40, Loss: 3464.736328125\n",
      "Epoch: 162, Batch number: 64, Loss: 3548.638671875\n",
      "Epoch: 164, Batch number: 12, Loss: 3407.931396484375\n",
      "Epoch: 165, Batch number: 36, Loss: 3474.078369140625\n",
      "Epoch: 166, Batch number: 60, Loss: 3453.477294921875\n",
      "Epoch: 168, Batch number: 8, Loss: 3437.499267578125\n",
      "Epoch: 169, Batch number: 32, Loss: 3417.557861328125\n",
      "Epoch: 170, Batch number: 56, Loss: 3403.14501953125\n",
      "Epoch: 172, Batch number: 4, Loss: 3355.6923828125\n",
      "Epoch: 173, Batch number: 28, Loss: 3349.841796875\n",
      "Epoch: 174, Batch number: 52, Loss: 3368.161865234375\n",
      "Epoch: 176, Batch number: 0, Loss: 3420.617919921875\n",
      "Epoch: 177, Batch number: 24, Loss: 3422.865966796875\n",
      "Epoch: 178, Batch number: 48, Loss: 3645.498779296875\n",
      "Epoch: 179, Batch number: 72, Loss: 3403.0009765625\n",
      "Epoch: 181, Batch number: 20, Loss: 3358.42529296875\n",
      "Epoch: 182, Batch number: 44, Loss: 3372.947265625\n",
      "Epoch: 183, Batch number: 68, Loss: 3469.818603515625\n",
      "Epoch: 185, Batch number: 16, Loss: 3512.7158203125\n",
      "Epoch: 186, Batch number: 40, Loss: 3547.75927734375\n",
      "Epoch: 187, Batch number: 64, Loss: 3345.5419921875\n",
      "Epoch: 189, Batch number: 12, Loss: 3441.7158203125\n",
      "Epoch: 190, Batch number: 36, Loss: 3274.949462890625\n",
      "Epoch: 191, Batch number: 60, Loss: 3438.067138671875\n",
      "Epoch: 193, Batch number: 8, Loss: 3279.47412109375\n",
      "Epoch: 194, Batch number: 32, Loss: 3507.408447265625\n",
      "Epoch: 195, Batch number: 56, Loss: 3376.878173828125\n",
      "Epoch: 197, Batch number: 4, Loss: 3271.62451171875\n",
      "Epoch: 198, Batch number: 28, Loss: 3355.768310546875\n",
      "Epoch: 199, Batch number: 52, Loss: 3497.07763671875\n",
      "Epoch: 201, Batch number: 0, Loss: 3253.65380859375\n",
      "Epoch: 202, Batch number: 24, Loss: 3284.871337890625\n",
      "Epoch: 203, Batch number: 48, Loss: 3322.598388671875\n",
      "Epoch: 204, Batch number: 72, Loss: 3209.5654296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 3356.16845703125\n",
      "Epoch: 207, Batch number: 44, Loss: 3363.999267578125\n",
      "Epoch: 208, Batch number: 68, Loss: 3426.956787109375\n",
      "Epoch: 210, Batch number: 16, Loss: 3460.0888671875\n",
      "Epoch: 211, Batch number: 40, Loss: 3441.960693359375\n",
      "Epoch: 212, Batch number: 64, Loss: 3343.122314453125\n",
      "Epoch: 214, Batch number: 12, Loss: 3322.14794921875\n",
      "Epoch: 215, Batch number: 36, Loss: 3223.489990234375\n",
      "Epoch: 216, Batch number: 60, Loss: 3274.672607421875\n",
      "Epoch: 218, Batch number: 8, Loss: 3516.762451171875\n",
      "Epoch: 219, Batch number: 32, Loss: 3451.792724609375\n",
      "Epoch: 220, Batch number: 56, Loss: 3235.129150390625\n",
      "Epoch: 222, Batch number: 4, Loss: 3147.301513671875\n",
      "Epoch: 223, Batch number: 28, Loss: 3229.815673828125\n",
      "Epoch: 224, Batch number: 52, Loss: 3402.410888671875\n",
      "Epoch: 226, Batch number: 0, Loss: 3356.888427734375\n",
      "Epoch: 227, Batch number: 24, Loss: 3182.70361328125\n",
      "Epoch: 228, Batch number: 48, Loss: 3385.10498046875\n",
      "Epoch: 229, Batch number: 72, Loss: 3416.743408203125\n",
      "Epoch: 231, Batch number: 20, Loss: 3298.094970703125\n",
      "Epoch: 232, Batch number: 44, Loss: 3319.271240234375\n",
      "Epoch: 233, Batch number: 68, Loss: 3260.841064453125\n",
      "Epoch: 235, Batch number: 16, Loss: 3300.4638671875\n",
      "Epoch: 236, Batch number: 40, Loss: 3337.07861328125\n",
      "Epoch: 237, Batch number: 64, Loss: 3435.837158203125\n",
      "Epoch: 239, Batch number: 12, Loss: 3252.559326171875\n",
      "Epoch: 240, Batch number: 36, Loss: 3363.005126953125\n",
      "Epoch: 241, Batch number: 60, Loss: 3280.227783203125\n",
      "Epoch: 243, Batch number: 8, Loss: 3287.0458984375\n",
      "Epoch: 244, Batch number: 32, Loss: 3405.844482421875\n",
      "Epoch: 245, Batch number: 56, Loss: 3358.458984375\n",
      "Epoch: 247, Batch number: 4, Loss: 3368.865966796875\n",
      "Epoch: 248, Batch number: 28, Loss: 3371.89501953125\n",
      "Epoch: 249, Batch number: 52, Loss: 3314.1298828125\n",
      "Epoch: 251, Batch number: 0, Loss: 3307.158935546875\n",
      "Epoch: 252, Batch number: 24, Loss: 3268.47998046875\n",
      "Epoch: 253, Batch number: 48, Loss: 3214.616943359375\n",
      "Epoch: 254, Batch number: 72, Loss: 3342.978515625\n",
      "Epoch: 256, Batch number: 20, Loss: 3377.984619140625\n",
      "Epoch: 257, Batch number: 44, Loss: 3196.9697265625\n",
      "Epoch: 258, Batch number: 68, Loss: 3207.750732421875\n",
      "Epoch: 260, Batch number: 16, Loss: 3207.325439453125\n",
      "Epoch: 261, Batch number: 40, Loss: 3266.526123046875\n",
      "Epoch: 262, Batch number: 64, Loss: 3286.60009765625\n",
      "Epoch: 264, Batch number: 12, Loss: 3223.1591796875\n",
      "Epoch: 265, Batch number: 36, Loss: 3291.171630859375\n",
      "Epoch: 266, Batch number: 60, Loss: 3325.60888671875\n",
      "Epoch: 268, Batch number: 8, Loss: 3142.953369140625\n",
      "Epoch: 269, Batch number: 32, Loss: 3291.135009765625\n",
      "Epoch: 270, Batch number: 56, Loss: 3260.869873046875\n",
      "Epoch: 272, Batch number: 4, Loss: 3301.208251953125\n",
      "Epoch: 273, Batch number: 28, Loss: 3301.130615234375\n",
      "Epoch: 274, Batch number: 52, Loss: 3297.0224609375\n",
      "Epoch: 276, Batch number: 0, Loss: 3330.247314453125\n",
      "Epoch: 277, Batch number: 24, Loss: 3260.109375\n",
      "Epoch: 278, Batch number: 48, Loss: 3262.712890625\n",
      "Epoch: 279, Batch number: 72, Loss: 3281.256103515625\n",
      "Epoch: 281, Batch number: 20, Loss: 3265.68896484375\n",
      "Epoch: 282, Batch number: 44, Loss: 3364.178955078125\n",
      "Epoch: 283, Batch number: 68, Loss: 3347.483154296875\n",
      "Epoch: 285, Batch number: 16, Loss: 3168.556640625\n",
      "Epoch: 286, Batch number: 40, Loss: 3349.20068359375\n",
      "Epoch: 287, Batch number: 64, Loss: 3144.81201171875\n",
      "Epoch: 289, Batch number: 12, Loss: 3171.553466796875\n",
      "Epoch: 290, Batch number: 36, Loss: 3143.82373046875\n",
      "Epoch: 291, Batch number: 60, Loss: 3434.93212890625\n",
      "Epoch: 293, Batch number: 8, Loss: 3265.727783203125\n",
      "Epoch: 294, Batch number: 32, Loss: 3245.06103515625\n",
      "Epoch: 295, Batch number: 56, Loss: 3112.270263671875\n",
      "Epoch: 297, Batch number: 4, Loss: 3173.082763671875\n",
      "Epoch: 298, Batch number: 28, Loss: 3066.451416015625\n",
      "Epoch: 299, Batch number: 52, Loss: 3163.414306640625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 7935.23486328125\n",
      "Epoch: 2, Batch number: 24, Loss: 7697.95166015625\n",
      "Epoch: 3, Batch number: 48, Loss: 7321.8505859375\n",
      "Epoch: 4, Batch number: 72, Loss: 7151.8583984375\n",
      "Epoch: 6, Batch number: 20, Loss: 6619.37255859375\n",
      "Epoch: 7, Batch number: 44, Loss: 6667.4794921875\n",
      "Epoch: 8, Batch number: 68, Loss: 6443.060546875\n",
      "Epoch: 10, Batch number: 16, Loss: 5937.98583984375\n",
      "Epoch: 11, Batch number: 40, Loss: 5960.5966796875\n",
      "Epoch: 12, Batch number: 64, Loss: 5876.451171875\n",
      "Epoch: 14, Batch number: 12, Loss: 5642.3974609375\n",
      "Epoch: 15, Batch number: 36, Loss: 5502.20361328125\n",
      "Epoch: 16, Batch number: 60, Loss: 5385.2861328125\n",
      "Epoch: 18, Batch number: 8, Loss: 5207.33154296875\n",
      "Epoch: 19, Batch number: 32, Loss: 5161.62744140625\n",
      "Epoch: 20, Batch number: 56, Loss: 4983.78662109375\n",
      "Epoch: 22, Batch number: 4, Loss: 4797.13720703125\n",
      "Epoch: 23, Batch number: 28, Loss: 4744.37353515625\n",
      "Epoch: 24, Batch number: 52, Loss: 4717.25048828125\n",
      "Epoch: 26, Batch number: 0, Loss: 4499.7734375\n",
      "Epoch: 27, Batch number: 24, Loss: 4507.20947265625\n",
      "Epoch: 28, Batch number: 48, Loss: 4418.39013671875\n",
      "Epoch: 29, Batch number: 72, Loss: 4534.66552734375\n",
      "Epoch: 31, Batch number: 20, Loss: 4359.2080078125\n",
      "Epoch: 32, Batch number: 44, Loss: 4455.51123046875\n",
      "Epoch: 33, Batch number: 68, Loss: 4434.66650390625\n",
      "Epoch: 35, Batch number: 16, Loss: 4133.451171875\n",
      "Epoch: 36, Batch number: 40, Loss: 4226.1884765625\n",
      "Epoch: 37, Batch number: 64, Loss: 4210.04638671875\n",
      "Epoch: 39, Batch number: 12, Loss: 4061.563720703125\n",
      "Epoch: 40, Batch number: 36, Loss: 4050.912109375\n",
      "Epoch: 41, Batch number: 60, Loss: 4123.18701171875\n",
      "Epoch: 43, Batch number: 8, Loss: 3952.077392578125\n",
      "Epoch: 44, Batch number: 32, Loss: 4015.69775390625\n",
      "Epoch: 45, Batch number: 56, Loss: 3926.638427734375\n",
      "Epoch: 47, Batch number: 4, Loss: 3907.48779296875\n",
      "Epoch: 48, Batch number: 28, Loss: 3853.18994140625\n",
      "Epoch: 49, Batch number: 52, Loss: 3880.416015625\n",
      "Epoch: 51, Batch number: 0, Loss: 3698.1201171875\n",
      "Epoch: 52, Batch number: 24, Loss: 3915.55908203125\n",
      "Epoch: 53, Batch number: 48, Loss: 3773.75927734375\n",
      "Epoch: 54, Batch number: 72, Loss: 3778.03125\n",
      "Epoch: 56, Batch number: 20, Loss: 3698.108642578125\n",
      "Epoch: 57, Batch number: 44, Loss: 3783.814453125\n",
      "Epoch: 58, Batch number: 68, Loss: 3875.132080078125\n",
      "Epoch: 60, Batch number: 16, Loss: 3703.733154296875\n",
      "Epoch: 61, Batch number: 40, Loss: 3732.533203125\n",
      "Epoch: 62, Batch number: 64, Loss: 3691.53076171875\n",
      "Epoch: 64, Batch number: 12, Loss: 3591.818115234375\n",
      "Epoch: 65, Batch number: 36, Loss: 3594.033203125\n",
      "Epoch: 66, Batch number: 60, Loss: 3653.203369140625\n",
      "Epoch: 68, Batch number: 8, Loss: 3656.205810546875\n",
      "Epoch: 69, Batch number: 32, Loss: 3577.058349609375\n",
      "Epoch: 70, Batch number: 56, Loss: 3473.149169921875\n",
      "Epoch: 72, Batch number: 4, Loss: 3546.714599609375\n",
      "Epoch: 73, Batch number: 28, Loss: 3517.95361328125\n",
      "Epoch: 74, Batch number: 52, Loss: 3648.306884765625\n",
      "Epoch: 76, Batch number: 0, Loss: 3482.711669921875\n",
      "Epoch: 77, Batch number: 24, Loss: 3597.820556640625\n",
      "Epoch: 78, Batch number: 48, Loss: 3436.959228515625\n",
      "Epoch: 79, Batch number: 72, Loss: 3434.65380859375\n",
      "Epoch: 81, Batch number: 20, Loss: 3412.979736328125\n",
      "Epoch: 82, Batch number: 44, Loss: 3463.900146484375\n",
      "Epoch: 83, Batch number: 68, Loss: 3534.26806640625\n",
      "Epoch: 85, Batch number: 16, Loss: 3361.90380859375\n",
      "Epoch: 86, Batch number: 40, Loss: 3515.7001953125\n",
      "Epoch: 87, Batch number: 64, Loss: 3373.3427734375\n",
      "Epoch: 89, Batch number: 12, Loss: 3438.21044921875\n",
      "Epoch: 90, Batch number: 36, Loss: 3374.89013671875\n",
      "Epoch: 91, Batch number: 60, Loss: 3533.138427734375\n",
      "Epoch: 93, Batch number: 8, Loss: 3475.31298828125\n",
      "Epoch: 94, Batch number: 32, Loss: 3308.574951171875\n",
      "Epoch: 95, Batch number: 56, Loss: 3487.03076171875\n",
      "Epoch: 97, Batch number: 4, Loss: 3395.895751953125\n",
      "Epoch: 98, Batch number: 28, Loss: 3335.202392578125\n",
      "Epoch: 99, Batch number: 52, Loss: 3320.335205078125\n",
      "Epoch: 101, Batch number: 0, Loss: 3314.47705078125\n",
      "Epoch: 102, Batch number: 24, Loss: 3362.72509765625\n",
      "Epoch: 103, Batch number: 48, Loss: 3300.2626953125\n",
      "Epoch: 104, Batch number: 72, Loss: 3335.4560546875\n",
      "Epoch: 106, Batch number: 20, Loss: 3344.428955078125\n",
      "Epoch: 107, Batch number: 44, Loss: 3448.7470703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Batch number: 68, Loss: 3299.842529296875\n",
      "Epoch: 110, Batch number: 16, Loss: 3214.678955078125\n",
      "Epoch: 111, Batch number: 40, Loss: 3318.345947265625\n",
      "Epoch: 112, Batch number: 64, Loss: 3271.87744140625\n",
      "Epoch: 114, Batch number: 12, Loss: 3385.904052734375\n",
      "Epoch: 115, Batch number: 36, Loss: 3273.841796875\n",
      "Epoch: 116, Batch number: 60, Loss: 3308.88427734375\n",
      "Epoch: 118, Batch number: 8, Loss: 3283.134033203125\n",
      "Epoch: 119, Batch number: 32, Loss: 3356.568359375\n",
      "Epoch: 120, Batch number: 56, Loss: 3252.722412109375\n",
      "Epoch: 122, Batch number: 4, Loss: 3248.814453125\n",
      "Epoch: 123, Batch number: 28, Loss: 3209.739990234375\n",
      "Epoch: 124, Batch number: 52, Loss: 3468.196533203125\n",
      "Epoch: 126, Batch number: 0, Loss: 3236.68896484375\n",
      "Epoch: 127, Batch number: 24, Loss: 3304.306884765625\n",
      "Epoch: 128, Batch number: 48, Loss: 3324.38037109375\n",
      "Epoch: 129, Batch number: 72, Loss: 3349.521240234375\n",
      "Epoch: 131, Batch number: 20, Loss: 3194.63232421875\n",
      "Epoch: 132, Batch number: 44, Loss: 3453.68701171875\n",
      "Epoch: 133, Batch number: 68, Loss: 3245.23779296875\n",
      "Epoch: 135, Batch number: 16, Loss: 3297.968505859375\n",
      "Epoch: 136, Batch number: 40, Loss: 3283.601318359375\n",
      "Epoch: 137, Batch number: 64, Loss: 3202.07470703125\n",
      "Epoch: 139, Batch number: 12, Loss: 3145.741943359375\n",
      "Epoch: 140, Batch number: 36, Loss: 3218.73291015625\n",
      "Epoch: 141, Batch number: 60, Loss: 3166.71728515625\n",
      "Epoch: 143, Batch number: 8, Loss: 3172.38232421875\n",
      "Epoch: 144, Batch number: 32, Loss: 3273.6396484375\n",
      "Epoch: 145, Batch number: 56, Loss: 3321.656494140625\n",
      "Epoch: 147, Batch number: 4, Loss: 3275.49267578125\n",
      "Epoch: 148, Batch number: 28, Loss: 3205.584716796875\n",
      "Epoch: 149, Batch number: 52, Loss: 3249.046630859375\n",
      "Epoch: 151, Batch number: 0, Loss: 3234.70556640625\n",
      "Epoch: 152, Batch number: 24, Loss: 3241.29833984375\n",
      "Epoch: 153, Batch number: 48, Loss: 3241.379150390625\n",
      "Epoch: 154, Batch number: 72, Loss: 3189.127685546875\n",
      "Epoch: 156, Batch number: 20, Loss: 3183.884521484375\n",
      "Epoch: 157, Batch number: 44, Loss: 3163.961181640625\n",
      "Epoch: 158, Batch number: 68, Loss: 3353.072265625\n",
      "Epoch: 160, Batch number: 16, Loss: 3044.965576171875\n",
      "Epoch: 161, Batch number: 40, Loss: 3321.828125\n",
      "Epoch: 162, Batch number: 64, Loss: 3336.01904296875\n",
      "Epoch: 164, Batch number: 12, Loss: 3193.049560546875\n",
      "Epoch: 165, Batch number: 36, Loss: 3180.0087890625\n",
      "Epoch: 166, Batch number: 60, Loss: 3270.87939453125\n",
      "Epoch: 168, Batch number: 8, Loss: 3062.96484375\n",
      "Epoch: 169, Batch number: 32, Loss: 3050.614501953125\n",
      "Epoch: 170, Batch number: 56, Loss: 3185.401123046875\n",
      "Epoch: 172, Batch number: 4, Loss: 3359.51123046875\n",
      "Epoch: 173, Batch number: 28, Loss: 3271.334716796875\n",
      "Epoch: 174, Batch number: 52, Loss: 3155.44580078125\n",
      "Epoch: 176, Batch number: 0, Loss: 3132.4345703125\n",
      "Epoch: 177, Batch number: 24, Loss: 3256.1669921875\n",
      "Epoch: 178, Batch number: 48, Loss: 3212.94189453125\n",
      "Epoch: 179, Batch number: 72, Loss: 3220.47265625\n",
      "Epoch: 181, Batch number: 20, Loss: 3238.485107421875\n",
      "Epoch: 182, Batch number: 44, Loss: 3242.86865234375\n",
      "Epoch: 183, Batch number: 68, Loss: 3215.311279296875\n",
      "Epoch: 185, Batch number: 16, Loss: 3224.151123046875\n",
      "Epoch: 186, Batch number: 40, Loss: 3250.982421875\n",
      "Epoch: 187, Batch number: 64, Loss: 3119.877685546875\n",
      "Epoch: 189, Batch number: 12, Loss: 3299.41943359375\n",
      "Epoch: 190, Batch number: 36, Loss: 3164.181640625\n",
      "Epoch: 191, Batch number: 60, Loss: 3274.779541015625\n",
      "Epoch: 193, Batch number: 8, Loss: 3253.973388671875\n",
      "Epoch: 194, Batch number: 32, Loss: 3328.615234375\n",
      "Epoch: 195, Batch number: 56, Loss: 3344.14404296875\n",
      "Epoch: 197, Batch number: 4, Loss: 3250.8271484375\n",
      "Epoch: 198, Batch number: 28, Loss: 3324.87841796875\n",
      "Epoch: 199, Batch number: 52, Loss: 3290.03955078125\n",
      "Epoch: 201, Batch number: 0, Loss: 3178.654052734375\n",
      "Epoch: 202, Batch number: 24, Loss: 3159.56103515625\n",
      "Epoch: 203, Batch number: 48, Loss: 3264.384521484375\n",
      "Epoch: 204, Batch number: 72, Loss: 3255.5244140625\n",
      "Epoch: 206, Batch number: 20, Loss: 3183.483154296875\n",
      "Epoch: 207, Batch number: 44, Loss: 3214.7080078125\n",
      "Epoch: 208, Batch number: 68, Loss: 3336.19580078125\n",
      "Epoch: 210, Batch number: 16, Loss: 3214.754638671875\n",
      "Epoch: 211, Batch number: 40, Loss: 3287.30224609375\n",
      "Epoch: 212, Batch number: 64, Loss: 3288.2001953125\n",
      "Epoch: 214, Batch number: 12, Loss: 2997.85498046875\n",
      "Epoch: 215, Batch number: 36, Loss: 3308.14453125\n",
      "Epoch: 216, Batch number: 60, Loss: 3335.237060546875\n",
      "Epoch: 218, Batch number: 8, Loss: 3294.048583984375\n",
      "Epoch: 219, Batch number: 32, Loss: 3194.82177734375\n",
      "Epoch: 220, Batch number: 56, Loss: 3224.90673828125\n",
      "Epoch: 222, Batch number: 4, Loss: 3078.86181640625\n",
      "Epoch: 223, Batch number: 28, Loss: 3332.44384765625\n",
      "Epoch: 224, Batch number: 52, Loss: 3176.65087890625\n",
      "Epoch: 226, Batch number: 0, Loss: 3183.744873046875\n",
      "Epoch: 227, Batch number: 24, Loss: 3306.9990234375\n",
      "Epoch: 228, Batch number: 48, Loss: 3221.14990234375\n",
      "Epoch: 229, Batch number: 72, Loss: 3168.737548828125\n",
      "Epoch: 231, Batch number: 20, Loss: 3125.146484375\n",
      "Epoch: 232, Batch number: 44, Loss: 3180.807861328125\n",
      "Epoch: 233, Batch number: 68, Loss: 3078.601318359375\n",
      "Epoch: 235, Batch number: 16, Loss: 3090.782958984375\n",
      "Epoch: 236, Batch number: 40, Loss: 3250.04736328125\n",
      "Epoch: 237, Batch number: 64, Loss: 3286.241943359375\n",
      "Epoch: 239, Batch number: 12, Loss: 3122.927001953125\n",
      "Epoch: 240, Batch number: 36, Loss: 3243.1513671875\n",
      "Epoch: 241, Batch number: 60, Loss: 3274.360107421875\n",
      "Epoch: 243, Batch number: 8, Loss: 3114.280517578125\n",
      "Epoch: 244, Batch number: 32, Loss: 3252.046875\n",
      "Epoch: 245, Batch number: 56, Loss: 3249.104248046875\n",
      "Epoch: 247, Batch number: 4, Loss: 3175.718994140625\n",
      "Epoch: 248, Batch number: 28, Loss: 3146.74169921875\n",
      "Epoch: 249, Batch number: 52, Loss: 3255.111083984375\n",
      "Epoch: 251, Batch number: 0, Loss: 3085.466796875\n",
      "Epoch: 252, Batch number: 24, Loss: 3071.841796875\n",
      "Epoch: 253, Batch number: 48, Loss: 3139.41845703125\n",
      "Epoch: 254, Batch number: 72, Loss: 3283.610595703125\n",
      "Epoch: 256, Batch number: 20, Loss: 3103.71484375\n",
      "Epoch: 257, Batch number: 44, Loss: 3217.677490234375\n",
      "Epoch: 258, Batch number: 68, Loss: 3230.93994140625\n",
      "Epoch: 260, Batch number: 16, Loss: 3199.598876953125\n",
      "Epoch: 261, Batch number: 40, Loss: 3224.9638671875\n",
      "Epoch: 262, Batch number: 64, Loss: 3302.4072265625\n",
      "Epoch: 264, Batch number: 12, Loss: 3084.232421875\n",
      "Epoch: 265, Batch number: 36, Loss: 3100.908203125\n",
      "Epoch: 266, Batch number: 60, Loss: 3301.439697265625\n",
      "Epoch: 268, Batch number: 8, Loss: 3229.798095703125\n",
      "Epoch: 269, Batch number: 32, Loss: 3115.089111328125\n",
      "Epoch: 270, Batch number: 56, Loss: 3248.874755859375\n",
      "Epoch: 272, Batch number: 4, Loss: 3270.3447265625\n",
      "Epoch: 273, Batch number: 28, Loss: 3274.8916015625\n",
      "Epoch: 274, Batch number: 52, Loss: 3242.09716796875\n",
      "Epoch: 276, Batch number: 0, Loss: 3264.756103515625\n",
      "Epoch: 277, Batch number: 24, Loss: 3116.13720703125\n",
      "Epoch: 278, Batch number: 48, Loss: 3178.209716796875\n",
      "Epoch: 279, Batch number: 72, Loss: 3373.06494140625\n",
      "Epoch: 281, Batch number: 20, Loss: 3207.11376953125\n",
      "Epoch: 282, Batch number: 44, Loss: 3224.13134765625\n",
      "Epoch: 283, Batch number: 68, Loss: 3133.311279296875\n",
      "Epoch: 285, Batch number: 16, Loss: 3302.12890625\n",
      "Epoch: 286, Batch number: 40, Loss: 3262.77587890625\n",
      "Epoch: 287, Batch number: 64, Loss: 3139.38671875\n",
      "Epoch: 289, Batch number: 12, Loss: 3200.34765625\n",
      "Epoch: 290, Batch number: 36, Loss: 3024.2880859375\n",
      "Epoch: 291, Batch number: 60, Loss: 3278.79736328125\n",
      "Epoch: 293, Batch number: 8, Loss: 3001.056640625\n",
      "Epoch: 294, Batch number: 32, Loss: 3272.087890625\n",
      "Epoch: 295, Batch number: 56, Loss: 3082.103759765625\n",
      "Epoch: 297, Batch number: 4, Loss: 3140.33984375\n",
      "Epoch: 298, Batch number: 28, Loss: 3075.93701171875\n",
      "Epoch: 299, Batch number: 52, Loss: 3187.220947265625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8128.650390625\n",
      "Epoch: 2, Batch number: 24, Loss: 7527.32861328125\n",
      "Epoch: 3, Batch number: 48, Loss: 7087.21240234375\n",
      "Epoch: 4, Batch number: 72, Loss: 6864.61865234375\n",
      "Epoch: 6, Batch number: 20, Loss: 6492.37158203125\n",
      "Epoch: 7, Batch number: 44, Loss: 6251.666015625\n",
      "Epoch: 8, Batch number: 68, Loss: 6017.5078125\n",
      "Epoch: 10, Batch number: 16, Loss: 5677.7783203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Batch number: 40, Loss: 5643.5380859375\n",
      "Epoch: 12, Batch number: 64, Loss: 5431.52490234375\n",
      "Epoch: 14, Batch number: 12, Loss: 5230.212890625\n",
      "Epoch: 15, Batch number: 36, Loss: 5156.35546875\n",
      "Epoch: 16, Batch number: 60, Loss: 4864.15625\n",
      "Epoch: 18, Batch number: 8, Loss: 4855.09033203125\n",
      "Epoch: 19, Batch number: 32, Loss: 4614.7841796875\n",
      "Epoch: 20, Batch number: 56, Loss: 4489.01708984375\n",
      "Epoch: 22, Batch number: 4, Loss: 4454.41259765625\n",
      "Epoch: 23, Batch number: 28, Loss: 4446.154296875\n",
      "Epoch: 24, Batch number: 52, Loss: 4428.8046875\n",
      "Epoch: 26, Batch number: 0, Loss: 4182.6767578125\n",
      "Epoch: 27, Batch number: 24, Loss: 4151.59521484375\n",
      "Epoch: 28, Batch number: 48, Loss: 4122.302734375\n",
      "Epoch: 29, Batch number: 72, Loss: 4224.4453125\n",
      "Epoch: 31, Batch number: 20, Loss: 4007.268310546875\n",
      "Epoch: 32, Batch number: 44, Loss: 4108.00927734375\n",
      "Epoch: 33, Batch number: 68, Loss: 4031.45849609375\n",
      "Epoch: 35, Batch number: 16, Loss: 3892.5458984375\n",
      "Epoch: 36, Batch number: 40, Loss: 3823.143310546875\n",
      "Epoch: 37, Batch number: 64, Loss: 3932.555908203125\n",
      "Epoch: 39, Batch number: 12, Loss: 3826.19384765625\n",
      "Epoch: 40, Batch number: 36, Loss: 3730.246337890625\n",
      "Epoch: 41, Batch number: 60, Loss: 3699.539794921875\n",
      "Epoch: 43, Batch number: 8, Loss: 3559.479736328125\n",
      "Epoch: 44, Batch number: 32, Loss: 3552.59912109375\n",
      "Epoch: 45, Batch number: 56, Loss: 3541.068115234375\n",
      "Epoch: 47, Batch number: 4, Loss: 3624.177001953125\n",
      "Epoch: 48, Batch number: 28, Loss: 3691.827880859375\n",
      "Epoch: 49, Batch number: 52, Loss: 3604.542724609375\n",
      "Epoch: 51, Batch number: 0, Loss: 3479.241455078125\n",
      "Epoch: 52, Batch number: 24, Loss: 3492.29345703125\n",
      "Epoch: 53, Batch number: 48, Loss: 3473.322998046875\n",
      "Epoch: 54, Batch number: 72, Loss: 3510.06884765625\n",
      "Epoch: 56, Batch number: 20, Loss: 3442.993896484375\n",
      "Epoch: 57, Batch number: 44, Loss: 3540.03515625\n",
      "Epoch: 58, Batch number: 68, Loss: 3432.8408203125\n",
      "Epoch: 60, Batch number: 16, Loss: 3395.376708984375\n",
      "Epoch: 61, Batch number: 40, Loss: 3550.451904296875\n",
      "Epoch: 62, Batch number: 64, Loss: 3477.5390625\n",
      "Epoch: 64, Batch number: 12, Loss: 3318.9765625\n",
      "Epoch: 65, Batch number: 36, Loss: 3483.790283203125\n",
      "Epoch: 66, Batch number: 60, Loss: 3500.65625\n",
      "Epoch: 68, Batch number: 8, Loss: 3543.078857421875\n",
      "Epoch: 69, Batch number: 32, Loss: 3298.642822265625\n",
      "Epoch: 70, Batch number: 56, Loss: 3502.4580078125\n",
      "Epoch: 72, Batch number: 4, Loss: 3180.859130859375\n",
      "Epoch: 73, Batch number: 28, Loss: 3358.87451171875\n",
      "Epoch: 74, Batch number: 52, Loss: 3358.73779296875\n",
      "Epoch: 76, Batch number: 0, Loss: 3342.373779296875\n",
      "Epoch: 77, Batch number: 24, Loss: 3271.322998046875\n",
      "Epoch: 78, Batch number: 48, Loss: 3463.556396484375\n",
      "Epoch: 79, Batch number: 72, Loss: 3479.9482421875\n",
      "Epoch: 81, Batch number: 20, Loss: 3352.795654296875\n",
      "Epoch: 82, Batch number: 44, Loss: 3501.22265625\n",
      "Epoch: 83, Batch number: 68, Loss: 3330.40234375\n",
      "Epoch: 85, Batch number: 16, Loss: 3277.349853515625\n",
      "Epoch: 86, Batch number: 40, Loss: 3369.637451171875\n",
      "Epoch: 87, Batch number: 64, Loss: 3368.0712890625\n",
      "Epoch: 89, Batch number: 12, Loss: 3411.08447265625\n",
      "Epoch: 90, Batch number: 36, Loss: 3337.43896484375\n",
      "Epoch: 91, Batch number: 60, Loss: 3339.6103515625\n",
      "Epoch: 93, Batch number: 8, Loss: 3270.48291015625\n",
      "Epoch: 94, Batch number: 32, Loss: 3254.390869140625\n",
      "Epoch: 95, Batch number: 56, Loss: 3308.303466796875\n",
      "Epoch: 97, Batch number: 4, Loss: 3209.66845703125\n",
      "Epoch: 98, Batch number: 28, Loss: 3160.4658203125\n",
      "Epoch: 99, Batch number: 52, Loss: 3368.452392578125\n",
      "Epoch: 101, Batch number: 0, Loss: 3182.33154296875\n",
      "Epoch: 102, Batch number: 24, Loss: 3181.058837890625\n",
      "Epoch: 103, Batch number: 48, Loss: 3211.83837890625\n",
      "Epoch: 104, Batch number: 72, Loss: 3382.93994140625\n",
      "Epoch: 106, Batch number: 20, Loss: 3221.523193359375\n",
      "Epoch: 107, Batch number: 44, Loss: 3260.2548828125\n",
      "Epoch: 108, Batch number: 68, Loss: 3226.326171875\n",
      "Epoch: 110, Batch number: 16, Loss: 3306.7177734375\n",
      "Epoch: 111, Batch number: 40, Loss: 3165.490966796875\n",
      "Epoch: 112, Batch number: 64, Loss: 3318.970703125\n",
      "Epoch: 114, Batch number: 12, Loss: 3258.417724609375\n",
      "Epoch: 115, Batch number: 36, Loss: 3308.641357421875\n",
      "Epoch: 116, Batch number: 60, Loss: 3360.05810546875\n",
      "Epoch: 118, Batch number: 8, Loss: 3312.8505859375\n",
      "Epoch: 119, Batch number: 32, Loss: 3173.7919921875\n",
      "Epoch: 120, Batch number: 56, Loss: 3231.1357421875\n",
      "Epoch: 122, Batch number: 4, Loss: 3156.34326171875\n",
      "Epoch: 123, Batch number: 28, Loss: 3330.4013671875\n",
      "Epoch: 124, Batch number: 52, Loss: 3337.232177734375\n",
      "Epoch: 126, Batch number: 0, Loss: 3161.18701171875\n",
      "Epoch: 127, Batch number: 24, Loss: 3146.745849609375\n",
      "Epoch: 128, Batch number: 48, Loss: 3158.18310546875\n",
      "Epoch: 129, Batch number: 72, Loss: 3247.725830078125\n",
      "Epoch: 131, Batch number: 20, Loss: 3175.9169921875\n",
      "Epoch: 132, Batch number: 44, Loss: 3328.122802734375\n",
      "Epoch: 133, Batch number: 68, Loss: 3241.843017578125\n",
      "Epoch: 135, Batch number: 16, Loss: 3263.5517578125\n",
      "Epoch: 136, Batch number: 40, Loss: 3096.59375\n",
      "Epoch: 137, Batch number: 64, Loss: 3295.308837890625\n",
      "Epoch: 139, Batch number: 12, Loss: 3200.826416015625\n",
      "Epoch: 140, Batch number: 36, Loss: 3107.20166015625\n",
      "Epoch: 141, Batch number: 60, Loss: 3271.40380859375\n",
      "Epoch: 143, Batch number: 8, Loss: 3307.099365234375\n",
      "Epoch: 144, Batch number: 32, Loss: 3261.61865234375\n",
      "Epoch: 145, Batch number: 56, Loss: 3280.685546875\n",
      "Epoch: 147, Batch number: 4, Loss: 3184.39697265625\n",
      "Epoch: 148, Batch number: 28, Loss: 3191.55615234375\n",
      "Epoch: 149, Batch number: 52, Loss: 3296.080322265625\n",
      "Epoch: 151, Batch number: 0, Loss: 3214.261474609375\n",
      "Epoch: 152, Batch number: 24, Loss: 3071.274658203125\n",
      "Epoch: 153, Batch number: 48, Loss: 3229.575927734375\n",
      "Epoch: 154, Batch number: 72, Loss: 3264.89599609375\n",
      "Epoch: 156, Batch number: 20, Loss: 3192.15185546875\n",
      "Epoch: 157, Batch number: 44, Loss: 3016.1748046875\n",
      "Epoch: 158, Batch number: 68, Loss: 3252.72216796875\n",
      "Epoch: 160, Batch number: 16, Loss: 3113.684326171875\n",
      "Epoch: 161, Batch number: 40, Loss: 3330.51708984375\n",
      "Epoch: 162, Batch number: 64, Loss: 3280.4296875\n",
      "Epoch: 164, Batch number: 12, Loss: 3147.234130859375\n",
      "Epoch: 165, Batch number: 36, Loss: 3186.769775390625\n",
      "Epoch: 166, Batch number: 60, Loss: 3216.98681640625\n",
      "Epoch: 168, Batch number: 8, Loss: 3032.85107421875\n",
      "Epoch: 169, Batch number: 32, Loss: 3129.930908203125\n",
      "Epoch: 170, Batch number: 56, Loss: 3170.19921875\n",
      "Epoch: 172, Batch number: 4, Loss: 3128.82080078125\n",
      "Epoch: 173, Batch number: 28, Loss: 3151.349853515625\n",
      "Epoch: 174, Batch number: 52, Loss: 3094.08447265625\n",
      "Epoch: 176, Batch number: 0, Loss: 3127.517333984375\n",
      "Epoch: 177, Batch number: 24, Loss: 3249.38232421875\n",
      "Epoch: 178, Batch number: 48, Loss: 3200.06494140625\n",
      "Epoch: 179, Batch number: 72, Loss: 3159.7001953125\n",
      "Epoch: 181, Batch number: 20, Loss: 3033.068603515625\n",
      "Epoch: 182, Batch number: 44, Loss: 3119.00634765625\n",
      "Epoch: 183, Batch number: 68, Loss: 3176.53173828125\n",
      "Epoch: 185, Batch number: 16, Loss: 3204.0859375\n",
      "Epoch: 186, Batch number: 40, Loss: 3186.389892578125\n",
      "Epoch: 187, Batch number: 64, Loss: 3126.284423828125\n",
      "Epoch: 189, Batch number: 12, Loss: 3186.199462890625\n",
      "Epoch: 190, Batch number: 36, Loss: 3275.082275390625\n",
      "Epoch: 191, Batch number: 60, Loss: 3240.191162109375\n",
      "Epoch: 193, Batch number: 8, Loss: 3194.2119140625\n",
      "Epoch: 194, Batch number: 32, Loss: 3240.397216796875\n",
      "Epoch: 195, Batch number: 56, Loss: 3226.973876953125\n",
      "Epoch: 197, Batch number: 4, Loss: 3086.091796875\n",
      "Epoch: 198, Batch number: 28, Loss: 3091.69091796875\n",
      "Epoch: 199, Batch number: 52, Loss: 3214.09130859375\n",
      "Epoch: 201, Batch number: 0, Loss: 3253.736328125\n",
      "Epoch: 202, Batch number: 24, Loss: 3226.572021484375\n",
      "Epoch: 203, Batch number: 48, Loss: 3110.3544921875\n",
      "Epoch: 204, Batch number: 72, Loss: 3198.907958984375\n",
      "Epoch: 206, Batch number: 20, Loss: 3296.163330078125\n",
      "Epoch: 207, Batch number: 44, Loss: 3112.189453125\n",
      "Epoch: 208, Batch number: 68, Loss: 3015.277587890625\n",
      "Epoch: 210, Batch number: 16, Loss: 3126.23046875\n",
      "Epoch: 211, Batch number: 40, Loss: 3130.283447265625\n",
      "Epoch: 212, Batch number: 64, Loss: 3260.189208984375\n",
      "Epoch: 214, Batch number: 12, Loss: 3086.8251953125\n",
      "Epoch: 215, Batch number: 36, Loss: 3174.958740234375\n",
      "Epoch: 216, Batch number: 60, Loss: 3340.0703125\n",
      "Epoch: 218, Batch number: 8, Loss: 3124.25634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219, Batch number: 32, Loss: 3161.0810546875\n",
      "Epoch: 220, Batch number: 56, Loss: 3411.954345703125\n",
      "Epoch: 222, Batch number: 4, Loss: 3107.835205078125\n",
      "Epoch: 223, Batch number: 28, Loss: 3265.247314453125\n",
      "Epoch: 224, Batch number: 52, Loss: 3241.4501953125\n",
      "Epoch: 226, Batch number: 0, Loss: 3277.532470703125\n",
      "Epoch: 227, Batch number: 24, Loss: 3176.315185546875\n",
      "Epoch: 228, Batch number: 48, Loss: 3333.126708984375\n",
      "Epoch: 229, Batch number: 72, Loss: 3196.651123046875\n",
      "Epoch: 231, Batch number: 20, Loss: 3211.433349609375\n",
      "Epoch: 232, Batch number: 44, Loss: 3115.51171875\n",
      "Epoch: 233, Batch number: 68, Loss: 3181.314453125\n",
      "Epoch: 235, Batch number: 16, Loss: 3196.893310546875\n",
      "Epoch: 236, Batch number: 40, Loss: 3214.510986328125\n",
      "Epoch: 237, Batch number: 64, Loss: 3157.139404296875\n",
      "Epoch: 239, Batch number: 12, Loss: 3143.700927734375\n",
      "Epoch: 240, Batch number: 36, Loss: 3224.060791015625\n",
      "Epoch: 241, Batch number: 60, Loss: 3342.64306640625\n",
      "Epoch: 243, Batch number: 8, Loss: 3007.709228515625\n",
      "Epoch: 244, Batch number: 32, Loss: 3294.98583984375\n",
      "Epoch: 245, Batch number: 56, Loss: 3229.82373046875\n",
      "Epoch: 247, Batch number: 4, Loss: 3156.37744140625\n",
      "Epoch: 248, Batch number: 28, Loss: 3184.765380859375\n",
      "Epoch: 249, Batch number: 52, Loss: 3112.42919921875\n",
      "Epoch: 251, Batch number: 0, Loss: 3159.677001953125\n",
      "Epoch: 252, Batch number: 24, Loss: 3227.73095703125\n",
      "Epoch: 253, Batch number: 48, Loss: 3042.134033203125\n",
      "Epoch: 254, Batch number: 72, Loss: 3187.7509765625\n",
      "Epoch: 256, Batch number: 20, Loss: 3147.205078125\n",
      "Epoch: 257, Batch number: 44, Loss: 3303.095947265625\n",
      "Epoch: 258, Batch number: 68, Loss: 3263.30078125\n",
      "Epoch: 260, Batch number: 16, Loss: 3256.25146484375\n",
      "Epoch: 261, Batch number: 40, Loss: 3283.569580078125\n",
      "Epoch: 262, Batch number: 64, Loss: 3171.332275390625\n",
      "Epoch: 264, Batch number: 12, Loss: 3204.42138671875\n",
      "Epoch: 265, Batch number: 36, Loss: 3163.388427734375\n",
      "Epoch: 266, Batch number: 60, Loss: 3135.08837890625\n",
      "Epoch: 268, Batch number: 8, Loss: 3124.0927734375\n",
      "Epoch: 269, Batch number: 32, Loss: 3259.76953125\n",
      "Epoch: 270, Batch number: 56, Loss: 3026.720458984375\n",
      "Epoch: 272, Batch number: 4, Loss: 3035.9970703125\n",
      "Epoch: 273, Batch number: 28, Loss: 3265.205322265625\n",
      "Epoch: 274, Batch number: 52, Loss: 3229.828369140625\n",
      "Epoch: 276, Batch number: 0, Loss: 3097.9150390625\n",
      "Epoch: 277, Batch number: 24, Loss: 3155.228271484375\n",
      "Epoch: 278, Batch number: 48, Loss: 3174.03564453125\n",
      "Epoch: 279, Batch number: 72, Loss: 3133.757080078125\n",
      "Epoch: 281, Batch number: 20, Loss: 3183.848876953125\n",
      "Epoch: 282, Batch number: 44, Loss: 3167.875732421875\n",
      "Epoch: 283, Batch number: 68, Loss: 3337.11865234375\n",
      "Epoch: 285, Batch number: 16, Loss: 3259.124755859375\n",
      "Epoch: 286, Batch number: 40, Loss: 3090.3642578125\n",
      "Epoch: 287, Batch number: 64, Loss: 3310.41455078125\n",
      "Epoch: 289, Batch number: 12, Loss: 3189.6640625\n",
      "Epoch: 290, Batch number: 36, Loss: 3282.05859375\n",
      "Epoch: 291, Batch number: 60, Loss: 3165.685546875\n",
      "Epoch: 293, Batch number: 8, Loss: 3068.131591796875\n",
      "Epoch: 294, Batch number: 32, Loss: 3347.759765625\n",
      "Epoch: 295, Batch number: 56, Loss: 3127.73583984375\n",
      "Epoch: 297, Batch number: 4, Loss: 3173.169677734375\n",
      "Epoch: 298, Batch number: 28, Loss: 3242.314697265625\n",
      "Epoch: 299, Batch number: 52, Loss: 3106.0068359375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8079.47607421875\n",
      "Epoch: 2, Batch number: 24, Loss: 7293.2900390625\n",
      "Epoch: 3, Batch number: 48, Loss: 6821.86376953125\n",
      "Epoch: 4, Batch number: 72, Loss: 6674.41455078125\n",
      "Epoch: 6, Batch number: 20, Loss: 6077.27978515625\n",
      "Epoch: 7, Batch number: 44, Loss: 6041.53271484375\n",
      "Epoch: 8, Batch number: 68, Loss: 5729.47216796875\n",
      "Epoch: 10, Batch number: 16, Loss: 5501.76611328125\n",
      "Epoch: 11, Batch number: 40, Loss: 5277.08984375\n",
      "Epoch: 12, Batch number: 64, Loss: 4970.85986328125\n",
      "Epoch: 14, Batch number: 12, Loss: 4899.2294921875\n",
      "Epoch: 15, Batch number: 36, Loss: 4778.4453125\n",
      "Epoch: 16, Batch number: 60, Loss: 4418.68798828125\n",
      "Epoch: 18, Batch number: 8, Loss: 4300.1279296875\n",
      "Epoch: 19, Batch number: 32, Loss: 4248.552734375\n",
      "Epoch: 20, Batch number: 56, Loss: 4282.0703125\n",
      "Epoch: 22, Batch number: 4, Loss: 4208.0810546875\n",
      "Epoch: 23, Batch number: 28, Loss: 4225.7001953125\n",
      "Epoch: 24, Batch number: 52, Loss: 3984.70703125\n",
      "Epoch: 26, Batch number: 0, Loss: 3718.696533203125\n",
      "Epoch: 27, Batch number: 24, Loss: 3866.7578125\n",
      "Epoch: 28, Batch number: 48, Loss: 3809.509521484375\n",
      "Epoch: 29, Batch number: 72, Loss: 3866.544677734375\n",
      "Epoch: 31, Batch number: 20, Loss: 3743.528564453125\n",
      "Epoch: 32, Batch number: 44, Loss: 3747.916015625\n",
      "Epoch: 33, Batch number: 68, Loss: 3698.611083984375\n",
      "Epoch: 35, Batch number: 16, Loss: 3817.525390625\n",
      "Epoch: 36, Batch number: 40, Loss: 3565.08251953125\n",
      "Epoch: 37, Batch number: 64, Loss: 3735.38330078125\n",
      "Epoch: 39, Batch number: 12, Loss: 3518.749755859375\n",
      "Epoch: 40, Batch number: 36, Loss: 3500.171630859375\n",
      "Epoch: 41, Batch number: 60, Loss: 3810.457275390625\n",
      "Epoch: 43, Batch number: 8, Loss: 3523.8095703125\n",
      "Epoch: 44, Batch number: 32, Loss: 3608.58154296875\n",
      "Epoch: 45, Batch number: 56, Loss: 3544.763916015625\n",
      "Epoch: 47, Batch number: 4, Loss: 3652.326171875\n",
      "Epoch: 48, Batch number: 28, Loss: 3447.568359375\n",
      "Epoch: 49, Batch number: 52, Loss: 3621.3134765625\n",
      "Epoch: 51, Batch number: 0, Loss: 3377.603759765625\n",
      "Epoch: 52, Batch number: 24, Loss: 3348.27587890625\n",
      "Epoch: 53, Batch number: 48, Loss: 3364.287109375\n",
      "Epoch: 54, Batch number: 72, Loss: 3520.916748046875\n",
      "Epoch: 56, Batch number: 20, Loss: 3394.830078125\n",
      "Epoch: 57, Batch number: 44, Loss: 3384.789794921875\n",
      "Epoch: 58, Batch number: 68, Loss: 3312.347412109375\n",
      "Epoch: 60, Batch number: 16, Loss: 3253.27734375\n",
      "Epoch: 61, Batch number: 40, Loss: 3541.429443359375\n",
      "Epoch: 62, Batch number: 64, Loss: 3400.103271484375\n",
      "Epoch: 64, Batch number: 12, Loss: 3356.4091796875\n",
      "Epoch: 65, Batch number: 36, Loss: 3247.37255859375\n",
      "Epoch: 66, Batch number: 60, Loss: 3296.46044921875\n",
      "Epoch: 68, Batch number: 8, Loss: 3231.119384765625\n",
      "Epoch: 69, Batch number: 32, Loss: 3396.270751953125\n",
      "Epoch: 70, Batch number: 56, Loss: 3361.391357421875\n",
      "Epoch: 72, Batch number: 4, Loss: 3321.180419921875\n",
      "Epoch: 73, Batch number: 28, Loss: 3156.0517578125\n",
      "Epoch: 74, Batch number: 52, Loss: 3327.78125\n",
      "Epoch: 76, Batch number: 0, Loss: 3179.82861328125\n",
      "Epoch: 77, Batch number: 24, Loss: 3328.593017578125\n",
      "Epoch: 78, Batch number: 48, Loss: 3357.62158203125\n",
      "Epoch: 79, Batch number: 72, Loss: 3144.471435546875\n",
      "Epoch: 81, Batch number: 20, Loss: 3066.63720703125\n",
      "Epoch: 82, Batch number: 44, Loss: 3257.818603515625\n",
      "Epoch: 83, Batch number: 68, Loss: 3487.3994140625\n",
      "Epoch: 85, Batch number: 16, Loss: 3081.32373046875\n",
      "Epoch: 86, Batch number: 40, Loss: 3390.355224609375\n",
      "Epoch: 87, Batch number: 64, Loss: 3320.853515625\n",
      "Epoch: 89, Batch number: 12, Loss: 3232.50830078125\n",
      "Epoch: 90, Batch number: 36, Loss: 3277.765625\n",
      "Epoch: 91, Batch number: 60, Loss: 3258.289306640625\n",
      "Epoch: 93, Batch number: 8, Loss: 3228.033935546875\n",
      "Epoch: 94, Batch number: 32, Loss: 3296.134033203125\n",
      "Epoch: 95, Batch number: 56, Loss: 3305.197265625\n",
      "Epoch: 97, Batch number: 4, Loss: 3189.775390625\n",
      "Epoch: 98, Batch number: 28, Loss: 3180.261962890625\n",
      "Epoch: 99, Batch number: 52, Loss: 3232.591552734375\n",
      "Epoch: 101, Batch number: 0, Loss: 3255.162841796875\n",
      "Epoch: 102, Batch number: 24, Loss: 3222.678466796875\n",
      "Epoch: 103, Batch number: 48, Loss: 3234.738037109375\n",
      "Epoch: 104, Batch number: 72, Loss: 3304.804443359375\n",
      "Epoch: 106, Batch number: 20, Loss: 3131.21923828125\n",
      "Epoch: 107, Batch number: 44, Loss: 3197.342529296875\n",
      "Epoch: 108, Batch number: 68, Loss: 3289.9990234375\n",
      "Epoch: 110, Batch number: 16, Loss: 3035.100341796875\n",
      "Epoch: 111, Batch number: 40, Loss: 3258.271728515625\n",
      "Epoch: 112, Batch number: 64, Loss: 3291.62939453125\n",
      "Epoch: 114, Batch number: 12, Loss: 3290.1708984375\n",
      "Epoch: 115, Batch number: 36, Loss: 3155.060791015625\n",
      "Epoch: 116, Batch number: 60, Loss: 3244.26611328125\n",
      "Epoch: 118, Batch number: 8, Loss: 3175.04931640625\n",
      "Epoch: 119, Batch number: 32, Loss: 3242.9599609375\n",
      "Epoch: 120, Batch number: 56, Loss: 3193.78076171875\n",
      "Epoch: 122, Batch number: 4, Loss: 3109.991455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123, Batch number: 28, Loss: 3143.684814453125\n",
      "Epoch: 124, Batch number: 52, Loss: 3242.466064453125\n",
      "Epoch: 126, Batch number: 0, Loss: 3144.481201171875\n",
      "Epoch: 127, Batch number: 24, Loss: 3113.004150390625\n",
      "Epoch: 128, Batch number: 48, Loss: 3226.072265625\n",
      "Epoch: 129, Batch number: 72, Loss: 3191.55615234375\n",
      "Epoch: 131, Batch number: 20, Loss: 3134.431884765625\n",
      "Epoch: 132, Batch number: 44, Loss: 3241.7861328125\n",
      "Epoch: 133, Batch number: 68, Loss: 3306.25\n",
      "Epoch: 135, Batch number: 16, Loss: 3122.4892578125\n",
      "Epoch: 136, Batch number: 40, Loss: 3262.59375\n",
      "Epoch: 137, Batch number: 64, Loss: 3340.421875\n",
      "Epoch: 139, Batch number: 12, Loss: 3175.990234375\n",
      "Epoch: 140, Batch number: 36, Loss: 3207.231689453125\n",
      "Epoch: 141, Batch number: 60, Loss: 3318.614501953125\n",
      "Epoch: 143, Batch number: 8, Loss: 3277.122314453125\n",
      "Epoch: 144, Batch number: 32, Loss: 3329.23046875\n",
      "Epoch: 145, Batch number: 56, Loss: 3266.40234375\n",
      "Epoch: 147, Batch number: 4, Loss: 3115.437255859375\n",
      "Epoch: 148, Batch number: 28, Loss: 3305.111328125\n",
      "Epoch: 149, Batch number: 52, Loss: 3406.9150390625\n",
      "Epoch: 151, Batch number: 0, Loss: 3157.234130859375\n",
      "Epoch: 152, Batch number: 24, Loss: 3162.2529296875\n",
      "Epoch: 153, Batch number: 48, Loss: 3288.369140625\n",
      "Epoch: 154, Batch number: 72, Loss: 3313.357177734375\n",
      "Epoch: 156, Batch number: 20, Loss: 3171.0556640625\n",
      "Epoch: 157, Batch number: 44, Loss: 3210.92919921875\n",
      "Epoch: 158, Batch number: 68, Loss: 3345.44091796875\n",
      "Epoch: 160, Batch number: 16, Loss: 3170.120361328125\n",
      "Epoch: 161, Batch number: 40, Loss: 3267.134765625\n",
      "Epoch: 162, Batch number: 64, Loss: 3207.571533203125\n",
      "Epoch: 164, Batch number: 12, Loss: 3091.4912109375\n",
      "Epoch: 165, Batch number: 36, Loss: 3143.79150390625\n",
      "Epoch: 166, Batch number: 60, Loss: 3270.575439453125\n",
      "Epoch: 168, Batch number: 8, Loss: 3266.905517578125\n",
      "Epoch: 169, Batch number: 32, Loss: 3207.40966796875\n",
      "Epoch: 170, Batch number: 56, Loss: 3186.370361328125\n",
      "Epoch: 172, Batch number: 4, Loss: 3189.141357421875\n",
      "Epoch: 173, Batch number: 28, Loss: 3261.574951171875\n",
      "Epoch: 174, Batch number: 52, Loss: 3076.64697265625\n",
      "Epoch: 176, Batch number: 0, Loss: 3161.37255859375\n",
      "Epoch: 177, Batch number: 24, Loss: 3250.4697265625\n",
      "Epoch: 178, Batch number: 48, Loss: 3213.660888671875\n",
      "Epoch: 179, Batch number: 72, Loss: 3267.9208984375\n",
      "Epoch: 181, Batch number: 20, Loss: 3291.20947265625\n",
      "Epoch: 182, Batch number: 44, Loss: 3259.92333984375\n",
      "Epoch: 183, Batch number: 68, Loss: 3195.5302734375\n",
      "Epoch: 185, Batch number: 16, Loss: 3068.3916015625\n",
      "Epoch: 186, Batch number: 40, Loss: 3204.03564453125\n",
      "Epoch: 187, Batch number: 64, Loss: 3241.497802734375\n",
      "Epoch: 189, Batch number: 12, Loss: 3168.06005859375\n",
      "Epoch: 190, Batch number: 36, Loss: 3140.371826171875\n",
      "Epoch: 191, Batch number: 60, Loss: 3306.28662109375\n",
      "Epoch: 193, Batch number: 8, Loss: 3148.241943359375\n",
      "Epoch: 194, Batch number: 32, Loss: 3218.5205078125\n",
      "Epoch: 195, Batch number: 56, Loss: 3272.90625\n",
      "Epoch: 197, Batch number: 4, Loss: 3111.2998046875\n",
      "Epoch: 198, Batch number: 28, Loss: 3208.218994140625\n",
      "Epoch: 199, Batch number: 52, Loss: 3284.135498046875\n",
      "Epoch: 201, Batch number: 0, Loss: 3264.00830078125\n",
      "Epoch: 202, Batch number: 24, Loss: 3234.991455078125\n",
      "Epoch: 203, Batch number: 48, Loss: 3221.91748046875\n",
      "Epoch: 204, Batch number: 72, Loss: 3288.3935546875\n",
      "Epoch: 206, Batch number: 20, Loss: 3247.17431640625\n",
      "Epoch: 207, Batch number: 44, Loss: 3242.9287109375\n",
      "Epoch: 208, Batch number: 68, Loss: 3281.41015625\n",
      "Epoch: 210, Batch number: 16, Loss: 3258.903564453125\n",
      "Epoch: 211, Batch number: 40, Loss: 3205.483642578125\n",
      "Epoch: 212, Batch number: 64, Loss: 3298.62109375\n",
      "Epoch: 214, Batch number: 12, Loss: 3140.147705078125\n",
      "Epoch: 215, Batch number: 36, Loss: 3226.38720703125\n",
      "Epoch: 216, Batch number: 60, Loss: 3223.821533203125\n",
      "Epoch: 218, Batch number: 8, Loss: 3125.61279296875\n",
      "Epoch: 219, Batch number: 32, Loss: 3264.2783203125\n",
      "Epoch: 220, Batch number: 56, Loss: 3194.08154296875\n",
      "Epoch: 222, Batch number: 4, Loss: 3102.859375\n",
      "Epoch: 223, Batch number: 28, Loss: 3106.823974609375\n",
      "Epoch: 224, Batch number: 52, Loss: 3294.7392578125\n",
      "Epoch: 226, Batch number: 0, Loss: 3239.013427734375\n",
      "Epoch: 227, Batch number: 24, Loss: 3225.548583984375\n",
      "Epoch: 228, Batch number: 48, Loss: 3237.93994140625\n",
      "Epoch: 229, Batch number: 72, Loss: 3208.590087890625\n",
      "Epoch: 231, Batch number: 20, Loss: 3350.888916015625\n",
      "Epoch: 232, Batch number: 44, Loss: 3127.43505859375\n",
      "Epoch: 233, Batch number: 68, Loss: 3002.163330078125\n",
      "Epoch: 235, Batch number: 16, Loss: 3256.582763671875\n",
      "Epoch: 236, Batch number: 40, Loss: 3195.52001953125\n",
      "Epoch: 237, Batch number: 64, Loss: 3256.207763671875\n",
      "Epoch: 239, Batch number: 12, Loss: 3151.941650390625\n",
      "Epoch: 240, Batch number: 36, Loss: 3218.5966796875\n",
      "Epoch: 241, Batch number: 60, Loss: 3375.3115234375\n",
      "Epoch: 243, Batch number: 8, Loss: 3121.578857421875\n",
      "Epoch: 244, Batch number: 32, Loss: 3137.021728515625\n",
      "Epoch: 245, Batch number: 56, Loss: 3188.7744140625\n",
      "Epoch: 247, Batch number: 4, Loss: 3111.82958984375\n",
      "Epoch: 248, Batch number: 28, Loss: 3151.126953125\n",
      "Epoch: 249, Batch number: 52, Loss: 3363.94091796875\n",
      "Epoch: 251, Batch number: 0, Loss: 3230.049560546875\n",
      "Epoch: 252, Batch number: 24, Loss: 3043.709716796875\n",
      "Epoch: 253, Batch number: 48, Loss: 3186.083251953125\n",
      "Epoch: 254, Batch number: 72, Loss: 3235.571044921875\n",
      "Epoch: 256, Batch number: 20, Loss: 3262.986083984375\n",
      "Epoch: 257, Batch number: 44, Loss: 3232.322265625\n",
      "Epoch: 258, Batch number: 68, Loss: 3395.041259765625\n",
      "Epoch: 260, Batch number: 16, Loss: 3107.511474609375\n",
      "Epoch: 261, Batch number: 40, Loss: 3284.45556640625\n",
      "Epoch: 262, Batch number: 64, Loss: 3271.912109375\n",
      "Epoch: 264, Batch number: 12, Loss: 2967.059814453125\n",
      "Epoch: 265, Batch number: 36, Loss: 3327.69287109375\n",
      "Epoch: 266, Batch number: 60, Loss: 3342.76806640625\n",
      "Epoch: 268, Batch number: 8, Loss: 3151.038818359375\n",
      "Epoch: 269, Batch number: 32, Loss: 3340.76318359375\n",
      "Epoch: 270, Batch number: 56, Loss: 3225.71630859375\n",
      "Epoch: 272, Batch number: 4, Loss: 3065.00439453125\n",
      "Epoch: 273, Batch number: 28, Loss: 3310.92724609375\n",
      "Epoch: 274, Batch number: 52, Loss: 3351.45263671875\n",
      "Epoch: 276, Batch number: 0, Loss: 3125.291015625\n",
      "Epoch: 277, Batch number: 24, Loss: 3189.96630859375\n",
      "Epoch: 278, Batch number: 48, Loss: 3318.037109375\n",
      "Epoch: 279, Batch number: 72, Loss: 3298.318359375\n",
      "Epoch: 281, Batch number: 20, Loss: 3338.927001953125\n",
      "Epoch: 282, Batch number: 44, Loss: 3345.089111328125\n",
      "Epoch: 283, Batch number: 68, Loss: 3347.03125\n",
      "Epoch: 285, Batch number: 16, Loss: 3044.37646484375\n",
      "Epoch: 286, Batch number: 40, Loss: 3156.171875\n",
      "Epoch: 287, Batch number: 64, Loss: 3201.007080078125\n",
      "Epoch: 289, Batch number: 12, Loss: 3176.15380859375\n",
      "Epoch: 290, Batch number: 36, Loss: 3185.810546875\n",
      "Epoch: 291, Batch number: 60, Loss: 3313.756591796875\n",
      "Epoch: 293, Batch number: 8, Loss: 3066.50048828125\n",
      "Epoch: 294, Batch number: 32, Loss: 3283.603759765625\n",
      "Epoch: 295, Batch number: 56, Loss: 3323.64404296875\n",
      "Epoch: 297, Batch number: 4, Loss: 3257.7900390625\n",
      "Epoch: 298, Batch number: 28, Loss: 3083.593994140625\n",
      "Epoch: 299, Batch number: 52, Loss: 3230.6337890625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8174.78564453125\n",
      "Epoch: 2, Batch number: 24, Loss: 7324.8974609375\n",
      "Epoch: 3, Batch number: 48, Loss: 6648.30859375\n",
      "Epoch: 4, Batch number: 72, Loss: 6320.22265625\n",
      "Epoch: 6, Batch number: 20, Loss: 5872.005859375\n",
      "Epoch: 7, Batch number: 44, Loss: 5625.7958984375\n",
      "Epoch: 8, Batch number: 68, Loss: 5404.63818359375\n",
      "Epoch: 10, Batch number: 16, Loss: 4995.0869140625\n",
      "Epoch: 11, Batch number: 40, Loss: 4775.279296875\n",
      "Epoch: 12, Batch number: 64, Loss: 4801.029296875\n",
      "Epoch: 14, Batch number: 12, Loss: 4352.00146484375\n",
      "Epoch: 15, Batch number: 36, Loss: 4287.4541015625\n",
      "Epoch: 16, Batch number: 60, Loss: 4432.95556640625\n",
      "Epoch: 18, Batch number: 8, Loss: 4105.8330078125\n",
      "Epoch: 19, Batch number: 32, Loss: 4107.009765625\n",
      "Epoch: 20, Batch number: 56, Loss: 3983.679931640625\n",
      "Epoch: 22, Batch number: 4, Loss: 3845.5263671875\n",
      "Epoch: 23, Batch number: 28, Loss: 3812.69482421875\n",
      "Epoch: 24, Batch number: 52, Loss: 3780.5537109375\n",
      "Epoch: 26, Batch number: 0, Loss: 3569.552001953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Batch number: 24, Loss: 3652.281982421875\n",
      "Epoch: 28, Batch number: 48, Loss: 3608.4140625\n",
      "Epoch: 29, Batch number: 72, Loss: 3796.44921875\n",
      "Epoch: 31, Batch number: 20, Loss: 3445.804931640625\n",
      "Epoch: 32, Batch number: 44, Loss: 3445.406982421875\n",
      "Epoch: 33, Batch number: 68, Loss: 3570.217041015625\n",
      "Epoch: 35, Batch number: 16, Loss: 3487.60107421875\n",
      "Epoch: 36, Batch number: 40, Loss: 3443.462646484375\n",
      "Epoch: 37, Batch number: 64, Loss: 3486.103515625\n",
      "Epoch: 39, Batch number: 12, Loss: 3360.364990234375\n",
      "Epoch: 40, Batch number: 36, Loss: 3443.603271484375\n",
      "Epoch: 41, Batch number: 60, Loss: 3572.364501953125\n",
      "Epoch: 43, Batch number: 8, Loss: 3299.8330078125\n",
      "Epoch: 44, Batch number: 32, Loss: 3376.684814453125\n",
      "Epoch: 45, Batch number: 56, Loss: 3358.038818359375\n",
      "Epoch: 47, Batch number: 4, Loss: 3258.233642578125\n",
      "Epoch: 48, Batch number: 28, Loss: 3376.373291015625\n",
      "Epoch: 49, Batch number: 52, Loss: 3240.24169921875\n",
      "Epoch: 51, Batch number: 0, Loss: 3270.810546875\n",
      "Epoch: 52, Batch number: 24, Loss: 3217.797119140625\n",
      "Epoch: 53, Batch number: 48, Loss: 3312.1435546875\n",
      "Epoch: 54, Batch number: 72, Loss: 3369.02099609375\n",
      "Epoch: 56, Batch number: 20, Loss: 3228.855712890625\n",
      "Epoch: 57, Batch number: 44, Loss: 3224.0302734375\n",
      "Epoch: 58, Batch number: 68, Loss: 3251.679931640625\n",
      "Epoch: 60, Batch number: 16, Loss: 3222.708251953125\n",
      "Epoch: 61, Batch number: 40, Loss: 3331.829345703125\n",
      "Epoch: 62, Batch number: 64, Loss: 3342.136474609375\n",
      "Epoch: 64, Batch number: 12, Loss: 3136.332763671875\n",
      "Epoch: 65, Batch number: 36, Loss: 3335.092529296875\n",
      "Epoch: 66, Batch number: 60, Loss: 3301.76171875\n",
      "Epoch: 68, Batch number: 8, Loss: 3151.42431640625\n",
      "Epoch: 69, Batch number: 32, Loss: 3149.314208984375\n",
      "Epoch: 70, Batch number: 56, Loss: 3160.619873046875\n",
      "Epoch: 72, Batch number: 4, Loss: 3158.00927734375\n",
      "Epoch: 73, Batch number: 28, Loss: 3181.219482421875\n",
      "Epoch: 74, Batch number: 52, Loss: 3385.476806640625\n",
      "Epoch: 76, Batch number: 0, Loss: 3157.06591796875\n",
      "Epoch: 77, Batch number: 24, Loss: 3174.403564453125\n",
      "Epoch: 78, Batch number: 48, Loss: 3341.77978515625\n",
      "Epoch: 79, Batch number: 72, Loss: 3413.6669921875\n",
      "Epoch: 81, Batch number: 20, Loss: 3195.4677734375\n",
      "Epoch: 82, Batch number: 44, Loss: 3293.27099609375\n",
      "Epoch: 83, Batch number: 68, Loss: 3345.851318359375\n",
      "Epoch: 85, Batch number: 16, Loss: 3286.18310546875\n",
      "Epoch: 86, Batch number: 40, Loss: 3388.968505859375\n",
      "Epoch: 87, Batch number: 64, Loss: 3144.8466796875\n",
      "Epoch: 89, Batch number: 12, Loss: 3132.63037109375\n",
      "Epoch: 90, Batch number: 36, Loss: 3303.39501953125\n",
      "Epoch: 91, Batch number: 60, Loss: 3297.337646484375\n",
      "Epoch: 93, Batch number: 8, Loss: 3198.168701171875\n",
      "Epoch: 94, Batch number: 32, Loss: 3234.54248046875\n",
      "Epoch: 95, Batch number: 56, Loss: 3174.13671875\n",
      "Epoch: 97, Batch number: 4, Loss: 3094.60693359375\n",
      "Epoch: 98, Batch number: 28, Loss: 3076.522216796875\n",
      "Epoch: 99, Batch number: 52, Loss: 3302.925537109375\n",
      "Epoch: 101, Batch number: 0, Loss: 3078.10791015625\n",
      "Epoch: 102, Batch number: 24, Loss: 3386.142822265625\n",
      "Epoch: 103, Batch number: 48, Loss: 3305.928955078125\n",
      "Epoch: 104, Batch number: 72, Loss: 3252.269775390625\n",
      "Epoch: 106, Batch number: 20, Loss: 3102.21728515625\n",
      "Epoch: 107, Batch number: 44, Loss: 3315.221435546875\n",
      "Epoch: 108, Batch number: 68, Loss: 3197.03125\n",
      "Epoch: 110, Batch number: 16, Loss: 3230.175537109375\n",
      "Epoch: 111, Batch number: 40, Loss: 3196.543701171875\n",
      "Epoch: 112, Batch number: 64, Loss: 3299.101318359375\n",
      "Epoch: 114, Batch number: 12, Loss: 3176.608154296875\n",
      "Epoch: 115, Batch number: 36, Loss: 3337.112060546875\n",
      "Epoch: 116, Batch number: 60, Loss: 3213.55712890625\n",
      "Epoch: 118, Batch number: 8, Loss: 3089.735595703125\n",
      "Epoch: 119, Batch number: 32, Loss: 3212.4306640625\n",
      "Epoch: 120, Batch number: 56, Loss: 3265.13232421875\n",
      "Epoch: 122, Batch number: 4, Loss: 3224.87841796875\n",
      "Epoch: 123, Batch number: 28, Loss: 3300.727783203125\n",
      "Epoch: 124, Batch number: 52, Loss: 3270.26513671875\n",
      "Epoch: 126, Batch number: 0, Loss: 3225.98779296875\n",
      "Epoch: 127, Batch number: 24, Loss: 3360.15771484375\n",
      "Epoch: 128, Batch number: 48, Loss: 3192.9775390625\n",
      "Epoch: 129, Batch number: 72, Loss: 3287.282958984375\n",
      "Epoch: 131, Batch number: 20, Loss: 3208.025390625\n",
      "Epoch: 132, Batch number: 44, Loss: 3302.4091796875\n",
      "Epoch: 133, Batch number: 68, Loss: 3413.385986328125\n",
      "Epoch: 135, Batch number: 16, Loss: 3099.58447265625\n",
      "Epoch: 136, Batch number: 40, Loss: 3165.645263671875\n",
      "Epoch: 137, Batch number: 64, Loss: 3200.6708984375\n",
      "Epoch: 139, Batch number: 12, Loss: 2998.247802734375\n",
      "Epoch: 140, Batch number: 36, Loss: 3158.7138671875\n",
      "Epoch: 141, Batch number: 60, Loss: 3315.515869140625\n",
      "Epoch: 143, Batch number: 8, Loss: 3080.911865234375\n",
      "Epoch: 144, Batch number: 32, Loss: 3272.53759765625\n",
      "Epoch: 145, Batch number: 56, Loss: 3200.06494140625\n",
      "Epoch: 147, Batch number: 4, Loss: 3233.468017578125\n",
      "Epoch: 148, Batch number: 28, Loss: 3184.544189453125\n",
      "Epoch: 149, Batch number: 52, Loss: 3345.025146484375\n",
      "Epoch: 151, Batch number: 0, Loss: 3221.482177734375\n",
      "Epoch: 152, Batch number: 24, Loss: 3241.336669921875\n",
      "Epoch: 153, Batch number: 48, Loss: 3231.27294921875\n",
      "Epoch: 154, Batch number: 72, Loss: 3283.978515625\n",
      "Epoch: 156, Batch number: 20, Loss: 3308.286865234375\n",
      "Epoch: 157, Batch number: 44, Loss: 3210.821044921875\n",
      "Epoch: 158, Batch number: 68, Loss: 3406.607421875\n",
      "Epoch: 160, Batch number: 16, Loss: 3156.352294921875\n",
      "Epoch: 161, Batch number: 40, Loss: 3175.55224609375\n",
      "Epoch: 162, Batch number: 64, Loss: 3270.203857421875\n",
      "Epoch: 164, Batch number: 12, Loss: 3317.565673828125\n",
      "Epoch: 165, Batch number: 36, Loss: 3113.137939453125\n",
      "Epoch: 166, Batch number: 60, Loss: 3306.39111328125\n",
      "Epoch: 168, Batch number: 8, Loss: 3118.837890625\n",
      "Epoch: 169, Batch number: 32, Loss: 3172.160400390625\n",
      "Epoch: 170, Batch number: 56, Loss: 3435.050048828125\n",
      "Epoch: 172, Batch number: 4, Loss: 3070.507080078125\n",
      "Epoch: 173, Batch number: 28, Loss: 3232.395263671875\n",
      "Epoch: 174, Batch number: 52, Loss: 3306.7763671875\n",
      "Epoch: 176, Batch number: 0, Loss: 3121.91259765625\n",
      "Epoch: 177, Batch number: 24, Loss: 3297.424560546875\n",
      "Epoch: 178, Batch number: 48, Loss: 3223.1865234375\n",
      "Epoch: 179, Batch number: 72, Loss: 3190.7060546875\n",
      "Epoch: 181, Batch number: 20, Loss: 3238.123779296875\n",
      "Epoch: 182, Batch number: 44, Loss: 3143.16455078125\n",
      "Epoch: 183, Batch number: 68, Loss: 3261.041748046875\n",
      "Epoch: 185, Batch number: 16, Loss: 3111.504150390625\n",
      "Epoch: 186, Batch number: 40, Loss: 3252.282958984375\n",
      "Epoch: 187, Batch number: 64, Loss: 3250.689208984375\n",
      "Epoch: 189, Batch number: 12, Loss: 3225.619384765625\n",
      "Epoch: 190, Batch number: 36, Loss: 3134.69482421875\n",
      "Epoch: 191, Batch number: 60, Loss: 3068.45654296875\n",
      "Epoch: 193, Batch number: 8, Loss: 3198.53466796875\n",
      "Epoch: 194, Batch number: 32, Loss: 3345.333984375\n",
      "Epoch: 195, Batch number: 56, Loss: 3221.26171875\n",
      "Epoch: 197, Batch number: 4, Loss: 3213.802001953125\n",
      "Epoch: 198, Batch number: 28, Loss: 3171.697021484375\n",
      "Epoch: 199, Batch number: 52, Loss: 3267.10888671875\n",
      "Epoch: 201, Batch number: 0, Loss: 3125.972900390625\n",
      "Epoch: 202, Batch number: 24, Loss: 3146.70458984375\n",
      "Epoch: 203, Batch number: 48, Loss: 3280.25244140625\n",
      "Epoch: 204, Batch number: 72, Loss: 3280.427001953125\n",
      "Epoch: 206, Batch number: 20, Loss: 3185.2880859375\n",
      "Epoch: 207, Batch number: 44, Loss: 3279.7265625\n",
      "Epoch: 208, Batch number: 68, Loss: 3198.501708984375\n",
      "Epoch: 210, Batch number: 16, Loss: 3048.72216796875\n",
      "Epoch: 211, Batch number: 40, Loss: 3175.25537109375\n",
      "Epoch: 212, Batch number: 64, Loss: 3192.171875\n",
      "Epoch: 214, Batch number: 12, Loss: 3188.298095703125\n",
      "Epoch: 215, Batch number: 36, Loss: 3191.647216796875\n",
      "Epoch: 216, Batch number: 60, Loss: 3172.81591796875\n",
      "Epoch: 218, Batch number: 8, Loss: 3023.651123046875\n",
      "Epoch: 219, Batch number: 32, Loss: 3240.572509765625\n",
      "Epoch: 220, Batch number: 56, Loss: 3201.843505859375\n",
      "Epoch: 222, Batch number: 4, Loss: 3181.6708984375\n",
      "Epoch: 223, Batch number: 28, Loss: 3126.25390625\n",
      "Epoch: 224, Batch number: 52, Loss: 3005.505126953125\n",
      "Epoch: 226, Batch number: 0, Loss: 3087.36376953125\n",
      "Epoch: 227, Batch number: 24, Loss: 3326.9287109375\n",
      "Epoch: 228, Batch number: 48, Loss: 3128.9482421875\n",
      "Epoch: 229, Batch number: 72, Loss: 3344.961181640625\n",
      "Epoch: 231, Batch number: 20, Loss: 3220.503173828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 232, Batch number: 44, Loss: 3238.28955078125\n",
      "Epoch: 233, Batch number: 68, Loss: 3207.71728515625\n",
      "Epoch: 235, Batch number: 16, Loss: 3133.994873046875\n",
      "Epoch: 236, Batch number: 40, Loss: 3215.276123046875\n",
      "Epoch: 237, Batch number: 64, Loss: 3363.839111328125\n",
      "Epoch: 239, Batch number: 12, Loss: 3158.80224609375\n",
      "Epoch: 240, Batch number: 36, Loss: 3205.058349609375\n",
      "Epoch: 241, Batch number: 60, Loss: 3321.3828125\n",
      "Epoch: 243, Batch number: 8, Loss: 2993.469970703125\n",
      "Epoch: 244, Batch number: 32, Loss: 3267.669189453125\n",
      "Epoch: 245, Batch number: 56, Loss: 3237.753173828125\n",
      "Epoch: 247, Batch number: 4, Loss: 3154.94482421875\n",
      "Epoch: 248, Batch number: 28, Loss: 3248.494873046875\n",
      "Epoch: 249, Batch number: 52, Loss: 3178.606689453125\n",
      "Epoch: 251, Batch number: 0, Loss: 3178.366943359375\n",
      "Epoch: 252, Batch number: 24, Loss: 3240.0927734375\n",
      "Epoch: 253, Batch number: 48, Loss: 3249.34814453125\n",
      "Epoch: 254, Batch number: 72, Loss: 3187.884033203125\n",
      "Epoch: 256, Batch number: 20, Loss: 3158.229736328125\n",
      "Epoch: 257, Batch number: 44, Loss: 3175.50048828125\n",
      "Epoch: 258, Batch number: 68, Loss: 3374.90185546875\n",
      "Epoch: 260, Batch number: 16, Loss: 3166.540283203125\n",
      "Epoch: 261, Batch number: 40, Loss: 3045.752197265625\n",
      "Epoch: 262, Batch number: 64, Loss: 3237.9931640625\n",
      "Epoch: 264, Batch number: 12, Loss: 3319.262451171875\n",
      "Epoch: 265, Batch number: 36, Loss: 3301.47265625\n",
      "Epoch: 266, Batch number: 60, Loss: 3350.478759765625\n",
      "Epoch: 268, Batch number: 8, Loss: 3100.221923828125\n",
      "Epoch: 269, Batch number: 32, Loss: 3190.564453125\n",
      "Epoch: 270, Batch number: 56, Loss: 3308.36083984375\n",
      "Epoch: 272, Batch number: 4, Loss: 3248.23193359375\n",
      "Epoch: 273, Batch number: 28, Loss: 3147.514404296875\n",
      "Epoch: 274, Batch number: 52, Loss: 3169.32275390625\n",
      "Epoch: 276, Batch number: 0, Loss: 3138.8544921875\n",
      "Epoch: 277, Batch number: 24, Loss: 3165.85205078125\n",
      "Epoch: 278, Batch number: 48, Loss: 3156.988525390625\n",
      "Epoch: 279, Batch number: 72, Loss: 3261.47705078125\n",
      "Epoch: 281, Batch number: 20, Loss: 3441.585693359375\n",
      "Epoch: 282, Batch number: 44, Loss: 3236.77783203125\n",
      "Epoch: 283, Batch number: 68, Loss: 3477.765869140625\n",
      "Epoch: 285, Batch number: 16, Loss: 3137.071533203125\n",
      "Epoch: 286, Batch number: 40, Loss: 3186.312744140625\n",
      "Epoch: 287, Batch number: 64, Loss: 3191.51318359375\n",
      "Epoch: 289, Batch number: 12, Loss: 3230.37890625\n",
      "Epoch: 290, Batch number: 36, Loss: 3195.881103515625\n",
      "Epoch: 291, Batch number: 60, Loss: 3382.72314453125\n",
      "Epoch: 293, Batch number: 8, Loss: 2957.813232421875\n",
      "Epoch: 294, Batch number: 32, Loss: 3090.07373046875\n",
      "Epoch: 295, Batch number: 56, Loss: 3246.536865234375\n",
      "Epoch: 297, Batch number: 4, Loss: 3136.210205078125\n",
      "Epoch: 298, Batch number: 28, Loss: 3265.353515625\n",
      "Epoch: 299, Batch number: 52, Loss: 3182.66845703125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8041.49951171875\n",
      "Epoch: 2, Batch number: 24, Loss: 7034.95166015625\n",
      "Epoch: 3, Batch number: 48, Loss: 6569.00830078125\n",
      "Epoch: 4, Batch number: 72, Loss: 5999.16650390625\n",
      "Epoch: 6, Batch number: 20, Loss: 5572.048828125\n",
      "Epoch: 7, Batch number: 44, Loss: 5212.9453125\n",
      "Epoch: 8, Batch number: 68, Loss: 5019.1708984375\n",
      "Epoch: 10, Batch number: 16, Loss: 4749.90869140625\n",
      "Epoch: 11, Batch number: 40, Loss: 4743.0908203125\n",
      "Epoch: 12, Batch number: 64, Loss: 4292.06787109375\n",
      "Epoch: 14, Batch number: 12, Loss: 4158.3984375\n",
      "Epoch: 15, Batch number: 36, Loss: 4235.89501953125\n",
      "Epoch: 16, Batch number: 60, Loss: 4000.36328125\n",
      "Epoch: 18, Batch number: 8, Loss: 3847.059814453125\n",
      "Epoch: 19, Batch number: 32, Loss: 3847.01318359375\n",
      "Epoch: 20, Batch number: 56, Loss: 3822.660400390625\n",
      "Epoch: 22, Batch number: 4, Loss: 3570.1103515625\n",
      "Epoch: 23, Batch number: 28, Loss: 3514.341796875\n",
      "Epoch: 24, Batch number: 52, Loss: 3653.136962890625\n",
      "Epoch: 26, Batch number: 0, Loss: 3594.429443359375\n",
      "Epoch: 27, Batch number: 24, Loss: 3308.660400390625\n",
      "Epoch: 28, Batch number: 48, Loss: 3472.130615234375\n",
      "Epoch: 29, Batch number: 72, Loss: 3484.02099609375\n",
      "Epoch: 31, Batch number: 20, Loss: 3345.483154296875\n",
      "Epoch: 32, Batch number: 44, Loss: 3504.5234375\n",
      "Epoch: 33, Batch number: 68, Loss: 3377.780517578125\n",
      "Epoch: 35, Batch number: 16, Loss: 3372.750244140625\n",
      "Epoch: 36, Batch number: 40, Loss: 3362.181396484375\n",
      "Epoch: 37, Batch number: 64, Loss: 3407.166015625\n",
      "Epoch: 39, Batch number: 12, Loss: 3310.094482421875\n",
      "Epoch: 40, Batch number: 36, Loss: 3322.636474609375\n",
      "Epoch: 41, Batch number: 60, Loss: 3441.916748046875\n",
      "Epoch: 43, Batch number: 8, Loss: 3331.4248046875\n",
      "Epoch: 44, Batch number: 32, Loss: 3411.093505859375\n",
      "Epoch: 45, Batch number: 56, Loss: 3424.03076171875\n",
      "Epoch: 47, Batch number: 4, Loss: 3299.056884765625\n",
      "Epoch: 48, Batch number: 28, Loss: 3100.77880859375\n",
      "Epoch: 49, Batch number: 52, Loss: 3382.640625\n",
      "Epoch: 51, Batch number: 0, Loss: 3202.8154296875\n",
      "Epoch: 52, Batch number: 24, Loss: 3336.327392578125\n",
      "Epoch: 53, Batch number: 48, Loss: 3397.78955078125\n",
      "Epoch: 54, Batch number: 72, Loss: 3445.66943359375\n",
      "Epoch: 56, Batch number: 20, Loss: 3278.989990234375\n",
      "Epoch: 57, Batch number: 44, Loss: 3402.329833984375\n",
      "Epoch: 58, Batch number: 68, Loss: 3309.887451171875\n",
      "Epoch: 60, Batch number: 16, Loss: 3197.49072265625\n",
      "Epoch: 61, Batch number: 40, Loss: 3257.564208984375\n",
      "Epoch: 62, Batch number: 64, Loss: 3497.664306640625\n",
      "Epoch: 64, Batch number: 12, Loss: 3326.1484375\n",
      "Epoch: 65, Batch number: 36, Loss: 3250.0283203125\n",
      "Epoch: 66, Batch number: 60, Loss: 3284.391357421875\n",
      "Epoch: 68, Batch number: 8, Loss: 3043.779052734375\n",
      "Epoch: 69, Batch number: 32, Loss: 3184.358154296875\n",
      "Epoch: 70, Batch number: 56, Loss: 3182.732177734375\n",
      "Epoch: 72, Batch number: 4, Loss: 3096.437255859375\n",
      "Epoch: 73, Batch number: 28, Loss: 3180.348876953125\n",
      "Epoch: 74, Batch number: 52, Loss: 3262.507080078125\n",
      "Epoch: 76, Batch number: 0, Loss: 3222.946044921875\n",
      "Epoch: 77, Batch number: 24, Loss: 3287.380126953125\n",
      "Epoch: 78, Batch number: 48, Loss: 3239.176513671875\n",
      "Epoch: 79, Batch number: 72, Loss: 3252.53466796875\n",
      "Epoch: 81, Batch number: 20, Loss: 3324.507568359375\n",
      "Epoch: 82, Batch number: 44, Loss: 3221.65087890625\n",
      "Epoch: 83, Batch number: 68, Loss: 3252.757080078125\n",
      "Epoch: 85, Batch number: 16, Loss: 3100.511474609375\n",
      "Epoch: 86, Batch number: 40, Loss: 3146.498291015625\n",
      "Epoch: 87, Batch number: 64, Loss: 3329.327880859375\n",
      "Epoch: 89, Batch number: 12, Loss: 3083.2939453125\n",
      "Epoch: 90, Batch number: 36, Loss: 3322.828857421875\n",
      "Epoch: 91, Batch number: 60, Loss: 3397.055419921875\n",
      "Epoch: 93, Batch number: 8, Loss: 3233.36328125\n",
      "Epoch: 94, Batch number: 32, Loss: 3217.322021484375\n",
      "Epoch: 95, Batch number: 56, Loss: 3222.2275390625\n",
      "Epoch: 97, Batch number: 4, Loss: 3171.18896484375\n",
      "Epoch: 98, Batch number: 28, Loss: 3039.24755859375\n",
      "Epoch: 99, Batch number: 52, Loss: 3276.562744140625\n",
      "Epoch: 101, Batch number: 0, Loss: 3140.39794921875\n",
      "Epoch: 102, Batch number: 24, Loss: 3139.364013671875\n",
      "Epoch: 103, Batch number: 48, Loss: 3158.352783203125\n",
      "Epoch: 104, Batch number: 72, Loss: 3344.20703125\n",
      "Epoch: 106, Batch number: 20, Loss: 3273.6298828125\n",
      "Epoch: 107, Batch number: 44, Loss: 3333.307373046875\n",
      "Epoch: 108, Batch number: 68, Loss: 3373.9404296875\n",
      "Epoch: 110, Batch number: 16, Loss: 3127.793701171875\n",
      "Epoch: 111, Batch number: 40, Loss: 3352.440673828125\n",
      "Epoch: 112, Batch number: 64, Loss: 3324.876953125\n",
      "Epoch: 114, Batch number: 12, Loss: 3152.473876953125\n",
      "Epoch: 115, Batch number: 36, Loss: 3379.959716796875\n",
      "Epoch: 116, Batch number: 60, Loss: 3111.8759765625\n",
      "Epoch: 118, Batch number: 8, Loss: 3189.049072265625\n",
      "Epoch: 119, Batch number: 32, Loss: 3256.93896484375\n",
      "Epoch: 120, Batch number: 56, Loss: 3326.918701171875\n",
      "Epoch: 122, Batch number: 4, Loss: 3180.21142578125\n",
      "Epoch: 123, Batch number: 28, Loss: 3058.328857421875\n",
      "Epoch: 124, Batch number: 52, Loss: 3342.812744140625\n",
      "Epoch: 126, Batch number: 0, Loss: 3172.57421875\n",
      "Epoch: 127, Batch number: 24, Loss: 3174.682861328125\n",
      "Epoch: 128, Batch number: 48, Loss: 3206.63330078125\n",
      "Epoch: 129, Batch number: 72, Loss: 3301.72265625\n",
      "Epoch: 131, Batch number: 20, Loss: 3264.4482421875\n",
      "Epoch: 132, Batch number: 44, Loss: 3310.6689453125\n",
      "Epoch: 133, Batch number: 68, Loss: 3291.834716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135, Batch number: 16, Loss: 3124.93310546875\n",
      "Epoch: 136, Batch number: 40, Loss: 3237.58984375\n",
      "Epoch: 137, Batch number: 64, Loss: 3339.762939453125\n",
      "Epoch: 139, Batch number: 12, Loss: 3202.705810546875\n",
      "Epoch: 140, Batch number: 36, Loss: 3198.29931640625\n",
      "Epoch: 141, Batch number: 60, Loss: 3182.290771484375\n",
      "Epoch: 143, Batch number: 8, Loss: 3047.377197265625\n",
      "Epoch: 144, Batch number: 32, Loss: 3148.760009765625\n",
      "Epoch: 145, Batch number: 56, Loss: 3467.434814453125\n",
      "Epoch: 147, Batch number: 4, Loss: 3173.24853515625\n",
      "Epoch: 148, Batch number: 28, Loss: 3391.103759765625\n",
      "Epoch: 149, Batch number: 52, Loss: 3420.861572265625\n",
      "Epoch: 151, Batch number: 0, Loss: 3155.928955078125\n",
      "Epoch: 152, Batch number: 24, Loss: 3201.55517578125\n",
      "Epoch: 153, Batch number: 48, Loss: 3229.9248046875\n",
      "Epoch: 154, Batch number: 72, Loss: 3463.863037109375\n",
      "Epoch: 156, Batch number: 20, Loss: 3263.87548828125\n",
      "Epoch: 157, Batch number: 44, Loss: 3245.53759765625\n",
      "Epoch: 158, Batch number: 68, Loss: 3280.0\n",
      "Epoch: 160, Batch number: 16, Loss: 3291.312744140625\n",
      "Epoch: 161, Batch number: 40, Loss: 3310.742431640625\n",
      "Epoch: 162, Batch number: 64, Loss: 3337.697998046875\n",
      "Epoch: 164, Batch number: 12, Loss: 3178.259765625\n",
      "Epoch: 165, Batch number: 36, Loss: 3276.8701171875\n",
      "Epoch: 166, Batch number: 60, Loss: 3350.2080078125\n",
      "Epoch: 168, Batch number: 8, Loss: 3120.01318359375\n",
      "Epoch: 169, Batch number: 32, Loss: 3134.255126953125\n",
      "Epoch: 170, Batch number: 56, Loss: 3400.463134765625\n",
      "Epoch: 172, Batch number: 4, Loss: 3214.107421875\n",
      "Epoch: 173, Batch number: 28, Loss: 3179.705078125\n",
      "Epoch: 174, Batch number: 52, Loss: 3331.503662109375\n",
      "Epoch: 176, Batch number: 0, Loss: 3228.8486328125\n",
      "Epoch: 177, Batch number: 24, Loss: 3209.691162109375\n",
      "Epoch: 178, Batch number: 48, Loss: 3382.158447265625\n",
      "Epoch: 179, Batch number: 72, Loss: 3305.450439453125\n",
      "Epoch: 181, Batch number: 20, Loss: 3149.876220703125\n",
      "Epoch: 182, Batch number: 44, Loss: 3143.055419921875\n",
      "Epoch: 183, Batch number: 68, Loss: 3398.4150390625\n",
      "Epoch: 185, Batch number: 16, Loss: 3241.055908203125\n",
      "Epoch: 186, Batch number: 40, Loss: 3178.662841796875\n",
      "Epoch: 187, Batch number: 64, Loss: 3406.123046875\n",
      "Epoch: 189, Batch number: 12, Loss: 3011.2216796875\n",
      "Epoch: 190, Batch number: 36, Loss: 3164.489501953125\n",
      "Epoch: 191, Batch number: 60, Loss: 3363.2548828125\n",
      "Epoch: 193, Batch number: 8, Loss: 3191.65771484375\n",
      "Epoch: 194, Batch number: 32, Loss: 3264.2265625\n",
      "Epoch: 195, Batch number: 56, Loss: 3312.480712890625\n",
      "Epoch: 197, Batch number: 4, Loss: 3143.41455078125\n",
      "Epoch: 198, Batch number: 28, Loss: 3294.989990234375\n",
      "Epoch: 199, Batch number: 52, Loss: 3200.576904296875\n",
      "Epoch: 201, Batch number: 0, Loss: 3276.043701171875\n",
      "Epoch: 202, Batch number: 24, Loss: 3159.46484375\n",
      "Epoch: 203, Batch number: 48, Loss: 3318.79736328125\n",
      "Epoch: 204, Batch number: 72, Loss: 3335.203369140625\n",
      "Epoch: 206, Batch number: 20, Loss: 3133.63037109375\n",
      "Epoch: 207, Batch number: 44, Loss: 3264.195068359375\n",
      "Epoch: 208, Batch number: 68, Loss: 3321.395751953125\n",
      "Epoch: 210, Batch number: 16, Loss: 3225.5390625\n",
      "Epoch: 211, Batch number: 40, Loss: 3342.110107421875\n",
      "Epoch: 212, Batch number: 64, Loss: 3417.11181640625\n",
      "Epoch: 214, Batch number: 12, Loss: 3074.412109375\n",
      "Epoch: 215, Batch number: 36, Loss: 3442.914794921875\n",
      "Epoch: 216, Batch number: 60, Loss: 3460.400146484375\n",
      "Epoch: 218, Batch number: 8, Loss: 3194.311767578125\n",
      "Epoch: 219, Batch number: 32, Loss: 3104.816162109375\n",
      "Epoch: 220, Batch number: 56, Loss: 3312.619384765625\n",
      "Epoch: 222, Batch number: 4, Loss: 3179.57421875\n",
      "Epoch: 223, Batch number: 28, Loss: 3172.8671875\n",
      "Epoch: 224, Batch number: 52, Loss: 3313.66650390625\n",
      "Epoch: 226, Batch number: 0, Loss: 3161.5341796875\n",
      "Epoch: 227, Batch number: 24, Loss: 3251.2939453125\n",
      "Epoch: 228, Batch number: 48, Loss: 3308.192138671875\n",
      "Epoch: 229, Batch number: 72, Loss: 3232.06591796875\n",
      "Epoch: 231, Batch number: 20, Loss: 3063.14013671875\n",
      "Epoch: 232, Batch number: 44, Loss: 3381.33935546875\n",
      "Epoch: 233, Batch number: 68, Loss: 3243.04345703125\n",
      "Epoch: 235, Batch number: 16, Loss: 3094.515625\n",
      "Epoch: 236, Batch number: 40, Loss: 3300.34375\n",
      "Epoch: 237, Batch number: 64, Loss: 3254.844482421875\n",
      "Epoch: 239, Batch number: 12, Loss: 3214.15380859375\n",
      "Epoch: 240, Batch number: 36, Loss: 3393.46923828125\n",
      "Epoch: 241, Batch number: 60, Loss: 3307.72314453125\n",
      "Epoch: 243, Batch number: 8, Loss: 3080.381103515625\n",
      "Epoch: 244, Batch number: 32, Loss: 3353.120361328125\n",
      "Epoch: 245, Batch number: 56, Loss: 3204.087890625\n",
      "Epoch: 247, Batch number: 4, Loss: 3196.8828125\n",
      "Epoch: 248, Batch number: 28, Loss: 3181.95556640625\n",
      "Epoch: 249, Batch number: 52, Loss: 3491.53173828125\n",
      "Epoch: 251, Batch number: 0, Loss: 3214.7080078125\n",
      "Epoch: 252, Batch number: 24, Loss: 3059.124267578125\n",
      "Epoch: 253, Batch number: 48, Loss: 3180.45654296875\n",
      "Epoch: 254, Batch number: 72, Loss: 3149.68017578125\n",
      "Epoch: 256, Batch number: 20, Loss: 3179.989990234375\n",
      "Epoch: 257, Batch number: 44, Loss: 3232.177001953125\n",
      "Epoch: 258, Batch number: 68, Loss: 3369.74072265625\n",
      "Epoch: 260, Batch number: 16, Loss: 3066.838134765625\n",
      "Epoch: 261, Batch number: 40, Loss: 3310.6298828125\n",
      "Epoch: 262, Batch number: 64, Loss: 3154.379638671875\n",
      "Epoch: 264, Batch number: 12, Loss: 3033.27978515625\n",
      "Epoch: 265, Batch number: 36, Loss: 3184.300537109375\n",
      "Epoch: 266, Batch number: 60, Loss: 3256.5380859375\n",
      "Epoch: 268, Batch number: 8, Loss: 3235.080810546875\n",
      "Epoch: 269, Batch number: 32, Loss: 3099.213134765625\n",
      "Epoch: 270, Batch number: 56, Loss: 3209.0595703125\n",
      "Epoch: 272, Batch number: 4, Loss: 3100.5458984375\n",
      "Epoch: 273, Batch number: 28, Loss: 3235.958740234375\n",
      "Epoch: 274, Batch number: 52, Loss: 3338.15185546875\n",
      "Epoch: 276, Batch number: 0, Loss: 3111.594970703125\n",
      "Epoch: 277, Batch number: 24, Loss: 3476.105712890625\n",
      "Epoch: 278, Batch number: 48, Loss: 3221.00048828125\n",
      "Epoch: 279, Batch number: 72, Loss: 3318.1318359375\n",
      "Epoch: 281, Batch number: 20, Loss: 3271.489013671875\n",
      "Epoch: 282, Batch number: 44, Loss: 3229.880126953125\n",
      "Epoch: 283, Batch number: 68, Loss: 3358.0673828125\n",
      "Epoch: 285, Batch number: 16, Loss: 3208.08544921875\n",
      "Epoch: 286, Batch number: 40, Loss: 3109.450439453125\n",
      "Epoch: 287, Batch number: 64, Loss: 3326.61767578125\n",
      "Epoch: 289, Batch number: 12, Loss: 3258.887939453125\n",
      "Epoch: 290, Batch number: 36, Loss: 3285.286376953125\n",
      "Epoch: 291, Batch number: 60, Loss: 3310.115478515625\n",
      "Epoch: 293, Batch number: 8, Loss: 3238.716796875\n",
      "Epoch: 294, Batch number: 32, Loss: 3184.926025390625\n",
      "Epoch: 295, Batch number: 56, Loss: 3379.8330078125\n",
      "Epoch: 297, Batch number: 4, Loss: 3188.593505859375\n",
      "Epoch: 298, Batch number: 28, Loss: 3140.13037109375\n",
      "Epoch: 299, Batch number: 52, Loss: 3310.767333984375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15144.94921875\n",
      "Epoch: 2, Batch number: 24, Loss: 14699.0859375\n",
      "Epoch: 3, Batch number: 48, Loss: 14769.03125\n",
      "Epoch: 4, Batch number: 72, Loss: 13855.490234375\n",
      "Epoch: 6, Batch number: 20, Loss: 13644.9892578125\n",
      "Epoch: 7, Batch number: 44, Loss: 13241.255859375\n",
      "Epoch: 8, Batch number: 68, Loss: 12901.18359375\n",
      "Epoch: 10, Batch number: 16, Loss: 12645.69140625\n",
      "Epoch: 11, Batch number: 40, Loss: 12270.5849609375\n",
      "Epoch: 12, Batch number: 64, Loss: 12242.5\n",
      "Epoch: 14, Batch number: 12, Loss: 11833.8076171875\n",
      "Epoch: 15, Batch number: 36, Loss: 11793.4765625\n",
      "Epoch: 16, Batch number: 60, Loss: 11743.828125\n",
      "Epoch: 18, Batch number: 8, Loss: 11371.947265625\n",
      "Epoch: 19, Batch number: 32, Loss: 11282.1298828125\n",
      "Epoch: 20, Batch number: 56, Loss: 11034.958984375\n",
      "Epoch: 22, Batch number: 4, Loss: 10979.388671875\n",
      "Epoch: 23, Batch number: 28, Loss: 10931.9228515625\n",
      "Epoch: 24, Batch number: 52, Loss: 10646.90625\n",
      "Epoch: 26, Batch number: 0, Loss: 10669.1064453125\n",
      "Epoch: 27, Batch number: 24, Loss: 10538.1474609375\n",
      "Epoch: 28, Batch number: 48, Loss: 10557.87890625\n",
      "Epoch: 29, Batch number: 72, Loss: 10770.9609375\n",
      "Epoch: 31, Batch number: 20, Loss: 10162.7685546875\n",
      "Epoch: 32, Batch number: 44, Loss: 10159.92578125\n",
      "Epoch: 33, Batch number: 68, Loss: 10113.4384765625\n",
      "Epoch: 35, Batch number: 16, Loss: 9966.5498046875\n",
      "Epoch: 36, Batch number: 40, Loss: 10204.650390625\n",
      "Epoch: 37, Batch number: 64, Loss: 10231.1953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Batch number: 12, Loss: 9672.78125\n",
      "Epoch: 40, Batch number: 36, Loss: 9806.703125\n",
      "Epoch: 41, Batch number: 60, Loss: 9967.07421875\n",
      "Epoch: 43, Batch number: 8, Loss: 9735.8447265625\n",
      "Epoch: 44, Batch number: 32, Loss: 9873.1845703125\n",
      "Epoch: 45, Batch number: 56, Loss: 9593.8974609375\n",
      "Epoch: 47, Batch number: 4, Loss: 9590.404296875\n",
      "Epoch: 48, Batch number: 28, Loss: 9518.486328125\n",
      "Epoch: 49, Batch number: 52, Loss: 9552.1318359375\n",
      "Epoch: 51, Batch number: 0, Loss: 9626.1787109375\n",
      "Epoch: 52, Batch number: 24, Loss: 9564.9580078125\n",
      "Epoch: 53, Batch number: 48, Loss: 9436.1474609375\n",
      "Epoch: 54, Batch number: 72, Loss: 9489.7333984375\n",
      "Epoch: 56, Batch number: 20, Loss: 9174.2373046875\n",
      "Epoch: 57, Batch number: 44, Loss: 9075.7021484375\n",
      "Epoch: 58, Batch number: 68, Loss: 9274.322265625\n",
      "Epoch: 60, Batch number: 16, Loss: 9212.1533203125\n",
      "Epoch: 61, Batch number: 40, Loss: 9349.97265625\n",
      "Epoch: 62, Batch number: 64, Loss: 9362.6181640625\n",
      "Epoch: 64, Batch number: 12, Loss: 9253.3701171875\n",
      "Epoch: 65, Batch number: 36, Loss: 9322.203125\n",
      "Epoch: 66, Batch number: 60, Loss: 9124.69921875\n",
      "Epoch: 68, Batch number: 8, Loss: 8989.9296875\n",
      "Epoch: 69, Batch number: 32, Loss: 9075.0966796875\n",
      "Epoch: 70, Batch number: 56, Loss: 9277.193359375\n",
      "Epoch: 72, Batch number: 4, Loss: 8928.1982421875\n",
      "Epoch: 73, Batch number: 28, Loss: 9160.419921875\n",
      "Epoch: 74, Batch number: 52, Loss: 9010.7880859375\n",
      "Epoch: 76, Batch number: 0, Loss: 8998.029296875\n",
      "Epoch: 77, Batch number: 24, Loss: 8958.7578125\n",
      "Epoch: 78, Batch number: 48, Loss: 8763.185546875\n",
      "Epoch: 79, Batch number: 72, Loss: 8786.435546875\n",
      "Epoch: 81, Batch number: 20, Loss: 8928.73046875\n",
      "Epoch: 82, Batch number: 44, Loss: 8806.0341796875\n",
      "Epoch: 83, Batch number: 68, Loss: 9095.453125\n",
      "Epoch: 85, Batch number: 16, Loss: 8683.9345703125\n",
      "Epoch: 86, Batch number: 40, Loss: 8742.2021484375\n",
      "Epoch: 87, Batch number: 64, Loss: 8766.6826171875\n",
      "Epoch: 89, Batch number: 12, Loss: 8802.80859375\n",
      "Epoch: 90, Batch number: 36, Loss: 8859.357421875\n",
      "Epoch: 91, Batch number: 60, Loss: 8695.08203125\n",
      "Epoch: 93, Batch number: 8, Loss: 8641.7470703125\n",
      "Epoch: 94, Batch number: 32, Loss: 8812.0126953125\n",
      "Epoch: 95, Batch number: 56, Loss: 8636.6552734375\n",
      "Epoch: 97, Batch number: 4, Loss: 8769.6279296875\n",
      "Epoch: 98, Batch number: 28, Loss: 8604.697265625\n",
      "Epoch: 99, Batch number: 52, Loss: 8540.4326171875\n",
      "Epoch: 101, Batch number: 0, Loss: 8522.5810546875\n",
      "Epoch: 102, Batch number: 24, Loss: 8579.2890625\n",
      "Epoch: 103, Batch number: 48, Loss: 8555.451171875\n",
      "Epoch: 104, Batch number: 72, Loss: 8721.1357421875\n",
      "Epoch: 106, Batch number: 20, Loss: 8576.75390625\n",
      "Epoch: 107, Batch number: 44, Loss: 8515.7841796875\n",
      "Epoch: 108, Batch number: 68, Loss: 8747.6484375\n",
      "Epoch: 110, Batch number: 16, Loss: 8379.5224609375\n",
      "Epoch: 111, Batch number: 40, Loss: 8401.2744140625\n",
      "Epoch: 112, Batch number: 64, Loss: 8516.3984375\n",
      "Epoch: 114, Batch number: 12, Loss: 8215.69921875\n",
      "Epoch: 115, Batch number: 36, Loss: 8406.599609375\n",
      "Epoch: 116, Batch number: 60, Loss: 8501.31640625\n",
      "Epoch: 118, Batch number: 8, Loss: 8255.892578125\n",
      "Epoch: 119, Batch number: 32, Loss: 8200.869140625\n",
      "Epoch: 120, Batch number: 56, Loss: 8267.2421875\n",
      "Epoch: 122, Batch number: 4, Loss: 8302.029296875\n",
      "Epoch: 123, Batch number: 28, Loss: 8400.64453125\n",
      "Epoch: 124, Batch number: 52, Loss: 8390.0390625\n",
      "Epoch: 126, Batch number: 0, Loss: 8243.400390625\n",
      "Epoch: 127, Batch number: 24, Loss: 8038.38818359375\n",
      "Epoch: 128, Batch number: 48, Loss: 8035.43017578125\n",
      "Epoch: 129, Batch number: 72, Loss: 8235.5771484375\n",
      "Epoch: 131, Batch number: 20, Loss: 8320.3056640625\n",
      "Epoch: 132, Batch number: 44, Loss: 8261.6572265625\n",
      "Epoch: 133, Batch number: 68, Loss: 8096.36669921875\n",
      "Epoch: 135, Batch number: 16, Loss: 8395.201171875\n",
      "Epoch: 136, Batch number: 40, Loss: 8081.97314453125\n",
      "Epoch: 137, Batch number: 64, Loss: 8412.802734375\n",
      "Epoch: 139, Batch number: 12, Loss: 8140.9599609375\n",
      "Epoch: 140, Batch number: 36, Loss: 8029.16650390625\n",
      "Epoch: 141, Batch number: 60, Loss: 8098.947265625\n",
      "Epoch: 143, Batch number: 8, Loss: 8113.8779296875\n",
      "Epoch: 144, Batch number: 32, Loss: 7924.74072265625\n",
      "Epoch: 145, Batch number: 56, Loss: 8151.017578125\n",
      "Epoch: 147, Batch number: 4, Loss: 8334.66015625\n",
      "Epoch: 148, Batch number: 28, Loss: 8219.966796875\n",
      "Epoch: 149, Batch number: 52, Loss: 8135.33447265625\n",
      "Epoch: 151, Batch number: 0, Loss: 7890.703125\n",
      "Epoch: 152, Batch number: 24, Loss: 8381.1650390625\n",
      "Epoch: 153, Batch number: 48, Loss: 7625.06396484375\n",
      "Epoch: 154, Batch number: 72, Loss: 8047.47900390625\n",
      "Epoch: 156, Batch number: 20, Loss: 8041.658203125\n",
      "Epoch: 157, Batch number: 44, Loss: 7894.72021484375\n",
      "Epoch: 158, Batch number: 68, Loss: 8167.6123046875\n",
      "Epoch: 160, Batch number: 16, Loss: 8159.15673828125\n",
      "Epoch: 161, Batch number: 40, Loss: 8127.35009765625\n",
      "Epoch: 162, Batch number: 64, Loss: 8057.611328125\n",
      "Epoch: 164, Batch number: 12, Loss: 8082.2080078125\n",
      "Epoch: 165, Batch number: 36, Loss: 8241.6767578125\n",
      "Epoch: 166, Batch number: 60, Loss: 8036.72900390625\n",
      "Epoch: 168, Batch number: 8, Loss: 7973.09130859375\n",
      "Epoch: 169, Batch number: 32, Loss: 7753.91748046875\n",
      "Epoch: 170, Batch number: 56, Loss: 7942.39404296875\n",
      "Epoch: 172, Batch number: 4, Loss: 8075.1796875\n",
      "Epoch: 173, Batch number: 28, Loss: 7867.9453125\n",
      "Epoch: 174, Batch number: 52, Loss: 7778.55126953125\n",
      "Epoch: 176, Batch number: 0, Loss: 7981.46533203125\n",
      "Epoch: 177, Batch number: 24, Loss: 8048.62744140625\n",
      "Epoch: 178, Batch number: 48, Loss: 7744.24609375\n",
      "Epoch: 179, Batch number: 72, Loss: 7807.30859375\n",
      "Epoch: 181, Batch number: 20, Loss: 7979.1982421875\n",
      "Epoch: 182, Batch number: 44, Loss: 7680.787109375\n",
      "Epoch: 183, Batch number: 68, Loss: 7883.58642578125\n",
      "Epoch: 185, Batch number: 16, Loss: 7748.8515625\n",
      "Epoch: 186, Batch number: 40, Loss: 7761.44970703125\n",
      "Epoch: 187, Batch number: 64, Loss: 8011.35009765625\n",
      "Epoch: 189, Batch number: 12, Loss: 7840.8115234375\n",
      "Epoch: 190, Batch number: 36, Loss: 7928.70751953125\n",
      "Epoch: 191, Batch number: 60, Loss: 7805.79443359375\n",
      "Epoch: 193, Batch number: 8, Loss: 7637.541015625\n",
      "Epoch: 194, Batch number: 32, Loss: 7896.44287109375\n",
      "Epoch: 195, Batch number: 56, Loss: 7857.36181640625\n",
      "Epoch: 197, Batch number: 4, Loss: 7740.0234375\n",
      "Epoch: 198, Batch number: 28, Loss: 7925.7001953125\n",
      "Epoch: 199, Batch number: 52, Loss: 7687.83349609375\n",
      "Epoch: 201, Batch number: 0, Loss: 7673.08447265625\n",
      "Epoch: 202, Batch number: 24, Loss: 7667.6923828125\n",
      "Epoch: 203, Batch number: 48, Loss: 7636.71044921875\n",
      "Epoch: 204, Batch number: 72, Loss: 7800.3837890625\n",
      "Epoch: 206, Batch number: 20, Loss: 7576.70703125\n",
      "Epoch: 207, Batch number: 44, Loss: 7783.3056640625\n",
      "Epoch: 208, Batch number: 68, Loss: 7954.45751953125\n",
      "Epoch: 210, Batch number: 16, Loss: 7839.57275390625\n",
      "Epoch: 211, Batch number: 40, Loss: 7698.525390625\n",
      "Epoch: 212, Batch number: 64, Loss: 7602.08544921875\n",
      "Epoch: 214, Batch number: 12, Loss: 7770.5341796875\n",
      "Epoch: 215, Batch number: 36, Loss: 7659.72265625\n",
      "Epoch: 216, Batch number: 60, Loss: 7985.5205078125\n",
      "Epoch: 218, Batch number: 8, Loss: 7518.40380859375\n",
      "Epoch: 219, Batch number: 32, Loss: 7544.337890625\n",
      "Epoch: 220, Batch number: 56, Loss: 7683.83251953125\n",
      "Epoch: 222, Batch number: 4, Loss: 7858.41552734375\n",
      "Epoch: 223, Batch number: 28, Loss: 7634.6767578125\n",
      "Epoch: 224, Batch number: 52, Loss: 7395.380859375\n",
      "Epoch: 226, Batch number: 0, Loss: 7544.689453125\n",
      "Epoch: 227, Batch number: 24, Loss: 7783.8173828125\n",
      "Epoch: 228, Batch number: 48, Loss: 7817.9638671875\n",
      "Epoch: 229, Batch number: 72, Loss: 7534.1923828125\n",
      "Epoch: 231, Batch number: 20, Loss: 7802.94677734375\n",
      "Epoch: 232, Batch number: 44, Loss: 7739.13232421875\n",
      "Epoch: 233, Batch number: 68, Loss: 7760.00830078125\n",
      "Epoch: 235, Batch number: 16, Loss: 7450.1875\n",
      "Epoch: 236, Batch number: 40, Loss: 7790.2939453125\n",
      "Epoch: 237, Batch number: 64, Loss: 7644.88818359375\n",
      "Epoch: 239, Batch number: 12, Loss: 7656.09765625\n",
      "Epoch: 240, Batch number: 36, Loss: 7891.47265625\n",
      "Epoch: 241, Batch number: 60, Loss: 7590.205078125\n",
      "Epoch: 243, Batch number: 8, Loss: 7297.8291015625\n",
      "Epoch: 244, Batch number: 32, Loss: 7729.54296875\n",
      "Epoch: 245, Batch number: 56, Loss: 7501.748046875\n",
      "Epoch: 247, Batch number: 4, Loss: 7494.60595703125\n",
      "Epoch: 248, Batch number: 28, Loss: 7518.1181640625\n",
      "Epoch: 249, Batch number: 52, Loss: 7438.06640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251, Batch number: 0, Loss: 7667.75390625\n",
      "Epoch: 252, Batch number: 24, Loss: 7475.31689453125\n",
      "Epoch: 253, Batch number: 48, Loss: 7643.39306640625\n",
      "Epoch: 254, Batch number: 72, Loss: 7316.578125\n",
      "Epoch: 256, Batch number: 20, Loss: 7373.359375\n",
      "Epoch: 257, Batch number: 44, Loss: 7400.08837890625\n",
      "Epoch: 258, Batch number: 68, Loss: 7447.3408203125\n",
      "Epoch: 260, Batch number: 16, Loss: 7266.2568359375\n",
      "Epoch: 261, Batch number: 40, Loss: 7576.00634765625\n",
      "Epoch: 262, Batch number: 64, Loss: 7575.17236328125\n",
      "Epoch: 264, Batch number: 12, Loss: 7555.60791015625\n",
      "Epoch: 265, Batch number: 36, Loss: 7527.015625\n",
      "Epoch: 266, Batch number: 60, Loss: 7690.62451171875\n",
      "Epoch: 268, Batch number: 8, Loss: 7654.890625\n",
      "Epoch: 269, Batch number: 32, Loss: 7517.98779296875\n",
      "Epoch: 270, Batch number: 56, Loss: 7711.6630859375\n",
      "Epoch: 272, Batch number: 4, Loss: 7332.67822265625\n",
      "Epoch: 273, Batch number: 28, Loss: 7586.30712890625\n",
      "Epoch: 274, Batch number: 52, Loss: 7560.482421875\n",
      "Epoch: 276, Batch number: 0, Loss: 7468.6044921875\n",
      "Epoch: 277, Batch number: 24, Loss: 7534.38525390625\n",
      "Epoch: 278, Batch number: 48, Loss: 7686.41015625\n",
      "Epoch: 279, Batch number: 72, Loss: 7480.83056640625\n",
      "Epoch: 281, Batch number: 20, Loss: 7474.51953125\n",
      "Epoch: 282, Batch number: 44, Loss: 7385.9287109375\n",
      "Epoch: 283, Batch number: 68, Loss: 7681.2998046875\n",
      "Epoch: 285, Batch number: 16, Loss: 7590.59375\n",
      "Epoch: 286, Batch number: 40, Loss: 7616.49560546875\n",
      "Epoch: 287, Batch number: 64, Loss: 7544.666015625\n",
      "Epoch: 289, Batch number: 12, Loss: 7574.76123046875\n",
      "Epoch: 290, Batch number: 36, Loss: 7501.24853515625\n",
      "Epoch: 291, Batch number: 60, Loss: 7483.44873046875\n",
      "Epoch: 293, Batch number: 8, Loss: 7593.740234375\n",
      "Epoch: 294, Batch number: 32, Loss: 7420.37060546875\n",
      "Epoch: 295, Batch number: 56, Loss: 7408.3525390625\n",
      "Epoch: 297, Batch number: 4, Loss: 7181.626953125\n",
      "Epoch: 298, Batch number: 28, Loss: 7229.3447265625\n",
      "Epoch: 299, Batch number: 52, Loss: 7410.8720703125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15150.455078125\n",
      "Epoch: 2, Batch number: 24, Loss: 14790.7353515625\n",
      "Epoch: 3, Batch number: 48, Loss: 14150.857421875\n",
      "Epoch: 4, Batch number: 72, Loss: 13473.8828125\n",
      "Epoch: 6, Batch number: 20, Loss: 12710.6171875\n",
      "Epoch: 7, Batch number: 44, Loss: 12573.4208984375\n",
      "Epoch: 8, Batch number: 68, Loss: 12216.845703125\n",
      "Epoch: 10, Batch number: 16, Loss: 11987.365234375\n",
      "Epoch: 11, Batch number: 40, Loss: 11296.0986328125\n",
      "Epoch: 12, Batch number: 64, Loss: 11381.2578125\n",
      "Epoch: 14, Batch number: 12, Loss: 11082.3662109375\n",
      "Epoch: 15, Batch number: 36, Loss: 10571.3837890625\n",
      "Epoch: 16, Batch number: 60, Loss: 10722.810546875\n",
      "Epoch: 18, Batch number: 8, Loss: 10150.0078125\n",
      "Epoch: 19, Batch number: 32, Loss: 10026.5966796875\n",
      "Epoch: 20, Batch number: 56, Loss: 10069.6171875\n",
      "Epoch: 22, Batch number: 4, Loss: 10035.853515625\n",
      "Epoch: 23, Batch number: 28, Loss: 9875.5888671875\n",
      "Epoch: 24, Batch number: 52, Loss: 9826.8828125\n",
      "Epoch: 26, Batch number: 0, Loss: 9582.3818359375\n",
      "Epoch: 27, Batch number: 24, Loss: 9453.49609375\n",
      "Epoch: 28, Batch number: 48, Loss: 9426.59375\n",
      "Epoch: 29, Batch number: 72, Loss: 9250.158203125\n",
      "Epoch: 31, Batch number: 20, Loss: 9389.2978515625\n",
      "Epoch: 32, Batch number: 44, Loss: 8887.841796875\n",
      "Epoch: 33, Batch number: 68, Loss: 8960.92578125\n",
      "Epoch: 35, Batch number: 16, Loss: 8884.0625\n",
      "Epoch: 36, Batch number: 40, Loss: 9056.38671875\n",
      "Epoch: 37, Batch number: 64, Loss: 9062.1650390625\n",
      "Epoch: 39, Batch number: 12, Loss: 8974.662109375\n",
      "Epoch: 40, Batch number: 36, Loss: 8719.5693359375\n",
      "Epoch: 41, Batch number: 60, Loss: 8791.6474609375\n",
      "Epoch: 43, Batch number: 8, Loss: 8583.697265625\n",
      "Epoch: 44, Batch number: 32, Loss: 8650.66796875\n",
      "Epoch: 45, Batch number: 56, Loss: 8623.8095703125\n",
      "Epoch: 47, Batch number: 4, Loss: 8521.396484375\n",
      "Epoch: 48, Batch number: 28, Loss: 8515.6181640625\n",
      "Epoch: 49, Batch number: 52, Loss: 8674.4189453125\n",
      "Epoch: 51, Batch number: 0, Loss: 8514.6484375\n",
      "Epoch: 52, Batch number: 24, Loss: 8447.41796875\n",
      "Epoch: 53, Batch number: 48, Loss: 8445.626953125\n",
      "Epoch: 54, Batch number: 72, Loss: 8510.4365234375\n",
      "Epoch: 56, Batch number: 20, Loss: 8461.6064453125\n",
      "Epoch: 57, Batch number: 44, Loss: 8335.5986328125\n",
      "Epoch: 58, Batch number: 68, Loss: 8264.4853515625\n",
      "Epoch: 60, Batch number: 16, Loss: 8045.466796875\n",
      "Epoch: 61, Batch number: 40, Loss: 8216.537109375\n",
      "Epoch: 62, Batch number: 64, Loss: 8118.0498046875\n",
      "Epoch: 64, Batch number: 12, Loss: 8339.8251953125\n",
      "Epoch: 65, Batch number: 36, Loss: 8140.08154296875\n",
      "Epoch: 66, Batch number: 60, Loss: 8259.65234375\n",
      "Epoch: 68, Batch number: 8, Loss: 8030.92138671875\n",
      "Epoch: 69, Batch number: 32, Loss: 8074.4677734375\n",
      "Epoch: 70, Batch number: 56, Loss: 8012.6064453125\n",
      "Epoch: 72, Batch number: 4, Loss: 8226.7158203125\n",
      "Epoch: 73, Batch number: 28, Loss: 8102.109375\n",
      "Epoch: 74, Batch number: 52, Loss: 8015.51318359375\n",
      "Epoch: 76, Batch number: 0, Loss: 7854.0673828125\n",
      "Epoch: 77, Batch number: 24, Loss: 8072.65087890625\n",
      "Epoch: 78, Batch number: 48, Loss: 8145.19287109375\n",
      "Epoch: 79, Batch number: 72, Loss: 8064.5546875\n",
      "Epoch: 81, Batch number: 20, Loss: 7712.9775390625\n",
      "Epoch: 82, Batch number: 44, Loss: 7737.232421875\n",
      "Epoch: 83, Batch number: 68, Loss: 8038.65380859375\n",
      "Epoch: 85, Batch number: 16, Loss: 7640.72265625\n",
      "Epoch: 86, Batch number: 40, Loss: 7850.99267578125\n",
      "Epoch: 87, Batch number: 64, Loss: 7876.13720703125\n",
      "Epoch: 89, Batch number: 12, Loss: 7762.1572265625\n",
      "Epoch: 90, Batch number: 36, Loss: 7792.5810546875\n",
      "Epoch: 91, Batch number: 60, Loss: 8004.90625\n",
      "Epoch: 93, Batch number: 8, Loss: 7849.4697265625\n",
      "Epoch: 94, Batch number: 32, Loss: 7772.23779296875\n",
      "Epoch: 95, Batch number: 56, Loss: 7731.1162109375\n",
      "Epoch: 97, Batch number: 4, Loss: 7568.13134765625\n",
      "Epoch: 98, Batch number: 28, Loss: 7814.37939453125\n",
      "Epoch: 99, Batch number: 52, Loss: 7864.4140625\n",
      "Epoch: 101, Batch number: 0, Loss: 7877.15478515625\n",
      "Epoch: 102, Batch number: 24, Loss: 7528.76025390625\n",
      "Epoch: 103, Batch number: 48, Loss: 7883.71044921875\n",
      "Epoch: 104, Batch number: 72, Loss: 7681.4033203125\n",
      "Epoch: 106, Batch number: 20, Loss: 7822.10888671875\n",
      "Epoch: 107, Batch number: 44, Loss: 7681.96533203125\n",
      "Epoch: 108, Batch number: 68, Loss: 7519.01416015625\n",
      "Epoch: 110, Batch number: 16, Loss: 7529.505859375\n",
      "Epoch: 111, Batch number: 40, Loss: 7705.732421875\n",
      "Epoch: 112, Batch number: 64, Loss: 7459.0234375\n",
      "Epoch: 114, Batch number: 12, Loss: 7694.52392578125\n",
      "Epoch: 115, Batch number: 36, Loss: 7592.79345703125\n",
      "Epoch: 116, Batch number: 60, Loss: 7624.6640625\n",
      "Epoch: 118, Batch number: 8, Loss: 7224.04638671875\n",
      "Epoch: 119, Batch number: 32, Loss: 7202.72509765625\n",
      "Epoch: 120, Batch number: 56, Loss: 7523.1650390625\n",
      "Epoch: 122, Batch number: 4, Loss: 7591.0703125\n",
      "Epoch: 123, Batch number: 28, Loss: 7440.47705078125\n",
      "Epoch: 124, Batch number: 52, Loss: 7512.64599609375\n",
      "Epoch: 126, Batch number: 0, Loss: 7520.4912109375\n",
      "Epoch: 127, Batch number: 24, Loss: 7607.85595703125\n",
      "Epoch: 128, Batch number: 48, Loss: 7675.3564453125\n",
      "Epoch: 129, Batch number: 72, Loss: 7594.380859375\n",
      "Epoch: 131, Batch number: 20, Loss: 7265.22607421875\n",
      "Epoch: 132, Batch number: 44, Loss: 7578.78515625\n",
      "Epoch: 133, Batch number: 68, Loss: 7286.833984375\n",
      "Epoch: 135, Batch number: 16, Loss: 7348.31982421875\n",
      "Epoch: 136, Batch number: 40, Loss: 7597.07373046875\n",
      "Epoch: 137, Batch number: 64, Loss: 7281.16455078125\n",
      "Epoch: 139, Batch number: 12, Loss: 7350.607421875\n",
      "Epoch: 140, Batch number: 36, Loss: 7230.81298828125\n",
      "Epoch: 141, Batch number: 60, Loss: 7288.47705078125\n",
      "Epoch: 143, Batch number: 8, Loss: 7303.216796875\n",
      "Epoch: 144, Batch number: 32, Loss: 7374.69287109375\n",
      "Epoch: 145, Batch number: 56, Loss: 7298.81201171875\n",
      "Epoch: 147, Batch number: 4, Loss: 7202.27099609375\n",
      "Epoch: 148, Batch number: 28, Loss: 7357.5625\n",
      "Epoch: 149, Batch number: 52, Loss: 7271.25146484375\n",
      "Epoch: 151, Batch number: 0, Loss: 7375.078125\n",
      "Epoch: 152, Batch number: 24, Loss: 7449.765625\n",
      "Epoch: 153, Batch number: 48, Loss: 7136.65185546875\n",
      "Epoch: 154, Batch number: 72, Loss: 7356.7255859375\n",
      "Epoch: 156, Batch number: 20, Loss: 7395.6435546875\n",
      "Epoch: 157, Batch number: 44, Loss: 7303.072265625\n",
      "Epoch: 158, Batch number: 68, Loss: 7406.509765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Batch number: 16, Loss: 7234.552734375\n",
      "Epoch: 161, Batch number: 40, Loss: 7137.5341796875\n",
      "Epoch: 162, Batch number: 64, Loss: 7187.59765625\n",
      "Epoch: 164, Batch number: 12, Loss: 7301.94921875\n",
      "Epoch: 165, Batch number: 36, Loss: 7045.6708984375\n",
      "Epoch: 166, Batch number: 60, Loss: 7203.33544921875\n",
      "Epoch: 168, Batch number: 8, Loss: 7141.78173828125\n",
      "Epoch: 169, Batch number: 32, Loss: 7021.232421875\n",
      "Epoch: 170, Batch number: 56, Loss: 7038.04833984375\n",
      "Epoch: 172, Batch number: 4, Loss: 7080.3095703125\n",
      "Epoch: 173, Batch number: 28, Loss: 7116.34716796875\n",
      "Epoch: 174, Batch number: 52, Loss: 7178.11474609375\n",
      "Epoch: 176, Batch number: 0, Loss: 7043.26171875\n",
      "Epoch: 177, Batch number: 24, Loss: 7387.05859375\n",
      "Epoch: 178, Batch number: 48, Loss: 7417.2021484375\n",
      "Epoch: 179, Batch number: 72, Loss: 7106.48486328125\n",
      "Epoch: 181, Batch number: 20, Loss: 7039.306640625\n",
      "Epoch: 182, Batch number: 44, Loss: 7051.4287109375\n",
      "Epoch: 183, Batch number: 68, Loss: 7147.07470703125\n",
      "Epoch: 185, Batch number: 16, Loss: 7088.892578125\n",
      "Epoch: 186, Batch number: 40, Loss: 7338.7041015625\n",
      "Epoch: 187, Batch number: 64, Loss: 7456.1865234375\n",
      "Epoch: 189, Batch number: 12, Loss: 7031.23486328125\n",
      "Epoch: 190, Batch number: 36, Loss: 7284.697265625\n",
      "Epoch: 191, Batch number: 60, Loss: 7288.01806640625\n",
      "Epoch: 193, Batch number: 8, Loss: 7079.02783203125\n",
      "Epoch: 194, Batch number: 32, Loss: 7160.126953125\n",
      "Epoch: 195, Batch number: 56, Loss: 7286.2666015625\n",
      "Epoch: 197, Batch number: 4, Loss: 7294.056640625\n",
      "Epoch: 198, Batch number: 28, Loss: 7272.28759765625\n",
      "Epoch: 199, Batch number: 52, Loss: 7223.87353515625\n",
      "Epoch: 201, Batch number: 0, Loss: 7087.00927734375\n",
      "Epoch: 202, Batch number: 24, Loss: 6981.9208984375\n",
      "Epoch: 203, Batch number: 48, Loss: 7091.09912109375\n",
      "Epoch: 204, Batch number: 72, Loss: 6825.568359375\n",
      "Epoch: 206, Batch number: 20, Loss: 7460.28076171875\n",
      "Epoch: 207, Batch number: 44, Loss: 7228.59912109375\n",
      "Epoch: 208, Batch number: 68, Loss: 7199.73095703125\n",
      "Epoch: 210, Batch number: 16, Loss: 7176.3701171875\n",
      "Epoch: 211, Batch number: 40, Loss: 7252.37060546875\n",
      "Epoch: 212, Batch number: 64, Loss: 7230.537109375\n",
      "Epoch: 214, Batch number: 12, Loss: 7216.17626953125\n",
      "Epoch: 215, Batch number: 36, Loss: 7065.43017578125\n",
      "Epoch: 216, Batch number: 60, Loss: 7317.6845703125\n",
      "Epoch: 218, Batch number: 8, Loss: 6989.17724609375\n",
      "Epoch: 219, Batch number: 32, Loss: 6978.5009765625\n",
      "Epoch: 220, Batch number: 56, Loss: 7202.8203125\n",
      "Epoch: 222, Batch number: 4, Loss: 6861.3115234375\n",
      "Epoch: 223, Batch number: 28, Loss: 7182.19287109375\n",
      "Epoch: 224, Batch number: 52, Loss: 7267.2568359375\n",
      "Epoch: 226, Batch number: 0, Loss: 7050.884765625\n",
      "Epoch: 227, Batch number: 24, Loss: 6825.01513671875\n",
      "Epoch: 228, Batch number: 48, Loss: 7141.63427734375\n",
      "Epoch: 229, Batch number: 72, Loss: 7324.85693359375\n",
      "Epoch: 231, Batch number: 20, Loss: 7108.98388671875\n",
      "Epoch: 232, Batch number: 44, Loss: 7188.435546875\n",
      "Epoch: 233, Batch number: 68, Loss: 7053.66650390625\n",
      "Epoch: 235, Batch number: 16, Loss: 6770.86865234375\n",
      "Epoch: 236, Batch number: 40, Loss: 7142.7080078125\n",
      "Epoch: 237, Batch number: 64, Loss: 7034.87890625\n",
      "Epoch: 239, Batch number: 12, Loss: 7002.2109375\n",
      "Epoch: 240, Batch number: 36, Loss: 7292.28955078125\n",
      "Epoch: 241, Batch number: 60, Loss: 7431.4501953125\n",
      "Epoch: 243, Batch number: 8, Loss: 6974.0751953125\n",
      "Epoch: 244, Batch number: 32, Loss: 7085.83251953125\n",
      "Epoch: 245, Batch number: 56, Loss: 7082.59912109375\n",
      "Epoch: 247, Batch number: 4, Loss: 7252.6904296875\n",
      "Epoch: 248, Batch number: 28, Loss: 6892.1630859375\n",
      "Epoch: 249, Batch number: 52, Loss: 6891.23828125\n",
      "Epoch: 251, Batch number: 0, Loss: 6953.4375\n",
      "Epoch: 252, Batch number: 24, Loss: 6976.92138671875\n",
      "Epoch: 253, Batch number: 48, Loss: 7094.46044921875\n",
      "Epoch: 254, Batch number: 72, Loss: 7216.97509765625\n",
      "Epoch: 256, Batch number: 20, Loss: 6952.44091796875\n",
      "Epoch: 257, Batch number: 44, Loss: 6918.39794921875\n",
      "Epoch: 258, Batch number: 68, Loss: 6931.26611328125\n",
      "Epoch: 260, Batch number: 16, Loss: 6873.580078125\n",
      "Epoch: 261, Batch number: 40, Loss: 7119.30615234375\n",
      "Epoch: 262, Batch number: 64, Loss: 6903.6435546875\n",
      "Epoch: 264, Batch number: 12, Loss: 7022.8916015625\n",
      "Epoch: 265, Batch number: 36, Loss: 6956.865234375\n",
      "Epoch: 266, Batch number: 60, Loss: 7179.4013671875\n",
      "Epoch: 268, Batch number: 8, Loss: 6964.79345703125\n",
      "Epoch: 269, Batch number: 32, Loss: 6815.13818359375\n",
      "Epoch: 270, Batch number: 56, Loss: 7405.26513671875\n",
      "Epoch: 272, Batch number: 4, Loss: 6977.7900390625\n",
      "Epoch: 273, Batch number: 28, Loss: 7080.27392578125\n",
      "Epoch: 274, Batch number: 52, Loss: 7214.0625\n",
      "Epoch: 276, Batch number: 0, Loss: 6761.28369140625\n",
      "Epoch: 277, Batch number: 24, Loss: 7177.99609375\n",
      "Epoch: 278, Batch number: 48, Loss: 7102.5439453125\n",
      "Epoch: 279, Batch number: 72, Loss: 7073.810546875\n",
      "Epoch: 281, Batch number: 20, Loss: 6990.56884765625\n",
      "Epoch: 282, Batch number: 44, Loss: 6941.05908203125\n",
      "Epoch: 283, Batch number: 68, Loss: 7002.0302734375\n",
      "Epoch: 285, Batch number: 16, Loss: 7163.37939453125\n",
      "Epoch: 286, Batch number: 40, Loss: 7262.74609375\n",
      "Epoch: 287, Batch number: 64, Loss: 6793.88671875\n",
      "Epoch: 289, Batch number: 12, Loss: 6856.046875\n",
      "Epoch: 290, Batch number: 36, Loss: 7169.23095703125\n",
      "Epoch: 291, Batch number: 60, Loss: 7255.67431640625\n",
      "Epoch: 293, Batch number: 8, Loss: 7277.56494140625\n",
      "Epoch: 294, Batch number: 32, Loss: 7035.71826171875\n",
      "Epoch: 295, Batch number: 56, Loss: 6710.28125\n",
      "Epoch: 297, Batch number: 4, Loss: 7050.32763671875\n",
      "Epoch: 298, Batch number: 28, Loss: 6924.43115234375\n",
      "Epoch: 299, Batch number: 52, Loss: 6849.49560546875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15584.326171875\n",
      "Epoch: 2, Batch number: 24, Loss: 14276.2841796875\n",
      "Epoch: 3, Batch number: 48, Loss: 13654.390625\n",
      "Epoch: 4, Batch number: 72, Loss: 13362.9873046875\n",
      "Epoch: 6, Batch number: 20, Loss: 12443.0\n",
      "Epoch: 7, Batch number: 44, Loss: 12078.25\n",
      "Epoch: 8, Batch number: 68, Loss: 11613.5859375\n",
      "Epoch: 10, Batch number: 16, Loss: 11249.6318359375\n",
      "Epoch: 11, Batch number: 40, Loss: 11156.7685546875\n",
      "Epoch: 12, Batch number: 64, Loss: 10530.1787109375\n",
      "Epoch: 14, Batch number: 12, Loss: 10236.439453125\n",
      "Epoch: 15, Batch number: 36, Loss: 10218.2744140625\n",
      "Epoch: 16, Batch number: 60, Loss: 10166.9404296875\n",
      "Epoch: 18, Batch number: 8, Loss: 9729.3564453125\n",
      "Epoch: 19, Batch number: 32, Loss: 9481.767578125\n",
      "Epoch: 20, Batch number: 56, Loss: 9544.5654296875\n",
      "Epoch: 22, Batch number: 4, Loss: 9276.25390625\n",
      "Epoch: 23, Batch number: 28, Loss: 9010.9013671875\n",
      "Epoch: 24, Batch number: 52, Loss: 9186.6416015625\n",
      "Epoch: 26, Batch number: 0, Loss: 8767.0087890625\n",
      "Epoch: 27, Batch number: 24, Loss: 8779.22265625\n",
      "Epoch: 28, Batch number: 48, Loss: 8634.818359375\n",
      "Epoch: 29, Batch number: 72, Loss: 8858.4111328125\n",
      "Epoch: 31, Batch number: 20, Loss: 8619.0361328125\n",
      "Epoch: 32, Batch number: 44, Loss: 8589.283203125\n",
      "Epoch: 33, Batch number: 68, Loss: 8628.6865234375\n",
      "Epoch: 35, Batch number: 16, Loss: 8643.001953125\n",
      "Epoch: 36, Batch number: 40, Loss: 8277.0244140625\n",
      "Epoch: 37, Batch number: 64, Loss: 8302.4111328125\n",
      "Epoch: 39, Batch number: 12, Loss: 8191.98095703125\n",
      "Epoch: 40, Batch number: 36, Loss: 8378.5126953125\n",
      "Epoch: 41, Batch number: 60, Loss: 8217.0478515625\n",
      "Epoch: 43, Batch number: 8, Loss: 8068.88525390625\n",
      "Epoch: 44, Batch number: 32, Loss: 7835.61474609375\n",
      "Epoch: 45, Batch number: 56, Loss: 8223.05078125\n",
      "Epoch: 47, Batch number: 4, Loss: 8008.6826171875\n",
      "Epoch: 48, Batch number: 28, Loss: 8134.98974609375\n",
      "Epoch: 49, Batch number: 52, Loss: 8064.125\n",
      "Epoch: 51, Batch number: 0, Loss: 7948.94775390625\n",
      "Epoch: 52, Batch number: 24, Loss: 7796.30126953125\n",
      "Epoch: 53, Batch number: 48, Loss: 7762.40185546875\n",
      "Epoch: 54, Batch number: 72, Loss: 7872.77978515625\n",
      "Epoch: 56, Batch number: 20, Loss: 7953.283203125\n",
      "Epoch: 57, Batch number: 44, Loss: 7850.68798828125\n",
      "Epoch: 58, Batch number: 68, Loss: 7932.376953125\n",
      "Epoch: 60, Batch number: 16, Loss: 7442.15283203125\n",
      "Epoch: 61, Batch number: 40, Loss: 7814.47705078125\n",
      "Epoch: 62, Batch number: 64, Loss: 7604.16162109375\n",
      "Epoch: 64, Batch number: 12, Loss: 7669.47705078125\n",
      "Epoch: 65, Batch number: 36, Loss: 7679.65771484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Batch number: 60, Loss: 7700.294921875\n",
      "Epoch: 68, Batch number: 8, Loss: 7569.92333984375\n",
      "Epoch: 69, Batch number: 32, Loss: 7584.60205078125\n",
      "Epoch: 70, Batch number: 56, Loss: 7579.87548828125\n",
      "Epoch: 72, Batch number: 4, Loss: 7596.10986328125\n",
      "Epoch: 73, Batch number: 28, Loss: 7509.80078125\n",
      "Epoch: 74, Batch number: 52, Loss: 7691.623046875\n",
      "Epoch: 76, Batch number: 0, Loss: 7496.4560546875\n",
      "Epoch: 77, Batch number: 24, Loss: 7507.11865234375\n",
      "Epoch: 78, Batch number: 48, Loss: 7533.1455078125\n",
      "Epoch: 79, Batch number: 72, Loss: 7751.4697265625\n",
      "Epoch: 81, Batch number: 20, Loss: 7339.3798828125\n",
      "Epoch: 82, Batch number: 44, Loss: 7493.5029296875\n",
      "Epoch: 83, Batch number: 68, Loss: 7622.107421875\n",
      "Epoch: 85, Batch number: 16, Loss: 7327.44775390625\n",
      "Epoch: 86, Batch number: 40, Loss: 7442.8115234375\n",
      "Epoch: 87, Batch number: 64, Loss: 7323.52197265625\n",
      "Epoch: 89, Batch number: 12, Loss: 7304.50634765625\n",
      "Epoch: 90, Batch number: 36, Loss: 7329.35595703125\n",
      "Epoch: 91, Batch number: 60, Loss: 7409.60400390625\n",
      "Epoch: 93, Batch number: 8, Loss: 7512.6875\n",
      "Epoch: 94, Batch number: 32, Loss: 7432.89990234375\n",
      "Epoch: 95, Batch number: 56, Loss: 7394.0224609375\n",
      "Epoch: 97, Batch number: 4, Loss: 7151.78173828125\n",
      "Epoch: 98, Batch number: 28, Loss: 7458.4970703125\n",
      "Epoch: 99, Batch number: 52, Loss: 7589.99169921875\n",
      "Epoch: 101, Batch number: 0, Loss: 7220.8046875\n",
      "Epoch: 102, Batch number: 24, Loss: 7355.064453125\n",
      "Epoch: 103, Batch number: 48, Loss: 7443.14306640625\n",
      "Epoch: 104, Batch number: 72, Loss: 7355.91455078125\n",
      "Epoch: 106, Batch number: 20, Loss: 7136.833984375\n",
      "Epoch: 107, Batch number: 44, Loss: 7182.9091796875\n",
      "Epoch: 108, Batch number: 68, Loss: 7615.4794921875\n",
      "Epoch: 110, Batch number: 16, Loss: 7213.6611328125\n",
      "Epoch: 111, Batch number: 40, Loss: 7082.56787109375\n",
      "Epoch: 112, Batch number: 64, Loss: 7473.8759765625\n",
      "Epoch: 114, Batch number: 12, Loss: 7310.93505859375\n",
      "Epoch: 115, Batch number: 36, Loss: 7263.72607421875\n",
      "Epoch: 116, Batch number: 60, Loss: 7479.14013671875\n",
      "Epoch: 118, Batch number: 8, Loss: 6916.30078125\n",
      "Epoch: 119, Batch number: 32, Loss: 7428.521484375\n",
      "Epoch: 120, Batch number: 56, Loss: 7056.97216796875\n",
      "Epoch: 122, Batch number: 4, Loss: 7176.12939453125\n",
      "Epoch: 123, Batch number: 28, Loss: 7111.31982421875\n",
      "Epoch: 124, Batch number: 52, Loss: 7249.14013671875\n",
      "Epoch: 126, Batch number: 0, Loss: 6903.65771484375\n",
      "Epoch: 127, Batch number: 24, Loss: 7005.75439453125\n",
      "Epoch: 128, Batch number: 48, Loss: 7215.1962890625\n",
      "Epoch: 129, Batch number: 72, Loss: 7206.32421875\n",
      "Epoch: 131, Batch number: 20, Loss: 7120.0361328125\n",
      "Epoch: 132, Batch number: 44, Loss: 7029.11376953125\n",
      "Epoch: 133, Batch number: 68, Loss: 7184.5830078125\n",
      "Epoch: 135, Batch number: 16, Loss: 7468.16455078125\n",
      "Epoch: 136, Batch number: 40, Loss: 7184.81982421875\n",
      "Epoch: 137, Batch number: 64, Loss: 7041.626953125\n",
      "Epoch: 139, Batch number: 12, Loss: 7109.431640625\n",
      "Epoch: 140, Batch number: 36, Loss: 7058.15478515625\n",
      "Epoch: 141, Batch number: 60, Loss: 7012.53515625\n",
      "Epoch: 143, Batch number: 8, Loss: 6940.259765625\n",
      "Epoch: 144, Batch number: 32, Loss: 6804.33544921875\n",
      "Epoch: 145, Batch number: 56, Loss: 7021.05419921875\n",
      "Epoch: 147, Batch number: 4, Loss: 7030.77978515625\n",
      "Epoch: 148, Batch number: 28, Loss: 6857.798828125\n",
      "Epoch: 149, Batch number: 52, Loss: 7296.33447265625\n",
      "Epoch: 151, Batch number: 0, Loss: 6988.41748046875\n",
      "Epoch: 152, Batch number: 24, Loss: 6682.20556640625\n",
      "Epoch: 153, Batch number: 48, Loss: 6865.8388671875\n",
      "Epoch: 154, Batch number: 72, Loss: 7058.91064453125\n",
      "Epoch: 156, Batch number: 20, Loss: 7449.4130859375\n",
      "Epoch: 157, Batch number: 44, Loss: 6983.2373046875\n",
      "Epoch: 158, Batch number: 68, Loss: 6960.41650390625\n",
      "Epoch: 160, Batch number: 16, Loss: 7039.36376953125\n",
      "Epoch: 161, Batch number: 40, Loss: 7121.37548828125\n",
      "Epoch: 162, Batch number: 64, Loss: 7197.22900390625\n",
      "Epoch: 164, Batch number: 12, Loss: 6877.7548828125\n",
      "Epoch: 165, Batch number: 36, Loss: 7239.91357421875\n",
      "Epoch: 166, Batch number: 60, Loss: 7240.11767578125\n",
      "Epoch: 168, Batch number: 8, Loss: 6843.0400390625\n",
      "Epoch: 169, Batch number: 32, Loss: 7002.890625\n",
      "Epoch: 170, Batch number: 56, Loss: 7131.80810546875\n",
      "Epoch: 172, Batch number: 4, Loss: 7032.1142578125\n",
      "Epoch: 173, Batch number: 28, Loss: 6981.21240234375\n",
      "Epoch: 174, Batch number: 52, Loss: 7080.88671875\n",
      "Epoch: 176, Batch number: 0, Loss: 6955.388671875\n",
      "Epoch: 177, Batch number: 24, Loss: 6897.0732421875\n",
      "Epoch: 178, Batch number: 48, Loss: 6846.1806640625\n",
      "Epoch: 179, Batch number: 72, Loss: 6906.2255859375\n",
      "Epoch: 181, Batch number: 20, Loss: 7183.2158203125\n",
      "Epoch: 182, Batch number: 44, Loss: 6974.22607421875\n",
      "Epoch: 183, Batch number: 68, Loss: 7178.13037109375\n",
      "Epoch: 185, Batch number: 16, Loss: 6819.23046875\n",
      "Epoch: 186, Batch number: 40, Loss: 7188.220703125\n",
      "Epoch: 187, Batch number: 64, Loss: 7083.05322265625\n",
      "Epoch: 189, Batch number: 12, Loss: 6909.71630859375\n",
      "Epoch: 190, Batch number: 36, Loss: 7034.4375\n",
      "Epoch: 191, Batch number: 60, Loss: 6970.3046875\n",
      "Epoch: 193, Batch number: 8, Loss: 6881.2412109375\n",
      "Epoch: 194, Batch number: 32, Loss: 6927.916015625\n",
      "Epoch: 195, Batch number: 56, Loss: 7308.12060546875\n",
      "Epoch: 197, Batch number: 4, Loss: 7070.97705078125\n",
      "Epoch: 198, Batch number: 28, Loss: 6980.6005859375\n",
      "Epoch: 199, Batch number: 52, Loss: 7149.56005859375\n",
      "Epoch: 201, Batch number: 0, Loss: 6865.7109375\n",
      "Epoch: 202, Batch number: 24, Loss: 6931.23876953125\n",
      "Epoch: 203, Batch number: 48, Loss: 6728.84619140625\n",
      "Epoch: 204, Batch number: 72, Loss: 7115.99267578125\n",
      "Epoch: 206, Batch number: 20, Loss: 6861.6201171875\n",
      "Epoch: 207, Batch number: 44, Loss: 6791.17822265625\n",
      "Epoch: 208, Batch number: 68, Loss: 6962.16064453125\n",
      "Epoch: 210, Batch number: 16, Loss: 6735.478515625\n",
      "Epoch: 211, Batch number: 40, Loss: 6979.9091796875\n",
      "Epoch: 212, Batch number: 64, Loss: 7116.13134765625\n",
      "Epoch: 214, Batch number: 12, Loss: 6790.021484375\n",
      "Epoch: 215, Batch number: 36, Loss: 7180.099609375\n",
      "Epoch: 216, Batch number: 60, Loss: 6998.87744140625\n",
      "Epoch: 218, Batch number: 8, Loss: 6784.84619140625\n",
      "Epoch: 219, Batch number: 32, Loss: 7186.91259765625\n",
      "Epoch: 220, Batch number: 56, Loss: 7140.7919921875\n",
      "Epoch: 222, Batch number: 4, Loss: 7188.138671875\n",
      "Epoch: 223, Batch number: 28, Loss: 6952.408203125\n",
      "Epoch: 224, Batch number: 52, Loss: 6859.2412109375\n",
      "Epoch: 226, Batch number: 0, Loss: 6879.52734375\n",
      "Epoch: 227, Batch number: 24, Loss: 6967.4091796875\n",
      "Epoch: 228, Batch number: 48, Loss: 7108.1005859375\n",
      "Epoch: 229, Batch number: 72, Loss: 7091.6259765625\n",
      "Epoch: 231, Batch number: 20, Loss: 6986.376953125\n",
      "Epoch: 232, Batch number: 44, Loss: 6955.779296875\n",
      "Epoch: 233, Batch number: 68, Loss: 7102.5673828125\n",
      "Epoch: 235, Batch number: 16, Loss: 6966.01708984375\n",
      "Epoch: 236, Batch number: 40, Loss: 6916.62353515625\n",
      "Epoch: 237, Batch number: 64, Loss: 7262.48681640625\n",
      "Epoch: 239, Batch number: 12, Loss: 7195.046875\n",
      "Epoch: 240, Batch number: 36, Loss: 7097.29052734375\n",
      "Epoch: 241, Batch number: 60, Loss: 7221.19189453125\n",
      "Epoch: 243, Batch number: 8, Loss: 7255.34619140625\n",
      "Epoch: 244, Batch number: 32, Loss: 7056.72119140625\n",
      "Epoch: 245, Batch number: 56, Loss: 7121.51025390625\n",
      "Epoch: 247, Batch number: 4, Loss: 6785.20263671875\n",
      "Epoch: 248, Batch number: 28, Loss: 6601.3388671875\n",
      "Epoch: 249, Batch number: 52, Loss: 6967.72119140625\n",
      "Epoch: 251, Batch number: 0, Loss: 6849.37060546875\n",
      "Epoch: 252, Batch number: 24, Loss: 6904.27783203125\n",
      "Epoch: 253, Batch number: 48, Loss: 7082.5830078125\n",
      "Epoch: 254, Batch number: 72, Loss: 6727.80908203125\n",
      "Epoch: 256, Batch number: 20, Loss: 7187.7705078125\n",
      "Epoch: 257, Batch number: 44, Loss: 6819.56640625\n",
      "Epoch: 258, Batch number: 68, Loss: 7094.923828125\n",
      "Epoch: 260, Batch number: 16, Loss: 7274.57080078125\n",
      "Epoch: 261, Batch number: 40, Loss: 7050.81494140625\n",
      "Epoch: 262, Batch number: 64, Loss: 7047.224609375\n",
      "Epoch: 264, Batch number: 12, Loss: 6682.7822265625\n",
      "Epoch: 265, Batch number: 36, Loss: 7063.88427734375\n",
      "Epoch: 266, Batch number: 60, Loss: 6941.2900390625\n",
      "Epoch: 268, Batch number: 8, Loss: 6897.1171875\n",
      "Epoch: 269, Batch number: 32, Loss: 7004.96875\n",
      "Epoch: 270, Batch number: 56, Loss: 7167.39892578125\n",
      "Epoch: 272, Batch number: 4, Loss: 6956.60498046875\n",
      "Epoch: 273, Batch number: 28, Loss: 6812.7275390625\n",
      "Epoch: 274, Batch number: 52, Loss: 7001.61376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 276, Batch number: 0, Loss: 6843.5341796875\n",
      "Epoch: 277, Batch number: 24, Loss: 6801.7060546875\n",
      "Epoch: 278, Batch number: 48, Loss: 7001.89306640625\n",
      "Epoch: 279, Batch number: 72, Loss: 7091.8828125\n",
      "Epoch: 281, Batch number: 20, Loss: 6917.146484375\n",
      "Epoch: 282, Batch number: 44, Loss: 7173.71728515625\n",
      "Epoch: 283, Batch number: 68, Loss: 7088.16259765625\n",
      "Epoch: 285, Batch number: 16, Loss: 6858.61181640625\n",
      "Epoch: 286, Batch number: 40, Loss: 7223.5244140625\n",
      "Epoch: 287, Batch number: 64, Loss: 7222.2998046875\n",
      "Epoch: 289, Batch number: 12, Loss: 6936.51416015625\n",
      "Epoch: 290, Batch number: 36, Loss: 7045.87255859375\n",
      "Epoch: 291, Batch number: 60, Loss: 6911.296875\n",
      "Epoch: 293, Batch number: 8, Loss: 6986.26708984375\n",
      "Epoch: 294, Batch number: 32, Loss: 7214.3828125\n",
      "Epoch: 295, Batch number: 56, Loss: 7081.7099609375\n",
      "Epoch: 297, Batch number: 4, Loss: 6805.55126953125\n",
      "Epoch: 298, Batch number: 28, Loss: 6870.29150390625\n",
      "Epoch: 299, Batch number: 52, Loss: 6661.97607421875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15344.548828125\n",
      "Epoch: 2, Batch number: 24, Loss: 13992.619140625\n",
      "Epoch: 3, Batch number: 48, Loss: 13403.416015625\n",
      "Epoch: 4, Batch number: 72, Loss: 12480.70703125\n",
      "Epoch: 6, Batch number: 20, Loss: 12078.6181640625\n",
      "Epoch: 7, Batch number: 44, Loss: 11631.734375\n",
      "Epoch: 8, Batch number: 68, Loss: 11143.7666015625\n",
      "Epoch: 10, Batch number: 16, Loss: 10778.3310546875\n",
      "Epoch: 11, Batch number: 40, Loss: 10559.048828125\n",
      "Epoch: 12, Batch number: 64, Loss: 10066.865234375\n",
      "Epoch: 14, Batch number: 12, Loss: 9903.9169921875\n",
      "Epoch: 15, Batch number: 36, Loss: 9804.064453125\n",
      "Epoch: 16, Batch number: 60, Loss: 9612.6259765625\n",
      "Epoch: 18, Batch number: 8, Loss: 9120.8515625\n",
      "Epoch: 19, Batch number: 32, Loss: 9201.6572265625\n",
      "Epoch: 20, Batch number: 56, Loss: 9089.900390625\n",
      "Epoch: 22, Batch number: 4, Loss: 8748.43359375\n",
      "Epoch: 23, Batch number: 28, Loss: 8763.8046875\n",
      "Epoch: 24, Batch number: 52, Loss: 8763.431640625\n",
      "Epoch: 26, Batch number: 0, Loss: 8396.6357421875\n",
      "Epoch: 27, Batch number: 24, Loss: 8449.5205078125\n",
      "Epoch: 28, Batch number: 48, Loss: 8332.0205078125\n",
      "Epoch: 29, Batch number: 72, Loss: 8173.99267578125\n",
      "Epoch: 31, Batch number: 20, Loss: 8172.7265625\n",
      "Epoch: 32, Batch number: 44, Loss: 8081.14111328125\n",
      "Epoch: 33, Batch number: 68, Loss: 8158.2568359375\n",
      "Epoch: 35, Batch number: 16, Loss: 8237.7275390625\n",
      "Epoch: 36, Batch number: 40, Loss: 7752.74755859375\n",
      "Epoch: 37, Batch number: 64, Loss: 8117.697265625\n",
      "Epoch: 39, Batch number: 12, Loss: 7960.884765625\n",
      "Epoch: 40, Batch number: 36, Loss: 7992.74267578125\n",
      "Epoch: 41, Batch number: 60, Loss: 7984.26513671875\n",
      "Epoch: 43, Batch number: 8, Loss: 7747.333984375\n",
      "Epoch: 44, Batch number: 32, Loss: 7820.87841796875\n",
      "Epoch: 45, Batch number: 56, Loss: 8003.443359375\n",
      "Epoch: 47, Batch number: 4, Loss: 7855.228515625\n",
      "Epoch: 48, Batch number: 28, Loss: 7845.119140625\n",
      "Epoch: 49, Batch number: 52, Loss: 7605.2236328125\n",
      "Epoch: 51, Batch number: 0, Loss: 7998.18505859375\n",
      "Epoch: 52, Batch number: 24, Loss: 7642.29248046875\n",
      "Epoch: 53, Batch number: 48, Loss: 7475.4462890625\n",
      "Epoch: 54, Batch number: 72, Loss: 7671.86376953125\n",
      "Epoch: 56, Batch number: 20, Loss: 7510.49755859375\n",
      "Epoch: 57, Batch number: 44, Loss: 7564.37158203125\n",
      "Epoch: 58, Batch number: 68, Loss: 7654.83740234375\n",
      "Epoch: 60, Batch number: 16, Loss: 7714.162109375\n",
      "Epoch: 61, Batch number: 40, Loss: 7572.3212890625\n",
      "Epoch: 62, Batch number: 64, Loss: 7440.08642578125\n",
      "Epoch: 64, Batch number: 12, Loss: 7363.23974609375\n",
      "Epoch: 65, Batch number: 36, Loss: 7743.0732421875\n",
      "Epoch: 66, Batch number: 60, Loss: 7602.24267578125\n",
      "Epoch: 68, Batch number: 8, Loss: 7405.73828125\n",
      "Epoch: 69, Batch number: 32, Loss: 7295.169921875\n",
      "Epoch: 70, Batch number: 56, Loss: 7340.2333984375\n",
      "Epoch: 72, Batch number: 4, Loss: 7233.5751953125\n",
      "Epoch: 73, Batch number: 28, Loss: 7389.4951171875\n",
      "Epoch: 74, Batch number: 52, Loss: 7323.02001953125\n",
      "Epoch: 76, Batch number: 0, Loss: 7105.65283203125\n",
      "Epoch: 77, Batch number: 24, Loss: 7217.328125\n",
      "Epoch: 78, Batch number: 48, Loss: 7247.9150390625\n",
      "Epoch: 79, Batch number: 72, Loss: 7389.6982421875\n",
      "Epoch: 81, Batch number: 20, Loss: 7158.03857421875\n",
      "Epoch: 82, Batch number: 44, Loss: 7214.79443359375\n",
      "Epoch: 83, Batch number: 68, Loss: 7562.92041015625\n",
      "Epoch: 85, Batch number: 16, Loss: 7176.9541015625\n",
      "Epoch: 86, Batch number: 40, Loss: 7294.48193359375\n",
      "Epoch: 87, Batch number: 64, Loss: 7471.6533203125\n",
      "Epoch: 89, Batch number: 12, Loss: 7163.8916015625\n",
      "Epoch: 90, Batch number: 36, Loss: 7340.45751953125\n",
      "Epoch: 91, Batch number: 60, Loss: 7505.72607421875\n",
      "Epoch: 93, Batch number: 8, Loss: 7313.7216796875\n",
      "Epoch: 94, Batch number: 32, Loss: 7187.9609375\n",
      "Epoch: 95, Batch number: 56, Loss: 7232.3115234375\n",
      "Epoch: 97, Batch number: 4, Loss: 7235.60595703125\n",
      "Epoch: 98, Batch number: 28, Loss: 6936.22265625\n",
      "Epoch: 99, Batch number: 52, Loss: 7156.3818359375\n",
      "Epoch: 101, Batch number: 0, Loss: 6898.5390625\n",
      "Epoch: 102, Batch number: 24, Loss: 7302.83642578125\n",
      "Epoch: 103, Batch number: 48, Loss: 7405.177734375\n",
      "Epoch: 104, Batch number: 72, Loss: 7035.9765625\n",
      "Epoch: 106, Batch number: 20, Loss: 7147.25244140625\n",
      "Epoch: 107, Batch number: 44, Loss: 7476.27392578125\n",
      "Epoch: 108, Batch number: 68, Loss: 6920.1181640625\n",
      "Epoch: 110, Batch number: 16, Loss: 7245.341796875\n",
      "Epoch: 111, Batch number: 40, Loss: 7194.552734375\n",
      "Epoch: 112, Batch number: 64, Loss: 7166.15966796875\n",
      "Epoch: 114, Batch number: 12, Loss: 7100.7275390625\n",
      "Epoch: 115, Batch number: 36, Loss: 7307.43212890625\n",
      "Epoch: 116, Batch number: 60, Loss: 7143.1494140625\n",
      "Epoch: 118, Batch number: 8, Loss: 6934.38818359375\n",
      "Epoch: 119, Batch number: 32, Loss: 6830.25048828125\n",
      "Epoch: 120, Batch number: 56, Loss: 7254.998046875\n",
      "Epoch: 122, Batch number: 4, Loss: 7196.76904296875\n",
      "Epoch: 123, Batch number: 28, Loss: 7006.9384765625\n",
      "Epoch: 124, Batch number: 52, Loss: 7104.04833984375\n",
      "Epoch: 126, Batch number: 0, Loss: 6951.48974609375\n",
      "Epoch: 127, Batch number: 24, Loss: 7131.11767578125\n",
      "Epoch: 128, Batch number: 48, Loss: 7204.37939453125\n",
      "Epoch: 129, Batch number: 72, Loss: 7002.92041015625\n",
      "Epoch: 131, Batch number: 20, Loss: 7002.04052734375\n",
      "Epoch: 132, Batch number: 44, Loss: 7184.42333984375\n",
      "Epoch: 133, Batch number: 68, Loss: 6997.8671875\n",
      "Epoch: 135, Batch number: 16, Loss: 7156.4033203125\n",
      "Epoch: 136, Batch number: 40, Loss: 7152.59912109375\n",
      "Epoch: 137, Batch number: 64, Loss: 7078.2822265625\n",
      "Epoch: 139, Batch number: 12, Loss: 6982.03271484375\n",
      "Epoch: 140, Batch number: 36, Loss: 7112.18701171875\n",
      "Epoch: 141, Batch number: 60, Loss: 7219.34423828125\n",
      "Epoch: 143, Batch number: 8, Loss: 6832.0234375\n",
      "Epoch: 144, Batch number: 32, Loss: 6870.0283203125\n",
      "Epoch: 145, Batch number: 56, Loss: 7223.01953125\n",
      "Epoch: 147, Batch number: 4, Loss: 6801.58154296875\n",
      "Epoch: 148, Batch number: 28, Loss: 7089.4775390625\n",
      "Epoch: 149, Batch number: 52, Loss: 6844.78515625\n",
      "Epoch: 151, Batch number: 0, Loss: 6818.2138671875\n",
      "Epoch: 152, Batch number: 24, Loss: 7085.0263671875\n",
      "Epoch: 153, Batch number: 48, Loss: 7294.9345703125\n",
      "Epoch: 154, Batch number: 72, Loss: 7172.25927734375\n",
      "Epoch: 156, Batch number: 20, Loss: 7021.6513671875\n",
      "Epoch: 157, Batch number: 44, Loss: 7072.990234375\n",
      "Epoch: 158, Batch number: 68, Loss: 6982.8154296875\n",
      "Epoch: 160, Batch number: 16, Loss: 7105.57177734375\n",
      "Epoch: 161, Batch number: 40, Loss: 6994.927734375\n",
      "Epoch: 162, Batch number: 64, Loss: 7179.60986328125\n",
      "Epoch: 164, Batch number: 12, Loss: 7115.46240234375\n",
      "Epoch: 165, Batch number: 36, Loss: 7125.029296875\n",
      "Epoch: 166, Batch number: 60, Loss: 7032.0888671875\n",
      "Epoch: 168, Batch number: 8, Loss: 6982.15771484375\n",
      "Epoch: 169, Batch number: 32, Loss: 7102.490234375\n",
      "Epoch: 170, Batch number: 56, Loss: 7111.6337890625\n",
      "Epoch: 172, Batch number: 4, Loss: 7004.95166015625\n",
      "Epoch: 173, Batch number: 28, Loss: 7150.0146484375\n",
      "Epoch: 174, Batch number: 52, Loss: 6991.49853515625\n",
      "Epoch: 176, Batch number: 0, Loss: 6735.7841796875\n",
      "Epoch: 177, Batch number: 24, Loss: 6894.89111328125\n",
      "Epoch: 178, Batch number: 48, Loss: 7006.5068359375\n",
      "Epoch: 179, Batch number: 72, Loss: 7022.76025390625\n",
      "Epoch: 181, Batch number: 20, Loss: 7121.8701171875\n",
      "Epoch: 182, Batch number: 44, Loss: 7202.0439453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 183, Batch number: 68, Loss: 7142.2861328125\n",
      "Epoch: 185, Batch number: 16, Loss: 7011.26318359375\n",
      "Epoch: 186, Batch number: 40, Loss: 6785.9326171875\n",
      "Epoch: 187, Batch number: 64, Loss: 7020.30712890625\n",
      "Epoch: 189, Batch number: 12, Loss: 6884.27490234375\n",
      "Epoch: 190, Batch number: 36, Loss: 7115.30615234375\n",
      "Epoch: 191, Batch number: 60, Loss: 7137.5166015625\n",
      "Epoch: 193, Batch number: 8, Loss: 7072.4970703125\n",
      "Epoch: 194, Batch number: 32, Loss: 6832.15673828125\n",
      "Epoch: 195, Batch number: 56, Loss: 7135.1123046875\n",
      "Epoch: 197, Batch number: 4, Loss: 6816.06884765625\n",
      "Epoch: 198, Batch number: 28, Loss: 7113.265625\n",
      "Epoch: 199, Batch number: 52, Loss: 7098.56787109375\n",
      "Epoch: 201, Batch number: 0, Loss: 6886.84130859375\n",
      "Epoch: 202, Batch number: 24, Loss: 6669.67041015625\n",
      "Epoch: 203, Batch number: 48, Loss: 7064.98095703125\n",
      "Epoch: 204, Batch number: 72, Loss: 6915.13330078125\n",
      "Epoch: 206, Batch number: 20, Loss: 6973.14794921875\n",
      "Epoch: 207, Batch number: 44, Loss: 7116.51708984375\n",
      "Epoch: 208, Batch number: 68, Loss: 7105.90380859375\n",
      "Epoch: 210, Batch number: 16, Loss: 7001.49853515625\n",
      "Epoch: 211, Batch number: 40, Loss: 6893.37109375\n",
      "Epoch: 212, Batch number: 64, Loss: 7185.22802734375\n",
      "Epoch: 214, Batch number: 12, Loss: 6981.7978515625\n",
      "Epoch: 215, Batch number: 36, Loss: 7184.99169921875\n",
      "Epoch: 216, Batch number: 60, Loss: 7014.96337890625\n",
      "Epoch: 218, Batch number: 8, Loss: 7070.70068359375\n",
      "Epoch: 219, Batch number: 32, Loss: 6836.91943359375\n",
      "Epoch: 220, Batch number: 56, Loss: 6875.830078125\n",
      "Epoch: 222, Batch number: 4, Loss: 6813.22900390625\n",
      "Epoch: 223, Batch number: 28, Loss: 7196.63818359375\n",
      "Epoch: 224, Batch number: 52, Loss: 7144.5576171875\n",
      "Epoch: 226, Batch number: 0, Loss: 6752.99658203125\n",
      "Epoch: 227, Batch number: 24, Loss: 7032.91552734375\n",
      "Epoch: 228, Batch number: 48, Loss: 6990.39013671875\n",
      "Epoch: 229, Batch number: 72, Loss: 7107.12548828125\n",
      "Epoch: 231, Batch number: 20, Loss: 7247.50390625\n",
      "Epoch: 232, Batch number: 44, Loss: 6775.353515625\n",
      "Epoch: 233, Batch number: 68, Loss: 7017.94677734375\n",
      "Epoch: 235, Batch number: 16, Loss: 7087.5283203125\n",
      "Epoch: 236, Batch number: 40, Loss: 7001.3251953125\n",
      "Epoch: 237, Batch number: 64, Loss: 7116.33251953125\n",
      "Epoch: 239, Batch number: 12, Loss: 6788.66650390625\n",
      "Epoch: 240, Batch number: 36, Loss: 6791.80224609375\n",
      "Epoch: 241, Batch number: 60, Loss: 7177.98779296875\n",
      "Epoch: 243, Batch number: 8, Loss: 7172.77490234375\n",
      "Epoch: 244, Batch number: 32, Loss: 6757.4033203125\n",
      "Epoch: 245, Batch number: 56, Loss: 6781.28564453125\n",
      "Epoch: 247, Batch number: 4, Loss: 7241.9462890625\n",
      "Epoch: 248, Batch number: 28, Loss: 7112.47265625\n",
      "Epoch: 249, Batch number: 52, Loss: 7402.78564453125\n",
      "Epoch: 251, Batch number: 0, Loss: 6995.466796875\n",
      "Epoch: 252, Batch number: 24, Loss: 6875.70849609375\n",
      "Epoch: 253, Batch number: 48, Loss: 7108.12158203125\n",
      "Epoch: 254, Batch number: 72, Loss: 6972.04443359375\n",
      "Epoch: 256, Batch number: 20, Loss: 6855.046875\n",
      "Epoch: 257, Batch number: 44, Loss: 7087.44873046875\n",
      "Epoch: 258, Batch number: 68, Loss: 6857.169921875\n",
      "Epoch: 260, Batch number: 16, Loss: 6924.60791015625\n",
      "Epoch: 261, Batch number: 40, Loss: 6971.15380859375\n",
      "Epoch: 262, Batch number: 64, Loss: 7154.9228515625\n",
      "Epoch: 264, Batch number: 12, Loss: 6905.5126953125\n",
      "Epoch: 265, Batch number: 36, Loss: 7264.40087890625\n",
      "Epoch: 266, Batch number: 60, Loss: 7298.03466796875\n",
      "Epoch: 268, Batch number: 8, Loss: 6899.79150390625\n",
      "Epoch: 269, Batch number: 32, Loss: 7236.3408203125\n",
      "Epoch: 270, Batch number: 56, Loss: 7274.8798828125\n",
      "Epoch: 272, Batch number: 4, Loss: 7016.19775390625\n",
      "Epoch: 273, Batch number: 28, Loss: 6712.466796875\n",
      "Epoch: 274, Batch number: 52, Loss: 6886.91796875\n",
      "Epoch: 276, Batch number: 0, Loss: 6833.49072265625\n",
      "Epoch: 277, Batch number: 24, Loss: 7137.20263671875\n",
      "Epoch: 278, Batch number: 48, Loss: 6906.474609375\n",
      "Epoch: 279, Batch number: 72, Loss: 7003.02099609375\n",
      "Epoch: 281, Batch number: 20, Loss: 7029.0966796875\n",
      "Epoch: 282, Batch number: 44, Loss: 6978.27734375\n",
      "Epoch: 283, Batch number: 68, Loss: 6778.89404296875\n",
      "Epoch: 285, Batch number: 16, Loss: 6956.23779296875\n",
      "Epoch: 286, Batch number: 40, Loss: 6993.1220703125\n",
      "Epoch: 287, Batch number: 64, Loss: 7219.45849609375\n",
      "Epoch: 289, Batch number: 12, Loss: 7129.212890625\n",
      "Epoch: 290, Batch number: 36, Loss: 6948.13916015625\n",
      "Epoch: 291, Batch number: 60, Loss: 6660.2216796875\n",
      "Epoch: 293, Batch number: 8, Loss: 7030.3798828125\n",
      "Epoch: 294, Batch number: 32, Loss: 6988.65869140625\n",
      "Epoch: 295, Batch number: 56, Loss: 7131.49609375\n",
      "Epoch: 297, Batch number: 4, Loss: 6985.36669921875\n",
      "Epoch: 298, Batch number: 28, Loss: 6966.9453125\n",
      "Epoch: 299, Batch number: 52, Loss: 6942.48486328125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15262.2412109375\n",
      "Epoch: 2, Batch number: 24, Loss: 13576.564453125\n",
      "Epoch: 3, Batch number: 48, Loss: 12797.5693359375\n",
      "Epoch: 4, Batch number: 72, Loss: 12342.791015625\n",
      "Epoch: 6, Batch number: 20, Loss: 11330.2666015625\n",
      "Epoch: 7, Batch number: 44, Loss: 10801.7333984375\n",
      "Epoch: 8, Batch number: 68, Loss: 10542.4814453125\n",
      "Epoch: 10, Batch number: 16, Loss: 10107.923828125\n",
      "Epoch: 11, Batch number: 40, Loss: 9655.5693359375\n",
      "Epoch: 12, Batch number: 64, Loss: 9676.39453125\n",
      "Epoch: 14, Batch number: 12, Loss: 9039.0087890625\n",
      "Epoch: 15, Batch number: 36, Loss: 8898.693359375\n",
      "Epoch: 16, Batch number: 60, Loss: 8811.146484375\n",
      "Epoch: 18, Batch number: 8, Loss: 8535.2421875\n",
      "Epoch: 19, Batch number: 32, Loss: 8363.3583984375\n",
      "Epoch: 20, Batch number: 56, Loss: 8317.552734375\n",
      "Epoch: 22, Batch number: 4, Loss: 8018.880859375\n",
      "Epoch: 23, Batch number: 28, Loss: 8110.0859375\n",
      "Epoch: 24, Batch number: 52, Loss: 8184.85546875\n",
      "Epoch: 26, Batch number: 0, Loss: 8036.37744140625\n",
      "Epoch: 27, Batch number: 24, Loss: 7814.07275390625\n",
      "Epoch: 28, Batch number: 48, Loss: 7966.76708984375\n",
      "Epoch: 29, Batch number: 72, Loss: 7867.95654296875\n",
      "Epoch: 31, Batch number: 20, Loss: 7620.2919921875\n",
      "Epoch: 32, Batch number: 44, Loss: 7956.91357421875\n",
      "Epoch: 33, Batch number: 68, Loss: 7825.95068359375\n",
      "Epoch: 35, Batch number: 16, Loss: 7616.04443359375\n",
      "Epoch: 36, Batch number: 40, Loss: 7972.2900390625\n",
      "Epoch: 37, Batch number: 64, Loss: 7569.89599609375\n",
      "Epoch: 39, Batch number: 12, Loss: 7714.0185546875\n",
      "Epoch: 40, Batch number: 36, Loss: 7434.49365234375\n",
      "Epoch: 41, Batch number: 60, Loss: 7535.9697265625\n",
      "Epoch: 43, Batch number: 8, Loss: 7598.38916015625\n",
      "Epoch: 44, Batch number: 32, Loss: 7368.36572265625\n",
      "Epoch: 45, Batch number: 56, Loss: 7650.82861328125\n",
      "Epoch: 47, Batch number: 4, Loss: 7227.01904296875\n",
      "Epoch: 48, Batch number: 28, Loss: 7546.59765625\n",
      "Epoch: 49, Batch number: 52, Loss: 7475.69580078125\n",
      "Epoch: 51, Batch number: 0, Loss: 7350.96142578125\n",
      "Epoch: 52, Batch number: 24, Loss: 7216.966796875\n",
      "Epoch: 53, Batch number: 48, Loss: 7178.98095703125\n",
      "Epoch: 54, Batch number: 72, Loss: 7424.666015625\n",
      "Epoch: 56, Batch number: 20, Loss: 7386.58642578125\n",
      "Epoch: 57, Batch number: 44, Loss: 7273.431640625\n",
      "Epoch: 58, Batch number: 68, Loss: 7431.65625\n",
      "Epoch: 60, Batch number: 16, Loss: 7480.9775390625\n",
      "Epoch: 61, Batch number: 40, Loss: 7217.67041015625\n",
      "Epoch: 62, Batch number: 64, Loss: 7224.484375\n",
      "Epoch: 64, Batch number: 12, Loss: 7182.62060546875\n",
      "Epoch: 65, Batch number: 36, Loss: 7281.1943359375\n",
      "Epoch: 66, Batch number: 60, Loss: 7672.59619140625\n",
      "Epoch: 68, Batch number: 8, Loss: 7204.8994140625\n",
      "Epoch: 69, Batch number: 32, Loss: 7220.076171875\n",
      "Epoch: 70, Batch number: 56, Loss: 7272.3583984375\n",
      "Epoch: 72, Batch number: 4, Loss: 7331.7138671875\n",
      "Epoch: 73, Batch number: 28, Loss: 7085.20947265625\n",
      "Epoch: 74, Batch number: 52, Loss: 7353.64404296875\n",
      "Epoch: 76, Batch number: 0, Loss: 7056.45947265625\n",
      "Epoch: 77, Batch number: 24, Loss: 7106.3837890625\n",
      "Epoch: 78, Batch number: 48, Loss: 7303.11181640625\n",
      "Epoch: 79, Batch number: 72, Loss: 7124.3994140625\n",
      "Epoch: 81, Batch number: 20, Loss: 6898.814453125\n",
      "Epoch: 82, Batch number: 44, Loss: 7236.326171875\n",
      "Epoch: 83, Batch number: 68, Loss: 6993.3154296875\n",
      "Epoch: 85, Batch number: 16, Loss: 7067.3935546875\n",
      "Epoch: 86, Batch number: 40, Loss: 7141.46826171875\n",
      "Epoch: 87, Batch number: 64, Loss: 7231.177734375\n",
      "Epoch: 89, Batch number: 12, Loss: 7090.25048828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Batch number: 36, Loss: 7016.4599609375\n",
      "Epoch: 91, Batch number: 60, Loss: 7320.8369140625\n",
      "Epoch: 93, Batch number: 8, Loss: 7249.98876953125\n",
      "Epoch: 94, Batch number: 32, Loss: 7048.48779296875\n",
      "Epoch: 95, Batch number: 56, Loss: 7055.91015625\n",
      "Epoch: 97, Batch number: 4, Loss: 7195.0341796875\n",
      "Epoch: 98, Batch number: 28, Loss: 7190.025390625\n",
      "Epoch: 99, Batch number: 52, Loss: 6984.09130859375\n",
      "Epoch: 101, Batch number: 0, Loss: 6914.20947265625\n",
      "Epoch: 102, Batch number: 24, Loss: 6915.57958984375\n",
      "Epoch: 103, Batch number: 48, Loss: 7036.16455078125\n",
      "Epoch: 104, Batch number: 72, Loss: 7215.63330078125\n",
      "Epoch: 106, Batch number: 20, Loss: 7191.662109375\n",
      "Epoch: 107, Batch number: 44, Loss: 7342.54736328125\n",
      "Epoch: 108, Batch number: 68, Loss: 7316.33837890625\n",
      "Epoch: 110, Batch number: 16, Loss: 6922.43115234375\n",
      "Epoch: 111, Batch number: 40, Loss: 7077.66748046875\n",
      "Epoch: 112, Batch number: 64, Loss: 7088.05810546875\n",
      "Epoch: 114, Batch number: 12, Loss: 7066.47265625\n",
      "Epoch: 115, Batch number: 36, Loss: 6900.97509765625\n",
      "Epoch: 116, Batch number: 60, Loss: 7112.43994140625\n",
      "Epoch: 118, Batch number: 8, Loss: 7049.13818359375\n",
      "Epoch: 119, Batch number: 32, Loss: 7021.7265625\n",
      "Epoch: 120, Batch number: 56, Loss: 7204.70458984375\n",
      "Epoch: 122, Batch number: 4, Loss: 7065.02587890625\n",
      "Epoch: 123, Batch number: 28, Loss: 7027.611328125\n",
      "Epoch: 124, Batch number: 52, Loss: 6954.57568359375\n",
      "Epoch: 126, Batch number: 0, Loss: 6824.71435546875\n",
      "Epoch: 127, Batch number: 24, Loss: 7163.404296875\n",
      "Epoch: 128, Batch number: 48, Loss: 7373.388671875\n",
      "Epoch: 129, Batch number: 72, Loss: 6945.9931640625\n",
      "Epoch: 131, Batch number: 20, Loss: 7014.568359375\n",
      "Epoch: 132, Batch number: 44, Loss: 6834.8720703125\n",
      "Epoch: 133, Batch number: 68, Loss: 6820.81298828125\n",
      "Epoch: 135, Batch number: 16, Loss: 7002.6083984375\n",
      "Epoch: 136, Batch number: 40, Loss: 7071.6611328125\n",
      "Epoch: 137, Batch number: 64, Loss: 7138.771484375\n",
      "Epoch: 139, Batch number: 12, Loss: 6754.1640625\n",
      "Epoch: 140, Batch number: 36, Loss: 7190.15966796875\n",
      "Epoch: 141, Batch number: 60, Loss: 7249.25439453125\n",
      "Epoch: 143, Batch number: 8, Loss: 6981.34814453125\n",
      "Epoch: 144, Batch number: 32, Loss: 7182.77734375\n",
      "Epoch: 145, Batch number: 56, Loss: 7078.9609375\n",
      "Epoch: 147, Batch number: 4, Loss: 7142.30126953125\n",
      "Epoch: 148, Batch number: 28, Loss: 7197.03076171875\n",
      "Epoch: 149, Batch number: 52, Loss: 6994.76318359375\n",
      "Epoch: 151, Batch number: 0, Loss: 6780.30615234375\n",
      "Epoch: 152, Batch number: 24, Loss: 7254.61572265625\n",
      "Epoch: 153, Batch number: 48, Loss: 6932.5908203125\n",
      "Epoch: 154, Batch number: 72, Loss: 7190.4677734375\n",
      "Epoch: 156, Batch number: 20, Loss: 6974.4111328125\n",
      "Epoch: 157, Batch number: 44, Loss: 7149.0361328125\n",
      "Epoch: 158, Batch number: 68, Loss: 7287.4208984375\n",
      "Epoch: 160, Batch number: 16, Loss: 7028.453125\n",
      "Epoch: 161, Batch number: 40, Loss: 7237.07568359375\n",
      "Epoch: 162, Batch number: 64, Loss: 7047.31396484375\n",
      "Epoch: 164, Batch number: 12, Loss: 7049.28369140625\n",
      "Epoch: 165, Batch number: 36, Loss: 7097.76806640625\n",
      "Epoch: 166, Batch number: 60, Loss: 7060.16845703125\n",
      "Epoch: 168, Batch number: 8, Loss: 6853.37939453125\n",
      "Epoch: 169, Batch number: 32, Loss: 7213.2939453125\n",
      "Epoch: 170, Batch number: 56, Loss: 6889.84765625\n",
      "Epoch: 172, Batch number: 4, Loss: 6790.93017578125\n",
      "Epoch: 173, Batch number: 28, Loss: 6962.44140625\n",
      "Epoch: 174, Batch number: 52, Loss: 7105.02587890625\n",
      "Epoch: 176, Batch number: 0, Loss: 7001.83740234375\n",
      "Epoch: 177, Batch number: 24, Loss: 6934.17578125\n",
      "Epoch: 178, Batch number: 48, Loss: 7099.96240234375\n",
      "Epoch: 179, Batch number: 72, Loss: 7093.0322265625\n",
      "Epoch: 181, Batch number: 20, Loss: 6780.19091796875\n",
      "Epoch: 182, Batch number: 44, Loss: 6985.6474609375\n",
      "Epoch: 183, Batch number: 68, Loss: 7117.18359375\n",
      "Epoch: 185, Batch number: 16, Loss: 7072.29833984375\n",
      "Epoch: 186, Batch number: 40, Loss: 7001.60595703125\n",
      "Epoch: 187, Batch number: 64, Loss: 6951.52734375\n",
      "Epoch: 189, Batch number: 12, Loss: 7180.505859375\n",
      "Epoch: 190, Batch number: 36, Loss: 7075.3291015625\n",
      "Epoch: 191, Batch number: 60, Loss: 7071.365234375\n",
      "Epoch: 193, Batch number: 8, Loss: 6795.30029296875\n",
      "Epoch: 194, Batch number: 32, Loss: 6937.01513671875\n",
      "Epoch: 195, Batch number: 56, Loss: 7056.80908203125\n",
      "Epoch: 197, Batch number: 4, Loss: 7021.4189453125\n",
      "Epoch: 198, Batch number: 28, Loss: 6946.0029296875\n",
      "Epoch: 199, Batch number: 52, Loss: 6977.93798828125\n",
      "Epoch: 201, Batch number: 0, Loss: 7200.11083984375\n",
      "Epoch: 202, Batch number: 24, Loss: 6830.49951171875\n",
      "Epoch: 203, Batch number: 48, Loss: 7039.0009765625\n",
      "Epoch: 204, Batch number: 72, Loss: 7165.169921875\n",
      "Epoch: 206, Batch number: 20, Loss: 6918.30419921875\n",
      "Epoch: 207, Batch number: 44, Loss: 7140.9248046875\n",
      "Epoch: 208, Batch number: 68, Loss: 7210.3994140625\n",
      "Epoch: 210, Batch number: 16, Loss: 6677.79150390625\n",
      "Epoch: 211, Batch number: 40, Loss: 6964.32666015625\n",
      "Epoch: 212, Batch number: 64, Loss: 7362.13427734375\n",
      "Epoch: 214, Batch number: 12, Loss: 6835.82080078125\n",
      "Epoch: 215, Batch number: 36, Loss: 7093.2890625\n",
      "Epoch: 216, Batch number: 60, Loss: 7012.3955078125\n",
      "Epoch: 218, Batch number: 8, Loss: 6988.0\n",
      "Epoch: 219, Batch number: 32, Loss: 6977.01171875\n",
      "Epoch: 220, Batch number: 56, Loss: 7355.1982421875\n",
      "Epoch: 222, Batch number: 4, Loss: 6778.39501953125\n",
      "Epoch: 223, Batch number: 28, Loss: 7082.33740234375\n",
      "Epoch: 224, Batch number: 52, Loss: 7112.8671875\n",
      "Epoch: 226, Batch number: 0, Loss: 7226.77685546875\n",
      "Epoch: 227, Batch number: 24, Loss: 6907.93505859375\n",
      "Epoch: 228, Batch number: 48, Loss: 7067.8369140625\n",
      "Epoch: 229, Batch number: 72, Loss: 7050.13232421875\n",
      "Epoch: 231, Batch number: 20, Loss: 7261.10595703125\n",
      "Epoch: 232, Batch number: 44, Loss: 6876.77783203125\n",
      "Epoch: 233, Batch number: 68, Loss: 7314.54345703125\n",
      "Epoch: 235, Batch number: 16, Loss: 6937.41259765625\n",
      "Epoch: 236, Batch number: 40, Loss: 6932.3115234375\n",
      "Epoch: 237, Batch number: 64, Loss: 7167.10693359375\n",
      "Epoch: 239, Batch number: 12, Loss: 7100.25634765625\n",
      "Epoch: 240, Batch number: 36, Loss: 6940.4443359375\n",
      "Epoch: 241, Batch number: 60, Loss: 7022.86669921875\n",
      "Epoch: 243, Batch number: 8, Loss: 7086.87939453125\n",
      "Epoch: 244, Batch number: 32, Loss: 6830.07861328125\n",
      "Epoch: 245, Batch number: 56, Loss: 7015.73828125\n",
      "Epoch: 247, Batch number: 4, Loss: 6846.37841796875\n",
      "Epoch: 248, Batch number: 28, Loss: 7002.146484375\n",
      "Epoch: 249, Batch number: 52, Loss: 7288.470703125\n",
      "Epoch: 251, Batch number: 0, Loss: 7105.38818359375\n",
      "Epoch: 252, Batch number: 24, Loss: 6843.22216796875\n",
      "Epoch: 253, Batch number: 48, Loss: 7384.333984375\n",
      "Epoch: 254, Batch number: 72, Loss: 7090.96826171875\n",
      "Epoch: 256, Batch number: 20, Loss: 6839.3701171875\n",
      "Epoch: 257, Batch number: 44, Loss: 7416.20556640625\n",
      "Epoch: 258, Batch number: 68, Loss: 6940.56640625\n",
      "Epoch: 260, Batch number: 16, Loss: 6754.37890625\n",
      "Epoch: 261, Batch number: 40, Loss: 7025.66552734375\n",
      "Epoch: 262, Batch number: 64, Loss: 6976.87158203125\n",
      "Epoch: 264, Batch number: 12, Loss: 6822.923828125\n",
      "Epoch: 265, Batch number: 36, Loss: 7218.3935546875\n",
      "Epoch: 266, Batch number: 60, Loss: 7052.89990234375\n",
      "Epoch: 268, Batch number: 8, Loss: 6902.08154296875\n",
      "Epoch: 269, Batch number: 32, Loss: 6832.87548828125\n",
      "Epoch: 270, Batch number: 56, Loss: 7076.13916015625\n",
      "Epoch: 272, Batch number: 4, Loss: 6767.50732421875\n",
      "Epoch: 273, Batch number: 28, Loss: 7088.3466796875\n",
      "Epoch: 274, Batch number: 52, Loss: 7018.5\n",
      "Epoch: 276, Batch number: 0, Loss: 6983.10791015625\n",
      "Epoch: 277, Batch number: 24, Loss: 7085.9208984375\n",
      "Epoch: 278, Batch number: 48, Loss: 7070.017578125\n",
      "Epoch: 279, Batch number: 72, Loss: 7333.3330078125\n",
      "Epoch: 281, Batch number: 20, Loss: 7084.24560546875\n",
      "Epoch: 282, Batch number: 44, Loss: 7160.154296875\n",
      "Epoch: 283, Batch number: 68, Loss: 7130.85693359375\n",
      "Epoch: 285, Batch number: 16, Loss: 6911.03125\n",
      "Epoch: 286, Batch number: 40, Loss: 7274.4755859375\n",
      "Epoch: 287, Batch number: 64, Loss: 6988.71044921875\n",
      "Epoch: 289, Batch number: 12, Loss: 7069.39111328125\n",
      "Epoch: 290, Batch number: 36, Loss: 7253.150390625\n",
      "Epoch: 291, Batch number: 60, Loss: 6818.22021484375\n",
      "Epoch: 293, Batch number: 8, Loss: 7066.55126953125\n",
      "Epoch: 294, Batch number: 32, Loss: 7099.84716796875\n",
      "Epoch: 295, Batch number: 56, Loss: 6733.76611328125\n",
      "Epoch: 297, Batch number: 4, Loss: 6873.60888671875\n",
      "Epoch: 298, Batch number: 28, Loss: 7183.50537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299, Batch number: 52, Loss: 7260.18798828125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15432.474609375\n",
      "Epoch: 2, Batch number: 24, Loss: 13443.7060546875\n",
      "Epoch: 3, Batch number: 48, Loss: 12907.533203125\n",
      "Epoch: 4, Batch number: 72, Loss: 11872.9599609375\n",
      "Epoch: 6, Batch number: 20, Loss: 11257.751953125\n",
      "Epoch: 7, Batch number: 44, Loss: 10547.10546875\n",
      "Epoch: 8, Batch number: 68, Loss: 10411.87890625\n",
      "Epoch: 10, Batch number: 16, Loss: 9567.6826171875\n",
      "Epoch: 11, Batch number: 40, Loss: 9308.9345703125\n",
      "Epoch: 12, Batch number: 64, Loss: 9207.2705078125\n",
      "Epoch: 14, Batch number: 12, Loss: 8457.4833984375\n",
      "Epoch: 15, Batch number: 36, Loss: 8430.0458984375\n",
      "Epoch: 16, Batch number: 60, Loss: 8502.6767578125\n",
      "Epoch: 18, Batch number: 8, Loss: 8168.78857421875\n",
      "Epoch: 19, Batch number: 32, Loss: 8006.03857421875\n",
      "Epoch: 20, Batch number: 56, Loss: 8383.7138671875\n",
      "Epoch: 22, Batch number: 4, Loss: 7852.10009765625\n",
      "Epoch: 23, Batch number: 28, Loss: 7947.8017578125\n",
      "Epoch: 24, Batch number: 52, Loss: 7958.07373046875\n",
      "Epoch: 26, Batch number: 0, Loss: 7864.4150390625\n",
      "Epoch: 27, Batch number: 24, Loss: 7710.25732421875\n",
      "Epoch: 28, Batch number: 48, Loss: 7665.55126953125\n",
      "Epoch: 29, Batch number: 72, Loss: 7621.529296875\n",
      "Epoch: 31, Batch number: 20, Loss: 7477.0322265625\n",
      "Epoch: 32, Batch number: 44, Loss: 7470.736328125\n",
      "Epoch: 33, Batch number: 68, Loss: 7621.310546875\n",
      "Epoch: 35, Batch number: 16, Loss: 7457.64501953125\n",
      "Epoch: 36, Batch number: 40, Loss: 7360.60498046875\n",
      "Epoch: 37, Batch number: 64, Loss: 7238.37060546875\n",
      "Epoch: 39, Batch number: 12, Loss: 7246.34423828125\n",
      "Epoch: 40, Batch number: 36, Loss: 7378.30322265625\n",
      "Epoch: 41, Batch number: 60, Loss: 7201.412109375\n",
      "Epoch: 43, Batch number: 8, Loss: 7183.5908203125\n",
      "Epoch: 44, Batch number: 32, Loss: 7192.00634765625\n",
      "Epoch: 45, Batch number: 56, Loss: 7475.4833984375\n",
      "Epoch: 47, Batch number: 4, Loss: 7240.6494140625\n",
      "Epoch: 48, Batch number: 28, Loss: 7131.59130859375\n",
      "Epoch: 49, Batch number: 52, Loss: 7046.93408203125\n",
      "Epoch: 51, Batch number: 0, Loss: 7042.6337890625\n",
      "Epoch: 52, Batch number: 24, Loss: 7372.9697265625\n",
      "Epoch: 53, Batch number: 48, Loss: 7342.24267578125\n",
      "Epoch: 54, Batch number: 72, Loss: 7232.1845703125\n",
      "Epoch: 56, Batch number: 20, Loss: 7201.2236328125\n",
      "Epoch: 57, Batch number: 44, Loss: 7365.697265625\n",
      "Epoch: 58, Batch number: 68, Loss: 6833.4697265625\n",
      "Epoch: 60, Batch number: 16, Loss: 7093.46875\n",
      "Epoch: 61, Batch number: 40, Loss: 7171.548828125\n",
      "Epoch: 62, Batch number: 64, Loss: 7299.87451171875\n",
      "Epoch: 64, Batch number: 12, Loss: 7049.02587890625\n",
      "Epoch: 65, Batch number: 36, Loss: 7114.4248046875\n",
      "Epoch: 66, Batch number: 60, Loss: 7248.88037109375\n",
      "Epoch: 68, Batch number: 8, Loss: 7060.3291015625\n",
      "Epoch: 69, Batch number: 32, Loss: 7058.85498046875\n",
      "Epoch: 70, Batch number: 56, Loss: 7218.6796875\n",
      "Epoch: 72, Batch number: 4, Loss: 6829.07373046875\n",
      "Epoch: 73, Batch number: 28, Loss: 7021.3017578125\n",
      "Epoch: 74, Batch number: 52, Loss: 7185.75830078125\n",
      "Epoch: 76, Batch number: 0, Loss: 6900.06640625\n",
      "Epoch: 77, Batch number: 24, Loss: 7041.5419921875\n",
      "Epoch: 78, Batch number: 48, Loss: 7227.87158203125\n",
      "Epoch: 79, Batch number: 72, Loss: 6972.6611328125\n",
      "Epoch: 81, Batch number: 20, Loss: 7186.767578125\n",
      "Epoch: 82, Batch number: 44, Loss: 6761.9892578125\n",
      "Epoch: 83, Batch number: 68, Loss: 7159.8359375\n",
      "Epoch: 85, Batch number: 16, Loss: 6711.4033203125\n",
      "Epoch: 86, Batch number: 40, Loss: 7092.8447265625\n",
      "Epoch: 87, Batch number: 64, Loss: 7199.77197265625\n",
      "Epoch: 89, Batch number: 12, Loss: 7258.376953125\n",
      "Epoch: 90, Batch number: 36, Loss: 7137.20947265625\n",
      "Epoch: 91, Batch number: 60, Loss: 7257.54345703125\n",
      "Epoch: 93, Batch number: 8, Loss: 6922.4208984375\n",
      "Epoch: 94, Batch number: 32, Loss: 7138.626953125\n",
      "Epoch: 95, Batch number: 56, Loss: 7121.73779296875\n",
      "Epoch: 97, Batch number: 4, Loss: 6957.87744140625\n",
      "Epoch: 98, Batch number: 28, Loss: 7031.59716796875\n",
      "Epoch: 99, Batch number: 52, Loss: 6964.57275390625\n",
      "Epoch: 101, Batch number: 0, Loss: 6832.5732421875\n",
      "Epoch: 102, Batch number: 24, Loss: 7019.66552734375\n",
      "Epoch: 103, Batch number: 48, Loss: 7183.64404296875\n",
      "Epoch: 104, Batch number: 72, Loss: 7246.31298828125\n",
      "Epoch: 106, Batch number: 20, Loss: 6901.0732421875\n",
      "Epoch: 107, Batch number: 44, Loss: 7107.03173828125\n",
      "Epoch: 108, Batch number: 68, Loss: 7097.11376953125\n",
      "Epoch: 110, Batch number: 16, Loss: 7106.97314453125\n",
      "Epoch: 111, Batch number: 40, Loss: 6992.79052734375\n",
      "Epoch: 112, Batch number: 64, Loss: 6822.22021484375\n",
      "Epoch: 114, Batch number: 12, Loss: 7023.44287109375\n",
      "Epoch: 115, Batch number: 36, Loss: 6957.0400390625\n",
      "Epoch: 116, Batch number: 60, Loss: 6925.32177734375\n",
      "Epoch: 118, Batch number: 8, Loss: 6874.11474609375\n",
      "Epoch: 119, Batch number: 32, Loss: 6879.89794921875\n",
      "Epoch: 120, Batch number: 56, Loss: 7212.27880859375\n",
      "Epoch: 122, Batch number: 4, Loss: 7081.6123046875\n",
      "Epoch: 123, Batch number: 28, Loss: 7208.80615234375\n",
      "Epoch: 124, Batch number: 52, Loss: 7026.75537109375\n",
      "Epoch: 126, Batch number: 0, Loss: 6924.37939453125\n",
      "Epoch: 127, Batch number: 24, Loss: 7102.4345703125\n",
      "Epoch: 128, Batch number: 48, Loss: 6912.9501953125\n",
      "Epoch: 129, Batch number: 72, Loss: 7062.64501953125\n",
      "Epoch: 131, Batch number: 20, Loss: 7463.26171875\n",
      "Epoch: 132, Batch number: 44, Loss: 7086.93017578125\n",
      "Epoch: 133, Batch number: 68, Loss: 6926.06982421875\n",
      "Epoch: 135, Batch number: 16, Loss: 6999.87548828125\n",
      "Epoch: 136, Batch number: 40, Loss: 7072.4453125\n",
      "Epoch: 137, Batch number: 64, Loss: 6979.2138671875\n",
      "Epoch: 139, Batch number: 12, Loss: 7021.0341796875\n",
      "Epoch: 140, Batch number: 36, Loss: 7495.94384765625\n",
      "Epoch: 141, Batch number: 60, Loss: 6968.3740234375\n",
      "Epoch: 143, Batch number: 8, Loss: 6702.4228515625\n",
      "Epoch: 144, Batch number: 32, Loss: 6970.8876953125\n",
      "Epoch: 145, Batch number: 56, Loss: 7127.2216796875\n",
      "Epoch: 147, Batch number: 4, Loss: 6807.888671875\n",
      "Epoch: 148, Batch number: 28, Loss: 6993.126953125\n",
      "Epoch: 149, Batch number: 52, Loss: 6973.95458984375\n",
      "Epoch: 151, Batch number: 0, Loss: 6989.14794921875\n",
      "Epoch: 152, Batch number: 24, Loss: 6943.6162109375\n",
      "Epoch: 153, Batch number: 48, Loss: 6899.70263671875\n",
      "Epoch: 154, Batch number: 72, Loss: 7498.07666015625\n",
      "Epoch: 156, Batch number: 20, Loss: 6895.05859375\n",
      "Epoch: 157, Batch number: 44, Loss: 7001.740234375\n",
      "Epoch: 158, Batch number: 68, Loss: 7254.5830078125\n",
      "Epoch: 160, Batch number: 16, Loss: 7057.53857421875\n",
      "Epoch: 161, Batch number: 40, Loss: 6937.2138671875\n",
      "Epoch: 162, Batch number: 64, Loss: 7245.2373046875\n",
      "Epoch: 164, Batch number: 12, Loss: 7161.033203125\n",
      "Epoch: 165, Batch number: 36, Loss: 6679.40283203125\n",
      "Epoch: 166, Batch number: 60, Loss: 7375.72314453125\n",
      "Epoch: 168, Batch number: 8, Loss: 6679.57421875\n",
      "Epoch: 169, Batch number: 32, Loss: 7111.38134765625\n",
      "Epoch: 170, Batch number: 56, Loss: 7100.439453125\n",
      "Epoch: 172, Batch number: 4, Loss: 7066.267578125\n",
      "Epoch: 173, Batch number: 28, Loss: 6840.70263671875\n",
      "Epoch: 174, Batch number: 52, Loss: 7053.30126953125\n",
      "Epoch: 176, Batch number: 0, Loss: 7114.3857421875\n",
      "Epoch: 177, Batch number: 24, Loss: 7104.29833984375\n",
      "Epoch: 178, Batch number: 48, Loss: 7206.18505859375\n",
      "Epoch: 179, Batch number: 72, Loss: 7146.25537109375\n",
      "Epoch: 181, Batch number: 20, Loss: 6898.431640625\n",
      "Epoch: 182, Batch number: 44, Loss: 7136.64794921875\n",
      "Epoch: 183, Batch number: 68, Loss: 7142.81787109375\n",
      "Epoch: 185, Batch number: 16, Loss: 6746.18994140625\n",
      "Epoch: 186, Batch number: 40, Loss: 6653.2490234375\n",
      "Epoch: 187, Batch number: 64, Loss: 6973.29248046875\n",
      "Epoch: 189, Batch number: 12, Loss: 7073.2509765625\n",
      "Epoch: 190, Batch number: 36, Loss: 7159.736328125\n",
      "Epoch: 191, Batch number: 60, Loss: 7259.02685546875\n",
      "Epoch: 193, Batch number: 8, Loss: 7084.53955078125\n",
      "Epoch: 194, Batch number: 32, Loss: 7002.92333984375\n",
      "Epoch: 195, Batch number: 56, Loss: 7172.423828125\n",
      "Epoch: 197, Batch number: 4, Loss: 6879.53369140625\n",
      "Epoch: 198, Batch number: 28, Loss: 7173.6298828125\n",
      "Epoch: 199, Batch number: 52, Loss: 6913.091796875\n",
      "Epoch: 201, Batch number: 0, Loss: 6807.75146484375\n",
      "Epoch: 202, Batch number: 24, Loss: 7154.802734375\n",
      "Epoch: 203, Batch number: 48, Loss: 7056.7958984375\n",
      "Epoch: 204, Batch number: 72, Loss: 7167.751953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 7079.3193359375\n",
      "Epoch: 207, Batch number: 44, Loss: 7175.67333984375\n",
      "Epoch: 208, Batch number: 68, Loss: 6957.24609375\n",
      "Epoch: 210, Batch number: 16, Loss: 6716.90673828125\n",
      "Epoch: 211, Batch number: 40, Loss: 6947.52001953125\n",
      "Epoch: 212, Batch number: 64, Loss: 7065.7138671875\n",
      "Epoch: 214, Batch number: 12, Loss: 6777.7490234375\n",
      "Epoch: 215, Batch number: 36, Loss: 6738.94921875\n",
      "Epoch: 216, Batch number: 60, Loss: 6893.47265625\n",
      "Epoch: 218, Batch number: 8, Loss: 6920.6923828125\n",
      "Epoch: 219, Batch number: 32, Loss: 6933.88623046875\n",
      "Epoch: 220, Batch number: 56, Loss: 7150.83154296875\n",
      "Epoch: 222, Batch number: 4, Loss: 6609.7255859375\n",
      "Epoch: 223, Batch number: 28, Loss: 7144.12841796875\n",
      "Epoch: 224, Batch number: 52, Loss: 7060.8798828125\n",
      "Epoch: 226, Batch number: 0, Loss: 6762.61767578125\n",
      "Epoch: 227, Batch number: 24, Loss: 6826.2705078125\n",
      "Epoch: 228, Batch number: 48, Loss: 7068.05517578125\n",
      "Epoch: 229, Batch number: 72, Loss: 6904.880859375\n",
      "Epoch: 231, Batch number: 20, Loss: 7036.68359375\n",
      "Epoch: 232, Batch number: 44, Loss: 6812.193359375\n",
      "Epoch: 233, Batch number: 68, Loss: 7137.068359375\n",
      "Epoch: 235, Batch number: 16, Loss: 6999.8828125\n",
      "Epoch: 236, Batch number: 40, Loss: 7042.50634765625\n",
      "Epoch: 237, Batch number: 64, Loss: 7231.150390625\n",
      "Epoch: 239, Batch number: 12, Loss: 7018.04736328125\n",
      "Epoch: 240, Batch number: 36, Loss: 7019.4072265625\n",
      "Epoch: 241, Batch number: 60, Loss: 7192.65185546875\n",
      "Epoch: 243, Batch number: 8, Loss: 7173.40576171875\n",
      "Epoch: 244, Batch number: 32, Loss: 6765.57861328125\n",
      "Epoch: 245, Batch number: 56, Loss: 7177.29150390625\n",
      "Epoch: 247, Batch number: 4, Loss: 6870.59912109375\n",
      "Epoch: 248, Batch number: 28, Loss: 6622.046875\n",
      "Epoch: 249, Batch number: 52, Loss: 7333.53857421875\n",
      "Epoch: 251, Batch number: 0, Loss: 6773.59619140625\n",
      "Epoch: 252, Batch number: 24, Loss: 7017.98486328125\n",
      "Epoch: 253, Batch number: 48, Loss: 6924.708984375\n",
      "Epoch: 254, Batch number: 72, Loss: 7003.31103515625\n",
      "Epoch: 256, Batch number: 20, Loss: 6959.6357421875\n",
      "Epoch: 257, Batch number: 44, Loss: 6804.314453125\n",
      "Epoch: 258, Batch number: 68, Loss: 7112.36669921875\n",
      "Epoch: 260, Batch number: 16, Loss: 7181.7294921875\n",
      "Epoch: 261, Batch number: 40, Loss: 6936.1826171875\n",
      "Epoch: 262, Batch number: 64, Loss: 7333.96240234375\n",
      "Epoch: 264, Batch number: 12, Loss: 7129.13037109375\n",
      "Epoch: 265, Batch number: 36, Loss: 7201.5625\n",
      "Epoch: 266, Batch number: 60, Loss: 7165.70703125\n",
      "Epoch: 268, Batch number: 8, Loss: 6846.05615234375\n",
      "Epoch: 269, Batch number: 32, Loss: 7134.18798828125\n",
      "Epoch: 270, Batch number: 56, Loss: 7179.92236328125\n",
      "Epoch: 272, Batch number: 4, Loss: 7023.4140625\n",
      "Epoch: 273, Batch number: 28, Loss: 6828.35546875\n",
      "Epoch: 274, Batch number: 52, Loss: 7234.15234375\n",
      "Epoch: 276, Batch number: 0, Loss: 6994.64794921875\n",
      "Epoch: 277, Batch number: 24, Loss: 7207.57421875\n",
      "Epoch: 278, Batch number: 48, Loss: 7139.6455078125\n",
      "Epoch: 279, Batch number: 72, Loss: 7406.24658203125\n",
      "Epoch: 281, Batch number: 20, Loss: 7105.86474609375\n",
      "Epoch: 282, Batch number: 44, Loss: 7193.69189453125\n",
      "Epoch: 283, Batch number: 68, Loss: 7195.07373046875\n",
      "Epoch: 285, Batch number: 16, Loss: 6937.3779296875\n",
      "Epoch: 286, Batch number: 40, Loss: 6979.41162109375\n",
      "Epoch: 287, Batch number: 64, Loss: 7008.30126953125\n",
      "Epoch: 289, Batch number: 12, Loss: 6835.75048828125\n",
      "Epoch: 290, Batch number: 36, Loss: 7051.1279296875\n",
      "Epoch: 291, Batch number: 60, Loss: 6951.333984375\n",
      "Epoch: 293, Batch number: 8, Loss: 6994.29833984375\n",
      "Epoch: 294, Batch number: 32, Loss: 7098.3466796875\n",
      "Epoch: 295, Batch number: 56, Loss: 7316.16259765625\n",
      "Epoch: 297, Batch number: 4, Loss: 6891.74755859375\n",
      "Epoch: 298, Batch number: 28, Loss: 7009.25390625\n",
      "Epoch: 299, Batch number: 52, Loss: 7085.8037109375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21347.255859375\n",
      "Epoch: 2, Batch number: 24, Loss: 21285.88671875\n",
      "Epoch: 3, Batch number: 48, Loss: 20884.75390625\n",
      "Epoch: 4, Batch number: 72, Loss: 19624.15234375\n",
      "Epoch: 6, Batch number: 20, Loss: 19107.05859375\n",
      "Epoch: 7, Batch number: 44, Loss: 18898.400390625\n",
      "Epoch: 8, Batch number: 68, Loss: 17951.189453125\n",
      "Epoch: 10, Batch number: 16, Loss: 17757.953125\n",
      "Epoch: 11, Batch number: 40, Loss: 17298.05859375\n",
      "Epoch: 12, Batch number: 64, Loss: 17154.888671875\n",
      "Epoch: 14, Batch number: 12, Loss: 16653.5703125\n",
      "Epoch: 15, Batch number: 36, Loss: 16598.90625\n",
      "Epoch: 16, Batch number: 60, Loss: 16551.78515625\n",
      "Epoch: 18, Batch number: 8, Loss: 16008.0546875\n",
      "Epoch: 19, Batch number: 32, Loss: 16117.451171875\n",
      "Epoch: 20, Batch number: 56, Loss: 15799.9267578125\n",
      "Epoch: 22, Batch number: 4, Loss: 15462.3330078125\n",
      "Epoch: 23, Batch number: 28, Loss: 15480.255859375\n",
      "Epoch: 24, Batch number: 52, Loss: 15618.078125\n",
      "Epoch: 26, Batch number: 0, Loss: 15603.044921875\n",
      "Epoch: 27, Batch number: 24, Loss: 15527.95703125\n",
      "Epoch: 28, Batch number: 48, Loss: 15266.5771484375\n",
      "Epoch: 29, Batch number: 72, Loss: 15177.21484375\n",
      "Epoch: 31, Batch number: 20, Loss: 14482.6962890625\n",
      "Epoch: 32, Batch number: 44, Loss: 14776.1953125\n",
      "Epoch: 33, Batch number: 68, Loss: 14616.814453125\n",
      "Epoch: 35, Batch number: 16, Loss: 14608.994140625\n",
      "Epoch: 36, Batch number: 40, Loss: 14904.7724609375\n",
      "Epoch: 37, Batch number: 64, Loss: 14602.384765625\n",
      "Epoch: 39, Batch number: 12, Loss: 14533.6240234375\n",
      "Epoch: 40, Batch number: 36, Loss: 14015.9208984375\n",
      "Epoch: 41, Batch number: 60, Loss: 14357.3310546875\n",
      "Epoch: 43, Batch number: 8, Loss: 14171.580078125\n",
      "Epoch: 44, Batch number: 32, Loss: 13933.2734375\n",
      "Epoch: 45, Batch number: 56, Loss: 14098.5439453125\n",
      "Epoch: 47, Batch number: 4, Loss: 14092.6171875\n",
      "Epoch: 48, Batch number: 28, Loss: 14113.8408203125\n",
      "Epoch: 49, Batch number: 52, Loss: 14113.8837890625\n",
      "Epoch: 51, Batch number: 0, Loss: 13929.9384765625\n",
      "Epoch: 52, Batch number: 24, Loss: 14260.5302734375\n",
      "Epoch: 53, Batch number: 48, Loss: 14050.705078125\n",
      "Epoch: 54, Batch number: 72, Loss: 14249.0234375\n",
      "Epoch: 56, Batch number: 20, Loss: 13690.5712890625\n",
      "Epoch: 57, Batch number: 44, Loss: 13782.44921875\n",
      "Epoch: 58, Batch number: 68, Loss: 14000.5732421875\n",
      "Epoch: 60, Batch number: 16, Loss: 13599.6826171875\n",
      "Epoch: 61, Batch number: 40, Loss: 14034.3212890625\n",
      "Epoch: 62, Batch number: 64, Loss: 13714.5498046875\n",
      "Epoch: 64, Batch number: 12, Loss: 13689.537109375\n",
      "Epoch: 65, Batch number: 36, Loss: 13656.607421875\n",
      "Epoch: 66, Batch number: 60, Loss: 13616.255859375\n",
      "Epoch: 68, Batch number: 8, Loss: 13512.724609375\n",
      "Epoch: 69, Batch number: 32, Loss: 13564.6669921875\n",
      "Epoch: 70, Batch number: 56, Loss: 13371.759765625\n",
      "Epoch: 72, Batch number: 4, Loss: 13280.1123046875\n",
      "Epoch: 73, Batch number: 28, Loss: 13359.4140625\n",
      "Epoch: 74, Batch number: 52, Loss: 13542.8310546875\n",
      "Epoch: 76, Batch number: 0, Loss: 13352.326171875\n",
      "Epoch: 77, Batch number: 24, Loss: 13270.4365234375\n",
      "Epoch: 78, Batch number: 48, Loss: 13106.462890625\n",
      "Epoch: 79, Batch number: 72, Loss: 13071.7529296875\n",
      "Epoch: 81, Batch number: 20, Loss: 13248.6044921875\n",
      "Epoch: 82, Batch number: 44, Loss: 13288.9541015625\n",
      "Epoch: 83, Batch number: 68, Loss: 13470.169921875\n",
      "Epoch: 85, Batch number: 16, Loss: 13320.2998046875\n",
      "Epoch: 86, Batch number: 40, Loss: 13147.23828125\n",
      "Epoch: 87, Batch number: 64, Loss: 13157.9755859375\n",
      "Epoch: 89, Batch number: 12, Loss: 13142.19140625\n",
      "Epoch: 90, Batch number: 36, Loss: 12825.6181640625\n",
      "Epoch: 91, Batch number: 60, Loss: 13243.328125\n",
      "Epoch: 93, Batch number: 8, Loss: 12923.4453125\n",
      "Epoch: 94, Batch number: 32, Loss: 13314.6337890625\n",
      "Epoch: 95, Batch number: 56, Loss: 12939.6435546875\n",
      "Epoch: 97, Batch number: 4, Loss: 12793.701171875\n",
      "Epoch: 98, Batch number: 28, Loss: 12865.3642578125\n",
      "Epoch: 99, Batch number: 52, Loss: 12973.275390625\n",
      "Epoch: 101, Batch number: 0, Loss: 12997.94921875\n",
      "Epoch: 102, Batch number: 24, Loss: 12890.3759765625\n",
      "Epoch: 103, Batch number: 48, Loss: 13038.5595703125\n",
      "Epoch: 104, Batch number: 72, Loss: 13001.07421875\n",
      "Epoch: 106, Batch number: 20, Loss: 13023.6025390625\n",
      "Epoch: 107, Batch number: 44, Loss: 12612.1826171875\n",
      "Epoch: 108, Batch number: 68, Loss: 12752.9921875\n",
      "Epoch: 110, Batch number: 16, Loss: 12733.3232421875\n",
      "Epoch: 111, Batch number: 40, Loss: 12662.349609375\n",
      "Epoch: 112, Batch number: 64, Loss: 12764.1455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114, Batch number: 12, Loss: 12582.25\n",
      "Epoch: 115, Batch number: 36, Loss: 12762.6767578125\n",
      "Epoch: 116, Batch number: 60, Loss: 12692.861328125\n",
      "Epoch: 118, Batch number: 8, Loss: 12646.0224609375\n",
      "Epoch: 119, Batch number: 32, Loss: 12429.189453125\n",
      "Epoch: 120, Batch number: 56, Loss: 12869.2578125\n",
      "Epoch: 122, Batch number: 4, Loss: 12260.2451171875\n",
      "Epoch: 123, Batch number: 28, Loss: 12787.6005859375\n",
      "Epoch: 124, Batch number: 52, Loss: 12611.2626953125\n",
      "Epoch: 126, Batch number: 0, Loss: 12505.82421875\n",
      "Epoch: 127, Batch number: 24, Loss: 12644.7705078125\n",
      "Epoch: 128, Batch number: 48, Loss: 12555.1728515625\n",
      "Epoch: 129, Batch number: 72, Loss: 12600.5703125\n",
      "Epoch: 131, Batch number: 20, Loss: 12286.701171875\n",
      "Epoch: 132, Batch number: 44, Loss: 12341.0712890625\n",
      "Epoch: 133, Batch number: 68, Loss: 12309.2236328125\n",
      "Epoch: 135, Batch number: 16, Loss: 12393.833984375\n",
      "Epoch: 136, Batch number: 40, Loss: 12275.1962890625\n",
      "Epoch: 137, Batch number: 64, Loss: 12452.91796875\n",
      "Epoch: 139, Batch number: 12, Loss: 12403.015625\n",
      "Epoch: 140, Batch number: 36, Loss: 12416.931640625\n",
      "Epoch: 141, Batch number: 60, Loss: 11910.8037109375\n",
      "Epoch: 143, Batch number: 8, Loss: 12296.5576171875\n",
      "Epoch: 144, Batch number: 32, Loss: 12411.71484375\n",
      "Epoch: 145, Batch number: 56, Loss: 12132.263671875\n",
      "Epoch: 147, Batch number: 4, Loss: 12199.5908203125\n",
      "Epoch: 148, Batch number: 28, Loss: 12321.68359375\n",
      "Epoch: 149, Batch number: 52, Loss: 12234.58203125\n",
      "Epoch: 151, Batch number: 0, Loss: 12185.1083984375\n",
      "Epoch: 152, Batch number: 24, Loss: 12275.8779296875\n",
      "Epoch: 153, Batch number: 48, Loss: 12149.9970703125\n",
      "Epoch: 154, Batch number: 72, Loss: 12353.5869140625\n",
      "Epoch: 156, Batch number: 20, Loss: 11806.5361328125\n",
      "Epoch: 157, Batch number: 44, Loss: 12246.84375\n",
      "Epoch: 158, Batch number: 68, Loss: 12220.7646484375\n",
      "Epoch: 160, Batch number: 16, Loss: 12211.353515625\n",
      "Epoch: 161, Batch number: 40, Loss: 11998.78515625\n",
      "Epoch: 162, Batch number: 64, Loss: 12303.1650390625\n",
      "Epoch: 164, Batch number: 12, Loss: 12152.232421875\n",
      "Epoch: 165, Batch number: 36, Loss: 12295.296875\n",
      "Epoch: 166, Batch number: 60, Loss: 12262.142578125\n",
      "Epoch: 168, Batch number: 8, Loss: 11838.4873046875\n",
      "Epoch: 169, Batch number: 32, Loss: 11982.626953125\n",
      "Epoch: 170, Batch number: 56, Loss: 12267.1484375\n",
      "Epoch: 172, Batch number: 4, Loss: 11664.654296875\n",
      "Epoch: 173, Batch number: 28, Loss: 11829.9072265625\n",
      "Epoch: 174, Batch number: 52, Loss: 12325.92578125\n",
      "Epoch: 176, Batch number: 0, Loss: 12041.7705078125\n",
      "Epoch: 177, Batch number: 24, Loss: 12018.9033203125\n",
      "Epoch: 178, Batch number: 48, Loss: 12061.40625\n",
      "Epoch: 179, Batch number: 72, Loss: 11827.8037109375\n",
      "Epoch: 181, Batch number: 20, Loss: 11559.8134765625\n",
      "Epoch: 182, Batch number: 44, Loss: 11821.98828125\n",
      "Epoch: 183, Batch number: 68, Loss: 11825.1416015625\n",
      "Epoch: 185, Batch number: 16, Loss: 12005.6748046875\n",
      "Epoch: 186, Batch number: 40, Loss: 11831.119140625\n",
      "Epoch: 187, Batch number: 64, Loss: 12057.49609375\n",
      "Epoch: 189, Batch number: 12, Loss: 11653.0224609375\n",
      "Epoch: 190, Batch number: 36, Loss: 11867.2275390625\n",
      "Epoch: 191, Batch number: 60, Loss: 12069.53515625\n",
      "Epoch: 193, Batch number: 8, Loss: 11982.4833984375\n",
      "Epoch: 194, Batch number: 32, Loss: 11674.384765625\n",
      "Epoch: 195, Batch number: 56, Loss: 11752.654296875\n",
      "Epoch: 197, Batch number: 4, Loss: 11893.4765625\n",
      "Epoch: 198, Batch number: 28, Loss: 12001.650390625\n",
      "Epoch: 199, Batch number: 52, Loss: 11671.8994140625\n",
      "Epoch: 201, Batch number: 0, Loss: 12117.841796875\n",
      "Epoch: 202, Batch number: 24, Loss: 11664.55859375\n",
      "Epoch: 203, Batch number: 48, Loss: 11510.6484375\n",
      "Epoch: 204, Batch number: 72, Loss: 11727.4853515625\n",
      "Epoch: 206, Batch number: 20, Loss: 11659.40234375\n",
      "Epoch: 207, Batch number: 44, Loss: 11791.8388671875\n",
      "Epoch: 208, Batch number: 68, Loss: 11422.978515625\n",
      "Epoch: 210, Batch number: 16, Loss: 11331.4794921875\n",
      "Epoch: 211, Batch number: 40, Loss: 11644.9306640625\n",
      "Epoch: 212, Batch number: 64, Loss: 11706.845703125\n",
      "Epoch: 214, Batch number: 12, Loss: 11689.423828125\n",
      "Epoch: 215, Batch number: 36, Loss: 11862.1572265625\n",
      "Epoch: 216, Batch number: 60, Loss: 11739.1572265625\n",
      "Epoch: 218, Batch number: 8, Loss: 11633.8955078125\n",
      "Epoch: 219, Batch number: 32, Loss: 11675.1357421875\n",
      "Epoch: 220, Batch number: 56, Loss: 11572.6337890625\n",
      "Epoch: 222, Batch number: 4, Loss: 12065.5986328125\n",
      "Epoch: 223, Batch number: 28, Loss: 11407.712890625\n",
      "Epoch: 224, Batch number: 52, Loss: 11487.962890625\n",
      "Epoch: 226, Batch number: 0, Loss: 11740.7568359375\n",
      "Epoch: 227, Batch number: 24, Loss: 11565.7958984375\n",
      "Epoch: 228, Batch number: 48, Loss: 11676.5107421875\n",
      "Epoch: 229, Batch number: 72, Loss: 11741.578125\n",
      "Epoch: 231, Batch number: 20, Loss: 11094.4814453125\n",
      "Epoch: 232, Batch number: 44, Loss: 11711.060546875\n",
      "Epoch: 233, Batch number: 68, Loss: 11857.9501953125\n",
      "Epoch: 235, Batch number: 16, Loss: 11495.009765625\n",
      "Epoch: 236, Batch number: 40, Loss: 11569.501953125\n",
      "Epoch: 237, Batch number: 64, Loss: 11372.205078125\n",
      "Epoch: 239, Batch number: 12, Loss: 11777.697265625\n",
      "Epoch: 240, Batch number: 36, Loss: 11727.65625\n",
      "Epoch: 241, Batch number: 60, Loss: 11479.560546875\n",
      "Epoch: 243, Batch number: 8, Loss: 11860.5634765625\n",
      "Epoch: 244, Batch number: 32, Loss: 11738.91796875\n",
      "Epoch: 245, Batch number: 56, Loss: 11874.8818359375\n",
      "Epoch: 247, Batch number: 4, Loss: 11266.181640625\n",
      "Epoch: 248, Batch number: 28, Loss: 11664.3623046875\n",
      "Epoch: 249, Batch number: 52, Loss: 11875.806640625\n",
      "Epoch: 251, Batch number: 0, Loss: 11797.8486328125\n",
      "Epoch: 252, Batch number: 24, Loss: 11336.9443359375\n",
      "Epoch: 253, Batch number: 48, Loss: 11610.154296875\n",
      "Epoch: 254, Batch number: 72, Loss: 11544.9208984375\n",
      "Epoch: 256, Batch number: 20, Loss: 11790.3955078125\n",
      "Epoch: 257, Batch number: 44, Loss: 11442.72265625\n",
      "Epoch: 258, Batch number: 68, Loss: 11369.9501953125\n",
      "Epoch: 260, Batch number: 16, Loss: 11690.806640625\n",
      "Epoch: 261, Batch number: 40, Loss: 11547.0712890625\n",
      "Epoch: 262, Batch number: 64, Loss: 11771.3896484375\n",
      "Epoch: 264, Batch number: 12, Loss: 11370.6953125\n",
      "Epoch: 265, Batch number: 36, Loss: 11396.8818359375\n",
      "Epoch: 266, Batch number: 60, Loss: 11383.1953125\n",
      "Epoch: 268, Batch number: 8, Loss: 11464.7939453125\n",
      "Epoch: 269, Batch number: 32, Loss: 11602.1640625\n",
      "Epoch: 270, Batch number: 56, Loss: 11309.326171875\n",
      "Epoch: 272, Batch number: 4, Loss: 11306.9384765625\n",
      "Epoch: 273, Batch number: 28, Loss: 11661.6923828125\n",
      "Epoch: 274, Batch number: 52, Loss: 11196.4140625\n",
      "Epoch: 276, Batch number: 0, Loss: 11383.513671875\n",
      "Epoch: 277, Batch number: 24, Loss: 11366.2578125\n",
      "Epoch: 278, Batch number: 48, Loss: 11257.0361328125\n",
      "Epoch: 279, Batch number: 72, Loss: 11266.728515625\n",
      "Epoch: 281, Batch number: 20, Loss: 11261.029296875\n",
      "Epoch: 282, Batch number: 44, Loss: 11402.333984375\n",
      "Epoch: 283, Batch number: 68, Loss: 11047.62890625\n",
      "Epoch: 285, Batch number: 16, Loss: 11356.3740234375\n",
      "Epoch: 286, Batch number: 40, Loss: 11719.787109375\n",
      "Epoch: 287, Batch number: 64, Loss: 11534.498046875\n",
      "Epoch: 289, Batch number: 12, Loss: 11435.462890625\n",
      "Epoch: 290, Batch number: 36, Loss: 11292.1416015625\n",
      "Epoch: 291, Batch number: 60, Loss: 11035.474609375\n",
      "Epoch: 293, Batch number: 8, Loss: 11182.9677734375\n",
      "Epoch: 294, Batch number: 32, Loss: 11331.6171875\n",
      "Epoch: 295, Batch number: 56, Loss: 10993.5908203125\n",
      "Epoch: 297, Batch number: 4, Loss: 11327.0478515625\n",
      "Epoch: 298, Batch number: 28, Loss: 10931.2080078125\n",
      "Epoch: 299, Batch number: 52, Loss: 11432.681640625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 20841.26953125\n",
      "Epoch: 2, Batch number: 24, Loss: 20697.3671875\n",
      "Epoch: 3, Batch number: 48, Loss: 20122.638671875\n",
      "Epoch: 4, Batch number: 72, Loss: 19287.728515625\n",
      "Epoch: 6, Batch number: 20, Loss: 18124.923828125\n",
      "Epoch: 7, Batch number: 44, Loss: 18184.611328125\n",
      "Epoch: 8, Batch number: 68, Loss: 16742.109375\n",
      "Epoch: 10, Batch number: 16, Loss: 16326.4765625\n",
      "Epoch: 11, Batch number: 40, Loss: 16381.1474609375\n",
      "Epoch: 12, Batch number: 64, Loss: 16178.4306640625\n",
      "Epoch: 14, Batch number: 12, Loss: 15728.1484375\n",
      "Epoch: 15, Batch number: 36, Loss: 15473.970703125\n",
      "Epoch: 16, Batch number: 60, Loss: 15315.107421875\n",
      "Epoch: 18, Batch number: 8, Loss: 14794.1572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Batch number: 32, Loss: 14750.654296875\n",
      "Epoch: 20, Batch number: 56, Loss: 14792.708984375\n",
      "Epoch: 22, Batch number: 4, Loss: 14511.626953125\n",
      "Epoch: 23, Batch number: 28, Loss: 14392.876953125\n",
      "Epoch: 24, Batch number: 52, Loss: 14137.0498046875\n",
      "Epoch: 26, Batch number: 0, Loss: 14087.060546875\n",
      "Epoch: 27, Batch number: 24, Loss: 13837.533203125\n",
      "Epoch: 28, Batch number: 48, Loss: 13759.900390625\n",
      "Epoch: 29, Batch number: 72, Loss: 14142.1552734375\n",
      "Epoch: 31, Batch number: 20, Loss: 13421.8681640625\n",
      "Epoch: 32, Batch number: 44, Loss: 13394.4306640625\n",
      "Epoch: 33, Batch number: 68, Loss: 13385.1826171875\n",
      "Epoch: 35, Batch number: 16, Loss: 13283.384765625\n",
      "Epoch: 36, Batch number: 40, Loss: 13173.3115234375\n",
      "Epoch: 37, Batch number: 64, Loss: 13194.1318359375\n",
      "Epoch: 39, Batch number: 12, Loss: 12878.8779296875\n",
      "Epoch: 40, Batch number: 36, Loss: 13140.0263671875\n",
      "Epoch: 41, Batch number: 60, Loss: 12959.33203125\n",
      "Epoch: 43, Batch number: 8, Loss: 12996.9873046875\n",
      "Epoch: 44, Batch number: 32, Loss: 12601.4560546875\n",
      "Epoch: 45, Batch number: 56, Loss: 12884.7421875\n",
      "Epoch: 47, Batch number: 4, Loss: 12703.556640625\n",
      "Epoch: 48, Batch number: 28, Loss: 12334.0576171875\n",
      "Epoch: 49, Batch number: 52, Loss: 12647.73046875\n",
      "Epoch: 51, Batch number: 0, Loss: 12604.3125\n",
      "Epoch: 52, Batch number: 24, Loss: 12733.021484375\n",
      "Epoch: 53, Batch number: 48, Loss: 12526.849609375\n",
      "Epoch: 54, Batch number: 72, Loss: 12626.677734375\n",
      "Epoch: 56, Batch number: 20, Loss: 12506.0771484375\n",
      "Epoch: 57, Batch number: 44, Loss: 12595.728515625\n",
      "Epoch: 58, Batch number: 68, Loss: 12529.615234375\n",
      "Epoch: 60, Batch number: 16, Loss: 12220.662109375\n",
      "Epoch: 61, Batch number: 40, Loss: 12114.5068359375\n",
      "Epoch: 62, Batch number: 64, Loss: 12613.67578125\n",
      "Epoch: 64, Batch number: 12, Loss: 12248.31640625\n",
      "Epoch: 65, Batch number: 36, Loss: 12232.13671875\n",
      "Epoch: 66, Batch number: 60, Loss: 12093.9521484375\n",
      "Epoch: 68, Batch number: 8, Loss: 12309.7197265625\n",
      "Epoch: 69, Batch number: 32, Loss: 12121.509765625\n",
      "Epoch: 70, Batch number: 56, Loss: 12187.119140625\n",
      "Epoch: 72, Batch number: 4, Loss: 12227.9091796875\n",
      "Epoch: 73, Batch number: 28, Loss: 12214.0859375\n",
      "Epoch: 74, Batch number: 52, Loss: 11908.2900390625\n",
      "Epoch: 76, Batch number: 0, Loss: 12236.4365234375\n",
      "Epoch: 77, Batch number: 24, Loss: 12225.794921875\n",
      "Epoch: 78, Batch number: 48, Loss: 11746.947265625\n",
      "Epoch: 79, Batch number: 72, Loss: 12221.12890625\n",
      "Epoch: 81, Batch number: 20, Loss: 12186.9599609375\n",
      "Epoch: 82, Batch number: 44, Loss: 12024.884765625\n",
      "Epoch: 83, Batch number: 68, Loss: 11978.4462890625\n",
      "Epoch: 85, Batch number: 16, Loss: 11719.6796875\n",
      "Epoch: 86, Batch number: 40, Loss: 11996.861328125\n",
      "Epoch: 87, Batch number: 64, Loss: 12005.640625\n",
      "Epoch: 89, Batch number: 12, Loss: 12056.9267578125\n",
      "Epoch: 90, Batch number: 36, Loss: 11649.84765625\n",
      "Epoch: 91, Batch number: 60, Loss: 12411.796875\n",
      "Epoch: 93, Batch number: 8, Loss: 11994.25\n",
      "Epoch: 94, Batch number: 32, Loss: 11562.28125\n",
      "Epoch: 95, Batch number: 56, Loss: 11538.9306640625\n",
      "Epoch: 97, Batch number: 4, Loss: 11383.74609375\n",
      "Epoch: 98, Batch number: 28, Loss: 11378.5224609375\n",
      "Epoch: 99, Batch number: 52, Loss: 11751.740234375\n",
      "Epoch: 101, Batch number: 0, Loss: 11832.623046875\n",
      "Epoch: 102, Batch number: 24, Loss: 11709.2978515625\n",
      "Epoch: 103, Batch number: 48, Loss: 11457.732421875\n",
      "Epoch: 104, Batch number: 72, Loss: 11503.607421875\n",
      "Epoch: 106, Batch number: 20, Loss: 11473.814453125\n",
      "Epoch: 107, Batch number: 44, Loss: 11496.697265625\n",
      "Epoch: 108, Batch number: 68, Loss: 11804.689453125\n",
      "Epoch: 110, Batch number: 16, Loss: 11667.943359375\n",
      "Epoch: 111, Batch number: 40, Loss: 11343.5791015625\n",
      "Epoch: 112, Batch number: 64, Loss: 11475.1259765625\n",
      "Epoch: 114, Batch number: 12, Loss: 11789.41796875\n",
      "Epoch: 115, Batch number: 36, Loss: 11161.380859375\n",
      "Epoch: 116, Batch number: 60, Loss: 11580.21875\n",
      "Epoch: 118, Batch number: 8, Loss: 11311.1943359375\n",
      "Epoch: 119, Batch number: 32, Loss: 11236.1396484375\n",
      "Epoch: 120, Batch number: 56, Loss: 11703.6826171875\n",
      "Epoch: 122, Batch number: 4, Loss: 11503.984375\n",
      "Epoch: 123, Batch number: 28, Loss: 11194.369140625\n",
      "Epoch: 124, Batch number: 52, Loss: 11120.650390625\n",
      "Epoch: 126, Batch number: 0, Loss: 11176.6826171875\n",
      "Epoch: 127, Batch number: 24, Loss: 11413.1298828125\n",
      "Epoch: 128, Batch number: 48, Loss: 11514.11328125\n",
      "Epoch: 129, Batch number: 72, Loss: 11236.2763671875\n",
      "Epoch: 131, Batch number: 20, Loss: 11264.7197265625\n",
      "Epoch: 132, Batch number: 44, Loss: 11518.7900390625\n",
      "Epoch: 133, Batch number: 68, Loss: 11461.2216796875\n",
      "Epoch: 135, Batch number: 16, Loss: 11246.0947265625\n",
      "Epoch: 136, Batch number: 40, Loss: 10940.7001953125\n",
      "Epoch: 137, Batch number: 64, Loss: 11088.3837890625\n",
      "Epoch: 139, Batch number: 12, Loss: 11777.4638671875\n",
      "Epoch: 140, Batch number: 36, Loss: 10963.0986328125\n",
      "Epoch: 141, Batch number: 60, Loss: 11263.0947265625\n",
      "Epoch: 143, Batch number: 8, Loss: 11323.193359375\n",
      "Epoch: 144, Batch number: 32, Loss: 11274.6083984375\n",
      "Epoch: 145, Batch number: 56, Loss: 11247.1845703125\n",
      "Epoch: 147, Batch number: 4, Loss: 11207.728515625\n",
      "Epoch: 148, Batch number: 28, Loss: 11037.4931640625\n",
      "Epoch: 149, Batch number: 52, Loss: 10871.9716796875\n",
      "Epoch: 151, Batch number: 0, Loss: 11081.28125\n",
      "Epoch: 152, Batch number: 24, Loss: 11071.328125\n",
      "Epoch: 153, Batch number: 48, Loss: 11157.94140625\n",
      "Epoch: 154, Batch number: 72, Loss: 11206.443359375\n",
      "Epoch: 156, Batch number: 20, Loss: 11054.8203125\n",
      "Epoch: 157, Batch number: 44, Loss: 11398.0537109375\n",
      "Epoch: 158, Batch number: 68, Loss: 11053.7431640625\n",
      "Epoch: 160, Batch number: 16, Loss: 11111.765625\n",
      "Epoch: 161, Batch number: 40, Loss: 11066.0693359375\n",
      "Epoch: 162, Batch number: 64, Loss: 10757.5634765625\n",
      "Epoch: 164, Batch number: 12, Loss: 11122.0302734375\n",
      "Epoch: 165, Batch number: 36, Loss: 10967.49609375\n",
      "Epoch: 166, Batch number: 60, Loss: 10962.09765625\n",
      "Epoch: 168, Batch number: 8, Loss: 11075.0322265625\n",
      "Epoch: 169, Batch number: 32, Loss: 11215.4404296875\n",
      "Epoch: 170, Batch number: 56, Loss: 10746.7822265625\n",
      "Epoch: 172, Batch number: 4, Loss: 10950.60546875\n",
      "Epoch: 173, Batch number: 28, Loss: 11031.9931640625\n",
      "Epoch: 174, Batch number: 52, Loss: 10620.0458984375\n",
      "Epoch: 176, Batch number: 0, Loss: 10757.59375\n",
      "Epoch: 177, Batch number: 24, Loss: 11265.19921875\n",
      "Epoch: 178, Batch number: 48, Loss: 10906.46875\n",
      "Epoch: 179, Batch number: 72, Loss: 11267.8671875\n",
      "Epoch: 181, Batch number: 20, Loss: 10989.037109375\n",
      "Epoch: 182, Batch number: 44, Loss: 11264.5185546875\n",
      "Epoch: 183, Batch number: 68, Loss: 10794.4921875\n",
      "Epoch: 185, Batch number: 16, Loss: 11094.521484375\n",
      "Epoch: 186, Batch number: 40, Loss: 10945.271484375\n",
      "Epoch: 187, Batch number: 64, Loss: 10971.37109375\n",
      "Epoch: 189, Batch number: 12, Loss: 11083.1904296875\n",
      "Epoch: 190, Batch number: 36, Loss: 10872.7734375\n",
      "Epoch: 191, Batch number: 60, Loss: 11373.837890625\n",
      "Epoch: 193, Batch number: 8, Loss: 10964.0224609375\n",
      "Epoch: 194, Batch number: 32, Loss: 10763.2822265625\n",
      "Epoch: 195, Batch number: 56, Loss: 10851.890625\n",
      "Epoch: 197, Batch number: 4, Loss: 10668.4482421875\n",
      "Epoch: 198, Batch number: 28, Loss: 10712.203125\n",
      "Epoch: 199, Batch number: 52, Loss: 11172.630859375\n",
      "Epoch: 201, Batch number: 0, Loss: 10778.671875\n",
      "Epoch: 202, Batch number: 24, Loss: 10967.7890625\n",
      "Epoch: 203, Batch number: 48, Loss: 10961.5146484375\n",
      "Epoch: 204, Batch number: 72, Loss: 10611.6337890625\n",
      "Epoch: 206, Batch number: 20, Loss: 10793.923828125\n",
      "Epoch: 207, Batch number: 44, Loss: 10940.1083984375\n",
      "Epoch: 208, Batch number: 68, Loss: 10802.9482421875\n",
      "Epoch: 210, Batch number: 16, Loss: 10813.83984375\n",
      "Epoch: 211, Batch number: 40, Loss: 10536.748046875\n",
      "Epoch: 212, Batch number: 64, Loss: 10846.611328125\n",
      "Epoch: 214, Batch number: 12, Loss: 10903.4853515625\n",
      "Epoch: 215, Batch number: 36, Loss: 10873.7763671875\n",
      "Epoch: 216, Batch number: 60, Loss: 10643.1748046875\n",
      "Epoch: 218, Batch number: 8, Loss: 10888.5966796875\n",
      "Epoch: 219, Batch number: 32, Loss: 10745.849609375\n",
      "Epoch: 220, Batch number: 56, Loss: 10711.3251953125\n",
      "Epoch: 222, Batch number: 4, Loss: 10751.2548828125\n",
      "Epoch: 223, Batch number: 28, Loss: 10790.890625\n",
      "Epoch: 224, Batch number: 52, Loss: 10637.6533203125\n",
      "Epoch: 226, Batch number: 0, Loss: 10621.4677734375\n",
      "Epoch: 227, Batch number: 24, Loss: 10777.67578125\n",
      "Epoch: 228, Batch number: 48, Loss: 10925.7373046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 229, Batch number: 72, Loss: 10742.4189453125\n",
      "Epoch: 231, Batch number: 20, Loss: 10672.2119140625\n",
      "Epoch: 232, Batch number: 44, Loss: 10804.955078125\n",
      "Epoch: 233, Batch number: 68, Loss: 10713.4716796875\n",
      "Epoch: 235, Batch number: 16, Loss: 10622.3447265625\n",
      "Epoch: 236, Batch number: 40, Loss: 10773.947265625\n",
      "Epoch: 237, Batch number: 64, Loss: 11022.5751953125\n",
      "Epoch: 239, Batch number: 12, Loss: 10386.7236328125\n",
      "Epoch: 240, Batch number: 36, Loss: 10563.5947265625\n",
      "Epoch: 241, Batch number: 60, Loss: 10978.1015625\n",
      "Epoch: 243, Batch number: 8, Loss: 10642.7138671875\n",
      "Epoch: 244, Batch number: 32, Loss: 10817.9814453125\n",
      "Epoch: 245, Batch number: 56, Loss: 10489.6083984375\n",
      "Epoch: 247, Batch number: 4, Loss: 10807.1875\n",
      "Epoch: 248, Batch number: 28, Loss: 10436.7685546875\n",
      "Epoch: 249, Batch number: 52, Loss: 10851.2421875\n",
      "Epoch: 251, Batch number: 0, Loss: 10482.29296875\n",
      "Epoch: 252, Batch number: 24, Loss: 10342.8876953125\n",
      "Epoch: 253, Batch number: 48, Loss: 10825.421875\n",
      "Epoch: 254, Batch number: 72, Loss: 10573.9091796875\n",
      "Epoch: 256, Batch number: 20, Loss: 10676.5751953125\n",
      "Epoch: 257, Batch number: 44, Loss: 10788.96484375\n",
      "Epoch: 258, Batch number: 68, Loss: 11045.33203125\n",
      "Epoch: 260, Batch number: 16, Loss: 10695.9609375\n",
      "Epoch: 261, Batch number: 40, Loss: 10794.099609375\n",
      "Epoch: 262, Batch number: 64, Loss: 10630.9150390625\n",
      "Epoch: 264, Batch number: 12, Loss: 10908.8037109375\n",
      "Epoch: 265, Batch number: 36, Loss: 10910.046875\n",
      "Epoch: 266, Batch number: 60, Loss: 10365.4765625\n",
      "Epoch: 268, Batch number: 8, Loss: 10535.716796875\n",
      "Epoch: 269, Batch number: 32, Loss: 10457.1259765625\n",
      "Epoch: 270, Batch number: 56, Loss: 11185.7802734375\n",
      "Epoch: 272, Batch number: 4, Loss: 10343.60546875\n",
      "Epoch: 273, Batch number: 28, Loss: 10701.1279296875\n",
      "Epoch: 274, Batch number: 52, Loss: 10552.0869140625\n",
      "Epoch: 276, Batch number: 0, Loss: 10430.0625\n",
      "Epoch: 277, Batch number: 24, Loss: 10780.2353515625\n",
      "Epoch: 278, Batch number: 48, Loss: 10749.21875\n",
      "Epoch: 279, Batch number: 72, Loss: 10878.65234375\n",
      "Epoch: 281, Batch number: 20, Loss: 10690.9228515625\n",
      "Epoch: 282, Batch number: 44, Loss: 10806.578125\n",
      "Epoch: 283, Batch number: 68, Loss: 10548.70703125\n",
      "Epoch: 285, Batch number: 16, Loss: 10712.287109375\n",
      "Epoch: 286, Batch number: 40, Loss: 10547.6953125\n",
      "Epoch: 287, Batch number: 64, Loss: 10446.732421875\n",
      "Epoch: 289, Batch number: 12, Loss: 10395.4521484375\n",
      "Epoch: 290, Batch number: 36, Loss: 10502.7392578125\n",
      "Epoch: 291, Batch number: 60, Loss: 11112.6796875\n",
      "Epoch: 293, Batch number: 8, Loss: 10676.896484375\n",
      "Epoch: 294, Batch number: 32, Loss: 10973.6865234375\n",
      "Epoch: 295, Batch number: 56, Loss: 10681.09765625\n",
      "Epoch: 297, Batch number: 4, Loss: 10386.0703125\n",
      "Epoch: 298, Batch number: 28, Loss: 10785.224609375\n",
      "Epoch: 299, Batch number: 52, Loss: 10743.083984375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21886.248046875\n",
      "Epoch: 2, Batch number: 24, Loss: 20454.783203125\n",
      "Epoch: 3, Batch number: 48, Loss: 19163.138671875\n",
      "Epoch: 4, Batch number: 72, Loss: 18493.41796875\n",
      "Epoch: 6, Batch number: 20, Loss: 17431.171875\n",
      "Epoch: 7, Batch number: 44, Loss: 17097.61328125\n",
      "Epoch: 8, Batch number: 68, Loss: 16817.814453125\n",
      "Epoch: 10, Batch number: 16, Loss: 15998.2626953125\n",
      "Epoch: 11, Batch number: 40, Loss: 15647.677734375\n",
      "Epoch: 12, Batch number: 64, Loss: 15498.03125\n",
      "Epoch: 14, Batch number: 12, Loss: 14865.2646484375\n",
      "Epoch: 15, Batch number: 36, Loss: 14634.3876953125\n",
      "Epoch: 16, Batch number: 60, Loss: 14173.138671875\n",
      "Epoch: 18, Batch number: 8, Loss: 14129.283203125\n",
      "Epoch: 19, Batch number: 32, Loss: 13942.6953125\n",
      "Epoch: 20, Batch number: 56, Loss: 13631.2578125\n",
      "Epoch: 22, Batch number: 4, Loss: 13567.96484375\n",
      "Epoch: 23, Batch number: 28, Loss: 13536.0517578125\n",
      "Epoch: 24, Batch number: 52, Loss: 13349.9560546875\n",
      "Epoch: 26, Batch number: 0, Loss: 13229.9365234375\n",
      "Epoch: 27, Batch number: 24, Loss: 12750.1181640625\n",
      "Epoch: 28, Batch number: 48, Loss: 13241.7099609375\n",
      "Epoch: 29, Batch number: 72, Loss: 12982.298828125\n",
      "Epoch: 31, Batch number: 20, Loss: 12902.4990234375\n",
      "Epoch: 32, Batch number: 44, Loss: 12580.6298828125\n",
      "Epoch: 33, Batch number: 68, Loss: 12723.48046875\n",
      "Epoch: 35, Batch number: 16, Loss: 12694.9443359375\n",
      "Epoch: 36, Batch number: 40, Loss: 12927.1298828125\n",
      "Epoch: 37, Batch number: 64, Loss: 12393.828125\n",
      "Epoch: 39, Batch number: 12, Loss: 12301.515625\n",
      "Epoch: 40, Batch number: 36, Loss: 12345.029296875\n",
      "Epoch: 41, Batch number: 60, Loss: 12399.306640625\n",
      "Epoch: 43, Batch number: 8, Loss: 12216.1025390625\n",
      "Epoch: 44, Batch number: 32, Loss: 12374.2109375\n",
      "Epoch: 45, Batch number: 56, Loss: 12213.4189453125\n",
      "Epoch: 47, Batch number: 4, Loss: 12116.841796875\n",
      "Epoch: 48, Batch number: 28, Loss: 11818.25390625\n",
      "Epoch: 49, Batch number: 52, Loss: 11956.580078125\n",
      "Epoch: 51, Batch number: 0, Loss: 11853.734375\n",
      "Epoch: 52, Batch number: 24, Loss: 11936.984375\n",
      "Epoch: 53, Batch number: 48, Loss: 11873.2470703125\n",
      "Epoch: 54, Batch number: 72, Loss: 12198.6591796875\n",
      "Epoch: 56, Batch number: 20, Loss: 11940.7314453125\n",
      "Epoch: 57, Batch number: 44, Loss: 12181.1796875\n",
      "Epoch: 58, Batch number: 68, Loss: 12104.98828125\n",
      "Epoch: 60, Batch number: 16, Loss: 11824.40234375\n",
      "Epoch: 61, Batch number: 40, Loss: 11803.6826171875\n",
      "Epoch: 62, Batch number: 64, Loss: 11948.0615234375\n",
      "Epoch: 64, Batch number: 12, Loss: 11471.533203125\n",
      "Epoch: 65, Batch number: 36, Loss: 11660.9794921875\n",
      "Epoch: 66, Batch number: 60, Loss: 11395.35546875\n",
      "Epoch: 68, Batch number: 8, Loss: 11286.2353515625\n",
      "Epoch: 69, Batch number: 32, Loss: 11446.814453125\n",
      "Epoch: 70, Batch number: 56, Loss: 11298.3427734375\n",
      "Epoch: 72, Batch number: 4, Loss: 11505.05859375\n",
      "Epoch: 73, Batch number: 28, Loss: 11697.830078125\n",
      "Epoch: 74, Batch number: 52, Loss: 11755.90625\n",
      "Epoch: 76, Batch number: 0, Loss: 11472.3662109375\n",
      "Epoch: 77, Batch number: 24, Loss: 11456.7333984375\n",
      "Epoch: 78, Batch number: 48, Loss: 11502.884765625\n",
      "Epoch: 79, Batch number: 72, Loss: 11520.634765625\n",
      "Epoch: 81, Batch number: 20, Loss: 11155.0556640625\n",
      "Epoch: 82, Batch number: 44, Loss: 11325.88671875\n",
      "Epoch: 83, Batch number: 68, Loss: 11226.1474609375\n",
      "Epoch: 85, Batch number: 16, Loss: 11269.58984375\n",
      "Epoch: 86, Batch number: 40, Loss: 11434.568359375\n",
      "Epoch: 87, Batch number: 64, Loss: 11058.0927734375\n",
      "Epoch: 89, Batch number: 12, Loss: 11479.87109375\n",
      "Epoch: 90, Batch number: 36, Loss: 11513.720703125\n",
      "Epoch: 91, Batch number: 60, Loss: 11447.279296875\n",
      "Epoch: 93, Batch number: 8, Loss: 11056.1220703125\n",
      "Epoch: 94, Batch number: 32, Loss: 11631.3330078125\n",
      "Epoch: 95, Batch number: 56, Loss: 11118.177734375\n",
      "Epoch: 97, Batch number: 4, Loss: 11143.5146484375\n",
      "Epoch: 98, Batch number: 28, Loss: 11152.81640625\n",
      "Epoch: 99, Batch number: 52, Loss: 11316.4482421875\n",
      "Epoch: 101, Batch number: 0, Loss: 10802.2919921875\n",
      "Epoch: 102, Batch number: 24, Loss: 11027.75390625\n",
      "Epoch: 103, Batch number: 48, Loss: 11205.86328125\n",
      "Epoch: 104, Batch number: 72, Loss: 11173.21875\n",
      "Epoch: 106, Batch number: 20, Loss: 10911.923828125\n",
      "Epoch: 107, Batch number: 44, Loss: 10883.255859375\n",
      "Epoch: 108, Batch number: 68, Loss: 11430.75\n",
      "Epoch: 110, Batch number: 16, Loss: 11047.4990234375\n",
      "Epoch: 111, Batch number: 40, Loss: 11249.1259765625\n",
      "Epoch: 112, Batch number: 64, Loss: 11360.5244140625\n",
      "Epoch: 114, Batch number: 12, Loss: 10876.1201171875\n",
      "Epoch: 115, Batch number: 36, Loss: 10913.861328125\n",
      "Epoch: 116, Batch number: 60, Loss: 10987.046875\n",
      "Epoch: 118, Batch number: 8, Loss: 11222.033203125\n",
      "Epoch: 119, Batch number: 32, Loss: 10418.033203125\n",
      "Epoch: 120, Batch number: 56, Loss: 10586.2607421875\n",
      "Epoch: 122, Batch number: 4, Loss: 10918.90234375\n",
      "Epoch: 123, Batch number: 28, Loss: 10870.912109375\n",
      "Epoch: 124, Batch number: 52, Loss: 11112.5390625\n",
      "Epoch: 126, Batch number: 0, Loss: 11175.5634765625\n",
      "Epoch: 127, Batch number: 24, Loss: 10746.076171875\n",
      "Epoch: 128, Batch number: 48, Loss: 10636.3203125\n",
      "Epoch: 129, Batch number: 72, Loss: 10877.16796875\n",
      "Epoch: 131, Batch number: 20, Loss: 11228.564453125\n",
      "Epoch: 132, Batch number: 44, Loss: 10998.2578125\n",
      "Epoch: 133, Batch number: 68, Loss: 10732.333984375\n",
      "Epoch: 135, Batch number: 16, Loss: 10542.9130859375\n",
      "Epoch: 136, Batch number: 40, Loss: 10942.341796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137, Batch number: 64, Loss: 11250.8662109375\n",
      "Epoch: 139, Batch number: 12, Loss: 10387.9736328125\n",
      "Epoch: 140, Batch number: 36, Loss: 10750.3994140625\n",
      "Epoch: 141, Batch number: 60, Loss: 10828.140625\n",
      "Epoch: 143, Batch number: 8, Loss: 10730.53125\n",
      "Epoch: 144, Batch number: 32, Loss: 10647.5390625\n",
      "Epoch: 145, Batch number: 56, Loss: 10928.205078125\n",
      "Epoch: 147, Batch number: 4, Loss: 11062.0556640625\n",
      "Epoch: 148, Batch number: 28, Loss: 10664.5126953125\n",
      "Epoch: 149, Batch number: 52, Loss: 10920.767578125\n",
      "Epoch: 151, Batch number: 0, Loss: 10916.05859375\n",
      "Epoch: 152, Batch number: 24, Loss: 10647.703125\n",
      "Epoch: 153, Batch number: 48, Loss: 10627.1318359375\n",
      "Epoch: 154, Batch number: 72, Loss: 10430.84765625\n",
      "Epoch: 156, Batch number: 20, Loss: 11144.205078125\n",
      "Epoch: 157, Batch number: 44, Loss: 10748.083984375\n",
      "Epoch: 158, Batch number: 68, Loss: 10809.8447265625\n",
      "Epoch: 160, Batch number: 16, Loss: 10650.2509765625\n",
      "Epoch: 161, Batch number: 40, Loss: 10798.4375\n",
      "Epoch: 162, Batch number: 64, Loss: 10791.4375\n",
      "Epoch: 164, Batch number: 12, Loss: 10619.896484375\n",
      "Epoch: 165, Batch number: 36, Loss: 10547.6787109375\n",
      "Epoch: 166, Batch number: 60, Loss: 10474.86328125\n",
      "Epoch: 168, Batch number: 8, Loss: 10238.5166015625\n",
      "Epoch: 169, Batch number: 32, Loss: 10614.4609375\n",
      "Epoch: 170, Batch number: 56, Loss: 10871.451171875\n",
      "Epoch: 172, Batch number: 4, Loss: 10533.15625\n",
      "Epoch: 173, Batch number: 28, Loss: 10592.31640625\n",
      "Epoch: 174, Batch number: 52, Loss: 10686.8134765625\n",
      "Epoch: 176, Batch number: 0, Loss: 10459.06640625\n",
      "Epoch: 177, Batch number: 24, Loss: 11232.6669921875\n",
      "Epoch: 178, Batch number: 48, Loss: 10482.953125\n",
      "Epoch: 179, Batch number: 72, Loss: 10576.6015625\n",
      "Epoch: 181, Batch number: 20, Loss: 10530.6640625\n",
      "Epoch: 182, Batch number: 44, Loss: 10602.4462890625\n",
      "Epoch: 183, Batch number: 68, Loss: 10928.7265625\n",
      "Epoch: 185, Batch number: 16, Loss: 10470.1943359375\n",
      "Epoch: 186, Batch number: 40, Loss: 10658.841796875\n",
      "Epoch: 187, Batch number: 64, Loss: 10612.001953125\n",
      "Epoch: 189, Batch number: 12, Loss: 10245.1328125\n",
      "Epoch: 190, Batch number: 36, Loss: 10453.3134765625\n",
      "Epoch: 191, Batch number: 60, Loss: 10643.8271484375\n",
      "Epoch: 193, Batch number: 8, Loss: 10583.1884765625\n",
      "Epoch: 194, Batch number: 32, Loss: 10898.3310546875\n",
      "Epoch: 195, Batch number: 56, Loss: 10401.337890625\n",
      "Epoch: 197, Batch number: 4, Loss: 10129.2236328125\n",
      "Epoch: 198, Batch number: 28, Loss: 10513.5419921875\n",
      "Epoch: 199, Batch number: 52, Loss: 10689.580078125\n",
      "Epoch: 201, Batch number: 0, Loss: 10284.658203125\n",
      "Epoch: 202, Batch number: 24, Loss: 10362.8779296875\n",
      "Epoch: 203, Batch number: 48, Loss: 10807.3173828125\n",
      "Epoch: 204, Batch number: 72, Loss: 10845.4189453125\n",
      "Epoch: 206, Batch number: 20, Loss: 10401.3515625\n",
      "Epoch: 207, Batch number: 44, Loss: 10495.9443359375\n",
      "Epoch: 208, Batch number: 68, Loss: 10638.1083984375\n",
      "Epoch: 210, Batch number: 16, Loss: 10352.7021484375\n",
      "Epoch: 211, Batch number: 40, Loss: 10401.4287109375\n",
      "Epoch: 212, Batch number: 64, Loss: 10520.955078125\n",
      "Epoch: 214, Batch number: 12, Loss: 10601.71484375\n",
      "Epoch: 215, Batch number: 36, Loss: 10290.19140625\n",
      "Epoch: 216, Batch number: 60, Loss: 10639.6171875\n",
      "Epoch: 218, Batch number: 8, Loss: 10595.8984375\n",
      "Epoch: 219, Batch number: 32, Loss: 10321.3232421875\n",
      "Epoch: 220, Batch number: 56, Loss: 10232.03515625\n",
      "Epoch: 222, Batch number: 4, Loss: 10769.0849609375\n",
      "Epoch: 223, Batch number: 28, Loss: 10425.5673828125\n",
      "Epoch: 224, Batch number: 52, Loss: 10908.49609375\n",
      "Epoch: 226, Batch number: 0, Loss: 10025.4365234375\n",
      "Epoch: 227, Batch number: 24, Loss: 10625.546875\n",
      "Epoch: 228, Batch number: 48, Loss: 10460.3447265625\n",
      "Epoch: 229, Batch number: 72, Loss: 10447.0654296875\n",
      "Epoch: 231, Batch number: 20, Loss: 10731.861328125\n",
      "Epoch: 232, Batch number: 44, Loss: 10615.9775390625\n",
      "Epoch: 233, Batch number: 68, Loss: 10926.255859375\n",
      "Epoch: 235, Batch number: 16, Loss: 10707.80078125\n",
      "Epoch: 236, Batch number: 40, Loss: 10879.953125\n",
      "Epoch: 237, Batch number: 64, Loss: 10779.228515625\n",
      "Epoch: 239, Batch number: 12, Loss: 10672.1376953125\n",
      "Epoch: 240, Batch number: 36, Loss: 10816.0751953125\n",
      "Epoch: 241, Batch number: 60, Loss: 10683.6025390625\n",
      "Epoch: 243, Batch number: 8, Loss: 10403.2685546875\n",
      "Epoch: 244, Batch number: 32, Loss: 10774.486328125\n",
      "Epoch: 245, Batch number: 56, Loss: 10451.9697265625\n",
      "Epoch: 247, Batch number: 4, Loss: 10335.7255859375\n",
      "Epoch: 248, Batch number: 28, Loss: 10436.2607421875\n",
      "Epoch: 249, Batch number: 52, Loss: 10709.060546875\n",
      "Epoch: 251, Batch number: 0, Loss: 10362.8779296875\n",
      "Epoch: 252, Batch number: 24, Loss: 10504.5673828125\n",
      "Epoch: 253, Batch number: 48, Loss: 10215.994140625\n",
      "Epoch: 254, Batch number: 72, Loss: 10665.5029296875\n",
      "Epoch: 256, Batch number: 20, Loss: 10356.2314453125\n",
      "Epoch: 257, Batch number: 44, Loss: 10093.4970703125\n",
      "Epoch: 258, Batch number: 68, Loss: 10613.009765625\n",
      "Epoch: 260, Batch number: 16, Loss: 10639.4169921875\n",
      "Epoch: 261, Batch number: 40, Loss: 10143.9296875\n",
      "Epoch: 262, Batch number: 64, Loss: 10479.2783203125\n",
      "Epoch: 264, Batch number: 12, Loss: 10202.0654296875\n",
      "Epoch: 265, Batch number: 36, Loss: 10451.8818359375\n",
      "Epoch: 266, Batch number: 60, Loss: 10760.828125\n",
      "Epoch: 268, Batch number: 8, Loss: 10177.2666015625\n",
      "Epoch: 269, Batch number: 32, Loss: 10317.970703125\n",
      "Epoch: 270, Batch number: 56, Loss: 10626.998046875\n",
      "Epoch: 272, Batch number: 4, Loss: 10388.7431640625\n",
      "Epoch: 273, Batch number: 28, Loss: 10470.607421875\n",
      "Epoch: 274, Batch number: 52, Loss: 10339.361328125\n",
      "Epoch: 276, Batch number: 0, Loss: 10299.0595703125\n",
      "Epoch: 277, Batch number: 24, Loss: 10641.8916015625\n",
      "Epoch: 278, Batch number: 48, Loss: 10529.51171875\n",
      "Epoch: 279, Batch number: 72, Loss: 10598.3271484375\n",
      "Epoch: 281, Batch number: 20, Loss: 10518.955078125\n",
      "Epoch: 282, Batch number: 44, Loss: 10236.1220703125\n",
      "Epoch: 283, Batch number: 68, Loss: 10461.8916015625\n",
      "Epoch: 285, Batch number: 16, Loss: 10455.9736328125\n",
      "Epoch: 286, Batch number: 40, Loss: 10822.0087890625\n",
      "Epoch: 287, Batch number: 64, Loss: 10432.5361328125\n",
      "Epoch: 289, Batch number: 12, Loss: 10569.62890625\n",
      "Epoch: 290, Batch number: 36, Loss: 10821.0625\n",
      "Epoch: 291, Batch number: 60, Loss: 10654.3603515625\n",
      "Epoch: 293, Batch number: 8, Loss: 10565.0625\n",
      "Epoch: 294, Batch number: 32, Loss: 10523.548828125\n",
      "Epoch: 295, Batch number: 56, Loss: 10132.1923828125\n",
      "Epoch: 297, Batch number: 4, Loss: 10183.5927734375\n",
      "Epoch: 298, Batch number: 28, Loss: 10443.087890625\n",
      "Epoch: 299, Batch number: 52, Loss: 10441.5751953125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21790.189453125\n",
      "Epoch: 2, Batch number: 24, Loss: 20001.333984375\n",
      "Epoch: 3, Batch number: 48, Loss: 18810.037109375\n",
      "Epoch: 4, Batch number: 72, Loss: 17874.291015625\n",
      "Epoch: 6, Batch number: 20, Loss: 17171.7421875\n",
      "Epoch: 7, Batch number: 44, Loss: 16707.57421875\n",
      "Epoch: 8, Batch number: 68, Loss: 15962.025390625\n",
      "Epoch: 10, Batch number: 16, Loss: 15340.1943359375\n",
      "Epoch: 11, Batch number: 40, Loss: 15180.16796875\n",
      "Epoch: 12, Batch number: 64, Loss: 14534.0537109375\n",
      "Epoch: 14, Batch number: 12, Loss: 14307.724609375\n",
      "Epoch: 15, Batch number: 36, Loss: 14177.18359375\n",
      "Epoch: 16, Batch number: 60, Loss: 13618.669921875\n",
      "Epoch: 18, Batch number: 8, Loss: 13348.9873046875\n",
      "Epoch: 19, Batch number: 32, Loss: 13459.0712890625\n",
      "Epoch: 20, Batch number: 56, Loss: 13393.123046875\n",
      "Epoch: 22, Batch number: 4, Loss: 13133.3056640625\n",
      "Epoch: 23, Batch number: 28, Loss: 12585.3359375\n",
      "Epoch: 24, Batch number: 52, Loss: 12767.9228515625\n",
      "Epoch: 26, Batch number: 0, Loss: 12726.939453125\n",
      "Epoch: 27, Batch number: 24, Loss: 12245.1044921875\n",
      "Epoch: 28, Batch number: 48, Loss: 12404.1669921875\n",
      "Epoch: 29, Batch number: 72, Loss: 12469.9453125\n",
      "Epoch: 31, Batch number: 20, Loss: 12423.1884765625\n",
      "Epoch: 32, Batch number: 44, Loss: 12335.326171875\n",
      "Epoch: 33, Batch number: 68, Loss: 12077.796875\n",
      "Epoch: 35, Batch number: 16, Loss: 12142.95703125\n",
      "Epoch: 36, Batch number: 40, Loss: 11734.6533203125\n",
      "Epoch: 37, Batch number: 64, Loss: 11961.5302734375\n",
      "Epoch: 39, Batch number: 12, Loss: 11859.8671875\n",
      "Epoch: 40, Batch number: 36, Loss: 11977.4091796875\n",
      "Epoch: 41, Batch number: 60, Loss: 12089.509765625\n",
      "Epoch: 43, Batch number: 8, Loss: 11902.7119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Batch number: 32, Loss: 11609.5947265625\n",
      "Epoch: 45, Batch number: 56, Loss: 11778.9228515625\n",
      "Epoch: 47, Batch number: 4, Loss: 11508.7890625\n",
      "Epoch: 48, Batch number: 28, Loss: 11614.8837890625\n",
      "Epoch: 49, Batch number: 52, Loss: 11431.408203125\n",
      "Epoch: 51, Batch number: 0, Loss: 11601.1904296875\n",
      "Epoch: 52, Batch number: 24, Loss: 11506.4736328125\n",
      "Epoch: 53, Batch number: 48, Loss: 11355.53515625\n",
      "Epoch: 54, Batch number: 72, Loss: 11891.5625\n",
      "Epoch: 56, Batch number: 20, Loss: 11635.84375\n",
      "Epoch: 57, Batch number: 44, Loss: 11608.421875\n",
      "Epoch: 58, Batch number: 68, Loss: 11184.7802734375\n",
      "Epoch: 60, Batch number: 16, Loss: 11282.4541015625\n",
      "Epoch: 61, Batch number: 40, Loss: 11322.5283203125\n",
      "Epoch: 62, Batch number: 64, Loss: 11238.7314453125\n",
      "Epoch: 64, Batch number: 12, Loss: 11473.349609375\n",
      "Epoch: 65, Batch number: 36, Loss: 11357.7626953125\n",
      "Epoch: 66, Batch number: 60, Loss: 11481.400390625\n",
      "Epoch: 68, Batch number: 8, Loss: 11039.1259765625\n",
      "Epoch: 69, Batch number: 32, Loss: 11009.34765625\n",
      "Epoch: 70, Batch number: 56, Loss: 11438.537109375\n",
      "Epoch: 72, Batch number: 4, Loss: 11012.634765625\n",
      "Epoch: 73, Batch number: 28, Loss: 10938.205078125\n",
      "Epoch: 74, Batch number: 52, Loss: 11024.3994140625\n",
      "Epoch: 76, Batch number: 0, Loss: 10842.2705078125\n",
      "Epoch: 77, Batch number: 24, Loss: 10884.265625\n",
      "Epoch: 78, Batch number: 48, Loss: 11258.6181640625\n",
      "Epoch: 79, Batch number: 72, Loss: 11303.1982421875\n",
      "Epoch: 81, Batch number: 20, Loss: 11101.7080078125\n",
      "Epoch: 82, Batch number: 44, Loss: 11608.4072265625\n",
      "Epoch: 83, Batch number: 68, Loss: 10656.611328125\n",
      "Epoch: 85, Batch number: 16, Loss: 10981.171875\n",
      "Epoch: 86, Batch number: 40, Loss: 11026.2099609375\n",
      "Epoch: 87, Batch number: 64, Loss: 11217.0107421875\n",
      "Epoch: 89, Batch number: 12, Loss: 11176.6103515625\n",
      "Epoch: 90, Batch number: 36, Loss: 10914.0693359375\n",
      "Epoch: 91, Batch number: 60, Loss: 10936.69921875\n",
      "Epoch: 93, Batch number: 8, Loss: 10663.87109375\n",
      "Epoch: 94, Batch number: 32, Loss: 10742.634765625\n",
      "Epoch: 95, Batch number: 56, Loss: 10915.0927734375\n",
      "Epoch: 97, Batch number: 4, Loss: 10702.59765625\n",
      "Epoch: 98, Batch number: 28, Loss: 10987.27734375\n",
      "Epoch: 99, Batch number: 52, Loss: 10730.1533203125\n",
      "Epoch: 101, Batch number: 0, Loss: 10642.1533203125\n",
      "Epoch: 102, Batch number: 24, Loss: 10809.3486328125\n",
      "Epoch: 103, Batch number: 48, Loss: 10741.5712890625\n",
      "Epoch: 104, Batch number: 72, Loss: 11282.6279296875\n",
      "Epoch: 106, Batch number: 20, Loss: 10441.23828125\n",
      "Epoch: 107, Batch number: 44, Loss: 10934.072265625\n",
      "Epoch: 108, Batch number: 68, Loss: 10489.8935546875\n",
      "Epoch: 110, Batch number: 16, Loss: 10743.73046875\n",
      "Epoch: 111, Batch number: 40, Loss: 10809.244140625\n",
      "Epoch: 112, Batch number: 64, Loss: 10687.3359375\n",
      "Epoch: 114, Batch number: 12, Loss: 10561.833984375\n",
      "Epoch: 115, Batch number: 36, Loss: 10770.2109375\n",
      "Epoch: 116, Batch number: 60, Loss: 10868.966796875\n",
      "Epoch: 118, Batch number: 8, Loss: 10468.2705078125\n",
      "Epoch: 119, Batch number: 32, Loss: 10555.2900390625\n",
      "Epoch: 120, Batch number: 56, Loss: 10650.2255859375\n",
      "Epoch: 122, Batch number: 4, Loss: 10481.2666015625\n",
      "Epoch: 123, Batch number: 28, Loss: 10916.2060546875\n",
      "Epoch: 124, Batch number: 52, Loss: 10751.251953125\n",
      "Epoch: 126, Batch number: 0, Loss: 10650.3935546875\n",
      "Epoch: 127, Batch number: 24, Loss: 10610.7333984375\n",
      "Epoch: 128, Batch number: 48, Loss: 10467.171875\n",
      "Epoch: 129, Batch number: 72, Loss: 10603.0888671875\n",
      "Epoch: 131, Batch number: 20, Loss: 10071.150390625\n",
      "Epoch: 132, Batch number: 44, Loss: 10937.6591796875\n",
      "Epoch: 133, Batch number: 68, Loss: 10814.900390625\n",
      "Epoch: 135, Batch number: 16, Loss: 10696.8837890625\n",
      "Epoch: 136, Batch number: 40, Loss: 10704.376953125\n",
      "Epoch: 137, Batch number: 64, Loss: 10610.728515625\n",
      "Epoch: 139, Batch number: 12, Loss: 10222.3720703125\n",
      "Epoch: 140, Batch number: 36, Loss: 10621.1943359375\n",
      "Epoch: 141, Batch number: 60, Loss: 10454.037109375\n",
      "Epoch: 143, Batch number: 8, Loss: 11034.380859375\n",
      "Epoch: 144, Batch number: 32, Loss: 10815.962890625\n",
      "Epoch: 145, Batch number: 56, Loss: 10635.0400390625\n",
      "Epoch: 147, Batch number: 4, Loss: 10251.65625\n",
      "Epoch: 148, Batch number: 28, Loss: 10468.6015625\n",
      "Epoch: 149, Batch number: 52, Loss: 10532.67578125\n",
      "Epoch: 151, Batch number: 0, Loss: 10571.8291015625\n",
      "Epoch: 152, Batch number: 24, Loss: 10544.1728515625\n",
      "Epoch: 153, Batch number: 48, Loss: 10368.056640625\n",
      "Epoch: 154, Batch number: 72, Loss: 10705.962890625\n",
      "Epoch: 156, Batch number: 20, Loss: 10337.4677734375\n",
      "Epoch: 157, Batch number: 44, Loss: 10425.7578125\n",
      "Epoch: 158, Batch number: 68, Loss: 10733.091796875\n",
      "Epoch: 160, Batch number: 16, Loss: 10823.279296875\n",
      "Epoch: 161, Batch number: 40, Loss: 10214.9814453125\n",
      "Epoch: 162, Batch number: 64, Loss: 10803.4150390625\n",
      "Epoch: 164, Batch number: 12, Loss: 10796.5830078125\n",
      "Epoch: 165, Batch number: 36, Loss: 10621.78515625\n",
      "Epoch: 166, Batch number: 60, Loss: 10753.3916015625\n",
      "Epoch: 168, Batch number: 8, Loss: 10460.0048828125\n",
      "Epoch: 169, Batch number: 32, Loss: 10433.94921875\n",
      "Epoch: 170, Batch number: 56, Loss: 10818.66796875\n",
      "Epoch: 172, Batch number: 4, Loss: 10413.5068359375\n",
      "Epoch: 173, Batch number: 28, Loss: 10611.2666015625\n",
      "Epoch: 174, Batch number: 52, Loss: 10736.76953125\n",
      "Epoch: 176, Batch number: 0, Loss: 10468.92578125\n",
      "Epoch: 177, Batch number: 24, Loss: 10458.201171875\n",
      "Epoch: 178, Batch number: 48, Loss: 10753.642578125\n",
      "Epoch: 179, Batch number: 72, Loss: 10477.369140625\n",
      "Epoch: 181, Batch number: 20, Loss: 10403.1796875\n",
      "Epoch: 182, Batch number: 44, Loss: 10832.9794921875\n",
      "Epoch: 183, Batch number: 68, Loss: 10561.4248046875\n",
      "Epoch: 185, Batch number: 16, Loss: 10574.3056640625\n",
      "Epoch: 186, Batch number: 40, Loss: 10863.9931640625\n",
      "Epoch: 187, Batch number: 64, Loss: 10340.474609375\n",
      "Epoch: 189, Batch number: 12, Loss: 10271.255859375\n",
      "Epoch: 190, Batch number: 36, Loss: 10665.533203125\n",
      "Epoch: 191, Batch number: 60, Loss: 10295.095703125\n",
      "Epoch: 193, Batch number: 8, Loss: 10568.4130859375\n",
      "Epoch: 194, Batch number: 32, Loss: 10531.9072265625\n",
      "Epoch: 195, Batch number: 56, Loss: 10526.259765625\n",
      "Epoch: 197, Batch number: 4, Loss: 10353.7802734375\n",
      "Epoch: 198, Batch number: 28, Loss: 10556.8193359375\n",
      "Epoch: 199, Batch number: 52, Loss: 11005.2138671875\n",
      "Epoch: 201, Batch number: 0, Loss: 10178.0712890625\n",
      "Epoch: 202, Batch number: 24, Loss: 10143.4560546875\n",
      "Epoch: 203, Batch number: 48, Loss: 10665.1220703125\n",
      "Epoch: 204, Batch number: 72, Loss: 10347.7587890625\n",
      "Epoch: 206, Batch number: 20, Loss: 10318.638671875\n",
      "Epoch: 207, Batch number: 44, Loss: 10344.158203125\n",
      "Epoch: 208, Batch number: 68, Loss: 10297.3779296875\n",
      "Epoch: 210, Batch number: 16, Loss: 10644.2958984375\n",
      "Epoch: 211, Batch number: 40, Loss: 10917.646484375\n",
      "Epoch: 212, Batch number: 64, Loss: 10340.6357421875\n",
      "Epoch: 214, Batch number: 12, Loss: 10262.849609375\n",
      "Epoch: 215, Batch number: 36, Loss: 10350.1181640625\n",
      "Epoch: 216, Batch number: 60, Loss: 10102.701171875\n",
      "Epoch: 218, Batch number: 8, Loss: 10489.671875\n",
      "Epoch: 219, Batch number: 32, Loss: 10407.5087890625\n",
      "Epoch: 220, Batch number: 56, Loss: 10274.0771484375\n",
      "Epoch: 222, Batch number: 4, Loss: 10606.0361328125\n",
      "Epoch: 223, Batch number: 28, Loss: 10332.7978515625\n",
      "Epoch: 224, Batch number: 52, Loss: 10432.0166015625\n",
      "Epoch: 226, Batch number: 0, Loss: 10314.4638671875\n",
      "Epoch: 227, Batch number: 24, Loss: 10488.3154296875\n",
      "Epoch: 228, Batch number: 48, Loss: 10627.9130859375\n",
      "Epoch: 229, Batch number: 72, Loss: 10815.7158203125\n",
      "Epoch: 231, Batch number: 20, Loss: 10640.8642578125\n",
      "Epoch: 232, Batch number: 44, Loss: 10533.017578125\n",
      "Epoch: 233, Batch number: 68, Loss: 10280.3271484375\n",
      "Epoch: 235, Batch number: 16, Loss: 10465.234375\n",
      "Epoch: 236, Batch number: 40, Loss: 10834.21875\n",
      "Epoch: 237, Batch number: 64, Loss: 10413.59765625\n",
      "Epoch: 239, Batch number: 12, Loss: 10556.0908203125\n",
      "Epoch: 240, Batch number: 36, Loss: 10422.73828125\n",
      "Epoch: 241, Batch number: 60, Loss: 10474.5146484375\n",
      "Epoch: 243, Batch number: 8, Loss: 10460.6865234375\n",
      "Epoch: 244, Batch number: 32, Loss: 10695.3740234375\n",
      "Epoch: 245, Batch number: 56, Loss: 10563.09765625\n",
      "Epoch: 247, Batch number: 4, Loss: 10738.4794921875\n",
      "Epoch: 248, Batch number: 28, Loss: 10285.6162109375\n",
      "Epoch: 249, Batch number: 52, Loss: 10601.310546875\n",
      "Epoch: 251, Batch number: 0, Loss: 10211.201171875\n",
      "Epoch: 252, Batch number: 24, Loss: 10275.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 253, Batch number: 48, Loss: 10612.76171875\n",
      "Epoch: 254, Batch number: 72, Loss: 10762.8798828125\n",
      "Epoch: 256, Batch number: 20, Loss: 10708.3583984375\n",
      "Epoch: 257, Batch number: 44, Loss: 10855.720703125\n",
      "Epoch: 258, Batch number: 68, Loss: 10625.4775390625\n",
      "Epoch: 260, Batch number: 16, Loss: 10249.2783203125\n",
      "Epoch: 261, Batch number: 40, Loss: 10295.3486328125\n",
      "Epoch: 262, Batch number: 64, Loss: 10496.6396484375\n",
      "Epoch: 264, Batch number: 12, Loss: 10317.2236328125\n",
      "Epoch: 265, Batch number: 36, Loss: 10470.765625\n",
      "Epoch: 266, Batch number: 60, Loss: 10321.064453125\n",
      "Epoch: 268, Batch number: 8, Loss: 10239.1181640625\n",
      "Epoch: 269, Batch number: 32, Loss: 10507.0625\n",
      "Epoch: 270, Batch number: 56, Loss: 10424.455078125\n",
      "Epoch: 272, Batch number: 4, Loss: 10508.064453125\n",
      "Epoch: 273, Batch number: 28, Loss: 10501.9375\n",
      "Epoch: 274, Batch number: 52, Loss: 10704.9755859375\n",
      "Epoch: 276, Batch number: 0, Loss: 10268.794921875\n",
      "Epoch: 277, Batch number: 24, Loss: 10616.419921875\n",
      "Epoch: 278, Batch number: 48, Loss: 10896.146484375\n",
      "Epoch: 279, Batch number: 72, Loss: 10759.1953125\n",
      "Epoch: 281, Batch number: 20, Loss: 10452.689453125\n",
      "Epoch: 282, Batch number: 44, Loss: 10692.3583984375\n",
      "Epoch: 283, Batch number: 68, Loss: 10540.4013671875\n",
      "Epoch: 285, Batch number: 16, Loss: 10199.533203125\n",
      "Epoch: 286, Batch number: 40, Loss: 10379.2294921875\n",
      "Epoch: 287, Batch number: 64, Loss: 10603.419921875\n",
      "Epoch: 289, Batch number: 12, Loss: 10486.6826171875\n",
      "Epoch: 290, Batch number: 36, Loss: 10534.36328125\n",
      "Epoch: 291, Batch number: 60, Loss: 10375.5654296875\n",
      "Epoch: 293, Batch number: 8, Loss: 10135.0693359375\n",
      "Epoch: 294, Batch number: 32, Loss: 10365.3291015625\n",
      "Epoch: 295, Batch number: 56, Loss: 10789.2041015625\n",
      "Epoch: 297, Batch number: 4, Loss: 10219.9326171875\n",
      "Epoch: 298, Batch number: 28, Loss: 10442.029296875\n",
      "Epoch: 299, Batch number: 52, Loss: 10600.908203125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21436.822265625\n",
      "Epoch: 2, Batch number: 24, Loss: 19637.314453125\n",
      "Epoch: 3, Batch number: 48, Loss: 17518.87890625\n",
      "Epoch: 4, Batch number: 72, Loss: 17594.908203125\n",
      "Epoch: 6, Batch number: 20, Loss: 16545.01171875\n",
      "Epoch: 7, Batch number: 44, Loss: 15639.978515625\n",
      "Epoch: 8, Batch number: 68, Loss: 15464.9208984375\n",
      "Epoch: 10, Batch number: 16, Loss: 14484.2861328125\n",
      "Epoch: 11, Batch number: 40, Loss: 14003.087890625\n",
      "Epoch: 12, Batch number: 64, Loss: 14024.4033203125\n",
      "Epoch: 14, Batch number: 12, Loss: 13396.337890625\n",
      "Epoch: 15, Batch number: 36, Loss: 13127.2041015625\n",
      "Epoch: 16, Batch number: 60, Loss: 13284.5654296875\n",
      "Epoch: 18, Batch number: 8, Loss: 12516.791015625\n",
      "Epoch: 19, Batch number: 32, Loss: 12529.9736328125\n",
      "Epoch: 20, Batch number: 56, Loss: 12413.65234375\n",
      "Epoch: 22, Batch number: 4, Loss: 12021.8310546875\n",
      "Epoch: 23, Batch number: 28, Loss: 12281.5830078125\n",
      "Epoch: 24, Batch number: 52, Loss: 12104.4404296875\n",
      "Epoch: 26, Batch number: 0, Loss: 12262.791015625\n",
      "Epoch: 27, Batch number: 24, Loss: 12241.1767578125\n",
      "Epoch: 28, Batch number: 48, Loss: 12111.8984375\n",
      "Epoch: 29, Batch number: 72, Loss: 11773.3837890625\n",
      "Epoch: 31, Batch number: 20, Loss: 11575.2431640625\n",
      "Epoch: 32, Batch number: 44, Loss: 11671.486328125\n",
      "Epoch: 33, Batch number: 68, Loss: 11702.9384765625\n",
      "Epoch: 35, Batch number: 16, Loss: 11371.2529296875\n",
      "Epoch: 36, Batch number: 40, Loss: 11366.5810546875\n",
      "Epoch: 37, Batch number: 64, Loss: 11665.24609375\n",
      "Epoch: 39, Batch number: 12, Loss: 11261.865234375\n",
      "Epoch: 40, Batch number: 36, Loss: 11398.1318359375\n",
      "Epoch: 41, Batch number: 60, Loss: 11512.2490234375\n",
      "Epoch: 43, Batch number: 8, Loss: 11170.0244140625\n",
      "Epoch: 44, Batch number: 32, Loss: 11082.111328125\n",
      "Epoch: 45, Batch number: 56, Loss: 11089.25\n",
      "Epoch: 47, Batch number: 4, Loss: 11046.119140625\n",
      "Epoch: 48, Batch number: 28, Loss: 11090.6455078125\n",
      "Epoch: 49, Batch number: 52, Loss: 11516.3623046875\n",
      "Epoch: 51, Batch number: 0, Loss: 11307.685546875\n",
      "Epoch: 52, Batch number: 24, Loss: 11315.48046875\n",
      "Epoch: 53, Batch number: 48, Loss: 11140.134765625\n",
      "Epoch: 54, Batch number: 72, Loss: 11219.7529296875\n",
      "Epoch: 56, Batch number: 20, Loss: 11006.4541015625\n",
      "Epoch: 57, Batch number: 44, Loss: 11167.2333984375\n",
      "Epoch: 58, Batch number: 68, Loss: 10924.619140625\n",
      "Epoch: 60, Batch number: 16, Loss: 10886.7763671875\n",
      "Epoch: 61, Batch number: 40, Loss: 10918.478515625\n",
      "Epoch: 62, Batch number: 64, Loss: 11053.580078125\n",
      "Epoch: 64, Batch number: 12, Loss: 10740.5224609375\n",
      "Epoch: 65, Batch number: 36, Loss: 10798.9873046875\n",
      "Epoch: 66, Batch number: 60, Loss: 11077.6787109375\n",
      "Epoch: 68, Batch number: 8, Loss: 10928.3408203125\n",
      "Epoch: 69, Batch number: 32, Loss: 10393.2373046875\n",
      "Epoch: 70, Batch number: 56, Loss: 11008.560546875\n",
      "Epoch: 72, Batch number: 4, Loss: 10859.15625\n",
      "Epoch: 73, Batch number: 28, Loss: 10843.865234375\n",
      "Epoch: 74, Batch number: 52, Loss: 11046.859375\n",
      "Epoch: 76, Batch number: 0, Loss: 10562.32421875\n",
      "Epoch: 77, Batch number: 24, Loss: 10852.1767578125\n",
      "Epoch: 78, Batch number: 48, Loss: 11172.8955078125\n",
      "Epoch: 79, Batch number: 72, Loss: 11024.978515625\n",
      "Epoch: 81, Batch number: 20, Loss: 10538.4755859375\n",
      "Epoch: 82, Batch number: 44, Loss: 10908.9423828125\n",
      "Epoch: 83, Batch number: 68, Loss: 11258.6005859375\n",
      "Epoch: 85, Batch number: 16, Loss: 10833.697265625\n",
      "Epoch: 86, Batch number: 40, Loss: 10605.0009765625\n",
      "Epoch: 87, Batch number: 64, Loss: 10545.0029296875\n",
      "Epoch: 89, Batch number: 12, Loss: 10900.7763671875\n",
      "Epoch: 90, Batch number: 36, Loss: 10840.615234375\n",
      "Epoch: 91, Batch number: 60, Loss: 10993.1201171875\n",
      "Epoch: 93, Batch number: 8, Loss: 10564.3037109375\n",
      "Epoch: 94, Batch number: 32, Loss: 10588.73046875\n",
      "Epoch: 95, Batch number: 56, Loss: 10804.076171875\n",
      "Epoch: 97, Batch number: 4, Loss: 10816.125\n",
      "Epoch: 98, Batch number: 28, Loss: 10765.654296875\n",
      "Epoch: 99, Batch number: 52, Loss: 10701.5888671875\n",
      "Epoch: 101, Batch number: 0, Loss: 10517.5615234375\n",
      "Epoch: 102, Batch number: 24, Loss: 10623.9150390625\n",
      "Epoch: 103, Batch number: 48, Loss: 10577.533203125\n",
      "Epoch: 104, Batch number: 72, Loss: 10715.0390625\n",
      "Epoch: 106, Batch number: 20, Loss: 10717.578125\n",
      "Epoch: 107, Batch number: 44, Loss: 10737.591796875\n",
      "Epoch: 108, Batch number: 68, Loss: 10862.2939453125\n",
      "Epoch: 110, Batch number: 16, Loss: 10500.375\n",
      "Epoch: 111, Batch number: 40, Loss: 10233.6318359375\n",
      "Epoch: 112, Batch number: 64, Loss: 10404.40625\n",
      "Epoch: 114, Batch number: 12, Loss: 10401.80859375\n",
      "Epoch: 115, Batch number: 36, Loss: 10727.7900390625\n",
      "Epoch: 116, Batch number: 60, Loss: 10475.1025390625\n",
      "Epoch: 118, Batch number: 8, Loss: 10796.5517578125\n",
      "Epoch: 119, Batch number: 32, Loss: 10945.19140625\n",
      "Epoch: 120, Batch number: 56, Loss: 10534.6142578125\n",
      "Epoch: 122, Batch number: 4, Loss: 10743.37109375\n",
      "Epoch: 123, Batch number: 28, Loss: 10475.8154296875\n",
      "Epoch: 124, Batch number: 52, Loss: 10782.49609375\n",
      "Epoch: 126, Batch number: 0, Loss: 10714.4697265625\n",
      "Epoch: 127, Batch number: 24, Loss: 10552.0302734375\n",
      "Epoch: 128, Batch number: 48, Loss: 10796.63671875\n",
      "Epoch: 129, Batch number: 72, Loss: 10832.8779296875\n",
      "Epoch: 131, Batch number: 20, Loss: 10429.666015625\n",
      "Epoch: 132, Batch number: 44, Loss: 10719.6767578125\n",
      "Epoch: 133, Batch number: 68, Loss: 10809.365234375\n",
      "Epoch: 135, Batch number: 16, Loss: 10354.8330078125\n",
      "Epoch: 136, Batch number: 40, Loss: 10703.833984375\n",
      "Epoch: 137, Batch number: 64, Loss: 10683.9052734375\n",
      "Epoch: 139, Batch number: 12, Loss: 10353.4013671875\n",
      "Epoch: 140, Batch number: 36, Loss: 10436.197265625\n",
      "Epoch: 141, Batch number: 60, Loss: 10556.6484375\n",
      "Epoch: 143, Batch number: 8, Loss: 10610.791015625\n",
      "Epoch: 144, Batch number: 32, Loss: 10624.095703125\n",
      "Epoch: 145, Batch number: 56, Loss: 11097.4599609375\n",
      "Epoch: 147, Batch number: 4, Loss: 10406.87890625\n",
      "Epoch: 148, Batch number: 28, Loss: 10605.2890625\n",
      "Epoch: 149, Batch number: 52, Loss: 10571.177734375\n",
      "Epoch: 151, Batch number: 0, Loss: 10235.373046875\n",
      "Epoch: 152, Batch number: 24, Loss: 10342.353515625\n",
      "Epoch: 153, Batch number: 48, Loss: 10268.9892578125\n",
      "Epoch: 154, Batch number: 72, Loss: 10831.720703125\n",
      "Epoch: 156, Batch number: 20, Loss: 10556.021484375\n",
      "Epoch: 157, Batch number: 44, Loss: 10521.7373046875\n",
      "Epoch: 158, Batch number: 68, Loss: 10480.2705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Batch number: 16, Loss: 10382.34375\n",
      "Epoch: 161, Batch number: 40, Loss: 10821.2314453125\n",
      "Epoch: 162, Batch number: 64, Loss: 10276.1318359375\n",
      "Epoch: 164, Batch number: 12, Loss: 10609.1572265625\n",
      "Epoch: 165, Batch number: 36, Loss: 10598.97265625\n",
      "Epoch: 166, Batch number: 60, Loss: 10664.578125\n",
      "Epoch: 168, Batch number: 8, Loss: 10454.0751953125\n",
      "Epoch: 169, Batch number: 32, Loss: 10586.8017578125\n",
      "Epoch: 170, Batch number: 56, Loss: 10736.8916015625\n",
      "Epoch: 172, Batch number: 4, Loss: 10018.2109375\n",
      "Epoch: 173, Batch number: 28, Loss: 10556.7373046875\n",
      "Epoch: 174, Batch number: 52, Loss: 10582.1357421875\n",
      "Epoch: 176, Batch number: 0, Loss: 10218.6123046875\n",
      "Epoch: 177, Batch number: 24, Loss: 10334.2412109375\n",
      "Epoch: 178, Batch number: 48, Loss: 10320.6962890625\n",
      "Epoch: 179, Batch number: 72, Loss: 10302.521484375\n",
      "Epoch: 181, Batch number: 20, Loss: 10662.283203125\n",
      "Epoch: 182, Batch number: 44, Loss: 10508.140625\n",
      "Epoch: 183, Batch number: 68, Loss: 10527.8232421875\n",
      "Epoch: 185, Batch number: 16, Loss: 10476.5\n",
      "Epoch: 186, Batch number: 40, Loss: 10508.4150390625\n",
      "Epoch: 187, Batch number: 64, Loss: 10425.5751953125\n",
      "Epoch: 189, Batch number: 12, Loss: 10245.669921875\n",
      "Epoch: 190, Batch number: 36, Loss: 10180.15234375\n",
      "Epoch: 191, Batch number: 60, Loss: 10864.5419921875\n",
      "Epoch: 193, Batch number: 8, Loss: 10484.7919921875\n",
      "Epoch: 194, Batch number: 32, Loss: 10492.01953125\n",
      "Epoch: 195, Batch number: 56, Loss: 10867.00390625\n",
      "Epoch: 197, Batch number: 4, Loss: 10426.8671875\n",
      "Epoch: 198, Batch number: 28, Loss: 10459.892578125\n",
      "Epoch: 199, Batch number: 52, Loss: 10233.9423828125\n",
      "Epoch: 201, Batch number: 0, Loss: 10512.029296875\n",
      "Epoch: 202, Batch number: 24, Loss: 10402.6357421875\n",
      "Epoch: 203, Batch number: 48, Loss: 10396.3271484375\n",
      "Epoch: 204, Batch number: 72, Loss: 10441.9248046875\n",
      "Epoch: 206, Batch number: 20, Loss: 10589.7353515625\n",
      "Epoch: 207, Batch number: 44, Loss: 10492.3720703125\n",
      "Epoch: 208, Batch number: 68, Loss: 10582.1279296875\n",
      "Epoch: 210, Batch number: 16, Loss: 10433.3662109375\n",
      "Epoch: 211, Batch number: 40, Loss: 10200.46875\n",
      "Epoch: 212, Batch number: 64, Loss: 10520.0458984375\n",
      "Epoch: 214, Batch number: 12, Loss: 10347.953125\n",
      "Epoch: 215, Batch number: 36, Loss: 10238.6962890625\n",
      "Epoch: 216, Batch number: 60, Loss: 10474.240234375\n",
      "Epoch: 218, Batch number: 8, Loss: 10080.48828125\n",
      "Epoch: 219, Batch number: 32, Loss: 10855.744140625\n",
      "Epoch: 220, Batch number: 56, Loss: 10626.61328125\n",
      "Epoch: 222, Batch number: 4, Loss: 10146.4921875\n",
      "Epoch: 223, Batch number: 28, Loss: 10604.337890625\n",
      "Epoch: 224, Batch number: 52, Loss: 10296.693359375\n",
      "Epoch: 226, Batch number: 0, Loss: 10213.927734375\n",
      "Epoch: 227, Batch number: 24, Loss: 10614.2568359375\n",
      "Epoch: 228, Batch number: 48, Loss: 10742.76171875\n",
      "Epoch: 229, Batch number: 72, Loss: 10845.2421875\n",
      "Epoch: 231, Batch number: 20, Loss: 10321.6806640625\n",
      "Epoch: 232, Batch number: 44, Loss: 10521.5380859375\n",
      "Epoch: 233, Batch number: 68, Loss: 10701.4638671875\n",
      "Epoch: 235, Batch number: 16, Loss: 10306.8408203125\n",
      "Epoch: 236, Batch number: 40, Loss: 10722.923828125\n",
      "Epoch: 237, Batch number: 64, Loss: 10752.7763671875\n",
      "Epoch: 239, Batch number: 12, Loss: 10536.4384765625\n",
      "Epoch: 240, Batch number: 36, Loss: 10291.44921875\n",
      "Epoch: 241, Batch number: 60, Loss: 10233.5576171875\n",
      "Epoch: 243, Batch number: 8, Loss: 10579.193359375\n",
      "Epoch: 244, Batch number: 32, Loss: 10613.0869140625\n",
      "Epoch: 245, Batch number: 56, Loss: 10617.7021484375\n",
      "Epoch: 247, Batch number: 4, Loss: 9977.1171875\n",
      "Epoch: 248, Batch number: 28, Loss: 10295.3359375\n",
      "Epoch: 249, Batch number: 52, Loss: 11001.15625\n",
      "Epoch: 251, Batch number: 0, Loss: 10154.142578125\n",
      "Epoch: 252, Batch number: 24, Loss: 10195.4208984375\n",
      "Epoch: 253, Batch number: 48, Loss: 10722.8583984375\n",
      "Epoch: 254, Batch number: 72, Loss: 10576.80859375\n",
      "Epoch: 256, Batch number: 20, Loss: 10332.70703125\n",
      "Epoch: 257, Batch number: 44, Loss: 10539.4052734375\n",
      "Epoch: 258, Batch number: 68, Loss: 10614.5244140625\n",
      "Epoch: 260, Batch number: 16, Loss: 10494.2080078125\n",
      "Epoch: 261, Batch number: 40, Loss: 10520.841796875\n",
      "Epoch: 262, Batch number: 64, Loss: 10888.908203125\n",
      "Epoch: 264, Batch number: 12, Loss: 10289.078125\n",
      "Epoch: 265, Batch number: 36, Loss: 10524.98046875\n",
      "Epoch: 266, Batch number: 60, Loss: 10701.0087890625\n",
      "Epoch: 268, Batch number: 8, Loss: 10088.4208984375\n",
      "Epoch: 269, Batch number: 32, Loss: 10260.4794921875\n",
      "Epoch: 270, Batch number: 56, Loss: 10254.2734375\n",
      "Epoch: 272, Batch number: 4, Loss: 10629.798828125\n",
      "Epoch: 273, Batch number: 28, Loss: 10601.3818359375\n",
      "Epoch: 274, Batch number: 52, Loss: 10590.9892578125\n",
      "Epoch: 276, Batch number: 0, Loss: 10326.6171875\n",
      "Epoch: 277, Batch number: 24, Loss: 10516.2216796875\n",
      "Epoch: 278, Batch number: 48, Loss: 10443.97265625\n",
      "Epoch: 279, Batch number: 72, Loss: 10339.6494140625\n",
      "Epoch: 281, Batch number: 20, Loss: 10619.4296875\n",
      "Epoch: 282, Batch number: 44, Loss: 10458.0830078125\n",
      "Epoch: 283, Batch number: 68, Loss: 10997.8330078125\n",
      "Epoch: 285, Batch number: 16, Loss: 10254.521484375\n",
      "Epoch: 286, Batch number: 40, Loss: 10684.3916015625\n",
      "Epoch: 287, Batch number: 64, Loss: 10249.9560546875\n",
      "Epoch: 289, Batch number: 12, Loss: 10273.328125\n",
      "Epoch: 290, Batch number: 36, Loss: 10572.9951171875\n",
      "Epoch: 291, Batch number: 60, Loss: 10314.4921875\n",
      "Epoch: 293, Batch number: 8, Loss: 10323.349609375\n",
      "Epoch: 294, Batch number: 32, Loss: 10309.6064453125\n",
      "Epoch: 295, Batch number: 56, Loss: 10429.306640625\n",
      "Epoch: 297, Batch number: 4, Loss: 10041.29296875\n",
      "Epoch: 298, Batch number: 28, Loss: 10391.9580078125\n",
      "Epoch: 299, Batch number: 52, Loss: 10744.6826171875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21584.052734375\n",
      "Epoch: 2, Batch number: 24, Loss: 19035.28125\n",
      "Epoch: 3, Batch number: 48, Loss: 17603.705078125\n",
      "Epoch: 4, Batch number: 72, Loss: 16751.173828125\n",
      "Epoch: 6, Batch number: 20, Loss: 15888.7548828125\n",
      "Epoch: 7, Batch number: 44, Loss: 14966.6328125\n",
      "Epoch: 8, Batch number: 68, Loss: 14584.2294921875\n",
      "Epoch: 10, Batch number: 16, Loss: 13535.67578125\n",
      "Epoch: 11, Batch number: 40, Loss: 13587.328125\n",
      "Epoch: 12, Batch number: 64, Loss: 13277.162109375\n",
      "Epoch: 14, Batch number: 12, Loss: 12381.6748046875\n",
      "Epoch: 15, Batch number: 36, Loss: 12775.6865234375\n",
      "Epoch: 16, Batch number: 60, Loss: 12326.060546875\n",
      "Epoch: 18, Batch number: 8, Loss: 11890.2578125\n",
      "Epoch: 19, Batch number: 32, Loss: 12249.0048828125\n",
      "Epoch: 20, Batch number: 56, Loss: 11909.470703125\n",
      "Epoch: 22, Batch number: 4, Loss: 11778.091796875\n",
      "Epoch: 23, Batch number: 28, Loss: 11892.4501953125\n",
      "Epoch: 24, Batch number: 52, Loss: 11794.1630859375\n",
      "Epoch: 26, Batch number: 0, Loss: 11346.431640625\n",
      "Epoch: 27, Batch number: 24, Loss: 11834.505859375\n",
      "Epoch: 28, Batch number: 48, Loss: 11618.8701171875\n",
      "Epoch: 29, Batch number: 72, Loss: 11624.947265625\n",
      "Epoch: 31, Batch number: 20, Loss: 11105.1259765625\n",
      "Epoch: 32, Batch number: 44, Loss: 11287.234375\n",
      "Epoch: 33, Batch number: 68, Loss: 11517.1689453125\n",
      "Epoch: 35, Batch number: 16, Loss: 11021.76171875\n",
      "Epoch: 36, Batch number: 40, Loss: 11557.994140625\n",
      "Epoch: 37, Batch number: 64, Loss: 11370.8330078125\n",
      "Epoch: 39, Batch number: 12, Loss: 11184.966796875\n",
      "Epoch: 40, Batch number: 36, Loss: 10960.744140625\n",
      "Epoch: 41, Batch number: 60, Loss: 10711.943359375\n",
      "Epoch: 43, Batch number: 8, Loss: 11330.984375\n",
      "Epoch: 44, Batch number: 32, Loss: 11205.40234375\n",
      "Epoch: 45, Batch number: 56, Loss: 10837.9169921875\n",
      "Epoch: 47, Batch number: 4, Loss: 10549.7861328125\n",
      "Epoch: 48, Batch number: 28, Loss: 10951.126953125\n",
      "Epoch: 49, Batch number: 52, Loss: 11090.015625\n",
      "Epoch: 51, Batch number: 0, Loss: 10912.54296875\n",
      "Epoch: 52, Batch number: 24, Loss: 11258.015625\n",
      "Epoch: 53, Batch number: 48, Loss: 10883.857421875\n",
      "Epoch: 54, Batch number: 72, Loss: 10909.4755859375\n",
      "Epoch: 56, Batch number: 20, Loss: 10925.2763671875\n",
      "Epoch: 57, Batch number: 44, Loss: 10903.251953125\n",
      "Epoch: 58, Batch number: 68, Loss: 11306.052734375\n",
      "Epoch: 60, Batch number: 16, Loss: 10973.1640625\n",
      "Epoch: 61, Batch number: 40, Loss: 10781.2724609375\n",
      "Epoch: 62, Batch number: 64, Loss: 11104.9873046875\n",
      "Epoch: 64, Batch number: 12, Loss: 10628.99609375\n",
      "Epoch: 65, Batch number: 36, Loss: 11185.89453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Batch number: 60, Loss: 10890.7919921875\n",
      "Epoch: 68, Batch number: 8, Loss: 10402.3271484375\n",
      "Epoch: 69, Batch number: 32, Loss: 10561.6650390625\n",
      "Epoch: 70, Batch number: 56, Loss: 10653.2158203125\n",
      "Epoch: 72, Batch number: 4, Loss: 10394.9287109375\n",
      "Epoch: 73, Batch number: 28, Loss: 10761.4375\n",
      "Epoch: 74, Batch number: 52, Loss: 10902.21875\n",
      "Epoch: 76, Batch number: 0, Loss: 10589.751953125\n",
      "Epoch: 77, Batch number: 24, Loss: 10310.82421875\n",
      "Epoch: 78, Batch number: 48, Loss: 10637.6923828125\n",
      "Epoch: 79, Batch number: 72, Loss: 11062.0927734375\n",
      "Epoch: 81, Batch number: 20, Loss: 10678.5703125\n",
      "Epoch: 82, Batch number: 44, Loss: 10621.7451171875\n",
      "Epoch: 83, Batch number: 68, Loss: 11310.8447265625\n",
      "Epoch: 85, Batch number: 16, Loss: 10409.6513671875\n",
      "Epoch: 86, Batch number: 40, Loss: 10403.0400390625\n",
      "Epoch: 87, Batch number: 64, Loss: 10611.21484375\n",
      "Epoch: 89, Batch number: 12, Loss: 10127.8017578125\n",
      "Epoch: 90, Batch number: 36, Loss: 10566.6865234375\n",
      "Epoch: 91, Batch number: 60, Loss: 10719.93359375\n",
      "Epoch: 93, Batch number: 8, Loss: 10420.6748046875\n",
      "Epoch: 94, Batch number: 32, Loss: 10543.5791015625\n",
      "Epoch: 95, Batch number: 56, Loss: 10994.0517578125\n",
      "Epoch: 97, Batch number: 4, Loss: 10402.310546875\n",
      "Epoch: 98, Batch number: 28, Loss: 10667.8466796875\n",
      "Epoch: 99, Batch number: 52, Loss: 10957.7783203125\n",
      "Epoch: 101, Batch number: 0, Loss: 10732.1728515625\n",
      "Epoch: 102, Batch number: 24, Loss: 10505.978515625\n",
      "Epoch: 103, Batch number: 48, Loss: 10847.435546875\n",
      "Epoch: 104, Batch number: 72, Loss: 10842.9970703125\n",
      "Epoch: 106, Batch number: 20, Loss: 10465.31640625\n",
      "Epoch: 107, Batch number: 44, Loss: 10587.1064453125\n",
      "Epoch: 108, Batch number: 68, Loss: 10616.2890625\n",
      "Epoch: 110, Batch number: 16, Loss: 10639.595703125\n",
      "Epoch: 111, Batch number: 40, Loss: 10413.83984375\n",
      "Epoch: 112, Batch number: 64, Loss: 10376.544921875\n",
      "Epoch: 114, Batch number: 12, Loss: 10417.0791015625\n",
      "Epoch: 115, Batch number: 36, Loss: 10688.5263671875\n",
      "Epoch: 116, Batch number: 60, Loss: 10540.3583984375\n",
      "Epoch: 118, Batch number: 8, Loss: 10572.2783203125\n",
      "Epoch: 119, Batch number: 32, Loss: 10611.99609375\n",
      "Epoch: 120, Batch number: 56, Loss: 11181.9345703125\n",
      "Epoch: 122, Batch number: 4, Loss: 10549.1171875\n",
      "Epoch: 123, Batch number: 28, Loss: 10317.599609375\n",
      "Epoch: 124, Batch number: 52, Loss: 10947.2470703125\n",
      "Epoch: 126, Batch number: 0, Loss: 10716.5498046875\n",
      "Epoch: 127, Batch number: 24, Loss: 10658.794921875\n",
      "Epoch: 128, Batch number: 48, Loss: 10373.3369140625\n",
      "Epoch: 129, Batch number: 72, Loss: 10590.7978515625\n",
      "Epoch: 131, Batch number: 20, Loss: 10440.9150390625\n",
      "Epoch: 132, Batch number: 44, Loss: 10059.3876953125\n",
      "Epoch: 133, Batch number: 68, Loss: 10740.240234375\n",
      "Epoch: 135, Batch number: 16, Loss: 10595.3798828125\n",
      "Epoch: 136, Batch number: 40, Loss: 10496.4697265625\n",
      "Epoch: 137, Batch number: 64, Loss: 10746.3134765625\n",
      "Epoch: 139, Batch number: 12, Loss: 10400.369140625\n",
      "Epoch: 140, Batch number: 36, Loss: 10983.376953125\n",
      "Epoch: 141, Batch number: 60, Loss: 10452.25\n",
      "Epoch: 143, Batch number: 8, Loss: 10248.2998046875\n",
      "Epoch: 144, Batch number: 32, Loss: 10430.3046875\n",
      "Epoch: 145, Batch number: 56, Loss: 10750.41796875\n",
      "Epoch: 147, Batch number: 4, Loss: 10280.2734375\n",
      "Epoch: 148, Batch number: 28, Loss: 10477.9765625\n",
      "Epoch: 149, Batch number: 52, Loss: 10625.6201171875\n",
      "Epoch: 151, Batch number: 0, Loss: 10069.5693359375\n",
      "Epoch: 152, Batch number: 24, Loss: 10433.1904296875\n",
      "Epoch: 153, Batch number: 48, Loss: 10298.373046875\n",
      "Epoch: 154, Batch number: 72, Loss: 10471.8466796875\n",
      "Epoch: 156, Batch number: 20, Loss: 10387.7080078125\n",
      "Epoch: 157, Batch number: 44, Loss: 10556.8173828125\n",
      "Epoch: 158, Batch number: 68, Loss: 10771.6123046875\n",
      "Epoch: 160, Batch number: 16, Loss: 10343.74609375\n",
      "Epoch: 161, Batch number: 40, Loss: 10646.3203125\n",
      "Epoch: 162, Batch number: 64, Loss: 10610.4541015625\n",
      "Epoch: 164, Batch number: 12, Loss: 10138.546875\n",
      "Epoch: 165, Batch number: 36, Loss: 10399.708984375\n",
      "Epoch: 166, Batch number: 60, Loss: 10444.07421875\n",
      "Epoch: 168, Batch number: 8, Loss: 10687.466796875\n",
      "Epoch: 169, Batch number: 32, Loss: 10629.3662109375\n",
      "Epoch: 170, Batch number: 56, Loss: 10719.908203125\n",
      "Epoch: 172, Batch number: 4, Loss: 10509.69140625\n",
      "Epoch: 173, Batch number: 28, Loss: 10273.3046875\n",
      "Epoch: 174, Batch number: 52, Loss: 10650.5498046875\n",
      "Epoch: 176, Batch number: 0, Loss: 10628.619140625\n",
      "Epoch: 177, Batch number: 24, Loss: 10308.875\n",
      "Epoch: 178, Batch number: 48, Loss: 10338.9013671875\n",
      "Epoch: 179, Batch number: 72, Loss: 10851.189453125\n",
      "Epoch: 181, Batch number: 20, Loss: 10462.255859375\n",
      "Epoch: 182, Batch number: 44, Loss: 10565.02734375\n",
      "Epoch: 183, Batch number: 68, Loss: 10694.0126953125\n",
      "Epoch: 185, Batch number: 16, Loss: 10360.4111328125\n",
      "Epoch: 186, Batch number: 40, Loss: 10537.9052734375\n",
      "Epoch: 187, Batch number: 64, Loss: 10772.06640625\n",
      "Epoch: 189, Batch number: 12, Loss: 10104.14453125\n",
      "Epoch: 190, Batch number: 36, Loss: 10532.2041015625\n",
      "Epoch: 191, Batch number: 60, Loss: 10576.4150390625\n",
      "Epoch: 193, Batch number: 8, Loss: 10519.1240234375\n",
      "Epoch: 194, Batch number: 32, Loss: 10480.3251953125\n",
      "Epoch: 195, Batch number: 56, Loss: 10481.2392578125\n",
      "Epoch: 197, Batch number: 4, Loss: 10216.1591796875\n",
      "Epoch: 198, Batch number: 28, Loss: 10677.498046875\n",
      "Epoch: 199, Batch number: 52, Loss: 11106.8173828125\n",
      "Epoch: 201, Batch number: 0, Loss: 10775.4375\n",
      "Epoch: 202, Batch number: 24, Loss: 10709.392578125\n",
      "Epoch: 203, Batch number: 48, Loss: 10775.064453125\n",
      "Epoch: 204, Batch number: 72, Loss: 10732.4365234375\n",
      "Epoch: 206, Batch number: 20, Loss: 10573.72265625\n",
      "Epoch: 207, Batch number: 44, Loss: 10494.552734375\n",
      "Epoch: 208, Batch number: 68, Loss: 11084.9013671875\n",
      "Epoch: 210, Batch number: 16, Loss: 10292.732421875\n",
      "Epoch: 211, Batch number: 40, Loss: 10479.6982421875\n",
      "Epoch: 212, Batch number: 64, Loss: 10467.7841796875\n",
      "Epoch: 214, Batch number: 12, Loss: 10583.1103515625\n",
      "Epoch: 215, Batch number: 36, Loss: 10660.759765625\n",
      "Epoch: 216, Batch number: 60, Loss: 10428.3681640625\n",
      "Epoch: 218, Batch number: 8, Loss: 10459.7783203125\n",
      "Epoch: 219, Batch number: 32, Loss: 10332.8056640625\n",
      "Epoch: 220, Batch number: 56, Loss: 10319.29296875\n",
      "Epoch: 222, Batch number: 4, Loss: 10642.66796875\n",
      "Epoch: 223, Batch number: 28, Loss: 10489.78515625\n",
      "Epoch: 224, Batch number: 52, Loss: 10609.98046875\n",
      "Epoch: 226, Batch number: 0, Loss: 10202.7255859375\n",
      "Epoch: 227, Batch number: 24, Loss: 10486.3330078125\n",
      "Epoch: 228, Batch number: 48, Loss: 10123.31640625\n",
      "Epoch: 229, Batch number: 72, Loss: 10504.06640625\n",
      "Epoch: 231, Batch number: 20, Loss: 10229.14453125\n",
      "Epoch: 232, Batch number: 44, Loss: 10358.8466796875\n",
      "Epoch: 233, Batch number: 68, Loss: 10393.4404296875\n",
      "Epoch: 235, Batch number: 16, Loss: 10241.6220703125\n",
      "Epoch: 236, Batch number: 40, Loss: 11113.86328125\n",
      "Epoch: 237, Batch number: 64, Loss: 10590.2041015625\n",
      "Epoch: 239, Batch number: 12, Loss: 10713.8291015625\n",
      "Epoch: 240, Batch number: 36, Loss: 10724.9248046875\n",
      "Epoch: 241, Batch number: 60, Loss: 10330.8935546875\n",
      "Epoch: 243, Batch number: 8, Loss: 10647.1787109375\n",
      "Epoch: 244, Batch number: 32, Loss: 10163.9404296875\n",
      "Epoch: 245, Batch number: 56, Loss: 10869.912109375\n",
      "Epoch: 247, Batch number: 4, Loss: 10956.6484375\n",
      "Epoch: 248, Batch number: 28, Loss: 10517.0419921875\n",
      "Epoch: 249, Batch number: 52, Loss: 10844.103515625\n",
      "Epoch: 251, Batch number: 0, Loss: 10534.736328125\n",
      "Epoch: 252, Batch number: 24, Loss: 10228.6865234375\n",
      "Epoch: 253, Batch number: 48, Loss: 10218.6806640625\n",
      "Epoch: 254, Batch number: 72, Loss: 10722.0107421875\n",
      "Epoch: 256, Batch number: 20, Loss: 10598.384765625\n",
      "Epoch: 257, Batch number: 44, Loss: 10655.1689453125\n",
      "Epoch: 258, Batch number: 68, Loss: 10686.880859375\n",
      "Epoch: 260, Batch number: 16, Loss: 10601.890625\n",
      "Epoch: 261, Batch number: 40, Loss: 10365.4599609375\n",
      "Epoch: 262, Batch number: 64, Loss: 10622.3671875\n",
      "Epoch: 264, Batch number: 12, Loss: 9937.5859375\n",
      "Epoch: 265, Batch number: 36, Loss: 10785.7890625\n",
      "Epoch: 266, Batch number: 60, Loss: 10887.3857421875\n",
      "Epoch: 268, Batch number: 8, Loss: 10317.5107421875\n",
      "Epoch: 269, Batch number: 32, Loss: 10517.556640625\n",
      "Epoch: 270, Batch number: 56, Loss: 10456.4462890625\n",
      "Epoch: 272, Batch number: 4, Loss: 10440.759765625\n",
      "Epoch: 273, Batch number: 28, Loss: 10518.4208984375\n",
      "Epoch: 274, Batch number: 52, Loss: 10712.8623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 276, Batch number: 0, Loss: 10649.076171875\n",
      "Epoch: 277, Batch number: 24, Loss: 10537.8994140625\n",
      "Epoch: 278, Batch number: 48, Loss: 10498.4365234375\n",
      "Epoch: 279, Batch number: 72, Loss: 10249.0400390625\n",
      "Epoch: 281, Batch number: 20, Loss: 10538.8447265625\n",
      "Epoch: 282, Batch number: 44, Loss: 10841.5556640625\n",
      "Epoch: 283, Batch number: 68, Loss: 10788.2919921875\n",
      "Epoch: 285, Batch number: 16, Loss: 10343.982421875\n",
      "Epoch: 286, Batch number: 40, Loss: 10969.4169921875\n",
      "Epoch: 287, Batch number: 64, Loss: 10391.2236328125\n",
      "Epoch: 289, Batch number: 12, Loss: 10200.966796875\n",
      "Epoch: 290, Batch number: 36, Loss: 10595.6201171875\n",
      "Epoch: 291, Batch number: 60, Loss: 10836.64453125\n",
      "Epoch: 293, Batch number: 8, Loss: 10571.10546875\n",
      "Epoch: 294, Batch number: 32, Loss: 10804.58203125\n",
      "Epoch: 295, Batch number: 56, Loss: 10434.880859375\n",
      "Epoch: 297, Batch number: 4, Loss: 10290.1240234375\n",
      "Epoch: 298, Batch number: 28, Loss: 10682.587890625\n",
      "Epoch: 299, Batch number: 52, Loss: 10516.5595703125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 27365.255859375\n",
      "Epoch: 2, Batch number: 24, Loss: 26302.125\n",
      "Epoch: 3, Batch number: 48, Loss: 25870.802734375\n",
      "Epoch: 4, Batch number: 72, Loss: 24767.5546875\n",
      "Epoch: 6, Batch number: 20, Loss: 23483.611328125\n",
      "Epoch: 7, Batch number: 44, Loss: 23267.1875\n",
      "Epoch: 8, Batch number: 68, Loss: 22133.5390625\n",
      "Epoch: 10, Batch number: 16, Loss: 21979.7265625\n",
      "Epoch: 11, Batch number: 40, Loss: 21753.79296875\n",
      "Epoch: 12, Batch number: 64, Loss: 21543.0390625\n",
      "Epoch: 14, Batch number: 12, Loss: 20624.1484375\n",
      "Epoch: 15, Batch number: 36, Loss: 20603.509765625\n",
      "Epoch: 16, Batch number: 60, Loss: 20039.640625\n",
      "Epoch: 18, Batch number: 8, Loss: 20675.333984375\n",
      "Epoch: 19, Batch number: 32, Loss: 19975.9609375\n",
      "Epoch: 20, Batch number: 56, Loss: 19627.40625\n",
      "Epoch: 22, Batch number: 4, Loss: 19168.224609375\n",
      "Epoch: 23, Batch number: 28, Loss: 19722.171875\n",
      "Epoch: 24, Batch number: 52, Loss: 19411.818359375\n",
      "Epoch: 26, Batch number: 0, Loss: 19237.30859375\n",
      "Epoch: 27, Batch number: 24, Loss: 19146.71875\n",
      "Epoch: 28, Batch number: 48, Loss: 18544.15625\n",
      "Epoch: 29, Batch number: 72, Loss: 18763.8359375\n",
      "Epoch: 31, Batch number: 20, Loss: 18943.5859375\n",
      "Epoch: 32, Batch number: 44, Loss: 18527.70703125\n",
      "Epoch: 33, Batch number: 68, Loss: 18517.490234375\n",
      "Epoch: 35, Batch number: 16, Loss: 18928.11328125\n",
      "Epoch: 36, Batch number: 40, Loss: 18295.154296875\n",
      "Epoch: 37, Batch number: 64, Loss: 18207.591796875\n",
      "Epoch: 39, Batch number: 12, Loss: 18280.095703125\n",
      "Epoch: 40, Batch number: 36, Loss: 18531.078125\n",
      "Epoch: 41, Batch number: 60, Loss: 18682.62109375\n",
      "Epoch: 43, Batch number: 8, Loss: 18249.587890625\n",
      "Epoch: 44, Batch number: 32, Loss: 17810.24609375\n",
      "Epoch: 45, Batch number: 56, Loss: 18236.81640625\n",
      "Epoch: 47, Batch number: 4, Loss: 17815.55078125\n",
      "Epoch: 48, Batch number: 28, Loss: 17703.259765625\n",
      "Epoch: 49, Batch number: 52, Loss: 17756.396484375\n",
      "Epoch: 51, Batch number: 0, Loss: 17591.388671875\n",
      "Epoch: 52, Batch number: 24, Loss: 17661.990234375\n",
      "Epoch: 53, Batch number: 48, Loss: 17435.4140625\n",
      "Epoch: 54, Batch number: 72, Loss: 17702.81640625\n",
      "Epoch: 56, Batch number: 20, Loss: 17543.6875\n",
      "Epoch: 57, Batch number: 44, Loss: 18144.19921875\n",
      "Epoch: 58, Batch number: 68, Loss: 17480.0859375\n",
      "Epoch: 60, Batch number: 16, Loss: 17934.28125\n",
      "Epoch: 61, Batch number: 40, Loss: 17282.177734375\n",
      "Epoch: 62, Batch number: 64, Loss: 17292.0234375\n",
      "Epoch: 64, Batch number: 12, Loss: 17250.66796875\n",
      "Epoch: 65, Batch number: 36, Loss: 17198.6953125\n",
      "Epoch: 66, Batch number: 60, Loss: 16977.9296875\n",
      "Epoch: 68, Batch number: 8, Loss: 16933.75\n",
      "Epoch: 69, Batch number: 32, Loss: 17271.771484375\n",
      "Epoch: 70, Batch number: 56, Loss: 16905.9453125\n",
      "Epoch: 72, Batch number: 4, Loss: 17028.296875\n",
      "Epoch: 73, Batch number: 28, Loss: 17199.2265625\n",
      "Epoch: 74, Batch number: 52, Loss: 17284.853515625\n",
      "Epoch: 76, Batch number: 0, Loss: 17348.455078125\n",
      "Epoch: 77, Batch number: 24, Loss: 16943.474609375\n",
      "Epoch: 78, Batch number: 48, Loss: 16993.955078125\n",
      "Epoch: 79, Batch number: 72, Loss: 16914.474609375\n",
      "Epoch: 81, Batch number: 20, Loss: 17074.513671875\n",
      "Epoch: 82, Batch number: 44, Loss: 17067.87109375\n",
      "Epoch: 83, Batch number: 68, Loss: 16627.458984375\n",
      "Epoch: 85, Batch number: 16, Loss: 17063.87109375\n",
      "Epoch: 86, Batch number: 40, Loss: 16632.310546875\n",
      "Epoch: 87, Batch number: 64, Loss: 16891.193359375\n",
      "Epoch: 89, Batch number: 12, Loss: 16826.00390625\n",
      "Epoch: 90, Batch number: 36, Loss: 16541.19140625\n",
      "Epoch: 91, Batch number: 60, Loss: 16847.12890625\n",
      "Epoch: 93, Batch number: 8, Loss: 16479.3828125\n",
      "Epoch: 94, Batch number: 32, Loss: 16753.859375\n",
      "Epoch: 95, Batch number: 56, Loss: 17258.32421875\n",
      "Epoch: 97, Batch number: 4, Loss: 16216.3681640625\n",
      "Epoch: 98, Batch number: 28, Loss: 16792.34375\n",
      "Epoch: 99, Batch number: 52, Loss: 16425.564453125\n",
      "Epoch: 101, Batch number: 0, Loss: 16762.99609375\n",
      "Epoch: 102, Batch number: 24, Loss: 16701.044921875\n",
      "Epoch: 103, Batch number: 48, Loss: 16789.765625\n",
      "Epoch: 104, Batch number: 72, Loss: 16564.1171875\n",
      "Epoch: 106, Batch number: 20, Loss: 16612.921875\n",
      "Epoch: 107, Batch number: 44, Loss: 16222.119140625\n",
      "Epoch: 108, Batch number: 68, Loss: 16559.759765625\n",
      "Epoch: 110, Batch number: 16, Loss: 16344.4970703125\n",
      "Epoch: 111, Batch number: 40, Loss: 16339.0869140625\n",
      "Epoch: 112, Batch number: 64, Loss: 16410.365234375\n",
      "Epoch: 114, Batch number: 12, Loss: 16359.130859375\n",
      "Epoch: 115, Batch number: 36, Loss: 16312.5390625\n",
      "Epoch: 116, Batch number: 60, Loss: 16246.0771484375\n",
      "Epoch: 118, Batch number: 8, Loss: 16543.75\n",
      "Epoch: 119, Batch number: 32, Loss: 16583.521484375\n",
      "Epoch: 120, Batch number: 56, Loss: 15935.6083984375\n",
      "Epoch: 122, Batch number: 4, Loss: 15980.7275390625\n",
      "Epoch: 123, Batch number: 28, Loss: 16317.6630859375\n",
      "Epoch: 124, Batch number: 52, Loss: 16122.634765625\n",
      "Epoch: 126, Batch number: 0, Loss: 15797.533203125\n",
      "Epoch: 127, Batch number: 24, Loss: 16250.1513671875\n",
      "Epoch: 128, Batch number: 48, Loss: 16245.4208984375\n",
      "Epoch: 129, Batch number: 72, Loss: 15988.873046875\n",
      "Epoch: 131, Batch number: 20, Loss: 15945.0703125\n",
      "Epoch: 132, Batch number: 44, Loss: 16074.974609375\n",
      "Epoch: 133, Batch number: 68, Loss: 16269.4609375\n",
      "Epoch: 135, Batch number: 16, Loss: 16080.4638671875\n",
      "Epoch: 136, Batch number: 40, Loss: 16107.9482421875\n",
      "Epoch: 137, Batch number: 64, Loss: 15757.7900390625\n",
      "Epoch: 139, Batch number: 12, Loss: 15773.7529296875\n",
      "Epoch: 140, Batch number: 36, Loss: 16061.5166015625\n",
      "Epoch: 141, Batch number: 60, Loss: 15791.8681640625\n",
      "Epoch: 143, Batch number: 8, Loss: 16006.9912109375\n",
      "Epoch: 144, Batch number: 32, Loss: 15769.4619140625\n",
      "Epoch: 145, Batch number: 56, Loss: 15714.2236328125\n",
      "Epoch: 147, Batch number: 4, Loss: 15797.955078125\n",
      "Epoch: 148, Batch number: 28, Loss: 15841.4052734375\n",
      "Epoch: 149, Batch number: 52, Loss: 15608.8447265625\n",
      "Epoch: 151, Batch number: 0, Loss: 16021.767578125\n",
      "Epoch: 152, Batch number: 24, Loss: 15582.6767578125\n",
      "Epoch: 153, Batch number: 48, Loss: 15771.5537109375\n",
      "Epoch: 154, Batch number: 72, Loss: 15700.6953125\n",
      "Epoch: 156, Batch number: 20, Loss: 16003.2646484375\n",
      "Epoch: 157, Batch number: 44, Loss: 15780.9853515625\n",
      "Epoch: 158, Batch number: 68, Loss: 15476.3984375\n",
      "Epoch: 160, Batch number: 16, Loss: 15525.4609375\n",
      "Epoch: 161, Batch number: 40, Loss: 15940.9892578125\n",
      "Epoch: 162, Batch number: 64, Loss: 15641.1337890625\n",
      "Epoch: 164, Batch number: 12, Loss: 15609.794921875\n",
      "Epoch: 165, Batch number: 36, Loss: 15416.5478515625\n",
      "Epoch: 166, Batch number: 60, Loss: 15471.94140625\n",
      "Epoch: 168, Batch number: 8, Loss: 15800.0693359375\n",
      "Epoch: 169, Batch number: 32, Loss: 15831.69921875\n",
      "Epoch: 170, Batch number: 56, Loss: 15575.740234375\n",
      "Epoch: 172, Batch number: 4, Loss: 15641.453125\n",
      "Epoch: 173, Batch number: 28, Loss: 15435.345703125\n",
      "Epoch: 174, Batch number: 52, Loss: 15462.9072265625\n",
      "Epoch: 176, Batch number: 0, Loss: 15719.02734375\n",
      "Epoch: 177, Batch number: 24, Loss: 15515.173828125\n",
      "Epoch: 178, Batch number: 48, Loss: 15504.2138671875\n",
      "Epoch: 179, Batch number: 72, Loss: 15980.9609375\n",
      "Epoch: 181, Batch number: 20, Loss: 15193.6142578125\n",
      "Epoch: 182, Batch number: 44, Loss: 15647.3701171875\n",
      "Epoch: 183, Batch number: 68, Loss: 15299.4296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, Batch number: 16, Loss: 15203.798828125\n",
      "Epoch: 186, Batch number: 40, Loss: 15117.064453125\n",
      "Epoch: 187, Batch number: 64, Loss: 15472.126953125\n",
      "Epoch: 189, Batch number: 12, Loss: 15399.2939453125\n",
      "Epoch: 190, Batch number: 36, Loss: 15469.0390625\n",
      "Epoch: 191, Batch number: 60, Loss: 15437.849609375\n",
      "Epoch: 193, Batch number: 8, Loss: 15420.275390625\n",
      "Epoch: 194, Batch number: 32, Loss: 15113.7197265625\n",
      "Epoch: 195, Batch number: 56, Loss: 15493.033203125\n",
      "Epoch: 197, Batch number: 4, Loss: 15402.9384765625\n",
      "Epoch: 198, Batch number: 28, Loss: 14979.6005859375\n",
      "Epoch: 199, Batch number: 52, Loss: 15468.3232421875\n",
      "Epoch: 201, Batch number: 0, Loss: 15169.2607421875\n",
      "Epoch: 202, Batch number: 24, Loss: 15195.0546875\n",
      "Epoch: 203, Batch number: 48, Loss: 15247.849609375\n",
      "Epoch: 204, Batch number: 72, Loss: 15606.4033203125\n",
      "Epoch: 206, Batch number: 20, Loss: 15382.947265625\n",
      "Epoch: 207, Batch number: 44, Loss: 15397.4501953125\n",
      "Epoch: 208, Batch number: 68, Loss: 15108.462890625\n",
      "Epoch: 210, Batch number: 16, Loss: 14820.857421875\n",
      "Epoch: 211, Batch number: 40, Loss: 15348.1416015625\n",
      "Epoch: 212, Batch number: 64, Loss: 14903.140625\n",
      "Epoch: 214, Batch number: 12, Loss: 15339.1357421875\n",
      "Epoch: 215, Batch number: 36, Loss: 14665.1474609375\n",
      "Epoch: 216, Batch number: 60, Loss: 15640.9375\n",
      "Epoch: 218, Batch number: 8, Loss: 14444.7392578125\n",
      "Epoch: 219, Batch number: 32, Loss: 15077.1455078125\n",
      "Epoch: 220, Batch number: 56, Loss: 15095.2548828125\n",
      "Epoch: 222, Batch number: 4, Loss: 15007.9541015625\n",
      "Epoch: 223, Batch number: 28, Loss: 14927.54296875\n",
      "Epoch: 224, Batch number: 52, Loss: 15014.505859375\n",
      "Epoch: 226, Batch number: 0, Loss: 15052.6220703125\n",
      "Epoch: 227, Batch number: 24, Loss: 14795.9482421875\n",
      "Epoch: 228, Batch number: 48, Loss: 14840.228515625\n",
      "Epoch: 229, Batch number: 72, Loss: 14655.185546875\n",
      "Epoch: 231, Batch number: 20, Loss: 14902.4443359375\n",
      "Epoch: 232, Batch number: 44, Loss: 14913.7412109375\n",
      "Epoch: 233, Batch number: 68, Loss: 15127.5810546875\n",
      "Epoch: 235, Batch number: 16, Loss: 14962.251953125\n",
      "Epoch: 236, Batch number: 40, Loss: 14803.8173828125\n",
      "Epoch: 237, Batch number: 64, Loss: 15001.490234375\n",
      "Epoch: 239, Batch number: 12, Loss: 15260.2119140625\n",
      "Epoch: 240, Batch number: 36, Loss: 15033.9794921875\n",
      "Epoch: 241, Batch number: 60, Loss: 15121.654296875\n",
      "Epoch: 243, Batch number: 8, Loss: 14838.4501953125\n",
      "Epoch: 244, Batch number: 32, Loss: 15094.5869140625\n",
      "Epoch: 245, Batch number: 56, Loss: 14804.513671875\n",
      "Epoch: 247, Batch number: 4, Loss: 14505.0322265625\n",
      "Epoch: 248, Batch number: 28, Loss: 15335.9580078125\n",
      "Epoch: 249, Batch number: 52, Loss: 14835.8583984375\n",
      "Epoch: 251, Batch number: 0, Loss: 14592.4814453125\n",
      "Epoch: 252, Batch number: 24, Loss: 14855.1787109375\n",
      "Epoch: 253, Batch number: 48, Loss: 15148.705078125\n",
      "Epoch: 254, Batch number: 72, Loss: 14817.0478515625\n",
      "Epoch: 256, Batch number: 20, Loss: 15339.4345703125\n",
      "Epoch: 257, Batch number: 44, Loss: 14627.4775390625\n",
      "Epoch: 258, Batch number: 68, Loss: 15178.298828125\n",
      "Epoch: 260, Batch number: 16, Loss: 14963.5400390625\n",
      "Epoch: 261, Batch number: 40, Loss: 14750.5830078125\n",
      "Epoch: 262, Batch number: 64, Loss: 14941.8896484375\n",
      "Epoch: 264, Batch number: 12, Loss: 15039.392578125\n",
      "Epoch: 265, Batch number: 36, Loss: 15105.12890625\n",
      "Epoch: 266, Batch number: 60, Loss: 15158.59375\n",
      "Epoch: 268, Batch number: 8, Loss: 14845.2998046875\n",
      "Epoch: 269, Batch number: 32, Loss: 15001.50390625\n",
      "Epoch: 270, Batch number: 56, Loss: 14879.2080078125\n",
      "Epoch: 272, Batch number: 4, Loss: 14339.3623046875\n",
      "Epoch: 273, Batch number: 28, Loss: 15179.8447265625\n",
      "Epoch: 274, Batch number: 52, Loss: 14650.3349609375\n",
      "Epoch: 276, Batch number: 0, Loss: 14736.9990234375\n",
      "Epoch: 277, Batch number: 24, Loss: 14704.4208984375\n",
      "Epoch: 278, Batch number: 48, Loss: 14830.7529296875\n",
      "Epoch: 279, Batch number: 72, Loss: 14865.9775390625\n",
      "Epoch: 281, Batch number: 20, Loss: 14869.751953125\n",
      "Epoch: 282, Batch number: 44, Loss: 14718.998046875\n",
      "Epoch: 283, Batch number: 68, Loss: 14853.7060546875\n",
      "Epoch: 285, Batch number: 16, Loss: 14846.5751953125\n",
      "Epoch: 286, Batch number: 40, Loss: 14783.18359375\n",
      "Epoch: 287, Batch number: 64, Loss: 15112.9287109375\n",
      "Epoch: 289, Batch number: 12, Loss: 14699.5595703125\n",
      "Epoch: 290, Batch number: 36, Loss: 14710.5732421875\n",
      "Epoch: 291, Batch number: 60, Loss: 14482.568359375\n",
      "Epoch: 293, Batch number: 8, Loss: 14665.0107421875\n",
      "Epoch: 294, Batch number: 32, Loss: 14413.5888671875\n",
      "Epoch: 295, Batch number: 56, Loss: 14613.099609375\n",
      "Epoch: 297, Batch number: 4, Loss: 14505.44140625\n",
      "Epoch: 298, Batch number: 28, Loss: 14779.1845703125\n",
      "Epoch: 299, Batch number: 52, Loss: 14658.7060546875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 26976.064453125\n",
      "Epoch: 2, Batch number: 24, Loss: 25879.744140625\n",
      "Epoch: 3, Batch number: 48, Loss: 24361.400390625\n",
      "Epoch: 4, Batch number: 72, Loss: 23823.697265625\n",
      "Epoch: 6, Batch number: 20, Loss: 22350.744140625\n",
      "Epoch: 7, Batch number: 44, Loss: 21496.39453125\n",
      "Epoch: 8, Batch number: 68, Loss: 21025.361328125\n",
      "Epoch: 10, Batch number: 16, Loss: 21199.193359375\n",
      "Epoch: 11, Batch number: 40, Loss: 20416.861328125\n",
      "Epoch: 12, Batch number: 64, Loss: 20087.16796875\n",
      "Epoch: 14, Batch number: 12, Loss: 19503.10546875\n",
      "Epoch: 15, Batch number: 36, Loss: 19329.177734375\n",
      "Epoch: 16, Batch number: 60, Loss: 19358.392578125\n",
      "Epoch: 18, Batch number: 8, Loss: 18777.248046875\n",
      "Epoch: 19, Batch number: 32, Loss: 18992.25390625\n",
      "Epoch: 20, Batch number: 56, Loss: 18474.658203125\n",
      "Epoch: 22, Batch number: 4, Loss: 18572.283203125\n",
      "Epoch: 23, Batch number: 28, Loss: 17858.796875\n",
      "Epoch: 24, Batch number: 52, Loss: 17783.08984375\n",
      "Epoch: 26, Batch number: 0, Loss: 17510.62890625\n",
      "Epoch: 27, Batch number: 24, Loss: 17528.9140625\n",
      "Epoch: 28, Batch number: 48, Loss: 17684.208984375\n",
      "Epoch: 29, Batch number: 72, Loss: 17318.974609375\n",
      "Epoch: 31, Batch number: 20, Loss: 16999.482421875\n",
      "Epoch: 32, Batch number: 44, Loss: 17559.271484375\n",
      "Epoch: 33, Batch number: 68, Loss: 16902.5625\n",
      "Epoch: 35, Batch number: 16, Loss: 16893.650390625\n",
      "Epoch: 36, Batch number: 40, Loss: 16881.306640625\n",
      "Epoch: 37, Batch number: 64, Loss: 16802.083984375\n",
      "Epoch: 39, Batch number: 12, Loss: 16998.958984375\n",
      "Epoch: 40, Batch number: 36, Loss: 16728.75\n",
      "Epoch: 41, Batch number: 60, Loss: 16752.14453125\n",
      "Epoch: 43, Batch number: 8, Loss: 16474.181640625\n",
      "Epoch: 44, Batch number: 32, Loss: 16412.20703125\n",
      "Epoch: 45, Batch number: 56, Loss: 16594.25390625\n",
      "Epoch: 47, Batch number: 4, Loss: 16457.56640625\n",
      "Epoch: 48, Batch number: 28, Loss: 16433.697265625\n",
      "Epoch: 49, Batch number: 52, Loss: 16544.875\n",
      "Epoch: 51, Batch number: 0, Loss: 16552.5234375\n",
      "Epoch: 52, Batch number: 24, Loss: 16022.81640625\n",
      "Epoch: 53, Batch number: 48, Loss: 16104.0595703125\n",
      "Epoch: 54, Batch number: 72, Loss: 15859.3369140625\n",
      "Epoch: 56, Batch number: 20, Loss: 16369.82421875\n",
      "Epoch: 57, Batch number: 44, Loss: 16233.689453125\n",
      "Epoch: 58, Batch number: 68, Loss: 16000.646484375\n",
      "Epoch: 60, Batch number: 16, Loss: 16236.6328125\n",
      "Epoch: 61, Batch number: 40, Loss: 15662.638671875\n",
      "Epoch: 62, Batch number: 64, Loss: 16014.173828125\n",
      "Epoch: 64, Batch number: 12, Loss: 15796.7568359375\n",
      "Epoch: 65, Batch number: 36, Loss: 15871.603515625\n",
      "Epoch: 66, Batch number: 60, Loss: 16069.7587890625\n",
      "Epoch: 68, Batch number: 8, Loss: 15504.5166015625\n",
      "Epoch: 69, Batch number: 32, Loss: 15664.990234375\n",
      "Epoch: 70, Batch number: 56, Loss: 15783.7939453125\n",
      "Epoch: 72, Batch number: 4, Loss: 15579.900390625\n",
      "Epoch: 73, Batch number: 28, Loss: 15554.2978515625\n",
      "Epoch: 74, Batch number: 52, Loss: 15666.5439453125\n",
      "Epoch: 76, Batch number: 0, Loss: 15523.8291015625\n",
      "Epoch: 77, Batch number: 24, Loss: 15512.5478515625\n",
      "Epoch: 78, Batch number: 48, Loss: 15488.080078125\n",
      "Epoch: 79, Batch number: 72, Loss: 15717.16015625\n",
      "Epoch: 81, Batch number: 20, Loss: 15452.4697265625\n",
      "Epoch: 82, Batch number: 44, Loss: 15011.615234375\n",
      "Epoch: 83, Batch number: 68, Loss: 15505.435546875\n",
      "Epoch: 85, Batch number: 16, Loss: 15079.7421875\n",
      "Epoch: 86, Batch number: 40, Loss: 15056.6806640625\n",
      "Epoch: 87, Batch number: 64, Loss: 15294.2236328125\n",
      "Epoch: 89, Batch number: 12, Loss: 14999.83984375\n",
      "Epoch: 90, Batch number: 36, Loss: 15454.9462890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91, Batch number: 60, Loss: 15190.3916015625\n",
      "Epoch: 93, Batch number: 8, Loss: 15177.2255859375\n",
      "Epoch: 94, Batch number: 32, Loss: 15148.2744140625\n",
      "Epoch: 95, Batch number: 56, Loss: 15050.77734375\n",
      "Epoch: 97, Batch number: 4, Loss: 15040.7841796875\n",
      "Epoch: 98, Batch number: 28, Loss: 15273.2578125\n",
      "Epoch: 99, Batch number: 52, Loss: 14996.3916015625\n",
      "Epoch: 101, Batch number: 0, Loss: 15108.5166015625\n",
      "Epoch: 102, Batch number: 24, Loss: 15266.017578125\n",
      "Epoch: 103, Batch number: 48, Loss: 14966.439453125\n",
      "Epoch: 104, Batch number: 72, Loss: 14675.4169921875\n",
      "Epoch: 106, Batch number: 20, Loss: 15060.2724609375\n",
      "Epoch: 107, Batch number: 44, Loss: 15023.240234375\n",
      "Epoch: 108, Batch number: 68, Loss: 15073.2109375\n",
      "Epoch: 110, Batch number: 16, Loss: 15081.869140625\n",
      "Epoch: 111, Batch number: 40, Loss: 15155.4853515625\n",
      "Epoch: 112, Batch number: 64, Loss: 15338.939453125\n",
      "Epoch: 114, Batch number: 12, Loss: 14906.2822265625\n",
      "Epoch: 115, Batch number: 36, Loss: 14915.0703125\n",
      "Epoch: 116, Batch number: 60, Loss: 15094.9765625\n",
      "Epoch: 118, Batch number: 8, Loss: 14870.111328125\n",
      "Epoch: 119, Batch number: 32, Loss: 14655.6484375\n",
      "Epoch: 120, Batch number: 56, Loss: 14542.3515625\n",
      "Epoch: 122, Batch number: 4, Loss: 14752.6376953125\n",
      "Epoch: 123, Batch number: 28, Loss: 14628.65234375\n",
      "Epoch: 124, Batch number: 52, Loss: 14979.1494140625\n",
      "Epoch: 126, Batch number: 0, Loss: 14408.365234375\n",
      "Epoch: 127, Batch number: 24, Loss: 14453.533203125\n",
      "Epoch: 128, Batch number: 48, Loss: 14994.9931640625\n",
      "Epoch: 129, Batch number: 72, Loss: 14780.876953125\n",
      "Epoch: 131, Batch number: 20, Loss: 14596.64453125\n",
      "Epoch: 132, Batch number: 44, Loss: 14509.107421875\n",
      "Epoch: 133, Batch number: 68, Loss: 14860.5439453125\n",
      "Epoch: 135, Batch number: 16, Loss: 14729.5087890625\n",
      "Epoch: 136, Batch number: 40, Loss: 14607.1796875\n",
      "Epoch: 137, Batch number: 64, Loss: 14622.4697265625\n",
      "Epoch: 139, Batch number: 12, Loss: 14198.529296875\n",
      "Epoch: 140, Batch number: 36, Loss: 14490.3466796875\n",
      "Epoch: 141, Batch number: 60, Loss: 14892.365234375\n",
      "Epoch: 143, Batch number: 8, Loss: 14521.47265625\n",
      "Epoch: 144, Batch number: 32, Loss: 14346.55859375\n",
      "Epoch: 145, Batch number: 56, Loss: 14935.580078125\n",
      "Epoch: 147, Batch number: 4, Loss: 14468.529296875\n",
      "Epoch: 148, Batch number: 28, Loss: 14583.185546875\n",
      "Epoch: 149, Batch number: 52, Loss: 14119.2216796875\n",
      "Epoch: 151, Batch number: 0, Loss: 14374.0244140625\n",
      "Epoch: 152, Batch number: 24, Loss: 13922.185546875\n",
      "Epoch: 153, Batch number: 48, Loss: 14148.91015625\n",
      "Epoch: 154, Batch number: 72, Loss: 14649.5888671875\n",
      "Epoch: 156, Batch number: 20, Loss: 14164.70703125\n",
      "Epoch: 157, Batch number: 44, Loss: 14094.7275390625\n",
      "Epoch: 158, Batch number: 68, Loss: 14493.443359375\n",
      "Epoch: 160, Batch number: 16, Loss: 14462.935546875\n",
      "Epoch: 161, Batch number: 40, Loss: 14243.8388671875\n",
      "Epoch: 162, Batch number: 64, Loss: 14776.404296875\n",
      "Epoch: 164, Batch number: 12, Loss: 14068.0185546875\n",
      "Epoch: 165, Batch number: 36, Loss: 13802.560546875\n",
      "Epoch: 166, Batch number: 60, Loss: 14644.255859375\n",
      "Epoch: 168, Batch number: 8, Loss: 14255.8740234375\n",
      "Epoch: 169, Batch number: 32, Loss: 14440.1181640625\n",
      "Epoch: 170, Batch number: 56, Loss: 14042.1494140625\n",
      "Epoch: 172, Batch number: 4, Loss: 14499.763671875\n",
      "Epoch: 173, Batch number: 28, Loss: 14157.27734375\n",
      "Epoch: 174, Batch number: 52, Loss: 14267.708984375\n",
      "Epoch: 176, Batch number: 0, Loss: 14415.3203125\n",
      "Epoch: 177, Batch number: 24, Loss: 14328.3115234375\n",
      "Epoch: 178, Batch number: 48, Loss: 14391.2333984375\n",
      "Epoch: 179, Batch number: 72, Loss: 14967.2080078125\n",
      "Epoch: 181, Batch number: 20, Loss: 14656.671875\n",
      "Epoch: 182, Batch number: 44, Loss: 13950.8671875\n",
      "Epoch: 183, Batch number: 68, Loss: 14254.798828125\n",
      "Epoch: 185, Batch number: 16, Loss: 14049.40234375\n",
      "Epoch: 186, Batch number: 40, Loss: 14115.29296875\n",
      "Epoch: 187, Batch number: 64, Loss: 14183.7060546875\n",
      "Epoch: 189, Batch number: 12, Loss: 14149.4677734375\n",
      "Epoch: 190, Batch number: 36, Loss: 14505.681640625\n",
      "Epoch: 191, Batch number: 60, Loss: 14074.0849609375\n",
      "Epoch: 193, Batch number: 8, Loss: 14120.4208984375\n",
      "Epoch: 194, Batch number: 32, Loss: 13934.3203125\n",
      "Epoch: 195, Batch number: 56, Loss: 14082.70703125\n",
      "Epoch: 197, Batch number: 4, Loss: 14075.572265625\n",
      "Epoch: 198, Batch number: 28, Loss: 13750.1689453125\n",
      "Epoch: 199, Batch number: 52, Loss: 14129.18359375\n",
      "Epoch: 201, Batch number: 0, Loss: 14218.60546875\n",
      "Epoch: 202, Batch number: 24, Loss: 14188.7880859375\n",
      "Epoch: 203, Batch number: 48, Loss: 13935.234375\n",
      "Epoch: 204, Batch number: 72, Loss: 14296.7998046875\n",
      "Epoch: 206, Batch number: 20, Loss: 14021.7568359375\n",
      "Epoch: 207, Batch number: 44, Loss: 14239.1748046875\n",
      "Epoch: 208, Batch number: 68, Loss: 14469.6767578125\n",
      "Epoch: 210, Batch number: 16, Loss: 13919.208984375\n",
      "Epoch: 211, Batch number: 40, Loss: 13917.0517578125\n",
      "Epoch: 212, Batch number: 64, Loss: 14100.525390625\n",
      "Epoch: 214, Batch number: 12, Loss: 13986.681640625\n",
      "Epoch: 215, Batch number: 36, Loss: 14411.017578125\n",
      "Epoch: 216, Batch number: 60, Loss: 14223.8486328125\n",
      "Epoch: 218, Batch number: 8, Loss: 14236.8134765625\n",
      "Epoch: 219, Batch number: 32, Loss: 14210.0849609375\n",
      "Epoch: 220, Batch number: 56, Loss: 14448.4677734375\n",
      "Epoch: 222, Batch number: 4, Loss: 13702.392578125\n",
      "Epoch: 223, Batch number: 28, Loss: 14235.9345703125\n",
      "Epoch: 224, Batch number: 52, Loss: 14061.953125\n",
      "Epoch: 226, Batch number: 0, Loss: 14146.8369140625\n",
      "Epoch: 227, Batch number: 24, Loss: 13852.421875\n",
      "Epoch: 228, Batch number: 48, Loss: 14131.4228515625\n",
      "Epoch: 229, Batch number: 72, Loss: 13732.154296875\n",
      "Epoch: 231, Batch number: 20, Loss: 13889.2646484375\n",
      "Epoch: 232, Batch number: 44, Loss: 14401.1552734375\n",
      "Epoch: 233, Batch number: 68, Loss: 13888.8173828125\n",
      "Epoch: 235, Batch number: 16, Loss: 13476.9462890625\n",
      "Epoch: 236, Batch number: 40, Loss: 13859.7099609375\n",
      "Epoch: 237, Batch number: 64, Loss: 13704.8583984375\n",
      "Epoch: 239, Batch number: 12, Loss: 14027.5703125\n",
      "Epoch: 240, Batch number: 36, Loss: 14351.1787109375\n",
      "Epoch: 241, Batch number: 60, Loss: 13917.576171875\n",
      "Epoch: 243, Batch number: 8, Loss: 13760.310546875\n",
      "Epoch: 244, Batch number: 32, Loss: 14077.0791015625\n",
      "Epoch: 245, Batch number: 56, Loss: 14034.294921875\n",
      "Epoch: 247, Batch number: 4, Loss: 13725.90625\n",
      "Epoch: 248, Batch number: 28, Loss: 14054.7314453125\n",
      "Epoch: 249, Batch number: 52, Loss: 13920.630859375\n",
      "Epoch: 251, Batch number: 0, Loss: 13899.5498046875\n",
      "Epoch: 252, Batch number: 24, Loss: 14151.275390625\n",
      "Epoch: 253, Batch number: 48, Loss: 13901.330078125\n",
      "Epoch: 254, Batch number: 72, Loss: 13639.662109375\n",
      "Epoch: 256, Batch number: 20, Loss: 13609.1728515625\n",
      "Epoch: 257, Batch number: 44, Loss: 13771.064453125\n",
      "Epoch: 258, Batch number: 68, Loss: 14061.2265625\n",
      "Epoch: 260, Batch number: 16, Loss: 14194.02734375\n",
      "Epoch: 261, Batch number: 40, Loss: 13536.865234375\n",
      "Epoch: 262, Batch number: 64, Loss: 13719.1083984375\n",
      "Epoch: 264, Batch number: 12, Loss: 13800.1279296875\n",
      "Epoch: 265, Batch number: 36, Loss: 14182.162109375\n",
      "Epoch: 266, Batch number: 60, Loss: 13661.22265625\n",
      "Epoch: 268, Batch number: 8, Loss: 13548.71875\n",
      "Epoch: 269, Batch number: 32, Loss: 13992.5859375\n",
      "Epoch: 270, Batch number: 56, Loss: 14067.2763671875\n",
      "Epoch: 272, Batch number: 4, Loss: 13617.7880859375\n",
      "Epoch: 273, Batch number: 28, Loss: 14213.650390625\n",
      "Epoch: 274, Batch number: 52, Loss: 14172.298828125\n",
      "Epoch: 276, Batch number: 0, Loss: 13447.5439453125\n",
      "Epoch: 277, Batch number: 24, Loss: 13431.4951171875\n",
      "Epoch: 278, Batch number: 48, Loss: 13887.251953125\n",
      "Epoch: 279, Batch number: 72, Loss: 13296.7275390625\n",
      "Epoch: 281, Batch number: 20, Loss: 13662.2265625\n",
      "Epoch: 282, Batch number: 44, Loss: 13867.1962890625\n",
      "Epoch: 283, Batch number: 68, Loss: 13793.001953125\n",
      "Epoch: 285, Batch number: 16, Loss: 13489.4716796875\n",
      "Epoch: 286, Batch number: 40, Loss: 13649.2744140625\n",
      "Epoch: 287, Batch number: 64, Loss: 13696.9912109375\n",
      "Epoch: 289, Batch number: 12, Loss: 13612.857421875\n",
      "Epoch: 290, Batch number: 36, Loss: 13725.6953125\n",
      "Epoch: 291, Batch number: 60, Loss: 13950.013671875\n",
      "Epoch: 293, Batch number: 8, Loss: 13773.4150390625\n",
      "Epoch: 294, Batch number: 32, Loss: 13955.0498046875\n",
      "Epoch: 295, Batch number: 56, Loss: 13817.990234375\n",
      "Epoch: 297, Batch number: 4, Loss: 13530.353515625\n",
      "Epoch: 298, Batch number: 28, Loss: 13682.1455078125\n",
      "Epoch: 299, Batch number: 52, Loss: 14017.4091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 26608.291015625\n",
      "Epoch: 2, Batch number: 24, Loss: 25146.662109375\n",
      "Epoch: 3, Batch number: 48, Loss: 24218.951171875\n",
      "Epoch: 4, Batch number: 72, Loss: 22696.9921875\n",
      "Epoch: 6, Batch number: 20, Loss: 22228.76953125\n",
      "Epoch: 7, Batch number: 44, Loss: 21413.708984375\n",
      "Epoch: 8, Batch number: 68, Loss: 20603.623046875\n",
      "Epoch: 10, Batch number: 16, Loss: 19871.669921875\n",
      "Epoch: 11, Batch number: 40, Loss: 19689.046875\n",
      "Epoch: 12, Batch number: 64, Loss: 19304.666015625\n",
      "Epoch: 14, Batch number: 12, Loss: 18902.501953125\n",
      "Epoch: 15, Batch number: 36, Loss: 18402.875\n",
      "Epoch: 16, Batch number: 60, Loss: 18431.529296875\n",
      "Epoch: 18, Batch number: 8, Loss: 18167.341796875\n",
      "Epoch: 19, Batch number: 32, Loss: 17898.5234375\n",
      "Epoch: 20, Batch number: 56, Loss: 17497.6484375\n",
      "Epoch: 22, Batch number: 4, Loss: 17493.865234375\n",
      "Epoch: 23, Batch number: 28, Loss: 17024.259765625\n",
      "Epoch: 24, Batch number: 52, Loss: 17352.341796875\n",
      "Epoch: 26, Batch number: 0, Loss: 17081.498046875\n",
      "Epoch: 27, Batch number: 24, Loss: 16733.962890625\n",
      "Epoch: 28, Batch number: 48, Loss: 16396.119140625\n",
      "Epoch: 29, Batch number: 72, Loss: 16632.171875\n",
      "Epoch: 31, Batch number: 20, Loss: 16369.3486328125\n",
      "Epoch: 32, Batch number: 44, Loss: 16043.3046875\n",
      "Epoch: 33, Batch number: 68, Loss: 16417.595703125\n",
      "Epoch: 35, Batch number: 16, Loss: 16645.828125\n",
      "Epoch: 36, Batch number: 40, Loss: 15958.0751953125\n",
      "Epoch: 37, Batch number: 64, Loss: 16198.70703125\n",
      "Epoch: 39, Batch number: 12, Loss: 15684.0712890625\n",
      "Epoch: 40, Batch number: 36, Loss: 16090.4755859375\n",
      "Epoch: 41, Batch number: 60, Loss: 16023.2294921875\n",
      "Epoch: 43, Batch number: 8, Loss: 15408.515625\n",
      "Epoch: 44, Batch number: 32, Loss: 15595.8369140625\n",
      "Epoch: 45, Batch number: 56, Loss: 15443.1572265625\n",
      "Epoch: 47, Batch number: 4, Loss: 15214.919921875\n",
      "Epoch: 48, Batch number: 28, Loss: 15463.3994140625\n",
      "Epoch: 49, Batch number: 52, Loss: 15654.0859375\n",
      "Epoch: 51, Batch number: 0, Loss: 15079.3642578125\n",
      "Epoch: 52, Batch number: 24, Loss: 15403.7216796875\n",
      "Epoch: 53, Batch number: 48, Loss: 15729.63671875\n",
      "Epoch: 54, Batch number: 72, Loss: 15506.2822265625\n",
      "Epoch: 56, Batch number: 20, Loss: 15362.712890625\n",
      "Epoch: 57, Batch number: 44, Loss: 15353.4453125\n",
      "Epoch: 58, Batch number: 68, Loss: 15846.494140625\n",
      "Epoch: 60, Batch number: 16, Loss: 15041.0712890625\n",
      "Epoch: 61, Batch number: 40, Loss: 15014.46484375\n",
      "Epoch: 62, Batch number: 64, Loss: 14925.9814453125\n",
      "Epoch: 64, Batch number: 12, Loss: 15175.7021484375\n",
      "Epoch: 65, Batch number: 36, Loss: 14985.8935546875\n",
      "Epoch: 66, Batch number: 60, Loss: 15631.763671875\n",
      "Epoch: 68, Batch number: 8, Loss: 14790.599609375\n",
      "Epoch: 69, Batch number: 32, Loss: 14863.3701171875\n",
      "Epoch: 70, Batch number: 56, Loss: 15172.93359375\n",
      "Epoch: 72, Batch number: 4, Loss: 14738.337890625\n",
      "Epoch: 73, Batch number: 28, Loss: 14731.947265625\n",
      "Epoch: 74, Batch number: 52, Loss: 15230.109375\n",
      "Epoch: 76, Batch number: 0, Loss: 14578.1728515625\n",
      "Epoch: 77, Batch number: 24, Loss: 14746.2119140625\n",
      "Epoch: 78, Batch number: 48, Loss: 15094.0078125\n",
      "Epoch: 79, Batch number: 72, Loss: 14660.9130859375\n",
      "Epoch: 81, Batch number: 20, Loss: 14706.58984375\n",
      "Epoch: 82, Batch number: 44, Loss: 14781.22265625\n",
      "Epoch: 83, Batch number: 68, Loss: 14611.7578125\n",
      "Epoch: 85, Batch number: 16, Loss: 14752.9609375\n",
      "Epoch: 86, Batch number: 40, Loss: 14914.5810546875\n",
      "Epoch: 87, Batch number: 64, Loss: 14865.6171875\n",
      "Epoch: 89, Batch number: 12, Loss: 15013.5302734375\n",
      "Epoch: 90, Batch number: 36, Loss: 14364.853515625\n",
      "Epoch: 91, Batch number: 60, Loss: 14603.6494140625\n",
      "Epoch: 93, Batch number: 8, Loss: 14357.185546875\n",
      "Epoch: 94, Batch number: 32, Loss: 14715.779296875\n",
      "Epoch: 95, Batch number: 56, Loss: 14472.3115234375\n",
      "Epoch: 97, Batch number: 4, Loss: 14982.0712890625\n",
      "Epoch: 98, Batch number: 28, Loss: 14420.1875\n",
      "Epoch: 99, Batch number: 52, Loss: 14106.5029296875\n",
      "Epoch: 101, Batch number: 0, Loss: 14286.634765625\n",
      "Epoch: 102, Batch number: 24, Loss: 14612.2626953125\n",
      "Epoch: 103, Batch number: 48, Loss: 14649.2099609375\n",
      "Epoch: 104, Batch number: 72, Loss: 14463.9228515625\n",
      "Epoch: 106, Batch number: 20, Loss: 14317.3291015625\n",
      "Epoch: 107, Batch number: 44, Loss: 14484.490234375\n",
      "Epoch: 108, Batch number: 68, Loss: 14170.7060546875\n",
      "Epoch: 110, Batch number: 16, Loss: 14253.7578125\n",
      "Epoch: 111, Batch number: 40, Loss: 14525.0439453125\n",
      "Epoch: 112, Batch number: 64, Loss: 14503.50390625\n",
      "Epoch: 114, Batch number: 12, Loss: 14467.4208984375\n",
      "Epoch: 115, Batch number: 36, Loss: 13918.1806640625\n",
      "Epoch: 116, Batch number: 60, Loss: 14213.0390625\n",
      "Epoch: 118, Batch number: 8, Loss: 14218.322265625\n",
      "Epoch: 119, Batch number: 32, Loss: 14153.2578125\n",
      "Epoch: 120, Batch number: 56, Loss: 14404.818359375\n",
      "Epoch: 122, Batch number: 4, Loss: 14278.607421875\n",
      "Epoch: 123, Batch number: 28, Loss: 13781.2890625\n",
      "Epoch: 124, Batch number: 52, Loss: 13822.2548828125\n",
      "Epoch: 126, Batch number: 0, Loss: 14020.5595703125\n",
      "Epoch: 127, Batch number: 24, Loss: 14498.005859375\n",
      "Epoch: 128, Batch number: 48, Loss: 14295.33203125\n",
      "Epoch: 129, Batch number: 72, Loss: 14188.0791015625\n",
      "Epoch: 131, Batch number: 20, Loss: 13907.5517578125\n",
      "Epoch: 132, Batch number: 44, Loss: 14230.1591796875\n",
      "Epoch: 133, Batch number: 68, Loss: 14437.8427734375\n",
      "Epoch: 135, Batch number: 16, Loss: 13764.2470703125\n",
      "Epoch: 136, Batch number: 40, Loss: 14291.259765625\n",
      "Epoch: 137, Batch number: 64, Loss: 14104.35546875\n",
      "Epoch: 139, Batch number: 12, Loss: 13865.0556640625\n",
      "Epoch: 140, Batch number: 36, Loss: 14259.767578125\n",
      "Epoch: 141, Batch number: 60, Loss: 13706.7958984375\n",
      "Epoch: 143, Batch number: 8, Loss: 13980.578125\n",
      "Epoch: 144, Batch number: 32, Loss: 13871.4462890625\n",
      "Epoch: 145, Batch number: 56, Loss: 13753.17578125\n",
      "Epoch: 147, Batch number: 4, Loss: 14085.345703125\n",
      "Epoch: 148, Batch number: 28, Loss: 14179.9423828125\n",
      "Epoch: 149, Batch number: 52, Loss: 14360.009765625\n",
      "Epoch: 151, Batch number: 0, Loss: 14036.4541015625\n",
      "Epoch: 152, Batch number: 24, Loss: 13745.625\n",
      "Epoch: 153, Batch number: 48, Loss: 14158.9951171875\n",
      "Epoch: 154, Batch number: 72, Loss: 13939.60546875\n",
      "Epoch: 156, Batch number: 20, Loss: 13696.6611328125\n",
      "Epoch: 157, Batch number: 44, Loss: 14035.4443359375\n",
      "Epoch: 158, Batch number: 68, Loss: 13918.375\n",
      "Epoch: 160, Batch number: 16, Loss: 13239.5517578125\n",
      "Epoch: 161, Batch number: 40, Loss: 14297.431640625\n",
      "Epoch: 162, Batch number: 64, Loss: 13930.71875\n",
      "Epoch: 164, Batch number: 12, Loss: 14025.068359375\n",
      "Epoch: 165, Batch number: 36, Loss: 13773.68359375\n",
      "Epoch: 166, Batch number: 60, Loss: 14144.470703125\n",
      "Epoch: 168, Batch number: 8, Loss: 13920.173828125\n",
      "Epoch: 169, Batch number: 32, Loss: 13704.20703125\n",
      "Epoch: 170, Batch number: 56, Loss: 13550.0322265625\n",
      "Epoch: 172, Batch number: 4, Loss: 13436.9541015625\n",
      "Epoch: 173, Batch number: 28, Loss: 13457.25\n",
      "Epoch: 174, Batch number: 52, Loss: 14300.3681640625\n",
      "Epoch: 176, Batch number: 0, Loss: 14029.1396484375\n",
      "Epoch: 177, Batch number: 24, Loss: 14023.1181640625\n",
      "Epoch: 178, Batch number: 48, Loss: 13279.2509765625\n",
      "Epoch: 179, Batch number: 72, Loss: 13811.849609375\n",
      "Epoch: 181, Batch number: 20, Loss: 13997.416015625\n",
      "Epoch: 182, Batch number: 44, Loss: 13929.8466796875\n",
      "Epoch: 183, Batch number: 68, Loss: 13559.841796875\n",
      "Epoch: 185, Batch number: 16, Loss: 13578.9140625\n",
      "Epoch: 186, Batch number: 40, Loss: 13720.412109375\n",
      "Epoch: 187, Batch number: 64, Loss: 13150.93359375\n",
      "Epoch: 189, Batch number: 12, Loss: 13990.9599609375\n",
      "Epoch: 190, Batch number: 36, Loss: 13978.8408203125\n",
      "Epoch: 191, Batch number: 60, Loss: 13615.3125\n",
      "Epoch: 193, Batch number: 8, Loss: 13866.3056640625\n",
      "Epoch: 194, Batch number: 32, Loss: 13597.2958984375\n",
      "Epoch: 195, Batch number: 56, Loss: 13982.57421875\n",
      "Epoch: 197, Batch number: 4, Loss: 13905.0849609375\n",
      "Epoch: 198, Batch number: 28, Loss: 13784.681640625\n",
      "Epoch: 199, Batch number: 52, Loss: 13496.666015625\n",
      "Epoch: 201, Batch number: 0, Loss: 13895.4599609375\n",
      "Epoch: 202, Batch number: 24, Loss: 13759.2685546875\n",
      "Epoch: 203, Batch number: 48, Loss: 13851.90625\n",
      "Epoch: 204, Batch number: 72, Loss: 14237.15625\n",
      "Epoch: 206, Batch number: 20, Loss: 13830.3671875\n",
      "Epoch: 207, Batch number: 44, Loss: 13601.646484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 13759.900390625\n",
      "Epoch: 210, Batch number: 16, Loss: 13690.28515625\n",
      "Epoch: 211, Batch number: 40, Loss: 13808.392578125\n",
      "Epoch: 212, Batch number: 64, Loss: 14263.8876953125\n",
      "Epoch: 214, Batch number: 12, Loss: 13462.2802734375\n",
      "Epoch: 215, Batch number: 36, Loss: 13822.19140625\n",
      "Epoch: 216, Batch number: 60, Loss: 13707.8125\n",
      "Epoch: 218, Batch number: 8, Loss: 13416.1630859375\n",
      "Epoch: 219, Batch number: 32, Loss: 13557.248046875\n",
      "Epoch: 220, Batch number: 56, Loss: 13705.4853515625\n",
      "Epoch: 222, Batch number: 4, Loss: 13349.1328125\n",
      "Epoch: 223, Batch number: 28, Loss: 14098.853515625\n",
      "Epoch: 224, Batch number: 52, Loss: 13896.466796875\n",
      "Epoch: 226, Batch number: 0, Loss: 13904.12890625\n",
      "Epoch: 227, Batch number: 24, Loss: 13920.4140625\n",
      "Epoch: 228, Batch number: 48, Loss: 13748.265625\n",
      "Epoch: 229, Batch number: 72, Loss: 13457.3505859375\n",
      "Epoch: 231, Batch number: 20, Loss: 13951.29296875\n",
      "Epoch: 232, Batch number: 44, Loss: 13805.93359375\n",
      "Epoch: 233, Batch number: 68, Loss: 14117.4326171875\n",
      "Epoch: 235, Batch number: 16, Loss: 13462.775390625\n",
      "Epoch: 236, Batch number: 40, Loss: 13638.03515625\n",
      "Epoch: 237, Batch number: 64, Loss: 13854.4326171875\n",
      "Epoch: 239, Batch number: 12, Loss: 13695.7353515625\n",
      "Epoch: 240, Batch number: 36, Loss: 13405.09375\n",
      "Epoch: 241, Batch number: 60, Loss: 13376.7109375\n",
      "Epoch: 243, Batch number: 8, Loss: 13556.708984375\n",
      "Epoch: 244, Batch number: 32, Loss: 13754.6669921875\n",
      "Epoch: 245, Batch number: 56, Loss: 13983.583984375\n",
      "Epoch: 247, Batch number: 4, Loss: 13316.1259765625\n",
      "Epoch: 248, Batch number: 28, Loss: 13544.7958984375\n",
      "Epoch: 249, Batch number: 52, Loss: 13755.36328125\n",
      "Epoch: 251, Batch number: 0, Loss: 13622.396484375\n",
      "Epoch: 252, Batch number: 24, Loss: 13886.5234375\n",
      "Epoch: 253, Batch number: 48, Loss: 13609.6796875\n",
      "Epoch: 254, Batch number: 72, Loss: 13611.5087890625\n",
      "Epoch: 256, Batch number: 20, Loss: 13792.9052734375\n",
      "Epoch: 257, Batch number: 44, Loss: 13658.3916015625\n",
      "Epoch: 258, Batch number: 68, Loss: 13884.2783203125\n",
      "Epoch: 260, Batch number: 16, Loss: 13856.7431640625\n",
      "Epoch: 261, Batch number: 40, Loss: 13295.888671875\n",
      "Epoch: 262, Batch number: 64, Loss: 13910.3603515625\n",
      "Epoch: 264, Batch number: 12, Loss: 13600.2861328125\n",
      "Epoch: 265, Batch number: 36, Loss: 13448.6982421875\n",
      "Epoch: 266, Batch number: 60, Loss: 13739.396484375\n",
      "Epoch: 268, Batch number: 8, Loss: 13474.5703125\n",
      "Epoch: 269, Batch number: 32, Loss: 13456.892578125\n",
      "Epoch: 270, Batch number: 56, Loss: 13524.8310546875\n",
      "Epoch: 272, Batch number: 4, Loss: 13684.27734375\n",
      "Epoch: 273, Batch number: 28, Loss: 13847.560546875\n",
      "Epoch: 274, Batch number: 52, Loss: 13829.78515625\n",
      "Epoch: 276, Batch number: 0, Loss: 13303.5966796875\n",
      "Epoch: 277, Batch number: 24, Loss: 13464.923828125\n",
      "Epoch: 278, Batch number: 48, Loss: 13219.693359375\n",
      "Epoch: 279, Batch number: 72, Loss: 14089.06640625\n",
      "Epoch: 281, Batch number: 20, Loss: 13540.4599609375\n",
      "Epoch: 282, Batch number: 44, Loss: 13567.8740234375\n",
      "Epoch: 283, Batch number: 68, Loss: 13611.609375\n",
      "Epoch: 285, Batch number: 16, Loss: 13454.03515625\n",
      "Epoch: 286, Batch number: 40, Loss: 13504.54296875\n",
      "Epoch: 287, Batch number: 64, Loss: 14001.6103515625\n",
      "Epoch: 289, Batch number: 12, Loss: 13170.822265625\n",
      "Epoch: 290, Batch number: 36, Loss: 13776.50390625\n",
      "Epoch: 291, Batch number: 60, Loss: 13661.1826171875\n",
      "Epoch: 293, Batch number: 8, Loss: 13481.78125\n",
      "Epoch: 294, Batch number: 32, Loss: 14010.2783203125\n",
      "Epoch: 295, Batch number: 56, Loss: 14104.71875\n",
      "Epoch: 297, Batch number: 4, Loss: 13502.041015625\n",
      "Epoch: 298, Batch number: 28, Loss: 13671.7041015625\n",
      "Epoch: 299, Batch number: 52, Loss: 13404.435546875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 27259.697265625\n",
      "Epoch: 2, Batch number: 24, Loss: 25032.541015625\n",
      "Epoch: 3, Batch number: 48, Loss: 23604.318359375\n",
      "Epoch: 4, Batch number: 72, Loss: 22370.19140625\n",
      "Epoch: 6, Batch number: 20, Loss: 21146.353515625\n",
      "Epoch: 7, Batch number: 44, Loss: 21050.40234375\n",
      "Epoch: 8, Batch number: 68, Loss: 20520.625\n",
      "Epoch: 10, Batch number: 16, Loss: 19236.458984375\n",
      "Epoch: 11, Batch number: 40, Loss: 18957.662109375\n",
      "Epoch: 12, Batch number: 64, Loss: 18513.6484375\n",
      "Epoch: 14, Batch number: 12, Loss: 18427.3125\n",
      "Epoch: 15, Batch number: 36, Loss: 17691.642578125\n",
      "Epoch: 16, Batch number: 60, Loss: 17683.13671875\n",
      "Epoch: 18, Batch number: 8, Loss: 17255.2265625\n",
      "Epoch: 19, Batch number: 32, Loss: 16973.4140625\n",
      "Epoch: 20, Batch number: 56, Loss: 16842.359375\n",
      "Epoch: 22, Batch number: 4, Loss: 16911.1875\n",
      "Epoch: 23, Batch number: 28, Loss: 16567.33203125\n",
      "Epoch: 24, Batch number: 52, Loss: 16461.966796875\n",
      "Epoch: 26, Batch number: 0, Loss: 15977.9775390625\n",
      "Epoch: 27, Batch number: 24, Loss: 16278.1455078125\n",
      "Epoch: 28, Batch number: 48, Loss: 16152.8984375\n",
      "Epoch: 29, Batch number: 72, Loss: 16037.203125\n",
      "Epoch: 31, Batch number: 20, Loss: 15867.2744140625\n",
      "Epoch: 32, Batch number: 44, Loss: 15853.3623046875\n",
      "Epoch: 33, Batch number: 68, Loss: 15589.4814453125\n",
      "Epoch: 35, Batch number: 16, Loss: 15704.1474609375\n",
      "Epoch: 36, Batch number: 40, Loss: 15447.8447265625\n",
      "Epoch: 37, Batch number: 64, Loss: 15695.54296875\n",
      "Epoch: 39, Batch number: 12, Loss: 15217.443359375\n",
      "Epoch: 40, Batch number: 36, Loss: 15018.1923828125\n",
      "Epoch: 41, Batch number: 60, Loss: 15082.751953125\n",
      "Epoch: 43, Batch number: 8, Loss: 15023.9814453125\n",
      "Epoch: 44, Batch number: 32, Loss: 15059.650390625\n",
      "Epoch: 45, Batch number: 56, Loss: 15020.6591796875\n",
      "Epoch: 47, Batch number: 4, Loss: 15029.369140625\n",
      "Epoch: 48, Batch number: 28, Loss: 14991.7421875\n",
      "Epoch: 49, Batch number: 52, Loss: 15088.4443359375\n",
      "Epoch: 51, Batch number: 0, Loss: 14639.7880859375\n",
      "Epoch: 52, Batch number: 24, Loss: 15006.3349609375\n",
      "Epoch: 53, Batch number: 48, Loss: 14884.177734375\n",
      "Epoch: 54, Batch number: 72, Loss: 15388.2861328125\n",
      "Epoch: 56, Batch number: 20, Loss: 14824.900390625\n",
      "Epoch: 57, Batch number: 44, Loss: 14748.8515625\n",
      "Epoch: 58, Batch number: 68, Loss: 14889.259765625\n",
      "Epoch: 60, Batch number: 16, Loss: 14695.2646484375\n",
      "Epoch: 61, Batch number: 40, Loss: 14550.8837890625\n",
      "Epoch: 62, Batch number: 64, Loss: 15365.69921875\n",
      "Epoch: 64, Batch number: 12, Loss: 14447.0400390625\n",
      "Epoch: 65, Batch number: 36, Loss: 14418.3974609375\n",
      "Epoch: 66, Batch number: 60, Loss: 14610.37109375\n",
      "Epoch: 68, Batch number: 8, Loss: 14215.708984375\n",
      "Epoch: 69, Batch number: 32, Loss: 14337.408203125\n",
      "Epoch: 70, Batch number: 56, Loss: 14440.5107421875\n",
      "Epoch: 72, Batch number: 4, Loss: 14614.396484375\n",
      "Epoch: 73, Batch number: 28, Loss: 14342.9228515625\n",
      "Epoch: 74, Batch number: 52, Loss: 14772.666015625\n",
      "Epoch: 76, Batch number: 0, Loss: 14157.046875\n",
      "Epoch: 77, Batch number: 24, Loss: 14226.9306640625\n",
      "Epoch: 78, Batch number: 48, Loss: 14595.291015625\n",
      "Epoch: 79, Batch number: 72, Loss: 14180.0703125\n",
      "Epoch: 81, Batch number: 20, Loss: 14014.7275390625\n",
      "Epoch: 82, Batch number: 44, Loss: 14658.42578125\n",
      "Epoch: 83, Batch number: 68, Loss: 14506.345703125\n",
      "Epoch: 85, Batch number: 16, Loss: 14465.3603515625\n",
      "Epoch: 86, Batch number: 40, Loss: 14547.7548828125\n",
      "Epoch: 87, Batch number: 64, Loss: 14306.462890625\n",
      "Epoch: 89, Batch number: 12, Loss: 14127.279296875\n",
      "Epoch: 90, Batch number: 36, Loss: 14120.0087890625\n",
      "Epoch: 91, Batch number: 60, Loss: 14053.6103515625\n",
      "Epoch: 93, Batch number: 8, Loss: 14170.7431640625\n",
      "Epoch: 94, Batch number: 32, Loss: 13751.9716796875\n",
      "Epoch: 95, Batch number: 56, Loss: 13984.1708984375\n",
      "Epoch: 97, Batch number: 4, Loss: 14031.5927734375\n",
      "Epoch: 98, Batch number: 28, Loss: 13877.796875\n",
      "Epoch: 99, Batch number: 52, Loss: 14101.82421875\n",
      "Epoch: 101, Batch number: 0, Loss: 14166.6767578125\n",
      "Epoch: 102, Batch number: 24, Loss: 14209.578125\n",
      "Epoch: 103, Batch number: 48, Loss: 14286.58984375\n",
      "Epoch: 104, Batch number: 72, Loss: 14401.3671875\n",
      "Epoch: 106, Batch number: 20, Loss: 13863.55078125\n",
      "Epoch: 107, Batch number: 44, Loss: 14207.1474609375\n",
      "Epoch: 108, Batch number: 68, Loss: 14035.6015625\n",
      "Epoch: 110, Batch number: 16, Loss: 13745.5341796875\n",
      "Epoch: 111, Batch number: 40, Loss: 13664.4501953125\n",
      "Epoch: 112, Batch number: 64, Loss: 14267.6357421875\n",
      "Epoch: 114, Batch number: 12, Loss: 13678.86328125\n",
      "Epoch: 115, Batch number: 36, Loss: 14080.0615234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116, Batch number: 60, Loss: 13986.1533203125\n",
      "Epoch: 118, Batch number: 8, Loss: 14093.9365234375\n",
      "Epoch: 119, Batch number: 32, Loss: 13874.2470703125\n",
      "Epoch: 120, Batch number: 56, Loss: 14105.8427734375\n",
      "Epoch: 122, Batch number: 4, Loss: 13747.775390625\n",
      "Epoch: 123, Batch number: 28, Loss: 14035.0458984375\n",
      "Epoch: 124, Batch number: 52, Loss: 13491.0048828125\n",
      "Epoch: 126, Batch number: 0, Loss: 13697.974609375\n",
      "Epoch: 127, Batch number: 24, Loss: 14305.349609375\n",
      "Epoch: 128, Batch number: 48, Loss: 13749.0927734375\n",
      "Epoch: 129, Batch number: 72, Loss: 13714.6162109375\n",
      "Epoch: 131, Batch number: 20, Loss: 13856.96484375\n",
      "Epoch: 132, Batch number: 44, Loss: 14128.2998046875\n",
      "Epoch: 133, Batch number: 68, Loss: 13912.5244140625\n",
      "Epoch: 135, Batch number: 16, Loss: 13731.01171875\n",
      "Epoch: 136, Batch number: 40, Loss: 13410.1953125\n",
      "Epoch: 137, Batch number: 64, Loss: 13508.7470703125\n",
      "Epoch: 139, Batch number: 12, Loss: 13828.42578125\n",
      "Epoch: 140, Batch number: 36, Loss: 13949.0068359375\n",
      "Epoch: 141, Batch number: 60, Loss: 13579.3671875\n",
      "Epoch: 143, Batch number: 8, Loss: 13360.8798828125\n",
      "Epoch: 144, Batch number: 32, Loss: 14082.59765625\n",
      "Epoch: 145, Batch number: 56, Loss: 13515.990234375\n",
      "Epoch: 147, Batch number: 4, Loss: 13419.3310546875\n",
      "Epoch: 148, Batch number: 28, Loss: 13862.8203125\n",
      "Epoch: 149, Batch number: 52, Loss: 13651.5712890625\n",
      "Epoch: 151, Batch number: 0, Loss: 13786.7998046875\n",
      "Epoch: 152, Batch number: 24, Loss: 13577.0830078125\n",
      "Epoch: 153, Batch number: 48, Loss: 13641.037109375\n",
      "Epoch: 154, Batch number: 72, Loss: 13855.1513671875\n",
      "Epoch: 156, Batch number: 20, Loss: 13917.07421875\n",
      "Epoch: 157, Batch number: 44, Loss: 13782.7001953125\n",
      "Epoch: 158, Batch number: 68, Loss: 13909.267578125\n",
      "Epoch: 160, Batch number: 16, Loss: 13497.73828125\n",
      "Epoch: 161, Batch number: 40, Loss: 13719.578125\n",
      "Epoch: 162, Batch number: 64, Loss: 14129.1826171875\n",
      "Epoch: 164, Batch number: 12, Loss: 13410.3740234375\n",
      "Epoch: 165, Batch number: 36, Loss: 13997.6865234375\n",
      "Epoch: 166, Batch number: 60, Loss: 13894.6650390625\n",
      "Epoch: 168, Batch number: 8, Loss: 13969.8232421875\n",
      "Epoch: 169, Batch number: 32, Loss: 13593.7841796875\n",
      "Epoch: 170, Batch number: 56, Loss: 14359.2646484375\n",
      "Epoch: 172, Batch number: 4, Loss: 13473.9443359375\n",
      "Epoch: 173, Batch number: 28, Loss: 13279.3095703125\n",
      "Epoch: 174, Batch number: 52, Loss: 13863.5693359375\n",
      "Epoch: 176, Batch number: 0, Loss: 13081.0595703125\n",
      "Epoch: 177, Batch number: 24, Loss: 13715.0673828125\n",
      "Epoch: 178, Batch number: 48, Loss: 13963.78125\n",
      "Epoch: 179, Batch number: 72, Loss: 13876.5673828125\n",
      "Epoch: 181, Batch number: 20, Loss: 14054.439453125\n",
      "Epoch: 182, Batch number: 44, Loss: 13631.7490234375\n",
      "Epoch: 183, Batch number: 68, Loss: 13355.408203125\n",
      "Epoch: 185, Batch number: 16, Loss: 13648.8095703125\n",
      "Epoch: 186, Batch number: 40, Loss: 13816.7099609375\n",
      "Epoch: 187, Batch number: 64, Loss: 14114.8798828125\n",
      "Epoch: 189, Batch number: 12, Loss: 13326.2060546875\n",
      "Epoch: 190, Batch number: 36, Loss: 13705.66015625\n",
      "Epoch: 191, Batch number: 60, Loss: 14130.2001953125\n",
      "Epoch: 193, Batch number: 8, Loss: 13345.47265625\n",
      "Epoch: 194, Batch number: 32, Loss: 13434.197265625\n",
      "Epoch: 195, Batch number: 56, Loss: 13524.1123046875\n",
      "Epoch: 197, Batch number: 4, Loss: 13921.001953125\n",
      "Epoch: 198, Batch number: 28, Loss: 13264.681640625\n",
      "Epoch: 199, Batch number: 52, Loss: 13460.060546875\n",
      "Epoch: 201, Batch number: 0, Loss: 13651.5390625\n",
      "Epoch: 202, Batch number: 24, Loss: 13829.142578125\n",
      "Epoch: 203, Batch number: 48, Loss: 13311.6953125\n",
      "Epoch: 204, Batch number: 72, Loss: 13170.306640625\n",
      "Epoch: 206, Batch number: 20, Loss: 13610.93359375\n",
      "Epoch: 207, Batch number: 44, Loss: 13910.1904296875\n",
      "Epoch: 208, Batch number: 68, Loss: 13692.6240234375\n",
      "Epoch: 210, Batch number: 16, Loss: 13148.73828125\n",
      "Epoch: 211, Batch number: 40, Loss: 13894.16796875\n",
      "Epoch: 212, Batch number: 64, Loss: 13280.0\n",
      "Epoch: 214, Batch number: 12, Loss: 13436.2900390625\n",
      "Epoch: 215, Batch number: 36, Loss: 13264.365234375\n",
      "Epoch: 216, Batch number: 60, Loss: 13638.0859375\n",
      "Epoch: 218, Batch number: 8, Loss: 13625.4755859375\n",
      "Epoch: 219, Batch number: 32, Loss: 13673.376953125\n",
      "Epoch: 220, Batch number: 56, Loss: 13492.1767578125\n",
      "Epoch: 222, Batch number: 4, Loss: 13280.4453125\n",
      "Epoch: 223, Batch number: 28, Loss: 13517.1240234375\n",
      "Epoch: 224, Batch number: 52, Loss: 13926.3603515625\n",
      "Epoch: 226, Batch number: 0, Loss: 13250.166015625\n",
      "Epoch: 227, Batch number: 24, Loss: 13383.21875\n",
      "Epoch: 228, Batch number: 48, Loss: 13722.6650390625\n",
      "Epoch: 229, Batch number: 72, Loss: 13851.583984375\n",
      "Epoch: 231, Batch number: 20, Loss: 13340.8251953125\n",
      "Epoch: 232, Batch number: 44, Loss: 13439.5\n",
      "Epoch: 233, Batch number: 68, Loss: 13898.4072265625\n",
      "Epoch: 235, Batch number: 16, Loss: 13456.5634765625\n",
      "Epoch: 236, Batch number: 40, Loss: 13531.5283203125\n",
      "Epoch: 237, Batch number: 64, Loss: 13692.056640625\n",
      "Epoch: 239, Batch number: 12, Loss: 13661.375\n",
      "Epoch: 240, Batch number: 36, Loss: 13541.7880859375\n",
      "Epoch: 241, Batch number: 60, Loss: 13739.1318359375\n",
      "Epoch: 243, Batch number: 8, Loss: 13426.8916015625\n",
      "Epoch: 244, Batch number: 32, Loss: 13290.5166015625\n",
      "Epoch: 245, Batch number: 56, Loss: 13711.0166015625\n",
      "Epoch: 247, Batch number: 4, Loss: 13945.69921875\n",
      "Epoch: 248, Batch number: 28, Loss: 13227.037109375\n",
      "Epoch: 249, Batch number: 52, Loss: 13340.7294921875\n",
      "Epoch: 251, Batch number: 0, Loss: 13574.0869140625\n",
      "Epoch: 252, Batch number: 24, Loss: 13938.3974609375\n",
      "Epoch: 253, Batch number: 48, Loss: 14126.083984375\n",
      "Epoch: 254, Batch number: 72, Loss: 13506.0478515625\n",
      "Epoch: 256, Batch number: 20, Loss: 13150.81640625\n",
      "Epoch: 257, Batch number: 44, Loss: 13803.82421875\n",
      "Epoch: 258, Batch number: 68, Loss: 13628.6708984375\n",
      "Epoch: 260, Batch number: 16, Loss: 13639.7607421875\n",
      "Epoch: 261, Batch number: 40, Loss: 13453.36328125\n",
      "Epoch: 262, Batch number: 64, Loss: 13373.6513671875\n",
      "Epoch: 264, Batch number: 12, Loss: 13602.8857421875\n",
      "Epoch: 265, Batch number: 36, Loss: 13200.970703125\n",
      "Epoch: 266, Batch number: 60, Loss: 13574.7080078125\n",
      "Epoch: 268, Batch number: 8, Loss: 13372.5712890625\n",
      "Epoch: 269, Batch number: 32, Loss: 13791.791015625\n",
      "Epoch: 270, Batch number: 56, Loss: 13601.7021484375\n",
      "Epoch: 272, Batch number: 4, Loss: 13657.583984375\n",
      "Epoch: 273, Batch number: 28, Loss: 13793.3125\n",
      "Epoch: 274, Batch number: 52, Loss: 13842.9052734375\n",
      "Epoch: 276, Batch number: 0, Loss: 13326.6396484375\n",
      "Epoch: 277, Batch number: 24, Loss: 13098.236328125\n",
      "Epoch: 278, Batch number: 48, Loss: 13435.373046875\n",
      "Epoch: 279, Batch number: 72, Loss: 13353.388671875\n",
      "Epoch: 281, Batch number: 20, Loss: 13613.16796875\n",
      "Epoch: 282, Batch number: 44, Loss: 13219.9794921875\n",
      "Epoch: 283, Batch number: 68, Loss: 13566.947265625\n",
      "Epoch: 285, Batch number: 16, Loss: 13658.8681640625\n",
      "Epoch: 286, Batch number: 40, Loss: 13525.20703125\n",
      "Epoch: 287, Batch number: 64, Loss: 13893.166015625\n",
      "Epoch: 289, Batch number: 12, Loss: 13661.03515625\n",
      "Epoch: 290, Batch number: 36, Loss: 12873.4638671875\n",
      "Epoch: 291, Batch number: 60, Loss: 13767.2568359375\n",
      "Epoch: 293, Batch number: 8, Loss: 13392.0283203125\n",
      "Epoch: 294, Batch number: 32, Loss: 13417.2890625\n",
      "Epoch: 295, Batch number: 56, Loss: 13954.8740234375\n",
      "Epoch: 297, Batch number: 4, Loss: 13128.2236328125\n",
      "Epoch: 298, Batch number: 28, Loss: 13767.6962890625\n",
      "Epoch: 299, Batch number: 52, Loss: 13792.4873046875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 26964.8515625\n",
      "Epoch: 2, Batch number: 24, Loss: 24349.87109375\n",
      "Epoch: 3, Batch number: 48, Loss: 22843.26171875\n",
      "Epoch: 4, Batch number: 72, Loss: 21870.65625\n",
      "Epoch: 6, Batch number: 20, Loss: 20361.875\n",
      "Epoch: 7, Batch number: 44, Loss: 19884.900390625\n",
      "Epoch: 8, Batch number: 68, Loss: 19499.068359375\n",
      "Epoch: 10, Batch number: 16, Loss: 17781.658203125\n",
      "Epoch: 11, Batch number: 40, Loss: 17697.7265625\n",
      "Epoch: 12, Batch number: 64, Loss: 17400.599609375\n",
      "Epoch: 14, Batch number: 12, Loss: 16583.44921875\n",
      "Epoch: 15, Batch number: 36, Loss: 16825.767578125\n",
      "Epoch: 16, Batch number: 60, Loss: 16738.478515625\n",
      "Epoch: 18, Batch number: 8, Loss: 16499.345703125\n",
      "Epoch: 19, Batch number: 32, Loss: 16058.798828125\n",
      "Epoch: 20, Batch number: 56, Loss: 16012.3203125\n",
      "Epoch: 22, Batch number: 4, Loss: 15518.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Batch number: 28, Loss: 15423.177734375\n",
      "Epoch: 24, Batch number: 52, Loss: 15577.7978515625\n",
      "Epoch: 26, Batch number: 0, Loss: 15248.087890625\n",
      "Epoch: 27, Batch number: 24, Loss: 15080.1474609375\n",
      "Epoch: 28, Batch number: 48, Loss: 15128.162109375\n",
      "Epoch: 29, Batch number: 72, Loss: 15399.85546875\n",
      "Epoch: 31, Batch number: 20, Loss: 14881.3017578125\n",
      "Epoch: 32, Batch number: 44, Loss: 15112.5302734375\n",
      "Epoch: 33, Batch number: 68, Loss: 14794.3408203125\n",
      "Epoch: 35, Batch number: 16, Loss: 15195.9267578125\n",
      "Epoch: 36, Batch number: 40, Loss: 14920.0419921875\n",
      "Epoch: 37, Batch number: 64, Loss: 15060.4833984375\n",
      "Epoch: 39, Batch number: 12, Loss: 14538.0712890625\n",
      "Epoch: 40, Batch number: 36, Loss: 14823.2626953125\n",
      "Epoch: 41, Batch number: 60, Loss: 14857.0322265625\n",
      "Epoch: 43, Batch number: 8, Loss: 14619.412109375\n",
      "Epoch: 44, Batch number: 32, Loss: 14642.869140625\n",
      "Epoch: 45, Batch number: 56, Loss: 14484.060546875\n",
      "Epoch: 47, Batch number: 4, Loss: 14670.509765625\n",
      "Epoch: 48, Batch number: 28, Loss: 14447.390625\n",
      "Epoch: 49, Batch number: 52, Loss: 14928.5439453125\n",
      "Epoch: 51, Batch number: 0, Loss: 14209.7080078125\n",
      "Epoch: 52, Batch number: 24, Loss: 14746.998046875\n",
      "Epoch: 53, Batch number: 48, Loss: 14283.783203125\n",
      "Epoch: 54, Batch number: 72, Loss: 14671.59375\n",
      "Epoch: 56, Batch number: 20, Loss: 14521.5517578125\n",
      "Epoch: 57, Batch number: 44, Loss: 14290.3037109375\n",
      "Epoch: 58, Batch number: 68, Loss: 14678.560546875\n",
      "Epoch: 60, Batch number: 16, Loss: 14124.3115234375\n",
      "Epoch: 61, Batch number: 40, Loss: 14049.8798828125\n",
      "Epoch: 62, Batch number: 64, Loss: 14266.3203125\n",
      "Epoch: 64, Batch number: 12, Loss: 13965.3115234375\n",
      "Epoch: 65, Batch number: 36, Loss: 13953.9375\n",
      "Epoch: 66, Batch number: 60, Loss: 14130.087890625\n",
      "Epoch: 68, Batch number: 8, Loss: 13824.2138671875\n",
      "Epoch: 69, Batch number: 32, Loss: 13675.8017578125\n",
      "Epoch: 70, Batch number: 56, Loss: 13650.3955078125\n",
      "Epoch: 72, Batch number: 4, Loss: 13635.2265625\n",
      "Epoch: 73, Batch number: 28, Loss: 14128.7822265625\n",
      "Epoch: 74, Batch number: 52, Loss: 14033.7041015625\n",
      "Epoch: 76, Batch number: 0, Loss: 13888.6884765625\n",
      "Epoch: 77, Batch number: 24, Loss: 13836.703125\n",
      "Epoch: 78, Batch number: 48, Loss: 13795.400390625\n",
      "Epoch: 79, Batch number: 72, Loss: 14104.060546875\n",
      "Epoch: 81, Batch number: 20, Loss: 13645.3583984375\n",
      "Epoch: 82, Batch number: 44, Loss: 13851.7734375\n",
      "Epoch: 83, Batch number: 68, Loss: 14026.1552734375\n",
      "Epoch: 85, Batch number: 16, Loss: 14129.16015625\n",
      "Epoch: 86, Batch number: 40, Loss: 14117.2861328125\n",
      "Epoch: 87, Batch number: 64, Loss: 13897.0224609375\n",
      "Epoch: 89, Batch number: 12, Loss: 13988.73046875\n",
      "Epoch: 90, Batch number: 36, Loss: 13498.365234375\n",
      "Epoch: 91, Batch number: 60, Loss: 14234.4306640625\n",
      "Epoch: 93, Batch number: 8, Loss: 14105.154296875\n",
      "Epoch: 94, Batch number: 32, Loss: 13940.677734375\n",
      "Epoch: 95, Batch number: 56, Loss: 13509.9814453125\n",
      "Epoch: 97, Batch number: 4, Loss: 13541.7744140625\n",
      "Epoch: 98, Batch number: 28, Loss: 13712.697265625\n",
      "Epoch: 99, Batch number: 52, Loss: 13810.0078125\n",
      "Epoch: 101, Batch number: 0, Loss: 14000.986328125\n",
      "Epoch: 102, Batch number: 24, Loss: 13583.78125\n",
      "Epoch: 103, Batch number: 48, Loss: 13544.4375\n",
      "Epoch: 104, Batch number: 72, Loss: 13928.05078125\n",
      "Epoch: 106, Batch number: 20, Loss: 13629.3251953125\n",
      "Epoch: 107, Batch number: 44, Loss: 14027.0078125\n",
      "Epoch: 108, Batch number: 68, Loss: 13816.78125\n",
      "Epoch: 110, Batch number: 16, Loss: 13607.9873046875\n",
      "Epoch: 111, Batch number: 40, Loss: 13929.287109375\n",
      "Epoch: 112, Batch number: 64, Loss: 13775.44140625\n",
      "Epoch: 114, Batch number: 12, Loss: 13750.7109375\n",
      "Epoch: 115, Batch number: 36, Loss: 13980.560546875\n",
      "Epoch: 116, Batch number: 60, Loss: 13698.85546875\n",
      "Epoch: 118, Batch number: 8, Loss: 13546.751953125\n",
      "Epoch: 119, Batch number: 32, Loss: 13746.9365234375\n",
      "Epoch: 120, Batch number: 56, Loss: 14033.1123046875\n",
      "Epoch: 122, Batch number: 4, Loss: 12769.8427734375\n",
      "Epoch: 123, Batch number: 28, Loss: 13321.92578125\n",
      "Epoch: 124, Batch number: 52, Loss: 14116.361328125\n",
      "Epoch: 126, Batch number: 0, Loss: 13686.953125\n",
      "Epoch: 127, Batch number: 24, Loss: 13241.580078125\n",
      "Epoch: 128, Batch number: 48, Loss: 14121.357421875\n",
      "Epoch: 129, Batch number: 72, Loss: 13949.39453125\n",
      "Epoch: 131, Batch number: 20, Loss: 13536.8828125\n",
      "Epoch: 132, Batch number: 44, Loss: 13804.2021484375\n",
      "Epoch: 133, Batch number: 68, Loss: 13915.12890625\n",
      "Epoch: 135, Batch number: 16, Loss: 13455.7919921875\n",
      "Epoch: 136, Batch number: 40, Loss: 13560.5537109375\n",
      "Epoch: 137, Batch number: 64, Loss: 13915.9794921875\n",
      "Epoch: 139, Batch number: 12, Loss: 13535.1806640625\n",
      "Epoch: 140, Batch number: 36, Loss: 13522.7138671875\n",
      "Epoch: 141, Batch number: 60, Loss: 13842.09375\n",
      "Epoch: 143, Batch number: 8, Loss: 13453.6435546875\n",
      "Epoch: 144, Batch number: 32, Loss: 13619.724609375\n",
      "Epoch: 145, Batch number: 56, Loss: 13386.7880859375\n",
      "Epoch: 147, Batch number: 4, Loss: 13289.8515625\n",
      "Epoch: 148, Batch number: 28, Loss: 13457.1572265625\n",
      "Epoch: 149, Batch number: 52, Loss: 13528.5947265625\n",
      "Epoch: 151, Batch number: 0, Loss: 13420.8564453125\n",
      "Epoch: 152, Batch number: 24, Loss: 13236.08984375\n",
      "Epoch: 153, Batch number: 48, Loss: 13412.5654296875\n",
      "Epoch: 154, Batch number: 72, Loss: 13774.7353515625\n",
      "Epoch: 156, Batch number: 20, Loss: 13475.7529296875\n",
      "Epoch: 157, Batch number: 44, Loss: 13731.0751953125\n",
      "Epoch: 158, Batch number: 68, Loss: 13492.1171875\n",
      "Epoch: 160, Batch number: 16, Loss: 13533.904296875\n",
      "Epoch: 161, Batch number: 40, Loss: 13572.0361328125\n",
      "Epoch: 162, Batch number: 64, Loss: 13569.0341796875\n",
      "Epoch: 164, Batch number: 12, Loss: 13403.0625\n",
      "Epoch: 165, Batch number: 36, Loss: 13214.6875\n",
      "Epoch: 166, Batch number: 60, Loss: 13578.5556640625\n",
      "Epoch: 168, Batch number: 8, Loss: 13165.0849609375\n",
      "Epoch: 169, Batch number: 32, Loss: 13674.3369140625\n",
      "Epoch: 170, Batch number: 56, Loss: 13467.75390625\n",
      "Epoch: 172, Batch number: 4, Loss: 13457.8955078125\n",
      "Epoch: 173, Batch number: 28, Loss: 13645.9150390625\n",
      "Epoch: 174, Batch number: 52, Loss: 13527.6884765625\n",
      "Epoch: 176, Batch number: 0, Loss: 13513.72265625\n",
      "Epoch: 177, Batch number: 24, Loss: 13767.333984375\n",
      "Epoch: 178, Batch number: 48, Loss: 13867.6220703125\n",
      "Epoch: 179, Batch number: 72, Loss: 13622.251953125\n",
      "Epoch: 181, Batch number: 20, Loss: 13614.6708984375\n",
      "Epoch: 182, Batch number: 44, Loss: 13404.615234375\n",
      "Epoch: 183, Batch number: 68, Loss: 13699.6005859375\n",
      "Epoch: 185, Batch number: 16, Loss: 13837.4453125\n",
      "Epoch: 186, Batch number: 40, Loss: 13481.625\n",
      "Epoch: 187, Batch number: 64, Loss: 13737.8583984375\n",
      "Epoch: 189, Batch number: 12, Loss: 13275.6865234375\n",
      "Epoch: 190, Batch number: 36, Loss: 14099.9765625\n",
      "Epoch: 191, Batch number: 60, Loss: 13535.0576171875\n",
      "Epoch: 193, Batch number: 8, Loss: 13340.912109375\n",
      "Epoch: 194, Batch number: 32, Loss: 13749.4306640625\n",
      "Epoch: 195, Batch number: 56, Loss: 13853.2490234375\n",
      "Epoch: 197, Batch number: 4, Loss: 13133.8125\n",
      "Epoch: 198, Batch number: 28, Loss: 14002.765625\n",
      "Epoch: 199, Batch number: 52, Loss: 14116.439453125\n",
      "Epoch: 201, Batch number: 0, Loss: 13349.9873046875\n",
      "Epoch: 202, Batch number: 24, Loss: 13214.291015625\n",
      "Epoch: 203, Batch number: 48, Loss: 13873.7158203125\n",
      "Epoch: 204, Batch number: 72, Loss: 13432.5390625\n",
      "Epoch: 206, Batch number: 20, Loss: 13936.1513671875\n",
      "Epoch: 207, Batch number: 44, Loss: 13569.767578125\n",
      "Epoch: 208, Batch number: 68, Loss: 13741.6044921875\n",
      "Epoch: 210, Batch number: 16, Loss: 13295.3427734375\n",
      "Epoch: 211, Batch number: 40, Loss: 13246.2080078125\n",
      "Epoch: 212, Batch number: 64, Loss: 13727.9580078125\n",
      "Epoch: 214, Batch number: 12, Loss: 13432.8427734375\n",
      "Epoch: 215, Batch number: 36, Loss: 13631.779296875\n",
      "Epoch: 216, Batch number: 60, Loss: 13363.681640625\n",
      "Epoch: 218, Batch number: 8, Loss: 13571.873046875\n",
      "Epoch: 219, Batch number: 32, Loss: 13823.8232421875\n",
      "Epoch: 220, Batch number: 56, Loss: 13574.1552734375\n",
      "Epoch: 222, Batch number: 4, Loss: 13096.19140625\n",
      "Epoch: 223, Batch number: 28, Loss: 13612.5634765625\n",
      "Epoch: 224, Batch number: 52, Loss: 13361.1904296875\n",
      "Epoch: 226, Batch number: 0, Loss: 13418.4111328125\n",
      "Epoch: 227, Batch number: 24, Loss: 13376.59765625\n",
      "Epoch: 228, Batch number: 48, Loss: 13981.2890625\n",
      "Epoch: 229, Batch number: 72, Loss: 13673.6201171875\n",
      "Epoch: 231, Batch number: 20, Loss: 13564.8720703125\n",
      "Epoch: 232, Batch number: 44, Loss: 13878.724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 233, Batch number: 68, Loss: 13697.8740234375\n",
      "Epoch: 235, Batch number: 16, Loss: 13734.6796875\n",
      "Epoch: 236, Batch number: 40, Loss: 13750.5244140625\n",
      "Epoch: 237, Batch number: 64, Loss: 13363.84765625\n",
      "Epoch: 239, Batch number: 12, Loss: 13542.826171875\n",
      "Epoch: 240, Batch number: 36, Loss: 13640.4111328125\n",
      "Epoch: 241, Batch number: 60, Loss: 13511.138671875\n",
      "Epoch: 243, Batch number: 8, Loss: 13917.951171875\n",
      "Epoch: 244, Batch number: 32, Loss: 13512.75\n",
      "Epoch: 245, Batch number: 56, Loss: 13636.3876953125\n",
      "Epoch: 247, Batch number: 4, Loss: 13655.7138671875\n",
      "Epoch: 248, Batch number: 28, Loss: 13861.22265625\n",
      "Epoch: 249, Batch number: 52, Loss: 13657.7734375\n",
      "Epoch: 251, Batch number: 0, Loss: 13560.4296875\n",
      "Epoch: 252, Batch number: 24, Loss: 13373.5927734375\n",
      "Epoch: 253, Batch number: 48, Loss: 13870.916015625\n",
      "Epoch: 254, Batch number: 72, Loss: 13581.9375\n",
      "Epoch: 256, Batch number: 20, Loss: 13132.15234375\n",
      "Epoch: 257, Batch number: 44, Loss: 14150.177734375\n",
      "Epoch: 258, Batch number: 68, Loss: 13472.2080078125\n",
      "Epoch: 260, Batch number: 16, Loss: 13479.7568359375\n",
      "Epoch: 261, Batch number: 40, Loss: 13839.38671875\n",
      "Epoch: 262, Batch number: 64, Loss: 13601.7255859375\n",
      "Epoch: 264, Batch number: 12, Loss: 13337.0810546875\n",
      "Epoch: 265, Batch number: 36, Loss: 13987.4853515625\n",
      "Epoch: 266, Batch number: 60, Loss: 13530.712890625\n",
      "Epoch: 268, Batch number: 8, Loss: 13660.541015625\n",
      "Epoch: 269, Batch number: 32, Loss: 13342.939453125\n",
      "Epoch: 270, Batch number: 56, Loss: 13730.6728515625\n",
      "Epoch: 272, Batch number: 4, Loss: 13279.09765625\n",
      "Epoch: 273, Batch number: 28, Loss: 13701.0927734375\n",
      "Epoch: 274, Batch number: 52, Loss: 13283.560546875\n",
      "Epoch: 276, Batch number: 0, Loss: 13380.4013671875\n",
      "Epoch: 277, Batch number: 24, Loss: 13321.78125\n",
      "Epoch: 278, Batch number: 48, Loss: 13558.744140625\n",
      "Epoch: 279, Batch number: 72, Loss: 13515.8876953125\n",
      "Epoch: 281, Batch number: 20, Loss: 13646.107421875\n",
      "Epoch: 282, Batch number: 44, Loss: 13569.640625\n",
      "Epoch: 283, Batch number: 68, Loss: 13926.4453125\n",
      "Epoch: 285, Batch number: 16, Loss: 13397.392578125\n",
      "Epoch: 286, Batch number: 40, Loss: 13826.9267578125\n",
      "Epoch: 287, Batch number: 64, Loss: 13782.607421875\n",
      "Epoch: 289, Batch number: 12, Loss: 13448.47265625\n",
      "Epoch: 290, Batch number: 36, Loss: 13036.173828125\n",
      "Epoch: 291, Batch number: 60, Loss: 14012.4560546875\n",
      "Epoch: 293, Batch number: 8, Loss: 13816.9814453125\n",
      "Epoch: 294, Batch number: 32, Loss: 13348.091796875\n",
      "Epoch: 295, Batch number: 56, Loss: 14020.099609375\n",
      "Epoch: 297, Batch number: 4, Loss: 13187.587890625\n",
      "Epoch: 298, Batch number: 28, Loss: 14390.458984375\n",
      "Epoch: 299, Batch number: 52, Loss: 13505.3896484375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 27004.9921875\n",
      "Epoch: 2, Batch number: 24, Loss: 24157.318359375\n",
      "Epoch: 3, Batch number: 48, Loss: 22274.099609375\n",
      "Epoch: 4, Batch number: 72, Loss: 21173.267578125\n",
      "Epoch: 6, Batch number: 20, Loss: 19537.232421875\n",
      "Epoch: 7, Batch number: 44, Loss: 18940.521484375\n",
      "Epoch: 8, Batch number: 68, Loss: 17854.734375\n",
      "Epoch: 10, Batch number: 16, Loss: 17410.328125\n",
      "Epoch: 11, Batch number: 40, Loss: 17221.91796875\n",
      "Epoch: 12, Batch number: 64, Loss: 16811.791015625\n",
      "Epoch: 14, Batch number: 12, Loss: 16446.10546875\n",
      "Epoch: 15, Batch number: 36, Loss: 16106.330078125\n",
      "Epoch: 16, Batch number: 60, Loss: 16209.0673828125\n",
      "Epoch: 18, Batch number: 8, Loss: 15224.44140625\n",
      "Epoch: 19, Batch number: 32, Loss: 15186.9580078125\n",
      "Epoch: 20, Batch number: 56, Loss: 15475.705078125\n",
      "Epoch: 22, Batch number: 4, Loss: 15369.60546875\n",
      "Epoch: 23, Batch number: 28, Loss: 14785.6650390625\n",
      "Epoch: 24, Batch number: 52, Loss: 15047.57421875\n",
      "Epoch: 26, Batch number: 0, Loss: 14867.900390625\n",
      "Epoch: 27, Batch number: 24, Loss: 14884.517578125\n",
      "Epoch: 28, Batch number: 48, Loss: 14983.2333984375\n",
      "Epoch: 29, Batch number: 72, Loss: 15385.5634765625\n",
      "Epoch: 31, Batch number: 20, Loss: 14602.125\n",
      "Epoch: 32, Batch number: 44, Loss: 14818.3359375\n",
      "Epoch: 33, Batch number: 68, Loss: 14984.6904296875\n",
      "Epoch: 35, Batch number: 16, Loss: 14687.412109375\n",
      "Epoch: 36, Batch number: 40, Loss: 14762.6494140625\n",
      "Epoch: 37, Batch number: 64, Loss: 14575.060546875\n",
      "Epoch: 39, Batch number: 12, Loss: 14218.9990234375\n",
      "Epoch: 40, Batch number: 36, Loss: 14389.9189453125\n",
      "Epoch: 41, Batch number: 60, Loss: 14396.3369140625\n",
      "Epoch: 43, Batch number: 8, Loss: 14465.1484375\n",
      "Epoch: 44, Batch number: 32, Loss: 14282.138671875\n",
      "Epoch: 45, Batch number: 56, Loss: 14796.3447265625\n",
      "Epoch: 47, Batch number: 4, Loss: 14191.2060546875\n",
      "Epoch: 48, Batch number: 28, Loss: 14140.9248046875\n",
      "Epoch: 49, Batch number: 52, Loss: 14630.5322265625\n",
      "Epoch: 51, Batch number: 0, Loss: 13711.1171875\n",
      "Epoch: 52, Batch number: 24, Loss: 14052.7734375\n",
      "Epoch: 53, Batch number: 48, Loss: 13879.71484375\n",
      "Epoch: 54, Batch number: 72, Loss: 14051.78125\n",
      "Epoch: 56, Batch number: 20, Loss: 14048.654296875\n",
      "Epoch: 57, Batch number: 44, Loss: 14311.576171875\n",
      "Epoch: 58, Batch number: 68, Loss: 14288.5712890625\n",
      "Epoch: 60, Batch number: 16, Loss: 13802.103515625\n",
      "Epoch: 61, Batch number: 40, Loss: 13961.25390625\n",
      "Epoch: 62, Batch number: 64, Loss: 13969.6689453125\n",
      "Epoch: 64, Batch number: 12, Loss: 13927.9951171875\n",
      "Epoch: 65, Batch number: 36, Loss: 14066.8994140625\n",
      "Epoch: 66, Batch number: 60, Loss: 14194.3076171875\n",
      "Epoch: 68, Batch number: 8, Loss: 13904.5029296875\n",
      "Epoch: 69, Batch number: 32, Loss: 13579.6875\n",
      "Epoch: 70, Batch number: 56, Loss: 14226.28125\n",
      "Epoch: 72, Batch number: 4, Loss: 13334.1845703125\n",
      "Epoch: 73, Batch number: 28, Loss: 13713.0185546875\n",
      "Epoch: 74, Batch number: 52, Loss: 13979.6240234375\n",
      "Epoch: 76, Batch number: 0, Loss: 13136.0087890625\n",
      "Epoch: 77, Batch number: 24, Loss: 13886.4794921875\n",
      "Epoch: 78, Batch number: 48, Loss: 13892.64453125\n",
      "Epoch: 79, Batch number: 72, Loss: 14109.6904296875\n",
      "Epoch: 81, Batch number: 20, Loss: 13188.0009765625\n",
      "Epoch: 82, Batch number: 44, Loss: 14358.087890625\n",
      "Epoch: 83, Batch number: 68, Loss: 13815.6044921875\n",
      "Epoch: 85, Batch number: 16, Loss: 14056.12890625\n",
      "Epoch: 86, Batch number: 40, Loss: 14351.1025390625\n",
      "Epoch: 87, Batch number: 64, Loss: 13910.357421875\n",
      "Epoch: 89, Batch number: 12, Loss: 13524.646484375\n",
      "Epoch: 90, Batch number: 36, Loss: 13920.3828125\n",
      "Epoch: 91, Batch number: 60, Loss: 14177.8896484375\n",
      "Epoch: 93, Batch number: 8, Loss: 13877.6005859375\n",
      "Epoch: 94, Batch number: 32, Loss: 13864.6181640625\n",
      "Epoch: 95, Batch number: 56, Loss: 13772.685546875\n",
      "Epoch: 97, Batch number: 4, Loss: 13581.47265625\n",
      "Epoch: 98, Batch number: 28, Loss: 13408.716796875\n",
      "Epoch: 99, Batch number: 52, Loss: 14325.1318359375\n",
      "Epoch: 101, Batch number: 0, Loss: 13538.1748046875\n",
      "Epoch: 102, Batch number: 24, Loss: 13381.8291015625\n",
      "Epoch: 103, Batch number: 48, Loss: 13963.880859375\n",
      "Epoch: 104, Batch number: 72, Loss: 14107.0283203125\n",
      "Epoch: 106, Batch number: 20, Loss: 13572.2216796875\n",
      "Epoch: 107, Batch number: 44, Loss: 13536.9541015625\n",
      "Epoch: 108, Batch number: 68, Loss: 13718.919921875\n",
      "Epoch: 110, Batch number: 16, Loss: 13749.8955078125\n",
      "Epoch: 111, Batch number: 40, Loss: 13635.896484375\n",
      "Epoch: 112, Batch number: 64, Loss: 13947.4609375\n",
      "Epoch: 114, Batch number: 12, Loss: 13800.623046875\n",
      "Epoch: 115, Batch number: 36, Loss: 13377.34375\n",
      "Epoch: 116, Batch number: 60, Loss: 13657.3037109375\n",
      "Epoch: 118, Batch number: 8, Loss: 13344.0888671875\n",
      "Epoch: 119, Batch number: 32, Loss: 14144.2197265625\n",
      "Epoch: 120, Batch number: 56, Loss: 13397.158203125\n",
      "Epoch: 122, Batch number: 4, Loss: 13435.3818359375\n",
      "Epoch: 123, Batch number: 28, Loss: 13226.033203125\n",
      "Epoch: 124, Batch number: 52, Loss: 13658.70703125\n",
      "Epoch: 126, Batch number: 0, Loss: 13764.86328125\n",
      "Epoch: 127, Batch number: 24, Loss: 13538.3388671875\n",
      "Epoch: 128, Batch number: 48, Loss: 14268.0068359375\n",
      "Epoch: 129, Batch number: 72, Loss: 13946.349609375\n",
      "Epoch: 131, Batch number: 20, Loss: 13618.998046875\n",
      "Epoch: 132, Batch number: 44, Loss: 13907.966796875\n",
      "Epoch: 133, Batch number: 68, Loss: 13581.36328125\n",
      "Epoch: 135, Batch number: 16, Loss: 13656.517578125\n",
      "Epoch: 136, Batch number: 40, Loss: 13636.564453125\n",
      "Epoch: 137, Batch number: 64, Loss: 13843.2861328125\n",
      "Epoch: 139, Batch number: 12, Loss: 13801.94140625\n",
      "Epoch: 140, Batch number: 36, Loss: 13747.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141, Batch number: 60, Loss: 13793.0458984375\n",
      "Epoch: 143, Batch number: 8, Loss: 13135.2119140625\n",
      "Epoch: 144, Batch number: 32, Loss: 13578.787109375\n",
      "Epoch: 145, Batch number: 56, Loss: 13722.7705078125\n",
      "Epoch: 147, Batch number: 4, Loss: 13532.6630859375\n",
      "Epoch: 148, Batch number: 28, Loss: 13926.2138671875\n",
      "Epoch: 149, Batch number: 52, Loss: 13950.552734375\n",
      "Epoch: 151, Batch number: 0, Loss: 13405.1015625\n",
      "Epoch: 152, Batch number: 24, Loss: 13556.8154296875\n",
      "Epoch: 153, Batch number: 48, Loss: 13677.3349609375\n",
      "Epoch: 154, Batch number: 72, Loss: 13528.30859375\n",
      "Epoch: 156, Batch number: 20, Loss: 13264.16796875\n",
      "Epoch: 157, Batch number: 44, Loss: 13586.35546875\n",
      "Epoch: 158, Batch number: 68, Loss: 13697.7978515625\n",
      "Epoch: 160, Batch number: 16, Loss: 13285.482421875\n",
      "Epoch: 161, Batch number: 40, Loss: 13598.28125\n",
      "Epoch: 162, Batch number: 64, Loss: 13382.13671875\n",
      "Epoch: 164, Batch number: 12, Loss: 13458.658203125\n",
      "Epoch: 165, Batch number: 36, Loss: 13391.123046875\n",
      "Epoch: 166, Batch number: 60, Loss: 13960.646484375\n",
      "Epoch: 168, Batch number: 8, Loss: 13415.412109375\n",
      "Epoch: 169, Batch number: 32, Loss: 13666.2080078125\n",
      "Epoch: 170, Batch number: 56, Loss: 13942.4384765625\n",
      "Epoch: 172, Batch number: 4, Loss: 13390.943359375\n",
      "Epoch: 173, Batch number: 28, Loss: 13401.6083984375\n",
      "Epoch: 174, Batch number: 52, Loss: 13373.5224609375\n",
      "Epoch: 176, Batch number: 0, Loss: 13252.62890625\n",
      "Epoch: 177, Batch number: 24, Loss: 13863.865234375\n",
      "Epoch: 178, Batch number: 48, Loss: 13426.3955078125\n",
      "Epoch: 179, Batch number: 72, Loss: 13698.5302734375\n",
      "Epoch: 181, Batch number: 20, Loss: 13141.6279296875\n",
      "Epoch: 182, Batch number: 44, Loss: 13639.708984375\n",
      "Epoch: 183, Batch number: 68, Loss: 13799.7265625\n",
      "Epoch: 185, Batch number: 16, Loss: 13507.6689453125\n",
      "Epoch: 186, Batch number: 40, Loss: 13413.2255859375\n",
      "Epoch: 187, Batch number: 64, Loss: 14013.5791015625\n",
      "Epoch: 189, Batch number: 12, Loss: 13424.6689453125\n",
      "Epoch: 190, Batch number: 36, Loss: 13826.0947265625\n",
      "Epoch: 191, Batch number: 60, Loss: 13419.3251953125\n",
      "Epoch: 193, Batch number: 8, Loss: 13410.365234375\n",
      "Epoch: 194, Batch number: 32, Loss: 13832.97265625\n",
      "Epoch: 195, Batch number: 56, Loss: 13545.9130859375\n",
      "Epoch: 197, Batch number: 4, Loss: 13427.1962890625\n",
      "Epoch: 198, Batch number: 28, Loss: 13732.6044921875\n",
      "Epoch: 199, Batch number: 52, Loss: 13578.7236328125\n",
      "Epoch: 201, Batch number: 0, Loss: 13472.8876953125\n",
      "Epoch: 202, Batch number: 24, Loss: 13391.2255859375\n",
      "Epoch: 203, Batch number: 48, Loss: 14122.173828125\n",
      "Epoch: 204, Batch number: 72, Loss: 13650.076171875\n",
      "Epoch: 206, Batch number: 20, Loss: 13298.7021484375\n",
      "Epoch: 207, Batch number: 44, Loss: 14074.0322265625\n",
      "Epoch: 208, Batch number: 68, Loss: 13953.4892578125\n",
      "Epoch: 210, Batch number: 16, Loss: 13520.7548828125\n",
      "Epoch: 211, Batch number: 40, Loss: 13531.2255859375\n",
      "Epoch: 212, Batch number: 64, Loss: 13744.19921875\n",
      "Epoch: 214, Batch number: 12, Loss: 13297.5478515625\n",
      "Epoch: 215, Batch number: 36, Loss: 13441.326171875\n",
      "Epoch: 216, Batch number: 60, Loss: 13628.1845703125\n",
      "Epoch: 218, Batch number: 8, Loss: 13315.3525390625\n",
      "Epoch: 219, Batch number: 32, Loss: 13674.638671875\n",
      "Epoch: 220, Batch number: 56, Loss: 14130.599609375\n",
      "Epoch: 222, Batch number: 4, Loss: 13307.3369140625\n",
      "Epoch: 223, Batch number: 28, Loss: 13632.697265625\n",
      "Epoch: 224, Batch number: 52, Loss: 13390.4501953125\n",
      "Epoch: 226, Batch number: 0, Loss: 13520.916015625\n",
      "Epoch: 227, Batch number: 24, Loss: 14005.263671875\n",
      "Epoch: 228, Batch number: 48, Loss: 13749.30078125\n",
      "Epoch: 229, Batch number: 72, Loss: 13562.431640625\n",
      "Epoch: 231, Batch number: 20, Loss: 13120.03515625\n",
      "Epoch: 232, Batch number: 44, Loss: 13692.2236328125\n",
      "Epoch: 233, Batch number: 68, Loss: 13810.5576171875\n",
      "Epoch: 235, Batch number: 16, Loss: 13586.748046875\n",
      "Epoch: 236, Batch number: 40, Loss: 13393.291015625\n",
      "Epoch: 237, Batch number: 64, Loss: 13891.0927734375\n",
      "Epoch: 239, Batch number: 12, Loss: 13175.73046875\n",
      "Epoch: 240, Batch number: 36, Loss: 13978.7861328125\n",
      "Epoch: 241, Batch number: 60, Loss: 13419.794921875\n",
      "Epoch: 243, Batch number: 8, Loss: 13691.462890625\n",
      "Epoch: 244, Batch number: 32, Loss: 13750.197265625\n",
      "Epoch: 245, Batch number: 56, Loss: 13798.9609375\n",
      "Epoch: 247, Batch number: 4, Loss: 13369.3701171875\n",
      "Epoch: 248, Batch number: 28, Loss: 13615.498046875\n",
      "Epoch: 249, Batch number: 52, Loss: 13965.7080078125\n",
      "Epoch: 251, Batch number: 0, Loss: 13096.8359375\n",
      "Epoch: 252, Batch number: 24, Loss: 13638.9892578125\n",
      "Epoch: 253, Batch number: 48, Loss: 13389.560546875\n",
      "Epoch: 254, Batch number: 72, Loss: 13546.8828125\n",
      "Epoch: 256, Batch number: 20, Loss: 13425.8935546875\n",
      "Epoch: 257, Batch number: 44, Loss: 13583.837890625\n",
      "Epoch: 258, Batch number: 68, Loss: 13495.9208984375\n",
      "Epoch: 260, Batch number: 16, Loss: 13317.0263671875\n",
      "Epoch: 261, Batch number: 40, Loss: 13407.6142578125\n",
      "Epoch: 262, Batch number: 64, Loss: 13794.1796875\n",
      "Epoch: 264, Batch number: 12, Loss: 13292.634765625\n",
      "Epoch: 265, Batch number: 36, Loss: 13641.2412109375\n",
      "Epoch: 266, Batch number: 60, Loss: 14056.28125\n",
      "Epoch: 268, Batch number: 8, Loss: 13634.7412109375\n",
      "Epoch: 269, Batch number: 32, Loss: 13793.7177734375\n",
      "Epoch: 270, Batch number: 56, Loss: 13374.01953125\n",
      "Epoch: 272, Batch number: 4, Loss: 13526.2158203125\n",
      "Epoch: 273, Batch number: 28, Loss: 13553.783203125\n",
      "Epoch: 274, Batch number: 52, Loss: 13944.1865234375\n",
      "Epoch: 276, Batch number: 0, Loss: 13655.2890625\n",
      "Epoch: 277, Batch number: 24, Loss: 13559.0576171875\n",
      "Epoch: 278, Batch number: 48, Loss: 13902.4482421875\n",
      "Epoch: 279, Batch number: 72, Loss: 13548.037109375\n",
      "Epoch: 281, Batch number: 20, Loss: 13164.3564453125\n",
      "Epoch: 282, Batch number: 44, Loss: 13696.859375\n",
      "Epoch: 283, Batch number: 68, Loss: 13655.30078125\n",
      "Epoch: 285, Batch number: 16, Loss: 13204.46875\n",
      "Epoch: 286, Batch number: 40, Loss: 13898.1474609375\n",
      "Epoch: 287, Batch number: 64, Loss: 13883.8212890625\n",
      "Epoch: 289, Batch number: 12, Loss: 13275.1396484375\n",
      "Epoch: 290, Batch number: 36, Loss: 14007.3095703125\n",
      "Epoch: 291, Batch number: 60, Loss: 13489.4462890625\n",
      "Epoch: 293, Batch number: 8, Loss: 13511.3388671875\n",
      "Epoch: 294, Batch number: 32, Loss: 13643.1142578125\n",
      "Epoch: 295, Batch number: 56, Loss: 13682.177734375\n",
      "Epoch: 297, Batch number: 4, Loss: 13246.3056640625\n",
      "Epoch: 298, Batch number: 28, Loss: 13739.70703125\n",
      "Epoch: 299, Batch number: 52, Loss: 13426.8740234375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 30903.4921875\n",
      "Epoch: 2, Batch number: 24, Loss: 30646.62890625\n",
      "Epoch: 3, Batch number: 48, Loss: 29516.330078125\n",
      "Epoch: 4, Batch number: 72, Loss: 29141.8125\n",
      "Epoch: 6, Batch number: 20, Loss: 28281.330078125\n",
      "Epoch: 7, Batch number: 44, Loss: 27414.515625\n",
      "Epoch: 8, Batch number: 68, Loss: 26188.443359375\n",
      "Epoch: 10, Batch number: 16, Loss: 25539.88671875\n",
      "Epoch: 11, Batch number: 40, Loss: 25635.0078125\n",
      "Epoch: 12, Batch number: 64, Loss: 24481.548828125\n",
      "Epoch: 14, Batch number: 12, Loss: 24611.173828125\n",
      "Epoch: 15, Batch number: 36, Loss: 24955.3828125\n",
      "Epoch: 16, Batch number: 60, Loss: 23646.220703125\n",
      "Epoch: 18, Batch number: 8, Loss: 23239.111328125\n",
      "Epoch: 19, Batch number: 32, Loss: 23241.138671875\n",
      "Epoch: 20, Batch number: 56, Loss: 23242.595703125\n",
      "Epoch: 22, Batch number: 4, Loss: 22798.603515625\n",
      "Epoch: 23, Batch number: 28, Loss: 22974.904296875\n",
      "Epoch: 24, Batch number: 52, Loss: 22736.392578125\n",
      "Epoch: 26, Batch number: 0, Loss: 22287.5546875\n",
      "Epoch: 27, Batch number: 24, Loss: 22223.2109375\n",
      "Epoch: 28, Batch number: 48, Loss: 22065.671875\n",
      "Epoch: 29, Batch number: 72, Loss: 21948.373046875\n",
      "Epoch: 31, Batch number: 20, Loss: 21574.6015625\n",
      "Epoch: 32, Batch number: 44, Loss: 21919.755859375\n",
      "Epoch: 33, Batch number: 68, Loss: 21599.09375\n",
      "Epoch: 35, Batch number: 16, Loss: 21508.958984375\n",
      "Epoch: 36, Batch number: 40, Loss: 21558.787109375\n",
      "Epoch: 37, Batch number: 64, Loss: 21810.263671875\n",
      "Epoch: 39, Batch number: 12, Loss: 21205.67578125\n",
      "Epoch: 40, Batch number: 36, Loss: 21413.16796875\n",
      "Epoch: 41, Batch number: 60, Loss: 21109.4765625\n",
      "Epoch: 43, Batch number: 8, Loss: 21543.810546875\n",
      "Epoch: 44, Batch number: 32, Loss: 20938.25390625\n",
      "Epoch: 45, Batch number: 56, Loss: 21082.939453125\n",
      "Epoch: 47, Batch number: 4, Loss: 21050.66796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Batch number: 28, Loss: 20800.234375\n",
      "Epoch: 49, Batch number: 52, Loss: 20831.18359375\n",
      "Epoch: 51, Batch number: 0, Loss: 20897.4375\n",
      "Epoch: 52, Batch number: 24, Loss: 20552.423828125\n",
      "Epoch: 53, Batch number: 48, Loss: 20640.724609375\n",
      "Epoch: 54, Batch number: 72, Loss: 20519.228515625\n",
      "Epoch: 56, Batch number: 20, Loss: 20718.5390625\n",
      "Epoch: 57, Batch number: 44, Loss: 20615.8984375\n",
      "Epoch: 58, Batch number: 68, Loss: 20649.48828125\n",
      "Epoch: 60, Batch number: 16, Loss: 20074.71875\n",
      "Epoch: 61, Batch number: 40, Loss: 20080.853515625\n",
      "Epoch: 62, Batch number: 64, Loss: 20416.671875\n",
      "Epoch: 64, Batch number: 12, Loss: 20166.697265625\n",
      "Epoch: 65, Batch number: 36, Loss: 20711.5546875\n",
      "Epoch: 66, Batch number: 60, Loss: 20373.26953125\n",
      "Epoch: 68, Batch number: 8, Loss: 20108.71875\n",
      "Epoch: 69, Batch number: 32, Loss: 19951.25390625\n",
      "Epoch: 70, Batch number: 56, Loss: 19961.349609375\n",
      "Epoch: 72, Batch number: 4, Loss: 19891.197265625\n",
      "Epoch: 73, Batch number: 28, Loss: 20363.6640625\n",
      "Epoch: 74, Batch number: 52, Loss: 20155.560546875\n",
      "Epoch: 76, Batch number: 0, Loss: 19965.291015625\n",
      "Epoch: 77, Batch number: 24, Loss: 19964.865234375\n",
      "Epoch: 78, Batch number: 48, Loss: 19953.720703125\n",
      "Epoch: 79, Batch number: 72, Loss: 19977.1953125\n",
      "Epoch: 81, Batch number: 20, Loss: 20027.794921875\n",
      "Epoch: 82, Batch number: 44, Loss: 19808.3828125\n",
      "Epoch: 83, Batch number: 68, Loss: 19509.279296875\n",
      "Epoch: 85, Batch number: 16, Loss: 19902.44140625\n",
      "Epoch: 86, Batch number: 40, Loss: 19983.51953125\n",
      "Epoch: 87, Batch number: 64, Loss: 19867.14453125\n",
      "Epoch: 89, Batch number: 12, Loss: 19454.5703125\n",
      "Epoch: 90, Batch number: 36, Loss: 19662.20703125\n",
      "Epoch: 91, Batch number: 60, Loss: 20157.201171875\n",
      "Epoch: 93, Batch number: 8, Loss: 19924.72265625\n",
      "Epoch: 94, Batch number: 32, Loss: 19839.9140625\n",
      "Epoch: 95, Batch number: 56, Loss: 19446.91796875\n",
      "Epoch: 97, Batch number: 4, Loss: 19688.919921875\n",
      "Epoch: 98, Batch number: 28, Loss: 19503.33203125\n",
      "Epoch: 99, Batch number: 52, Loss: 19502.552734375\n",
      "Epoch: 101, Batch number: 0, Loss: 19628.90625\n",
      "Epoch: 102, Batch number: 24, Loss: 19443.88671875\n",
      "Epoch: 103, Batch number: 48, Loss: 19716.880859375\n",
      "Epoch: 104, Batch number: 72, Loss: 19423.84375\n",
      "Epoch: 106, Batch number: 20, Loss: 19216.203125\n",
      "Epoch: 107, Batch number: 44, Loss: 19699.3515625\n",
      "Epoch: 108, Batch number: 68, Loss: 19605.224609375\n",
      "Epoch: 110, Batch number: 16, Loss: 19354.3671875\n",
      "Epoch: 111, Batch number: 40, Loss: 19331.4140625\n",
      "Epoch: 112, Batch number: 64, Loss: 19116.01953125\n",
      "Epoch: 114, Batch number: 12, Loss: 18877.755859375\n",
      "Epoch: 115, Batch number: 36, Loss: 19193.056640625\n",
      "Epoch: 116, Batch number: 60, Loss: 19223.373046875\n",
      "Epoch: 118, Batch number: 8, Loss: 18905.314453125\n",
      "Epoch: 119, Batch number: 32, Loss: 18938.0546875\n",
      "Epoch: 120, Batch number: 56, Loss: 19134.59375\n",
      "Epoch: 122, Batch number: 4, Loss: 19109.119140625\n",
      "Epoch: 123, Batch number: 28, Loss: 19446.607421875\n",
      "Epoch: 124, Batch number: 52, Loss: 18953.587890625\n",
      "Epoch: 126, Batch number: 0, Loss: 19212.958984375\n",
      "Epoch: 127, Batch number: 24, Loss: 19043.779296875\n",
      "Epoch: 128, Batch number: 48, Loss: 19174.38671875\n",
      "Epoch: 129, Batch number: 72, Loss: 19098.671875\n",
      "Epoch: 131, Batch number: 20, Loss: 18659.6015625\n",
      "Epoch: 132, Batch number: 44, Loss: 18864.068359375\n",
      "Epoch: 133, Batch number: 68, Loss: 18934.349609375\n",
      "Epoch: 135, Batch number: 16, Loss: 18745.095703125\n",
      "Epoch: 136, Batch number: 40, Loss: 18951.533203125\n",
      "Epoch: 137, Batch number: 64, Loss: 18763.1640625\n",
      "Epoch: 139, Batch number: 12, Loss: 18874.3125\n",
      "Epoch: 140, Batch number: 36, Loss: 19004.275390625\n",
      "Epoch: 141, Batch number: 60, Loss: 18792.40625\n",
      "Epoch: 143, Batch number: 8, Loss: 18835.884765625\n",
      "Epoch: 144, Batch number: 32, Loss: 18553.314453125\n",
      "Epoch: 145, Batch number: 56, Loss: 18596.119140625\n",
      "Epoch: 147, Batch number: 4, Loss: 18617.482421875\n",
      "Epoch: 148, Batch number: 28, Loss: 18710.27734375\n",
      "Epoch: 149, Batch number: 52, Loss: 18227.123046875\n",
      "Epoch: 151, Batch number: 0, Loss: 18540.099609375\n",
      "Epoch: 152, Batch number: 24, Loss: 18276.248046875\n",
      "Epoch: 153, Batch number: 48, Loss: 18619.279296875\n",
      "Epoch: 154, Batch number: 72, Loss: 18469.1328125\n",
      "Epoch: 156, Batch number: 20, Loss: 18751.671875\n",
      "Epoch: 157, Batch number: 44, Loss: 18775.240234375\n",
      "Epoch: 158, Batch number: 68, Loss: 18568.0703125\n",
      "Epoch: 160, Batch number: 16, Loss: 18653.18359375\n",
      "Epoch: 161, Batch number: 40, Loss: 18546.48828125\n",
      "Epoch: 162, Batch number: 64, Loss: 19065.95703125\n",
      "Epoch: 164, Batch number: 12, Loss: 18425.263671875\n",
      "Epoch: 165, Batch number: 36, Loss: 18504.08203125\n",
      "Epoch: 166, Batch number: 60, Loss: 18366.6171875\n",
      "Epoch: 168, Batch number: 8, Loss: 18444.61328125\n",
      "Epoch: 169, Batch number: 32, Loss: 18504.0078125\n",
      "Epoch: 170, Batch number: 56, Loss: 18711.685546875\n",
      "Epoch: 172, Batch number: 4, Loss: 18029.84375\n",
      "Epoch: 173, Batch number: 28, Loss: 18409.3984375\n",
      "Epoch: 174, Batch number: 52, Loss: 18827.9921875\n",
      "Epoch: 176, Batch number: 0, Loss: 18251.8515625\n",
      "Epoch: 177, Batch number: 24, Loss: 18540.3125\n",
      "Epoch: 178, Batch number: 48, Loss: 18443.205078125\n",
      "Epoch: 179, Batch number: 72, Loss: 18026.306640625\n",
      "Epoch: 181, Batch number: 20, Loss: 17889.462890625\n",
      "Epoch: 182, Batch number: 44, Loss: 18313.794921875\n",
      "Epoch: 183, Batch number: 68, Loss: 18459.48828125\n",
      "Epoch: 185, Batch number: 16, Loss: 18255.626953125\n",
      "Epoch: 186, Batch number: 40, Loss: 18366.697265625\n",
      "Epoch: 187, Batch number: 64, Loss: 18259.185546875\n",
      "Epoch: 189, Batch number: 12, Loss: 18115.947265625\n",
      "Epoch: 190, Batch number: 36, Loss: 18110.947265625\n",
      "Epoch: 191, Batch number: 60, Loss: 18164.78125\n",
      "Epoch: 193, Batch number: 8, Loss: 17643.263671875\n",
      "Epoch: 194, Batch number: 32, Loss: 18381.396484375\n",
      "Epoch: 195, Batch number: 56, Loss: 17851.109375\n",
      "Epoch: 197, Batch number: 4, Loss: 18327.9921875\n",
      "Epoch: 198, Batch number: 28, Loss: 18068.9765625\n",
      "Epoch: 199, Batch number: 52, Loss: 18247.66796875\n",
      "Epoch: 201, Batch number: 0, Loss: 18295.69140625\n",
      "Epoch: 202, Batch number: 24, Loss: 18139.013671875\n",
      "Epoch: 203, Batch number: 48, Loss: 17972.55859375\n",
      "Epoch: 204, Batch number: 72, Loss: 17895.9609375\n",
      "Epoch: 206, Batch number: 20, Loss: 18203.748046875\n",
      "Epoch: 207, Batch number: 44, Loss: 18021.052734375\n",
      "Epoch: 208, Batch number: 68, Loss: 18293.884765625\n",
      "Epoch: 210, Batch number: 16, Loss: 18091.2109375\n",
      "Epoch: 211, Batch number: 40, Loss: 18218.88671875\n",
      "Epoch: 212, Batch number: 64, Loss: 17992.3984375\n",
      "Epoch: 214, Batch number: 12, Loss: 18024.95703125\n",
      "Epoch: 215, Batch number: 36, Loss: 18251.3046875\n",
      "Epoch: 216, Batch number: 60, Loss: 17736.03515625\n",
      "Epoch: 218, Batch number: 8, Loss: 17901.13671875\n",
      "Epoch: 219, Batch number: 32, Loss: 18270.427734375\n",
      "Epoch: 220, Batch number: 56, Loss: 18157.29296875\n",
      "Epoch: 222, Batch number: 4, Loss: 18114.13671875\n",
      "Epoch: 223, Batch number: 28, Loss: 17798.4609375\n",
      "Epoch: 224, Batch number: 52, Loss: 17874.734375\n",
      "Epoch: 226, Batch number: 0, Loss: 17986.916015625\n",
      "Epoch: 227, Batch number: 24, Loss: 17940.998046875\n",
      "Epoch: 228, Batch number: 48, Loss: 17965.5703125\n",
      "Epoch: 229, Batch number: 72, Loss: 18050.603515625\n",
      "Epoch: 231, Batch number: 20, Loss: 17924.091796875\n",
      "Epoch: 232, Batch number: 44, Loss: 18014.251953125\n",
      "Epoch: 233, Batch number: 68, Loss: 17772.9375\n",
      "Epoch: 235, Batch number: 16, Loss: 17823.646484375\n",
      "Epoch: 236, Batch number: 40, Loss: 17967.58984375\n",
      "Epoch: 237, Batch number: 64, Loss: 17767.337890625\n",
      "Epoch: 239, Batch number: 12, Loss: 17840.287109375\n",
      "Epoch: 240, Batch number: 36, Loss: 17777.720703125\n",
      "Epoch: 241, Batch number: 60, Loss: 17949.677734375\n",
      "Epoch: 243, Batch number: 8, Loss: 18495.427734375\n",
      "Epoch: 244, Batch number: 32, Loss: 17774.7109375\n",
      "Epoch: 245, Batch number: 56, Loss: 17726.3671875\n",
      "Epoch: 247, Batch number: 4, Loss: 17576.03125\n",
      "Epoch: 248, Batch number: 28, Loss: 17348.06640625\n",
      "Epoch: 249, Batch number: 52, Loss: 17216.11328125\n",
      "Epoch: 251, Batch number: 0, Loss: 17513.697265625\n",
      "Epoch: 252, Batch number: 24, Loss: 18241.390625\n",
      "Epoch: 253, Batch number: 48, Loss: 17616.458984375\n",
      "Epoch: 254, Batch number: 72, Loss: 17591.115234375\n",
      "Epoch: 256, Batch number: 20, Loss: 17622.373046875\n",
      "Epoch: 257, Batch number: 44, Loss: 17240.6796875\n",
      "Epoch: 258, Batch number: 68, Loss: 17562.62890625\n",
      "Epoch: 260, Batch number: 16, Loss: 17549.529296875\n",
      "Epoch: 261, Batch number: 40, Loss: 17393.884765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 262, Batch number: 64, Loss: 17710.62890625\n",
      "Epoch: 264, Batch number: 12, Loss: 17783.408203125\n",
      "Epoch: 265, Batch number: 36, Loss: 18049.0625\n",
      "Epoch: 266, Batch number: 60, Loss: 17718.46484375\n",
      "Epoch: 268, Batch number: 8, Loss: 17529.640625\n",
      "Epoch: 269, Batch number: 32, Loss: 17574.984375\n",
      "Epoch: 270, Batch number: 56, Loss: 17920.328125\n",
      "Epoch: 272, Batch number: 4, Loss: 17211.05078125\n",
      "Epoch: 273, Batch number: 28, Loss: 17766.939453125\n",
      "Epoch: 274, Batch number: 52, Loss: 17303.359375\n",
      "Epoch: 276, Batch number: 0, Loss: 17606.919921875\n",
      "Epoch: 277, Batch number: 24, Loss: 17575.484375\n",
      "Epoch: 278, Batch number: 48, Loss: 17689.255859375\n",
      "Epoch: 279, Batch number: 72, Loss: 17738.431640625\n",
      "Epoch: 281, Batch number: 20, Loss: 18006.521484375\n",
      "Epoch: 282, Batch number: 44, Loss: 17458.951171875\n",
      "Epoch: 283, Batch number: 68, Loss: 18026.458984375\n",
      "Epoch: 285, Batch number: 16, Loss: 17370.1875\n",
      "Epoch: 286, Batch number: 40, Loss: 17562.326171875\n",
      "Epoch: 287, Batch number: 64, Loss: 17612.15234375\n",
      "Epoch: 289, Batch number: 12, Loss: 17617.025390625\n",
      "Epoch: 290, Batch number: 36, Loss: 17910.654296875\n",
      "Epoch: 291, Batch number: 60, Loss: 17246.5703125\n",
      "Epoch: 293, Batch number: 8, Loss: 17125.8515625\n",
      "Epoch: 294, Batch number: 32, Loss: 17646.015625\n",
      "Epoch: 295, Batch number: 56, Loss: 17179.98828125\n",
      "Epoch: 297, Batch number: 4, Loss: 17750.380859375\n",
      "Epoch: 298, Batch number: 28, Loss: 17650.521484375\n",
      "Epoch: 299, Batch number: 52, Loss: 16893.919921875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 31418.591796875\n",
      "Epoch: 2, Batch number: 24, Loss: 30307.3203125\n",
      "Epoch: 3, Batch number: 48, Loss: 29308.462890625\n",
      "Epoch: 4, Batch number: 72, Loss: 27154.044921875\n",
      "Epoch: 6, Batch number: 20, Loss: 26883.15625\n",
      "Epoch: 7, Batch number: 44, Loss: 25649.939453125\n",
      "Epoch: 8, Batch number: 68, Loss: 24987.91015625\n",
      "Epoch: 10, Batch number: 16, Loss: 24381.6328125\n",
      "Epoch: 11, Batch number: 40, Loss: 23880.12890625\n",
      "Epoch: 12, Batch number: 64, Loss: 23026.0546875\n",
      "Epoch: 14, Batch number: 12, Loss: 22792.9609375\n",
      "Epoch: 15, Batch number: 36, Loss: 22359.53125\n",
      "Epoch: 16, Batch number: 60, Loss: 22385.923828125\n",
      "Epoch: 18, Batch number: 8, Loss: 22093.92578125\n",
      "Epoch: 19, Batch number: 32, Loss: 21604.99609375\n",
      "Epoch: 20, Batch number: 56, Loss: 21763.142578125\n",
      "Epoch: 22, Batch number: 4, Loss: 21255.58984375\n",
      "Epoch: 23, Batch number: 28, Loss: 21350.2265625\n",
      "Epoch: 24, Batch number: 52, Loss: 21282.466796875\n",
      "Epoch: 26, Batch number: 0, Loss: 20648.560546875\n",
      "Epoch: 27, Batch number: 24, Loss: 20723.802734375\n",
      "Epoch: 28, Batch number: 48, Loss: 20663.912109375\n",
      "Epoch: 29, Batch number: 72, Loss: 20837.927734375\n",
      "Epoch: 31, Batch number: 20, Loss: 20551.666015625\n",
      "Epoch: 32, Batch number: 44, Loss: 20140.03515625\n",
      "Epoch: 33, Batch number: 68, Loss: 20054.63671875\n",
      "Epoch: 35, Batch number: 16, Loss: 19788.357421875\n",
      "Epoch: 36, Batch number: 40, Loss: 20167.650390625\n",
      "Epoch: 37, Batch number: 64, Loss: 19912.82421875\n",
      "Epoch: 39, Batch number: 12, Loss: 19832.203125\n",
      "Epoch: 40, Batch number: 36, Loss: 19793.484375\n",
      "Epoch: 41, Batch number: 60, Loss: 19608.52734375\n",
      "Epoch: 43, Batch number: 8, Loss: 19606.255859375\n",
      "Epoch: 44, Batch number: 32, Loss: 19657.1953125\n",
      "Epoch: 45, Batch number: 56, Loss: 19624.810546875\n",
      "Epoch: 47, Batch number: 4, Loss: 19497.578125\n",
      "Epoch: 48, Batch number: 28, Loss: 19372.146484375\n",
      "Epoch: 49, Batch number: 52, Loss: 19187.53125\n",
      "Epoch: 51, Batch number: 0, Loss: 19119.45703125\n",
      "Epoch: 52, Batch number: 24, Loss: 19131.630859375\n",
      "Epoch: 53, Batch number: 48, Loss: 19149.96484375\n",
      "Epoch: 54, Batch number: 72, Loss: 19294.75390625\n",
      "Epoch: 56, Batch number: 20, Loss: 19007.7578125\n",
      "Epoch: 57, Batch number: 44, Loss: 19013.837890625\n",
      "Epoch: 58, Batch number: 68, Loss: 18754.96875\n",
      "Epoch: 60, Batch number: 16, Loss: 18687.474609375\n",
      "Epoch: 61, Batch number: 40, Loss: 18941.197265625\n",
      "Epoch: 62, Batch number: 64, Loss: 18793.87109375\n",
      "Epoch: 64, Batch number: 12, Loss: 18345.560546875\n",
      "Epoch: 65, Batch number: 36, Loss: 18996.091796875\n",
      "Epoch: 66, Batch number: 60, Loss: 18889.12890625\n",
      "Epoch: 68, Batch number: 8, Loss: 18341.810546875\n",
      "Epoch: 69, Batch number: 32, Loss: 18316.50390625\n",
      "Epoch: 70, Batch number: 56, Loss: 18340.267578125\n",
      "Epoch: 72, Batch number: 4, Loss: 18712.203125\n",
      "Epoch: 73, Batch number: 28, Loss: 18178.30078125\n",
      "Epoch: 74, Batch number: 52, Loss: 18382.001953125\n",
      "Epoch: 76, Batch number: 0, Loss: 18018.5859375\n",
      "Epoch: 77, Batch number: 24, Loss: 18342.06640625\n",
      "Epoch: 78, Batch number: 48, Loss: 18356.033203125\n",
      "Epoch: 79, Batch number: 72, Loss: 18079.87109375\n",
      "Epoch: 81, Batch number: 20, Loss: 17929.9375\n",
      "Epoch: 82, Batch number: 44, Loss: 18126.638671875\n",
      "Epoch: 83, Batch number: 68, Loss: 18437.5078125\n",
      "Epoch: 85, Batch number: 16, Loss: 18351.07421875\n",
      "Epoch: 86, Batch number: 40, Loss: 18248.47265625\n",
      "Epoch: 87, Batch number: 64, Loss: 18199.80859375\n",
      "Epoch: 89, Batch number: 12, Loss: 17788.294921875\n",
      "Epoch: 90, Batch number: 36, Loss: 17909.390625\n",
      "Epoch: 91, Batch number: 60, Loss: 18186.189453125\n",
      "Epoch: 93, Batch number: 8, Loss: 18208.419921875\n",
      "Epoch: 94, Batch number: 32, Loss: 17781.080078125\n",
      "Epoch: 95, Batch number: 56, Loss: 17983.142578125\n",
      "Epoch: 97, Batch number: 4, Loss: 17955.8046875\n",
      "Epoch: 98, Batch number: 28, Loss: 17753.18359375\n",
      "Epoch: 99, Batch number: 52, Loss: 18087.685546875\n",
      "Epoch: 101, Batch number: 0, Loss: 18164.845703125\n",
      "Epoch: 102, Batch number: 24, Loss: 17447.00390625\n",
      "Epoch: 103, Batch number: 48, Loss: 17885.888671875\n",
      "Epoch: 104, Batch number: 72, Loss: 18074.072265625\n",
      "Epoch: 106, Batch number: 20, Loss: 17504.587890625\n",
      "Epoch: 107, Batch number: 44, Loss: 17606.556640625\n",
      "Epoch: 108, Batch number: 68, Loss: 18073.1953125\n",
      "Epoch: 110, Batch number: 16, Loss: 17834.568359375\n",
      "Epoch: 111, Batch number: 40, Loss: 17660.271484375\n",
      "Epoch: 112, Batch number: 64, Loss: 17680.32421875\n",
      "Epoch: 114, Batch number: 12, Loss: 17590.89453125\n",
      "Epoch: 115, Batch number: 36, Loss: 17856.365234375\n",
      "Epoch: 116, Batch number: 60, Loss: 17486.412109375\n",
      "Epoch: 118, Batch number: 8, Loss: 17538.822265625\n",
      "Epoch: 119, Batch number: 32, Loss: 17879.58984375\n",
      "Epoch: 120, Batch number: 56, Loss: 17902.025390625\n",
      "Epoch: 122, Batch number: 4, Loss: 17922.798828125\n",
      "Epoch: 123, Batch number: 28, Loss: 18032.857421875\n",
      "Epoch: 124, Batch number: 52, Loss: 17233.46875\n",
      "Epoch: 126, Batch number: 0, Loss: 17689.9765625\n",
      "Epoch: 127, Batch number: 24, Loss: 17560.095703125\n",
      "Epoch: 128, Batch number: 48, Loss: 17717.216796875\n",
      "Epoch: 129, Batch number: 72, Loss: 17689.9765625\n",
      "Epoch: 131, Batch number: 20, Loss: 17331.896484375\n",
      "Epoch: 132, Batch number: 44, Loss: 17586.607421875\n",
      "Epoch: 133, Batch number: 68, Loss: 17387.8984375\n",
      "Epoch: 135, Batch number: 16, Loss: 17185.12109375\n",
      "Epoch: 136, Batch number: 40, Loss: 17681.6953125\n",
      "Epoch: 137, Batch number: 64, Loss: 17371.322265625\n",
      "Epoch: 139, Batch number: 12, Loss: 17133.498046875\n",
      "Epoch: 140, Batch number: 36, Loss: 17487.349609375\n",
      "Epoch: 141, Batch number: 60, Loss: 17710.98046875\n",
      "Epoch: 143, Batch number: 8, Loss: 17049.416015625\n",
      "Epoch: 144, Batch number: 32, Loss: 17400.140625\n",
      "Epoch: 145, Batch number: 56, Loss: 17207.6796875\n",
      "Epoch: 147, Batch number: 4, Loss: 17358.771484375\n",
      "Epoch: 148, Batch number: 28, Loss: 16990.427734375\n",
      "Epoch: 149, Batch number: 52, Loss: 17371.875\n",
      "Epoch: 151, Batch number: 0, Loss: 17378.09375\n",
      "Epoch: 152, Batch number: 24, Loss: 17060.7109375\n",
      "Epoch: 153, Batch number: 48, Loss: 17479.3359375\n",
      "Epoch: 154, Batch number: 72, Loss: 17352.287109375\n",
      "Epoch: 156, Batch number: 20, Loss: 17142.8046875\n",
      "Epoch: 157, Batch number: 44, Loss: 17014.953125\n",
      "Epoch: 158, Batch number: 68, Loss: 17250.791015625\n",
      "Epoch: 160, Batch number: 16, Loss: 16870.06640625\n",
      "Epoch: 161, Batch number: 40, Loss: 17483.4140625\n",
      "Epoch: 162, Batch number: 64, Loss: 17106.4375\n",
      "Epoch: 164, Batch number: 12, Loss: 17017.146484375\n",
      "Epoch: 165, Batch number: 36, Loss: 17008.375\n",
      "Epoch: 166, Batch number: 60, Loss: 17618.29296875\n",
      "Epoch: 168, Batch number: 8, Loss: 17144.396484375\n",
      "Epoch: 169, Batch number: 32, Loss: 17290.263671875\n",
      "Epoch: 170, Batch number: 56, Loss: 17075.013671875\n",
      "Epoch: 172, Batch number: 4, Loss: 16569.7578125\n",
      "Epoch: 173, Batch number: 28, Loss: 17426.052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 174, Batch number: 52, Loss: 16888.970703125\n",
      "Epoch: 176, Batch number: 0, Loss: 17103.5234375\n",
      "Epoch: 177, Batch number: 24, Loss: 16440.458984375\n",
      "Epoch: 178, Batch number: 48, Loss: 16969.462890625\n",
      "Epoch: 179, Batch number: 72, Loss: 17008.822265625\n",
      "Epoch: 181, Batch number: 20, Loss: 16804.765625\n",
      "Epoch: 182, Batch number: 44, Loss: 16675.7109375\n",
      "Epoch: 183, Batch number: 68, Loss: 16430.755859375\n",
      "Epoch: 185, Batch number: 16, Loss: 17117.419921875\n",
      "Epoch: 186, Batch number: 40, Loss: 16995.30859375\n",
      "Epoch: 187, Batch number: 64, Loss: 16886.623046875\n",
      "Epoch: 189, Batch number: 12, Loss: 16529.57421875\n",
      "Epoch: 190, Batch number: 36, Loss: 17035.740234375\n",
      "Epoch: 191, Batch number: 60, Loss: 17040.228515625\n",
      "Epoch: 193, Batch number: 8, Loss: 16467.65625\n",
      "Epoch: 194, Batch number: 32, Loss: 16838.6953125\n",
      "Epoch: 195, Batch number: 56, Loss: 16866.10546875\n",
      "Epoch: 197, Batch number: 4, Loss: 17311.73828125\n",
      "Epoch: 198, Batch number: 28, Loss: 16893.8125\n",
      "Epoch: 199, Batch number: 52, Loss: 16982.716796875\n",
      "Epoch: 201, Batch number: 0, Loss: 16659.783203125\n",
      "Epoch: 202, Batch number: 24, Loss: 16540.06640625\n",
      "Epoch: 203, Batch number: 48, Loss: 16962.142578125\n",
      "Epoch: 204, Batch number: 72, Loss: 17342.033203125\n",
      "Epoch: 206, Batch number: 20, Loss: 16998.974609375\n",
      "Epoch: 207, Batch number: 44, Loss: 16606.1328125\n",
      "Epoch: 208, Batch number: 68, Loss: 16874.30859375\n",
      "Epoch: 210, Batch number: 16, Loss: 16642.568359375\n",
      "Epoch: 211, Batch number: 40, Loss: 16760.130859375\n",
      "Epoch: 212, Batch number: 64, Loss: 17011.41015625\n",
      "Epoch: 214, Batch number: 12, Loss: 16708.166015625\n",
      "Epoch: 215, Batch number: 36, Loss: 16672.626953125\n",
      "Epoch: 216, Batch number: 60, Loss: 16727.1640625\n",
      "Epoch: 218, Batch number: 8, Loss: 16743.603515625\n",
      "Epoch: 219, Batch number: 32, Loss: 17186.515625\n",
      "Epoch: 220, Batch number: 56, Loss: 16738.873046875\n",
      "Epoch: 222, Batch number: 4, Loss: 16419.109375\n",
      "Epoch: 223, Batch number: 28, Loss: 16556.689453125\n",
      "Epoch: 224, Batch number: 52, Loss: 16903.548828125\n",
      "Epoch: 226, Batch number: 0, Loss: 16632.919921875\n",
      "Epoch: 227, Batch number: 24, Loss: 16883.345703125\n",
      "Epoch: 228, Batch number: 48, Loss: 16698.962890625\n",
      "Epoch: 229, Batch number: 72, Loss: 16763.7890625\n",
      "Epoch: 231, Batch number: 20, Loss: 16722.255859375\n",
      "Epoch: 232, Batch number: 44, Loss: 17165.009765625\n",
      "Epoch: 233, Batch number: 68, Loss: 16873.962890625\n",
      "Epoch: 235, Batch number: 16, Loss: 16833.482421875\n",
      "Epoch: 236, Batch number: 40, Loss: 16639.126953125\n",
      "Epoch: 237, Batch number: 64, Loss: 16270.16796875\n",
      "Epoch: 239, Batch number: 12, Loss: 16817.109375\n",
      "Epoch: 240, Batch number: 36, Loss: 16340.28515625\n",
      "Epoch: 241, Batch number: 60, Loss: 17048.892578125\n",
      "Epoch: 243, Batch number: 8, Loss: 16413.115234375\n",
      "Epoch: 244, Batch number: 32, Loss: 16697.9609375\n",
      "Epoch: 245, Batch number: 56, Loss: 16095.076171875\n",
      "Epoch: 247, Batch number: 4, Loss: 16402.517578125\n",
      "Epoch: 248, Batch number: 28, Loss: 16285.6474609375\n",
      "Epoch: 249, Batch number: 52, Loss: 16597.3359375\n",
      "Epoch: 251, Batch number: 0, Loss: 16511.3828125\n",
      "Epoch: 252, Batch number: 24, Loss: 16442.125\n",
      "Epoch: 253, Batch number: 48, Loss: 16063.5283203125\n",
      "Epoch: 254, Batch number: 72, Loss: 16206.31640625\n",
      "Epoch: 256, Batch number: 20, Loss: 16442.271484375\n",
      "Epoch: 257, Batch number: 44, Loss: 16458.06640625\n",
      "Epoch: 258, Batch number: 68, Loss: 16693.697265625\n",
      "Epoch: 260, Batch number: 16, Loss: 16347.2451171875\n",
      "Epoch: 261, Batch number: 40, Loss: 16904.9296875\n",
      "Epoch: 262, Batch number: 64, Loss: 16473.392578125\n",
      "Epoch: 264, Batch number: 12, Loss: 16590.517578125\n",
      "Epoch: 265, Batch number: 36, Loss: 16559.71875\n",
      "Epoch: 266, Batch number: 60, Loss: 16748.58203125\n",
      "Epoch: 268, Batch number: 8, Loss: 16341.046875\n",
      "Epoch: 269, Batch number: 32, Loss: 16295.021484375\n",
      "Epoch: 270, Batch number: 56, Loss: 16441.900390625\n",
      "Epoch: 272, Batch number: 4, Loss: 16414.5390625\n",
      "Epoch: 273, Batch number: 28, Loss: 16723.560546875\n",
      "Epoch: 274, Batch number: 52, Loss: 16383.3037109375\n",
      "Epoch: 276, Batch number: 0, Loss: 16838.41796875\n",
      "Epoch: 277, Batch number: 24, Loss: 16235.3369140625\n",
      "Epoch: 278, Batch number: 48, Loss: 16569.18359375\n",
      "Epoch: 279, Batch number: 72, Loss: 16430.001953125\n",
      "Epoch: 281, Batch number: 20, Loss: 15843.73046875\n",
      "Epoch: 282, Batch number: 44, Loss: 16543.341796875\n",
      "Epoch: 283, Batch number: 68, Loss: 16302.607421875\n",
      "Epoch: 285, Batch number: 16, Loss: 16659.857421875\n",
      "Epoch: 286, Batch number: 40, Loss: 16142.701171875\n",
      "Epoch: 287, Batch number: 64, Loss: 16955.09765625\n",
      "Epoch: 289, Batch number: 12, Loss: 16258.498046875\n",
      "Epoch: 290, Batch number: 36, Loss: 16734.376953125\n",
      "Epoch: 291, Batch number: 60, Loss: 16583.048828125\n",
      "Epoch: 293, Batch number: 8, Loss: 16661.841796875\n",
      "Epoch: 294, Batch number: 32, Loss: 16244.080078125\n",
      "Epoch: 295, Batch number: 56, Loss: 16181.9619140625\n",
      "Epoch: 297, Batch number: 4, Loss: 16245.48046875\n",
      "Epoch: 298, Batch number: 28, Loss: 16324.615234375\n",
      "Epoch: 299, Batch number: 52, Loss: 16355.3056640625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 31660.12890625\n",
      "Epoch: 2, Batch number: 24, Loss: 29530.673828125\n",
      "Epoch: 3, Batch number: 48, Loss: 27933.369140625\n",
      "Epoch: 4, Batch number: 72, Loss: 26572.61328125\n",
      "Epoch: 6, Batch number: 20, Loss: 25991.787109375\n",
      "Epoch: 7, Batch number: 44, Loss: 24791.0390625\n",
      "Epoch: 8, Batch number: 68, Loss: 24299.9921875\n",
      "Epoch: 10, Batch number: 16, Loss: 23141.50390625\n",
      "Epoch: 11, Batch number: 40, Loss: 22901.919921875\n",
      "Epoch: 12, Batch number: 64, Loss: 22631.546875\n",
      "Epoch: 14, Batch number: 12, Loss: 22268.015625\n",
      "Epoch: 15, Batch number: 36, Loss: 21453.998046875\n",
      "Epoch: 16, Batch number: 60, Loss: 21253.861328125\n",
      "Epoch: 18, Batch number: 8, Loss: 21119.701171875\n",
      "Epoch: 19, Batch number: 32, Loss: 21062.662109375\n",
      "Epoch: 20, Batch number: 56, Loss: 20471.88671875\n",
      "Epoch: 22, Batch number: 4, Loss: 20548.90234375\n",
      "Epoch: 23, Batch number: 28, Loss: 20188.2578125\n",
      "Epoch: 24, Batch number: 52, Loss: 20119.267578125\n",
      "Epoch: 26, Batch number: 0, Loss: 19866.9609375\n",
      "Epoch: 27, Batch number: 24, Loss: 19752.83203125\n",
      "Epoch: 28, Batch number: 48, Loss: 19859.869140625\n",
      "Epoch: 29, Batch number: 72, Loss: 19451.765625\n",
      "Epoch: 31, Batch number: 20, Loss: 19400.212890625\n",
      "Epoch: 32, Batch number: 44, Loss: 19336.431640625\n",
      "Epoch: 33, Batch number: 68, Loss: 19561.572265625\n",
      "Epoch: 35, Batch number: 16, Loss: 19303.728515625\n",
      "Epoch: 36, Batch number: 40, Loss: 19007.98828125\n",
      "Epoch: 37, Batch number: 64, Loss: 18953.28515625\n",
      "Epoch: 39, Batch number: 12, Loss: 18696.14453125\n",
      "Epoch: 40, Batch number: 36, Loss: 18418.841796875\n",
      "Epoch: 41, Batch number: 60, Loss: 18972.50390625\n",
      "Epoch: 43, Batch number: 8, Loss: 18663.85546875\n",
      "Epoch: 44, Batch number: 32, Loss: 18633.056640625\n",
      "Epoch: 45, Batch number: 56, Loss: 18912.1796875\n",
      "Epoch: 47, Batch number: 4, Loss: 18405.826171875\n",
      "Epoch: 48, Batch number: 28, Loss: 18260.58203125\n",
      "Epoch: 49, Batch number: 52, Loss: 18380.12890625\n",
      "Epoch: 51, Batch number: 0, Loss: 18095.2265625\n",
      "Epoch: 52, Batch number: 24, Loss: 18462.517578125\n",
      "Epoch: 53, Batch number: 48, Loss: 18250.703125\n",
      "Epoch: 54, Batch number: 72, Loss: 18241.5078125\n",
      "Epoch: 56, Batch number: 20, Loss: 18267.392578125\n",
      "Epoch: 57, Batch number: 44, Loss: 18292.3515625\n",
      "Epoch: 58, Batch number: 68, Loss: 18329.474609375\n",
      "Epoch: 60, Batch number: 16, Loss: 18135.29296875\n",
      "Epoch: 61, Batch number: 40, Loss: 17987.376953125\n",
      "Epoch: 62, Batch number: 64, Loss: 18156.310546875\n",
      "Epoch: 64, Batch number: 12, Loss: 18022.6328125\n",
      "Epoch: 65, Batch number: 36, Loss: 18169.04296875\n",
      "Epoch: 66, Batch number: 60, Loss: 17866.73828125\n",
      "Epoch: 68, Batch number: 8, Loss: 17800.69140625\n",
      "Epoch: 69, Batch number: 32, Loss: 17953.462890625\n",
      "Epoch: 70, Batch number: 56, Loss: 18084.919921875\n",
      "Epoch: 72, Batch number: 4, Loss: 17609.990234375\n",
      "Epoch: 73, Batch number: 28, Loss: 18134.310546875\n",
      "Epoch: 74, Batch number: 52, Loss: 17816.61328125\n",
      "Epoch: 76, Batch number: 0, Loss: 17125.609375\n",
      "Epoch: 77, Batch number: 24, Loss: 17829.55078125\n",
      "Epoch: 78, Batch number: 48, Loss: 17407.865234375\n",
      "Epoch: 79, Batch number: 72, Loss: 17204.67578125\n",
      "Epoch: 81, Batch number: 20, Loss: 17291.9609375\n",
      "Epoch: 82, Batch number: 44, Loss: 17329.78125\n",
      "Epoch: 83, Batch number: 68, Loss: 17566.619140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85, Batch number: 16, Loss: 17066.099609375\n",
      "Epoch: 86, Batch number: 40, Loss: 17312.63671875\n",
      "Epoch: 87, Batch number: 64, Loss: 17572.74609375\n",
      "Epoch: 89, Batch number: 12, Loss: 17518.177734375\n",
      "Epoch: 90, Batch number: 36, Loss: 17510.974609375\n",
      "Epoch: 91, Batch number: 60, Loss: 17420.373046875\n",
      "Epoch: 93, Batch number: 8, Loss: 17565.8515625\n",
      "Epoch: 94, Batch number: 32, Loss: 17226.49609375\n",
      "Epoch: 95, Batch number: 56, Loss: 17272.94140625\n",
      "Epoch: 97, Batch number: 4, Loss: 17302.51953125\n",
      "Epoch: 98, Batch number: 28, Loss: 16706.505859375\n",
      "Epoch: 99, Batch number: 52, Loss: 16871.998046875\n",
      "Epoch: 101, Batch number: 0, Loss: 16954.228515625\n",
      "Epoch: 102, Batch number: 24, Loss: 17284.857421875\n",
      "Epoch: 103, Batch number: 48, Loss: 17153.775390625\n",
      "Epoch: 104, Batch number: 72, Loss: 16835.740234375\n",
      "Epoch: 106, Batch number: 20, Loss: 16830.6875\n",
      "Epoch: 107, Batch number: 44, Loss: 17110.439453125\n",
      "Epoch: 108, Batch number: 68, Loss: 17243.208984375\n",
      "Epoch: 110, Batch number: 16, Loss: 17250.57421875\n",
      "Epoch: 111, Batch number: 40, Loss: 16704.857421875\n",
      "Epoch: 112, Batch number: 64, Loss: 17069.818359375\n",
      "Epoch: 114, Batch number: 12, Loss: 16802.484375\n",
      "Epoch: 115, Batch number: 36, Loss: 16846.50390625\n",
      "Epoch: 116, Batch number: 60, Loss: 16849.2265625\n",
      "Epoch: 118, Batch number: 8, Loss: 17082.94921875\n",
      "Epoch: 119, Batch number: 32, Loss: 17076.685546875\n",
      "Epoch: 120, Batch number: 56, Loss: 17001.916015625\n",
      "Epoch: 122, Batch number: 4, Loss: 16654.947265625\n",
      "Epoch: 123, Batch number: 28, Loss: 17198.43359375\n",
      "Epoch: 124, Batch number: 52, Loss: 16987.662109375\n",
      "Epoch: 126, Batch number: 0, Loss: 16479.33984375\n",
      "Epoch: 127, Batch number: 24, Loss: 16847.32421875\n",
      "Epoch: 128, Batch number: 48, Loss: 16732.4765625\n",
      "Epoch: 129, Batch number: 72, Loss: 16788.615234375\n",
      "Epoch: 131, Batch number: 20, Loss: 16964.318359375\n",
      "Epoch: 132, Batch number: 44, Loss: 17173.1015625\n",
      "Epoch: 133, Batch number: 68, Loss: 16762.076171875\n",
      "Epoch: 135, Batch number: 16, Loss: 16707.025390625\n",
      "Epoch: 136, Batch number: 40, Loss: 16545.2109375\n",
      "Epoch: 137, Batch number: 64, Loss: 17203.216796875\n",
      "Epoch: 139, Batch number: 12, Loss: 16712.298828125\n",
      "Epoch: 140, Batch number: 36, Loss: 16516.375\n",
      "Epoch: 141, Batch number: 60, Loss: 17061.69140625\n",
      "Epoch: 143, Batch number: 8, Loss: 16853.115234375\n",
      "Epoch: 144, Batch number: 32, Loss: 17147.72265625\n",
      "Epoch: 145, Batch number: 56, Loss: 17073.10546875\n",
      "Epoch: 147, Batch number: 4, Loss: 16499.201171875\n",
      "Epoch: 148, Batch number: 28, Loss: 16725.150390625\n",
      "Epoch: 149, Batch number: 52, Loss: 16928.701171875\n",
      "Epoch: 151, Batch number: 0, Loss: 16473.677734375\n",
      "Epoch: 152, Batch number: 24, Loss: 17060.79296875\n",
      "Epoch: 153, Batch number: 48, Loss: 16664.744140625\n",
      "Epoch: 154, Batch number: 72, Loss: 16571.671875\n",
      "Epoch: 156, Batch number: 20, Loss: 16154.7353515625\n",
      "Epoch: 157, Batch number: 44, Loss: 16276.669921875\n",
      "Epoch: 158, Batch number: 68, Loss: 16462.37109375\n",
      "Epoch: 160, Batch number: 16, Loss: 16357.4521484375\n",
      "Epoch: 161, Batch number: 40, Loss: 16464.92578125\n",
      "Epoch: 162, Batch number: 64, Loss: 16810.40234375\n",
      "Epoch: 164, Batch number: 12, Loss: 16496.259765625\n",
      "Epoch: 165, Batch number: 36, Loss: 17168.47265625\n",
      "Epoch: 166, Batch number: 60, Loss: 16869.9609375\n",
      "Epoch: 168, Batch number: 8, Loss: 16308.54296875\n",
      "Epoch: 169, Batch number: 32, Loss: 16736.501953125\n",
      "Epoch: 170, Batch number: 56, Loss: 16645.15625\n",
      "Epoch: 172, Batch number: 4, Loss: 16308.7998046875\n",
      "Epoch: 173, Batch number: 28, Loss: 16366.173828125\n",
      "Epoch: 174, Batch number: 52, Loss: 16664.423828125\n",
      "Epoch: 176, Batch number: 0, Loss: 16460.271484375\n",
      "Epoch: 177, Batch number: 24, Loss: 16930.1953125\n",
      "Epoch: 178, Batch number: 48, Loss: 16662.748046875\n",
      "Epoch: 179, Batch number: 72, Loss: 16791.373046875\n",
      "Epoch: 181, Batch number: 20, Loss: 16815.828125\n",
      "Epoch: 182, Batch number: 44, Loss: 16026.3330078125\n",
      "Epoch: 183, Batch number: 68, Loss: 16669.119140625\n",
      "Epoch: 185, Batch number: 16, Loss: 16251.3701171875\n",
      "Epoch: 186, Batch number: 40, Loss: 16591.708984375\n",
      "Epoch: 187, Batch number: 64, Loss: 16649.12109375\n",
      "Epoch: 189, Batch number: 12, Loss: 16329.4765625\n",
      "Epoch: 190, Batch number: 36, Loss: 16294.73828125\n",
      "Epoch: 191, Batch number: 60, Loss: 16600.138671875\n",
      "Epoch: 193, Batch number: 8, Loss: 16120.62890625\n",
      "Epoch: 194, Batch number: 32, Loss: 16124.365234375\n",
      "Epoch: 195, Batch number: 56, Loss: 16346.4560546875\n",
      "Epoch: 197, Batch number: 4, Loss: 16314.3935546875\n",
      "Epoch: 198, Batch number: 28, Loss: 16617.814453125\n",
      "Epoch: 199, Batch number: 52, Loss: 16879.96875\n",
      "Epoch: 201, Batch number: 0, Loss: 15886.0185546875\n",
      "Epoch: 202, Batch number: 24, Loss: 16140.6982421875\n",
      "Epoch: 203, Batch number: 48, Loss: 16572.470703125\n",
      "Epoch: 204, Batch number: 72, Loss: 16360.921875\n",
      "Epoch: 206, Batch number: 20, Loss: 16164.4208984375\n",
      "Epoch: 207, Batch number: 44, Loss: 15965.9248046875\n",
      "Epoch: 208, Batch number: 68, Loss: 15904.6826171875\n",
      "Epoch: 210, Batch number: 16, Loss: 16267.8203125\n",
      "Epoch: 211, Batch number: 40, Loss: 16337.8896484375\n",
      "Epoch: 212, Batch number: 64, Loss: 16634.697265625\n",
      "Epoch: 214, Batch number: 12, Loss: 16541.44140625\n",
      "Epoch: 215, Batch number: 36, Loss: 16223.8798828125\n",
      "Epoch: 216, Batch number: 60, Loss: 16415.630859375\n",
      "Epoch: 218, Batch number: 8, Loss: 16039.98828125\n",
      "Epoch: 219, Batch number: 32, Loss: 16106.73046875\n",
      "Epoch: 220, Batch number: 56, Loss: 16090.580078125\n",
      "Epoch: 222, Batch number: 4, Loss: 16652.001953125\n",
      "Epoch: 223, Batch number: 28, Loss: 16290.869140625\n",
      "Epoch: 224, Batch number: 52, Loss: 15829.4580078125\n",
      "Epoch: 226, Batch number: 0, Loss: 16091.732421875\n",
      "Epoch: 227, Batch number: 24, Loss: 16646.30078125\n",
      "Epoch: 228, Batch number: 48, Loss: 16272.982421875\n",
      "Epoch: 229, Batch number: 72, Loss: 15756.3330078125\n",
      "Epoch: 231, Batch number: 20, Loss: 15713.7470703125\n",
      "Epoch: 232, Batch number: 44, Loss: 16526.75\n",
      "Epoch: 233, Batch number: 68, Loss: 16335.15234375\n",
      "Epoch: 235, Batch number: 16, Loss: 16381.57421875\n",
      "Epoch: 236, Batch number: 40, Loss: 16343.0595703125\n",
      "Epoch: 237, Batch number: 64, Loss: 16110.2734375\n",
      "Epoch: 239, Batch number: 12, Loss: 16333.7724609375\n",
      "Epoch: 240, Batch number: 36, Loss: 16584.66015625\n",
      "Epoch: 241, Batch number: 60, Loss: 16311.154296875\n",
      "Epoch: 243, Batch number: 8, Loss: 16202.984375\n",
      "Epoch: 244, Batch number: 32, Loss: 16164.416015625\n",
      "Epoch: 245, Batch number: 56, Loss: 16273.8388671875\n",
      "Epoch: 247, Batch number: 4, Loss: 16032.763671875\n",
      "Epoch: 248, Batch number: 28, Loss: 16335.244140625\n",
      "Epoch: 249, Batch number: 52, Loss: 16706.791015625\n",
      "Epoch: 251, Batch number: 0, Loss: 16224.458984375\n",
      "Epoch: 252, Batch number: 24, Loss: 15980.0322265625\n",
      "Epoch: 253, Batch number: 48, Loss: 16287.787109375\n",
      "Epoch: 254, Batch number: 72, Loss: 16509.29296875\n",
      "Epoch: 256, Batch number: 20, Loss: 16071.9599609375\n",
      "Epoch: 257, Batch number: 44, Loss: 16113.759765625\n",
      "Epoch: 258, Batch number: 68, Loss: 16202.447265625\n",
      "Epoch: 260, Batch number: 16, Loss: 16280.88671875\n",
      "Epoch: 261, Batch number: 40, Loss: 16524.705078125\n",
      "Epoch: 262, Batch number: 64, Loss: 16131.5380859375\n",
      "Epoch: 264, Batch number: 12, Loss: 16510.056640625\n",
      "Epoch: 265, Batch number: 36, Loss: 16218.76171875\n",
      "Epoch: 266, Batch number: 60, Loss: 15868.43359375\n",
      "Epoch: 268, Batch number: 8, Loss: 16074.697265625\n",
      "Epoch: 269, Batch number: 32, Loss: 16447.599609375\n",
      "Epoch: 270, Batch number: 56, Loss: 16028.84765625\n",
      "Epoch: 272, Batch number: 4, Loss: 15950.5947265625\n",
      "Epoch: 273, Batch number: 28, Loss: 16482.755859375\n",
      "Epoch: 274, Batch number: 52, Loss: 15848.5498046875\n",
      "Epoch: 276, Batch number: 0, Loss: 15955.109375\n",
      "Epoch: 277, Batch number: 24, Loss: 16360.4990234375\n",
      "Epoch: 278, Batch number: 48, Loss: 16433.21875\n",
      "Epoch: 279, Batch number: 72, Loss: 15987.3271484375\n",
      "Epoch: 281, Batch number: 20, Loss: 16060.6611328125\n",
      "Epoch: 282, Batch number: 44, Loss: 16100.408203125\n",
      "Epoch: 283, Batch number: 68, Loss: 16122.6962890625\n",
      "Epoch: 285, Batch number: 16, Loss: 15716.4013671875\n",
      "Epoch: 286, Batch number: 40, Loss: 16434.826171875\n",
      "Epoch: 287, Batch number: 64, Loss: 16368.9140625\n",
      "Epoch: 289, Batch number: 12, Loss: 16260.6982421875\n",
      "Epoch: 290, Batch number: 36, Loss: 16158.12890625\n",
      "Epoch: 291, Batch number: 60, Loss: 16377.8544921875\n",
      "Epoch: 293, Batch number: 8, Loss: 16037.3388671875\n",
      "Epoch: 294, Batch number: 32, Loss: 16730.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 295, Batch number: 56, Loss: 16761.505859375\n",
      "Epoch: 297, Batch number: 4, Loss: 16137.0498046875\n",
      "Epoch: 298, Batch number: 28, Loss: 16409.486328125\n",
      "Epoch: 299, Batch number: 52, Loss: 16524.984375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 32039.328125\n",
      "Epoch: 2, Batch number: 24, Loss: 29404.427734375\n",
      "Epoch: 3, Batch number: 48, Loss: 27187.796875\n",
      "Epoch: 4, Batch number: 72, Loss: 26122.74609375\n",
      "Epoch: 6, Batch number: 20, Loss: 24818.029296875\n",
      "Epoch: 7, Batch number: 44, Loss: 24220.728515625\n",
      "Epoch: 8, Batch number: 68, Loss: 23282.056640625\n",
      "Epoch: 10, Batch number: 16, Loss: 22697.95703125\n",
      "Epoch: 11, Batch number: 40, Loss: 22118.173828125\n",
      "Epoch: 12, Batch number: 64, Loss: 21302.728515625\n",
      "Epoch: 14, Batch number: 12, Loss: 21142.419921875\n",
      "Epoch: 15, Batch number: 36, Loss: 21115.193359375\n",
      "Epoch: 16, Batch number: 60, Loss: 20142.064453125\n",
      "Epoch: 18, Batch number: 8, Loss: 20146.865234375\n",
      "Epoch: 19, Batch number: 32, Loss: 20087.7578125\n",
      "Epoch: 20, Batch number: 56, Loss: 19793.619140625\n",
      "Epoch: 22, Batch number: 4, Loss: 19370.765625\n",
      "Epoch: 23, Batch number: 28, Loss: 19073.525390625\n",
      "Epoch: 24, Batch number: 52, Loss: 19233.8671875\n",
      "Epoch: 26, Batch number: 0, Loss: 19467.642578125\n",
      "Epoch: 27, Batch number: 24, Loss: 19310.134765625\n",
      "Epoch: 28, Batch number: 48, Loss: 18833.025390625\n",
      "Epoch: 29, Batch number: 72, Loss: 18956.74609375\n",
      "Epoch: 31, Batch number: 20, Loss: 18567.310546875\n",
      "Epoch: 32, Batch number: 44, Loss: 18439.68359375\n",
      "Epoch: 33, Batch number: 68, Loss: 18894.6328125\n",
      "Epoch: 35, Batch number: 16, Loss: 18382.169921875\n",
      "Epoch: 36, Batch number: 40, Loss: 17979.69140625\n",
      "Epoch: 37, Batch number: 64, Loss: 18423.720703125\n",
      "Epoch: 39, Batch number: 12, Loss: 18070.97265625\n",
      "Epoch: 40, Batch number: 36, Loss: 18134.787109375\n",
      "Epoch: 41, Batch number: 60, Loss: 18229.287109375\n",
      "Epoch: 43, Batch number: 8, Loss: 18217.91796875\n",
      "Epoch: 44, Batch number: 32, Loss: 18103.0\n",
      "Epoch: 45, Batch number: 56, Loss: 18199.767578125\n",
      "Epoch: 47, Batch number: 4, Loss: 17563.396484375\n",
      "Epoch: 48, Batch number: 28, Loss: 18066.607421875\n",
      "Epoch: 49, Batch number: 52, Loss: 18327.240234375\n",
      "Epoch: 51, Batch number: 0, Loss: 17626.3359375\n",
      "Epoch: 52, Batch number: 24, Loss: 17564.841796875\n",
      "Epoch: 53, Batch number: 48, Loss: 17690.525390625\n",
      "Epoch: 54, Batch number: 72, Loss: 17915.083984375\n",
      "Epoch: 56, Batch number: 20, Loss: 18025.541015625\n",
      "Epoch: 57, Batch number: 44, Loss: 17570.81640625\n",
      "Epoch: 58, Batch number: 68, Loss: 17700.25\n",
      "Epoch: 60, Batch number: 16, Loss: 17372.7890625\n",
      "Epoch: 61, Batch number: 40, Loss: 17534.361328125\n",
      "Epoch: 62, Batch number: 64, Loss: 17276.033203125\n",
      "Epoch: 64, Batch number: 12, Loss: 17743.421875\n",
      "Epoch: 65, Batch number: 36, Loss: 17409.615234375\n",
      "Epoch: 66, Batch number: 60, Loss: 17125.908203125\n",
      "Epoch: 68, Batch number: 8, Loss: 17735.521484375\n",
      "Epoch: 69, Batch number: 32, Loss: 17660.66796875\n",
      "Epoch: 70, Batch number: 56, Loss: 17647.0390625\n",
      "Epoch: 72, Batch number: 4, Loss: 17215.1875\n",
      "Epoch: 73, Batch number: 28, Loss: 17546.841796875\n",
      "Epoch: 74, Batch number: 52, Loss: 17254.8046875\n",
      "Epoch: 76, Batch number: 0, Loss: 17115.478515625\n",
      "Epoch: 77, Batch number: 24, Loss: 17035.17578125\n",
      "Epoch: 78, Batch number: 48, Loss: 17513.994140625\n",
      "Epoch: 79, Batch number: 72, Loss: 17336.677734375\n",
      "Epoch: 81, Batch number: 20, Loss: 16948.107421875\n",
      "Epoch: 82, Batch number: 44, Loss: 17041.81640625\n",
      "Epoch: 83, Batch number: 68, Loss: 17039.716796875\n",
      "Epoch: 85, Batch number: 16, Loss: 17412.0859375\n",
      "Epoch: 86, Batch number: 40, Loss: 16818.763671875\n",
      "Epoch: 87, Batch number: 64, Loss: 17483.287109375\n",
      "Epoch: 89, Batch number: 12, Loss: 16313.1328125\n",
      "Epoch: 90, Batch number: 36, Loss: 16598.3046875\n",
      "Epoch: 91, Batch number: 60, Loss: 17165.1875\n",
      "Epoch: 93, Batch number: 8, Loss: 16819.517578125\n",
      "Epoch: 94, Batch number: 32, Loss: 16775.2109375\n",
      "Epoch: 95, Batch number: 56, Loss: 16530.498046875\n",
      "Epoch: 97, Batch number: 4, Loss: 16359.8779296875\n",
      "Epoch: 98, Batch number: 28, Loss: 16555.740234375\n",
      "Epoch: 99, Batch number: 52, Loss: 16670.46875\n",
      "Epoch: 101, Batch number: 0, Loss: 16805.916015625\n",
      "Epoch: 102, Batch number: 24, Loss: 17193.341796875\n",
      "Epoch: 103, Batch number: 48, Loss: 17123.4140625\n",
      "Epoch: 104, Batch number: 72, Loss: 17615.82421875\n",
      "Epoch: 106, Batch number: 20, Loss: 16682.748046875\n",
      "Epoch: 107, Batch number: 44, Loss: 16847.634765625\n",
      "Epoch: 108, Batch number: 68, Loss: 17395.060546875\n",
      "Epoch: 110, Batch number: 16, Loss: 16702.072265625\n",
      "Epoch: 111, Batch number: 40, Loss: 16687.3125\n",
      "Epoch: 112, Batch number: 64, Loss: 16580.521484375\n",
      "Epoch: 114, Batch number: 12, Loss: 16371.6787109375\n",
      "Epoch: 115, Batch number: 36, Loss: 16679.744140625\n",
      "Epoch: 116, Batch number: 60, Loss: 16860.48046875\n",
      "Epoch: 118, Batch number: 8, Loss: 15926.6064453125\n",
      "Epoch: 119, Batch number: 32, Loss: 16578.28515625\n",
      "Epoch: 120, Batch number: 56, Loss: 16469.396484375\n",
      "Epoch: 122, Batch number: 4, Loss: 16895.814453125\n",
      "Epoch: 123, Batch number: 28, Loss: 16416.24609375\n",
      "Epoch: 124, Batch number: 52, Loss: 16978.451171875\n",
      "Epoch: 126, Batch number: 0, Loss: 16109.501953125\n",
      "Epoch: 127, Batch number: 24, Loss: 16562.443359375\n",
      "Epoch: 128, Batch number: 48, Loss: 16321.9169921875\n",
      "Epoch: 129, Batch number: 72, Loss: 16630.140625\n",
      "Epoch: 131, Batch number: 20, Loss: 16554.619140625\n",
      "Epoch: 132, Batch number: 44, Loss: 16283.177734375\n",
      "Epoch: 133, Batch number: 68, Loss: 16787.98046875\n",
      "Epoch: 135, Batch number: 16, Loss: 16663.55078125\n",
      "Epoch: 136, Batch number: 40, Loss: 16523.11328125\n",
      "Epoch: 137, Batch number: 64, Loss: 16591.5\n",
      "Epoch: 139, Batch number: 12, Loss: 16305.8173828125\n",
      "Epoch: 140, Batch number: 36, Loss: 16402.359375\n",
      "Epoch: 141, Batch number: 60, Loss: 16266.6845703125\n",
      "Epoch: 143, Batch number: 8, Loss: 16072.3017578125\n",
      "Epoch: 144, Batch number: 32, Loss: 16247.298828125\n",
      "Epoch: 145, Batch number: 56, Loss: 16327.37890625\n",
      "Epoch: 147, Batch number: 4, Loss: 16462.525390625\n",
      "Epoch: 148, Batch number: 28, Loss: 16547.802734375\n",
      "Epoch: 149, Batch number: 52, Loss: 16596.392578125\n",
      "Epoch: 151, Batch number: 0, Loss: 16331.1728515625\n",
      "Epoch: 152, Batch number: 24, Loss: 16519.3046875\n",
      "Epoch: 153, Batch number: 48, Loss: 16265.4287109375\n",
      "Epoch: 154, Batch number: 72, Loss: 16468.0390625\n",
      "Epoch: 156, Batch number: 20, Loss: 15975.8701171875\n",
      "Epoch: 157, Batch number: 44, Loss: 16543.4609375\n",
      "Epoch: 158, Batch number: 68, Loss: 16642.55859375\n",
      "Epoch: 160, Batch number: 16, Loss: 16367.6513671875\n",
      "Epoch: 161, Batch number: 40, Loss: 16181.458984375\n",
      "Epoch: 162, Batch number: 64, Loss: 16335.6220703125\n",
      "Epoch: 164, Batch number: 12, Loss: 16323.849609375\n",
      "Epoch: 165, Batch number: 36, Loss: 16853.796875\n",
      "Epoch: 166, Batch number: 60, Loss: 16547.984375\n",
      "Epoch: 168, Batch number: 8, Loss: 15816.767578125\n",
      "Epoch: 169, Batch number: 32, Loss: 16233.865234375\n",
      "Epoch: 170, Batch number: 56, Loss: 16439.029296875\n",
      "Epoch: 172, Batch number: 4, Loss: 16681.615234375\n",
      "Epoch: 173, Batch number: 28, Loss: 16341.3798828125\n",
      "Epoch: 174, Batch number: 52, Loss: 16263.6552734375\n",
      "Epoch: 176, Batch number: 0, Loss: 15928.728515625\n",
      "Epoch: 177, Batch number: 24, Loss: 16263.2080078125\n",
      "Epoch: 178, Batch number: 48, Loss: 16040.9482421875\n",
      "Epoch: 179, Batch number: 72, Loss: 16351.0048828125\n",
      "Epoch: 181, Batch number: 20, Loss: 16467.798828125\n",
      "Epoch: 182, Batch number: 44, Loss: 16334.1533203125\n",
      "Epoch: 183, Batch number: 68, Loss: 16289.6201171875\n",
      "Epoch: 185, Batch number: 16, Loss: 16353.384765625\n",
      "Epoch: 186, Batch number: 40, Loss: 16134.015625\n",
      "Epoch: 187, Batch number: 64, Loss: 16161.9228515625\n",
      "Epoch: 189, Batch number: 12, Loss: 16058.34375\n",
      "Epoch: 190, Batch number: 36, Loss: 16081.3115234375\n",
      "Epoch: 191, Batch number: 60, Loss: 16985.716796875\n",
      "Epoch: 193, Batch number: 8, Loss: 15995.3037109375\n",
      "Epoch: 194, Batch number: 32, Loss: 16375.345703125\n",
      "Epoch: 195, Batch number: 56, Loss: 16526.380859375\n",
      "Epoch: 197, Batch number: 4, Loss: 16109.646484375\n",
      "Epoch: 198, Batch number: 28, Loss: 16245.609375\n",
      "Epoch: 199, Batch number: 52, Loss: 15976.861328125\n",
      "Epoch: 201, Batch number: 0, Loss: 16974.05859375\n",
      "Epoch: 202, Batch number: 24, Loss: 16821.599609375\n",
      "Epoch: 203, Batch number: 48, Loss: 16074.83203125\n",
      "Epoch: 204, Batch number: 72, Loss: 16599.041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 16322.2587890625\n",
      "Epoch: 207, Batch number: 44, Loss: 16652.9296875\n",
      "Epoch: 208, Batch number: 68, Loss: 16182.37109375\n",
      "Epoch: 210, Batch number: 16, Loss: 15827.8369140625\n",
      "Epoch: 211, Batch number: 40, Loss: 15770.5244140625\n",
      "Epoch: 212, Batch number: 64, Loss: 16110.107421875\n",
      "Epoch: 214, Batch number: 12, Loss: 15843.3701171875\n",
      "Epoch: 215, Batch number: 36, Loss: 15935.6123046875\n",
      "Epoch: 216, Batch number: 60, Loss: 16477.970703125\n",
      "Epoch: 218, Batch number: 8, Loss: 16161.3037109375\n",
      "Epoch: 219, Batch number: 32, Loss: 16381.5068359375\n",
      "Epoch: 220, Batch number: 56, Loss: 16516.03515625\n",
      "Epoch: 222, Batch number: 4, Loss: 15690.705078125\n",
      "Epoch: 223, Batch number: 28, Loss: 15599.384765625\n",
      "Epoch: 224, Batch number: 52, Loss: 16504.970703125\n",
      "Epoch: 226, Batch number: 0, Loss: 15802.8759765625\n",
      "Epoch: 227, Batch number: 24, Loss: 16186.078125\n",
      "Epoch: 228, Batch number: 48, Loss: 16326.478515625\n",
      "Epoch: 229, Batch number: 72, Loss: 16643.560546875\n",
      "Epoch: 231, Batch number: 20, Loss: 15700.6494140625\n",
      "Epoch: 232, Batch number: 44, Loss: 16230.4873046875\n",
      "Epoch: 233, Batch number: 68, Loss: 16105.396484375\n",
      "Epoch: 235, Batch number: 16, Loss: 16237.380859375\n",
      "Epoch: 236, Batch number: 40, Loss: 16240.9091796875\n",
      "Epoch: 237, Batch number: 64, Loss: 16032.41796875\n",
      "Epoch: 239, Batch number: 12, Loss: 16433.05078125\n",
      "Epoch: 240, Batch number: 36, Loss: 16378.591796875\n",
      "Epoch: 241, Batch number: 60, Loss: 15988.2705078125\n",
      "Epoch: 243, Batch number: 8, Loss: 15770.810546875\n",
      "Epoch: 244, Batch number: 32, Loss: 16020.2548828125\n",
      "Epoch: 245, Batch number: 56, Loss: 16219.4638671875\n",
      "Epoch: 247, Batch number: 4, Loss: 15944.609375\n",
      "Epoch: 248, Batch number: 28, Loss: 16362.294921875\n",
      "Epoch: 249, Batch number: 52, Loss: 16481.8203125\n",
      "Epoch: 251, Batch number: 0, Loss: 15930.29296875\n",
      "Epoch: 252, Batch number: 24, Loss: 16127.4248046875\n",
      "Epoch: 253, Batch number: 48, Loss: 16169.1875\n",
      "Epoch: 254, Batch number: 72, Loss: 16469.015625\n",
      "Epoch: 256, Batch number: 20, Loss: 16306.7587890625\n",
      "Epoch: 257, Batch number: 44, Loss: 15875.7119140625\n",
      "Epoch: 258, Batch number: 68, Loss: 16452.876953125\n",
      "Epoch: 260, Batch number: 16, Loss: 16088.96875\n",
      "Epoch: 261, Batch number: 40, Loss: 16302.435546875\n",
      "Epoch: 262, Batch number: 64, Loss: 16215.5283203125\n",
      "Epoch: 264, Batch number: 12, Loss: 16708.7734375\n",
      "Epoch: 265, Batch number: 36, Loss: 16350.2353515625\n",
      "Epoch: 266, Batch number: 60, Loss: 16328.9326171875\n",
      "Epoch: 268, Batch number: 8, Loss: 16125.49609375\n",
      "Epoch: 269, Batch number: 32, Loss: 15986.7529296875\n",
      "Epoch: 270, Batch number: 56, Loss: 16392.828125\n",
      "Epoch: 272, Batch number: 4, Loss: 15869.1552734375\n",
      "Epoch: 273, Batch number: 28, Loss: 16424.869140625\n",
      "Epoch: 274, Batch number: 52, Loss: 16060.6943359375\n",
      "Epoch: 276, Batch number: 0, Loss: 16514.990234375\n",
      "Epoch: 277, Batch number: 24, Loss: 16109.0859375\n",
      "Epoch: 278, Batch number: 48, Loss: 16106.0625\n",
      "Epoch: 279, Batch number: 72, Loss: 16369.25\n",
      "Epoch: 281, Batch number: 20, Loss: 16046.8828125\n",
      "Epoch: 282, Batch number: 44, Loss: 16367.70703125\n",
      "Epoch: 283, Batch number: 68, Loss: 16108.7568359375\n",
      "Epoch: 285, Batch number: 16, Loss: 16305.1474609375\n",
      "Epoch: 286, Batch number: 40, Loss: 16515.732421875\n",
      "Epoch: 287, Batch number: 64, Loss: 16075.5283203125\n",
      "Epoch: 289, Batch number: 12, Loss: 16027.8095703125\n",
      "Epoch: 290, Batch number: 36, Loss: 16069.4931640625\n",
      "Epoch: 291, Batch number: 60, Loss: 16171.763671875\n",
      "Epoch: 293, Batch number: 8, Loss: 16486.7265625\n",
      "Epoch: 294, Batch number: 32, Loss: 16392.10546875\n",
      "Epoch: 295, Batch number: 56, Loss: 15749.9599609375\n",
      "Epoch: 297, Batch number: 4, Loss: 15836.6015625\n",
      "Epoch: 298, Batch number: 28, Loss: 16126.5068359375\n",
      "Epoch: 299, Batch number: 52, Loss: 16270.6474609375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 31957.10546875\n",
      "Epoch: 2, Batch number: 24, Loss: 28206.82421875\n",
      "Epoch: 3, Batch number: 48, Loss: 26200.962890625\n",
      "Epoch: 4, Batch number: 72, Loss: 25398.71484375\n",
      "Epoch: 6, Batch number: 20, Loss: 23798.640625\n",
      "Epoch: 7, Batch number: 44, Loss: 22842.55078125\n",
      "Epoch: 8, Batch number: 68, Loss: 22292.298828125\n",
      "Epoch: 10, Batch number: 16, Loss: 21396.064453125\n",
      "Epoch: 11, Batch number: 40, Loss: 20880.833984375\n",
      "Epoch: 12, Batch number: 64, Loss: 20933.423828125\n",
      "Epoch: 14, Batch number: 12, Loss: 20172.6796875\n",
      "Epoch: 15, Batch number: 36, Loss: 19930.05078125\n",
      "Epoch: 16, Batch number: 60, Loss: 19998.7265625\n",
      "Epoch: 18, Batch number: 8, Loss: 18982.255859375\n",
      "Epoch: 19, Batch number: 32, Loss: 19175.052734375\n",
      "Epoch: 20, Batch number: 56, Loss: 18864.435546875\n",
      "Epoch: 22, Batch number: 4, Loss: 18603.744140625\n",
      "Epoch: 23, Batch number: 28, Loss: 18433.31640625\n",
      "Epoch: 24, Batch number: 52, Loss: 17899.236328125\n",
      "Epoch: 26, Batch number: 0, Loss: 18084.64453125\n",
      "Epoch: 27, Batch number: 24, Loss: 17926.48828125\n",
      "Epoch: 28, Batch number: 48, Loss: 17756.763671875\n",
      "Epoch: 29, Batch number: 72, Loss: 17881.201171875\n",
      "Epoch: 31, Batch number: 20, Loss: 17765.748046875\n",
      "Epoch: 32, Batch number: 44, Loss: 17514.255859375\n",
      "Epoch: 33, Batch number: 68, Loss: 17893.541015625\n",
      "Epoch: 35, Batch number: 16, Loss: 17895.162109375\n",
      "Epoch: 36, Batch number: 40, Loss: 17534.9609375\n",
      "Epoch: 37, Batch number: 64, Loss: 17632.826171875\n",
      "Epoch: 39, Batch number: 12, Loss: 17919.181640625\n",
      "Epoch: 40, Batch number: 36, Loss: 17359.93359375\n",
      "Epoch: 41, Batch number: 60, Loss: 17532.396484375\n",
      "Epoch: 43, Batch number: 8, Loss: 17239.451171875\n",
      "Epoch: 44, Batch number: 32, Loss: 17574.8359375\n",
      "Epoch: 45, Batch number: 56, Loss: 17585.748046875\n",
      "Epoch: 47, Batch number: 4, Loss: 17256.359375\n",
      "Epoch: 48, Batch number: 28, Loss: 17012.328125\n",
      "Epoch: 49, Batch number: 52, Loss: 17093.07421875\n",
      "Epoch: 51, Batch number: 0, Loss: 16755.578125\n",
      "Epoch: 52, Batch number: 24, Loss: 16960.974609375\n",
      "Epoch: 53, Batch number: 48, Loss: 17174.9375\n",
      "Epoch: 54, Batch number: 72, Loss: 17102.771484375\n",
      "Epoch: 56, Batch number: 20, Loss: 16998.62109375\n",
      "Epoch: 57, Batch number: 44, Loss: 17182.34375\n",
      "Epoch: 58, Batch number: 68, Loss: 17087.71484375\n",
      "Epoch: 60, Batch number: 16, Loss: 16680.103515625\n",
      "Epoch: 61, Batch number: 40, Loss: 17088.474609375\n",
      "Epoch: 62, Batch number: 64, Loss: 17243.87109375\n",
      "Epoch: 64, Batch number: 12, Loss: 16888.4609375\n",
      "Epoch: 65, Batch number: 36, Loss: 16651.791015625\n",
      "Epoch: 66, Batch number: 60, Loss: 16760.396484375\n",
      "Epoch: 68, Batch number: 8, Loss: 16517.0234375\n",
      "Epoch: 69, Batch number: 32, Loss: 16537.541015625\n",
      "Epoch: 70, Batch number: 56, Loss: 16635.4375\n",
      "Epoch: 72, Batch number: 4, Loss: 16377.423828125\n",
      "Epoch: 73, Batch number: 28, Loss: 16650.181640625\n",
      "Epoch: 74, Batch number: 52, Loss: 16510.8828125\n",
      "Epoch: 76, Batch number: 0, Loss: 16701.93359375\n",
      "Epoch: 77, Batch number: 24, Loss: 17334.154296875\n",
      "Epoch: 78, Batch number: 48, Loss: 16631.935546875\n",
      "Epoch: 79, Batch number: 72, Loss: 16664.986328125\n",
      "Epoch: 81, Batch number: 20, Loss: 16774.916015625\n",
      "Epoch: 82, Batch number: 44, Loss: 17076.759765625\n",
      "Epoch: 83, Batch number: 68, Loss: 17287.296875\n",
      "Epoch: 85, Batch number: 16, Loss: 16582.513671875\n",
      "Epoch: 86, Batch number: 40, Loss: 16736.01171875\n",
      "Epoch: 87, Batch number: 64, Loss: 16602.60546875\n",
      "Epoch: 89, Batch number: 12, Loss: 16890.453125\n",
      "Epoch: 90, Batch number: 36, Loss: 16960.04296875\n",
      "Epoch: 91, Batch number: 60, Loss: 16622.263671875\n",
      "Epoch: 93, Batch number: 8, Loss: 15956.8623046875\n",
      "Epoch: 94, Batch number: 32, Loss: 16556.10546875\n",
      "Epoch: 95, Batch number: 56, Loss: 17015.671875\n",
      "Epoch: 97, Batch number: 4, Loss: 16554.30859375\n",
      "Epoch: 98, Batch number: 28, Loss: 16221.251953125\n",
      "Epoch: 99, Batch number: 52, Loss: 16614.037109375\n",
      "Epoch: 101, Batch number: 0, Loss: 16356.8505859375\n",
      "Epoch: 102, Batch number: 24, Loss: 16191.876953125\n",
      "Epoch: 103, Batch number: 48, Loss: 16498.7890625\n",
      "Epoch: 104, Batch number: 72, Loss: 16309.5107421875\n",
      "Epoch: 106, Batch number: 20, Loss: 16280.80859375\n",
      "Epoch: 107, Batch number: 44, Loss: 16350.939453125\n",
      "Epoch: 108, Batch number: 68, Loss: 16602.55078125\n",
      "Epoch: 110, Batch number: 16, Loss: 16351.650390625\n",
      "Epoch: 111, Batch number: 40, Loss: 16348.76953125\n",
      "Epoch: 112, Batch number: 64, Loss: 16284.923828125\n",
      "Epoch: 114, Batch number: 12, Loss: 16415.005859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115, Batch number: 36, Loss: 16044.583984375\n",
      "Epoch: 116, Batch number: 60, Loss: 16646.21875\n",
      "Epoch: 118, Batch number: 8, Loss: 16492.0\n",
      "Epoch: 119, Batch number: 32, Loss: 16390.40234375\n",
      "Epoch: 120, Batch number: 56, Loss: 16356.1357421875\n",
      "Epoch: 122, Batch number: 4, Loss: 16047.576171875\n",
      "Epoch: 123, Batch number: 28, Loss: 16456.923828125\n",
      "Epoch: 124, Batch number: 52, Loss: 16112.6884765625\n",
      "Epoch: 126, Batch number: 0, Loss: 16536.255859375\n",
      "Epoch: 127, Batch number: 24, Loss: 15630.8876953125\n",
      "Epoch: 128, Batch number: 48, Loss: 16051.3291015625\n",
      "Epoch: 129, Batch number: 72, Loss: 16207.4423828125\n",
      "Epoch: 131, Batch number: 20, Loss: 16260.3671875\n",
      "Epoch: 132, Batch number: 44, Loss: 16333.8798828125\n",
      "Epoch: 133, Batch number: 68, Loss: 16788.86328125\n",
      "Epoch: 135, Batch number: 16, Loss: 16462.865234375\n",
      "Epoch: 136, Batch number: 40, Loss: 16140.669921875\n",
      "Epoch: 137, Batch number: 64, Loss: 16863.39453125\n",
      "Epoch: 139, Batch number: 12, Loss: 16405.650390625\n",
      "Epoch: 140, Batch number: 36, Loss: 16397.2890625\n",
      "Epoch: 141, Batch number: 60, Loss: 16353.5537109375\n",
      "Epoch: 143, Batch number: 8, Loss: 16202.37109375\n",
      "Epoch: 144, Batch number: 32, Loss: 16067.193359375\n",
      "Epoch: 145, Batch number: 56, Loss: 16624.8515625\n",
      "Epoch: 147, Batch number: 4, Loss: 16040.6923828125\n",
      "Epoch: 148, Batch number: 28, Loss: 16187.267578125\n",
      "Epoch: 149, Batch number: 52, Loss: 16141.978515625\n",
      "Epoch: 151, Batch number: 0, Loss: 15659.1962890625\n",
      "Epoch: 152, Batch number: 24, Loss: 15815.5\n",
      "Epoch: 153, Batch number: 48, Loss: 16161.4384765625\n",
      "Epoch: 154, Batch number: 72, Loss: 16741.1015625\n",
      "Epoch: 156, Batch number: 20, Loss: 16696.2109375\n",
      "Epoch: 157, Batch number: 44, Loss: 16272.9296875\n",
      "Epoch: 158, Batch number: 68, Loss: 16079.8828125\n",
      "Epoch: 160, Batch number: 16, Loss: 16157.671875\n",
      "Epoch: 161, Batch number: 40, Loss: 15960.935546875\n",
      "Epoch: 162, Batch number: 64, Loss: 16098.3818359375\n",
      "Epoch: 164, Batch number: 12, Loss: 15710.6064453125\n",
      "Epoch: 165, Batch number: 36, Loss: 16009.2841796875\n",
      "Epoch: 166, Batch number: 60, Loss: 16510.171875\n",
      "Epoch: 168, Batch number: 8, Loss: 16333.5361328125\n",
      "Epoch: 169, Batch number: 32, Loss: 16418.314453125\n",
      "Epoch: 170, Batch number: 56, Loss: 16495.8828125\n",
      "Epoch: 172, Batch number: 4, Loss: 16238.955078125\n",
      "Epoch: 173, Batch number: 28, Loss: 16304.97265625\n",
      "Epoch: 174, Batch number: 52, Loss: 16763.185546875\n",
      "Epoch: 176, Batch number: 0, Loss: 16398.2890625\n",
      "Epoch: 177, Batch number: 24, Loss: 15853.5029296875\n",
      "Epoch: 178, Batch number: 48, Loss: 16365.6923828125\n",
      "Epoch: 179, Batch number: 72, Loss: 16392.947265625\n",
      "Epoch: 181, Batch number: 20, Loss: 15594.5625\n",
      "Epoch: 182, Batch number: 44, Loss: 16133.77734375\n",
      "Epoch: 183, Batch number: 68, Loss: 16538.830078125\n",
      "Epoch: 185, Batch number: 16, Loss: 15989.4033203125\n",
      "Epoch: 186, Batch number: 40, Loss: 15995.2548828125\n",
      "Epoch: 187, Batch number: 64, Loss: 16095.9580078125\n",
      "Epoch: 189, Batch number: 12, Loss: 16447.099609375\n",
      "Epoch: 190, Batch number: 36, Loss: 16914.4765625\n",
      "Epoch: 191, Batch number: 60, Loss: 16497.419921875\n",
      "Epoch: 193, Batch number: 8, Loss: 16304.1611328125\n",
      "Epoch: 194, Batch number: 32, Loss: 16240.21484375\n",
      "Epoch: 195, Batch number: 56, Loss: 16503.55078125\n",
      "Epoch: 197, Batch number: 4, Loss: 15838.28515625\n",
      "Epoch: 198, Batch number: 28, Loss: 16252.0380859375\n",
      "Epoch: 199, Batch number: 52, Loss: 16650.224609375\n",
      "Epoch: 201, Batch number: 0, Loss: 16048.240234375\n",
      "Epoch: 202, Batch number: 24, Loss: 15550.2939453125\n",
      "Epoch: 203, Batch number: 48, Loss: 16287.5205078125\n",
      "Epoch: 204, Batch number: 72, Loss: 16539.28515625\n",
      "Epoch: 206, Batch number: 20, Loss: 16104.1103515625\n",
      "Epoch: 207, Batch number: 44, Loss: 15900.2392578125\n",
      "Epoch: 208, Batch number: 68, Loss: 16487.017578125\n",
      "Epoch: 210, Batch number: 16, Loss: 15977.6669921875\n",
      "Epoch: 211, Batch number: 40, Loss: 16204.2919921875\n",
      "Epoch: 212, Batch number: 64, Loss: 16212.8310546875\n",
      "Epoch: 214, Batch number: 12, Loss: 15767.96875\n",
      "Epoch: 215, Batch number: 36, Loss: 16342.67578125\n",
      "Epoch: 216, Batch number: 60, Loss: 16400.416015625\n",
      "Epoch: 218, Batch number: 8, Loss: 15875.7158203125\n",
      "Epoch: 219, Batch number: 32, Loss: 16021.5029296875\n",
      "Epoch: 220, Batch number: 56, Loss: 16153.5126953125\n",
      "Epoch: 222, Batch number: 4, Loss: 16146.87890625\n",
      "Epoch: 223, Batch number: 28, Loss: 16553.861328125\n",
      "Epoch: 224, Batch number: 52, Loss: 17063.650390625\n",
      "Epoch: 226, Batch number: 0, Loss: 15889.7451171875\n",
      "Epoch: 227, Batch number: 24, Loss: 15993.49609375\n",
      "Epoch: 228, Batch number: 48, Loss: 16278.033203125\n",
      "Epoch: 229, Batch number: 72, Loss: 16370.78125\n",
      "Epoch: 231, Batch number: 20, Loss: 16161.5302734375\n",
      "Epoch: 232, Batch number: 44, Loss: 16413.2265625\n",
      "Epoch: 233, Batch number: 68, Loss: 16132.4462890625\n",
      "Epoch: 235, Batch number: 16, Loss: 16375.328125\n",
      "Epoch: 236, Batch number: 40, Loss: 16251.5361328125\n",
      "Epoch: 237, Batch number: 64, Loss: 15910.2177734375\n",
      "Epoch: 239, Batch number: 12, Loss: 15718.0712890625\n",
      "Epoch: 240, Batch number: 36, Loss: 15932.97265625\n",
      "Epoch: 241, Batch number: 60, Loss: 16567.61328125\n",
      "Epoch: 243, Batch number: 8, Loss: 15856.6611328125\n",
      "Epoch: 244, Batch number: 32, Loss: 16238.62890625\n",
      "Epoch: 245, Batch number: 56, Loss: 16601.720703125\n",
      "Epoch: 247, Batch number: 4, Loss: 15469.623046875\n",
      "Epoch: 248, Batch number: 28, Loss: 16301.736328125\n",
      "Epoch: 249, Batch number: 52, Loss: 16916.1796875\n",
      "Epoch: 251, Batch number: 0, Loss: 16094.8115234375\n",
      "Epoch: 252, Batch number: 24, Loss: 16100.6787109375\n",
      "Epoch: 253, Batch number: 48, Loss: 16550.171875\n",
      "Epoch: 254, Batch number: 72, Loss: 16455.244140625\n",
      "Epoch: 256, Batch number: 20, Loss: 16288.9169921875\n",
      "Epoch: 257, Batch number: 44, Loss: 15928.7841796875\n",
      "Epoch: 258, Batch number: 68, Loss: 16339.2890625\n",
      "Epoch: 260, Batch number: 16, Loss: 16171.03515625\n",
      "Epoch: 261, Batch number: 40, Loss: 16282.072265625\n",
      "Epoch: 262, Batch number: 64, Loss: 16449.703125\n",
      "Epoch: 264, Batch number: 12, Loss: 15825.9462890625\n",
      "Epoch: 265, Batch number: 36, Loss: 15587.12109375\n",
      "Epoch: 266, Batch number: 60, Loss: 16160.9599609375\n",
      "Epoch: 268, Batch number: 8, Loss: 15997.37890625\n",
      "Epoch: 269, Batch number: 32, Loss: 16086.6904296875\n",
      "Epoch: 270, Batch number: 56, Loss: 16495.166015625\n",
      "Epoch: 272, Batch number: 4, Loss: 16028.646484375\n",
      "Epoch: 273, Batch number: 28, Loss: 16333.8837890625\n",
      "Epoch: 274, Batch number: 52, Loss: 15992.7265625\n",
      "Epoch: 276, Batch number: 0, Loss: 16367.48046875\n",
      "Epoch: 277, Batch number: 24, Loss: 16067.986328125\n",
      "Epoch: 278, Batch number: 48, Loss: 16318.4716796875\n",
      "Epoch: 279, Batch number: 72, Loss: 16381.8525390625\n",
      "Epoch: 281, Batch number: 20, Loss: 15875.1318359375\n",
      "Epoch: 282, Batch number: 44, Loss: 16162.33203125\n",
      "Epoch: 283, Batch number: 68, Loss: 16253.091796875\n",
      "Epoch: 285, Batch number: 16, Loss: 16173.2431640625\n",
      "Epoch: 286, Batch number: 40, Loss: 15814.3388671875\n",
      "Epoch: 287, Batch number: 64, Loss: 16108.8916015625\n",
      "Epoch: 289, Batch number: 12, Loss: 15668.736328125\n",
      "Epoch: 290, Batch number: 36, Loss: 16328.2822265625\n",
      "Epoch: 291, Batch number: 60, Loss: 16719.9765625\n",
      "Epoch: 293, Batch number: 8, Loss: 16272.1650390625\n",
      "Epoch: 294, Batch number: 32, Loss: 15883.150390625\n",
      "Epoch: 295, Batch number: 56, Loss: 16276.6640625\n",
      "Epoch: 297, Batch number: 4, Loss: 16304.8349609375\n",
      "Epoch: 298, Batch number: 28, Loss: 16060.5458984375\n",
      "Epoch: 299, Batch number: 52, Loss: 16135.6513671875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 31484.046875\n",
      "Epoch: 2, Batch number: 24, Loss: 28115.7421875\n",
      "Epoch: 3, Batch number: 48, Loss: 25948.296875\n",
      "Epoch: 4, Batch number: 72, Loss: 24560.15625\n",
      "Epoch: 6, Batch number: 20, Loss: 23385.177734375\n",
      "Epoch: 7, Batch number: 44, Loss: 22048.205078125\n",
      "Epoch: 8, Batch number: 68, Loss: 21123.49609375\n",
      "Epoch: 10, Batch number: 16, Loss: 20688.060546875\n",
      "Epoch: 11, Batch number: 40, Loss: 19625.08203125\n",
      "Epoch: 12, Batch number: 64, Loss: 20073.314453125\n",
      "Epoch: 14, Batch number: 12, Loss: 19259.40625\n",
      "Epoch: 15, Batch number: 36, Loss: 19328.31640625\n",
      "Epoch: 16, Batch number: 60, Loss: 18828.482421875\n",
      "Epoch: 18, Batch number: 8, Loss: 18563.029296875\n",
      "Epoch: 19, Batch number: 32, Loss: 17937.92578125\n",
      "Epoch: 20, Batch number: 56, Loss: 18292.6328125\n",
      "Epoch: 22, Batch number: 4, Loss: 17692.224609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Batch number: 28, Loss: 17898.3515625\n",
      "Epoch: 24, Batch number: 52, Loss: 17889.376953125\n",
      "Epoch: 26, Batch number: 0, Loss: 17462.724609375\n",
      "Epoch: 27, Batch number: 24, Loss: 17947.001953125\n",
      "Epoch: 28, Batch number: 48, Loss: 17315.166015625\n",
      "Epoch: 29, Batch number: 72, Loss: 17535.466796875\n",
      "Epoch: 31, Batch number: 20, Loss: 17665.197265625\n",
      "Epoch: 32, Batch number: 44, Loss: 17151.666015625\n",
      "Epoch: 33, Batch number: 68, Loss: 17813.875\n",
      "Epoch: 35, Batch number: 16, Loss: 16907.310546875\n",
      "Epoch: 36, Batch number: 40, Loss: 16976.482421875\n",
      "Epoch: 37, Batch number: 64, Loss: 17693.259765625\n",
      "Epoch: 39, Batch number: 12, Loss: 16734.109375\n",
      "Epoch: 40, Batch number: 36, Loss: 17175.34765625\n",
      "Epoch: 41, Batch number: 60, Loss: 17179.615234375\n",
      "Epoch: 43, Batch number: 8, Loss: 16930.818359375\n",
      "Epoch: 44, Batch number: 32, Loss: 16819.9140625\n",
      "Epoch: 45, Batch number: 56, Loss: 17131.716796875\n",
      "Epoch: 47, Batch number: 4, Loss: 17190.6015625\n",
      "Epoch: 48, Batch number: 28, Loss: 16685.283203125\n",
      "Epoch: 49, Batch number: 52, Loss: 17111.138671875\n",
      "Epoch: 51, Batch number: 0, Loss: 16952.677734375\n",
      "Epoch: 52, Batch number: 24, Loss: 16592.197265625\n",
      "Epoch: 53, Batch number: 48, Loss: 16927.0546875\n",
      "Epoch: 54, Batch number: 72, Loss: 16636.98046875\n",
      "Epoch: 56, Batch number: 20, Loss: 17180.150390625\n",
      "Epoch: 57, Batch number: 44, Loss: 16711.208984375\n",
      "Epoch: 58, Batch number: 68, Loss: 17020.7890625\n",
      "Epoch: 60, Batch number: 16, Loss: 16637.630859375\n",
      "Epoch: 61, Batch number: 40, Loss: 16714.705078125\n",
      "Epoch: 62, Batch number: 64, Loss: 16597.9453125\n",
      "Epoch: 64, Batch number: 12, Loss: 16541.29296875\n",
      "Epoch: 65, Batch number: 36, Loss: 16680.3515625\n",
      "Epoch: 66, Batch number: 60, Loss: 16689.126953125\n",
      "Epoch: 68, Batch number: 8, Loss: 16422.216796875\n",
      "Epoch: 69, Batch number: 32, Loss: 16402.8046875\n",
      "Epoch: 70, Batch number: 56, Loss: 16713.865234375\n",
      "Epoch: 72, Batch number: 4, Loss: 16366.7421875\n",
      "Epoch: 73, Batch number: 28, Loss: 16644.20703125\n",
      "Epoch: 74, Batch number: 52, Loss: 16504.712890625\n",
      "Epoch: 76, Batch number: 0, Loss: 16526.197265625\n",
      "Epoch: 77, Batch number: 24, Loss: 16594.087890625\n",
      "Epoch: 78, Batch number: 48, Loss: 16483.5859375\n",
      "Epoch: 79, Batch number: 72, Loss: 16536.96484375\n",
      "Epoch: 81, Batch number: 20, Loss: 16254.0458984375\n",
      "Epoch: 82, Batch number: 44, Loss: 16729.0703125\n",
      "Epoch: 83, Batch number: 68, Loss: 16474.287109375\n",
      "Epoch: 85, Batch number: 16, Loss: 16498.6484375\n",
      "Epoch: 86, Batch number: 40, Loss: 16834.83203125\n",
      "Epoch: 87, Batch number: 64, Loss: 16617.091796875\n",
      "Epoch: 89, Batch number: 12, Loss: 15802.51953125\n",
      "Epoch: 90, Batch number: 36, Loss: 16234.333984375\n",
      "Epoch: 91, Batch number: 60, Loss: 16731.84765625\n",
      "Epoch: 93, Batch number: 8, Loss: 16436.541015625\n",
      "Epoch: 94, Batch number: 32, Loss: 16720.619140625\n",
      "Epoch: 95, Batch number: 56, Loss: 16837.45703125\n",
      "Epoch: 97, Batch number: 4, Loss: 16283.2001953125\n",
      "Epoch: 98, Batch number: 28, Loss: 16112.3466796875\n",
      "Epoch: 99, Batch number: 52, Loss: 16313.154296875\n",
      "Epoch: 101, Batch number: 0, Loss: 15553.35546875\n",
      "Epoch: 102, Batch number: 24, Loss: 16380.259765625\n",
      "Epoch: 103, Batch number: 48, Loss: 16340.62109375\n",
      "Epoch: 104, Batch number: 72, Loss: 16487.169921875\n",
      "Epoch: 106, Batch number: 20, Loss: 16582.296875\n",
      "Epoch: 107, Batch number: 44, Loss: 16452.6875\n",
      "Epoch: 108, Batch number: 68, Loss: 16846.86328125\n",
      "Epoch: 110, Batch number: 16, Loss: 15824.361328125\n",
      "Epoch: 111, Batch number: 40, Loss: 17164.435546875\n",
      "Epoch: 112, Batch number: 64, Loss: 16113.46875\n",
      "Epoch: 114, Batch number: 12, Loss: 16297.46484375\n",
      "Epoch: 115, Batch number: 36, Loss: 16656.18359375\n",
      "Epoch: 116, Batch number: 60, Loss: 16582.865234375\n",
      "Epoch: 118, Batch number: 8, Loss: 15649.1787109375\n",
      "Epoch: 119, Batch number: 32, Loss: 16432.828125\n",
      "Epoch: 120, Batch number: 56, Loss: 16188.8193359375\n",
      "Epoch: 122, Batch number: 4, Loss: 16588.68359375\n",
      "Epoch: 123, Batch number: 28, Loss: 16142.482421875\n",
      "Epoch: 124, Batch number: 52, Loss: 16121.30078125\n",
      "Epoch: 126, Batch number: 0, Loss: 15658.7080078125\n",
      "Epoch: 127, Batch number: 24, Loss: 16323.1201171875\n",
      "Epoch: 128, Batch number: 48, Loss: 16032.46484375\n",
      "Epoch: 129, Batch number: 72, Loss: 16467.8125\n",
      "Epoch: 131, Batch number: 20, Loss: 16312.8837890625\n",
      "Epoch: 132, Batch number: 44, Loss: 16046.1025390625\n",
      "Epoch: 133, Batch number: 68, Loss: 16194.150390625\n",
      "Epoch: 135, Batch number: 16, Loss: 16228.404296875\n",
      "Epoch: 136, Batch number: 40, Loss: 16499.4296875\n",
      "Epoch: 137, Batch number: 64, Loss: 16178.2060546875\n",
      "Epoch: 139, Batch number: 12, Loss: 16187.947265625\n",
      "Epoch: 140, Batch number: 36, Loss: 16337.29296875\n",
      "Epoch: 141, Batch number: 60, Loss: 16010.6552734375\n",
      "Epoch: 143, Batch number: 8, Loss: 16189.53125\n",
      "Epoch: 144, Batch number: 32, Loss: 16524.8203125\n",
      "Epoch: 145, Batch number: 56, Loss: 17151.005859375\n",
      "Epoch: 147, Batch number: 4, Loss: 15895.677734375\n",
      "Epoch: 148, Batch number: 28, Loss: 16223.814453125\n",
      "Epoch: 149, Batch number: 52, Loss: 16346.85546875\n",
      "Epoch: 151, Batch number: 0, Loss: 15926.64453125\n",
      "Epoch: 152, Batch number: 24, Loss: 16323.41015625\n",
      "Epoch: 153, Batch number: 48, Loss: 16195.2568359375\n",
      "Epoch: 154, Batch number: 72, Loss: 16447.544921875\n",
      "Epoch: 156, Batch number: 20, Loss: 15860.6533203125\n",
      "Epoch: 157, Batch number: 44, Loss: 15892.87109375\n",
      "Epoch: 158, Batch number: 68, Loss: 16241.76953125\n",
      "Epoch: 160, Batch number: 16, Loss: 16283.9970703125\n",
      "Epoch: 161, Batch number: 40, Loss: 16009.96875\n",
      "Epoch: 162, Batch number: 64, Loss: 16097.8525390625\n",
      "Epoch: 164, Batch number: 12, Loss: 15170.064453125\n",
      "Epoch: 165, Batch number: 36, Loss: 16911.158203125\n",
      "Epoch: 166, Batch number: 60, Loss: 15907.4658203125\n",
      "Epoch: 168, Batch number: 8, Loss: 15824.73046875\n",
      "Epoch: 169, Batch number: 32, Loss: 16081.7216796875\n",
      "Epoch: 170, Batch number: 56, Loss: 16442.306640625\n",
      "Epoch: 172, Batch number: 4, Loss: 16159.732421875\n",
      "Epoch: 173, Batch number: 28, Loss: 16176.9658203125\n",
      "Epoch: 174, Batch number: 52, Loss: 16097.501953125\n",
      "Epoch: 176, Batch number: 0, Loss: 15958.783203125\n",
      "Epoch: 177, Batch number: 24, Loss: 16368.986328125\n",
      "Epoch: 178, Batch number: 48, Loss: 16169.3818359375\n",
      "Epoch: 179, Batch number: 72, Loss: 16666.208984375\n",
      "Epoch: 181, Batch number: 20, Loss: 16057.9560546875\n",
      "Epoch: 182, Batch number: 44, Loss: 16312.1240234375\n",
      "Epoch: 183, Batch number: 68, Loss: 16224.6083984375\n",
      "Epoch: 185, Batch number: 16, Loss: 15774.8466796875\n",
      "Epoch: 186, Batch number: 40, Loss: 16176.26953125\n",
      "Epoch: 187, Batch number: 64, Loss: 16551.89453125\n",
      "Epoch: 189, Batch number: 12, Loss: 15986.1953125\n",
      "Epoch: 190, Batch number: 36, Loss: 16383.978515625\n",
      "Epoch: 191, Batch number: 60, Loss: 16232.4150390625\n",
      "Epoch: 193, Batch number: 8, Loss: 16435.646484375\n",
      "Epoch: 194, Batch number: 32, Loss: 16322.7958984375\n",
      "Epoch: 195, Batch number: 56, Loss: 16614.818359375\n",
      "Epoch: 197, Batch number: 4, Loss: 15813.90234375\n",
      "Epoch: 198, Batch number: 28, Loss: 15859.0947265625\n",
      "Epoch: 199, Batch number: 52, Loss: 16797.73046875\n",
      "Epoch: 201, Batch number: 0, Loss: 15845.138671875\n",
      "Epoch: 202, Batch number: 24, Loss: 16298.564453125\n",
      "Epoch: 203, Batch number: 48, Loss: 15964.6748046875\n",
      "Epoch: 204, Batch number: 72, Loss: 16141.091796875\n",
      "Epoch: 206, Batch number: 20, Loss: 16439.43359375\n",
      "Epoch: 207, Batch number: 44, Loss: 16385.673828125\n",
      "Epoch: 208, Batch number: 68, Loss: 16378.6611328125\n",
      "Epoch: 210, Batch number: 16, Loss: 16224.8193359375\n",
      "Epoch: 211, Batch number: 40, Loss: 16397.826171875\n",
      "Epoch: 212, Batch number: 64, Loss: 16295.419921875\n",
      "Epoch: 214, Batch number: 12, Loss: 16211.037109375\n",
      "Epoch: 215, Batch number: 36, Loss: 16665.146484375\n",
      "Epoch: 216, Batch number: 60, Loss: 16624.2421875\n",
      "Epoch: 218, Batch number: 8, Loss: 15909.64453125\n",
      "Epoch: 219, Batch number: 32, Loss: 16179.7919921875\n",
      "Epoch: 220, Batch number: 56, Loss: 16364.625\n",
      "Epoch: 222, Batch number: 4, Loss: 15647.0390625\n",
      "Epoch: 223, Batch number: 28, Loss: 16243.203125\n",
      "Epoch: 224, Batch number: 52, Loss: 16632.25\n",
      "Epoch: 226, Batch number: 0, Loss: 16121.3447265625\n",
      "Epoch: 227, Batch number: 24, Loss: 16089.11328125\n",
      "Epoch: 228, Batch number: 48, Loss: 16226.2802734375\n",
      "Epoch: 229, Batch number: 72, Loss: 16569.2734375\n",
      "Epoch: 231, Batch number: 20, Loss: 16193.2607421875\n",
      "Epoch: 232, Batch number: 44, Loss: 16107.1611328125\n",
      "Epoch: 233, Batch number: 68, Loss: 16078.6259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 235, Batch number: 16, Loss: 16278.16015625\n",
      "Epoch: 236, Batch number: 40, Loss: 16359.693359375\n",
      "Epoch: 237, Batch number: 64, Loss: 16389.30078125\n",
      "Epoch: 239, Batch number: 12, Loss: 16246.2099609375\n",
      "Epoch: 240, Batch number: 36, Loss: 16376.228515625\n",
      "Epoch: 241, Batch number: 60, Loss: 15822.5947265625\n",
      "Epoch: 243, Batch number: 8, Loss: 16151.498046875\n",
      "Epoch: 244, Batch number: 32, Loss: 15712.580078125\n",
      "Epoch: 245, Batch number: 56, Loss: 16312.767578125\n",
      "Epoch: 247, Batch number: 4, Loss: 16038.451171875\n",
      "Epoch: 248, Batch number: 28, Loss: 16688.6484375\n",
      "Epoch: 249, Batch number: 52, Loss: 16076.8466796875\n",
      "Epoch: 251, Batch number: 0, Loss: 15963.8037109375\n",
      "Epoch: 252, Batch number: 24, Loss: 15950.9521484375\n",
      "Epoch: 253, Batch number: 48, Loss: 16163.4453125\n",
      "Epoch: 254, Batch number: 72, Loss: 16674.955078125\n",
      "Epoch: 256, Batch number: 20, Loss: 15972.8271484375\n",
      "Epoch: 257, Batch number: 44, Loss: 16065.9755859375\n",
      "Epoch: 258, Batch number: 68, Loss: 16440.8828125\n",
      "Epoch: 260, Batch number: 16, Loss: 15768.5234375\n",
      "Epoch: 261, Batch number: 40, Loss: 16103.0693359375\n",
      "Epoch: 262, Batch number: 64, Loss: 16386.27734375\n",
      "Epoch: 264, Batch number: 12, Loss: 16084.763671875\n",
      "Epoch: 265, Batch number: 36, Loss: 16117.876953125\n",
      "Epoch: 266, Batch number: 60, Loss: 16208.42578125\n",
      "Epoch: 268, Batch number: 8, Loss: 15766.8544921875\n",
      "Epoch: 269, Batch number: 32, Loss: 15976.87890625\n",
      "Epoch: 270, Batch number: 56, Loss: 15928.82421875\n",
      "Epoch: 272, Batch number: 4, Loss: 15923.1396484375\n",
      "Epoch: 273, Batch number: 28, Loss: 16457.775390625\n",
      "Epoch: 274, Batch number: 52, Loss: 16302.666015625\n",
      "Epoch: 276, Batch number: 0, Loss: 15517.169921875\n",
      "Epoch: 277, Batch number: 24, Loss: 15954.2568359375\n",
      "Epoch: 278, Batch number: 48, Loss: 15782.037109375\n",
      "Epoch: 279, Batch number: 72, Loss: 16302.9404296875\n",
      "Epoch: 281, Batch number: 20, Loss: 15883.7265625\n",
      "Epoch: 282, Batch number: 44, Loss: 16109.8447265625\n",
      "Epoch: 283, Batch number: 68, Loss: 15968.9091796875\n",
      "Epoch: 285, Batch number: 16, Loss: 15922.7138671875\n",
      "Epoch: 286, Batch number: 40, Loss: 16605.9609375\n",
      "Epoch: 287, Batch number: 64, Loss: 16257.685546875\n",
      "Epoch: 289, Batch number: 12, Loss: 16293.033203125\n",
      "Epoch: 290, Batch number: 36, Loss: 16331.0419921875\n",
      "Epoch: 291, Batch number: 60, Loss: 16263.5927734375\n",
      "Epoch: 293, Batch number: 8, Loss: 15789.0380859375\n",
      "Epoch: 294, Batch number: 32, Loss: 16709.708984375\n",
      "Epoch: 295, Batch number: 56, Loss: 16798.42578125\n",
      "Epoch: 297, Batch number: 4, Loss: 16149.90625\n",
      "Epoch: 298, Batch number: 28, Loss: 15946.65234375\n",
      "Epoch: 299, Batch number: 52, Loss: 16506.2265625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 35099.4140625\n",
      "Epoch: 2, Batch number: 24, Loss: 34196.9765625\n",
      "Epoch: 3, Batch number: 48, Loss: 32823.859375\n",
      "Epoch: 4, Batch number: 72, Loss: 32969.28125\n",
      "Epoch: 6, Batch number: 20, Loss: 31271.1015625\n",
      "Epoch: 7, Batch number: 44, Loss: 29802.939453125\n",
      "Epoch: 8, Batch number: 68, Loss: 29492.580078125\n",
      "Epoch: 10, Batch number: 16, Loss: 28460.51171875\n",
      "Epoch: 11, Batch number: 40, Loss: 27997.330078125\n",
      "Epoch: 12, Batch number: 64, Loss: 28058.21875\n",
      "Epoch: 14, Batch number: 12, Loss: 26902.146484375\n",
      "Epoch: 15, Batch number: 36, Loss: 26338.748046875\n",
      "Epoch: 16, Batch number: 60, Loss: 26640.169921875\n",
      "Epoch: 18, Batch number: 8, Loss: 26369.689453125\n",
      "Epoch: 19, Batch number: 32, Loss: 25789.30859375\n",
      "Epoch: 20, Batch number: 56, Loss: 25384.525390625\n",
      "Epoch: 22, Batch number: 4, Loss: 25159.265625\n",
      "Epoch: 23, Batch number: 28, Loss: 25212.92578125\n",
      "Epoch: 24, Batch number: 52, Loss: 25340.1484375\n",
      "Epoch: 26, Batch number: 0, Loss: 24894.1640625\n",
      "Epoch: 27, Batch number: 24, Loss: 25014.65234375\n",
      "Epoch: 28, Batch number: 48, Loss: 24900.46484375\n",
      "Epoch: 29, Batch number: 72, Loss: 24939.6640625\n",
      "Epoch: 31, Batch number: 20, Loss: 24288.626953125\n",
      "Epoch: 32, Batch number: 44, Loss: 24193.64453125\n",
      "Epoch: 33, Batch number: 68, Loss: 24062.15625\n",
      "Epoch: 35, Batch number: 16, Loss: 23727.576171875\n",
      "Epoch: 36, Batch number: 40, Loss: 24073.953125\n",
      "Epoch: 37, Batch number: 64, Loss: 23784.56640625\n",
      "Epoch: 39, Batch number: 12, Loss: 23881.947265625\n",
      "Epoch: 40, Batch number: 36, Loss: 23685.599609375\n",
      "Epoch: 41, Batch number: 60, Loss: 23699.8984375\n",
      "Epoch: 43, Batch number: 8, Loss: 23646.568359375\n",
      "Epoch: 44, Batch number: 32, Loss: 23878.076171875\n",
      "Epoch: 45, Batch number: 56, Loss: 23393.94921875\n",
      "Epoch: 47, Batch number: 4, Loss: 23854.5\n",
      "Epoch: 48, Batch number: 28, Loss: 23284.720703125\n",
      "Epoch: 49, Batch number: 52, Loss: 23061.541015625\n",
      "Epoch: 51, Batch number: 0, Loss: 23222.78515625\n",
      "Epoch: 52, Batch number: 24, Loss: 23337.21484375\n",
      "Epoch: 53, Batch number: 48, Loss: 22661.9453125\n",
      "Epoch: 54, Batch number: 72, Loss: 23183.01171875\n",
      "Epoch: 56, Batch number: 20, Loss: 22929.05859375\n",
      "Epoch: 57, Batch number: 44, Loss: 23137.91796875\n",
      "Epoch: 58, Batch number: 68, Loss: 23430.111328125\n",
      "Epoch: 60, Batch number: 16, Loss: 22945.099609375\n",
      "Epoch: 61, Batch number: 40, Loss: 22722.97265625\n",
      "Epoch: 62, Batch number: 64, Loss: 22993.1171875\n",
      "Epoch: 64, Batch number: 12, Loss: 22809.083984375\n",
      "Epoch: 65, Batch number: 36, Loss: 22862.5234375\n",
      "Epoch: 66, Batch number: 60, Loss: 22823.513671875\n",
      "Epoch: 68, Batch number: 8, Loss: 22804.80078125\n",
      "Epoch: 69, Batch number: 32, Loss: 22640.494140625\n",
      "Epoch: 70, Batch number: 56, Loss: 22639.88671875\n",
      "Epoch: 72, Batch number: 4, Loss: 21947.990234375\n",
      "Epoch: 73, Batch number: 28, Loss: 22124.982421875\n",
      "Epoch: 74, Batch number: 52, Loss: 22440.029296875\n",
      "Epoch: 76, Batch number: 0, Loss: 22611.28515625\n",
      "Epoch: 77, Batch number: 24, Loss: 22302.64453125\n",
      "Epoch: 78, Batch number: 48, Loss: 22425.89453125\n",
      "Epoch: 79, Batch number: 72, Loss: 22170.841796875\n",
      "Epoch: 81, Batch number: 20, Loss: 22152.728515625\n",
      "Epoch: 82, Batch number: 44, Loss: 22600.28515625\n",
      "Epoch: 83, Batch number: 68, Loss: 21930.369140625\n",
      "Epoch: 85, Batch number: 16, Loss: 22105.421875\n",
      "Epoch: 86, Batch number: 40, Loss: 21876.328125\n",
      "Epoch: 87, Batch number: 64, Loss: 22197.232421875\n",
      "Epoch: 89, Batch number: 12, Loss: 22159.638671875\n",
      "Epoch: 90, Batch number: 36, Loss: 22235.87890625\n",
      "Epoch: 91, Batch number: 60, Loss: 22290.12890625\n",
      "Epoch: 93, Batch number: 8, Loss: 22065.337890625\n",
      "Epoch: 94, Batch number: 32, Loss: 22261.9296875\n",
      "Epoch: 95, Batch number: 56, Loss: 21889.77734375\n",
      "Epoch: 97, Batch number: 4, Loss: 21857.125\n",
      "Epoch: 98, Batch number: 28, Loss: 21870.748046875\n",
      "Epoch: 99, Batch number: 52, Loss: 22075.173828125\n",
      "Epoch: 101, Batch number: 0, Loss: 22015.267578125\n",
      "Epoch: 102, Batch number: 24, Loss: 21463.2421875\n",
      "Epoch: 103, Batch number: 48, Loss: 21907.9375\n",
      "Epoch: 104, Batch number: 72, Loss: 21702.44921875\n",
      "Epoch: 106, Batch number: 20, Loss: 21530.27734375\n",
      "Epoch: 107, Batch number: 44, Loss: 21955.685546875\n",
      "Epoch: 108, Batch number: 68, Loss: 21621.978515625\n",
      "Epoch: 110, Batch number: 16, Loss: 21671.30859375\n",
      "Epoch: 111, Batch number: 40, Loss: 21556.3203125\n",
      "Epoch: 112, Batch number: 64, Loss: 21671.650390625\n",
      "Epoch: 114, Batch number: 12, Loss: 21385.5390625\n",
      "Epoch: 115, Batch number: 36, Loss: 21648.873046875\n",
      "Epoch: 116, Batch number: 60, Loss: 21735.21484375\n",
      "Epoch: 118, Batch number: 8, Loss: 21762.759765625\n",
      "Epoch: 119, Batch number: 32, Loss: 21296.15234375\n",
      "Epoch: 120, Batch number: 56, Loss: 21540.4140625\n",
      "Epoch: 122, Batch number: 4, Loss: 21291.802734375\n",
      "Epoch: 123, Batch number: 28, Loss: 21267.28125\n",
      "Epoch: 124, Batch number: 52, Loss: 21481.5859375\n",
      "Epoch: 126, Batch number: 0, Loss: 21385.626953125\n",
      "Epoch: 127, Batch number: 24, Loss: 21194.572265625\n",
      "Epoch: 128, Batch number: 48, Loss: 21262.380859375\n",
      "Epoch: 129, Batch number: 72, Loss: 21479.837890625\n",
      "Epoch: 131, Batch number: 20, Loss: 21016.880859375\n",
      "Epoch: 132, Batch number: 44, Loss: 21412.501953125\n",
      "Epoch: 133, Batch number: 68, Loss: 21510.369140625\n",
      "Epoch: 135, Batch number: 16, Loss: 21035.326171875\n",
      "Epoch: 136, Batch number: 40, Loss: 21231.478515625\n",
      "Epoch: 137, Batch number: 64, Loss: 20724.912109375\n",
      "Epoch: 139, Batch number: 12, Loss: 21186.58984375\n",
      "Epoch: 140, Batch number: 36, Loss: 20976.97265625\n",
      "Epoch: 141, Batch number: 60, Loss: 21320.318359375\n",
      "Epoch: 143, Batch number: 8, Loss: 21161.013671875\n",
      "Epoch: 144, Batch number: 32, Loss: 20720.7578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, Batch number: 56, Loss: 21134.939453125\n",
      "Epoch: 147, Batch number: 4, Loss: 20946.142578125\n",
      "Epoch: 148, Batch number: 28, Loss: 20928.4296875\n",
      "Epoch: 149, Batch number: 52, Loss: 20567.33203125\n",
      "Epoch: 151, Batch number: 0, Loss: 20676.37890625\n",
      "Epoch: 152, Batch number: 24, Loss: 21122.162109375\n",
      "Epoch: 153, Batch number: 48, Loss: 20861.52734375\n",
      "Epoch: 154, Batch number: 72, Loss: 20837.666015625\n",
      "Epoch: 156, Batch number: 20, Loss: 21085.494140625\n",
      "Epoch: 157, Batch number: 44, Loss: 20701.576171875\n",
      "Epoch: 158, Batch number: 68, Loss: 20819.58203125\n",
      "Epoch: 160, Batch number: 16, Loss: 20312.716796875\n",
      "Epoch: 161, Batch number: 40, Loss: 20571.05078125\n",
      "Epoch: 162, Batch number: 64, Loss: 20922.904296875\n",
      "Epoch: 164, Batch number: 12, Loss: 21198.337890625\n",
      "Epoch: 165, Batch number: 36, Loss: 20670.939453125\n",
      "Epoch: 166, Batch number: 60, Loss: 20799.759765625\n",
      "Epoch: 168, Batch number: 8, Loss: 20650.640625\n",
      "Epoch: 169, Batch number: 32, Loss: 20684.572265625\n",
      "Epoch: 170, Batch number: 56, Loss: 20792.591796875\n",
      "Epoch: 172, Batch number: 4, Loss: 20671.970703125\n",
      "Epoch: 173, Batch number: 28, Loss: 20659.431640625\n",
      "Epoch: 174, Batch number: 52, Loss: 20543.642578125\n",
      "Epoch: 176, Batch number: 0, Loss: 20329.609375\n",
      "Epoch: 177, Batch number: 24, Loss: 20462.927734375\n",
      "Epoch: 178, Batch number: 48, Loss: 20509.546875\n",
      "Epoch: 179, Batch number: 72, Loss: 20413.7734375\n",
      "Epoch: 181, Batch number: 20, Loss: 20638.54296875\n",
      "Epoch: 182, Batch number: 44, Loss: 20185.6640625\n",
      "Epoch: 183, Batch number: 68, Loss: 20644.541015625\n",
      "Epoch: 185, Batch number: 16, Loss: 20166.802734375\n",
      "Epoch: 186, Batch number: 40, Loss: 20552.0234375\n",
      "Epoch: 187, Batch number: 64, Loss: 20782.525390625\n",
      "Epoch: 189, Batch number: 12, Loss: 20452.28125\n",
      "Epoch: 190, Batch number: 36, Loss: 20633.275390625\n",
      "Epoch: 191, Batch number: 60, Loss: 20730.9453125\n",
      "Epoch: 193, Batch number: 8, Loss: 20316.2109375\n",
      "Epoch: 194, Batch number: 32, Loss: 19984.541015625\n",
      "Epoch: 195, Batch number: 56, Loss: 20289.88671875\n",
      "Epoch: 197, Batch number: 4, Loss: 19655.501953125\n",
      "Epoch: 198, Batch number: 28, Loss: 20334.69921875\n",
      "Epoch: 199, Batch number: 52, Loss: 20105.203125\n",
      "Epoch: 201, Batch number: 0, Loss: 20483.33203125\n",
      "Epoch: 202, Batch number: 24, Loss: 20576.087890625\n",
      "Epoch: 203, Batch number: 48, Loss: 20099.38671875\n",
      "Epoch: 204, Batch number: 72, Loss: 20947.865234375\n",
      "Epoch: 206, Batch number: 20, Loss: 20015.951171875\n",
      "Epoch: 207, Batch number: 44, Loss: 19951.9921875\n",
      "Epoch: 208, Batch number: 68, Loss: 20314.951171875\n",
      "Epoch: 210, Batch number: 16, Loss: 20125.779296875\n",
      "Epoch: 211, Batch number: 40, Loss: 20147.73046875\n",
      "Epoch: 212, Batch number: 64, Loss: 20589.275390625\n",
      "Epoch: 214, Batch number: 12, Loss: 20654.244140625\n",
      "Epoch: 215, Batch number: 36, Loss: 19975.080078125\n",
      "Epoch: 216, Batch number: 60, Loss: 20209.978515625\n",
      "Epoch: 218, Batch number: 8, Loss: 20223.458984375\n",
      "Epoch: 219, Batch number: 32, Loss: 20164.853515625\n",
      "Epoch: 220, Batch number: 56, Loss: 20113.2109375\n",
      "Epoch: 222, Batch number: 4, Loss: 20140.8125\n",
      "Epoch: 223, Batch number: 28, Loss: 20079.955078125\n",
      "Epoch: 224, Batch number: 52, Loss: 20340.884765625\n",
      "Epoch: 226, Batch number: 0, Loss: 20117.12109375\n",
      "Epoch: 227, Batch number: 24, Loss: 20205.931640625\n",
      "Epoch: 228, Batch number: 48, Loss: 19790.642578125\n",
      "Epoch: 229, Batch number: 72, Loss: 19477.431640625\n",
      "Epoch: 231, Batch number: 20, Loss: 20006.552734375\n",
      "Epoch: 232, Batch number: 44, Loss: 19991.8046875\n",
      "Epoch: 233, Batch number: 68, Loss: 19604.13671875\n",
      "Epoch: 235, Batch number: 16, Loss: 20295.962890625\n",
      "Epoch: 236, Batch number: 40, Loss: 20183.615234375\n",
      "Epoch: 237, Batch number: 64, Loss: 20000.380859375\n",
      "Epoch: 239, Batch number: 12, Loss: 20226.591796875\n",
      "Epoch: 240, Batch number: 36, Loss: 20303.8359375\n",
      "Epoch: 241, Batch number: 60, Loss: 20048.125\n",
      "Epoch: 243, Batch number: 8, Loss: 19776.18359375\n",
      "Epoch: 244, Batch number: 32, Loss: 19944.61328125\n",
      "Epoch: 245, Batch number: 56, Loss: 19882.232421875\n",
      "Epoch: 247, Batch number: 4, Loss: 20089.708984375\n",
      "Epoch: 248, Batch number: 28, Loss: 20246.427734375\n",
      "Epoch: 249, Batch number: 52, Loss: 19888.658203125\n",
      "Epoch: 251, Batch number: 0, Loss: 19504.08203125\n",
      "Epoch: 252, Batch number: 24, Loss: 19926.408203125\n",
      "Epoch: 253, Batch number: 48, Loss: 19548.12109375\n",
      "Epoch: 254, Batch number: 72, Loss: 20125.083984375\n",
      "Epoch: 256, Batch number: 20, Loss: 19913.5\n",
      "Epoch: 257, Batch number: 44, Loss: 19765.802734375\n",
      "Epoch: 258, Batch number: 68, Loss: 20084.607421875\n",
      "Epoch: 260, Batch number: 16, Loss: 19639.34375\n",
      "Epoch: 261, Batch number: 40, Loss: 19624.607421875\n",
      "Epoch: 262, Batch number: 64, Loss: 20255.52734375\n",
      "Epoch: 264, Batch number: 12, Loss: 19936.84765625\n",
      "Epoch: 265, Batch number: 36, Loss: 19887.58203125\n",
      "Epoch: 266, Batch number: 60, Loss: 20117.462890625\n",
      "Epoch: 268, Batch number: 8, Loss: 19978.041015625\n",
      "Epoch: 269, Batch number: 32, Loss: 19966.6796875\n",
      "Epoch: 270, Batch number: 56, Loss: 19431.32421875\n",
      "Epoch: 272, Batch number: 4, Loss: 19843.5546875\n",
      "Epoch: 273, Batch number: 28, Loss: 19734.994140625\n",
      "Epoch: 274, Batch number: 52, Loss: 20310.94921875\n",
      "Epoch: 276, Batch number: 0, Loss: 19484.158203125\n",
      "Epoch: 277, Batch number: 24, Loss: 19753.998046875\n",
      "Epoch: 278, Batch number: 48, Loss: 19692.697265625\n",
      "Epoch: 279, Batch number: 72, Loss: 19773.05078125\n",
      "Epoch: 281, Batch number: 20, Loss: 19716.28125\n",
      "Epoch: 282, Batch number: 44, Loss: 19621.38671875\n",
      "Epoch: 283, Batch number: 68, Loss: 19975.88671875\n",
      "Epoch: 285, Batch number: 16, Loss: 19797.0625\n",
      "Epoch: 286, Batch number: 40, Loss: 19538.978515625\n",
      "Epoch: 287, Batch number: 64, Loss: 20097.578125\n",
      "Epoch: 289, Batch number: 12, Loss: 19568.4296875\n",
      "Epoch: 290, Batch number: 36, Loss: 19508.703125\n",
      "Epoch: 291, Batch number: 60, Loss: 20109.76953125\n",
      "Epoch: 293, Batch number: 8, Loss: 19849.509765625\n",
      "Epoch: 294, Batch number: 32, Loss: 19849.50390625\n",
      "Epoch: 295, Batch number: 56, Loss: 19335.15234375\n",
      "Epoch: 297, Batch number: 4, Loss: 19612.205078125\n",
      "Epoch: 298, Batch number: 28, Loss: 19666.421875\n",
      "Epoch: 299, Batch number: 52, Loss: 19445.984375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 35633.9140625\n",
      "Epoch: 2, Batch number: 24, Loss: 33296.26171875\n",
      "Epoch: 3, Batch number: 48, Loss: 31301.279296875\n",
      "Epoch: 4, Batch number: 72, Loss: 30588.044921875\n",
      "Epoch: 6, Batch number: 20, Loss: 28876.193359375\n",
      "Epoch: 7, Batch number: 44, Loss: 28577.30859375\n",
      "Epoch: 8, Batch number: 68, Loss: 27730.916015625\n",
      "Epoch: 10, Batch number: 16, Loss: 26832.671875\n",
      "Epoch: 11, Batch number: 40, Loss: 26296.6640625\n",
      "Epoch: 12, Batch number: 64, Loss: 26262.216796875\n",
      "Epoch: 14, Batch number: 12, Loss: 25438.525390625\n",
      "Epoch: 15, Batch number: 36, Loss: 24960.328125\n",
      "Epoch: 16, Batch number: 60, Loss: 24617.236328125\n",
      "Epoch: 18, Batch number: 8, Loss: 24285.1953125\n",
      "Epoch: 19, Batch number: 32, Loss: 24184.103515625\n",
      "Epoch: 20, Batch number: 56, Loss: 23779.80078125\n",
      "Epoch: 22, Batch number: 4, Loss: 23964.44140625\n",
      "Epoch: 23, Batch number: 28, Loss: 23531.302734375\n",
      "Epoch: 24, Batch number: 52, Loss: 23353.255859375\n",
      "Epoch: 26, Batch number: 0, Loss: 23525.349609375\n",
      "Epoch: 27, Batch number: 24, Loss: 23153.109375\n",
      "Epoch: 28, Batch number: 48, Loss: 23332.541015625\n",
      "Epoch: 29, Batch number: 72, Loss: 23043.05078125\n",
      "Epoch: 31, Batch number: 20, Loss: 23047.21875\n",
      "Epoch: 32, Batch number: 44, Loss: 22939.85546875\n",
      "Epoch: 33, Batch number: 68, Loss: 22567.69921875\n",
      "Epoch: 35, Batch number: 16, Loss: 22396.5625\n",
      "Epoch: 36, Batch number: 40, Loss: 22373.06640625\n",
      "Epoch: 37, Batch number: 64, Loss: 21970.724609375\n",
      "Epoch: 39, Batch number: 12, Loss: 21964.837890625\n",
      "Epoch: 40, Batch number: 36, Loss: 22184.22265625\n",
      "Epoch: 41, Batch number: 60, Loss: 22116.240234375\n",
      "Epoch: 43, Batch number: 8, Loss: 21799.501953125\n",
      "Epoch: 44, Batch number: 32, Loss: 22018.642578125\n",
      "Epoch: 45, Batch number: 56, Loss: 21963.23828125\n",
      "Epoch: 47, Batch number: 4, Loss: 21610.248046875\n",
      "Epoch: 48, Batch number: 28, Loss: 21658.400390625\n",
      "Epoch: 49, Batch number: 52, Loss: 21518.998046875\n",
      "Epoch: 51, Batch number: 0, Loss: 21568.177734375\n",
      "Epoch: 52, Batch number: 24, Loss: 21336.12890625\n",
      "Epoch: 53, Batch number: 48, Loss: 21566.85546875\n",
      "Epoch: 54, Batch number: 72, Loss: 21641.7421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Batch number: 20, Loss: 21360.41015625\n",
      "Epoch: 57, Batch number: 44, Loss: 20937.111328125\n",
      "Epoch: 58, Batch number: 68, Loss: 21539.890625\n",
      "Epoch: 60, Batch number: 16, Loss: 21235.32421875\n",
      "Epoch: 61, Batch number: 40, Loss: 21297.751953125\n",
      "Epoch: 62, Batch number: 64, Loss: 21083.21484375\n",
      "Epoch: 64, Batch number: 12, Loss: 21074.751953125\n",
      "Epoch: 65, Batch number: 36, Loss: 20956.396484375\n",
      "Epoch: 66, Batch number: 60, Loss: 21050.86328125\n",
      "Epoch: 68, Batch number: 8, Loss: 20802.771484375\n",
      "Epoch: 69, Batch number: 32, Loss: 20968.1796875\n",
      "Epoch: 70, Batch number: 56, Loss: 20956.044921875\n",
      "Epoch: 72, Batch number: 4, Loss: 20900.7421875\n",
      "Epoch: 73, Batch number: 28, Loss: 20501.3984375\n",
      "Epoch: 74, Batch number: 52, Loss: 20613.716796875\n",
      "Epoch: 76, Batch number: 0, Loss: 20569.78125\n",
      "Epoch: 77, Batch number: 24, Loss: 20910.62890625\n",
      "Epoch: 78, Batch number: 48, Loss: 20891.126953125\n",
      "Epoch: 79, Batch number: 72, Loss: 20541.359375\n",
      "Epoch: 81, Batch number: 20, Loss: 20612.58203125\n",
      "Epoch: 82, Batch number: 44, Loss: 20411.00390625\n",
      "Epoch: 83, Batch number: 68, Loss: 20286.7734375\n",
      "Epoch: 85, Batch number: 16, Loss: 20593.84765625\n",
      "Epoch: 86, Batch number: 40, Loss: 20815.830078125\n",
      "Epoch: 87, Batch number: 64, Loss: 20590.00390625\n",
      "Epoch: 89, Batch number: 12, Loss: 20232.162109375\n",
      "Epoch: 90, Batch number: 36, Loss: 20598.111328125\n",
      "Epoch: 91, Batch number: 60, Loss: 20229.412109375\n",
      "Epoch: 93, Batch number: 8, Loss: 20447.228515625\n",
      "Epoch: 94, Batch number: 32, Loss: 20251.146484375\n",
      "Epoch: 95, Batch number: 56, Loss: 20098.509765625\n",
      "Epoch: 97, Batch number: 4, Loss: 20350.1328125\n",
      "Epoch: 98, Batch number: 28, Loss: 19622.744140625\n",
      "Epoch: 99, Batch number: 52, Loss: 20294.5703125\n",
      "Epoch: 101, Batch number: 0, Loss: 19824.373046875\n",
      "Epoch: 102, Batch number: 24, Loss: 19657.15625\n",
      "Epoch: 103, Batch number: 48, Loss: 20290.5859375\n",
      "Epoch: 104, Batch number: 72, Loss: 20172.6875\n",
      "Epoch: 106, Batch number: 20, Loss: 19588.068359375\n",
      "Epoch: 107, Batch number: 44, Loss: 20239.78515625\n",
      "Epoch: 108, Batch number: 68, Loss: 19872.875\n",
      "Epoch: 110, Batch number: 16, Loss: 20171.7890625\n",
      "Epoch: 111, Batch number: 40, Loss: 20149.17578125\n",
      "Epoch: 112, Batch number: 64, Loss: 20123.818359375\n",
      "Epoch: 114, Batch number: 12, Loss: 19687.734375\n",
      "Epoch: 115, Batch number: 36, Loss: 19452.244140625\n",
      "Epoch: 116, Batch number: 60, Loss: 20098.7734375\n",
      "Epoch: 118, Batch number: 8, Loss: 19678.58203125\n",
      "Epoch: 119, Batch number: 32, Loss: 19714.7421875\n",
      "Epoch: 120, Batch number: 56, Loss: 19978.08203125\n",
      "Epoch: 122, Batch number: 4, Loss: 19339.291015625\n",
      "Epoch: 123, Batch number: 28, Loss: 20010.05078125\n",
      "Epoch: 124, Batch number: 52, Loss: 19964.400390625\n",
      "Epoch: 126, Batch number: 0, Loss: 20069.984375\n",
      "Epoch: 127, Batch number: 24, Loss: 19448.2421875\n",
      "Epoch: 128, Batch number: 48, Loss: 19800.875\n",
      "Epoch: 129, Batch number: 72, Loss: 20137.201171875\n",
      "Epoch: 131, Batch number: 20, Loss: 19952.19140625\n",
      "Epoch: 132, Batch number: 44, Loss: 19248.484375\n",
      "Epoch: 133, Batch number: 68, Loss: 19649.162109375\n",
      "Epoch: 135, Batch number: 16, Loss: 19508.64453125\n",
      "Epoch: 136, Batch number: 40, Loss: 19861.822265625\n",
      "Epoch: 137, Batch number: 64, Loss: 19586.033203125\n",
      "Epoch: 139, Batch number: 12, Loss: 19228.017578125\n",
      "Epoch: 140, Batch number: 36, Loss: 19563.927734375\n",
      "Epoch: 141, Batch number: 60, Loss: 19615.60546875\n",
      "Epoch: 143, Batch number: 8, Loss: 19613.9296875\n",
      "Epoch: 144, Batch number: 32, Loss: 19608.08984375\n",
      "Epoch: 145, Batch number: 56, Loss: 19911.017578125\n",
      "Epoch: 147, Batch number: 4, Loss: 19022.548828125\n",
      "Epoch: 148, Batch number: 28, Loss: 19463.314453125\n",
      "Epoch: 149, Batch number: 52, Loss: 19262.1328125\n",
      "Epoch: 151, Batch number: 0, Loss: 18934.39453125\n",
      "Epoch: 152, Batch number: 24, Loss: 19287.595703125\n",
      "Epoch: 153, Batch number: 48, Loss: 19816.501953125\n",
      "Epoch: 154, Batch number: 72, Loss: 19806.38671875\n",
      "Epoch: 156, Batch number: 20, Loss: 19216.185546875\n",
      "Epoch: 157, Batch number: 44, Loss: 19458.22265625\n",
      "Epoch: 158, Batch number: 68, Loss: 19550.517578125\n",
      "Epoch: 160, Batch number: 16, Loss: 19569.95703125\n",
      "Epoch: 161, Batch number: 40, Loss: 19536.5\n",
      "Epoch: 162, Batch number: 64, Loss: 19659.41015625\n",
      "Epoch: 164, Batch number: 12, Loss: 19263.388671875\n",
      "Epoch: 165, Batch number: 36, Loss: 19334.94140625\n",
      "Epoch: 166, Batch number: 60, Loss: 19465.521484375\n",
      "Epoch: 168, Batch number: 8, Loss: 19276.201171875\n",
      "Epoch: 169, Batch number: 32, Loss: 19216.37890625\n",
      "Epoch: 170, Batch number: 56, Loss: 19539.6875\n",
      "Epoch: 172, Batch number: 4, Loss: 18941.87109375\n",
      "Epoch: 173, Batch number: 28, Loss: 19236.107421875\n",
      "Epoch: 174, Batch number: 52, Loss: 19509.791015625\n",
      "Epoch: 176, Batch number: 0, Loss: 19730.822265625\n",
      "Epoch: 177, Batch number: 24, Loss: 19309.095703125\n",
      "Epoch: 178, Batch number: 48, Loss: 18923.03515625\n",
      "Epoch: 179, Batch number: 72, Loss: 19441.4765625\n",
      "Epoch: 181, Batch number: 20, Loss: 19026.43359375\n",
      "Epoch: 182, Batch number: 44, Loss: 19404.798828125\n",
      "Epoch: 183, Batch number: 68, Loss: 18960.51171875\n",
      "Epoch: 185, Batch number: 16, Loss: 19308.0859375\n",
      "Epoch: 186, Batch number: 40, Loss: 19218.85546875\n",
      "Epoch: 187, Batch number: 64, Loss: 19313.556640625\n",
      "Epoch: 189, Batch number: 12, Loss: 19016.390625\n",
      "Epoch: 190, Batch number: 36, Loss: 18757.546875\n",
      "Epoch: 191, Batch number: 60, Loss: 19370.896484375\n",
      "Epoch: 193, Batch number: 8, Loss: 19487.21484375\n",
      "Epoch: 194, Batch number: 32, Loss: 19023.4140625\n",
      "Epoch: 195, Batch number: 56, Loss: 19026.328125\n",
      "Epoch: 197, Batch number: 4, Loss: 19063.267578125\n",
      "Epoch: 198, Batch number: 28, Loss: 19155.892578125\n",
      "Epoch: 199, Batch number: 52, Loss: 18754.390625\n",
      "Epoch: 201, Batch number: 0, Loss: 19075.517578125\n",
      "Epoch: 202, Batch number: 24, Loss: 18589.90625\n",
      "Epoch: 203, Batch number: 48, Loss: 18784.16796875\n",
      "Epoch: 204, Batch number: 72, Loss: 19282.275390625\n",
      "Epoch: 206, Batch number: 20, Loss: 18885.06640625\n",
      "Epoch: 207, Batch number: 44, Loss: 18964.435546875\n",
      "Epoch: 208, Batch number: 68, Loss: 18869.505859375\n",
      "Epoch: 210, Batch number: 16, Loss: 18975.69921875\n",
      "Epoch: 211, Batch number: 40, Loss: 19322.3046875\n",
      "Epoch: 212, Batch number: 64, Loss: 19131.87109375\n",
      "Epoch: 214, Batch number: 12, Loss: 19249.953125\n",
      "Epoch: 215, Batch number: 36, Loss: 19200.828125\n",
      "Epoch: 216, Batch number: 60, Loss: 19222.796875\n",
      "Epoch: 218, Batch number: 8, Loss: 18740.208984375\n",
      "Epoch: 219, Batch number: 32, Loss: 18917.052734375\n",
      "Epoch: 220, Batch number: 56, Loss: 19063.083984375\n",
      "Epoch: 222, Batch number: 4, Loss: 18787.609375\n",
      "Epoch: 223, Batch number: 28, Loss: 18718.51953125\n",
      "Epoch: 224, Batch number: 52, Loss: 19102.533203125\n",
      "Epoch: 226, Batch number: 0, Loss: 18998.45703125\n",
      "Epoch: 227, Batch number: 24, Loss: 18981.353515625\n",
      "Epoch: 228, Batch number: 48, Loss: 18831.884765625\n",
      "Epoch: 229, Batch number: 72, Loss: 19108.287109375\n",
      "Epoch: 231, Batch number: 20, Loss: 18792.123046875\n",
      "Epoch: 232, Batch number: 44, Loss: 18766.310546875\n",
      "Epoch: 233, Batch number: 68, Loss: 19103.91015625\n",
      "Epoch: 235, Batch number: 16, Loss: 18317.046875\n",
      "Epoch: 236, Batch number: 40, Loss: 18966.025390625\n",
      "Epoch: 237, Batch number: 64, Loss: 18459.451171875\n",
      "Epoch: 239, Batch number: 12, Loss: 18152.431640625\n",
      "Epoch: 240, Batch number: 36, Loss: 18639.248046875\n",
      "Epoch: 241, Batch number: 60, Loss: 18858.513671875\n",
      "Epoch: 243, Batch number: 8, Loss: 18221.650390625\n",
      "Epoch: 244, Batch number: 32, Loss: 18726.47265625\n",
      "Epoch: 245, Batch number: 56, Loss: 18829.404296875\n",
      "Epoch: 247, Batch number: 4, Loss: 18618.818359375\n",
      "Epoch: 248, Batch number: 28, Loss: 19129.212890625\n",
      "Epoch: 249, Batch number: 52, Loss: 18798.939453125\n",
      "Epoch: 251, Batch number: 0, Loss: 18569.154296875\n",
      "Epoch: 252, Batch number: 24, Loss: 18870.8203125\n",
      "Epoch: 253, Batch number: 48, Loss: 18814.650390625\n",
      "Epoch: 254, Batch number: 72, Loss: 18840.107421875\n",
      "Epoch: 256, Batch number: 20, Loss: 18895.626953125\n",
      "Epoch: 257, Batch number: 44, Loss: 18512.515625\n",
      "Epoch: 258, Batch number: 68, Loss: 19022.73828125\n",
      "Epoch: 260, Batch number: 16, Loss: 18754.111328125\n",
      "Epoch: 261, Batch number: 40, Loss: 19171.396484375\n",
      "Epoch: 262, Batch number: 64, Loss: 18870.787109375\n",
      "Epoch: 264, Batch number: 12, Loss: 18594.85546875\n",
      "Epoch: 265, Batch number: 36, Loss: 18319.525390625\n",
      "Epoch: 266, Batch number: 60, Loss: 18928.087890625\n",
      "Epoch: 268, Batch number: 8, Loss: 18648.767578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 269, Batch number: 32, Loss: 18698.494140625\n",
      "Epoch: 270, Batch number: 56, Loss: 18779.328125\n",
      "Epoch: 272, Batch number: 4, Loss: 18423.546875\n",
      "Epoch: 273, Batch number: 28, Loss: 18287.15625\n",
      "Epoch: 274, Batch number: 52, Loss: 18673.9453125\n",
      "Epoch: 276, Batch number: 0, Loss: 18845.7109375\n",
      "Epoch: 277, Batch number: 24, Loss: 18463.548828125\n",
      "Epoch: 278, Batch number: 48, Loss: 18869.484375\n",
      "Epoch: 279, Batch number: 72, Loss: 18524.404296875\n",
      "Epoch: 281, Batch number: 20, Loss: 18332.806640625\n",
      "Epoch: 282, Batch number: 44, Loss: 18236.482421875\n",
      "Epoch: 283, Batch number: 68, Loss: 18613.537109375\n",
      "Epoch: 285, Batch number: 16, Loss: 18434.767578125\n",
      "Epoch: 286, Batch number: 40, Loss: 18745.96484375\n",
      "Epoch: 287, Batch number: 64, Loss: 18304.80078125\n",
      "Epoch: 289, Batch number: 12, Loss: 18607.693359375\n",
      "Epoch: 290, Batch number: 36, Loss: 18498.794921875\n",
      "Epoch: 291, Batch number: 60, Loss: 18660.05859375\n",
      "Epoch: 293, Batch number: 8, Loss: 18632.369140625\n",
      "Epoch: 294, Batch number: 32, Loss: 18243.00390625\n",
      "Epoch: 295, Batch number: 56, Loss: 18099.154296875\n",
      "Epoch: 297, Batch number: 4, Loss: 18697.376953125\n",
      "Epoch: 298, Batch number: 28, Loss: 17668.462890625\n",
      "Epoch: 299, Batch number: 52, Loss: 18958.30078125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 34575.12890625\n",
      "Epoch: 2, Batch number: 24, Loss: 32696.5546875\n",
      "Epoch: 3, Batch number: 48, Loss: 30918.490234375\n",
      "Epoch: 4, Batch number: 72, Loss: 29251.865234375\n",
      "Epoch: 6, Batch number: 20, Loss: 28478.330078125\n",
      "Epoch: 7, Batch number: 44, Loss: 27618.234375\n",
      "Epoch: 8, Batch number: 68, Loss: 26460.80078125\n",
      "Epoch: 10, Batch number: 16, Loss: 26013.91015625\n",
      "Epoch: 11, Batch number: 40, Loss: 25199.1875\n",
      "Epoch: 12, Batch number: 64, Loss: 24896.4765625\n",
      "Epoch: 14, Batch number: 12, Loss: 24539.123046875\n",
      "Epoch: 15, Batch number: 36, Loss: 23937.169921875\n",
      "Epoch: 16, Batch number: 60, Loss: 23879.935546875\n",
      "Epoch: 18, Batch number: 8, Loss: 23649.466796875\n",
      "Epoch: 19, Batch number: 32, Loss: 23072.6328125\n",
      "Epoch: 20, Batch number: 56, Loss: 23190.501953125\n",
      "Epoch: 22, Batch number: 4, Loss: 22583.189453125\n",
      "Epoch: 23, Batch number: 28, Loss: 22442.8828125\n",
      "Epoch: 24, Batch number: 52, Loss: 22215.693359375\n",
      "Epoch: 26, Batch number: 0, Loss: 21947.884765625\n",
      "Epoch: 27, Batch number: 24, Loss: 21896.412109375\n",
      "Epoch: 28, Batch number: 48, Loss: 21892.298828125\n",
      "Epoch: 29, Batch number: 72, Loss: 21953.701171875\n",
      "Epoch: 31, Batch number: 20, Loss: 21500.146484375\n",
      "Epoch: 32, Batch number: 44, Loss: 21531.5546875\n",
      "Epoch: 33, Batch number: 68, Loss: 21520.3359375\n",
      "Epoch: 35, Batch number: 16, Loss: 21568.88671875\n",
      "Epoch: 36, Batch number: 40, Loss: 21298.45703125\n",
      "Epoch: 37, Batch number: 64, Loss: 21309.91796875\n",
      "Epoch: 39, Batch number: 12, Loss: 21148.98828125\n",
      "Epoch: 40, Batch number: 36, Loss: 20880.21875\n",
      "Epoch: 41, Batch number: 60, Loss: 20959.474609375\n",
      "Epoch: 43, Batch number: 8, Loss: 21067.9296875\n",
      "Epoch: 44, Batch number: 32, Loss: 21249.818359375\n",
      "Epoch: 45, Batch number: 56, Loss: 21070.421875\n",
      "Epoch: 47, Batch number: 4, Loss: 20467.826171875\n",
      "Epoch: 48, Batch number: 28, Loss: 20463.958984375\n",
      "Epoch: 49, Batch number: 52, Loss: 20693.353515625\n",
      "Epoch: 51, Batch number: 0, Loss: 20995.814453125\n",
      "Epoch: 52, Batch number: 24, Loss: 20780.63671875\n",
      "Epoch: 53, Batch number: 48, Loss: 20385.9921875\n",
      "Epoch: 54, Batch number: 72, Loss: 20624.8828125\n",
      "Epoch: 56, Batch number: 20, Loss: 20524.326171875\n",
      "Epoch: 57, Batch number: 44, Loss: 20712.78515625\n",
      "Epoch: 58, Batch number: 68, Loss: 20178.970703125\n",
      "Epoch: 60, Batch number: 16, Loss: 20263.064453125\n",
      "Epoch: 61, Batch number: 40, Loss: 19946.77734375\n",
      "Epoch: 62, Batch number: 64, Loss: 20600.5859375\n",
      "Epoch: 64, Batch number: 12, Loss: 20153.978515625\n",
      "Epoch: 65, Batch number: 36, Loss: 19952.927734375\n",
      "Epoch: 66, Batch number: 60, Loss: 19960.86328125\n",
      "Epoch: 68, Batch number: 8, Loss: 20025.609375\n",
      "Epoch: 69, Batch number: 32, Loss: 20015.404296875\n",
      "Epoch: 70, Batch number: 56, Loss: 20054.544921875\n",
      "Epoch: 72, Batch number: 4, Loss: 20222.603515625\n",
      "Epoch: 73, Batch number: 28, Loss: 20227.080078125\n",
      "Epoch: 74, Batch number: 52, Loss: 20162.583984375\n",
      "Epoch: 76, Batch number: 0, Loss: 19545.748046875\n",
      "Epoch: 77, Batch number: 24, Loss: 19990.71484375\n",
      "Epoch: 78, Batch number: 48, Loss: 20014.720703125\n",
      "Epoch: 79, Batch number: 72, Loss: 20600.5078125\n",
      "Epoch: 81, Batch number: 20, Loss: 19564.083984375\n",
      "Epoch: 82, Batch number: 44, Loss: 19821.716796875\n",
      "Epoch: 83, Batch number: 68, Loss: 20123.892578125\n",
      "Epoch: 85, Batch number: 16, Loss: 19426.578125\n",
      "Epoch: 86, Batch number: 40, Loss: 19602.380859375\n",
      "Epoch: 87, Batch number: 64, Loss: 19802.916015625\n",
      "Epoch: 89, Batch number: 12, Loss: 19614.6015625\n",
      "Epoch: 90, Batch number: 36, Loss: 19526.748046875\n",
      "Epoch: 91, Batch number: 60, Loss: 19548.982421875\n",
      "Epoch: 93, Batch number: 8, Loss: 19529.390625\n",
      "Epoch: 94, Batch number: 32, Loss: 19672.19921875\n",
      "Epoch: 95, Batch number: 56, Loss: 19525.4453125\n",
      "Epoch: 97, Batch number: 4, Loss: 19429.5859375\n",
      "Epoch: 98, Batch number: 28, Loss: 19803.427734375\n",
      "Epoch: 99, Batch number: 52, Loss: 19435.6015625\n",
      "Epoch: 101, Batch number: 0, Loss: 19284.603515625\n",
      "Epoch: 102, Batch number: 24, Loss: 19289.3046875\n",
      "Epoch: 103, Batch number: 48, Loss: 19770.080078125\n",
      "Epoch: 104, Batch number: 72, Loss: 19285.62109375\n",
      "Epoch: 106, Batch number: 20, Loss: 19063.810546875\n",
      "Epoch: 107, Batch number: 44, Loss: 19268.5546875\n",
      "Epoch: 108, Batch number: 68, Loss: 19810.373046875\n",
      "Epoch: 110, Batch number: 16, Loss: 19166.03125\n",
      "Epoch: 111, Batch number: 40, Loss: 18765.763671875\n",
      "Epoch: 112, Batch number: 64, Loss: 19019.75\n",
      "Epoch: 114, Batch number: 12, Loss: 19202.435546875\n",
      "Epoch: 115, Batch number: 36, Loss: 19300.23046875\n",
      "Epoch: 116, Batch number: 60, Loss: 19068.0\n",
      "Epoch: 118, Batch number: 8, Loss: 18979.0\n",
      "Epoch: 119, Batch number: 32, Loss: 19221.208984375\n",
      "Epoch: 120, Batch number: 56, Loss: 19115.458984375\n",
      "Epoch: 122, Batch number: 4, Loss: 19115.296875\n",
      "Epoch: 123, Batch number: 28, Loss: 19106.994140625\n",
      "Epoch: 124, Batch number: 52, Loss: 19279.36328125\n",
      "Epoch: 126, Batch number: 0, Loss: 18695.173828125\n",
      "Epoch: 127, Batch number: 24, Loss: 19143.02734375\n",
      "Epoch: 128, Batch number: 48, Loss: 18971.138671875\n",
      "Epoch: 129, Batch number: 72, Loss: 19356.197265625\n",
      "Epoch: 131, Batch number: 20, Loss: 18865.171875\n",
      "Epoch: 132, Batch number: 44, Loss: 18733.048828125\n",
      "Epoch: 133, Batch number: 68, Loss: 19129.509765625\n",
      "Epoch: 135, Batch number: 16, Loss: 18708.005859375\n",
      "Epoch: 136, Batch number: 40, Loss: 18936.072265625\n",
      "Epoch: 137, Batch number: 64, Loss: 19165.48828125\n",
      "Epoch: 139, Batch number: 12, Loss: 18921.359375\n",
      "Epoch: 140, Batch number: 36, Loss: 18915.328125\n",
      "Epoch: 141, Batch number: 60, Loss: 18761.275390625\n",
      "Epoch: 143, Batch number: 8, Loss: 18348.4375\n",
      "Epoch: 144, Batch number: 32, Loss: 19184.28125\n",
      "Epoch: 145, Batch number: 56, Loss: 18928.828125\n",
      "Epoch: 147, Batch number: 4, Loss: 18533.1171875\n",
      "Epoch: 148, Batch number: 28, Loss: 18902.76953125\n",
      "Epoch: 149, Batch number: 52, Loss: 19036.279296875\n",
      "Epoch: 151, Batch number: 0, Loss: 18639.4296875\n",
      "Epoch: 152, Batch number: 24, Loss: 18672.361328125\n",
      "Epoch: 153, Batch number: 48, Loss: 18669.748046875\n",
      "Epoch: 154, Batch number: 72, Loss: 18627.74609375\n",
      "Epoch: 156, Batch number: 20, Loss: 18447.9140625\n",
      "Epoch: 157, Batch number: 44, Loss: 18725.724609375\n",
      "Epoch: 158, Batch number: 68, Loss: 19094.951171875\n",
      "Epoch: 160, Batch number: 16, Loss: 18516.677734375\n",
      "Epoch: 161, Batch number: 40, Loss: 18851.57421875\n",
      "Epoch: 162, Batch number: 64, Loss: 18598.048828125\n",
      "Epoch: 164, Batch number: 12, Loss: 18434.037109375\n",
      "Epoch: 165, Batch number: 36, Loss: 19008.9375\n",
      "Epoch: 166, Batch number: 60, Loss: 18993.30078125\n",
      "Epoch: 168, Batch number: 8, Loss: 18614.650390625\n",
      "Epoch: 169, Batch number: 32, Loss: 18888.498046875\n",
      "Epoch: 170, Batch number: 56, Loss: 18457.658203125\n",
      "Epoch: 172, Batch number: 4, Loss: 18340.185546875\n",
      "Epoch: 173, Batch number: 28, Loss: 18702.111328125\n",
      "Epoch: 174, Batch number: 52, Loss: 18965.02734375\n",
      "Epoch: 176, Batch number: 0, Loss: 18805.62890625\n",
      "Epoch: 177, Batch number: 24, Loss: 18599.142578125\n",
      "Epoch: 178, Batch number: 48, Loss: 18441.3359375\n",
      "Epoch: 179, Batch number: 72, Loss: 18226.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181, Batch number: 20, Loss: 18265.490234375\n",
      "Epoch: 182, Batch number: 44, Loss: 18017.53515625\n",
      "Epoch: 183, Batch number: 68, Loss: 18144.451171875\n",
      "Epoch: 185, Batch number: 16, Loss: 18399.60546875\n",
      "Epoch: 186, Batch number: 40, Loss: 18462.240234375\n",
      "Epoch: 187, Batch number: 64, Loss: 18504.48828125\n",
      "Epoch: 189, Batch number: 12, Loss: 18937.99609375\n",
      "Epoch: 190, Batch number: 36, Loss: 18995.443359375\n",
      "Epoch: 191, Batch number: 60, Loss: 18440.91796875\n",
      "Epoch: 193, Batch number: 8, Loss: 18875.982421875\n",
      "Epoch: 194, Batch number: 32, Loss: 18775.265625\n",
      "Epoch: 195, Batch number: 56, Loss: 18974.806640625\n",
      "Epoch: 197, Batch number: 4, Loss: 18646.8203125\n",
      "Epoch: 198, Batch number: 28, Loss: 18451.19140625\n",
      "Epoch: 199, Batch number: 52, Loss: 18238.943359375\n",
      "Epoch: 201, Batch number: 0, Loss: 18273.384765625\n",
      "Epoch: 202, Batch number: 24, Loss: 18508.478515625\n",
      "Epoch: 203, Batch number: 48, Loss: 18514.193359375\n",
      "Epoch: 204, Batch number: 72, Loss: 18871.25\n",
      "Epoch: 206, Batch number: 20, Loss: 18683.3828125\n",
      "Epoch: 207, Batch number: 44, Loss: 18064.18359375\n",
      "Epoch: 208, Batch number: 68, Loss: 18776.58203125\n",
      "Epoch: 210, Batch number: 16, Loss: 18063.072265625\n",
      "Epoch: 211, Batch number: 40, Loss: 18267.60546875\n",
      "Epoch: 212, Batch number: 64, Loss: 18238.19140625\n",
      "Epoch: 214, Batch number: 12, Loss: 18404.947265625\n",
      "Epoch: 215, Batch number: 36, Loss: 18114.2421875\n",
      "Epoch: 216, Batch number: 60, Loss: 18720.04296875\n",
      "Epoch: 218, Batch number: 8, Loss: 18032.8671875\n",
      "Epoch: 219, Batch number: 32, Loss: 18993.466796875\n",
      "Epoch: 220, Batch number: 56, Loss: 18214.833984375\n",
      "Epoch: 222, Batch number: 4, Loss: 18409.0\n",
      "Epoch: 223, Batch number: 28, Loss: 18356.82421875\n",
      "Epoch: 224, Batch number: 52, Loss: 18943.0703125\n",
      "Epoch: 226, Batch number: 0, Loss: 18365.56640625\n",
      "Epoch: 227, Batch number: 24, Loss: 18093.125\n",
      "Epoch: 228, Batch number: 48, Loss: 17984.4140625\n",
      "Epoch: 229, Batch number: 72, Loss: 18633.8984375\n",
      "Epoch: 231, Batch number: 20, Loss: 18447.626953125\n",
      "Epoch: 232, Batch number: 44, Loss: 18722.21875\n",
      "Epoch: 233, Batch number: 68, Loss: 18418.294921875\n",
      "Epoch: 235, Batch number: 16, Loss: 18630.78515625\n",
      "Epoch: 236, Batch number: 40, Loss: 18408.72265625\n",
      "Epoch: 237, Batch number: 64, Loss: 18524.92578125\n",
      "Epoch: 239, Batch number: 12, Loss: 18331.341796875\n",
      "Epoch: 240, Batch number: 36, Loss: 17966.21875\n",
      "Epoch: 241, Batch number: 60, Loss: 18441.455078125\n",
      "Epoch: 243, Batch number: 8, Loss: 18821.31640625\n",
      "Epoch: 244, Batch number: 32, Loss: 18516.28125\n",
      "Epoch: 245, Batch number: 56, Loss: 18212.123046875\n",
      "Epoch: 247, Batch number: 4, Loss: 18195.994140625\n",
      "Epoch: 248, Batch number: 28, Loss: 17948.69921875\n",
      "Epoch: 249, Batch number: 52, Loss: 18477.697265625\n",
      "Epoch: 251, Batch number: 0, Loss: 18402.31640625\n",
      "Epoch: 252, Batch number: 24, Loss: 17887.947265625\n",
      "Epoch: 253, Batch number: 48, Loss: 18703.873046875\n",
      "Epoch: 254, Batch number: 72, Loss: 18244.880859375\n",
      "Epoch: 256, Batch number: 20, Loss: 18465.21875\n",
      "Epoch: 257, Batch number: 44, Loss: 18460.73046875\n",
      "Epoch: 258, Batch number: 68, Loss: 18730.49609375\n",
      "Epoch: 260, Batch number: 16, Loss: 18153.541015625\n",
      "Epoch: 261, Batch number: 40, Loss: 18280.041015625\n",
      "Epoch: 262, Batch number: 64, Loss: 18215.72265625\n",
      "Epoch: 264, Batch number: 12, Loss: 18504.2734375\n",
      "Epoch: 265, Batch number: 36, Loss: 18479.056640625\n",
      "Epoch: 266, Batch number: 60, Loss: 18516.01171875\n",
      "Epoch: 268, Batch number: 8, Loss: 18409.138671875\n",
      "Epoch: 269, Batch number: 32, Loss: 18319.962890625\n",
      "Epoch: 270, Batch number: 56, Loss: 18420.9765625\n",
      "Epoch: 272, Batch number: 4, Loss: 18375.599609375\n",
      "Epoch: 273, Batch number: 28, Loss: 17646.38671875\n",
      "Epoch: 274, Batch number: 52, Loss: 18448.96875\n",
      "Epoch: 276, Batch number: 0, Loss: 18449.828125\n",
      "Epoch: 277, Batch number: 24, Loss: 18613.888671875\n",
      "Epoch: 278, Batch number: 48, Loss: 18242.4609375\n",
      "Epoch: 279, Batch number: 72, Loss: 18011.21875\n",
      "Epoch: 281, Batch number: 20, Loss: 18407.95703125\n",
      "Epoch: 282, Batch number: 44, Loss: 18514.34765625\n",
      "Epoch: 283, Batch number: 68, Loss: 18866.203125\n",
      "Epoch: 285, Batch number: 16, Loss: 18084.228515625\n",
      "Epoch: 286, Batch number: 40, Loss: 18696.587890625\n",
      "Epoch: 287, Batch number: 64, Loss: 18192.80078125\n",
      "Epoch: 289, Batch number: 12, Loss: 18319.0703125\n",
      "Epoch: 290, Batch number: 36, Loss: 18141.615234375\n",
      "Epoch: 291, Batch number: 60, Loss: 18746.6640625\n",
      "Epoch: 293, Batch number: 8, Loss: 18025.72265625\n",
      "Epoch: 294, Batch number: 32, Loss: 18212.53125\n",
      "Epoch: 295, Batch number: 56, Loss: 17991.654296875\n",
      "Epoch: 297, Batch number: 4, Loss: 17863.341796875\n",
      "Epoch: 298, Batch number: 28, Loss: 17856.29296875\n",
      "Epoch: 299, Batch number: 52, Loss: 18074.67578125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 34975.93359375\n",
      "Epoch: 2, Batch number: 24, Loss: 32081.216796875\n",
      "Epoch: 3, Batch number: 48, Loss: 30271.03125\n",
      "Epoch: 4, Batch number: 72, Loss: 29005.3671875\n",
      "Epoch: 6, Batch number: 20, Loss: 28163.173828125\n",
      "Epoch: 7, Batch number: 44, Loss: 26746.546875\n",
      "Epoch: 8, Batch number: 68, Loss: 26056.353515625\n",
      "Epoch: 10, Batch number: 16, Loss: 25483.51171875\n",
      "Epoch: 11, Batch number: 40, Loss: 24787.408203125\n",
      "Epoch: 12, Batch number: 64, Loss: 24667.07421875\n",
      "Epoch: 14, Batch number: 12, Loss: 23349.95703125\n",
      "Epoch: 15, Batch number: 36, Loss: 23379.12890625\n",
      "Epoch: 16, Batch number: 60, Loss: 22839.857421875\n",
      "Epoch: 18, Batch number: 8, Loss: 22623.36328125\n",
      "Epoch: 19, Batch number: 32, Loss: 22141.75390625\n",
      "Epoch: 20, Batch number: 56, Loss: 22452.080078125\n",
      "Epoch: 22, Batch number: 4, Loss: 21791.8203125\n",
      "Epoch: 23, Batch number: 28, Loss: 22024.990234375\n",
      "Epoch: 24, Batch number: 52, Loss: 21703.01171875\n",
      "Epoch: 26, Batch number: 0, Loss: 21565.181640625\n",
      "Epoch: 27, Batch number: 24, Loss: 21673.091796875\n",
      "Epoch: 28, Batch number: 48, Loss: 21114.912109375\n",
      "Epoch: 29, Batch number: 72, Loss: 21237.244140625\n",
      "Epoch: 31, Batch number: 20, Loss: 21093.08984375\n",
      "Epoch: 32, Batch number: 44, Loss: 20782.376953125\n",
      "Epoch: 33, Batch number: 68, Loss: 20402.03515625\n",
      "Epoch: 35, Batch number: 16, Loss: 20351.66796875\n",
      "Epoch: 36, Batch number: 40, Loss: 20716.17578125\n",
      "Epoch: 37, Batch number: 64, Loss: 20497.0703125\n",
      "Epoch: 39, Batch number: 12, Loss: 20412.671875\n",
      "Epoch: 40, Batch number: 36, Loss: 20291.310546875\n",
      "Epoch: 41, Batch number: 60, Loss: 20491.185546875\n",
      "Epoch: 43, Batch number: 8, Loss: 20007.076171875\n",
      "Epoch: 44, Batch number: 32, Loss: 19729.59765625\n",
      "Epoch: 45, Batch number: 56, Loss: 20042.55859375\n",
      "Epoch: 47, Batch number: 4, Loss: 20272.93359375\n",
      "Epoch: 48, Batch number: 28, Loss: 19974.888671875\n",
      "Epoch: 49, Batch number: 52, Loss: 20374.373046875\n",
      "Epoch: 51, Batch number: 0, Loss: 20070.6875\n",
      "Epoch: 52, Batch number: 24, Loss: 19676.18359375\n",
      "Epoch: 53, Batch number: 48, Loss: 19977.669921875\n",
      "Epoch: 54, Batch number: 72, Loss: 20015.443359375\n",
      "Epoch: 56, Batch number: 20, Loss: 19826.84375\n",
      "Epoch: 57, Batch number: 44, Loss: 20046.42578125\n",
      "Epoch: 58, Batch number: 68, Loss: 20225.798828125\n",
      "Epoch: 60, Batch number: 16, Loss: 20173.470703125\n",
      "Epoch: 61, Batch number: 40, Loss: 19739.625\n",
      "Epoch: 62, Batch number: 64, Loss: 20126.5703125\n",
      "Epoch: 64, Batch number: 12, Loss: 19628.234375\n",
      "Epoch: 65, Batch number: 36, Loss: 19729.42578125\n",
      "Epoch: 66, Batch number: 60, Loss: 19596.712890625\n",
      "Epoch: 68, Batch number: 8, Loss: 18792.859375\n",
      "Epoch: 69, Batch number: 32, Loss: 19673.654296875\n",
      "Epoch: 70, Batch number: 56, Loss: 19642.890625\n",
      "Epoch: 72, Batch number: 4, Loss: 19243.166015625\n",
      "Epoch: 73, Batch number: 28, Loss: 19096.787109375\n",
      "Epoch: 74, Batch number: 52, Loss: 19314.560546875\n",
      "Epoch: 76, Batch number: 0, Loss: 19279.322265625\n",
      "Epoch: 77, Batch number: 24, Loss: 19201.9140625\n",
      "Epoch: 78, Batch number: 48, Loss: 19487.126953125\n",
      "Epoch: 79, Batch number: 72, Loss: 19673.822265625\n",
      "Epoch: 81, Batch number: 20, Loss: 19246.7578125\n",
      "Epoch: 82, Batch number: 44, Loss: 19139.5234375\n",
      "Epoch: 83, Batch number: 68, Loss: 19498.84765625\n",
      "Epoch: 85, Batch number: 16, Loss: 19523.044921875\n",
      "Epoch: 86, Batch number: 40, Loss: 19221.638671875\n",
      "Epoch: 87, Batch number: 64, Loss: 19903.271484375\n",
      "Epoch: 89, Batch number: 12, Loss: 18839.791015625\n",
      "Epoch: 90, Batch number: 36, Loss: 18977.216796875\n",
      "Epoch: 91, Batch number: 60, Loss: 19046.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, Batch number: 8, Loss: 18532.93359375\n",
      "Epoch: 94, Batch number: 32, Loss: 19041.349609375\n",
      "Epoch: 95, Batch number: 56, Loss: 19385.662109375\n",
      "Epoch: 97, Batch number: 4, Loss: 18679.015625\n",
      "Epoch: 98, Batch number: 28, Loss: 18839.708984375\n",
      "Epoch: 99, Batch number: 52, Loss: 18755.744140625\n",
      "Epoch: 101, Batch number: 0, Loss: 18773.4921875\n",
      "Epoch: 102, Batch number: 24, Loss: 19055.431640625\n",
      "Epoch: 103, Batch number: 48, Loss: 18991.92578125\n",
      "Epoch: 104, Batch number: 72, Loss: 19203.720703125\n",
      "Epoch: 106, Batch number: 20, Loss: 18625.091796875\n",
      "Epoch: 107, Batch number: 44, Loss: 18265.02734375\n",
      "Epoch: 108, Batch number: 68, Loss: 19092.3828125\n",
      "Epoch: 110, Batch number: 16, Loss: 18757.1015625\n",
      "Epoch: 111, Batch number: 40, Loss: 18769.05859375\n",
      "Epoch: 112, Batch number: 64, Loss: 18823.974609375\n",
      "Epoch: 114, Batch number: 12, Loss: 18315.48046875\n",
      "Epoch: 115, Batch number: 36, Loss: 18709.060546875\n",
      "Epoch: 116, Batch number: 60, Loss: 19085.064453125\n",
      "Epoch: 118, Batch number: 8, Loss: 19266.12109375\n",
      "Epoch: 119, Batch number: 32, Loss: 18453.01171875\n",
      "Epoch: 120, Batch number: 56, Loss: 18273.603515625\n",
      "Epoch: 122, Batch number: 4, Loss: 19011.462890625\n",
      "Epoch: 123, Batch number: 28, Loss: 18635.884765625\n",
      "Epoch: 124, Batch number: 52, Loss: 18958.30078125\n",
      "Epoch: 126, Batch number: 0, Loss: 18610.306640625\n",
      "Epoch: 127, Batch number: 24, Loss: 18560.95703125\n",
      "Epoch: 128, Batch number: 48, Loss: 18715.58203125\n",
      "Epoch: 129, Batch number: 72, Loss: 18806.740234375\n",
      "Epoch: 131, Batch number: 20, Loss: 17985.201171875\n",
      "Epoch: 132, Batch number: 44, Loss: 18276.08984375\n",
      "Epoch: 133, Batch number: 68, Loss: 18406.12109375\n",
      "Epoch: 135, Batch number: 16, Loss: 18842.583984375\n",
      "Epoch: 136, Batch number: 40, Loss: 18527.228515625\n",
      "Epoch: 137, Batch number: 64, Loss: 18795.138671875\n",
      "Epoch: 139, Batch number: 12, Loss: 18590.998046875\n",
      "Epoch: 140, Batch number: 36, Loss: 18365.619140625\n",
      "Epoch: 141, Batch number: 60, Loss: 19013.95703125\n",
      "Epoch: 143, Batch number: 8, Loss: 18330.91796875\n",
      "Epoch: 144, Batch number: 32, Loss: 18913.0078125\n",
      "Epoch: 145, Batch number: 56, Loss: 18698.9453125\n",
      "Epoch: 147, Batch number: 4, Loss: 18088.38671875\n",
      "Epoch: 148, Batch number: 28, Loss: 18225.75\n",
      "Epoch: 149, Batch number: 52, Loss: 18825.9140625\n",
      "Epoch: 151, Batch number: 0, Loss: 18180.025390625\n",
      "Epoch: 152, Batch number: 24, Loss: 18795.841796875\n",
      "Epoch: 153, Batch number: 48, Loss: 18235.236328125\n",
      "Epoch: 154, Batch number: 72, Loss: 18420.51171875\n",
      "Epoch: 156, Batch number: 20, Loss: 18490.50390625\n",
      "Epoch: 157, Batch number: 44, Loss: 18583.283203125\n",
      "Epoch: 158, Batch number: 68, Loss: 18113.21875\n",
      "Epoch: 160, Batch number: 16, Loss: 18124.978515625\n",
      "Epoch: 161, Batch number: 40, Loss: 18477.7109375\n",
      "Epoch: 162, Batch number: 64, Loss: 17804.095703125\n",
      "Epoch: 164, Batch number: 12, Loss: 18461.400390625\n",
      "Epoch: 165, Batch number: 36, Loss: 18450.658203125\n",
      "Epoch: 166, Batch number: 60, Loss: 18673.103515625\n",
      "Epoch: 168, Batch number: 8, Loss: 18004.546875\n",
      "Epoch: 169, Batch number: 32, Loss: 18346.6171875\n",
      "Epoch: 170, Batch number: 56, Loss: 18639.962890625\n",
      "Epoch: 172, Batch number: 4, Loss: 18437.455078125\n",
      "Epoch: 173, Batch number: 28, Loss: 18526.505859375\n",
      "Epoch: 174, Batch number: 52, Loss: 18647.11328125\n",
      "Epoch: 176, Batch number: 0, Loss: 18643.1171875\n",
      "Epoch: 177, Batch number: 24, Loss: 18154.982421875\n",
      "Epoch: 178, Batch number: 48, Loss: 18101.154296875\n",
      "Epoch: 179, Batch number: 72, Loss: 18633.40625\n",
      "Epoch: 181, Batch number: 20, Loss: 18672.037109375\n",
      "Epoch: 182, Batch number: 44, Loss: 18508.66015625\n",
      "Epoch: 183, Batch number: 68, Loss: 18501.939453125\n",
      "Epoch: 185, Batch number: 16, Loss: 18725.3203125\n",
      "Epoch: 186, Batch number: 40, Loss: 18489.982421875\n",
      "Epoch: 187, Batch number: 64, Loss: 19040.306640625\n",
      "Epoch: 189, Batch number: 12, Loss: 17943.8984375\n",
      "Epoch: 190, Batch number: 36, Loss: 18286.751953125\n",
      "Epoch: 191, Batch number: 60, Loss: 18452.583984375\n",
      "Epoch: 193, Batch number: 8, Loss: 17587.8046875\n",
      "Epoch: 194, Batch number: 32, Loss: 18389.361328125\n",
      "Epoch: 195, Batch number: 56, Loss: 17963.529296875\n",
      "Epoch: 197, Batch number: 4, Loss: 18267.845703125\n",
      "Epoch: 198, Batch number: 28, Loss: 18617.0859375\n",
      "Epoch: 199, Batch number: 52, Loss: 18611.78125\n",
      "Epoch: 201, Batch number: 0, Loss: 18034.62890625\n",
      "Epoch: 202, Batch number: 24, Loss: 18469.7734375\n",
      "Epoch: 203, Batch number: 48, Loss: 18867.86328125\n",
      "Epoch: 204, Batch number: 72, Loss: 18453.8671875\n",
      "Epoch: 206, Batch number: 20, Loss: 18725.1171875\n",
      "Epoch: 207, Batch number: 44, Loss: 18587.92578125\n",
      "Epoch: 208, Batch number: 68, Loss: 18153.77734375\n",
      "Epoch: 210, Batch number: 16, Loss: 17997.646484375\n",
      "Epoch: 211, Batch number: 40, Loss: 18214.01171875\n",
      "Epoch: 212, Batch number: 64, Loss: 18410.3359375\n",
      "Epoch: 214, Batch number: 12, Loss: 18096.958984375\n",
      "Epoch: 215, Batch number: 36, Loss: 18734.93359375\n",
      "Epoch: 216, Batch number: 60, Loss: 18455.19140625\n",
      "Epoch: 218, Batch number: 8, Loss: 18749.2109375\n",
      "Epoch: 219, Batch number: 32, Loss: 18599.384765625\n",
      "Epoch: 220, Batch number: 56, Loss: 18805.419921875\n",
      "Epoch: 222, Batch number: 4, Loss: 18624.28125\n",
      "Epoch: 223, Batch number: 28, Loss: 18225.2265625\n",
      "Epoch: 224, Batch number: 52, Loss: 17939.904296875\n",
      "Epoch: 226, Batch number: 0, Loss: 18212.46875\n",
      "Epoch: 227, Batch number: 24, Loss: 18127.201171875\n",
      "Epoch: 228, Batch number: 48, Loss: 18539.611328125\n",
      "Epoch: 229, Batch number: 72, Loss: 18585.712890625\n",
      "Epoch: 231, Batch number: 20, Loss: 18289.044921875\n",
      "Epoch: 232, Batch number: 44, Loss: 18162.650390625\n",
      "Epoch: 233, Batch number: 68, Loss: 18583.54296875\n",
      "Epoch: 235, Batch number: 16, Loss: 18464.013671875\n",
      "Epoch: 236, Batch number: 40, Loss: 18562.068359375\n",
      "Epoch: 237, Batch number: 64, Loss: 18674.7421875\n",
      "Epoch: 239, Batch number: 12, Loss: 17934.30859375\n",
      "Epoch: 240, Batch number: 36, Loss: 18304.087890625\n",
      "Epoch: 241, Batch number: 60, Loss: 18457.23828125\n",
      "Epoch: 243, Batch number: 8, Loss: 18571.576171875\n",
      "Epoch: 244, Batch number: 32, Loss: 18360.982421875\n",
      "Epoch: 245, Batch number: 56, Loss: 18343.53515625\n",
      "Epoch: 247, Batch number: 4, Loss: 18204.431640625\n",
      "Epoch: 248, Batch number: 28, Loss: 18481.708984375\n",
      "Epoch: 249, Batch number: 52, Loss: 18457.345703125\n",
      "Epoch: 251, Batch number: 0, Loss: 18693.734375\n",
      "Epoch: 252, Batch number: 24, Loss: 18743.88671875\n",
      "Epoch: 253, Batch number: 48, Loss: 18314.62890625\n",
      "Epoch: 254, Batch number: 72, Loss: 18038.626953125\n",
      "Epoch: 256, Batch number: 20, Loss: 18278.859375\n",
      "Epoch: 257, Batch number: 44, Loss: 18075.212890625\n",
      "Epoch: 258, Batch number: 68, Loss: 18196.125\n",
      "Epoch: 260, Batch number: 16, Loss: 18296.310546875\n",
      "Epoch: 261, Batch number: 40, Loss: 18302.515625\n",
      "Epoch: 262, Batch number: 64, Loss: 18298.384765625\n",
      "Epoch: 264, Batch number: 12, Loss: 18201.755859375\n",
      "Epoch: 265, Batch number: 36, Loss: 17700.283203125\n",
      "Epoch: 266, Batch number: 60, Loss: 18321.20703125\n",
      "Epoch: 268, Batch number: 8, Loss: 18264.296875\n",
      "Epoch: 269, Batch number: 32, Loss: 18225.087890625\n",
      "Epoch: 270, Batch number: 56, Loss: 18710.384765625\n",
      "Epoch: 272, Batch number: 4, Loss: 18361.4921875\n",
      "Epoch: 273, Batch number: 28, Loss: 18224.44140625\n",
      "Epoch: 274, Batch number: 52, Loss: 18270.775390625\n",
      "Epoch: 276, Batch number: 0, Loss: 18391.00390625\n",
      "Epoch: 277, Batch number: 24, Loss: 18015.6953125\n",
      "Epoch: 278, Batch number: 48, Loss: 18563.365234375\n",
      "Epoch: 279, Batch number: 72, Loss: 18595.71875\n",
      "Epoch: 281, Batch number: 20, Loss: 17947.841796875\n",
      "Epoch: 282, Batch number: 44, Loss: 17942.86328125\n",
      "Epoch: 283, Batch number: 68, Loss: 18450.091796875\n",
      "Epoch: 285, Batch number: 16, Loss: 18871.8125\n",
      "Epoch: 286, Batch number: 40, Loss: 18361.775390625\n",
      "Epoch: 287, Batch number: 64, Loss: 17874.10546875\n",
      "Epoch: 289, Batch number: 12, Loss: 17851.205078125\n",
      "Epoch: 290, Batch number: 36, Loss: 18423.939453125\n",
      "Epoch: 291, Batch number: 60, Loss: 18404.1953125\n",
      "Epoch: 293, Batch number: 8, Loss: 18250.857421875\n",
      "Epoch: 294, Batch number: 32, Loss: 19088.150390625\n",
      "Epoch: 295, Batch number: 56, Loss: 18420.103515625\n",
      "Epoch: 297, Batch number: 4, Loss: 18512.552734375\n",
      "Epoch: 298, Batch number: 28, Loss: 18641.25\n",
      "Epoch: 299, Batch number: 52, Loss: 18129.49609375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 35385.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 24, Loss: 31323.6796875\n",
      "Epoch: 3, Batch number: 48, Loss: 29306.095703125\n",
      "Epoch: 4, Batch number: 72, Loss: 28449.30078125\n",
      "Epoch: 6, Batch number: 20, Loss: 26130.546875\n",
      "Epoch: 7, Batch number: 44, Loss: 25685.275390625\n",
      "Epoch: 8, Batch number: 68, Loss: 24900.388671875\n",
      "Epoch: 10, Batch number: 16, Loss: 24047.689453125\n",
      "Epoch: 11, Batch number: 40, Loss: 23851.16015625\n",
      "Epoch: 12, Batch number: 64, Loss: 23247.2421875\n",
      "Epoch: 14, Batch number: 12, Loss: 22535.017578125\n",
      "Epoch: 15, Batch number: 36, Loss: 22416.611328125\n",
      "Epoch: 16, Batch number: 60, Loss: 21689.388671875\n",
      "Epoch: 18, Batch number: 8, Loss: 21332.6953125\n",
      "Epoch: 19, Batch number: 32, Loss: 21313.6796875\n",
      "Epoch: 20, Batch number: 56, Loss: 21067.912109375\n",
      "Epoch: 22, Batch number: 4, Loss: 20665.560546875\n",
      "Epoch: 23, Batch number: 28, Loss: 20745.94140625\n",
      "Epoch: 24, Batch number: 52, Loss: 20552.0\n",
      "Epoch: 26, Batch number: 0, Loss: 20343.455078125\n",
      "Epoch: 27, Batch number: 24, Loss: 19954.595703125\n",
      "Epoch: 28, Batch number: 48, Loss: 20387.279296875\n",
      "Epoch: 29, Batch number: 72, Loss: 20364.3984375\n",
      "Epoch: 31, Batch number: 20, Loss: 20304.26171875\n",
      "Epoch: 32, Batch number: 44, Loss: 20147.228515625\n",
      "Epoch: 33, Batch number: 68, Loss: 20231.392578125\n",
      "Epoch: 35, Batch number: 16, Loss: 19738.173828125\n",
      "Epoch: 36, Batch number: 40, Loss: 19695.07421875\n",
      "Epoch: 37, Batch number: 64, Loss: 19974.728515625\n",
      "Epoch: 39, Batch number: 12, Loss: 19500.349609375\n",
      "Epoch: 40, Batch number: 36, Loss: 19702.87890625\n",
      "Epoch: 41, Batch number: 60, Loss: 19756.333984375\n",
      "Epoch: 43, Batch number: 8, Loss: 19759.126953125\n",
      "Epoch: 44, Batch number: 32, Loss: 19341.3125\n",
      "Epoch: 45, Batch number: 56, Loss: 19590.5234375\n",
      "Epoch: 47, Batch number: 4, Loss: 19626.37109375\n",
      "Epoch: 48, Batch number: 28, Loss: 19567.73828125\n",
      "Epoch: 49, Batch number: 52, Loss: 19702.994140625\n",
      "Epoch: 51, Batch number: 0, Loss: 19281.48046875\n",
      "Epoch: 52, Batch number: 24, Loss: 18982.685546875\n",
      "Epoch: 53, Batch number: 48, Loss: 19543.216796875\n",
      "Epoch: 54, Batch number: 72, Loss: 19502.13671875\n",
      "Epoch: 56, Batch number: 20, Loss: 18964.654296875\n",
      "Epoch: 57, Batch number: 44, Loss: 19251.67578125\n",
      "Epoch: 58, Batch number: 68, Loss: 19268.068359375\n",
      "Epoch: 60, Batch number: 16, Loss: 19458.513671875\n",
      "Epoch: 61, Batch number: 40, Loss: 18781.892578125\n",
      "Epoch: 62, Batch number: 64, Loss: 19477.513671875\n",
      "Epoch: 64, Batch number: 12, Loss: 18783.119140625\n",
      "Epoch: 65, Batch number: 36, Loss: 19520.544921875\n",
      "Epoch: 66, Batch number: 60, Loss: 19054.068359375\n",
      "Epoch: 68, Batch number: 8, Loss: 19391.578125\n",
      "Epoch: 69, Batch number: 32, Loss: 18741.119140625\n",
      "Epoch: 70, Batch number: 56, Loss: 19026.443359375\n",
      "Epoch: 72, Batch number: 4, Loss: 18772.728515625\n",
      "Epoch: 73, Batch number: 28, Loss: 18862.068359375\n",
      "Epoch: 74, Batch number: 52, Loss: 19470.94140625\n",
      "Epoch: 76, Batch number: 0, Loss: 18796.810546875\n",
      "Epoch: 77, Batch number: 24, Loss: 19044.033203125\n",
      "Epoch: 78, Batch number: 48, Loss: 18824.720703125\n",
      "Epoch: 79, Batch number: 72, Loss: 18817.189453125\n",
      "Epoch: 81, Batch number: 20, Loss: 18685.69140625\n",
      "Epoch: 82, Batch number: 44, Loss: 18511.900390625\n",
      "Epoch: 83, Batch number: 68, Loss: 19074.421875\n",
      "Epoch: 85, Batch number: 16, Loss: 18275.650390625\n",
      "Epoch: 86, Batch number: 40, Loss: 19062.998046875\n",
      "Epoch: 87, Batch number: 64, Loss: 18791.990234375\n",
      "Epoch: 89, Batch number: 12, Loss: 18626.544921875\n",
      "Epoch: 90, Batch number: 36, Loss: 18747.125\n",
      "Epoch: 91, Batch number: 60, Loss: 19234.939453125\n",
      "Epoch: 93, Batch number: 8, Loss: 18490.68359375\n",
      "Epoch: 94, Batch number: 32, Loss: 18526.58984375\n",
      "Epoch: 95, Batch number: 56, Loss: 18927.7890625\n",
      "Epoch: 97, Batch number: 4, Loss: 18808.595703125\n",
      "Epoch: 98, Batch number: 28, Loss: 18801.791015625\n",
      "Epoch: 99, Batch number: 52, Loss: 18333.365234375\n",
      "Epoch: 101, Batch number: 0, Loss: 18230.80859375\n",
      "Epoch: 102, Batch number: 24, Loss: 18839.544921875\n",
      "Epoch: 103, Batch number: 48, Loss: 18754.0859375\n",
      "Epoch: 104, Batch number: 72, Loss: 18489.0390625\n",
      "Epoch: 106, Batch number: 20, Loss: 18458.81640625\n",
      "Epoch: 107, Batch number: 44, Loss: 18426.474609375\n",
      "Epoch: 108, Batch number: 68, Loss: 18444.107421875\n",
      "Epoch: 110, Batch number: 16, Loss: 18978.64453125\n",
      "Epoch: 111, Batch number: 40, Loss: 18077.990234375\n",
      "Epoch: 112, Batch number: 64, Loss: 18989.58203125\n",
      "Epoch: 114, Batch number: 12, Loss: 18211.291015625\n",
      "Epoch: 115, Batch number: 36, Loss: 18273.328125\n",
      "Epoch: 116, Batch number: 60, Loss: 18749.0390625\n",
      "Epoch: 118, Batch number: 8, Loss: 18481.69921875\n",
      "Epoch: 119, Batch number: 32, Loss: 18922.400390625\n",
      "Epoch: 120, Batch number: 56, Loss: 18540.603515625\n",
      "Epoch: 122, Batch number: 4, Loss: 18534.080078125\n",
      "Epoch: 123, Batch number: 28, Loss: 18043.783203125\n",
      "Epoch: 124, Batch number: 52, Loss: 18437.234375\n",
      "Epoch: 126, Batch number: 0, Loss: 18698.4375\n",
      "Epoch: 127, Batch number: 24, Loss: 18861.76171875\n",
      "Epoch: 128, Batch number: 48, Loss: 18766.396484375\n",
      "Epoch: 129, Batch number: 72, Loss: 18477.6640625\n",
      "Epoch: 131, Batch number: 20, Loss: 18163.37890625\n",
      "Epoch: 132, Batch number: 44, Loss: 17814.296875\n",
      "Epoch: 133, Batch number: 68, Loss: 18716.7265625\n",
      "Epoch: 135, Batch number: 16, Loss: 17932.708984375\n",
      "Epoch: 136, Batch number: 40, Loss: 18246.611328125\n",
      "Epoch: 137, Batch number: 64, Loss: 18887.771484375\n",
      "Epoch: 139, Batch number: 12, Loss: 18695.11328125\n",
      "Epoch: 140, Batch number: 36, Loss: 18712.275390625\n",
      "Epoch: 141, Batch number: 60, Loss: 18439.078125\n",
      "Epoch: 143, Batch number: 8, Loss: 18588.244140625\n",
      "Epoch: 144, Batch number: 32, Loss: 18478.818359375\n",
      "Epoch: 145, Batch number: 56, Loss: 18780.30078125\n",
      "Epoch: 147, Batch number: 4, Loss: 18289.044921875\n",
      "Epoch: 148, Batch number: 28, Loss: 18762.904296875\n",
      "Epoch: 149, Batch number: 52, Loss: 18371.125\n",
      "Epoch: 151, Batch number: 0, Loss: 18117.052734375\n",
      "Epoch: 152, Batch number: 24, Loss: 18188.400390625\n",
      "Epoch: 153, Batch number: 48, Loss: 18553.59765625\n",
      "Epoch: 154, Batch number: 72, Loss: 17953.73828125\n",
      "Epoch: 156, Batch number: 20, Loss: 18182.107421875\n",
      "Epoch: 157, Batch number: 44, Loss: 18596.82421875\n",
      "Epoch: 158, Batch number: 68, Loss: 18988.751953125\n",
      "Epoch: 160, Batch number: 16, Loss: 18339.16796875\n",
      "Epoch: 161, Batch number: 40, Loss: 18319.978515625\n",
      "Epoch: 162, Batch number: 64, Loss: 18872.841796875\n",
      "Epoch: 164, Batch number: 12, Loss: 18125.615234375\n",
      "Epoch: 165, Batch number: 36, Loss: 18807.90625\n",
      "Epoch: 166, Batch number: 60, Loss: 18297.703125\n",
      "Epoch: 168, Batch number: 8, Loss: 18042.755859375\n",
      "Epoch: 169, Batch number: 32, Loss: 18118.7734375\n",
      "Epoch: 170, Batch number: 56, Loss: 18237.353515625\n",
      "Epoch: 172, Batch number: 4, Loss: 18407.779296875\n",
      "Epoch: 173, Batch number: 28, Loss: 18173.21484375\n",
      "Epoch: 174, Batch number: 52, Loss: 18201.716796875\n",
      "Epoch: 176, Batch number: 0, Loss: 18417.5\n",
      "Epoch: 177, Batch number: 24, Loss: 18247.103515625\n",
      "Epoch: 178, Batch number: 48, Loss: 18169.884765625\n",
      "Epoch: 179, Batch number: 72, Loss: 18035.14453125\n",
      "Epoch: 181, Batch number: 20, Loss: 18238.830078125\n",
      "Epoch: 182, Batch number: 44, Loss: 18758.74609375\n",
      "Epoch: 183, Batch number: 68, Loss: 18108.83203125\n",
      "Epoch: 185, Batch number: 16, Loss: 18320.29296875\n",
      "Epoch: 186, Batch number: 40, Loss: 18698.240234375\n",
      "Epoch: 187, Batch number: 64, Loss: 18117.177734375\n",
      "Epoch: 189, Batch number: 12, Loss: 18441.35546875\n",
      "Epoch: 190, Batch number: 36, Loss: 18440.056640625\n",
      "Epoch: 191, Batch number: 60, Loss: 18243.21875\n",
      "Epoch: 193, Batch number: 8, Loss: 17967.89453125\n",
      "Epoch: 194, Batch number: 32, Loss: 17648.44140625\n",
      "Epoch: 195, Batch number: 56, Loss: 18205.0625\n",
      "Epoch: 197, Batch number: 4, Loss: 18005.115234375\n",
      "Epoch: 198, Batch number: 28, Loss: 17877.18359375\n",
      "Epoch: 199, Batch number: 52, Loss: 18162.76171875\n",
      "Epoch: 201, Batch number: 0, Loss: 18611.876953125\n",
      "Epoch: 202, Batch number: 24, Loss: 18898.55078125\n",
      "Epoch: 203, Batch number: 48, Loss: 18498.291015625\n",
      "Epoch: 204, Batch number: 72, Loss: 18405.48828125\n",
      "Epoch: 206, Batch number: 20, Loss: 18347.099609375\n",
      "Epoch: 207, Batch number: 44, Loss: 18396.84375\n",
      "Epoch: 208, Batch number: 68, Loss: 18332.88671875\n",
      "Epoch: 210, Batch number: 16, Loss: 18378.0390625\n",
      "Epoch: 211, Batch number: 40, Loss: 18554.49609375\n",
      "Epoch: 212, Batch number: 64, Loss: 18138.8203125\n",
      "Epoch: 214, Batch number: 12, Loss: 18068.67578125\n",
      "Epoch: 215, Batch number: 36, Loss: 18097.404296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 216, Batch number: 60, Loss: 18273.921875\n",
      "Epoch: 218, Batch number: 8, Loss: 17909.09765625\n",
      "Epoch: 219, Batch number: 32, Loss: 18257.234375\n",
      "Epoch: 220, Batch number: 56, Loss: 18836.533203125\n",
      "Epoch: 222, Batch number: 4, Loss: 18090.396484375\n",
      "Epoch: 223, Batch number: 28, Loss: 18184.853515625\n",
      "Epoch: 224, Batch number: 52, Loss: 17849.15625\n",
      "Epoch: 226, Batch number: 0, Loss: 17932.083984375\n",
      "Epoch: 227, Batch number: 24, Loss: 18101.26953125\n",
      "Epoch: 228, Batch number: 48, Loss: 18616.40625\n",
      "Epoch: 229, Batch number: 72, Loss: 18218.251953125\n",
      "Epoch: 231, Batch number: 20, Loss: 18153.623046875\n",
      "Epoch: 232, Batch number: 44, Loss: 17944.33984375\n",
      "Epoch: 233, Batch number: 68, Loss: 18028.689453125\n",
      "Epoch: 235, Batch number: 16, Loss: 18274.91015625\n",
      "Epoch: 236, Batch number: 40, Loss: 17997.51953125\n",
      "Epoch: 237, Batch number: 64, Loss: 18546.240234375\n",
      "Epoch: 239, Batch number: 12, Loss: 18162.849609375\n",
      "Epoch: 240, Batch number: 36, Loss: 18671.421875\n",
      "Epoch: 241, Batch number: 60, Loss: 18618.712890625\n",
      "Epoch: 243, Batch number: 8, Loss: 18155.873046875\n",
      "Epoch: 244, Batch number: 32, Loss: 17951.3125\n",
      "Epoch: 245, Batch number: 56, Loss: 18202.94921875\n",
      "Epoch: 247, Batch number: 4, Loss: 18387.15234375\n",
      "Epoch: 248, Batch number: 28, Loss: 18235.294921875\n",
      "Epoch: 249, Batch number: 52, Loss: 18677.734375\n",
      "Epoch: 251, Batch number: 0, Loss: 18170.921875\n",
      "Epoch: 252, Batch number: 24, Loss: 18411.923828125\n",
      "Epoch: 253, Batch number: 48, Loss: 18339.462890625\n",
      "Epoch: 254, Batch number: 72, Loss: 18464.2734375\n",
      "Epoch: 256, Batch number: 20, Loss: 17932.94921875\n",
      "Epoch: 257, Batch number: 44, Loss: 18747.818359375\n",
      "Epoch: 258, Batch number: 68, Loss: 18472.251953125\n",
      "Epoch: 260, Batch number: 16, Loss: 18116.3671875\n",
      "Epoch: 261, Batch number: 40, Loss: 18351.173828125\n",
      "Epoch: 262, Batch number: 64, Loss: 18402.458984375\n",
      "Epoch: 264, Batch number: 12, Loss: 18263.34375\n",
      "Epoch: 265, Batch number: 36, Loss: 18864.9296875\n",
      "Epoch: 266, Batch number: 60, Loss: 18716.142578125\n",
      "Epoch: 268, Batch number: 8, Loss: 17882.103515625\n",
      "Epoch: 269, Batch number: 32, Loss: 18551.626953125\n",
      "Epoch: 270, Batch number: 56, Loss: 18201.267578125\n",
      "Epoch: 272, Batch number: 4, Loss: 18351.416015625\n",
      "Epoch: 273, Batch number: 28, Loss: 18490.1484375\n",
      "Epoch: 274, Batch number: 52, Loss: 18415.212890625\n",
      "Epoch: 276, Batch number: 0, Loss: 18452.98046875\n",
      "Epoch: 277, Batch number: 24, Loss: 17854.572265625\n",
      "Epoch: 278, Batch number: 48, Loss: 18556.380859375\n",
      "Epoch: 279, Batch number: 72, Loss: 17936.369140625\n",
      "Epoch: 281, Batch number: 20, Loss: 17896.349609375\n",
      "Epoch: 282, Batch number: 44, Loss: 18485.255859375\n",
      "Epoch: 283, Batch number: 68, Loss: 18727.388671875\n",
      "Epoch: 285, Batch number: 16, Loss: 17804.603515625\n",
      "Epoch: 286, Batch number: 40, Loss: 18121.61328125\n",
      "Epoch: 287, Batch number: 64, Loss: 18518.3203125\n",
      "Epoch: 289, Batch number: 12, Loss: 18163.83203125\n",
      "Epoch: 290, Batch number: 36, Loss: 17856.859375\n",
      "Epoch: 291, Batch number: 60, Loss: 18293.38671875\n",
      "Epoch: 293, Batch number: 8, Loss: 17773.91015625\n",
      "Epoch: 294, Batch number: 32, Loss: 18003.93359375\n",
      "Epoch: 295, Batch number: 56, Loss: 18153.171875\n",
      "Epoch: 297, Batch number: 4, Loss: 18068.78515625\n",
      "Epoch: 298, Batch number: 28, Loss: 18171.48046875\n",
      "Epoch: 299, Batch number: 52, Loss: 17403.8125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 35060.421875\n",
      "Epoch: 2, Batch number: 24, Loss: 31226.2421875\n",
      "Epoch: 3, Batch number: 48, Loss: 28651.6796875\n",
      "Epoch: 4, Batch number: 72, Loss: 27674.890625\n",
      "Epoch: 6, Batch number: 20, Loss: 25805.724609375\n",
      "Epoch: 7, Batch number: 44, Loss: 25346.85546875\n",
      "Epoch: 8, Batch number: 68, Loss: 23975.03125\n",
      "Epoch: 10, Batch number: 16, Loss: 22972.603515625\n",
      "Epoch: 11, Batch number: 40, Loss: 22681.880859375\n",
      "Epoch: 12, Batch number: 64, Loss: 22478.349609375\n",
      "Epoch: 14, Batch number: 12, Loss: 21265.1484375\n",
      "Epoch: 15, Batch number: 36, Loss: 21443.63671875\n",
      "Epoch: 16, Batch number: 60, Loss: 21317.15625\n",
      "Epoch: 18, Batch number: 8, Loss: 20477.978515625\n",
      "Epoch: 19, Batch number: 32, Loss: 20738.556640625\n",
      "Epoch: 20, Batch number: 56, Loss: 21097.142578125\n",
      "Epoch: 22, Batch number: 4, Loss: 20159.923828125\n",
      "Epoch: 23, Batch number: 28, Loss: 20398.640625\n",
      "Epoch: 24, Batch number: 52, Loss: 20222.037109375\n",
      "Epoch: 26, Batch number: 0, Loss: 19910.28515625\n",
      "Epoch: 27, Batch number: 24, Loss: 19622.169921875\n",
      "Epoch: 28, Batch number: 48, Loss: 20044.595703125\n",
      "Epoch: 29, Batch number: 72, Loss: 19466.8203125\n",
      "Epoch: 31, Batch number: 20, Loss: 19750.53515625\n",
      "Epoch: 32, Batch number: 44, Loss: 19478.208984375\n",
      "Epoch: 33, Batch number: 68, Loss: 19797.560546875\n",
      "Epoch: 35, Batch number: 16, Loss: 19353.3125\n",
      "Epoch: 36, Batch number: 40, Loss: 19460.44921875\n",
      "Epoch: 37, Batch number: 64, Loss: 19517.939453125\n",
      "Epoch: 39, Batch number: 12, Loss: 19299.005859375\n",
      "Epoch: 40, Batch number: 36, Loss: 19297.248046875\n",
      "Epoch: 41, Batch number: 60, Loss: 19705.06640625\n",
      "Epoch: 43, Batch number: 8, Loss: 19180.15625\n",
      "Epoch: 44, Batch number: 32, Loss: 19268.314453125\n",
      "Epoch: 45, Batch number: 56, Loss: 19971.23046875\n",
      "Epoch: 47, Batch number: 4, Loss: 18922.22265625\n",
      "Epoch: 48, Batch number: 28, Loss: 18714.369140625\n",
      "Epoch: 49, Batch number: 52, Loss: 19035.697265625\n",
      "Epoch: 51, Batch number: 0, Loss: 18552.548828125\n",
      "Epoch: 52, Batch number: 24, Loss: 19136.326171875\n",
      "Epoch: 53, Batch number: 48, Loss: 19055.015625\n",
      "Epoch: 54, Batch number: 72, Loss: 18860.7265625\n",
      "Epoch: 56, Batch number: 20, Loss: 18848.59765625\n",
      "Epoch: 57, Batch number: 44, Loss: 19114.744140625\n",
      "Epoch: 58, Batch number: 68, Loss: 19333.6796875\n",
      "Epoch: 60, Batch number: 16, Loss: 18550.779296875\n",
      "Epoch: 61, Batch number: 40, Loss: 19523.505859375\n",
      "Epoch: 62, Batch number: 64, Loss: 19167.94140625\n",
      "Epoch: 64, Batch number: 12, Loss: 18685.115234375\n",
      "Epoch: 65, Batch number: 36, Loss: 18694.947265625\n",
      "Epoch: 66, Batch number: 60, Loss: 19635.470703125\n",
      "Epoch: 68, Batch number: 8, Loss: 18586.8359375\n",
      "Epoch: 69, Batch number: 32, Loss: 18743.73046875\n",
      "Epoch: 70, Batch number: 56, Loss: 18560.287109375\n",
      "Epoch: 72, Batch number: 4, Loss: 18249.111328125\n",
      "Epoch: 73, Batch number: 28, Loss: 18994.8671875\n",
      "Epoch: 74, Batch number: 52, Loss: 18562.00390625\n",
      "Epoch: 76, Batch number: 0, Loss: 18585.31640625\n",
      "Epoch: 77, Batch number: 24, Loss: 18492.6484375\n",
      "Epoch: 78, Batch number: 48, Loss: 18916.462890625\n",
      "Epoch: 79, Batch number: 72, Loss: 19044.162109375\n",
      "Epoch: 81, Batch number: 20, Loss: 18535.373046875\n",
      "Epoch: 82, Batch number: 44, Loss: 18786.1953125\n",
      "Epoch: 83, Batch number: 68, Loss: 18615.466796875\n",
      "Epoch: 85, Batch number: 16, Loss: 18053.205078125\n",
      "Epoch: 86, Batch number: 40, Loss: 18219.748046875\n",
      "Epoch: 87, Batch number: 64, Loss: 18931.96875\n",
      "Epoch: 89, Batch number: 12, Loss: 18598.06640625\n",
      "Epoch: 90, Batch number: 36, Loss: 18428.814453125\n",
      "Epoch: 91, Batch number: 60, Loss: 18859.17578125\n",
      "Epoch: 93, Batch number: 8, Loss: 18054.01171875\n",
      "Epoch: 94, Batch number: 32, Loss: 19128.36328125\n",
      "Epoch: 95, Batch number: 56, Loss: 18402.310546875\n",
      "Epoch: 97, Batch number: 4, Loss: 18886.51953125\n",
      "Epoch: 98, Batch number: 28, Loss: 18498.501953125\n",
      "Epoch: 99, Batch number: 52, Loss: 18916.26171875\n",
      "Epoch: 101, Batch number: 0, Loss: 17919.638671875\n",
      "Epoch: 102, Batch number: 24, Loss: 18431.166015625\n",
      "Epoch: 103, Batch number: 48, Loss: 18310.5\n",
      "Epoch: 104, Batch number: 72, Loss: 19341.826171875\n",
      "Epoch: 106, Batch number: 20, Loss: 18120.6875\n",
      "Epoch: 107, Batch number: 44, Loss: 18397.8359375\n",
      "Epoch: 108, Batch number: 68, Loss: 18313.373046875\n",
      "Epoch: 110, Batch number: 16, Loss: 18465.513671875\n",
      "Epoch: 111, Batch number: 40, Loss: 18414.982421875\n",
      "Epoch: 112, Batch number: 64, Loss: 18427.0390625\n",
      "Epoch: 114, Batch number: 12, Loss: 18652.865234375\n",
      "Epoch: 115, Batch number: 36, Loss: 18644.900390625\n",
      "Epoch: 116, Batch number: 60, Loss: 18508.900390625\n",
      "Epoch: 118, Batch number: 8, Loss: 18083.716796875\n",
      "Epoch: 119, Batch number: 32, Loss: 18384.3046875\n",
      "Epoch: 120, Batch number: 56, Loss: 18130.115234375\n",
      "Epoch: 122, Batch number: 4, Loss: 18075.990234375\n",
      "Epoch: 123, Batch number: 28, Loss: 18459.654296875\n",
      "Epoch: 124, Batch number: 52, Loss: 18662.123046875\n",
      "Epoch: 126, Batch number: 0, Loss: 17921.39453125\n",
      "Epoch: 127, Batch number: 24, Loss: 18080.748046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128, Batch number: 48, Loss: 18676.283203125\n",
      "Epoch: 129, Batch number: 72, Loss: 18851.013671875\n",
      "Epoch: 131, Batch number: 20, Loss: 17919.794921875\n",
      "Epoch: 132, Batch number: 44, Loss: 18480.09375\n",
      "Epoch: 133, Batch number: 68, Loss: 18512.21875\n",
      "Epoch: 135, Batch number: 16, Loss: 17831.13671875\n",
      "Epoch: 136, Batch number: 40, Loss: 17933.6015625\n",
      "Epoch: 137, Batch number: 64, Loss: 18694.78515625\n",
      "Epoch: 139, Batch number: 12, Loss: 18728.583984375\n",
      "Epoch: 140, Batch number: 36, Loss: 18004.07421875\n",
      "Epoch: 141, Batch number: 60, Loss: 18403.109375\n",
      "Epoch: 143, Batch number: 8, Loss: 18201.81640625\n",
      "Epoch: 144, Batch number: 32, Loss: 18570.361328125\n",
      "Epoch: 145, Batch number: 56, Loss: 18265.201171875\n",
      "Epoch: 147, Batch number: 4, Loss: 18639.12890625\n",
      "Epoch: 148, Batch number: 28, Loss: 18182.849609375\n",
      "Epoch: 149, Batch number: 52, Loss: 18261.29296875\n",
      "Epoch: 151, Batch number: 0, Loss: 18164.265625\n",
      "Epoch: 152, Batch number: 24, Loss: 18210.529296875\n",
      "Epoch: 153, Batch number: 48, Loss: 18231.19921875\n",
      "Epoch: 154, Batch number: 72, Loss: 18635.01953125\n",
      "Epoch: 156, Batch number: 20, Loss: 18709.2109375\n",
      "Epoch: 157, Batch number: 44, Loss: 18220.12890625\n",
      "Epoch: 158, Batch number: 68, Loss: 18534.779296875\n",
      "Epoch: 160, Batch number: 16, Loss: 17906.5078125\n",
      "Epoch: 161, Batch number: 40, Loss: 18537.48046875\n",
      "Epoch: 162, Batch number: 64, Loss: 18214.638671875\n",
      "Epoch: 164, Batch number: 12, Loss: 17865.7890625\n",
      "Epoch: 165, Batch number: 36, Loss: 19055.41796875\n",
      "Epoch: 166, Batch number: 60, Loss: 18805.60546875\n",
      "Epoch: 168, Batch number: 8, Loss: 18272.3046875\n",
      "Epoch: 169, Batch number: 32, Loss: 18161.03125\n",
      "Epoch: 170, Batch number: 56, Loss: 17998.1328125\n",
      "Epoch: 172, Batch number: 4, Loss: 17745.923828125\n",
      "Epoch: 173, Batch number: 28, Loss: 18389.765625\n",
      "Epoch: 174, Batch number: 52, Loss: 18807.779296875\n",
      "Epoch: 176, Batch number: 0, Loss: 18049.66015625\n",
      "Epoch: 177, Batch number: 24, Loss: 18468.908203125\n",
      "Epoch: 178, Batch number: 48, Loss: 18343.763671875\n",
      "Epoch: 179, Batch number: 72, Loss: 18350.376953125\n",
      "Epoch: 181, Batch number: 20, Loss: 18083.3671875\n",
      "Epoch: 182, Batch number: 44, Loss: 18552.974609375\n",
      "Epoch: 183, Batch number: 68, Loss: 18774.056640625\n",
      "Epoch: 185, Batch number: 16, Loss: 17930.0546875\n",
      "Epoch: 186, Batch number: 40, Loss: 18397.53515625\n",
      "Epoch: 187, Batch number: 64, Loss: 18560.2421875\n",
      "Epoch: 189, Batch number: 12, Loss: 18432.203125\n",
      "Epoch: 190, Batch number: 36, Loss: 18571.921875\n",
      "Epoch: 191, Batch number: 60, Loss: 18371.958984375\n",
      "Epoch: 193, Batch number: 8, Loss: 17515.47265625\n",
      "Epoch: 194, Batch number: 32, Loss: 17963.0546875\n",
      "Epoch: 195, Batch number: 56, Loss: 18696.70703125\n",
      "Epoch: 197, Batch number: 4, Loss: 18414.21875\n",
      "Epoch: 198, Batch number: 28, Loss: 18523.193359375\n",
      "Epoch: 199, Batch number: 52, Loss: 18169.2578125\n",
      "Epoch: 201, Batch number: 0, Loss: 17889.1796875\n",
      "Epoch: 202, Batch number: 24, Loss: 17805.798828125\n",
      "Epoch: 203, Batch number: 48, Loss: 18685.267578125\n",
      "Epoch: 204, Batch number: 72, Loss: 18547.712890625\n",
      "Epoch: 206, Batch number: 20, Loss: 18175.572265625\n",
      "Epoch: 207, Batch number: 44, Loss: 18765.3125\n",
      "Epoch: 208, Batch number: 68, Loss: 18626.833984375\n",
      "Epoch: 210, Batch number: 16, Loss: 18411.869140625\n",
      "Epoch: 211, Batch number: 40, Loss: 17926.244140625\n",
      "Epoch: 212, Batch number: 64, Loss: 18394.12109375\n",
      "Epoch: 214, Batch number: 12, Loss: 18306.408203125\n",
      "Epoch: 215, Batch number: 36, Loss: 18630.546875\n",
      "Epoch: 216, Batch number: 60, Loss: 18113.365234375\n",
      "Epoch: 218, Batch number: 8, Loss: 17667.837890625\n",
      "Epoch: 219, Batch number: 32, Loss: 17874.619140625\n",
      "Epoch: 220, Batch number: 56, Loss: 18332.177734375\n",
      "Epoch: 222, Batch number: 4, Loss: 18107.76953125\n",
      "Epoch: 223, Batch number: 28, Loss: 17820.29296875\n",
      "Epoch: 224, Batch number: 52, Loss: 18484.09765625\n",
      "Epoch: 226, Batch number: 0, Loss: 18565.392578125\n",
      "Epoch: 227, Batch number: 24, Loss: 18470.234375\n",
      "Epoch: 228, Batch number: 48, Loss: 18130.5234375\n",
      "Epoch: 229, Batch number: 72, Loss: 18490.017578125\n",
      "Epoch: 231, Batch number: 20, Loss: 18482.314453125\n",
      "Epoch: 232, Batch number: 44, Loss: 18502.609375\n",
      "Epoch: 233, Batch number: 68, Loss: 18805.861328125\n",
      "Epoch: 235, Batch number: 16, Loss: 18208.0625\n",
      "Epoch: 236, Batch number: 40, Loss: 18301.51171875\n",
      "Epoch: 237, Batch number: 64, Loss: 19223.8125\n",
      "Epoch: 239, Batch number: 12, Loss: 18157.181640625\n",
      "Epoch: 240, Batch number: 36, Loss: 19320.49609375\n",
      "Epoch: 241, Batch number: 60, Loss: 18864.103515625\n",
      "Epoch: 243, Batch number: 8, Loss: 17879.318359375\n",
      "Epoch: 244, Batch number: 32, Loss: 18294.5234375\n",
      "Epoch: 245, Batch number: 56, Loss: 18325.580078125\n",
      "Epoch: 247, Batch number: 4, Loss: 17738.30859375\n",
      "Epoch: 248, Batch number: 28, Loss: 18268.61328125\n",
      "Epoch: 249, Batch number: 52, Loss: 18423.49609375\n",
      "Epoch: 251, Batch number: 0, Loss: 17952.8828125\n",
      "Epoch: 252, Batch number: 24, Loss: 17725.2265625\n",
      "Epoch: 253, Batch number: 48, Loss: 18128.435546875\n",
      "Epoch: 254, Batch number: 72, Loss: 18259.3203125\n",
      "Epoch: 256, Batch number: 20, Loss: 18456.55859375\n",
      "Epoch: 257, Batch number: 44, Loss: 18048.0078125\n",
      "Epoch: 258, Batch number: 68, Loss: 18587.41015625\n",
      "Epoch: 260, Batch number: 16, Loss: 17928.23046875\n",
      "Epoch: 261, Batch number: 40, Loss: 18129.185546875\n",
      "Epoch: 262, Batch number: 64, Loss: 18583.673828125\n",
      "Epoch: 264, Batch number: 12, Loss: 18287.263671875\n",
      "Epoch: 265, Batch number: 36, Loss: 18610.65234375\n",
      "Epoch: 266, Batch number: 60, Loss: 18460.658203125\n",
      "Epoch: 268, Batch number: 8, Loss: 18324.484375\n",
      "Epoch: 269, Batch number: 32, Loss: 18449.07421875\n",
      "Epoch: 270, Batch number: 56, Loss: 17805.33984375\n",
      "Epoch: 272, Batch number: 4, Loss: 18008.001953125\n",
      "Epoch: 273, Batch number: 28, Loss: 18349.10546875\n",
      "Epoch: 274, Batch number: 52, Loss: 18438.853515625\n",
      "Epoch: 276, Batch number: 0, Loss: 17432.501953125\n",
      "Epoch: 277, Batch number: 24, Loss: 18385.611328125\n",
      "Epoch: 278, Batch number: 48, Loss: 18600.5546875\n",
      "Epoch: 279, Batch number: 72, Loss: 18070.205078125\n",
      "Epoch: 281, Batch number: 20, Loss: 18041.724609375\n",
      "Epoch: 282, Batch number: 44, Loss: 18411.5859375\n",
      "Epoch: 283, Batch number: 68, Loss: 18225.72265625\n",
      "Epoch: 285, Batch number: 16, Loss: 18517.666015625\n",
      "Epoch: 286, Batch number: 40, Loss: 18165.630859375\n",
      "Epoch: 287, Batch number: 64, Loss: 19209.705078125\n",
      "Epoch: 289, Batch number: 12, Loss: 17733.634765625\n",
      "Epoch: 290, Batch number: 36, Loss: 18249.48046875\n",
      "Epoch: 291, Batch number: 60, Loss: 18747.037109375\n",
      "Epoch: 293, Batch number: 8, Loss: 18268.140625\n",
      "Epoch: 294, Batch number: 32, Loss: 18082.5859375\n",
      "Epoch: 295, Batch number: 56, Loss: 18372.28515625\n",
      "Epoch: 297, Batch number: 4, Loss: 18004.4140625\n",
      "Epoch: 298, Batch number: 28, Loss: 18368.39453125\n",
      "Epoch: 299, Batch number: 52, Loss: 18846.267578125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 38086.84765625\n",
      "Epoch: 2, Batch number: 24, Loss: 36375.41796875\n",
      "Epoch: 3, Batch number: 48, Loss: 35979.9921875\n",
      "Epoch: 4, Batch number: 72, Loss: 34114.89453125\n",
      "Epoch: 6, Batch number: 20, Loss: 32579.05859375\n",
      "Epoch: 7, Batch number: 44, Loss: 31394.966796875\n",
      "Epoch: 8, Batch number: 68, Loss: 31199.349609375\n",
      "Epoch: 10, Batch number: 16, Loss: 30467.58203125\n",
      "Epoch: 11, Batch number: 40, Loss: 29669.021484375\n",
      "Epoch: 12, Batch number: 64, Loss: 29377.337890625\n",
      "Epoch: 14, Batch number: 12, Loss: 28782.603515625\n",
      "Epoch: 15, Batch number: 36, Loss: 28355.740234375\n",
      "Epoch: 16, Batch number: 60, Loss: 27919.98828125\n",
      "Epoch: 18, Batch number: 8, Loss: 28132.720703125\n",
      "Epoch: 19, Batch number: 32, Loss: 27946.08984375\n",
      "Epoch: 20, Batch number: 56, Loss: 27530.544921875\n",
      "Epoch: 22, Batch number: 4, Loss: 27146.900390625\n",
      "Epoch: 23, Batch number: 28, Loss: 26498.109375\n",
      "Epoch: 24, Batch number: 52, Loss: 27047.60546875\n",
      "Epoch: 26, Batch number: 0, Loss: 26870.103515625\n",
      "Epoch: 27, Batch number: 24, Loss: 26657.208984375\n",
      "Epoch: 28, Batch number: 48, Loss: 26364.34765625\n",
      "Epoch: 29, Batch number: 72, Loss: 26202.412109375\n",
      "Epoch: 31, Batch number: 20, Loss: 25920.408203125\n",
      "Epoch: 32, Batch number: 44, Loss: 25998.59765625\n",
      "Epoch: 33, Batch number: 68, Loss: 26188.37109375\n",
      "Epoch: 35, Batch number: 16, Loss: 25843.08984375\n",
      "Epoch: 36, Batch number: 40, Loss: 25594.888671875\n",
      "Epoch: 37, Batch number: 64, Loss: 25251.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Batch number: 12, Loss: 25367.3984375\n",
      "Epoch: 40, Batch number: 36, Loss: 25346.884765625\n",
      "Epoch: 41, Batch number: 60, Loss: 25453.068359375\n",
      "Epoch: 43, Batch number: 8, Loss: 25459.39453125\n",
      "Epoch: 44, Batch number: 32, Loss: 25211.193359375\n",
      "Epoch: 45, Batch number: 56, Loss: 25273.83984375\n",
      "Epoch: 47, Batch number: 4, Loss: 24926.88671875\n",
      "Epoch: 48, Batch number: 28, Loss: 25168.21484375\n",
      "Epoch: 49, Batch number: 52, Loss: 25003.8828125\n",
      "Epoch: 51, Batch number: 0, Loss: 24775.779296875\n",
      "Epoch: 52, Batch number: 24, Loss: 24986.84765625\n",
      "Epoch: 53, Batch number: 48, Loss: 24964.99609375\n",
      "Epoch: 54, Batch number: 72, Loss: 25209.9609375\n",
      "Epoch: 56, Batch number: 20, Loss: 24757.583984375\n",
      "Epoch: 57, Batch number: 44, Loss: 24675.443359375\n",
      "Epoch: 58, Batch number: 68, Loss: 24385.291015625\n",
      "Epoch: 60, Batch number: 16, Loss: 24392.84375\n",
      "Epoch: 61, Batch number: 40, Loss: 24806.509765625\n",
      "Epoch: 62, Batch number: 64, Loss: 24699.837890625\n",
      "Epoch: 64, Batch number: 12, Loss: 24494.78515625\n",
      "Epoch: 65, Batch number: 36, Loss: 24769.490234375\n",
      "Epoch: 66, Batch number: 60, Loss: 24435.46875\n",
      "Epoch: 68, Batch number: 8, Loss: 24472.443359375\n",
      "Epoch: 69, Batch number: 32, Loss: 24207.521484375\n",
      "Epoch: 70, Batch number: 56, Loss: 24334.51953125\n",
      "Epoch: 72, Batch number: 4, Loss: 24433.708984375\n",
      "Epoch: 73, Batch number: 28, Loss: 24207.1953125\n",
      "Epoch: 74, Batch number: 52, Loss: 24459.380859375\n",
      "Epoch: 76, Batch number: 0, Loss: 24259.689453125\n",
      "Epoch: 77, Batch number: 24, Loss: 24120.55078125\n",
      "Epoch: 78, Batch number: 48, Loss: 24064.55078125\n",
      "Epoch: 79, Batch number: 72, Loss: 24316.423828125\n",
      "Epoch: 81, Batch number: 20, Loss: 24228.453125\n",
      "Epoch: 82, Batch number: 44, Loss: 23940.044921875\n",
      "Epoch: 83, Batch number: 68, Loss: 24251.52734375\n",
      "Epoch: 85, Batch number: 16, Loss: 23622.419921875\n",
      "Epoch: 86, Batch number: 40, Loss: 23876.15625\n",
      "Epoch: 87, Batch number: 64, Loss: 23795.34765625\n",
      "Epoch: 89, Batch number: 12, Loss: 23758.169921875\n",
      "Epoch: 90, Batch number: 36, Loss: 23911.22265625\n",
      "Epoch: 91, Batch number: 60, Loss: 23834.251953125\n",
      "Epoch: 93, Batch number: 8, Loss: 23625.564453125\n",
      "Epoch: 94, Batch number: 32, Loss: 23839.248046875\n",
      "Epoch: 95, Batch number: 56, Loss: 23712.591796875\n",
      "Epoch: 97, Batch number: 4, Loss: 23651.353515625\n",
      "Epoch: 98, Batch number: 28, Loss: 23320.57421875\n",
      "Epoch: 99, Batch number: 52, Loss: 23414.7734375\n",
      "Epoch: 101, Batch number: 0, Loss: 23649.689453125\n",
      "Epoch: 102, Batch number: 24, Loss: 23514.01171875\n",
      "Epoch: 103, Batch number: 48, Loss: 23407.28515625\n",
      "Epoch: 104, Batch number: 72, Loss: 23205.1640625\n",
      "Epoch: 106, Batch number: 20, Loss: 23717.2421875\n",
      "Epoch: 107, Batch number: 44, Loss: 23354.67578125\n",
      "Epoch: 108, Batch number: 68, Loss: 23342.7421875\n",
      "Epoch: 110, Batch number: 16, Loss: 23473.583984375\n",
      "Epoch: 111, Batch number: 40, Loss: 23019.810546875\n",
      "Epoch: 112, Batch number: 64, Loss: 23674.62890625\n",
      "Epoch: 114, Batch number: 12, Loss: 23435.77734375\n",
      "Epoch: 115, Batch number: 36, Loss: 23559.47265625\n",
      "Epoch: 116, Batch number: 60, Loss: 23016.970703125\n",
      "Epoch: 118, Batch number: 8, Loss: 23089.935546875\n",
      "Epoch: 119, Batch number: 32, Loss: 22902.234375\n",
      "Epoch: 120, Batch number: 56, Loss: 23195.009765625\n",
      "Epoch: 122, Batch number: 4, Loss: 23215.337890625\n",
      "Epoch: 123, Batch number: 28, Loss: 23202.21875\n",
      "Epoch: 124, Batch number: 52, Loss: 22625.236328125\n",
      "Epoch: 126, Batch number: 0, Loss: 23105.388671875\n",
      "Epoch: 127, Batch number: 24, Loss: 23319.849609375\n",
      "Epoch: 128, Batch number: 48, Loss: 22756.23046875\n",
      "Epoch: 129, Batch number: 72, Loss: 23255.162109375\n",
      "Epoch: 131, Batch number: 20, Loss: 22772.875\n",
      "Epoch: 132, Batch number: 44, Loss: 23082.283203125\n",
      "Epoch: 133, Batch number: 68, Loss: 22959.642578125\n",
      "Epoch: 135, Batch number: 16, Loss: 22876.525390625\n",
      "Epoch: 136, Batch number: 40, Loss: 22882.970703125\n",
      "Epoch: 137, Batch number: 64, Loss: 22936.359375\n",
      "Epoch: 139, Batch number: 12, Loss: 23106.373046875\n",
      "Epoch: 140, Batch number: 36, Loss: 22706.509765625\n",
      "Epoch: 141, Batch number: 60, Loss: 22877.654296875\n",
      "Epoch: 143, Batch number: 8, Loss: 23020.787109375\n",
      "Epoch: 144, Batch number: 32, Loss: 22668.626953125\n",
      "Epoch: 145, Batch number: 56, Loss: 22710.759765625\n",
      "Epoch: 147, Batch number: 4, Loss: 22584.7109375\n",
      "Epoch: 148, Batch number: 28, Loss: 22662.080078125\n",
      "Epoch: 149, Batch number: 52, Loss: 23080.166015625\n",
      "Epoch: 151, Batch number: 0, Loss: 22419.06640625\n",
      "Epoch: 152, Batch number: 24, Loss: 22491.71484375\n",
      "Epoch: 153, Batch number: 48, Loss: 22351.40234375\n",
      "Epoch: 154, Batch number: 72, Loss: 22679.11328125\n",
      "Epoch: 156, Batch number: 20, Loss: 22704.453125\n",
      "Epoch: 157, Batch number: 44, Loss: 22557.576171875\n",
      "Epoch: 158, Batch number: 68, Loss: 22500.234375\n",
      "Epoch: 160, Batch number: 16, Loss: 22138.88671875\n",
      "Epoch: 161, Batch number: 40, Loss: 22353.802734375\n",
      "Epoch: 162, Batch number: 64, Loss: 22434.650390625\n",
      "Epoch: 164, Batch number: 12, Loss: 22599.11328125\n",
      "Epoch: 165, Batch number: 36, Loss: 22477.64453125\n",
      "Epoch: 166, Batch number: 60, Loss: 22568.201171875\n",
      "Epoch: 168, Batch number: 8, Loss: 22093.625\n",
      "Epoch: 169, Batch number: 32, Loss: 22357.16015625\n",
      "Epoch: 170, Batch number: 56, Loss: 22009.767578125\n",
      "Epoch: 172, Batch number: 4, Loss: 21946.154296875\n",
      "Epoch: 173, Batch number: 28, Loss: 22344.61328125\n",
      "Epoch: 174, Batch number: 52, Loss: 22540.107421875\n",
      "Epoch: 176, Batch number: 0, Loss: 22459.375\n",
      "Epoch: 177, Batch number: 24, Loss: 22384.48828125\n",
      "Epoch: 178, Batch number: 48, Loss: 22207.552734375\n",
      "Epoch: 179, Batch number: 72, Loss: 21969.18359375\n",
      "Epoch: 181, Batch number: 20, Loss: 22244.416015625\n",
      "Epoch: 182, Batch number: 44, Loss: 22205.626953125\n",
      "Epoch: 183, Batch number: 68, Loss: 22121.833984375\n",
      "Epoch: 185, Batch number: 16, Loss: 22279.80859375\n",
      "Epoch: 186, Batch number: 40, Loss: 22249.529296875\n",
      "Epoch: 187, Batch number: 64, Loss: 21771.8671875\n",
      "Epoch: 189, Batch number: 12, Loss: 22012.515625\n",
      "Epoch: 190, Batch number: 36, Loss: 22194.2265625\n",
      "Epoch: 191, Batch number: 60, Loss: 22304.296875\n",
      "Epoch: 193, Batch number: 8, Loss: 21774.23828125\n",
      "Epoch: 194, Batch number: 32, Loss: 22687.515625\n",
      "Epoch: 195, Batch number: 56, Loss: 21748.501953125\n",
      "Epoch: 197, Batch number: 4, Loss: 22149.26953125\n",
      "Epoch: 198, Batch number: 28, Loss: 21980.923828125\n",
      "Epoch: 199, Batch number: 52, Loss: 22119.755859375\n",
      "Epoch: 201, Batch number: 0, Loss: 21639.6484375\n",
      "Epoch: 202, Batch number: 24, Loss: 22051.513671875\n",
      "Epoch: 203, Batch number: 48, Loss: 21802.73828125\n",
      "Epoch: 204, Batch number: 72, Loss: 22262.482421875\n",
      "Epoch: 206, Batch number: 20, Loss: 21708.130859375\n",
      "Epoch: 207, Batch number: 44, Loss: 22208.314453125\n",
      "Epoch: 208, Batch number: 68, Loss: 22095.607421875\n",
      "Epoch: 210, Batch number: 16, Loss: 22041.935546875\n",
      "Epoch: 211, Batch number: 40, Loss: 22103.32421875\n",
      "Epoch: 212, Batch number: 64, Loss: 21753.927734375\n",
      "Epoch: 214, Batch number: 12, Loss: 21642.03125\n",
      "Epoch: 215, Batch number: 36, Loss: 21698.990234375\n",
      "Epoch: 216, Batch number: 60, Loss: 22139.904296875\n",
      "Epoch: 218, Batch number: 8, Loss: 21575.705078125\n",
      "Epoch: 219, Batch number: 32, Loss: 22102.166015625\n",
      "Epoch: 220, Batch number: 56, Loss: 22172.017578125\n",
      "Epoch: 222, Batch number: 4, Loss: 22054.720703125\n",
      "Epoch: 223, Batch number: 28, Loss: 21482.283203125\n",
      "Epoch: 224, Batch number: 52, Loss: 22181.923828125\n",
      "Epoch: 226, Batch number: 0, Loss: 21570.505859375\n",
      "Epoch: 227, Batch number: 24, Loss: 21503.015625\n",
      "Epoch: 228, Batch number: 48, Loss: 21358.23046875\n",
      "Epoch: 229, Batch number: 72, Loss: 21167.015625\n",
      "Epoch: 231, Batch number: 20, Loss: 21512.62890625\n",
      "Epoch: 232, Batch number: 44, Loss: 21370.208984375\n",
      "Epoch: 233, Batch number: 68, Loss: 21662.7109375\n",
      "Epoch: 235, Batch number: 16, Loss: 21955.658203125\n",
      "Epoch: 236, Batch number: 40, Loss: 21910.251953125\n",
      "Epoch: 237, Batch number: 64, Loss: 21650.783203125\n",
      "Epoch: 239, Batch number: 12, Loss: 21825.171875\n",
      "Epoch: 240, Batch number: 36, Loss: 21875.6328125\n",
      "Epoch: 241, Batch number: 60, Loss: 21761.3828125\n",
      "Epoch: 243, Batch number: 8, Loss: 21405.205078125\n",
      "Epoch: 244, Batch number: 32, Loss: 21515.2109375\n",
      "Epoch: 245, Batch number: 56, Loss: 21446.283203125\n",
      "Epoch: 247, Batch number: 4, Loss: 21676.095703125\n",
      "Epoch: 248, Batch number: 28, Loss: 21677.5859375\n",
      "Epoch: 249, Batch number: 52, Loss: 21312.052734375\n",
      "Epoch: 251, Batch number: 0, Loss: 21731.65625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 252, Batch number: 24, Loss: 21357.298828125\n",
      "Epoch: 253, Batch number: 48, Loss: 21892.671875\n",
      "Epoch: 254, Batch number: 72, Loss: 21825.9453125\n",
      "Epoch: 256, Batch number: 20, Loss: 21706.66796875\n",
      "Epoch: 257, Batch number: 44, Loss: 21978.03125\n",
      "Epoch: 258, Batch number: 68, Loss: 21515.69921875\n",
      "Epoch: 260, Batch number: 16, Loss: 21564.330078125\n",
      "Epoch: 261, Batch number: 40, Loss: 21388.537109375\n",
      "Epoch: 262, Batch number: 64, Loss: 21642.09375\n",
      "Epoch: 264, Batch number: 12, Loss: 21371.89453125\n",
      "Epoch: 265, Batch number: 36, Loss: 21600.345703125\n",
      "Epoch: 266, Batch number: 60, Loss: 21633.650390625\n",
      "Epoch: 268, Batch number: 8, Loss: 20995.53125\n",
      "Epoch: 269, Batch number: 32, Loss: 21389.39453125\n",
      "Epoch: 270, Batch number: 56, Loss: 21700.380859375\n",
      "Epoch: 272, Batch number: 4, Loss: 21272.919921875\n",
      "Epoch: 273, Batch number: 28, Loss: 21331.94921875\n",
      "Epoch: 274, Batch number: 52, Loss: 21196.19921875\n",
      "Epoch: 276, Batch number: 0, Loss: 21592.958984375\n",
      "Epoch: 277, Batch number: 24, Loss: 21201.98046875\n",
      "Epoch: 278, Batch number: 48, Loss: 21986.755859375\n",
      "Epoch: 279, Batch number: 72, Loss: 21645.958984375\n",
      "Epoch: 281, Batch number: 20, Loss: 21347.970703125\n",
      "Epoch: 282, Batch number: 44, Loss: 21462.998046875\n",
      "Epoch: 283, Batch number: 68, Loss: 21686.916015625\n",
      "Epoch: 285, Batch number: 16, Loss: 21344.9453125\n",
      "Epoch: 286, Batch number: 40, Loss: 20944.140625\n",
      "Epoch: 287, Batch number: 64, Loss: 21349.87109375\n",
      "Epoch: 289, Batch number: 12, Loss: 21455.314453125\n",
      "Epoch: 290, Batch number: 36, Loss: 21575.90234375\n",
      "Epoch: 291, Batch number: 60, Loss: 21819.98828125\n",
      "Epoch: 293, Batch number: 8, Loss: 21255.4609375\n",
      "Epoch: 294, Batch number: 32, Loss: 21731.716796875\n",
      "Epoch: 295, Batch number: 56, Loss: 21098.9296875\n",
      "Epoch: 297, Batch number: 4, Loss: 21363.029296875\n",
      "Epoch: 298, Batch number: 28, Loss: 20933.845703125\n",
      "Epoch: 299, Batch number: 52, Loss: 21417.4140625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 37634.12109375\n",
      "Epoch: 2, Batch number: 24, Loss: 35727.1796875\n",
      "Epoch: 3, Batch number: 48, Loss: 34616.21875\n",
      "Epoch: 4, Batch number: 72, Loss: 32962.01171875\n",
      "Epoch: 6, Batch number: 20, Loss: 31771.599609375\n",
      "Epoch: 7, Batch number: 44, Loss: 30223.849609375\n",
      "Epoch: 8, Batch number: 68, Loss: 29759.529296875\n",
      "Epoch: 10, Batch number: 16, Loss: 28451.41015625\n",
      "Epoch: 11, Batch number: 40, Loss: 28771.9375\n",
      "Epoch: 12, Batch number: 64, Loss: 27794.1640625\n",
      "Epoch: 14, Batch number: 12, Loss: 27584.435546875\n",
      "Epoch: 15, Batch number: 36, Loss: 27416.03515625\n",
      "Epoch: 16, Batch number: 60, Loss: 26448.73828125\n",
      "Epoch: 18, Batch number: 8, Loss: 26056.63671875\n",
      "Epoch: 19, Batch number: 32, Loss: 26138.484375\n",
      "Epoch: 20, Batch number: 56, Loss: 25995.888671875\n",
      "Epoch: 22, Batch number: 4, Loss: 25646.78515625\n",
      "Epoch: 23, Batch number: 28, Loss: 25294.314453125\n",
      "Epoch: 24, Batch number: 52, Loss: 25118.599609375\n",
      "Epoch: 26, Batch number: 0, Loss: 24991.384765625\n",
      "Epoch: 27, Batch number: 24, Loss: 25254.060546875\n",
      "Epoch: 28, Batch number: 48, Loss: 24681.33203125\n",
      "Epoch: 29, Batch number: 72, Loss: 24620.45703125\n",
      "Epoch: 31, Batch number: 20, Loss: 24869.810546875\n",
      "Epoch: 32, Batch number: 44, Loss: 24238.642578125\n",
      "Epoch: 33, Batch number: 68, Loss: 24573.73828125\n",
      "Epoch: 35, Batch number: 16, Loss: 24062.494140625\n",
      "Epoch: 36, Batch number: 40, Loss: 24242.73828125\n",
      "Epoch: 37, Batch number: 64, Loss: 23995.64453125\n",
      "Epoch: 39, Batch number: 12, Loss: 23652.56640625\n",
      "Epoch: 40, Batch number: 36, Loss: 23564.443359375\n",
      "Epoch: 41, Batch number: 60, Loss: 23826.517578125\n",
      "Epoch: 43, Batch number: 8, Loss: 23533.240234375\n",
      "Epoch: 44, Batch number: 32, Loss: 23573.427734375\n",
      "Epoch: 45, Batch number: 56, Loss: 23354.12890625\n",
      "Epoch: 47, Batch number: 4, Loss: 23431.583984375\n",
      "Epoch: 48, Batch number: 28, Loss: 23420.029296875\n",
      "Epoch: 49, Batch number: 52, Loss: 23307.44921875\n",
      "Epoch: 51, Batch number: 0, Loss: 23593.58203125\n",
      "Epoch: 52, Batch number: 24, Loss: 23332.298828125\n",
      "Epoch: 53, Batch number: 48, Loss: 23215.08984375\n",
      "Epoch: 54, Batch number: 72, Loss: 23325.162109375\n",
      "Epoch: 56, Batch number: 20, Loss: 22871.525390625\n",
      "Epoch: 57, Batch number: 44, Loss: 23240.607421875\n",
      "Epoch: 58, Batch number: 68, Loss: 22746.53125\n",
      "Epoch: 60, Batch number: 16, Loss: 22641.9609375\n",
      "Epoch: 61, Batch number: 40, Loss: 22597.6484375\n",
      "Epoch: 62, Batch number: 64, Loss: 23154.095703125\n",
      "Epoch: 64, Batch number: 12, Loss: 23020.017578125\n",
      "Epoch: 65, Batch number: 36, Loss: 22776.767578125\n",
      "Epoch: 66, Batch number: 60, Loss: 22983.505859375\n",
      "Epoch: 68, Batch number: 8, Loss: 22560.94140625\n",
      "Epoch: 69, Batch number: 32, Loss: 22550.94921875\n",
      "Epoch: 70, Batch number: 56, Loss: 22202.224609375\n",
      "Epoch: 72, Batch number: 4, Loss: 22860.865234375\n",
      "Epoch: 73, Batch number: 28, Loss: 22554.740234375\n",
      "Epoch: 74, Batch number: 52, Loss: 22347.8203125\n",
      "Epoch: 76, Batch number: 0, Loss: 22343.37109375\n",
      "Epoch: 77, Batch number: 24, Loss: 22715.912109375\n",
      "Epoch: 78, Batch number: 48, Loss: 21952.13671875\n",
      "Epoch: 79, Batch number: 72, Loss: 22327.662109375\n",
      "Epoch: 81, Batch number: 20, Loss: 22259.119140625\n",
      "Epoch: 82, Batch number: 44, Loss: 21987.06640625\n",
      "Epoch: 83, Batch number: 68, Loss: 22529.380859375\n",
      "Epoch: 85, Batch number: 16, Loss: 21846.333984375\n",
      "Epoch: 86, Batch number: 40, Loss: 22034.83203125\n",
      "Epoch: 87, Batch number: 64, Loss: 22333.783203125\n",
      "Epoch: 89, Batch number: 12, Loss: 21577.74609375\n",
      "Epoch: 90, Batch number: 36, Loss: 21904.09765625\n",
      "Epoch: 91, Batch number: 60, Loss: 21643.318359375\n",
      "Epoch: 93, Batch number: 8, Loss: 22145.919921875\n",
      "Epoch: 94, Batch number: 32, Loss: 22028.353515625\n",
      "Epoch: 95, Batch number: 56, Loss: 22203.5390625\n",
      "Epoch: 97, Batch number: 4, Loss: 22043.169921875\n",
      "Epoch: 98, Batch number: 28, Loss: 21676.58984375\n",
      "Epoch: 99, Batch number: 52, Loss: 21856.083984375\n",
      "Epoch: 101, Batch number: 0, Loss: 21586.759765625\n",
      "Epoch: 102, Batch number: 24, Loss: 21664.50390625\n",
      "Epoch: 103, Batch number: 48, Loss: 21966.51953125\n",
      "Epoch: 104, Batch number: 72, Loss: 21737.72265625\n",
      "Epoch: 106, Batch number: 20, Loss: 21780.1640625\n",
      "Epoch: 107, Batch number: 44, Loss: 21805.10546875\n",
      "Epoch: 108, Batch number: 68, Loss: 21305.71484375\n",
      "Epoch: 110, Batch number: 16, Loss: 21606.375\n",
      "Epoch: 111, Batch number: 40, Loss: 21417.73046875\n",
      "Epoch: 112, Batch number: 64, Loss: 21813.341796875\n",
      "Epoch: 114, Batch number: 12, Loss: 21567.638671875\n",
      "Epoch: 115, Batch number: 36, Loss: 21688.474609375\n",
      "Epoch: 116, Batch number: 60, Loss: 21769.4140625\n",
      "Epoch: 118, Batch number: 8, Loss: 21488.34765625\n",
      "Epoch: 119, Batch number: 32, Loss: 21564.146484375\n",
      "Epoch: 120, Batch number: 56, Loss: 21661.642578125\n",
      "Epoch: 122, Batch number: 4, Loss: 21333.94140625\n",
      "Epoch: 123, Batch number: 28, Loss: 21474.4375\n",
      "Epoch: 124, Batch number: 52, Loss: 21304.98828125\n",
      "Epoch: 126, Batch number: 0, Loss: 21272.158203125\n",
      "Epoch: 127, Batch number: 24, Loss: 21411.90625\n",
      "Epoch: 128, Batch number: 48, Loss: 21625.337890625\n",
      "Epoch: 129, Batch number: 72, Loss: 21517.892578125\n",
      "Epoch: 131, Batch number: 20, Loss: 21368.2109375\n",
      "Epoch: 132, Batch number: 44, Loss: 21474.365234375\n",
      "Epoch: 133, Batch number: 68, Loss: 21051.046875\n",
      "Epoch: 135, Batch number: 16, Loss: 20866.830078125\n",
      "Epoch: 136, Batch number: 40, Loss: 21319.974609375\n",
      "Epoch: 137, Batch number: 64, Loss: 21594.671875\n",
      "Epoch: 139, Batch number: 12, Loss: 21430.4609375\n",
      "Epoch: 140, Batch number: 36, Loss: 20913.865234375\n",
      "Epoch: 141, Batch number: 60, Loss: 21251.958984375\n",
      "Epoch: 143, Batch number: 8, Loss: 20549.205078125\n",
      "Epoch: 144, Batch number: 32, Loss: 21424.314453125\n",
      "Epoch: 145, Batch number: 56, Loss: 21347.490234375\n",
      "Epoch: 147, Batch number: 4, Loss: 20932.64453125\n",
      "Epoch: 148, Batch number: 28, Loss: 20907.55078125\n",
      "Epoch: 149, Batch number: 52, Loss: 21254.345703125\n",
      "Epoch: 151, Batch number: 0, Loss: 21002.619140625\n",
      "Epoch: 152, Batch number: 24, Loss: 20942.09375\n",
      "Epoch: 153, Batch number: 48, Loss: 21320.056640625\n",
      "Epoch: 154, Batch number: 72, Loss: 20930.3203125\n",
      "Epoch: 156, Batch number: 20, Loss: 21169.203125\n",
      "Epoch: 157, Batch number: 44, Loss: 21039.314453125\n",
      "Epoch: 158, Batch number: 68, Loss: 20831.01953125\n",
      "Epoch: 160, Batch number: 16, Loss: 21062.025390625\n",
      "Epoch: 161, Batch number: 40, Loss: 20869.080078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162, Batch number: 64, Loss: 20778.630859375\n",
      "Epoch: 164, Batch number: 12, Loss: 20550.20703125\n",
      "Epoch: 165, Batch number: 36, Loss: 20835.0546875\n",
      "Epoch: 166, Batch number: 60, Loss: 20337.591796875\n",
      "Epoch: 168, Batch number: 8, Loss: 20828.478515625\n",
      "Epoch: 169, Batch number: 32, Loss: 21120.166015625\n",
      "Epoch: 170, Batch number: 56, Loss: 20788.197265625\n",
      "Epoch: 172, Batch number: 4, Loss: 20515.556640625\n",
      "Epoch: 173, Batch number: 28, Loss: 20858.521484375\n",
      "Epoch: 174, Batch number: 52, Loss: 20848.099609375\n",
      "Epoch: 176, Batch number: 0, Loss: 20556.1328125\n",
      "Epoch: 177, Batch number: 24, Loss: 20478.33203125\n",
      "Epoch: 178, Batch number: 48, Loss: 21297.93359375\n",
      "Epoch: 179, Batch number: 72, Loss: 21250.408203125\n",
      "Epoch: 181, Batch number: 20, Loss: 20575.462890625\n",
      "Epoch: 182, Batch number: 44, Loss: 20846.0234375\n",
      "Epoch: 183, Batch number: 68, Loss: 21041.015625\n",
      "Epoch: 185, Batch number: 16, Loss: 20506.1328125\n",
      "Epoch: 186, Batch number: 40, Loss: 20327.005859375\n",
      "Epoch: 187, Batch number: 64, Loss: 20609.79296875\n",
      "Epoch: 189, Batch number: 12, Loss: 20966.69921875\n",
      "Epoch: 190, Batch number: 36, Loss: 20774.44921875\n",
      "Epoch: 191, Batch number: 60, Loss: 20792.126953125\n",
      "Epoch: 193, Batch number: 8, Loss: 20407.892578125\n",
      "Epoch: 194, Batch number: 32, Loss: 20466.1640625\n",
      "Epoch: 195, Batch number: 56, Loss: 20421.5\n",
      "Epoch: 197, Batch number: 4, Loss: 20501.84765625\n",
      "Epoch: 198, Batch number: 28, Loss: 20782.453125\n",
      "Epoch: 199, Batch number: 52, Loss: 20657.32421875\n",
      "Epoch: 201, Batch number: 0, Loss: 20785.99609375\n",
      "Epoch: 202, Batch number: 24, Loss: 20642.35546875\n",
      "Epoch: 203, Batch number: 48, Loss: 20120.318359375\n",
      "Epoch: 204, Batch number: 72, Loss: 20516.134765625\n",
      "Epoch: 206, Batch number: 20, Loss: 20166.201171875\n",
      "Epoch: 207, Batch number: 44, Loss: 20414.40234375\n",
      "Epoch: 208, Batch number: 68, Loss: 20204.890625\n",
      "Epoch: 210, Batch number: 16, Loss: 20793.33203125\n",
      "Epoch: 211, Batch number: 40, Loss: 20629.61328125\n",
      "Epoch: 212, Batch number: 64, Loss: 20816.423828125\n",
      "Epoch: 214, Batch number: 12, Loss: 20934.93359375\n",
      "Epoch: 215, Batch number: 36, Loss: 20622.380859375\n",
      "Epoch: 216, Batch number: 60, Loss: 20139.66015625\n",
      "Epoch: 218, Batch number: 8, Loss: 20437.140625\n",
      "Epoch: 219, Batch number: 32, Loss: 19968.123046875\n",
      "Epoch: 220, Batch number: 56, Loss: 20190.796875\n",
      "Epoch: 222, Batch number: 4, Loss: 20112.669921875\n",
      "Epoch: 223, Batch number: 28, Loss: 20888.3125\n",
      "Epoch: 224, Batch number: 52, Loss: 20343.771484375\n",
      "Epoch: 226, Batch number: 0, Loss: 20725.3515625\n",
      "Epoch: 227, Batch number: 24, Loss: 20497.0546875\n",
      "Epoch: 228, Batch number: 48, Loss: 19913.95703125\n",
      "Epoch: 229, Batch number: 72, Loss: 19911.689453125\n",
      "Epoch: 231, Batch number: 20, Loss: 19898.060546875\n",
      "Epoch: 232, Batch number: 44, Loss: 20372.78125\n",
      "Epoch: 233, Batch number: 68, Loss: 20784.724609375\n",
      "Epoch: 235, Batch number: 16, Loss: 19855.25\n",
      "Epoch: 236, Batch number: 40, Loss: 20537.630859375\n",
      "Epoch: 237, Batch number: 64, Loss: 20774.697265625\n",
      "Epoch: 239, Batch number: 12, Loss: 20350.21484375\n",
      "Epoch: 240, Batch number: 36, Loss: 20544.46875\n",
      "Epoch: 241, Batch number: 60, Loss: 20433.90234375\n",
      "Epoch: 243, Batch number: 8, Loss: 20164.513671875\n",
      "Epoch: 244, Batch number: 32, Loss: 20219.17578125\n",
      "Epoch: 245, Batch number: 56, Loss: 20634.802734375\n",
      "Epoch: 247, Batch number: 4, Loss: 20123.90234375\n",
      "Epoch: 248, Batch number: 28, Loss: 20345.431640625\n",
      "Epoch: 249, Batch number: 52, Loss: 19976.04296875\n",
      "Epoch: 251, Batch number: 0, Loss: 20422.091796875\n",
      "Epoch: 252, Batch number: 24, Loss: 20082.79296875\n",
      "Epoch: 253, Batch number: 48, Loss: 20060.916015625\n",
      "Epoch: 254, Batch number: 72, Loss: 20267.5703125\n",
      "Epoch: 256, Batch number: 20, Loss: 20732.279296875\n",
      "Epoch: 257, Batch number: 44, Loss: 20398.0234375\n",
      "Epoch: 258, Batch number: 68, Loss: 20383.646484375\n",
      "Epoch: 260, Batch number: 16, Loss: 19999.767578125\n",
      "Epoch: 261, Batch number: 40, Loss: 20411.16796875\n",
      "Epoch: 262, Batch number: 64, Loss: 20252.70703125\n",
      "Epoch: 264, Batch number: 12, Loss: 20251.802734375\n",
      "Epoch: 265, Batch number: 36, Loss: 20007.154296875\n",
      "Epoch: 266, Batch number: 60, Loss: 20330.486328125\n",
      "Epoch: 268, Batch number: 8, Loss: 20124.380859375\n",
      "Epoch: 269, Batch number: 32, Loss: 20400.18359375\n",
      "Epoch: 270, Batch number: 56, Loss: 20287.439453125\n",
      "Epoch: 272, Batch number: 4, Loss: 20038.97265625\n",
      "Epoch: 273, Batch number: 28, Loss: 20562.005859375\n",
      "Epoch: 274, Batch number: 52, Loss: 20709.076171875\n",
      "Epoch: 276, Batch number: 0, Loss: 20281.89453125\n",
      "Epoch: 277, Batch number: 24, Loss: 20466.236328125\n",
      "Epoch: 278, Batch number: 48, Loss: 20214.865234375\n",
      "Epoch: 279, Batch number: 72, Loss: 20164.326171875\n",
      "Epoch: 281, Batch number: 20, Loss: 19928.0703125\n",
      "Epoch: 282, Batch number: 44, Loss: 20708.37109375\n",
      "Epoch: 283, Batch number: 68, Loss: 20766.72265625\n",
      "Epoch: 285, Batch number: 16, Loss: 20454.138671875\n",
      "Epoch: 286, Batch number: 40, Loss: 20247.169921875\n",
      "Epoch: 287, Batch number: 64, Loss: 19720.8515625\n",
      "Epoch: 289, Batch number: 12, Loss: 20262.744140625\n",
      "Epoch: 290, Batch number: 36, Loss: 20470.02734375\n",
      "Epoch: 291, Batch number: 60, Loss: 20375.74609375\n",
      "Epoch: 293, Batch number: 8, Loss: 19587.16796875\n",
      "Epoch: 294, Batch number: 32, Loss: 20581.94140625\n",
      "Epoch: 295, Batch number: 56, Loss: 20006.0703125\n",
      "Epoch: 297, Batch number: 4, Loss: 20199.888671875\n",
      "Epoch: 298, Batch number: 28, Loss: 20181.87890625\n",
      "Epoch: 299, Batch number: 52, Loss: 20073.12109375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 37799.63671875\n",
      "Epoch: 2, Batch number: 24, Loss: 34815.43359375\n",
      "Epoch: 3, Batch number: 48, Loss: 33313.35546875\n",
      "Epoch: 4, Batch number: 72, Loss: 31347.03125\n",
      "Epoch: 6, Batch number: 20, Loss: 30824.029296875\n",
      "Epoch: 7, Batch number: 44, Loss: 29289.861328125\n",
      "Epoch: 8, Batch number: 68, Loss: 28828.517578125\n",
      "Epoch: 10, Batch number: 16, Loss: 28051.904296875\n",
      "Epoch: 11, Batch number: 40, Loss: 27105.837890625\n",
      "Epoch: 12, Batch number: 64, Loss: 27335.02734375\n",
      "Epoch: 14, Batch number: 12, Loss: 26186.1953125\n",
      "Epoch: 15, Batch number: 36, Loss: 26249.935546875\n",
      "Epoch: 16, Batch number: 60, Loss: 25389.814453125\n",
      "Epoch: 18, Batch number: 8, Loss: 25094.92578125\n",
      "Epoch: 19, Batch number: 32, Loss: 25061.8515625\n",
      "Epoch: 20, Batch number: 56, Loss: 24686.640625\n",
      "Epoch: 22, Batch number: 4, Loss: 24522.271484375\n",
      "Epoch: 23, Batch number: 28, Loss: 24158.208984375\n",
      "Epoch: 24, Batch number: 52, Loss: 24277.076171875\n",
      "Epoch: 26, Batch number: 0, Loss: 23929.9453125\n",
      "Epoch: 27, Batch number: 24, Loss: 23740.53125\n",
      "Epoch: 28, Batch number: 48, Loss: 23674.109375\n",
      "Epoch: 29, Batch number: 72, Loss: 23683.96875\n",
      "Epoch: 31, Batch number: 20, Loss: 23495.140625\n",
      "Epoch: 32, Batch number: 44, Loss: 23419.576171875\n",
      "Epoch: 33, Batch number: 68, Loss: 23392.19140625\n",
      "Epoch: 35, Batch number: 16, Loss: 22942.0703125\n",
      "Epoch: 36, Batch number: 40, Loss: 22635.513671875\n",
      "Epoch: 37, Batch number: 64, Loss: 23163.595703125\n",
      "Epoch: 39, Batch number: 12, Loss: 22853.27734375\n",
      "Epoch: 40, Batch number: 36, Loss: 22419.669921875\n",
      "Epoch: 41, Batch number: 60, Loss: 22930.91796875\n",
      "Epoch: 43, Batch number: 8, Loss: 22180.7265625\n",
      "Epoch: 44, Batch number: 32, Loss: 22371.732421875\n",
      "Epoch: 45, Batch number: 56, Loss: 22587.0703125\n",
      "Epoch: 47, Batch number: 4, Loss: 22573.455078125\n",
      "Epoch: 48, Batch number: 28, Loss: 22320.1953125\n",
      "Epoch: 49, Batch number: 52, Loss: 22724.5078125\n",
      "Epoch: 51, Batch number: 0, Loss: 21960.873046875\n",
      "Epoch: 52, Batch number: 24, Loss: 21990.509765625\n",
      "Epoch: 53, Batch number: 48, Loss: 22227.021484375\n",
      "Epoch: 54, Batch number: 72, Loss: 22420.05078125\n",
      "Epoch: 56, Batch number: 20, Loss: 22077.37109375\n",
      "Epoch: 57, Batch number: 44, Loss: 22198.0\n",
      "Epoch: 58, Batch number: 68, Loss: 21750.28125\n",
      "Epoch: 60, Batch number: 16, Loss: 21710.009765625\n",
      "Epoch: 61, Batch number: 40, Loss: 22018.529296875\n",
      "Epoch: 62, Batch number: 64, Loss: 22128.119140625\n",
      "Epoch: 64, Batch number: 12, Loss: 21645.587890625\n",
      "Epoch: 65, Batch number: 36, Loss: 22038.9921875\n",
      "Epoch: 66, Batch number: 60, Loss: 22004.091796875\n",
      "Epoch: 68, Batch number: 8, Loss: 21906.638671875\n",
      "Epoch: 69, Batch number: 32, Loss: 21948.63671875\n",
      "Epoch: 70, Batch number: 56, Loss: 21609.115234375\n",
      "Epoch: 72, Batch number: 4, Loss: 21323.033203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Batch number: 28, Loss: 21695.08984375\n",
      "Epoch: 74, Batch number: 52, Loss: 21498.490234375\n",
      "Epoch: 76, Batch number: 0, Loss: 21362.419921875\n",
      "Epoch: 77, Batch number: 24, Loss: 21696.1953125\n",
      "Epoch: 78, Batch number: 48, Loss: 21432.162109375\n",
      "Epoch: 79, Batch number: 72, Loss: 21425.705078125\n",
      "Epoch: 81, Batch number: 20, Loss: 21545.56640625\n",
      "Epoch: 82, Batch number: 44, Loss: 21496.232421875\n",
      "Epoch: 83, Batch number: 68, Loss: 21696.31640625\n",
      "Epoch: 85, Batch number: 16, Loss: 20473.44921875\n",
      "Epoch: 86, Batch number: 40, Loss: 20794.203125\n",
      "Epoch: 87, Batch number: 64, Loss: 21077.79296875\n",
      "Epoch: 89, Batch number: 12, Loss: 21305.0625\n",
      "Epoch: 90, Batch number: 36, Loss: 21537.1015625\n",
      "Epoch: 91, Batch number: 60, Loss: 21483.640625\n",
      "Epoch: 93, Batch number: 8, Loss: 20905.583984375\n",
      "Epoch: 94, Batch number: 32, Loss: 20927.4296875\n",
      "Epoch: 95, Batch number: 56, Loss: 21025.498046875\n",
      "Epoch: 97, Batch number: 4, Loss: 20915.423828125\n",
      "Epoch: 98, Batch number: 28, Loss: 21145.376953125\n",
      "Epoch: 99, Batch number: 52, Loss: 21211.162109375\n",
      "Epoch: 101, Batch number: 0, Loss: 21073.52734375\n",
      "Epoch: 102, Batch number: 24, Loss: 21245.595703125\n",
      "Epoch: 103, Batch number: 48, Loss: 21262.3671875\n",
      "Epoch: 104, Batch number: 72, Loss: 21005.13671875\n",
      "Epoch: 106, Batch number: 20, Loss: 20700.8046875\n",
      "Epoch: 107, Batch number: 44, Loss: 20719.380859375\n",
      "Epoch: 108, Batch number: 68, Loss: 21374.525390625\n",
      "Epoch: 110, Batch number: 16, Loss: 20818.828125\n",
      "Epoch: 111, Batch number: 40, Loss: 21375.984375\n",
      "Epoch: 112, Batch number: 64, Loss: 20908.482421875\n",
      "Epoch: 114, Batch number: 12, Loss: 20646.21875\n",
      "Epoch: 115, Batch number: 36, Loss: 21146.3203125\n",
      "Epoch: 116, Batch number: 60, Loss: 21084.751953125\n",
      "Epoch: 118, Batch number: 8, Loss: 20626.001953125\n",
      "Epoch: 119, Batch number: 32, Loss: 20690.455078125\n",
      "Epoch: 120, Batch number: 56, Loss: 20265.279296875\n",
      "Epoch: 122, Batch number: 4, Loss: 20756.044921875\n",
      "Epoch: 123, Batch number: 28, Loss: 20437.806640625\n",
      "Epoch: 124, Batch number: 52, Loss: 20788.609375\n",
      "Epoch: 126, Batch number: 0, Loss: 20700.12109375\n",
      "Epoch: 127, Batch number: 24, Loss: 20518.83984375\n",
      "Epoch: 128, Batch number: 48, Loss: 20677.763671875\n",
      "Epoch: 129, Batch number: 72, Loss: 20358.462890625\n",
      "Epoch: 131, Batch number: 20, Loss: 20878.02734375\n",
      "Epoch: 132, Batch number: 44, Loss: 20620.642578125\n",
      "Epoch: 133, Batch number: 68, Loss: 21189.205078125\n",
      "Epoch: 135, Batch number: 16, Loss: 20684.8203125\n",
      "Epoch: 136, Batch number: 40, Loss: 20547.125\n",
      "Epoch: 137, Batch number: 64, Loss: 20523.57421875\n",
      "Epoch: 139, Batch number: 12, Loss: 20300.71875\n",
      "Epoch: 140, Batch number: 36, Loss: 20436.76171875\n",
      "Epoch: 141, Batch number: 60, Loss: 20311.5078125\n",
      "Epoch: 143, Batch number: 8, Loss: 20420.4296875\n",
      "Epoch: 144, Batch number: 32, Loss: 20715.685546875\n",
      "Epoch: 145, Batch number: 56, Loss: 20468.291015625\n",
      "Epoch: 147, Batch number: 4, Loss: 20477.501953125\n",
      "Epoch: 148, Batch number: 28, Loss: 20353.251953125\n",
      "Epoch: 149, Batch number: 52, Loss: 20613.66015625\n",
      "Epoch: 151, Batch number: 0, Loss: 20248.794921875\n",
      "Epoch: 152, Batch number: 24, Loss: 20239.255859375\n",
      "Epoch: 153, Batch number: 48, Loss: 20832.451171875\n",
      "Epoch: 154, Batch number: 72, Loss: 20642.998046875\n",
      "Epoch: 156, Batch number: 20, Loss: 20547.146484375\n",
      "Epoch: 157, Batch number: 44, Loss: 20464.603515625\n",
      "Epoch: 158, Batch number: 68, Loss: 20906.623046875\n",
      "Epoch: 160, Batch number: 16, Loss: 20095.3515625\n",
      "Epoch: 161, Batch number: 40, Loss: 20813.3828125\n",
      "Epoch: 162, Batch number: 64, Loss: 20535.376953125\n",
      "Epoch: 164, Batch number: 12, Loss: 20557.39453125\n",
      "Epoch: 165, Batch number: 36, Loss: 20255.1484375\n",
      "Epoch: 166, Batch number: 60, Loss: 20357.80078125\n",
      "Epoch: 168, Batch number: 8, Loss: 20497.1015625\n",
      "Epoch: 169, Batch number: 32, Loss: 19659.3515625\n",
      "Epoch: 170, Batch number: 56, Loss: 20018.447265625\n",
      "Epoch: 172, Batch number: 4, Loss: 20136.83984375\n",
      "Epoch: 173, Batch number: 28, Loss: 20205.4921875\n",
      "Epoch: 174, Batch number: 52, Loss: 20317.703125\n",
      "Epoch: 176, Batch number: 0, Loss: 20258.693359375\n",
      "Epoch: 177, Batch number: 24, Loss: 20045.509765625\n",
      "Epoch: 178, Batch number: 48, Loss: 20417.62109375\n",
      "Epoch: 179, Batch number: 72, Loss: 20232.361328125\n",
      "Epoch: 181, Batch number: 20, Loss: 20147.396484375\n",
      "Epoch: 182, Batch number: 44, Loss: 20300.5078125\n",
      "Epoch: 183, Batch number: 68, Loss: 20927.609375\n",
      "Epoch: 185, Batch number: 16, Loss: 20151.361328125\n",
      "Epoch: 186, Batch number: 40, Loss: 20477.3046875\n",
      "Epoch: 187, Batch number: 64, Loss: 20459.08984375\n",
      "Epoch: 189, Batch number: 12, Loss: 20574.494140625\n",
      "Epoch: 190, Batch number: 36, Loss: 19879.40234375\n",
      "Epoch: 191, Batch number: 60, Loss: 20509.611328125\n",
      "Epoch: 193, Batch number: 8, Loss: 20225.228515625\n",
      "Epoch: 194, Batch number: 32, Loss: 19810.892578125\n",
      "Epoch: 195, Batch number: 56, Loss: 19795.90234375\n",
      "Epoch: 197, Batch number: 4, Loss: 20484.76171875\n",
      "Epoch: 198, Batch number: 28, Loss: 20212.55078125\n",
      "Epoch: 199, Batch number: 52, Loss: 20507.7734375\n",
      "Epoch: 201, Batch number: 0, Loss: 19801.09765625\n",
      "Epoch: 202, Batch number: 24, Loss: 20361.1796875\n",
      "Epoch: 203, Batch number: 48, Loss: 20006.9765625\n",
      "Epoch: 204, Batch number: 72, Loss: 20235.12890625\n",
      "Epoch: 206, Batch number: 20, Loss: 20270.333984375\n",
      "Epoch: 207, Batch number: 44, Loss: 19526.42578125\n",
      "Epoch: 208, Batch number: 68, Loss: 20431.212890625\n",
      "Epoch: 210, Batch number: 16, Loss: 19787.00390625\n",
      "Epoch: 211, Batch number: 40, Loss: 20884.697265625\n",
      "Epoch: 212, Batch number: 64, Loss: 20129.212890625\n",
      "Epoch: 214, Batch number: 12, Loss: 19400.87890625\n",
      "Epoch: 215, Batch number: 36, Loss: 20158.931640625\n",
      "Epoch: 216, Batch number: 60, Loss: 20109.134765625\n",
      "Epoch: 218, Batch number: 8, Loss: 19970.763671875\n",
      "Epoch: 219, Batch number: 32, Loss: 19944.08984375\n",
      "Epoch: 220, Batch number: 56, Loss: 20158.447265625\n",
      "Epoch: 222, Batch number: 4, Loss: 20472.23828125\n",
      "Epoch: 223, Batch number: 28, Loss: 19867.6953125\n",
      "Epoch: 224, Batch number: 52, Loss: 20066.23828125\n",
      "Epoch: 226, Batch number: 0, Loss: 19910.443359375\n",
      "Epoch: 227, Batch number: 24, Loss: 19633.50390625\n",
      "Epoch: 228, Batch number: 48, Loss: 20326.83984375\n",
      "Epoch: 229, Batch number: 72, Loss: 20023.08984375\n",
      "Epoch: 231, Batch number: 20, Loss: 19876.576171875\n",
      "Epoch: 232, Batch number: 44, Loss: 19836.1015625\n",
      "Epoch: 233, Batch number: 68, Loss: 20273.236328125\n",
      "Epoch: 235, Batch number: 16, Loss: 20161.54296875\n",
      "Epoch: 236, Batch number: 40, Loss: 20069.341796875\n",
      "Epoch: 237, Batch number: 64, Loss: 20092.703125\n",
      "Epoch: 239, Batch number: 12, Loss: 20103.66015625\n",
      "Epoch: 240, Batch number: 36, Loss: 19870.37890625\n",
      "Epoch: 241, Batch number: 60, Loss: 20034.6484375\n",
      "Epoch: 243, Batch number: 8, Loss: 19926.205078125\n",
      "Epoch: 244, Batch number: 32, Loss: 19825.65234375\n",
      "Epoch: 245, Batch number: 56, Loss: 19951.56640625\n",
      "Epoch: 247, Batch number: 4, Loss: 19574.701171875\n",
      "Epoch: 248, Batch number: 28, Loss: 20280.412109375\n",
      "Epoch: 249, Batch number: 52, Loss: 19541.169921875\n",
      "Epoch: 251, Batch number: 0, Loss: 19744.501953125\n",
      "Epoch: 252, Batch number: 24, Loss: 20104.177734375\n",
      "Epoch: 253, Batch number: 48, Loss: 19934.20703125\n",
      "Epoch: 254, Batch number: 72, Loss: 20073.16015625\n",
      "Epoch: 256, Batch number: 20, Loss: 19285.828125\n",
      "Epoch: 257, Batch number: 44, Loss: 20004.4296875\n",
      "Epoch: 258, Batch number: 68, Loss: 20382.666015625\n",
      "Epoch: 260, Batch number: 16, Loss: 19322.505859375\n",
      "Epoch: 261, Batch number: 40, Loss: 19584.5703125\n",
      "Epoch: 262, Batch number: 64, Loss: 19499.6171875\n",
      "Epoch: 264, Batch number: 12, Loss: 19869.009765625\n",
      "Epoch: 265, Batch number: 36, Loss: 19593.400390625\n",
      "Epoch: 266, Batch number: 60, Loss: 20236.84765625\n",
      "Epoch: 268, Batch number: 8, Loss: 20176.443359375\n",
      "Epoch: 269, Batch number: 32, Loss: 19327.09375\n",
      "Epoch: 270, Batch number: 56, Loss: 19652.2421875\n",
      "Epoch: 272, Batch number: 4, Loss: 19666.61328125\n",
      "Epoch: 273, Batch number: 28, Loss: 20401.9140625\n",
      "Epoch: 274, Batch number: 52, Loss: 19773.455078125\n",
      "Epoch: 276, Batch number: 0, Loss: 19936.013671875\n",
      "Epoch: 277, Batch number: 24, Loss: 20360.298828125\n",
      "Epoch: 278, Batch number: 48, Loss: 20008.16015625\n",
      "Epoch: 279, Batch number: 72, Loss: 19532.23046875\n",
      "Epoch: 281, Batch number: 20, Loss: 20471.015625\n",
      "Epoch: 282, Batch number: 44, Loss: 20047.677734375\n",
      "Epoch: 283, Batch number: 68, Loss: 20175.93359375\n",
      "Epoch: 285, Batch number: 16, Loss: 19082.232421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286, Batch number: 40, Loss: 19808.77734375\n",
      "Epoch: 287, Batch number: 64, Loss: 19933.734375\n",
      "Epoch: 289, Batch number: 12, Loss: 20013.607421875\n",
      "Epoch: 290, Batch number: 36, Loss: 19735.544921875\n",
      "Epoch: 291, Batch number: 60, Loss: 20316.615234375\n",
      "Epoch: 293, Batch number: 8, Loss: 19721.541015625\n",
      "Epoch: 294, Batch number: 32, Loss: 19943.599609375\n",
      "Epoch: 295, Batch number: 56, Loss: 20272.33984375\n",
      "Epoch: 297, Batch number: 4, Loss: 19457.072265625\n",
      "Epoch: 298, Batch number: 28, Loss: 20317.365234375\n",
      "Epoch: 299, Batch number: 52, Loss: 19737.359375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 38086.671875\n",
      "Epoch: 2, Batch number: 24, Loss: 34590.1953125\n",
      "Epoch: 3, Batch number: 48, Loss: 33051.2265625\n",
      "Epoch: 4, Batch number: 72, Loss: 31582.498046875\n",
      "Epoch: 6, Batch number: 20, Loss: 29485.302734375\n",
      "Epoch: 7, Batch number: 44, Loss: 28461.8828125\n",
      "Epoch: 8, Batch number: 68, Loss: 27852.56640625\n",
      "Epoch: 10, Batch number: 16, Loss: 26866.439453125\n",
      "Epoch: 11, Batch number: 40, Loss: 26363.837890625\n",
      "Epoch: 12, Batch number: 64, Loss: 25903.69140625\n",
      "Epoch: 14, Batch number: 12, Loss: 25347.763671875\n",
      "Epoch: 15, Batch number: 36, Loss: 25052.0859375\n",
      "Epoch: 16, Batch number: 60, Loss: 24817.703125\n",
      "Epoch: 18, Batch number: 8, Loss: 24302.216796875\n",
      "Epoch: 19, Batch number: 32, Loss: 24087.50390625\n",
      "Epoch: 20, Batch number: 56, Loss: 23955.169921875\n",
      "Epoch: 22, Batch number: 4, Loss: 23573.8984375\n",
      "Epoch: 23, Batch number: 28, Loss: 23708.779296875\n",
      "Epoch: 24, Batch number: 52, Loss: 23299.767578125\n",
      "Epoch: 26, Batch number: 0, Loss: 23174.755859375\n",
      "Epoch: 27, Batch number: 24, Loss: 23116.16796875\n",
      "Epoch: 28, Batch number: 48, Loss: 22482.927734375\n",
      "Epoch: 29, Batch number: 72, Loss: 22557.869140625\n",
      "Epoch: 31, Batch number: 20, Loss: 22576.005859375\n",
      "Epoch: 32, Batch number: 44, Loss: 22413.759765625\n",
      "Epoch: 33, Batch number: 68, Loss: 23043.001953125\n",
      "Epoch: 35, Batch number: 16, Loss: 22382.162109375\n",
      "Epoch: 36, Batch number: 40, Loss: 22135.765625\n",
      "Epoch: 37, Batch number: 64, Loss: 22809.00390625\n",
      "Epoch: 39, Batch number: 12, Loss: 22178.904296875\n",
      "Epoch: 40, Batch number: 36, Loss: 22063.572265625\n",
      "Epoch: 41, Batch number: 60, Loss: 21913.072265625\n",
      "Epoch: 43, Batch number: 8, Loss: 21902.666015625\n",
      "Epoch: 44, Batch number: 32, Loss: 21830.0\n",
      "Epoch: 45, Batch number: 56, Loss: 21915.06640625\n",
      "Epoch: 47, Batch number: 4, Loss: 22023.4140625\n",
      "Epoch: 48, Batch number: 28, Loss: 21545.7734375\n",
      "Epoch: 49, Batch number: 52, Loss: 21714.330078125\n",
      "Epoch: 51, Batch number: 0, Loss: 21683.638671875\n",
      "Epoch: 52, Batch number: 24, Loss: 21459.44921875\n",
      "Epoch: 53, Batch number: 48, Loss: 21383.52734375\n",
      "Epoch: 54, Batch number: 72, Loss: 21954.93359375\n",
      "Epoch: 56, Batch number: 20, Loss: 21741.908203125\n",
      "Epoch: 57, Batch number: 44, Loss: 21478.28515625\n",
      "Epoch: 58, Batch number: 68, Loss: 21511.091796875\n",
      "Epoch: 60, Batch number: 16, Loss: 21861.857421875\n",
      "Epoch: 61, Batch number: 40, Loss: 21239.421875\n",
      "Epoch: 62, Batch number: 64, Loss: 21201.181640625\n",
      "Epoch: 64, Batch number: 12, Loss: 21389.4296875\n",
      "Epoch: 65, Batch number: 36, Loss: 21352.36328125\n",
      "Epoch: 66, Batch number: 60, Loss: 21004.1484375\n",
      "Epoch: 68, Batch number: 8, Loss: 21175.8984375\n",
      "Epoch: 69, Batch number: 32, Loss: 21158.46484375\n",
      "Epoch: 70, Batch number: 56, Loss: 21640.56640625\n",
      "Epoch: 72, Batch number: 4, Loss: 20930.591796875\n",
      "Epoch: 73, Batch number: 28, Loss: 21114.71484375\n",
      "Epoch: 74, Batch number: 52, Loss: 21018.6875\n",
      "Epoch: 76, Batch number: 0, Loss: 20894.53515625\n",
      "Epoch: 77, Batch number: 24, Loss: 20998.1953125\n",
      "Epoch: 78, Batch number: 48, Loss: 21520.861328125\n",
      "Epoch: 79, Batch number: 72, Loss: 21097.482421875\n",
      "Epoch: 81, Batch number: 20, Loss: 21108.201171875\n",
      "Epoch: 82, Batch number: 44, Loss: 20899.158203125\n",
      "Epoch: 83, Batch number: 68, Loss: 21307.296875\n",
      "Epoch: 85, Batch number: 16, Loss: 20892.615234375\n",
      "Epoch: 86, Batch number: 40, Loss: 20721.62109375\n",
      "Epoch: 87, Batch number: 64, Loss: 20807.6875\n",
      "Epoch: 89, Batch number: 12, Loss: 20418.576171875\n",
      "Epoch: 90, Batch number: 36, Loss: 20757.265625\n",
      "Epoch: 91, Batch number: 60, Loss: 20916.712890625\n",
      "Epoch: 93, Batch number: 8, Loss: 20798.556640625\n",
      "Epoch: 94, Batch number: 32, Loss: 21196.771484375\n",
      "Epoch: 95, Batch number: 56, Loss: 20908.86328125\n",
      "Epoch: 97, Batch number: 4, Loss: 20776.408203125\n",
      "Epoch: 98, Batch number: 28, Loss: 20740.80078125\n",
      "Epoch: 99, Batch number: 52, Loss: 20614.11328125\n",
      "Epoch: 101, Batch number: 0, Loss: 20736.509765625\n",
      "Epoch: 102, Batch number: 24, Loss: 20336.126953125\n",
      "Epoch: 103, Batch number: 48, Loss: 20918.001953125\n",
      "Epoch: 104, Batch number: 72, Loss: 20927.314453125\n",
      "Epoch: 106, Batch number: 20, Loss: 20204.541015625\n",
      "Epoch: 107, Batch number: 44, Loss: 20096.458984375\n",
      "Epoch: 108, Batch number: 68, Loss: 20618.537109375\n",
      "Epoch: 110, Batch number: 16, Loss: 20398.291015625\n",
      "Epoch: 111, Batch number: 40, Loss: 20442.919921875\n",
      "Epoch: 112, Batch number: 64, Loss: 20517.841796875\n",
      "Epoch: 114, Batch number: 12, Loss: 20698.443359375\n",
      "Epoch: 115, Batch number: 36, Loss: 20350.265625\n",
      "Epoch: 116, Batch number: 60, Loss: 21008.763671875\n",
      "Epoch: 118, Batch number: 8, Loss: 20069.244140625\n",
      "Epoch: 119, Batch number: 32, Loss: 20624.23046875\n",
      "Epoch: 120, Batch number: 56, Loss: 20700.642578125\n",
      "Epoch: 122, Batch number: 4, Loss: 20169.7265625\n",
      "Epoch: 123, Batch number: 28, Loss: 20744.12890625\n",
      "Epoch: 124, Batch number: 52, Loss: 20509.966796875\n",
      "Epoch: 126, Batch number: 0, Loss: 20244.44921875\n",
      "Epoch: 127, Batch number: 24, Loss: 20172.28515625\n",
      "Epoch: 128, Batch number: 48, Loss: 21191.685546875\n",
      "Epoch: 129, Batch number: 72, Loss: 20197.892578125\n",
      "Epoch: 131, Batch number: 20, Loss: 20422.9921875\n",
      "Epoch: 132, Batch number: 44, Loss: 20642.740234375\n",
      "Epoch: 133, Batch number: 68, Loss: 20704.998046875\n",
      "Epoch: 135, Batch number: 16, Loss: 20138.294921875\n",
      "Epoch: 136, Batch number: 40, Loss: 20359.548828125\n",
      "Epoch: 137, Batch number: 64, Loss: 19957.765625\n",
      "Epoch: 139, Batch number: 12, Loss: 20406.8359375\n",
      "Epoch: 140, Batch number: 36, Loss: 20441.166015625\n",
      "Epoch: 141, Batch number: 60, Loss: 20648.150390625\n",
      "Epoch: 143, Batch number: 8, Loss: 20180.443359375\n",
      "Epoch: 144, Batch number: 32, Loss: 20586.84765625\n",
      "Epoch: 145, Batch number: 56, Loss: 20120.4296875\n",
      "Epoch: 147, Batch number: 4, Loss: 19851.2421875\n",
      "Epoch: 148, Batch number: 28, Loss: 20370.380859375\n",
      "Epoch: 149, Batch number: 52, Loss: 20592.384765625\n",
      "Epoch: 151, Batch number: 0, Loss: 19859.29296875\n",
      "Epoch: 152, Batch number: 24, Loss: 19975.7265625\n",
      "Epoch: 153, Batch number: 48, Loss: 20189.990234375\n",
      "Epoch: 154, Batch number: 72, Loss: 20774.833984375\n",
      "Epoch: 156, Batch number: 20, Loss: 20147.947265625\n",
      "Epoch: 157, Batch number: 44, Loss: 20464.623046875\n",
      "Epoch: 158, Batch number: 68, Loss: 20094.962890625\n",
      "Epoch: 160, Batch number: 16, Loss: 19735.900390625\n",
      "Epoch: 161, Batch number: 40, Loss: 19906.6015625\n",
      "Epoch: 162, Batch number: 64, Loss: 19900.1015625\n",
      "Epoch: 164, Batch number: 12, Loss: 20276.599609375\n",
      "Epoch: 165, Batch number: 36, Loss: 20170.1328125\n",
      "Epoch: 166, Batch number: 60, Loss: 20138.48046875\n",
      "Epoch: 168, Batch number: 8, Loss: 20072.0625\n",
      "Epoch: 169, Batch number: 32, Loss: 20149.38671875\n",
      "Epoch: 170, Batch number: 56, Loss: 19748.23828125\n",
      "Epoch: 172, Batch number: 4, Loss: 20076.6640625\n",
      "Epoch: 173, Batch number: 28, Loss: 19416.927734375\n",
      "Epoch: 174, Batch number: 52, Loss: 20209.02734375\n",
      "Epoch: 176, Batch number: 0, Loss: 20243.623046875\n",
      "Epoch: 177, Batch number: 24, Loss: 20237.126953125\n",
      "Epoch: 178, Batch number: 48, Loss: 20249.568359375\n",
      "Epoch: 179, Batch number: 72, Loss: 19948.69140625\n",
      "Epoch: 181, Batch number: 20, Loss: 19892.892578125\n",
      "Epoch: 182, Batch number: 44, Loss: 20153.697265625\n",
      "Epoch: 183, Batch number: 68, Loss: 20110.08984375\n",
      "Epoch: 185, Batch number: 16, Loss: 19853.349609375\n",
      "Epoch: 186, Batch number: 40, Loss: 19916.52734375\n",
      "Epoch: 187, Batch number: 64, Loss: 20485.908203125\n",
      "Epoch: 189, Batch number: 12, Loss: 20495.8515625\n",
      "Epoch: 190, Batch number: 36, Loss: 19991.515625\n",
      "Epoch: 191, Batch number: 60, Loss: 20012.720703125\n",
      "Epoch: 193, Batch number: 8, Loss: 19686.58984375\n",
      "Epoch: 194, Batch number: 32, Loss: 20102.275390625\n",
      "Epoch: 195, Batch number: 56, Loss: 20394.138671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 197, Batch number: 4, Loss: 19991.501953125\n",
      "Epoch: 198, Batch number: 28, Loss: 19892.697265625\n",
      "Epoch: 199, Batch number: 52, Loss: 19912.13671875\n",
      "Epoch: 201, Batch number: 0, Loss: 19506.853515625\n",
      "Epoch: 202, Batch number: 24, Loss: 19698.828125\n",
      "Epoch: 203, Batch number: 48, Loss: 19963.740234375\n",
      "Epoch: 204, Batch number: 72, Loss: 20114.51953125\n",
      "Epoch: 206, Batch number: 20, Loss: 20090.826171875\n",
      "Epoch: 207, Batch number: 44, Loss: 20005.853515625\n",
      "Epoch: 208, Batch number: 68, Loss: 19675.3359375\n",
      "Epoch: 210, Batch number: 16, Loss: 19701.603515625\n",
      "Epoch: 211, Batch number: 40, Loss: 19908.033203125\n",
      "Epoch: 212, Batch number: 64, Loss: 19882.53125\n",
      "Epoch: 214, Batch number: 12, Loss: 19738.22265625\n",
      "Epoch: 215, Batch number: 36, Loss: 20382.466796875\n",
      "Epoch: 216, Batch number: 60, Loss: 20492.671875\n",
      "Epoch: 218, Batch number: 8, Loss: 19419.263671875\n",
      "Epoch: 219, Batch number: 32, Loss: 19489.357421875\n",
      "Epoch: 220, Batch number: 56, Loss: 19687.560546875\n",
      "Epoch: 222, Batch number: 4, Loss: 19627.572265625\n",
      "Epoch: 223, Batch number: 28, Loss: 19688.9921875\n",
      "Epoch: 224, Batch number: 52, Loss: 19887.09375\n",
      "Epoch: 226, Batch number: 0, Loss: 20041.501953125\n",
      "Epoch: 227, Batch number: 24, Loss: 19609.146484375\n",
      "Epoch: 228, Batch number: 48, Loss: 20347.537109375\n",
      "Epoch: 229, Batch number: 72, Loss: 20263.095703125\n",
      "Epoch: 231, Batch number: 20, Loss: 19776.134765625\n",
      "Epoch: 232, Batch number: 44, Loss: 20036.4453125\n",
      "Epoch: 233, Batch number: 68, Loss: 19687.23046875\n",
      "Epoch: 235, Batch number: 16, Loss: 20364.640625\n",
      "Epoch: 236, Batch number: 40, Loss: 19988.73828125\n",
      "Epoch: 237, Batch number: 64, Loss: 19797.1796875\n",
      "Epoch: 239, Batch number: 12, Loss: 19683.177734375\n",
      "Epoch: 240, Batch number: 36, Loss: 19489.3125\n",
      "Epoch: 241, Batch number: 60, Loss: 20288.375\n",
      "Epoch: 243, Batch number: 8, Loss: 19276.091796875\n",
      "Epoch: 244, Batch number: 32, Loss: 19847.37109375\n",
      "Epoch: 245, Batch number: 56, Loss: 20325.068359375\n",
      "Epoch: 247, Batch number: 4, Loss: 19945.837890625\n",
      "Epoch: 248, Batch number: 28, Loss: 19714.181640625\n",
      "Epoch: 249, Batch number: 52, Loss: 19715.369140625\n",
      "Epoch: 251, Batch number: 0, Loss: 19238.8671875\n",
      "Epoch: 252, Batch number: 24, Loss: 20253.025390625\n",
      "Epoch: 253, Batch number: 48, Loss: 20125.56640625\n",
      "Epoch: 254, Batch number: 72, Loss: 19526.943359375\n",
      "Epoch: 256, Batch number: 20, Loss: 19612.001953125\n",
      "Epoch: 257, Batch number: 44, Loss: 19879.169921875\n",
      "Epoch: 258, Batch number: 68, Loss: 20146.037109375\n",
      "Epoch: 260, Batch number: 16, Loss: 19993.37109375\n",
      "Epoch: 261, Batch number: 40, Loss: 20472.34765625\n",
      "Epoch: 262, Batch number: 64, Loss: 20478.3125\n",
      "Epoch: 264, Batch number: 12, Loss: 19140.49609375\n",
      "Epoch: 265, Batch number: 36, Loss: 19819.373046875\n",
      "Epoch: 266, Batch number: 60, Loss: 19429.333984375\n",
      "Epoch: 268, Batch number: 8, Loss: 19373.685546875\n",
      "Epoch: 269, Batch number: 32, Loss: 20023.15625\n",
      "Epoch: 270, Batch number: 56, Loss: 19778.517578125\n",
      "Epoch: 272, Batch number: 4, Loss: 19892.392578125\n",
      "Epoch: 273, Batch number: 28, Loss: 19704.626953125\n",
      "Epoch: 274, Batch number: 52, Loss: 20009.3046875\n",
      "Epoch: 276, Batch number: 0, Loss: 19055.853515625\n",
      "Epoch: 277, Batch number: 24, Loss: 19479.923828125\n",
      "Epoch: 278, Batch number: 48, Loss: 19595.9921875\n",
      "Epoch: 279, Batch number: 72, Loss: 20113.330078125\n",
      "Epoch: 281, Batch number: 20, Loss: 19993.021484375\n",
      "Epoch: 282, Batch number: 44, Loss: 19765.646484375\n",
      "Epoch: 283, Batch number: 68, Loss: 20444.919921875\n",
      "Epoch: 285, Batch number: 16, Loss: 20124.451171875\n",
      "Epoch: 286, Batch number: 40, Loss: 19806.564453125\n",
      "Epoch: 287, Batch number: 64, Loss: 19961.2890625\n",
      "Epoch: 289, Batch number: 12, Loss: 20047.98046875\n",
      "Epoch: 290, Batch number: 36, Loss: 19941.470703125\n",
      "Epoch: 291, Batch number: 60, Loss: 20216.51171875\n",
      "Epoch: 293, Batch number: 8, Loss: 19832.041015625\n",
      "Epoch: 294, Batch number: 32, Loss: 20156.80078125\n",
      "Epoch: 295, Batch number: 56, Loss: 19716.45703125\n",
      "Epoch: 297, Batch number: 4, Loss: 19362.10546875\n",
      "Epoch: 298, Batch number: 28, Loss: 19973.03125\n",
      "Epoch: 299, Batch number: 52, Loss: 19765.71875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 38390.53515625\n",
      "Epoch: 2, Batch number: 24, Loss: 34106.60546875\n",
      "Epoch: 3, Batch number: 48, Loss: 32138.166015625\n",
      "Epoch: 4, Batch number: 72, Loss: 30665.142578125\n",
      "Epoch: 6, Batch number: 20, Loss: 28406.17578125\n",
      "Epoch: 7, Batch number: 44, Loss: 27085.35546875\n",
      "Epoch: 8, Batch number: 68, Loss: 26787.296875\n",
      "Epoch: 10, Batch number: 16, Loss: 25451.64453125\n",
      "Epoch: 11, Batch number: 40, Loss: 25443.193359375\n",
      "Epoch: 12, Batch number: 64, Loss: 25022.66796875\n",
      "Epoch: 14, Batch number: 12, Loss: 24258.55078125\n",
      "Epoch: 15, Batch number: 36, Loss: 24129.2265625\n",
      "Epoch: 16, Batch number: 60, Loss: 23823.515625\n",
      "Epoch: 18, Batch number: 8, Loss: 22922.001953125\n",
      "Epoch: 19, Batch number: 32, Loss: 23287.845703125\n",
      "Epoch: 20, Batch number: 56, Loss: 22950.58984375\n",
      "Epoch: 22, Batch number: 4, Loss: 22370.900390625\n",
      "Epoch: 23, Batch number: 28, Loss: 22477.396484375\n",
      "Epoch: 24, Batch number: 52, Loss: 22289.97265625\n",
      "Epoch: 26, Batch number: 0, Loss: 22097.958984375\n",
      "Epoch: 27, Batch number: 24, Loss: 21735.77734375\n",
      "Epoch: 28, Batch number: 48, Loss: 22463.916015625\n",
      "Epoch: 29, Batch number: 72, Loss: 21922.4765625\n",
      "Epoch: 31, Batch number: 20, Loss: 21826.234375\n",
      "Epoch: 32, Batch number: 44, Loss: 21613.7578125\n",
      "Epoch: 33, Batch number: 68, Loss: 21725.666015625\n",
      "Epoch: 35, Batch number: 16, Loss: 21416.74609375\n",
      "Epoch: 36, Batch number: 40, Loss: 21550.6953125\n",
      "Epoch: 37, Batch number: 64, Loss: 21538.26953125\n",
      "Epoch: 39, Batch number: 12, Loss: 21632.63671875\n",
      "Epoch: 40, Batch number: 36, Loss: 21487.76953125\n",
      "Epoch: 41, Batch number: 60, Loss: 21324.474609375\n",
      "Epoch: 43, Batch number: 8, Loss: 21269.546875\n",
      "Epoch: 44, Batch number: 32, Loss: 21261.28515625\n",
      "Epoch: 45, Batch number: 56, Loss: 21563.03515625\n",
      "Epoch: 47, Batch number: 4, Loss: 21283.021484375\n",
      "Epoch: 48, Batch number: 28, Loss: 20501.162109375\n",
      "Epoch: 49, Batch number: 52, Loss: 21343.765625\n",
      "Epoch: 51, Batch number: 0, Loss: 20713.169921875\n",
      "Epoch: 52, Batch number: 24, Loss: 20581.5625\n",
      "Epoch: 53, Batch number: 48, Loss: 20778.361328125\n",
      "Epoch: 54, Batch number: 72, Loss: 20824.7109375\n",
      "Epoch: 56, Batch number: 20, Loss: 20812.947265625\n",
      "Epoch: 57, Batch number: 44, Loss: 20267.708984375\n",
      "Epoch: 58, Batch number: 68, Loss: 20812.875\n",
      "Epoch: 60, Batch number: 16, Loss: 20447.888671875\n",
      "Epoch: 61, Batch number: 40, Loss: 20239.58984375\n",
      "Epoch: 62, Batch number: 64, Loss: 21090.71875\n",
      "Epoch: 64, Batch number: 12, Loss: 20282.19921875\n",
      "Epoch: 65, Batch number: 36, Loss: 20173.068359375\n",
      "Epoch: 66, Batch number: 60, Loss: 21022.671875\n",
      "Epoch: 68, Batch number: 8, Loss: 20890.26171875\n",
      "Epoch: 69, Batch number: 32, Loss: 20764.59375\n",
      "Epoch: 70, Batch number: 56, Loss: 20614.732421875\n",
      "Epoch: 72, Batch number: 4, Loss: 20106.599609375\n",
      "Epoch: 73, Batch number: 28, Loss: 20397.513671875\n",
      "Epoch: 74, Batch number: 52, Loss: 21040.021484375\n",
      "Epoch: 76, Batch number: 0, Loss: 20397.62890625\n",
      "Epoch: 77, Batch number: 24, Loss: 20268.94921875\n",
      "Epoch: 78, Batch number: 48, Loss: 20378.865234375\n",
      "Epoch: 79, Batch number: 72, Loss: 20027.79296875\n",
      "Epoch: 81, Batch number: 20, Loss: 20693.037109375\n",
      "Epoch: 82, Batch number: 44, Loss: 20257.4296875\n",
      "Epoch: 83, Batch number: 68, Loss: 20857.98828125\n",
      "Epoch: 85, Batch number: 16, Loss: 20892.4921875\n",
      "Epoch: 86, Batch number: 40, Loss: 20158.12890625\n",
      "Epoch: 87, Batch number: 64, Loss: 20227.66015625\n",
      "Epoch: 89, Batch number: 12, Loss: 20332.525390625\n",
      "Epoch: 90, Batch number: 36, Loss: 20035.5546875\n",
      "Epoch: 91, Batch number: 60, Loss: 20632.263671875\n",
      "Epoch: 93, Batch number: 8, Loss: 20065.734375\n",
      "Epoch: 94, Batch number: 32, Loss: 19513.060546875\n",
      "Epoch: 95, Batch number: 56, Loss: 20261.7578125\n",
      "Epoch: 97, Batch number: 4, Loss: 20246.283203125\n",
      "Epoch: 98, Batch number: 28, Loss: 19707.19140625\n",
      "Epoch: 99, Batch number: 52, Loss: 20568.251953125\n",
      "Epoch: 101, Batch number: 0, Loss: 20255.451171875\n",
      "Epoch: 102, Batch number: 24, Loss: 20220.462890625\n",
      "Epoch: 103, Batch number: 48, Loss: 20162.916015625\n",
      "Epoch: 104, Batch number: 72, Loss: 20173.107421875\n",
      "Epoch: 106, Batch number: 20, Loss: 19966.033203125\n",
      "Epoch: 107, Batch number: 44, Loss: 20235.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Batch number: 68, Loss: 19763.015625\n",
      "Epoch: 110, Batch number: 16, Loss: 19901.068359375\n",
      "Epoch: 111, Batch number: 40, Loss: 20092.9453125\n",
      "Epoch: 112, Batch number: 64, Loss: 20086.423828125\n",
      "Epoch: 114, Batch number: 12, Loss: 19935.17578125\n",
      "Epoch: 115, Batch number: 36, Loss: 19782.6328125\n",
      "Epoch: 116, Batch number: 60, Loss: 20162.115234375\n",
      "Epoch: 118, Batch number: 8, Loss: 20290.923828125\n",
      "Epoch: 119, Batch number: 32, Loss: 20354.265625\n",
      "Epoch: 120, Batch number: 56, Loss: 20164.24609375\n",
      "Epoch: 122, Batch number: 4, Loss: 19757.111328125\n",
      "Epoch: 123, Batch number: 28, Loss: 19631.630859375\n",
      "Epoch: 124, Batch number: 52, Loss: 20185.09765625\n",
      "Epoch: 126, Batch number: 0, Loss: 19956.712890625\n",
      "Epoch: 127, Batch number: 24, Loss: 19311.462890625\n",
      "Epoch: 128, Batch number: 48, Loss: 20169.234375\n",
      "Epoch: 129, Batch number: 72, Loss: 20319.90625\n",
      "Epoch: 131, Batch number: 20, Loss: 20047.53125\n",
      "Epoch: 132, Batch number: 44, Loss: 19839.76953125\n",
      "Epoch: 133, Batch number: 68, Loss: 20356.078125\n",
      "Epoch: 135, Batch number: 16, Loss: 19788.603515625\n",
      "Epoch: 136, Batch number: 40, Loss: 20168.578125\n",
      "Epoch: 137, Batch number: 64, Loss: 19940.517578125\n",
      "Epoch: 139, Batch number: 12, Loss: 20251.609375\n",
      "Epoch: 140, Batch number: 36, Loss: 19895.978515625\n",
      "Epoch: 141, Batch number: 60, Loss: 20146.10546875\n",
      "Epoch: 143, Batch number: 8, Loss: 19891.658203125\n",
      "Epoch: 144, Batch number: 32, Loss: 20155.3359375\n",
      "Epoch: 145, Batch number: 56, Loss: 19898.486328125\n",
      "Epoch: 147, Batch number: 4, Loss: 20038.3671875\n",
      "Epoch: 148, Batch number: 28, Loss: 20128.349609375\n",
      "Epoch: 149, Batch number: 52, Loss: 20240.962890625\n",
      "Epoch: 151, Batch number: 0, Loss: 19336.263671875\n",
      "Epoch: 152, Batch number: 24, Loss: 19581.15625\n",
      "Epoch: 153, Batch number: 48, Loss: 19865.62109375\n",
      "Epoch: 154, Batch number: 72, Loss: 19805.36328125\n",
      "Epoch: 156, Batch number: 20, Loss: 19829.439453125\n",
      "Epoch: 157, Batch number: 44, Loss: 20236.99609375\n",
      "Epoch: 158, Batch number: 68, Loss: 20014.693359375\n",
      "Epoch: 160, Batch number: 16, Loss: 19828.40625\n",
      "Epoch: 161, Batch number: 40, Loss: 19631.478515625\n",
      "Epoch: 162, Batch number: 64, Loss: 20193.2734375\n",
      "Epoch: 164, Batch number: 12, Loss: 20076.23046875\n",
      "Epoch: 165, Batch number: 36, Loss: 19645.66015625\n",
      "Epoch: 166, Batch number: 60, Loss: 20004.623046875\n",
      "Epoch: 168, Batch number: 8, Loss: 19248.763671875\n",
      "Epoch: 169, Batch number: 32, Loss: 19703.197265625\n",
      "Epoch: 170, Batch number: 56, Loss: 19756.349609375\n",
      "Epoch: 172, Batch number: 4, Loss: 19661.2890625\n",
      "Epoch: 173, Batch number: 28, Loss: 19929.388671875\n",
      "Epoch: 174, Batch number: 52, Loss: 20211.50390625\n",
      "Epoch: 176, Batch number: 0, Loss: 20029.16796875\n",
      "Epoch: 177, Batch number: 24, Loss: 19652.796875\n",
      "Epoch: 178, Batch number: 48, Loss: 20018.337890625\n",
      "Epoch: 179, Batch number: 72, Loss: 20229.8828125\n",
      "Epoch: 181, Batch number: 20, Loss: 19686.310546875\n",
      "Epoch: 182, Batch number: 44, Loss: 19998.99609375\n",
      "Epoch: 183, Batch number: 68, Loss: 20879.3671875\n",
      "Epoch: 185, Batch number: 16, Loss: 19796.1171875\n",
      "Epoch: 186, Batch number: 40, Loss: 19776.333984375\n",
      "Epoch: 187, Batch number: 64, Loss: 19961.080078125\n",
      "Epoch: 189, Batch number: 12, Loss: 19421.671875\n",
      "Epoch: 190, Batch number: 36, Loss: 20146.28125\n",
      "Epoch: 191, Batch number: 60, Loss: 19748.33203125\n",
      "Epoch: 193, Batch number: 8, Loss: 19931.498046875\n",
      "Epoch: 194, Batch number: 32, Loss: 19606.607421875\n",
      "Epoch: 195, Batch number: 56, Loss: 20016.169921875\n",
      "Epoch: 197, Batch number: 4, Loss: 19708.42578125\n",
      "Epoch: 198, Batch number: 28, Loss: 19785.19140625\n",
      "Epoch: 199, Batch number: 52, Loss: 19564.45703125\n",
      "Epoch: 201, Batch number: 0, Loss: 19661.38671875\n",
      "Epoch: 202, Batch number: 24, Loss: 19694.13671875\n",
      "Epoch: 203, Batch number: 48, Loss: 20007.14453125\n",
      "Epoch: 204, Batch number: 72, Loss: 20104.091796875\n",
      "Epoch: 206, Batch number: 20, Loss: 19644.4921875\n",
      "Epoch: 207, Batch number: 44, Loss: 19575.943359375\n",
      "Epoch: 208, Batch number: 68, Loss: 19811.705078125\n",
      "Epoch: 210, Batch number: 16, Loss: 19914.515625\n",
      "Epoch: 211, Batch number: 40, Loss: 20570.12109375\n",
      "Epoch: 212, Batch number: 64, Loss: 19373.2265625\n",
      "Epoch: 214, Batch number: 12, Loss: 19425.263671875\n",
      "Epoch: 215, Batch number: 36, Loss: 19712.52734375\n",
      "Epoch: 216, Batch number: 60, Loss: 20187.865234375\n",
      "Epoch: 218, Batch number: 8, Loss: 19945.5546875\n",
      "Epoch: 219, Batch number: 32, Loss: 19943.2578125\n",
      "Epoch: 220, Batch number: 56, Loss: 20650.55078125\n",
      "Epoch: 222, Batch number: 4, Loss: 19718.18359375\n",
      "Epoch: 223, Batch number: 28, Loss: 19691.2734375\n",
      "Epoch: 224, Batch number: 52, Loss: 19342.939453125\n",
      "Epoch: 226, Batch number: 0, Loss: 19376.712890625\n",
      "Epoch: 227, Batch number: 24, Loss: 20030.35546875\n",
      "Epoch: 228, Batch number: 48, Loss: 20163.744140625\n",
      "Epoch: 229, Batch number: 72, Loss: 20264.203125\n",
      "Epoch: 231, Batch number: 20, Loss: 19842.16015625\n",
      "Epoch: 232, Batch number: 44, Loss: 20249.654296875\n",
      "Epoch: 233, Batch number: 68, Loss: 19559.94921875\n",
      "Epoch: 235, Batch number: 16, Loss: 18964.41015625\n",
      "Epoch: 236, Batch number: 40, Loss: 19611.7734375\n",
      "Epoch: 237, Batch number: 64, Loss: 19550.41015625\n",
      "Epoch: 239, Batch number: 12, Loss: 19258.7734375\n",
      "Epoch: 240, Batch number: 36, Loss: 19453.453125\n",
      "Epoch: 241, Batch number: 60, Loss: 19487.150390625\n",
      "Epoch: 243, Batch number: 8, Loss: 19577.83984375\n",
      "Epoch: 244, Batch number: 32, Loss: 18976.83984375\n",
      "Epoch: 245, Batch number: 56, Loss: 19779.28515625\n",
      "Epoch: 247, Batch number: 4, Loss: 19575.84765625\n",
      "Epoch: 248, Batch number: 28, Loss: 19620.0546875\n",
      "Epoch: 249, Batch number: 52, Loss: 19828.240234375\n",
      "Epoch: 251, Batch number: 0, Loss: 19255.435546875\n",
      "Epoch: 252, Batch number: 24, Loss: 19997.767578125\n",
      "Epoch: 253, Batch number: 48, Loss: 19994.0390625\n",
      "Epoch: 254, Batch number: 72, Loss: 20301.79296875\n",
      "Epoch: 256, Batch number: 20, Loss: 19405.28125\n",
      "Epoch: 257, Batch number: 44, Loss: 19959.2109375\n",
      "Epoch: 258, Batch number: 68, Loss: 20087.568359375\n",
      "Epoch: 260, Batch number: 16, Loss: 19720.236328125\n",
      "Epoch: 261, Batch number: 40, Loss: 20155.095703125\n",
      "Epoch: 262, Batch number: 64, Loss: 19955.64453125\n",
      "Epoch: 264, Batch number: 12, Loss: 19643.876953125\n",
      "Epoch: 265, Batch number: 36, Loss: 20056.390625\n",
      "Epoch: 266, Batch number: 60, Loss: 20332.505859375\n",
      "Epoch: 268, Batch number: 8, Loss: 19572.12109375\n",
      "Epoch: 269, Batch number: 32, Loss: 19389.982421875\n",
      "Epoch: 270, Batch number: 56, Loss: 20077.3359375\n",
      "Epoch: 272, Batch number: 4, Loss: 19763.39453125\n",
      "Epoch: 273, Batch number: 28, Loss: 20001.77734375\n",
      "Epoch: 274, Batch number: 52, Loss: 19964.888671875\n",
      "Epoch: 276, Batch number: 0, Loss: 19558.591796875\n",
      "Epoch: 277, Batch number: 24, Loss: 19454.376953125\n",
      "Epoch: 278, Batch number: 48, Loss: 19808.111328125\n",
      "Epoch: 279, Batch number: 72, Loss: 19576.095703125\n",
      "Epoch: 281, Batch number: 20, Loss: 20038.615234375\n",
      "Epoch: 282, Batch number: 44, Loss: 20098.623046875\n",
      "Epoch: 283, Batch number: 68, Loss: 20058.67578125\n",
      "Epoch: 285, Batch number: 16, Loss: 19702.072265625\n",
      "Epoch: 286, Batch number: 40, Loss: 19991.70703125\n",
      "Epoch: 287, Batch number: 64, Loss: 19773.453125\n",
      "Epoch: 289, Batch number: 12, Loss: 19388.244140625\n",
      "Epoch: 290, Batch number: 36, Loss: 19740.828125\n",
      "Epoch: 291, Batch number: 60, Loss: 20212.88671875\n",
      "Epoch: 293, Batch number: 8, Loss: 19590.10546875\n",
      "Epoch: 294, Batch number: 32, Loss: 19951.49609375\n",
      "Epoch: 295, Batch number: 56, Loss: 19585.423828125\n",
      "Epoch: 297, Batch number: 4, Loss: 19453.828125\n",
      "Epoch: 298, Batch number: 28, Loss: 19523.66796875\n",
      "Epoch: 299, Batch number: 52, Loss: 19535.91015625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 37959.36328125\n",
      "Epoch: 2, Batch number: 24, Loss: 32913.68359375\n",
      "Epoch: 3, Batch number: 48, Loss: 31070.79296875\n",
      "Epoch: 4, Batch number: 72, Loss: 30126.103515625\n",
      "Epoch: 6, Batch number: 20, Loss: 27772.732421875\n",
      "Epoch: 7, Batch number: 44, Loss: 26750.58203125\n",
      "Epoch: 8, Batch number: 68, Loss: 26123.373046875\n",
      "Epoch: 10, Batch number: 16, Loss: 24655.4140625\n",
      "Epoch: 11, Batch number: 40, Loss: 24876.146484375\n",
      "Epoch: 12, Batch number: 64, Loss: 23694.701171875\n",
      "Epoch: 14, Batch number: 12, Loss: 23396.154296875\n",
      "Epoch: 15, Batch number: 36, Loss: 22850.2578125\n",
      "Epoch: 16, Batch number: 60, Loss: 22937.08984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Batch number: 8, Loss: 22343.16796875\n",
      "Epoch: 19, Batch number: 32, Loss: 22157.5390625\n",
      "Epoch: 20, Batch number: 56, Loss: 22202.634765625\n",
      "Epoch: 22, Batch number: 4, Loss: 21854.765625\n",
      "Epoch: 23, Batch number: 28, Loss: 21674.484375\n",
      "Epoch: 24, Batch number: 52, Loss: 21993.041015625\n",
      "Epoch: 26, Batch number: 0, Loss: 21651.61328125\n",
      "Epoch: 27, Batch number: 24, Loss: 21211.755859375\n",
      "Epoch: 28, Batch number: 48, Loss: 21115.181640625\n",
      "Epoch: 29, Batch number: 72, Loss: 21740.8515625\n",
      "Epoch: 31, Batch number: 20, Loss: 21367.24609375\n",
      "Epoch: 32, Batch number: 44, Loss: 20975.45703125\n",
      "Epoch: 33, Batch number: 68, Loss: 21570.693359375\n",
      "Epoch: 35, Batch number: 16, Loss: 21077.638671875\n",
      "Epoch: 36, Batch number: 40, Loss: 21029.423828125\n",
      "Epoch: 37, Batch number: 64, Loss: 21521.427734375\n",
      "Epoch: 39, Batch number: 12, Loss: 20976.2421875\n",
      "Epoch: 40, Batch number: 36, Loss: 20533.021484375\n",
      "Epoch: 41, Batch number: 60, Loss: 21356.400390625\n",
      "Epoch: 43, Batch number: 8, Loss: 20638.86328125\n",
      "Epoch: 44, Batch number: 32, Loss: 20916.341796875\n",
      "Epoch: 45, Batch number: 56, Loss: 20786.017578125\n",
      "Epoch: 47, Batch number: 4, Loss: 20727.4921875\n",
      "Epoch: 48, Batch number: 28, Loss: 20493.517578125\n",
      "Epoch: 49, Batch number: 52, Loss: 20579.271484375\n",
      "Epoch: 51, Batch number: 0, Loss: 20451.853515625\n",
      "Epoch: 52, Batch number: 24, Loss: 20782.875\n",
      "Epoch: 53, Batch number: 48, Loss: 21129.3828125\n",
      "Epoch: 54, Batch number: 72, Loss: 20790.435546875\n",
      "Epoch: 56, Batch number: 20, Loss: 20841.013671875\n",
      "Epoch: 57, Batch number: 44, Loss: 20420.07421875\n",
      "Epoch: 58, Batch number: 68, Loss: 20790.96484375\n",
      "Epoch: 60, Batch number: 16, Loss: 20087.697265625\n",
      "Epoch: 61, Batch number: 40, Loss: 20380.884765625\n",
      "Epoch: 62, Batch number: 64, Loss: 20777.80859375\n",
      "Epoch: 64, Batch number: 12, Loss: 20630.93359375\n",
      "Epoch: 65, Batch number: 36, Loss: 20203.794921875\n",
      "Epoch: 66, Batch number: 60, Loss: 19996.267578125\n",
      "Epoch: 68, Batch number: 8, Loss: 20422.732421875\n",
      "Epoch: 69, Batch number: 32, Loss: 20241.064453125\n",
      "Epoch: 70, Batch number: 56, Loss: 20147.341796875\n",
      "Epoch: 72, Batch number: 4, Loss: 20591.6796875\n",
      "Epoch: 73, Batch number: 28, Loss: 20092.720703125\n",
      "Epoch: 74, Batch number: 52, Loss: 21090.4765625\n",
      "Epoch: 76, Batch number: 0, Loss: 19709.44140625\n",
      "Epoch: 77, Batch number: 24, Loss: 20220.37109375\n",
      "Epoch: 78, Batch number: 48, Loss: 20582.037109375\n",
      "Epoch: 79, Batch number: 72, Loss: 20215.939453125\n",
      "Epoch: 81, Batch number: 20, Loss: 20242.828125\n",
      "Epoch: 82, Batch number: 44, Loss: 20562.10546875\n",
      "Epoch: 83, Batch number: 68, Loss: 20272.541015625\n",
      "Epoch: 85, Batch number: 16, Loss: 19682.74609375\n",
      "Epoch: 86, Batch number: 40, Loss: 19931.23828125\n",
      "Epoch: 87, Batch number: 64, Loss: 20524.8984375\n",
      "Epoch: 89, Batch number: 12, Loss: 20416.587890625\n",
      "Epoch: 90, Batch number: 36, Loss: 20557.615234375\n",
      "Epoch: 91, Batch number: 60, Loss: 20538.12890625\n",
      "Epoch: 93, Batch number: 8, Loss: 20043.328125\n",
      "Epoch: 94, Batch number: 32, Loss: 20580.857421875\n",
      "Epoch: 95, Batch number: 56, Loss: 20560.8359375\n",
      "Epoch: 97, Batch number: 4, Loss: 19972.990234375\n",
      "Epoch: 98, Batch number: 28, Loss: 20220.1640625\n",
      "Epoch: 99, Batch number: 52, Loss: 20118.8515625\n",
      "Epoch: 101, Batch number: 0, Loss: 19848.478515625\n",
      "Epoch: 102, Batch number: 24, Loss: 19644.55859375\n",
      "Epoch: 103, Batch number: 48, Loss: 20089.126953125\n",
      "Epoch: 104, Batch number: 72, Loss: 20109.0546875\n",
      "Epoch: 106, Batch number: 20, Loss: 19964.501953125\n",
      "Epoch: 107, Batch number: 44, Loss: 20568.6875\n",
      "Epoch: 108, Batch number: 68, Loss: 20725.001953125\n",
      "Epoch: 110, Batch number: 16, Loss: 19879.568359375\n",
      "Epoch: 111, Batch number: 40, Loss: 20104.484375\n",
      "Epoch: 112, Batch number: 64, Loss: 20267.77734375\n",
      "Epoch: 114, Batch number: 12, Loss: 19892.37109375\n",
      "Epoch: 115, Batch number: 36, Loss: 19876.939453125\n",
      "Epoch: 116, Batch number: 60, Loss: 20284.296875\n",
      "Epoch: 118, Batch number: 8, Loss: 19660.662109375\n",
      "Epoch: 119, Batch number: 32, Loss: 19733.486328125\n",
      "Epoch: 120, Batch number: 56, Loss: 20096.0859375\n",
      "Epoch: 122, Batch number: 4, Loss: 19793.857421875\n",
      "Epoch: 123, Batch number: 28, Loss: 20313.1640625\n",
      "Epoch: 124, Batch number: 52, Loss: 19872.04296875\n",
      "Epoch: 126, Batch number: 0, Loss: 19907.765625\n",
      "Epoch: 127, Batch number: 24, Loss: 20261.552734375\n",
      "Epoch: 128, Batch number: 48, Loss: 20018.271484375\n",
      "Epoch: 129, Batch number: 72, Loss: 20122.0625\n",
      "Epoch: 131, Batch number: 20, Loss: 19847.630859375\n",
      "Epoch: 132, Batch number: 44, Loss: 20316.361328125\n",
      "Epoch: 133, Batch number: 68, Loss: 20735.828125\n",
      "Epoch: 135, Batch number: 16, Loss: 20077.267578125\n",
      "Epoch: 136, Batch number: 40, Loss: 20217.306640625\n",
      "Epoch: 137, Batch number: 64, Loss: 20132.14453125\n",
      "Epoch: 139, Batch number: 12, Loss: 19779.412109375\n",
      "Epoch: 140, Batch number: 36, Loss: 19698.298828125\n",
      "Epoch: 141, Batch number: 60, Loss: 20215.3359375\n",
      "Epoch: 143, Batch number: 8, Loss: 20217.33984375\n",
      "Epoch: 144, Batch number: 32, Loss: 19282.3984375\n",
      "Epoch: 145, Batch number: 56, Loss: 19777.671875\n",
      "Epoch: 147, Batch number: 4, Loss: 19933.322265625\n",
      "Epoch: 148, Batch number: 28, Loss: 19494.2421875\n",
      "Epoch: 149, Batch number: 52, Loss: 19691.23046875\n",
      "Epoch: 151, Batch number: 0, Loss: 19199.11328125\n",
      "Epoch: 152, Batch number: 24, Loss: 20060.056640625\n",
      "Epoch: 153, Batch number: 48, Loss: 20139.708984375\n",
      "Epoch: 154, Batch number: 72, Loss: 19835.392578125\n",
      "Epoch: 156, Batch number: 20, Loss: 19842.07421875\n",
      "Epoch: 157, Batch number: 44, Loss: 20201.76953125\n",
      "Epoch: 158, Batch number: 68, Loss: 19955.587890625\n",
      "Epoch: 160, Batch number: 16, Loss: 19900.046875\n",
      "Epoch: 161, Batch number: 40, Loss: 19925.21484375\n",
      "Epoch: 162, Batch number: 64, Loss: 20006.013671875\n",
      "Epoch: 164, Batch number: 12, Loss: 19656.697265625\n",
      "Epoch: 165, Batch number: 36, Loss: 20191.93359375\n",
      "Epoch: 166, Batch number: 60, Loss: 20057.814453125\n",
      "Epoch: 168, Batch number: 8, Loss: 19720.353515625\n",
      "Epoch: 169, Batch number: 32, Loss: 20380.71484375\n",
      "Epoch: 170, Batch number: 56, Loss: 20060.71484375\n",
      "Epoch: 172, Batch number: 4, Loss: 20062.0703125\n",
      "Epoch: 173, Batch number: 28, Loss: 19541.794921875\n",
      "Epoch: 174, Batch number: 52, Loss: 20270.69921875\n",
      "Epoch: 176, Batch number: 0, Loss: 19714.595703125\n",
      "Epoch: 177, Batch number: 24, Loss: 19432.6953125\n",
      "Epoch: 178, Batch number: 48, Loss: 19940.125\n",
      "Epoch: 179, Batch number: 72, Loss: 20185.970703125\n",
      "Epoch: 181, Batch number: 20, Loss: 19720.748046875\n",
      "Epoch: 182, Batch number: 44, Loss: 20148.140625\n",
      "Epoch: 183, Batch number: 68, Loss: 20273.916015625\n",
      "Epoch: 185, Batch number: 16, Loss: 20146.015625\n",
      "Epoch: 186, Batch number: 40, Loss: 19584.60546875\n",
      "Epoch: 187, Batch number: 64, Loss: 19902.115234375\n",
      "Epoch: 189, Batch number: 12, Loss: 20090.08984375\n",
      "Epoch: 190, Batch number: 36, Loss: 19580.900390625\n",
      "Epoch: 191, Batch number: 60, Loss: 19858.55859375\n",
      "Epoch: 193, Batch number: 8, Loss: 19343.583984375\n",
      "Epoch: 194, Batch number: 32, Loss: 19784.357421875\n",
      "Epoch: 195, Batch number: 56, Loss: 20533.880859375\n",
      "Epoch: 197, Batch number: 4, Loss: 19523.7109375\n",
      "Epoch: 198, Batch number: 28, Loss: 19726.96484375\n",
      "Epoch: 199, Batch number: 52, Loss: 19643.1953125\n",
      "Epoch: 201, Batch number: 0, Loss: 18995.208984375\n",
      "Epoch: 202, Batch number: 24, Loss: 19952.412109375\n",
      "Epoch: 203, Batch number: 48, Loss: 20728.125\n",
      "Epoch: 204, Batch number: 72, Loss: 19788.2265625\n",
      "Epoch: 206, Batch number: 20, Loss: 19092.884765625\n",
      "Epoch: 207, Batch number: 44, Loss: 19914.583984375\n",
      "Epoch: 208, Batch number: 68, Loss: 19572.8046875\n",
      "Epoch: 210, Batch number: 16, Loss: 19721.34375\n",
      "Epoch: 211, Batch number: 40, Loss: 19933.927734375\n",
      "Epoch: 212, Batch number: 64, Loss: 20434.1328125\n",
      "Epoch: 214, Batch number: 12, Loss: 19707.201171875\n",
      "Epoch: 215, Batch number: 36, Loss: 20032.482421875\n",
      "Epoch: 216, Batch number: 60, Loss: 20215.9296875\n",
      "Epoch: 218, Batch number: 8, Loss: 19834.7578125\n",
      "Epoch: 219, Batch number: 32, Loss: 20435.609375\n",
      "Epoch: 220, Batch number: 56, Loss: 19531.994140625\n",
      "Epoch: 222, Batch number: 4, Loss: 19697.173828125\n",
      "Epoch: 223, Batch number: 28, Loss: 19790.20703125\n",
      "Epoch: 224, Batch number: 52, Loss: 19889.451171875\n",
      "Epoch: 226, Batch number: 0, Loss: 19540.83984375\n",
      "Epoch: 227, Batch number: 24, Loss: 19383.484375\n",
      "Epoch: 228, Batch number: 48, Loss: 19867.380859375\n",
      "Epoch: 229, Batch number: 72, Loss: 20201.130859375\n",
      "Epoch: 231, Batch number: 20, Loss: 19965.083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 232, Batch number: 44, Loss: 20328.791015625\n",
      "Epoch: 233, Batch number: 68, Loss: 20293.548828125\n",
      "Epoch: 235, Batch number: 16, Loss: 19388.6875\n",
      "Epoch: 236, Batch number: 40, Loss: 19899.53515625\n",
      "Epoch: 237, Batch number: 64, Loss: 19931.130859375\n",
      "Epoch: 239, Batch number: 12, Loss: 19173.375\n",
      "Epoch: 240, Batch number: 36, Loss: 19737.658203125\n",
      "Epoch: 241, Batch number: 60, Loss: 19790.890625\n",
      "Epoch: 243, Batch number: 8, Loss: 20028.712890625\n",
      "Epoch: 244, Batch number: 32, Loss: 20048.443359375\n",
      "Epoch: 245, Batch number: 56, Loss: 20340.439453125\n",
      "Epoch: 247, Batch number: 4, Loss: 19673.58984375\n",
      "Epoch: 248, Batch number: 28, Loss: 19828.443359375\n",
      "Epoch: 249, Batch number: 52, Loss: 19615.076171875\n",
      "Epoch: 251, Batch number: 0, Loss: 19281.939453125\n",
      "Epoch: 252, Batch number: 24, Loss: 19468.96875\n",
      "Epoch: 253, Batch number: 48, Loss: 19898.171875\n",
      "Epoch: 254, Batch number: 72, Loss: 20092.009765625\n",
      "Epoch: 256, Batch number: 20, Loss: 19851.591796875\n",
      "Epoch: 257, Batch number: 44, Loss: 19854.654296875\n",
      "Epoch: 258, Batch number: 68, Loss: 20101.970703125\n",
      "Epoch: 260, Batch number: 16, Loss: 19719.458984375\n",
      "Epoch: 261, Batch number: 40, Loss: 19850.6796875\n",
      "Epoch: 262, Batch number: 64, Loss: 20101.048828125\n",
      "Epoch: 264, Batch number: 12, Loss: 19957.263671875\n",
      "Epoch: 265, Batch number: 36, Loss: 20036.203125\n",
      "Epoch: 266, Batch number: 60, Loss: 19474.142578125\n",
      "Epoch: 268, Batch number: 8, Loss: 19781.37890625\n",
      "Epoch: 269, Batch number: 32, Loss: 19951.349609375\n",
      "Epoch: 270, Batch number: 56, Loss: 19948.40625\n",
      "Epoch: 272, Batch number: 4, Loss: 19670.525390625\n",
      "Epoch: 273, Batch number: 28, Loss: 19602.44140625\n",
      "Epoch: 274, Batch number: 52, Loss: 20176.837890625\n",
      "Epoch: 276, Batch number: 0, Loss: 19400.8359375\n",
      "Epoch: 277, Batch number: 24, Loss: 20259.0078125\n",
      "Epoch: 278, Batch number: 48, Loss: 19998.34765625\n",
      "Epoch: 279, Batch number: 72, Loss: 19718.291015625\n",
      "Epoch: 281, Batch number: 20, Loss: 19560.857421875\n",
      "Epoch: 282, Batch number: 44, Loss: 19441.84375\n",
      "Epoch: 283, Batch number: 68, Loss: 19832.013671875\n",
      "Epoch: 285, Batch number: 16, Loss: 19891.060546875\n",
      "Epoch: 286, Batch number: 40, Loss: 20141.185546875\n",
      "Epoch: 287, Batch number: 64, Loss: 19861.65625\n",
      "Epoch: 289, Batch number: 12, Loss: 19657.8203125\n",
      "Epoch: 290, Batch number: 36, Loss: 19446.3515625\n",
      "Epoch: 291, Batch number: 60, Loss: 20698.392578125\n",
      "Epoch: 293, Batch number: 8, Loss: 19710.08984375\n",
      "Epoch: 294, Batch number: 32, Loss: 19716.3359375\n",
      "Epoch: 295, Batch number: 56, Loss: 19201.22265625\n",
      "Epoch: 297, Batch number: 4, Loss: 19690.248046875\n",
      "Epoch: 298, Batch number: 28, Loss: 19116.6875\n",
      "Epoch: 299, Batch number: 52, Loss: 20158.42578125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 39937.15234375\n",
      "Epoch: 2, Batch number: 24, Loss: 38667.2734375\n",
      "Epoch: 3, Batch number: 48, Loss: 37551.91796875\n",
      "Epoch: 4, Batch number: 72, Loss: 35948.4921875\n",
      "Epoch: 6, Batch number: 20, Loss: 33847.3671875\n",
      "Epoch: 7, Batch number: 44, Loss: 33203.05859375\n",
      "Epoch: 8, Batch number: 68, Loss: 32544.095703125\n",
      "Epoch: 10, Batch number: 16, Loss: 31345.466796875\n",
      "Epoch: 11, Batch number: 40, Loss: 31092.0859375\n",
      "Epoch: 12, Batch number: 64, Loss: 29979.244140625\n",
      "Epoch: 14, Batch number: 12, Loss: 29853.90625\n",
      "Epoch: 15, Batch number: 36, Loss: 29723.6953125\n",
      "Epoch: 16, Batch number: 60, Loss: 29414.142578125\n",
      "Epoch: 18, Batch number: 8, Loss: 29164.28515625\n",
      "Epoch: 19, Batch number: 32, Loss: 28581.71875\n",
      "Epoch: 20, Batch number: 56, Loss: 28415.712890625\n",
      "Epoch: 22, Batch number: 4, Loss: 28347.875\n",
      "Epoch: 23, Batch number: 28, Loss: 28037.93359375\n",
      "Epoch: 24, Batch number: 52, Loss: 27800.033203125\n",
      "Epoch: 26, Batch number: 0, Loss: 27400.63671875\n",
      "Epoch: 27, Batch number: 24, Loss: 27700.501953125\n",
      "Epoch: 28, Batch number: 48, Loss: 27546.1953125\n",
      "Epoch: 29, Batch number: 72, Loss: 27277.78515625\n",
      "Epoch: 31, Batch number: 20, Loss: 26891.21484375\n",
      "Epoch: 32, Batch number: 44, Loss: 27603.080078125\n",
      "Epoch: 33, Batch number: 68, Loss: 27131.353515625\n",
      "Epoch: 35, Batch number: 16, Loss: 27075.849609375\n",
      "Epoch: 36, Batch number: 40, Loss: 26865.314453125\n",
      "Epoch: 37, Batch number: 64, Loss: 26474.603515625\n",
      "Epoch: 39, Batch number: 12, Loss: 26803.56640625\n",
      "Epoch: 40, Batch number: 36, Loss: 26431.083984375\n",
      "Epoch: 41, Batch number: 60, Loss: 26303.5546875\n",
      "Epoch: 43, Batch number: 8, Loss: 26185.158203125\n",
      "Epoch: 44, Batch number: 32, Loss: 26492.90625\n",
      "Epoch: 45, Batch number: 56, Loss: 26354.0\n",
      "Epoch: 47, Batch number: 4, Loss: 26106.94921875\n",
      "Epoch: 48, Batch number: 28, Loss: 26224.431640625\n",
      "Epoch: 49, Batch number: 52, Loss: 26204.087890625\n",
      "Epoch: 51, Batch number: 0, Loss: 26108.7734375\n",
      "Epoch: 52, Batch number: 24, Loss: 25627.29296875\n",
      "Epoch: 53, Batch number: 48, Loss: 26378.025390625\n",
      "Epoch: 54, Batch number: 72, Loss: 25728.71484375\n",
      "Epoch: 56, Batch number: 20, Loss: 26020.470703125\n",
      "Epoch: 57, Batch number: 44, Loss: 25782.216796875\n",
      "Epoch: 58, Batch number: 68, Loss: 25923.61328125\n",
      "Epoch: 60, Batch number: 16, Loss: 25807.318359375\n",
      "Epoch: 61, Batch number: 40, Loss: 25846.203125\n",
      "Epoch: 62, Batch number: 64, Loss: 25397.720703125\n",
      "Epoch: 64, Batch number: 12, Loss: 25734.72265625\n",
      "Epoch: 65, Batch number: 36, Loss: 25547.208984375\n",
      "Epoch: 66, Batch number: 60, Loss: 25808.490234375\n",
      "Epoch: 68, Batch number: 8, Loss: 25208.9609375\n",
      "Epoch: 69, Batch number: 32, Loss: 25403.939453125\n",
      "Epoch: 70, Batch number: 56, Loss: 25269.42578125\n",
      "Epoch: 72, Batch number: 4, Loss: 25237.10546875\n",
      "Epoch: 73, Batch number: 28, Loss: 25511.822265625\n",
      "Epoch: 74, Batch number: 52, Loss: 25171.380859375\n",
      "Epoch: 76, Batch number: 0, Loss: 25192.115234375\n",
      "Epoch: 77, Batch number: 24, Loss: 25204.330078125\n",
      "Epoch: 78, Batch number: 48, Loss: 25538.69921875\n",
      "Epoch: 79, Batch number: 72, Loss: 24827.396484375\n",
      "Epoch: 81, Batch number: 20, Loss: 25092.9140625\n",
      "Epoch: 82, Batch number: 44, Loss: 24850.677734375\n",
      "Epoch: 83, Batch number: 68, Loss: 25354.1171875\n",
      "Epoch: 85, Batch number: 16, Loss: 25080.955078125\n",
      "Epoch: 86, Batch number: 40, Loss: 25079.814453125\n",
      "Epoch: 87, Batch number: 64, Loss: 24851.376953125\n",
      "Epoch: 89, Batch number: 12, Loss: 24775.44921875\n",
      "Epoch: 90, Batch number: 36, Loss: 24963.474609375\n",
      "Epoch: 91, Batch number: 60, Loss: 24985.892578125\n",
      "Epoch: 93, Batch number: 8, Loss: 24762.77734375\n",
      "Epoch: 94, Batch number: 32, Loss: 24889.939453125\n",
      "Epoch: 95, Batch number: 56, Loss: 24855.8671875\n",
      "Epoch: 97, Batch number: 4, Loss: 25071.01953125\n",
      "Epoch: 98, Batch number: 28, Loss: 24962.201171875\n",
      "Epoch: 99, Batch number: 52, Loss: 25030.34375\n",
      "Epoch: 101, Batch number: 0, Loss: 24633.25\n",
      "Epoch: 102, Batch number: 24, Loss: 24669.986328125\n",
      "Epoch: 103, Batch number: 48, Loss: 24458.611328125\n",
      "Epoch: 104, Batch number: 72, Loss: 24507.48046875\n",
      "Epoch: 106, Batch number: 20, Loss: 24980.865234375\n",
      "Epoch: 107, Batch number: 44, Loss: 24539.396484375\n",
      "Epoch: 108, Batch number: 68, Loss: 24523.541015625\n",
      "Epoch: 110, Batch number: 16, Loss: 24210.009765625\n",
      "Epoch: 111, Batch number: 40, Loss: 24087.474609375\n",
      "Epoch: 112, Batch number: 64, Loss: 24714.19140625\n",
      "Epoch: 114, Batch number: 12, Loss: 24476.314453125\n",
      "Epoch: 115, Batch number: 36, Loss: 24347.740234375\n",
      "Epoch: 116, Batch number: 60, Loss: 24603.044921875\n",
      "Epoch: 118, Batch number: 8, Loss: 24114.94140625\n",
      "Epoch: 119, Batch number: 32, Loss: 24601.82421875\n",
      "Epoch: 120, Batch number: 56, Loss: 24185.08984375\n",
      "Epoch: 122, Batch number: 4, Loss: 24437.0703125\n",
      "Epoch: 123, Batch number: 28, Loss: 23984.970703125\n",
      "Epoch: 124, Batch number: 52, Loss: 24569.3828125\n",
      "Epoch: 126, Batch number: 0, Loss: 23687.01171875\n",
      "Epoch: 127, Batch number: 24, Loss: 24101.029296875\n",
      "Epoch: 128, Batch number: 48, Loss: 24583.310546875\n",
      "Epoch: 129, Batch number: 72, Loss: 24107.51953125\n",
      "Epoch: 131, Batch number: 20, Loss: 24000.8359375\n",
      "Epoch: 132, Batch number: 44, Loss: 24065.509765625\n",
      "Epoch: 133, Batch number: 68, Loss: 23943.380859375\n",
      "Epoch: 135, Batch number: 16, Loss: 24042.84375\n",
      "Epoch: 136, Batch number: 40, Loss: 24393.34375\n",
      "Epoch: 137, Batch number: 64, Loss: 24132.33203125\n",
      "Epoch: 139, Batch number: 12, Loss: 24177.8359375\n",
      "Epoch: 140, Batch number: 36, Loss: 23585.787109375\n",
      "Epoch: 141, Batch number: 60, Loss: 24155.919921875\n",
      "Epoch: 143, Batch number: 8, Loss: 23670.806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144, Batch number: 32, Loss: 23623.9296875\n",
      "Epoch: 145, Batch number: 56, Loss: 23640.20703125\n",
      "Epoch: 147, Batch number: 4, Loss: 23783.99609375\n",
      "Epoch: 148, Batch number: 28, Loss: 23683.619140625\n",
      "Epoch: 149, Batch number: 52, Loss: 23360.048828125\n",
      "Epoch: 151, Batch number: 0, Loss: 23499.58203125\n",
      "Epoch: 152, Batch number: 24, Loss: 23295.6640625\n",
      "Epoch: 153, Batch number: 48, Loss: 23933.822265625\n",
      "Epoch: 154, Batch number: 72, Loss: 24230.853515625\n",
      "Epoch: 156, Batch number: 20, Loss: 23446.8125\n",
      "Epoch: 157, Batch number: 44, Loss: 23715.72265625\n",
      "Epoch: 158, Batch number: 68, Loss: 23503.625\n",
      "Epoch: 160, Batch number: 16, Loss: 23703.5\n",
      "Epoch: 161, Batch number: 40, Loss: 23775.638671875\n",
      "Epoch: 162, Batch number: 64, Loss: 23651.4609375\n",
      "Epoch: 164, Batch number: 12, Loss: 23187.90234375\n",
      "Epoch: 165, Batch number: 36, Loss: 23531.0\n",
      "Epoch: 166, Batch number: 60, Loss: 23582.240234375\n",
      "Epoch: 168, Batch number: 8, Loss: 23531.8828125\n",
      "Epoch: 169, Batch number: 32, Loss: 23316.630859375\n",
      "Epoch: 170, Batch number: 56, Loss: 23146.76171875\n",
      "Epoch: 172, Batch number: 4, Loss: 23684.857421875\n",
      "Epoch: 173, Batch number: 28, Loss: 23701.095703125\n",
      "Epoch: 174, Batch number: 52, Loss: 23422.9921875\n",
      "Epoch: 176, Batch number: 0, Loss: 23413.865234375\n",
      "Epoch: 177, Batch number: 24, Loss: 23123.177734375\n",
      "Epoch: 178, Batch number: 48, Loss: 23061.775390625\n",
      "Epoch: 179, Batch number: 72, Loss: 23124.83203125\n",
      "Epoch: 181, Batch number: 20, Loss: 23452.216796875\n",
      "Epoch: 182, Batch number: 44, Loss: 22661.943359375\n",
      "Epoch: 183, Batch number: 68, Loss: 23386.76171875\n",
      "Epoch: 185, Batch number: 16, Loss: 23317.689453125\n",
      "Epoch: 186, Batch number: 40, Loss: 23242.28515625\n",
      "Epoch: 187, Batch number: 64, Loss: 23422.0859375\n",
      "Epoch: 189, Batch number: 12, Loss: 23528.40234375\n",
      "Epoch: 190, Batch number: 36, Loss: 23239.923828125\n",
      "Epoch: 191, Batch number: 60, Loss: 22779.4140625\n",
      "Epoch: 193, Batch number: 8, Loss: 22830.177734375\n",
      "Epoch: 194, Batch number: 32, Loss: 22621.85546875\n",
      "Epoch: 195, Batch number: 56, Loss: 22779.53515625\n",
      "Epoch: 197, Batch number: 4, Loss: 22724.150390625\n",
      "Epoch: 198, Batch number: 28, Loss: 23083.00390625\n",
      "Epoch: 199, Batch number: 52, Loss: 23280.517578125\n",
      "Epoch: 201, Batch number: 0, Loss: 23148.9921875\n",
      "Epoch: 202, Batch number: 24, Loss: 23153.330078125\n",
      "Epoch: 203, Batch number: 48, Loss: 22602.19921875\n",
      "Epoch: 204, Batch number: 72, Loss: 22919.98046875\n",
      "Epoch: 206, Batch number: 20, Loss: 23471.859375\n",
      "Epoch: 207, Batch number: 44, Loss: 22915.3125\n",
      "Epoch: 208, Batch number: 68, Loss: 23119.57421875\n",
      "Epoch: 210, Batch number: 16, Loss: 22914.96875\n",
      "Epoch: 211, Batch number: 40, Loss: 23328.61328125\n",
      "Epoch: 212, Batch number: 64, Loss: 22572.75\n",
      "Epoch: 214, Batch number: 12, Loss: 22539.677734375\n",
      "Epoch: 215, Batch number: 36, Loss: 22694.814453125\n",
      "Epoch: 216, Batch number: 60, Loss: 23268.384765625\n",
      "Epoch: 218, Batch number: 8, Loss: 23075.423828125\n",
      "Epoch: 219, Batch number: 32, Loss: 22945.09765625\n",
      "Epoch: 220, Batch number: 56, Loss: 22654.11328125\n",
      "Epoch: 222, Batch number: 4, Loss: 22793.693359375\n",
      "Epoch: 223, Batch number: 28, Loss: 22803.767578125\n",
      "Epoch: 224, Batch number: 52, Loss: 22825.822265625\n",
      "Epoch: 226, Batch number: 0, Loss: 23154.1015625\n",
      "Epoch: 227, Batch number: 24, Loss: 22883.802734375\n",
      "Epoch: 228, Batch number: 48, Loss: 23187.47265625\n",
      "Epoch: 229, Batch number: 72, Loss: 22746.92578125\n",
      "Epoch: 231, Batch number: 20, Loss: 22571.759765625\n",
      "Epoch: 232, Batch number: 44, Loss: 23069.294921875\n",
      "Epoch: 233, Batch number: 68, Loss: 22488.265625\n",
      "Epoch: 235, Batch number: 16, Loss: 23298.96875\n",
      "Epoch: 236, Batch number: 40, Loss: 22488.515625\n",
      "Epoch: 237, Batch number: 64, Loss: 22957.97265625\n",
      "Epoch: 239, Batch number: 12, Loss: 22120.638671875\n",
      "Epoch: 240, Batch number: 36, Loss: 22708.080078125\n",
      "Epoch: 241, Batch number: 60, Loss: 22959.466796875\n",
      "Epoch: 243, Batch number: 8, Loss: 22673.884765625\n",
      "Epoch: 244, Batch number: 32, Loss: 22958.642578125\n",
      "Epoch: 245, Batch number: 56, Loss: 23110.998046875\n",
      "Epoch: 247, Batch number: 4, Loss: 22457.787109375\n",
      "Epoch: 248, Batch number: 28, Loss: 22773.375\n",
      "Epoch: 249, Batch number: 52, Loss: 22501.013671875\n",
      "Epoch: 251, Batch number: 0, Loss: 22817.38671875\n",
      "Epoch: 252, Batch number: 24, Loss: 22721.130859375\n",
      "Epoch: 253, Batch number: 48, Loss: 22544.48828125\n",
      "Epoch: 254, Batch number: 72, Loss: 22886.705078125\n",
      "Epoch: 256, Batch number: 20, Loss: 23296.75\n",
      "Epoch: 257, Batch number: 44, Loss: 23025.521484375\n",
      "Epoch: 258, Batch number: 68, Loss: 23047.677734375\n",
      "Epoch: 260, Batch number: 16, Loss: 22161.08984375\n",
      "Epoch: 261, Batch number: 40, Loss: 22762.96875\n",
      "Epoch: 262, Batch number: 64, Loss: 22439.982421875\n",
      "Epoch: 264, Batch number: 12, Loss: 22745.140625\n",
      "Epoch: 265, Batch number: 36, Loss: 22668.2890625\n",
      "Epoch: 266, Batch number: 60, Loss: 22019.2890625\n",
      "Epoch: 268, Batch number: 8, Loss: 22264.46875\n",
      "Epoch: 269, Batch number: 32, Loss: 22611.76171875\n",
      "Epoch: 270, Batch number: 56, Loss: 22577.8828125\n",
      "Epoch: 272, Batch number: 4, Loss: 23028.1796875\n",
      "Epoch: 273, Batch number: 28, Loss: 22212.255859375\n",
      "Epoch: 274, Batch number: 52, Loss: 22415.53515625\n",
      "Epoch: 276, Batch number: 0, Loss: 22763.810546875\n",
      "Epoch: 277, Batch number: 24, Loss: 22524.3046875\n",
      "Epoch: 278, Batch number: 48, Loss: 22373.359375\n",
      "Epoch: 279, Batch number: 72, Loss: 22111.20703125\n",
      "Epoch: 281, Batch number: 20, Loss: 22523.9609375\n",
      "Epoch: 282, Batch number: 44, Loss: 22412.705078125\n",
      "Epoch: 283, Batch number: 68, Loss: 22495.6875\n",
      "Epoch: 285, Batch number: 16, Loss: 22857.583984375\n",
      "Epoch: 286, Batch number: 40, Loss: 22154.15234375\n",
      "Epoch: 287, Batch number: 64, Loss: 22291.130859375\n",
      "Epoch: 289, Batch number: 12, Loss: 22064.29296875\n",
      "Epoch: 290, Batch number: 36, Loss: 22510.09375\n",
      "Epoch: 291, Batch number: 60, Loss: 22237.150390625\n",
      "Epoch: 293, Batch number: 8, Loss: 22696.111328125\n",
      "Epoch: 294, Batch number: 32, Loss: 22506.107421875\n",
      "Epoch: 295, Batch number: 56, Loss: 22405.55078125\n",
      "Epoch: 297, Batch number: 4, Loss: 22569.822265625\n",
      "Epoch: 298, Batch number: 28, Loss: 22452.7734375\n",
      "Epoch: 299, Batch number: 52, Loss: 22727.75\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 39772.6171875\n",
      "Epoch: 2, Batch number: 24, Loss: 38308.58984375\n",
      "Epoch: 3, Batch number: 48, Loss: 36482.4140625\n",
      "Epoch: 4, Batch number: 72, Loss: 34019.74609375\n",
      "Epoch: 6, Batch number: 20, Loss: 33540.4921875\n",
      "Epoch: 7, Batch number: 44, Loss: 31671.3125\n",
      "Epoch: 8, Batch number: 68, Loss: 31105.732421875\n",
      "Epoch: 10, Batch number: 16, Loss: 30655.18359375\n",
      "Epoch: 11, Batch number: 40, Loss: 29675.884765625\n",
      "Epoch: 12, Batch number: 64, Loss: 28533.150390625\n",
      "Epoch: 14, Batch number: 12, Loss: 28512.369140625\n",
      "Epoch: 15, Batch number: 36, Loss: 28168.4296875\n",
      "Epoch: 16, Batch number: 60, Loss: 27661.08203125\n",
      "Epoch: 18, Batch number: 8, Loss: 27286.95703125\n",
      "Epoch: 19, Batch number: 32, Loss: 27102.0546875\n",
      "Epoch: 20, Batch number: 56, Loss: 26808.0390625\n",
      "Epoch: 22, Batch number: 4, Loss: 26742.685546875\n",
      "Epoch: 23, Batch number: 28, Loss: 26734.08984375\n",
      "Epoch: 24, Batch number: 52, Loss: 26344.189453125\n",
      "Epoch: 26, Batch number: 0, Loss: 26047.99609375\n",
      "Epoch: 27, Batch number: 24, Loss: 25926.1484375\n",
      "Epoch: 28, Batch number: 48, Loss: 26188.3671875\n",
      "Epoch: 29, Batch number: 72, Loss: 25703.140625\n",
      "Epoch: 31, Batch number: 20, Loss: 25384.2578125\n",
      "Epoch: 32, Batch number: 44, Loss: 25463.921875\n",
      "Epoch: 33, Batch number: 68, Loss: 25141.95703125\n",
      "Epoch: 35, Batch number: 16, Loss: 25457.982421875\n",
      "Epoch: 36, Batch number: 40, Loss: 25709.017578125\n",
      "Epoch: 37, Batch number: 64, Loss: 24599.3984375\n",
      "Epoch: 39, Batch number: 12, Loss: 25179.703125\n",
      "Epoch: 40, Batch number: 36, Loss: 25097.177734375\n",
      "Epoch: 41, Batch number: 60, Loss: 24593.705078125\n",
      "Epoch: 43, Batch number: 8, Loss: 24629.748046875\n",
      "Epoch: 44, Batch number: 32, Loss: 25117.96484375\n",
      "Epoch: 45, Batch number: 56, Loss: 25061.25390625\n",
      "Epoch: 47, Batch number: 4, Loss: 24201.576171875\n",
      "Epoch: 48, Batch number: 28, Loss: 24695.859375\n",
      "Epoch: 49, Batch number: 52, Loss: 24491.1875\n",
      "Epoch: 51, Batch number: 0, Loss: 24526.12890625\n",
      "Epoch: 52, Batch number: 24, Loss: 24342.28515625\n",
      "Epoch: 53, Batch number: 48, Loss: 24501.693359375\n",
      "Epoch: 54, Batch number: 72, Loss: 24705.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Batch number: 20, Loss: 24046.33984375\n",
      "Epoch: 57, Batch number: 44, Loss: 24201.080078125\n",
      "Epoch: 58, Batch number: 68, Loss: 23832.474609375\n",
      "Epoch: 60, Batch number: 16, Loss: 23694.578125\n",
      "Epoch: 61, Batch number: 40, Loss: 23943.673828125\n",
      "Epoch: 62, Batch number: 64, Loss: 23960.771484375\n",
      "Epoch: 64, Batch number: 12, Loss: 23368.2265625\n",
      "Epoch: 65, Batch number: 36, Loss: 23990.140625\n",
      "Epoch: 66, Batch number: 60, Loss: 23523.845703125\n",
      "Epoch: 68, Batch number: 8, Loss: 24119.623046875\n",
      "Epoch: 69, Batch number: 32, Loss: 23386.16015625\n",
      "Epoch: 70, Batch number: 56, Loss: 24008.2578125\n",
      "Epoch: 72, Batch number: 4, Loss: 23397.24609375\n",
      "Epoch: 73, Batch number: 28, Loss: 23550.650390625\n",
      "Epoch: 74, Batch number: 52, Loss: 23586.814453125\n",
      "Epoch: 76, Batch number: 0, Loss: 23184.75\n",
      "Epoch: 77, Batch number: 24, Loss: 23571.734375\n",
      "Epoch: 78, Batch number: 48, Loss: 23692.7265625\n",
      "Epoch: 79, Batch number: 72, Loss: 22998.724609375\n",
      "Epoch: 81, Batch number: 20, Loss: 23880.3671875\n",
      "Epoch: 82, Batch number: 44, Loss: 23185.06640625\n",
      "Epoch: 83, Batch number: 68, Loss: 23135.421875\n",
      "Epoch: 85, Batch number: 16, Loss: 23308.412109375\n",
      "Epoch: 86, Batch number: 40, Loss: 22520.0\n",
      "Epoch: 87, Batch number: 64, Loss: 23156.4609375\n",
      "Epoch: 89, Batch number: 12, Loss: 22820.75390625\n",
      "Epoch: 90, Batch number: 36, Loss: 23310.03125\n",
      "Epoch: 91, Batch number: 60, Loss: 23137.177734375\n",
      "Epoch: 93, Batch number: 8, Loss: 22722.83203125\n",
      "Epoch: 94, Batch number: 32, Loss: 23038.1171875\n",
      "Epoch: 95, Batch number: 56, Loss: 23259.326171875\n",
      "Epoch: 97, Batch number: 4, Loss: 22592.93359375\n",
      "Epoch: 98, Batch number: 28, Loss: 22329.029296875\n",
      "Epoch: 99, Batch number: 52, Loss: 23358.83984375\n",
      "Epoch: 101, Batch number: 0, Loss: 22699.025390625\n",
      "Epoch: 102, Batch number: 24, Loss: 22931.443359375\n",
      "Epoch: 103, Batch number: 48, Loss: 23227.12109375\n",
      "Epoch: 104, Batch number: 72, Loss: 22982.375\n",
      "Epoch: 106, Batch number: 20, Loss: 22346.662109375\n",
      "Epoch: 107, Batch number: 44, Loss: 23383.140625\n",
      "Epoch: 108, Batch number: 68, Loss: 22906.310546875\n",
      "Epoch: 110, Batch number: 16, Loss: 22982.439453125\n",
      "Epoch: 111, Batch number: 40, Loss: 22704.923828125\n",
      "Epoch: 112, Batch number: 64, Loss: 22463.4296875\n",
      "Epoch: 114, Batch number: 12, Loss: 22693.970703125\n",
      "Epoch: 115, Batch number: 36, Loss: 22723.24609375\n",
      "Epoch: 116, Batch number: 60, Loss: 22785.865234375\n",
      "Epoch: 118, Batch number: 8, Loss: 22174.89453125\n",
      "Epoch: 119, Batch number: 32, Loss: 22804.16015625\n",
      "Epoch: 120, Batch number: 56, Loss: 22634.564453125\n",
      "Epoch: 122, Batch number: 4, Loss: 22429.50390625\n",
      "Epoch: 123, Batch number: 28, Loss: 22507.31640625\n",
      "Epoch: 124, Batch number: 52, Loss: 22411.97265625\n",
      "Epoch: 126, Batch number: 0, Loss: 22444.548828125\n",
      "Epoch: 127, Batch number: 24, Loss: 22386.658203125\n",
      "Epoch: 128, Batch number: 48, Loss: 22129.7578125\n",
      "Epoch: 129, Batch number: 72, Loss: 22478.96875\n",
      "Epoch: 131, Batch number: 20, Loss: 22680.763671875\n",
      "Epoch: 132, Batch number: 44, Loss: 22654.166015625\n",
      "Epoch: 133, Batch number: 68, Loss: 22599.359375\n",
      "Epoch: 135, Batch number: 16, Loss: 22120.42578125\n",
      "Epoch: 136, Batch number: 40, Loss: 22078.03125\n",
      "Epoch: 137, Batch number: 64, Loss: 22230.4375\n",
      "Epoch: 139, Batch number: 12, Loss: 22313.521484375\n",
      "Epoch: 140, Batch number: 36, Loss: 22398.1484375\n",
      "Epoch: 141, Batch number: 60, Loss: 22475.1796875\n",
      "Epoch: 143, Batch number: 8, Loss: 21976.875\n",
      "Epoch: 144, Batch number: 32, Loss: 22024.78125\n",
      "Epoch: 145, Batch number: 56, Loss: 22310.53125\n",
      "Epoch: 147, Batch number: 4, Loss: 22033.470703125\n",
      "Epoch: 148, Batch number: 28, Loss: 22239.345703125\n",
      "Epoch: 149, Batch number: 52, Loss: 22190.7421875\n",
      "Epoch: 151, Batch number: 0, Loss: 22155.0703125\n",
      "Epoch: 152, Batch number: 24, Loss: 22036.466796875\n",
      "Epoch: 153, Batch number: 48, Loss: 22244.701171875\n",
      "Epoch: 154, Batch number: 72, Loss: 21922.322265625\n",
      "Epoch: 156, Batch number: 20, Loss: 22317.083984375\n",
      "Epoch: 157, Batch number: 44, Loss: 22027.078125\n",
      "Epoch: 158, Batch number: 68, Loss: 22364.498046875\n",
      "Epoch: 160, Batch number: 16, Loss: 21797.716796875\n",
      "Epoch: 161, Batch number: 40, Loss: 21650.69921875\n",
      "Epoch: 162, Batch number: 64, Loss: 21899.54296875\n",
      "Epoch: 164, Batch number: 12, Loss: 21650.03515625\n",
      "Epoch: 165, Batch number: 36, Loss: 22003.9609375\n",
      "Epoch: 166, Batch number: 60, Loss: 22598.466796875\n",
      "Epoch: 168, Batch number: 8, Loss: 21881.318359375\n",
      "Epoch: 169, Batch number: 32, Loss: 22395.986328125\n",
      "Epoch: 170, Batch number: 56, Loss: 21745.1171875\n",
      "Epoch: 172, Batch number: 4, Loss: 21969.638671875\n",
      "Epoch: 173, Batch number: 28, Loss: 21690.0625\n",
      "Epoch: 174, Batch number: 52, Loss: 21527.814453125\n",
      "Epoch: 176, Batch number: 0, Loss: 22136.828125\n",
      "Epoch: 177, Batch number: 24, Loss: 22111.021484375\n",
      "Epoch: 178, Batch number: 48, Loss: 22288.62109375\n",
      "Epoch: 179, Batch number: 72, Loss: 21455.322265625\n",
      "Epoch: 181, Batch number: 20, Loss: 21897.1953125\n",
      "Epoch: 182, Batch number: 44, Loss: 22501.607421875\n",
      "Epoch: 183, Batch number: 68, Loss: 21848.80078125\n",
      "Epoch: 185, Batch number: 16, Loss: 21550.998046875\n",
      "Epoch: 186, Batch number: 40, Loss: 21935.58984375\n",
      "Epoch: 187, Batch number: 64, Loss: 21968.97265625\n",
      "Epoch: 189, Batch number: 12, Loss: 21116.330078125\n",
      "Epoch: 190, Batch number: 36, Loss: 22122.6796875\n",
      "Epoch: 191, Batch number: 60, Loss: 21655.314453125\n",
      "Epoch: 193, Batch number: 8, Loss: 22230.705078125\n",
      "Epoch: 194, Batch number: 32, Loss: 22106.853515625\n",
      "Epoch: 195, Batch number: 56, Loss: 21541.833984375\n",
      "Epoch: 197, Batch number: 4, Loss: 21674.896484375\n",
      "Epoch: 198, Batch number: 28, Loss: 21804.53125\n",
      "Epoch: 199, Batch number: 52, Loss: 21813.501953125\n",
      "Epoch: 201, Batch number: 0, Loss: 22138.73828125\n",
      "Epoch: 202, Batch number: 24, Loss: 21614.7578125\n",
      "Epoch: 203, Batch number: 48, Loss: 21831.892578125\n",
      "Epoch: 204, Batch number: 72, Loss: 21707.259765625\n",
      "Epoch: 206, Batch number: 20, Loss: 20957.87109375\n",
      "Epoch: 207, Batch number: 44, Loss: 21459.478515625\n",
      "Epoch: 208, Batch number: 68, Loss: 21646.48828125\n",
      "Epoch: 210, Batch number: 16, Loss: 21498.490234375\n",
      "Epoch: 211, Batch number: 40, Loss: 21260.19140625\n",
      "Epoch: 212, Batch number: 64, Loss: 21761.568359375\n",
      "Epoch: 214, Batch number: 12, Loss: 21592.833984375\n",
      "Epoch: 215, Batch number: 36, Loss: 21578.212890625\n",
      "Epoch: 216, Batch number: 60, Loss: 22528.9375\n",
      "Epoch: 218, Batch number: 8, Loss: 21538.4921875\n",
      "Epoch: 219, Batch number: 32, Loss: 20819.8515625\n",
      "Epoch: 220, Batch number: 56, Loss: 21788.912109375\n",
      "Epoch: 222, Batch number: 4, Loss: 21621.3359375\n",
      "Epoch: 223, Batch number: 28, Loss: 22253.08203125\n",
      "Epoch: 224, Batch number: 52, Loss: 22016.8125\n",
      "Epoch: 226, Batch number: 0, Loss: 21793.892578125\n",
      "Epoch: 227, Batch number: 24, Loss: 21822.728515625\n",
      "Epoch: 228, Batch number: 48, Loss: 21350.884765625\n",
      "Epoch: 229, Batch number: 72, Loss: 21739.9140625\n",
      "Epoch: 231, Batch number: 20, Loss: 21587.490234375\n",
      "Epoch: 232, Batch number: 44, Loss: 21378.322265625\n",
      "Epoch: 233, Batch number: 68, Loss: 21764.400390625\n",
      "Epoch: 235, Batch number: 16, Loss: 21789.345703125\n",
      "Epoch: 236, Batch number: 40, Loss: 21709.6640625\n",
      "Epoch: 237, Batch number: 64, Loss: 20940.24609375\n",
      "Epoch: 239, Batch number: 12, Loss: 22056.779296875\n",
      "Epoch: 240, Batch number: 36, Loss: 22021.505859375\n",
      "Epoch: 241, Batch number: 60, Loss: 21264.72265625\n",
      "Epoch: 243, Batch number: 8, Loss: 21961.60546875\n",
      "Epoch: 244, Batch number: 32, Loss: 21662.05078125\n",
      "Epoch: 245, Batch number: 56, Loss: 21367.251953125\n",
      "Epoch: 247, Batch number: 4, Loss: 21273.80078125\n",
      "Epoch: 248, Batch number: 28, Loss: 21308.849609375\n",
      "Epoch: 249, Batch number: 52, Loss: 21800.12109375\n",
      "Epoch: 251, Batch number: 0, Loss: 21221.267578125\n",
      "Epoch: 252, Batch number: 24, Loss: 21566.541015625\n",
      "Epoch: 253, Batch number: 48, Loss: 21701.578125\n",
      "Epoch: 254, Batch number: 72, Loss: 21368.767578125\n",
      "Epoch: 256, Batch number: 20, Loss: 21326.21875\n",
      "Epoch: 257, Batch number: 44, Loss: 21364.7109375\n",
      "Epoch: 258, Batch number: 68, Loss: 21047.513671875\n",
      "Epoch: 260, Batch number: 16, Loss: 21488.3359375\n",
      "Epoch: 261, Batch number: 40, Loss: 21822.796875\n",
      "Epoch: 262, Batch number: 64, Loss: 21622.9453125\n",
      "Epoch: 264, Batch number: 12, Loss: 21455.755859375\n",
      "Epoch: 265, Batch number: 36, Loss: 20930.673828125\n",
      "Epoch: 266, Batch number: 60, Loss: 21723.65625\n",
      "Epoch: 268, Batch number: 8, Loss: 21436.2578125\n",
      "Epoch: 269, Batch number: 32, Loss: 21113.994140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Batch number: 56, Loss: 21248.916015625\n",
      "Epoch: 272, Batch number: 4, Loss: 21558.818359375\n",
      "Epoch: 273, Batch number: 28, Loss: 21237.27734375\n",
      "Epoch: 274, Batch number: 52, Loss: 21611.5078125\n",
      "Epoch: 276, Batch number: 0, Loss: 20713.11328125\n",
      "Epoch: 277, Batch number: 24, Loss: 21255.05078125\n",
      "Epoch: 278, Batch number: 48, Loss: 21062.025390625\n",
      "Epoch: 279, Batch number: 72, Loss: 21156.478515625\n",
      "Epoch: 281, Batch number: 20, Loss: 21152.859375\n",
      "Epoch: 282, Batch number: 44, Loss: 21018.232421875\n",
      "Epoch: 283, Batch number: 68, Loss: 21685.369140625\n",
      "Epoch: 285, Batch number: 16, Loss: 21213.146484375\n",
      "Epoch: 286, Batch number: 40, Loss: 20541.599609375\n",
      "Epoch: 287, Batch number: 64, Loss: 20919.947265625\n",
      "Epoch: 289, Batch number: 12, Loss: 21496.197265625\n",
      "Epoch: 290, Batch number: 36, Loss: 20969.466796875\n",
      "Epoch: 291, Batch number: 60, Loss: 21359.96484375\n",
      "Epoch: 293, Batch number: 8, Loss: 21293.478515625\n",
      "Epoch: 294, Batch number: 32, Loss: 21452.009765625\n",
      "Epoch: 295, Batch number: 56, Loss: 21489.55078125\n",
      "Epoch: 297, Batch number: 4, Loss: 21332.619140625\n",
      "Epoch: 298, Batch number: 28, Loss: 21424.314453125\n",
      "Epoch: 299, Batch number: 52, Loss: 20987.861328125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 39783.75390625\n",
      "Epoch: 2, Batch number: 24, Loss: 37577.1953125\n",
      "Epoch: 3, Batch number: 48, Loss: 34316.34765625\n",
      "Epoch: 4, Batch number: 72, Loss: 33179.51953125\n",
      "Epoch: 6, Batch number: 20, Loss: 31703.857421875\n",
      "Epoch: 7, Batch number: 44, Loss: 30278.064453125\n",
      "Epoch: 8, Batch number: 68, Loss: 29852.578125\n",
      "Epoch: 10, Batch number: 16, Loss: 29110.41015625\n",
      "Epoch: 11, Batch number: 40, Loss: 28151.87109375\n",
      "Epoch: 12, Batch number: 64, Loss: 27932.1953125\n",
      "Epoch: 14, Batch number: 12, Loss: 27608.939453125\n",
      "Epoch: 15, Batch number: 36, Loss: 26853.7265625\n",
      "Epoch: 16, Batch number: 60, Loss: 26942.8359375\n",
      "Epoch: 18, Batch number: 8, Loss: 26272.81640625\n",
      "Epoch: 19, Batch number: 32, Loss: 25969.84765625\n",
      "Epoch: 20, Batch number: 56, Loss: 25575.40234375\n",
      "Epoch: 22, Batch number: 4, Loss: 25365.244140625\n",
      "Epoch: 23, Batch number: 28, Loss: 25176.24609375\n",
      "Epoch: 24, Batch number: 52, Loss: 25039.009765625\n",
      "Epoch: 26, Batch number: 0, Loss: 24987.345703125\n",
      "Epoch: 27, Batch number: 24, Loss: 24575.376953125\n",
      "Epoch: 28, Batch number: 48, Loss: 24963.41015625\n",
      "Epoch: 29, Batch number: 72, Loss: 24764.673828125\n",
      "Epoch: 31, Batch number: 20, Loss: 24105.248046875\n",
      "Epoch: 32, Batch number: 44, Loss: 24388.283203125\n",
      "Epoch: 33, Batch number: 68, Loss: 24368.81640625\n",
      "Epoch: 35, Batch number: 16, Loss: 23770.583984375\n",
      "Epoch: 36, Batch number: 40, Loss: 24208.296875\n",
      "Epoch: 37, Batch number: 64, Loss: 23919.20703125\n",
      "Epoch: 39, Batch number: 12, Loss: 23991.21875\n",
      "Epoch: 40, Batch number: 36, Loss: 23697.828125\n",
      "Epoch: 41, Batch number: 60, Loss: 23964.984375\n",
      "Epoch: 43, Batch number: 8, Loss: 23515.0078125\n",
      "Epoch: 44, Batch number: 32, Loss: 23440.16015625\n",
      "Epoch: 45, Batch number: 56, Loss: 23592.6640625\n",
      "Epoch: 47, Batch number: 4, Loss: 23495.341796875\n",
      "Epoch: 48, Batch number: 28, Loss: 23542.240234375\n",
      "Epoch: 49, Batch number: 52, Loss: 23360.560546875\n",
      "Epoch: 51, Batch number: 0, Loss: 23567.29296875\n",
      "Epoch: 52, Batch number: 24, Loss: 23151.37890625\n",
      "Epoch: 53, Batch number: 48, Loss: 23063.9609375\n",
      "Epoch: 54, Batch number: 72, Loss: 22964.703125\n",
      "Epoch: 56, Batch number: 20, Loss: 22979.41015625\n",
      "Epoch: 57, Batch number: 44, Loss: 23402.916015625\n",
      "Epoch: 58, Batch number: 68, Loss: 22860.759765625\n",
      "Epoch: 60, Batch number: 16, Loss: 22935.4140625\n",
      "Epoch: 61, Batch number: 40, Loss: 22958.1953125\n",
      "Epoch: 62, Batch number: 64, Loss: 22604.439453125\n",
      "Epoch: 64, Batch number: 12, Loss: 22510.646484375\n",
      "Epoch: 65, Batch number: 36, Loss: 22862.03125\n",
      "Epoch: 66, Batch number: 60, Loss: 23031.15625\n",
      "Epoch: 68, Batch number: 8, Loss: 23160.365234375\n",
      "Epoch: 69, Batch number: 32, Loss: 22734.689453125\n",
      "Epoch: 70, Batch number: 56, Loss: 22516.28515625\n",
      "Epoch: 72, Batch number: 4, Loss: 22250.39453125\n",
      "Epoch: 73, Batch number: 28, Loss: 22846.513671875\n",
      "Epoch: 74, Batch number: 52, Loss: 22729.630859375\n",
      "Epoch: 76, Batch number: 0, Loss: 22281.755859375\n",
      "Epoch: 77, Batch number: 24, Loss: 22716.939453125\n",
      "Epoch: 78, Batch number: 48, Loss: 21954.7109375\n",
      "Epoch: 79, Batch number: 72, Loss: 22813.05078125\n",
      "Epoch: 81, Batch number: 20, Loss: 22240.609375\n",
      "Epoch: 82, Batch number: 44, Loss: 22396.271484375\n",
      "Epoch: 83, Batch number: 68, Loss: 22173.294921875\n",
      "Epoch: 85, Batch number: 16, Loss: 22393.666015625\n",
      "Epoch: 86, Batch number: 40, Loss: 22714.833984375\n",
      "Epoch: 87, Batch number: 64, Loss: 22354.103515625\n",
      "Epoch: 89, Batch number: 12, Loss: 21960.08203125\n",
      "Epoch: 90, Batch number: 36, Loss: 22291.72265625\n",
      "Epoch: 91, Batch number: 60, Loss: 22531.4140625\n",
      "Epoch: 93, Batch number: 8, Loss: 22134.76953125\n",
      "Epoch: 94, Batch number: 32, Loss: 22306.501953125\n",
      "Epoch: 95, Batch number: 56, Loss: 22346.884765625\n",
      "Epoch: 97, Batch number: 4, Loss: 21921.466796875\n",
      "Epoch: 98, Batch number: 28, Loss: 22138.638671875\n",
      "Epoch: 99, Batch number: 52, Loss: 22078.634765625\n",
      "Epoch: 101, Batch number: 0, Loss: 22341.06640625\n",
      "Epoch: 102, Batch number: 24, Loss: 21584.05078125\n",
      "Epoch: 103, Batch number: 48, Loss: 22101.16015625\n",
      "Epoch: 104, Batch number: 72, Loss: 22178.830078125\n",
      "Epoch: 106, Batch number: 20, Loss: 21892.83984375\n",
      "Epoch: 107, Batch number: 44, Loss: 21839.48828125\n",
      "Epoch: 108, Batch number: 68, Loss: 22136.017578125\n",
      "Epoch: 110, Batch number: 16, Loss: 21797.197265625\n",
      "Epoch: 111, Batch number: 40, Loss: 21532.130859375\n",
      "Epoch: 112, Batch number: 64, Loss: 21623.08984375\n",
      "Epoch: 114, Batch number: 12, Loss: 21506.9921875\n",
      "Epoch: 115, Batch number: 36, Loss: 21700.6953125\n",
      "Epoch: 116, Batch number: 60, Loss: 22058.26171875\n",
      "Epoch: 118, Batch number: 8, Loss: 21006.041015625\n",
      "Epoch: 119, Batch number: 32, Loss: 21774.666015625\n",
      "Epoch: 120, Batch number: 56, Loss: 21913.83203125\n",
      "Epoch: 122, Batch number: 4, Loss: 21669.275390625\n",
      "Epoch: 123, Batch number: 28, Loss: 21620.447265625\n",
      "Epoch: 124, Batch number: 52, Loss: 21608.037109375\n",
      "Epoch: 126, Batch number: 0, Loss: 21609.359375\n",
      "Epoch: 127, Batch number: 24, Loss: 21836.541015625\n",
      "Epoch: 128, Batch number: 48, Loss: 22006.201171875\n",
      "Epoch: 129, Batch number: 72, Loss: 21827.38671875\n",
      "Epoch: 131, Batch number: 20, Loss: 21436.14453125\n",
      "Epoch: 132, Batch number: 44, Loss: 21261.412109375\n",
      "Epoch: 133, Batch number: 68, Loss: 21793.923828125\n",
      "Epoch: 135, Batch number: 16, Loss: 21360.46484375\n",
      "Epoch: 136, Batch number: 40, Loss: 21600.794921875\n",
      "Epoch: 137, Batch number: 64, Loss: 22145.365234375\n",
      "Epoch: 139, Batch number: 12, Loss: 21545.115234375\n",
      "Epoch: 140, Batch number: 36, Loss: 21798.404296875\n",
      "Epoch: 141, Batch number: 60, Loss: 21712.189453125\n",
      "Epoch: 143, Batch number: 8, Loss: 21509.92578125\n",
      "Epoch: 144, Batch number: 32, Loss: 22239.123046875\n",
      "Epoch: 145, Batch number: 56, Loss: 21819.408203125\n",
      "Epoch: 147, Batch number: 4, Loss: 21605.197265625\n",
      "Epoch: 148, Batch number: 28, Loss: 21220.978515625\n",
      "Epoch: 149, Batch number: 52, Loss: 21592.4765625\n",
      "Epoch: 151, Batch number: 0, Loss: 21245.150390625\n",
      "Epoch: 152, Batch number: 24, Loss: 21430.732421875\n",
      "Epoch: 153, Batch number: 48, Loss: 21431.501953125\n",
      "Epoch: 154, Batch number: 72, Loss: 21583.857421875\n",
      "Epoch: 156, Batch number: 20, Loss: 21202.177734375\n",
      "Epoch: 157, Batch number: 44, Loss: 21774.4921875\n",
      "Epoch: 158, Batch number: 68, Loss: 21786.7578125\n",
      "Epoch: 160, Batch number: 16, Loss: 21725.556640625\n",
      "Epoch: 161, Batch number: 40, Loss: 21506.390625\n",
      "Epoch: 162, Batch number: 64, Loss: 22008.81640625\n",
      "Epoch: 164, Batch number: 12, Loss: 21419.62890625\n",
      "Epoch: 165, Batch number: 36, Loss: 21336.45703125\n",
      "Epoch: 166, Batch number: 60, Loss: 21050.134765625\n",
      "Epoch: 168, Batch number: 8, Loss: 20893.466796875\n",
      "Epoch: 169, Batch number: 32, Loss: 21188.75390625\n",
      "Epoch: 170, Batch number: 56, Loss: 21327.384765625\n",
      "Epoch: 172, Batch number: 4, Loss: 21008.79296875\n",
      "Epoch: 173, Batch number: 28, Loss: 21515.828125\n",
      "Epoch: 174, Batch number: 52, Loss: 21373.96484375\n",
      "Epoch: 176, Batch number: 0, Loss: 21096.03515625\n",
      "Epoch: 177, Batch number: 24, Loss: 21184.021484375\n",
      "Epoch: 178, Batch number: 48, Loss: 21229.51953125\n",
      "Epoch: 179, Batch number: 72, Loss: 21024.185546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181, Batch number: 20, Loss: 21117.818359375\n",
      "Epoch: 182, Batch number: 44, Loss: 21162.443359375\n",
      "Epoch: 183, Batch number: 68, Loss: 21529.724609375\n",
      "Epoch: 185, Batch number: 16, Loss: 21481.021484375\n",
      "Epoch: 186, Batch number: 40, Loss: 20986.083984375\n",
      "Epoch: 187, Batch number: 64, Loss: 21225.921875\n",
      "Epoch: 189, Batch number: 12, Loss: 21290.900390625\n",
      "Epoch: 190, Batch number: 36, Loss: 20803.078125\n",
      "Epoch: 191, Batch number: 60, Loss: 21658.74609375\n",
      "Epoch: 193, Batch number: 8, Loss: 21507.884765625\n",
      "Epoch: 194, Batch number: 32, Loss: 20988.466796875\n",
      "Epoch: 195, Batch number: 56, Loss: 21041.26171875\n",
      "Epoch: 197, Batch number: 4, Loss: 20946.169921875\n",
      "Epoch: 198, Batch number: 28, Loss: 21274.314453125\n",
      "Epoch: 199, Batch number: 52, Loss: 21296.287109375\n",
      "Epoch: 201, Batch number: 0, Loss: 21322.599609375\n",
      "Epoch: 202, Batch number: 24, Loss: 21216.119140625\n",
      "Epoch: 203, Batch number: 48, Loss: 20987.16796875\n",
      "Epoch: 204, Batch number: 72, Loss: 21406.3515625\n",
      "Epoch: 206, Batch number: 20, Loss: 20501.736328125\n",
      "Epoch: 207, Batch number: 44, Loss: 21013.8984375\n",
      "Epoch: 208, Batch number: 68, Loss: 22116.712890625\n",
      "Epoch: 210, Batch number: 16, Loss: 21044.970703125\n",
      "Epoch: 211, Batch number: 40, Loss: 21201.75390625\n",
      "Epoch: 212, Batch number: 64, Loss: 21478.935546875\n",
      "Epoch: 214, Batch number: 12, Loss: 20625.32421875\n",
      "Epoch: 215, Batch number: 36, Loss: 21111.5859375\n",
      "Epoch: 216, Batch number: 60, Loss: 20337.19921875\n",
      "Epoch: 218, Batch number: 8, Loss: 21241.171875\n",
      "Epoch: 219, Batch number: 32, Loss: 21171.1640625\n",
      "Epoch: 220, Batch number: 56, Loss: 21448.201171875\n",
      "Epoch: 222, Batch number: 4, Loss: 20303.859375\n",
      "Epoch: 223, Batch number: 28, Loss: 20985.318359375\n",
      "Epoch: 224, Batch number: 52, Loss: 21253.158203125\n",
      "Epoch: 226, Batch number: 0, Loss: 21006.259765625\n",
      "Epoch: 227, Batch number: 24, Loss: 21248.748046875\n",
      "Epoch: 228, Batch number: 48, Loss: 20612.490234375\n",
      "Epoch: 229, Batch number: 72, Loss: 21057.0546875\n",
      "Epoch: 231, Batch number: 20, Loss: 21249.181640625\n",
      "Epoch: 232, Batch number: 44, Loss: 20910.498046875\n",
      "Epoch: 233, Batch number: 68, Loss: 21567.83984375\n",
      "Epoch: 235, Batch number: 16, Loss: 21024.7890625\n",
      "Epoch: 236, Batch number: 40, Loss: 21161.84765625\n",
      "Epoch: 237, Batch number: 64, Loss: 21510.224609375\n",
      "Epoch: 239, Batch number: 12, Loss: 20931.1484375\n",
      "Epoch: 240, Batch number: 36, Loss: 20833.314453125\n",
      "Epoch: 241, Batch number: 60, Loss: 20694.330078125\n",
      "Epoch: 243, Batch number: 8, Loss: 21428.22265625\n",
      "Epoch: 244, Batch number: 32, Loss: 21184.810546875\n",
      "Epoch: 245, Batch number: 56, Loss: 20854.232421875\n",
      "Epoch: 247, Batch number: 4, Loss: 20911.310546875\n",
      "Epoch: 248, Batch number: 28, Loss: 20430.193359375\n",
      "Epoch: 249, Batch number: 52, Loss: 20974.53125\n",
      "Epoch: 251, Batch number: 0, Loss: 21522.529296875\n",
      "Epoch: 252, Batch number: 24, Loss: 21196.244140625\n",
      "Epoch: 253, Batch number: 48, Loss: 20972.916015625\n",
      "Epoch: 254, Batch number: 72, Loss: 21373.50390625\n",
      "Epoch: 256, Batch number: 20, Loss: 20769.826171875\n",
      "Epoch: 257, Batch number: 44, Loss: 20689.671875\n",
      "Epoch: 258, Batch number: 68, Loss: 21155.919921875\n",
      "Epoch: 260, Batch number: 16, Loss: 20875.482421875\n",
      "Epoch: 261, Batch number: 40, Loss: 20678.1953125\n",
      "Epoch: 262, Batch number: 64, Loss: 21458.158203125\n",
      "Epoch: 264, Batch number: 12, Loss: 20590.513671875\n",
      "Epoch: 265, Batch number: 36, Loss: 21267.560546875\n",
      "Epoch: 266, Batch number: 60, Loss: 20861.42578125\n",
      "Epoch: 268, Batch number: 8, Loss: 21102.193359375\n",
      "Epoch: 269, Batch number: 32, Loss: 21482.150390625\n",
      "Epoch: 270, Batch number: 56, Loss: 20853.166015625\n",
      "Epoch: 272, Batch number: 4, Loss: 20977.59375\n",
      "Epoch: 273, Batch number: 28, Loss: 21009.025390625\n",
      "Epoch: 274, Batch number: 52, Loss: 21168.6640625\n",
      "Epoch: 276, Batch number: 0, Loss: 20468.185546875\n",
      "Epoch: 277, Batch number: 24, Loss: 20870.05859375\n",
      "Epoch: 278, Batch number: 48, Loss: 21165.158203125\n",
      "Epoch: 279, Batch number: 72, Loss: 20305.68359375\n",
      "Epoch: 281, Batch number: 20, Loss: 21037.21484375\n",
      "Epoch: 282, Batch number: 44, Loss: 20895.873046875\n",
      "Epoch: 283, Batch number: 68, Loss: 20875.27734375\n",
      "Epoch: 285, Batch number: 16, Loss: 21137.787109375\n",
      "Epoch: 286, Batch number: 40, Loss: 21411.0859375\n",
      "Epoch: 287, Batch number: 64, Loss: 20638.841796875\n",
      "Epoch: 289, Batch number: 12, Loss: 20867.06640625\n",
      "Epoch: 290, Batch number: 36, Loss: 21399.67578125\n",
      "Epoch: 291, Batch number: 60, Loss: 21030.533203125\n",
      "Epoch: 293, Batch number: 8, Loss: 20819.013671875\n",
      "Epoch: 294, Batch number: 32, Loss: 21510.173828125\n",
      "Epoch: 295, Batch number: 56, Loss: 21040.138671875\n",
      "Epoch: 297, Batch number: 4, Loss: 20866.869140625\n",
      "Epoch: 298, Batch number: 28, Loss: 20734.544921875\n",
      "Epoch: 299, Batch number: 52, Loss: 20964.234375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 39927.1484375\n",
      "Epoch: 2, Batch number: 24, Loss: 35973.94140625\n",
      "Epoch: 3, Batch number: 48, Loss: 33771.2578125\n",
      "Epoch: 4, Batch number: 72, Loss: 32783.01171875\n",
      "Epoch: 6, Batch number: 20, Loss: 31376.03515625\n",
      "Epoch: 7, Batch number: 44, Loss: 30209.46875\n",
      "Epoch: 8, Batch number: 68, Loss: 29410.412109375\n",
      "Epoch: 10, Batch number: 16, Loss: 28535.314453125\n",
      "Epoch: 11, Batch number: 40, Loss: 28123.9453125\n",
      "Epoch: 12, Batch number: 64, Loss: 26836.041015625\n",
      "Epoch: 14, Batch number: 12, Loss: 26485.564453125\n",
      "Epoch: 15, Batch number: 36, Loss: 26047.078125\n",
      "Epoch: 16, Batch number: 60, Loss: 25713.91796875\n",
      "Epoch: 18, Batch number: 8, Loss: 25573.908203125\n",
      "Epoch: 19, Batch number: 32, Loss: 25282.564453125\n",
      "Epoch: 20, Batch number: 56, Loss: 25332.974609375\n",
      "Epoch: 22, Batch number: 4, Loss: 24342.705078125\n",
      "Epoch: 23, Batch number: 28, Loss: 25030.8515625\n",
      "Epoch: 24, Batch number: 52, Loss: 24335.447265625\n",
      "Epoch: 26, Batch number: 0, Loss: 24246.509765625\n",
      "Epoch: 27, Batch number: 24, Loss: 24164.98046875\n",
      "Epoch: 28, Batch number: 48, Loss: 24009.216796875\n",
      "Epoch: 29, Batch number: 72, Loss: 24174.234375\n",
      "Epoch: 31, Batch number: 20, Loss: 23901.001953125\n",
      "Epoch: 32, Batch number: 44, Loss: 24053.150390625\n",
      "Epoch: 33, Batch number: 68, Loss: 23684.87109375\n",
      "Epoch: 35, Batch number: 16, Loss: 23462.841796875\n",
      "Epoch: 36, Batch number: 40, Loss: 23128.72265625\n",
      "Epoch: 37, Batch number: 64, Loss: 23866.978515625\n",
      "Epoch: 39, Batch number: 12, Loss: 22954.328125\n",
      "Epoch: 40, Batch number: 36, Loss: 23104.021484375\n",
      "Epoch: 41, Batch number: 60, Loss: 23057.697265625\n",
      "Epoch: 43, Batch number: 8, Loss: 22769.974609375\n",
      "Epoch: 44, Batch number: 32, Loss: 23544.44921875\n",
      "Epoch: 45, Batch number: 56, Loss: 23211.658203125\n",
      "Epoch: 47, Batch number: 4, Loss: 22620.755859375\n",
      "Epoch: 48, Batch number: 28, Loss: 22641.724609375\n",
      "Epoch: 49, Batch number: 52, Loss: 22887.658203125\n",
      "Epoch: 51, Batch number: 0, Loss: 22253.01953125\n",
      "Epoch: 52, Batch number: 24, Loss: 22448.625\n",
      "Epoch: 53, Batch number: 48, Loss: 22618.0546875\n",
      "Epoch: 54, Batch number: 72, Loss: 22783.078125\n",
      "Epoch: 56, Batch number: 20, Loss: 22518.861328125\n",
      "Epoch: 57, Batch number: 44, Loss: 22341.6328125\n",
      "Epoch: 58, Batch number: 68, Loss: 22460.970703125\n",
      "Epoch: 60, Batch number: 16, Loss: 21746.279296875\n",
      "Epoch: 61, Batch number: 40, Loss: 22352.376953125\n",
      "Epoch: 62, Batch number: 64, Loss: 22168.662109375\n",
      "Epoch: 64, Batch number: 12, Loss: 22360.396484375\n",
      "Epoch: 65, Batch number: 36, Loss: 22314.02734375\n",
      "Epoch: 66, Batch number: 60, Loss: 21907.96875\n",
      "Epoch: 68, Batch number: 8, Loss: 22191.962890625\n",
      "Epoch: 69, Batch number: 32, Loss: 21677.6796875\n",
      "Epoch: 70, Batch number: 56, Loss: 22459.35546875\n",
      "Epoch: 72, Batch number: 4, Loss: 22236.9765625\n",
      "Epoch: 73, Batch number: 28, Loss: 22650.9609375\n",
      "Epoch: 74, Batch number: 52, Loss: 22390.44921875\n",
      "Epoch: 76, Batch number: 0, Loss: 21541.419921875\n",
      "Epoch: 77, Batch number: 24, Loss: 22543.255859375\n",
      "Epoch: 78, Batch number: 48, Loss: 22120.876953125\n",
      "Epoch: 79, Batch number: 72, Loss: 22182.619140625\n",
      "Epoch: 81, Batch number: 20, Loss: 21290.37109375\n",
      "Epoch: 82, Batch number: 44, Loss: 22147.125\n",
      "Epoch: 83, Batch number: 68, Loss: 22294.609375\n",
      "Epoch: 85, Batch number: 16, Loss: 21799.41015625\n",
      "Epoch: 86, Batch number: 40, Loss: 21991.421875\n",
      "Epoch: 87, Batch number: 64, Loss: 22531.744140625\n",
      "Epoch: 89, Batch number: 12, Loss: 21870.99609375\n",
      "Epoch: 90, Batch number: 36, Loss: 21675.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91, Batch number: 60, Loss: 21912.171875\n",
      "Epoch: 93, Batch number: 8, Loss: 21656.076171875\n",
      "Epoch: 94, Batch number: 32, Loss: 21651.3046875\n",
      "Epoch: 95, Batch number: 56, Loss: 21725.322265625\n",
      "Epoch: 97, Batch number: 4, Loss: 20959.33984375\n",
      "Epoch: 98, Batch number: 28, Loss: 21188.462890625\n",
      "Epoch: 99, Batch number: 52, Loss: 21882.84375\n",
      "Epoch: 101, Batch number: 0, Loss: 21622.12890625\n",
      "Epoch: 102, Batch number: 24, Loss: 21355.86328125\n",
      "Epoch: 103, Batch number: 48, Loss: 21487.76171875\n",
      "Epoch: 104, Batch number: 72, Loss: 20984.021484375\n",
      "Epoch: 106, Batch number: 20, Loss: 21406.8671875\n",
      "Epoch: 107, Batch number: 44, Loss: 21628.08203125\n",
      "Epoch: 108, Batch number: 68, Loss: 21625.916015625\n",
      "Epoch: 110, Batch number: 16, Loss: 21728.134765625\n",
      "Epoch: 111, Batch number: 40, Loss: 21418.458984375\n",
      "Epoch: 112, Batch number: 64, Loss: 21630.384765625\n",
      "Epoch: 114, Batch number: 12, Loss: 21170.34765625\n",
      "Epoch: 115, Batch number: 36, Loss: 21659.5078125\n",
      "Epoch: 116, Batch number: 60, Loss: 21564.830078125\n",
      "Epoch: 118, Batch number: 8, Loss: 21756.298828125\n",
      "Epoch: 119, Batch number: 32, Loss: 21090.07421875\n",
      "Epoch: 120, Batch number: 56, Loss: 21986.767578125\n",
      "Epoch: 122, Batch number: 4, Loss: 21420.400390625\n",
      "Epoch: 123, Batch number: 28, Loss: 21131.13671875\n",
      "Epoch: 124, Batch number: 52, Loss: 21607.564453125\n",
      "Epoch: 126, Batch number: 0, Loss: 20667.494140625\n",
      "Epoch: 127, Batch number: 24, Loss: 21783.75\n",
      "Epoch: 128, Batch number: 48, Loss: 21393.498046875\n",
      "Epoch: 129, Batch number: 72, Loss: 22009.501953125\n",
      "Epoch: 131, Batch number: 20, Loss: 21400.626953125\n",
      "Epoch: 132, Batch number: 44, Loss: 21406.828125\n",
      "Epoch: 133, Batch number: 68, Loss: 21306.498046875\n",
      "Epoch: 135, Batch number: 16, Loss: 20989.798828125\n",
      "Epoch: 136, Batch number: 40, Loss: 21249.5234375\n",
      "Epoch: 137, Batch number: 64, Loss: 21519.154296875\n",
      "Epoch: 139, Batch number: 12, Loss: 21521.796875\n",
      "Epoch: 140, Batch number: 36, Loss: 21010.578125\n",
      "Epoch: 141, Batch number: 60, Loss: 21337.83984375\n",
      "Epoch: 143, Batch number: 8, Loss: 21189.0546875\n",
      "Epoch: 144, Batch number: 32, Loss: 20755.427734375\n",
      "Epoch: 145, Batch number: 56, Loss: 21798.515625\n",
      "Epoch: 147, Batch number: 4, Loss: 20531.15234375\n",
      "Epoch: 148, Batch number: 28, Loss: 21197.837890625\n",
      "Epoch: 149, Batch number: 52, Loss: 21340.912109375\n",
      "Epoch: 151, Batch number: 0, Loss: 21492.107421875\n",
      "Epoch: 152, Batch number: 24, Loss: 20854.599609375\n",
      "Epoch: 153, Batch number: 48, Loss: 21384.41796875\n",
      "Epoch: 154, Batch number: 72, Loss: 21090.3046875\n",
      "Epoch: 156, Batch number: 20, Loss: 21071.322265625\n",
      "Epoch: 157, Batch number: 44, Loss: 20776.986328125\n",
      "Epoch: 158, Batch number: 68, Loss: 20859.80859375\n",
      "Epoch: 160, Batch number: 16, Loss: 21188.3515625\n",
      "Epoch: 161, Batch number: 40, Loss: 21182.642578125\n",
      "Epoch: 162, Batch number: 64, Loss: 20895.978515625\n",
      "Epoch: 164, Batch number: 12, Loss: 20959.076171875\n",
      "Epoch: 165, Batch number: 36, Loss: 21127.900390625\n",
      "Epoch: 166, Batch number: 60, Loss: 21272.7421875\n",
      "Epoch: 168, Batch number: 8, Loss: 20833.498046875\n",
      "Epoch: 169, Batch number: 32, Loss: 20706.552734375\n",
      "Epoch: 170, Batch number: 56, Loss: 21194.912109375\n",
      "Epoch: 172, Batch number: 4, Loss: 20948.142578125\n",
      "Epoch: 173, Batch number: 28, Loss: 21187.9140625\n",
      "Epoch: 174, Batch number: 52, Loss: 21319.638671875\n",
      "Epoch: 176, Batch number: 0, Loss: 20925.14453125\n",
      "Epoch: 177, Batch number: 24, Loss: 21600.912109375\n",
      "Epoch: 178, Batch number: 48, Loss: 20844.0078125\n",
      "Epoch: 179, Batch number: 72, Loss: 21177.8828125\n",
      "Epoch: 181, Batch number: 20, Loss: 20484.939453125\n",
      "Epoch: 182, Batch number: 44, Loss: 20423.3046875\n",
      "Epoch: 183, Batch number: 68, Loss: 21302.05078125\n",
      "Epoch: 185, Batch number: 16, Loss: 20959.80078125\n",
      "Epoch: 186, Batch number: 40, Loss: 21414.078125\n",
      "Epoch: 187, Batch number: 64, Loss: 21141.767578125\n",
      "Epoch: 189, Batch number: 12, Loss: 21213.41015625\n",
      "Epoch: 190, Batch number: 36, Loss: 20897.748046875\n",
      "Epoch: 191, Batch number: 60, Loss: 21138.267578125\n",
      "Epoch: 193, Batch number: 8, Loss: 20815.48828125\n",
      "Epoch: 194, Batch number: 32, Loss: 20496.8125\n",
      "Epoch: 195, Batch number: 56, Loss: 20890.642578125\n",
      "Epoch: 197, Batch number: 4, Loss: 21045.23046875\n",
      "Epoch: 198, Batch number: 28, Loss: 21249.3125\n",
      "Epoch: 199, Batch number: 52, Loss: 21207.16015625\n",
      "Epoch: 201, Batch number: 0, Loss: 20648.888671875\n",
      "Epoch: 202, Batch number: 24, Loss: 20551.75390625\n",
      "Epoch: 203, Batch number: 48, Loss: 20529.419921875\n",
      "Epoch: 204, Batch number: 72, Loss: 21046.30078125\n",
      "Epoch: 206, Batch number: 20, Loss: 20670.755859375\n",
      "Epoch: 207, Batch number: 44, Loss: 20900.580078125\n",
      "Epoch: 208, Batch number: 68, Loss: 20927.12109375\n",
      "Epoch: 210, Batch number: 16, Loss: 20819.4921875\n",
      "Epoch: 211, Batch number: 40, Loss: 20687.06640625\n",
      "Epoch: 212, Batch number: 64, Loss: 21053.51953125\n",
      "Epoch: 214, Batch number: 12, Loss: 20280.759765625\n",
      "Epoch: 215, Batch number: 36, Loss: 20904.63671875\n",
      "Epoch: 216, Batch number: 60, Loss: 20477.7265625\n",
      "Epoch: 218, Batch number: 8, Loss: 20601.986328125\n",
      "Epoch: 219, Batch number: 32, Loss: 20552.458984375\n",
      "Epoch: 220, Batch number: 56, Loss: 21229.01171875\n",
      "Epoch: 222, Batch number: 4, Loss: 20991.853515625\n",
      "Epoch: 223, Batch number: 28, Loss: 20893.177734375\n",
      "Epoch: 224, Batch number: 52, Loss: 21082.23828125\n",
      "Epoch: 226, Batch number: 0, Loss: 20658.177734375\n",
      "Epoch: 227, Batch number: 24, Loss: 20713.5703125\n",
      "Epoch: 228, Batch number: 48, Loss: 21124.82421875\n",
      "Epoch: 229, Batch number: 72, Loss: 21332.802734375\n",
      "Epoch: 231, Batch number: 20, Loss: 20652.705078125\n",
      "Epoch: 232, Batch number: 44, Loss: 20805.634765625\n",
      "Epoch: 233, Batch number: 68, Loss: 21173.306640625\n",
      "Epoch: 235, Batch number: 16, Loss: 21181.81640625\n",
      "Epoch: 236, Batch number: 40, Loss: 21185.2890625\n",
      "Epoch: 237, Batch number: 64, Loss: 21037.302734375\n",
      "Epoch: 239, Batch number: 12, Loss: 21145.271484375\n",
      "Epoch: 240, Batch number: 36, Loss: 20051.966796875\n",
      "Epoch: 241, Batch number: 60, Loss: 20464.115234375\n",
      "Epoch: 243, Batch number: 8, Loss: 20667.630859375\n",
      "Epoch: 244, Batch number: 32, Loss: 20988.705078125\n",
      "Epoch: 245, Batch number: 56, Loss: 21022.322265625\n",
      "Epoch: 247, Batch number: 4, Loss: 20831.701171875\n",
      "Epoch: 248, Batch number: 28, Loss: 20910.85546875\n",
      "Epoch: 249, Batch number: 52, Loss: 21116.646484375\n",
      "Epoch: 251, Batch number: 0, Loss: 20339.283203125\n",
      "Epoch: 252, Batch number: 24, Loss: 20730.236328125\n",
      "Epoch: 253, Batch number: 48, Loss: 20794.8515625\n",
      "Epoch: 254, Batch number: 72, Loss: 21444.02734375\n",
      "Epoch: 256, Batch number: 20, Loss: 21165.01953125\n",
      "Epoch: 257, Batch number: 44, Loss: 20809.625\n",
      "Epoch: 258, Batch number: 68, Loss: 20937.591796875\n",
      "Epoch: 260, Batch number: 16, Loss: 20647.654296875\n",
      "Epoch: 261, Batch number: 40, Loss: 21020.16015625\n",
      "Epoch: 262, Batch number: 64, Loss: 20887.24609375\n",
      "Epoch: 264, Batch number: 12, Loss: 20745.431640625\n",
      "Epoch: 265, Batch number: 36, Loss: 20146.083984375\n",
      "Epoch: 266, Batch number: 60, Loss: 20983.140625\n",
      "Epoch: 268, Batch number: 8, Loss: 20786.9453125\n",
      "Epoch: 269, Batch number: 32, Loss: 21150.689453125\n",
      "Epoch: 270, Batch number: 56, Loss: 20978.404296875\n",
      "Epoch: 272, Batch number: 4, Loss: 21251.974609375\n",
      "Epoch: 273, Batch number: 28, Loss: 20869.212890625\n",
      "Epoch: 274, Batch number: 52, Loss: 20446.42578125\n",
      "Epoch: 276, Batch number: 0, Loss: 20889.369140625\n",
      "Epoch: 277, Batch number: 24, Loss: 21042.458984375\n",
      "Epoch: 278, Batch number: 48, Loss: 20498.515625\n",
      "Epoch: 279, Batch number: 72, Loss: 20635.759765625\n",
      "Epoch: 281, Batch number: 20, Loss: 20419.3671875\n",
      "Epoch: 282, Batch number: 44, Loss: 21159.763671875\n",
      "Epoch: 283, Batch number: 68, Loss: 20712.9921875\n",
      "Epoch: 285, Batch number: 16, Loss: 21137.9453125\n",
      "Epoch: 286, Batch number: 40, Loss: 20616.94921875\n",
      "Epoch: 287, Batch number: 64, Loss: 20369.830078125\n",
      "Epoch: 289, Batch number: 12, Loss: 21030.220703125\n",
      "Epoch: 290, Batch number: 36, Loss: 20782.099609375\n",
      "Epoch: 291, Batch number: 60, Loss: 20539.783203125\n",
      "Epoch: 293, Batch number: 8, Loss: 21066.076171875\n",
      "Epoch: 294, Batch number: 32, Loss: 20827.412109375\n",
      "Epoch: 295, Batch number: 56, Loss: 20894.361328125\n",
      "Epoch: 297, Batch number: 4, Loss: 20178.447265625\n",
      "Epoch: 298, Batch number: 28, Loss: 20778.173828125\n",
      "Epoch: 299, Batch number: 52, Loss: 20769.3671875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 39611.6484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 24, Loss: 35551.03515625\n",
      "Epoch: 3, Batch number: 48, Loss: 32893.08984375\n",
      "Epoch: 4, Batch number: 72, Loss: 31648.103515625\n",
      "Epoch: 6, Batch number: 20, Loss: 30216.216796875\n",
      "Epoch: 7, Batch number: 44, Loss: 28883.5078125\n",
      "Epoch: 8, Batch number: 68, Loss: 28223.80859375\n",
      "Epoch: 10, Batch number: 16, Loss: 26804.009765625\n",
      "Epoch: 11, Batch number: 40, Loss: 26307.53125\n",
      "Epoch: 12, Batch number: 64, Loss: 26003.89453125\n",
      "Epoch: 14, Batch number: 12, Loss: 25239.392578125\n",
      "Epoch: 15, Batch number: 36, Loss: 25336.869140625\n",
      "Epoch: 16, Batch number: 60, Loss: 24861.361328125\n",
      "Epoch: 18, Batch number: 8, Loss: 24538.580078125\n",
      "Epoch: 19, Batch number: 32, Loss: 24124.888671875\n",
      "Epoch: 20, Batch number: 56, Loss: 23757.177734375\n",
      "Epoch: 22, Batch number: 4, Loss: 23715.6875\n",
      "Epoch: 23, Batch number: 28, Loss: 23580.84375\n",
      "Epoch: 24, Batch number: 52, Loss: 23251.009765625\n",
      "Epoch: 26, Batch number: 0, Loss: 22929.388671875\n",
      "Epoch: 27, Batch number: 24, Loss: 22561.09375\n",
      "Epoch: 28, Batch number: 48, Loss: 23333.951171875\n",
      "Epoch: 29, Batch number: 72, Loss: 23072.21484375\n",
      "Epoch: 31, Batch number: 20, Loss: 22748.140625\n",
      "Epoch: 32, Batch number: 44, Loss: 22337.134765625\n",
      "Epoch: 33, Batch number: 68, Loss: 22843.052734375\n",
      "Epoch: 35, Batch number: 16, Loss: 22873.6640625\n",
      "Epoch: 36, Batch number: 40, Loss: 22574.97265625\n",
      "Epoch: 37, Batch number: 64, Loss: 22619.064453125\n",
      "Epoch: 39, Batch number: 12, Loss: 22769.6484375\n",
      "Epoch: 40, Batch number: 36, Loss: 22364.45703125\n",
      "Epoch: 41, Batch number: 60, Loss: 22561.28515625\n",
      "Epoch: 43, Batch number: 8, Loss: 22404.033203125\n",
      "Epoch: 44, Batch number: 32, Loss: 22690.7421875\n",
      "Epoch: 45, Batch number: 56, Loss: 22049.583984375\n",
      "Epoch: 47, Batch number: 4, Loss: 21854.375\n",
      "Epoch: 48, Batch number: 28, Loss: 22163.85546875\n",
      "Epoch: 49, Batch number: 52, Loss: 21980.482421875\n",
      "Epoch: 51, Batch number: 0, Loss: 21583.3046875\n",
      "Epoch: 52, Batch number: 24, Loss: 21571.7109375\n",
      "Epoch: 53, Batch number: 48, Loss: 21766.166015625\n",
      "Epoch: 54, Batch number: 72, Loss: 21712.697265625\n",
      "Epoch: 56, Batch number: 20, Loss: 21761.931640625\n",
      "Epoch: 57, Batch number: 44, Loss: 21345.326171875\n",
      "Epoch: 58, Batch number: 68, Loss: 21958.087890625\n",
      "Epoch: 60, Batch number: 16, Loss: 21512.4765625\n",
      "Epoch: 61, Batch number: 40, Loss: 21974.169921875\n",
      "Epoch: 62, Batch number: 64, Loss: 22008.541015625\n",
      "Epoch: 64, Batch number: 12, Loss: 21463.748046875\n",
      "Epoch: 65, Batch number: 36, Loss: 22014.9765625\n",
      "Epoch: 66, Batch number: 60, Loss: 22199.1640625\n",
      "Epoch: 68, Batch number: 8, Loss: 21706.271484375\n",
      "Epoch: 69, Batch number: 32, Loss: 21980.40625\n",
      "Epoch: 70, Batch number: 56, Loss: 21504.853515625\n",
      "Epoch: 72, Batch number: 4, Loss: 21761.056640625\n",
      "Epoch: 73, Batch number: 28, Loss: 21300.283203125\n",
      "Epoch: 74, Batch number: 52, Loss: 21383.8359375\n",
      "Epoch: 76, Batch number: 0, Loss: 21336.986328125\n",
      "Epoch: 77, Batch number: 24, Loss: 21473.296875\n",
      "Epoch: 78, Batch number: 48, Loss: 21761.96875\n",
      "Epoch: 79, Batch number: 72, Loss: 22156.5390625\n",
      "Epoch: 81, Batch number: 20, Loss: 21543.0546875\n",
      "Epoch: 82, Batch number: 44, Loss: 21243.21484375\n",
      "Epoch: 83, Batch number: 68, Loss: 20965.021484375\n",
      "Epoch: 85, Batch number: 16, Loss: 21140.654296875\n",
      "Epoch: 86, Batch number: 40, Loss: 21923.79296875\n",
      "Epoch: 87, Batch number: 64, Loss: 21577.275390625\n",
      "Epoch: 89, Batch number: 12, Loss: 21177.724609375\n",
      "Epoch: 90, Batch number: 36, Loss: 21414.48046875\n",
      "Epoch: 91, Batch number: 60, Loss: 22104.392578125\n",
      "Epoch: 93, Batch number: 8, Loss: 21054.498046875\n",
      "Epoch: 94, Batch number: 32, Loss: 21430.970703125\n",
      "Epoch: 95, Batch number: 56, Loss: 21354.544921875\n",
      "Epoch: 97, Batch number: 4, Loss: 21032.1640625\n",
      "Epoch: 98, Batch number: 28, Loss: 21310.55859375\n",
      "Epoch: 99, Batch number: 52, Loss: 21869.87890625\n",
      "Epoch: 101, Batch number: 0, Loss: 20754.677734375\n",
      "Epoch: 102, Batch number: 24, Loss: 21424.99609375\n",
      "Epoch: 103, Batch number: 48, Loss: 20937.01171875\n",
      "Epoch: 104, Batch number: 72, Loss: 21524.189453125\n",
      "Epoch: 106, Batch number: 20, Loss: 21260.97265625\n",
      "Epoch: 107, Batch number: 44, Loss: 21427.16796875\n",
      "Epoch: 108, Batch number: 68, Loss: 21539.505859375\n",
      "Epoch: 110, Batch number: 16, Loss: 21076.54296875\n",
      "Epoch: 111, Batch number: 40, Loss: 21705.294921875\n",
      "Epoch: 112, Batch number: 64, Loss: 21084.126953125\n",
      "Epoch: 114, Batch number: 12, Loss: 20814.4375\n",
      "Epoch: 115, Batch number: 36, Loss: 21147.794921875\n",
      "Epoch: 116, Batch number: 60, Loss: 21430.228515625\n",
      "Epoch: 118, Batch number: 8, Loss: 20621.845703125\n",
      "Epoch: 119, Batch number: 32, Loss: 20633.26953125\n",
      "Epoch: 120, Batch number: 56, Loss: 20931.939453125\n",
      "Epoch: 122, Batch number: 4, Loss: 20463.642578125\n",
      "Epoch: 123, Batch number: 28, Loss: 20985.9140625\n",
      "Epoch: 124, Batch number: 52, Loss: 21757.51953125\n",
      "Epoch: 126, Batch number: 0, Loss: 20572.8046875\n",
      "Epoch: 127, Batch number: 24, Loss: 21029.298828125\n",
      "Epoch: 128, Batch number: 48, Loss: 21106.6328125\n",
      "Epoch: 129, Batch number: 72, Loss: 21076.134765625\n",
      "Epoch: 131, Batch number: 20, Loss: 21465.9453125\n",
      "Epoch: 132, Batch number: 44, Loss: 21190.666015625\n",
      "Epoch: 133, Batch number: 68, Loss: 20892.734375\n",
      "Epoch: 135, Batch number: 16, Loss: 20600.97265625\n",
      "Epoch: 136, Batch number: 40, Loss: 21300.54296875\n",
      "Epoch: 137, Batch number: 64, Loss: 21116.603515625\n",
      "Epoch: 139, Batch number: 12, Loss: 20543.55859375\n",
      "Epoch: 140, Batch number: 36, Loss: 20707.228515625\n",
      "Epoch: 141, Batch number: 60, Loss: 20932.83984375\n",
      "Epoch: 143, Batch number: 8, Loss: 20622.046875\n",
      "Epoch: 144, Batch number: 32, Loss: 20965.587890625\n",
      "Epoch: 145, Batch number: 56, Loss: 21413.47265625\n",
      "Epoch: 147, Batch number: 4, Loss: 20729.13671875\n",
      "Epoch: 148, Batch number: 28, Loss: 20821.0\n",
      "Epoch: 149, Batch number: 52, Loss: 20868.298828125\n",
      "Epoch: 151, Batch number: 0, Loss: 20607.96875\n",
      "Epoch: 152, Batch number: 24, Loss: 20969.380859375\n",
      "Epoch: 153, Batch number: 48, Loss: 21050.2734375\n",
      "Epoch: 154, Batch number: 72, Loss: 21462.392578125\n",
      "Epoch: 156, Batch number: 20, Loss: 21222.736328125\n",
      "Epoch: 157, Batch number: 44, Loss: 20769.615234375\n",
      "Epoch: 158, Batch number: 68, Loss: 21428.603515625\n",
      "Epoch: 160, Batch number: 16, Loss: 20954.5859375\n",
      "Epoch: 161, Batch number: 40, Loss: 21080.998046875\n",
      "Epoch: 162, Batch number: 64, Loss: 20503.060546875\n",
      "Epoch: 164, Batch number: 12, Loss: 21048.970703125\n",
      "Epoch: 165, Batch number: 36, Loss: 21051.81640625\n",
      "Epoch: 166, Batch number: 60, Loss: 20736.73046875\n",
      "Epoch: 168, Batch number: 8, Loss: 20882.19921875\n",
      "Epoch: 169, Batch number: 32, Loss: 20513.029296875\n",
      "Epoch: 170, Batch number: 56, Loss: 21174.4453125\n",
      "Epoch: 172, Batch number: 4, Loss: 20630.349609375\n",
      "Epoch: 173, Batch number: 28, Loss: 20650.716796875\n",
      "Epoch: 174, Batch number: 52, Loss: 20859.013671875\n",
      "Epoch: 176, Batch number: 0, Loss: 20739.984375\n",
      "Epoch: 177, Batch number: 24, Loss: 21580.68359375\n",
      "Epoch: 178, Batch number: 48, Loss: 21230.765625\n",
      "Epoch: 179, Batch number: 72, Loss: 20677.1875\n",
      "Epoch: 181, Batch number: 20, Loss: 20430.740234375\n",
      "Epoch: 182, Batch number: 44, Loss: 20471.208984375\n",
      "Epoch: 183, Batch number: 68, Loss: 21467.443359375\n",
      "Epoch: 185, Batch number: 16, Loss: 20994.408203125\n",
      "Epoch: 186, Batch number: 40, Loss: 21387.4609375\n",
      "Epoch: 187, Batch number: 64, Loss: 20651.24609375\n",
      "Epoch: 189, Batch number: 12, Loss: 20930.73828125\n",
      "Epoch: 190, Batch number: 36, Loss: 20732.12890625\n",
      "Epoch: 191, Batch number: 60, Loss: 21033.939453125\n",
      "Epoch: 193, Batch number: 8, Loss: 20614.439453125\n",
      "Epoch: 194, Batch number: 32, Loss: 20989.7734375\n",
      "Epoch: 195, Batch number: 56, Loss: 21121.9765625\n",
      "Epoch: 197, Batch number: 4, Loss: 21106.4140625\n",
      "Epoch: 198, Batch number: 28, Loss: 21009.380859375\n",
      "Epoch: 199, Batch number: 52, Loss: 21369.234375\n",
      "Epoch: 201, Batch number: 0, Loss: 20845.494140625\n",
      "Epoch: 202, Batch number: 24, Loss: 20925.298828125\n",
      "Epoch: 203, Batch number: 48, Loss: 20838.998046875\n",
      "Epoch: 204, Batch number: 72, Loss: 20420.298828125\n",
      "Epoch: 206, Batch number: 20, Loss: 21302.154296875\n",
      "Epoch: 207, Batch number: 44, Loss: 20480.888671875\n",
      "Epoch: 208, Batch number: 68, Loss: 21028.359375\n",
      "Epoch: 210, Batch number: 16, Loss: 20662.423828125\n",
      "Epoch: 211, Batch number: 40, Loss: 21450.3828125\n",
      "Epoch: 212, Batch number: 64, Loss: 20788.318359375\n",
      "Epoch: 214, Batch number: 12, Loss: 20882.09765625\n",
      "Epoch: 215, Batch number: 36, Loss: 21072.18359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 216, Batch number: 60, Loss: 21119.458984375\n",
      "Epoch: 218, Batch number: 8, Loss: 21126.705078125\n",
      "Epoch: 219, Batch number: 32, Loss: 20939.2578125\n",
      "Epoch: 220, Batch number: 56, Loss: 21069.05078125\n",
      "Epoch: 222, Batch number: 4, Loss: 20931.71484375\n",
      "Epoch: 223, Batch number: 28, Loss: 20764.625\n",
      "Epoch: 224, Batch number: 52, Loss: 20935.78125\n",
      "Epoch: 226, Batch number: 0, Loss: 20712.55859375\n",
      "Epoch: 227, Batch number: 24, Loss: 20457.169921875\n",
      "Epoch: 228, Batch number: 48, Loss: 21111.68359375\n",
      "Epoch: 229, Batch number: 72, Loss: 20692.462890625\n",
      "Epoch: 231, Batch number: 20, Loss: 20818.171875\n",
      "Epoch: 232, Batch number: 44, Loss: 21216.701171875\n",
      "Epoch: 233, Batch number: 68, Loss: 20498.978515625\n",
      "Epoch: 235, Batch number: 16, Loss: 20869.888671875\n",
      "Epoch: 236, Batch number: 40, Loss: 21008.802734375\n",
      "Epoch: 237, Batch number: 64, Loss: 20729.30078125\n",
      "Epoch: 239, Batch number: 12, Loss: 20612.732421875\n",
      "Epoch: 240, Batch number: 36, Loss: 20854.376953125\n",
      "Epoch: 241, Batch number: 60, Loss: 20945.94140625\n",
      "Epoch: 243, Batch number: 8, Loss: 20960.099609375\n",
      "Epoch: 244, Batch number: 32, Loss: 21003.29296875\n",
      "Epoch: 245, Batch number: 56, Loss: 20795.173828125\n",
      "Epoch: 247, Batch number: 4, Loss: 20345.3984375\n",
      "Epoch: 248, Batch number: 28, Loss: 20618.599609375\n",
      "Epoch: 249, Batch number: 52, Loss: 20943.888671875\n",
      "Epoch: 251, Batch number: 0, Loss: 20943.763671875\n",
      "Epoch: 252, Batch number: 24, Loss: 21154.849609375\n",
      "Epoch: 253, Batch number: 48, Loss: 21032.416015625\n",
      "Epoch: 254, Batch number: 72, Loss: 21083.162109375\n",
      "Epoch: 256, Batch number: 20, Loss: 20769.53125\n",
      "Epoch: 257, Batch number: 44, Loss: 20723.22265625\n",
      "Epoch: 258, Batch number: 68, Loss: 20412.62890625\n",
      "Epoch: 260, Batch number: 16, Loss: 21845.98046875\n",
      "Epoch: 261, Batch number: 40, Loss: 20420.326171875\n",
      "Epoch: 262, Batch number: 64, Loss: 21055.07421875\n",
      "Epoch: 264, Batch number: 12, Loss: 21081.48046875\n",
      "Epoch: 265, Batch number: 36, Loss: 20809.0234375\n",
      "Epoch: 266, Batch number: 60, Loss: 20800.091796875\n",
      "Epoch: 268, Batch number: 8, Loss: 20834.232421875\n",
      "Epoch: 269, Batch number: 32, Loss: 20750.73046875\n",
      "Epoch: 270, Batch number: 56, Loss: 20702.83203125\n",
      "Epoch: 272, Batch number: 4, Loss: 21135.125\n",
      "Epoch: 273, Batch number: 28, Loss: 20412.015625\n",
      "Epoch: 274, Batch number: 52, Loss: 20707.609375\n",
      "Epoch: 276, Batch number: 0, Loss: 20614.412109375\n",
      "Epoch: 277, Batch number: 24, Loss: 20609.220703125\n",
      "Epoch: 278, Batch number: 48, Loss: 20889.57421875\n",
      "Epoch: 279, Batch number: 72, Loss: 21101.16015625\n",
      "Epoch: 281, Batch number: 20, Loss: 20628.796875\n",
      "Epoch: 282, Batch number: 44, Loss: 21141.955078125\n",
      "Epoch: 283, Batch number: 68, Loss: 20687.7578125\n",
      "Epoch: 285, Batch number: 16, Loss: 20185.90625\n",
      "Epoch: 286, Batch number: 40, Loss: 21095.392578125\n",
      "Epoch: 287, Batch number: 64, Loss: 20243.16796875\n",
      "Epoch: 289, Batch number: 12, Loss: 20628.228515625\n",
      "Epoch: 290, Batch number: 36, Loss: 20122.51953125\n",
      "Epoch: 291, Batch number: 60, Loss: 21319.79296875\n",
      "Epoch: 293, Batch number: 8, Loss: 20695.44140625\n",
      "Epoch: 294, Batch number: 32, Loss: 20839.111328125\n",
      "Epoch: 295, Batch number: 56, Loss: 21243.50390625\n",
      "Epoch: 297, Batch number: 4, Loss: 20478.041015625\n",
      "Epoch: 298, Batch number: 28, Loss: 20380.2734375\n",
      "Epoch: 299, Batch number: 52, Loss: 21033.732421875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 39427.33984375\n",
      "Epoch: 2, Batch number: 24, Loss: 35040.984375\n",
      "Epoch: 3, Batch number: 48, Loss: 31941.9765625\n",
      "Epoch: 4, Batch number: 72, Loss: 30665.205078125\n",
      "Epoch: 6, Batch number: 20, Loss: 28788.61328125\n",
      "Epoch: 7, Batch number: 44, Loss: 27985.681640625\n",
      "Epoch: 8, Batch number: 68, Loss: 27082.6015625\n",
      "Epoch: 10, Batch number: 16, Loss: 25750.580078125\n",
      "Epoch: 11, Batch number: 40, Loss: 25402.341796875\n",
      "Epoch: 12, Batch number: 64, Loss: 25232.84375\n",
      "Epoch: 14, Batch number: 12, Loss: 24239.400390625\n",
      "Epoch: 15, Batch number: 36, Loss: 24146.21484375\n",
      "Epoch: 16, Batch number: 60, Loss: 23543.2734375\n",
      "Epoch: 18, Batch number: 8, Loss: 23572.611328125\n",
      "Epoch: 19, Batch number: 32, Loss: 23151.48828125\n",
      "Epoch: 20, Batch number: 56, Loss: 23358.193359375\n",
      "Epoch: 22, Batch number: 4, Loss: 22614.1484375\n",
      "Epoch: 23, Batch number: 28, Loss: 22760.640625\n",
      "Epoch: 24, Batch number: 52, Loss: 22923.607421875\n",
      "Epoch: 26, Batch number: 0, Loss: 22455.73046875\n",
      "Epoch: 27, Batch number: 24, Loss: 22181.478515625\n",
      "Epoch: 28, Batch number: 48, Loss: 23146.828125\n",
      "Epoch: 29, Batch number: 72, Loss: 22941.880859375\n",
      "Epoch: 31, Batch number: 20, Loss: 21714.37890625\n",
      "Epoch: 32, Batch number: 44, Loss: 22054.76171875\n",
      "Epoch: 33, Batch number: 68, Loss: 22248.447265625\n",
      "Epoch: 35, Batch number: 16, Loss: 22505.3828125\n",
      "Epoch: 36, Batch number: 40, Loss: 21873.939453125\n",
      "Epoch: 37, Batch number: 64, Loss: 22697.861328125\n",
      "Epoch: 39, Batch number: 12, Loss: 21725.88671875\n",
      "Epoch: 40, Batch number: 36, Loss: 21980.494140625\n",
      "Epoch: 41, Batch number: 60, Loss: 21805.501953125\n",
      "Epoch: 43, Batch number: 8, Loss: 21644.296875\n",
      "Epoch: 44, Batch number: 32, Loss: 22340.7265625\n",
      "Epoch: 45, Batch number: 56, Loss: 22124.443359375\n",
      "Epoch: 47, Batch number: 4, Loss: 21698.375\n",
      "Epoch: 48, Batch number: 28, Loss: 21543.50390625\n",
      "Epoch: 49, Batch number: 52, Loss: 22127.970703125\n",
      "Epoch: 51, Batch number: 0, Loss: 21939.826171875\n",
      "Epoch: 52, Batch number: 24, Loss: 21303.49609375\n",
      "Epoch: 53, Batch number: 48, Loss: 21858.8828125\n",
      "Epoch: 54, Batch number: 72, Loss: 21771.671875\n",
      "Epoch: 56, Batch number: 20, Loss: 21790.55859375\n",
      "Epoch: 57, Batch number: 44, Loss: 21522.501953125\n",
      "Epoch: 58, Batch number: 68, Loss: 21831.9140625\n",
      "Epoch: 60, Batch number: 16, Loss: 21738.580078125\n",
      "Epoch: 61, Batch number: 40, Loss: 21032.302734375\n",
      "Epoch: 62, Batch number: 64, Loss: 22140.072265625\n",
      "Epoch: 64, Batch number: 12, Loss: 21638.123046875\n",
      "Epoch: 65, Batch number: 36, Loss: 21003.4296875\n",
      "Epoch: 66, Batch number: 60, Loss: 21518.69921875\n",
      "Epoch: 68, Batch number: 8, Loss: 21362.462890625\n",
      "Epoch: 69, Batch number: 32, Loss: 21514.412109375\n",
      "Epoch: 70, Batch number: 56, Loss: 21474.587890625\n",
      "Epoch: 72, Batch number: 4, Loss: 21531.759765625\n",
      "Epoch: 73, Batch number: 28, Loss: 21386.59375\n",
      "Epoch: 74, Batch number: 52, Loss: 21856.548828125\n",
      "Epoch: 76, Batch number: 0, Loss: 20982.189453125\n",
      "Epoch: 77, Batch number: 24, Loss: 20993.47265625\n",
      "Epoch: 78, Batch number: 48, Loss: 21269.5234375\n",
      "Epoch: 79, Batch number: 72, Loss: 21206.130859375\n",
      "Epoch: 81, Batch number: 20, Loss: 21490.4296875\n",
      "Epoch: 82, Batch number: 44, Loss: 22008.53515625\n",
      "Epoch: 83, Batch number: 68, Loss: 21301.5703125\n",
      "Epoch: 85, Batch number: 16, Loss: 21204.115234375\n",
      "Epoch: 86, Batch number: 40, Loss: 21086.498046875\n",
      "Epoch: 87, Batch number: 64, Loss: 21670.908203125\n",
      "Epoch: 89, Batch number: 12, Loss: 20683.326171875\n",
      "Epoch: 90, Batch number: 36, Loss: 21071.427734375\n",
      "Epoch: 91, Batch number: 60, Loss: 21645.865234375\n",
      "Epoch: 93, Batch number: 8, Loss: 21146.451171875\n",
      "Epoch: 94, Batch number: 32, Loss: 21345.513671875\n",
      "Epoch: 95, Batch number: 56, Loss: 21780.69140625\n",
      "Epoch: 97, Batch number: 4, Loss: 21249.73046875\n",
      "Epoch: 98, Batch number: 28, Loss: 20847.94140625\n",
      "Epoch: 99, Batch number: 52, Loss: 21680.455078125\n",
      "Epoch: 101, Batch number: 0, Loss: 20924.37109375\n",
      "Epoch: 102, Batch number: 24, Loss: 21043.912109375\n",
      "Epoch: 103, Batch number: 48, Loss: 20963.3203125\n",
      "Epoch: 104, Batch number: 72, Loss: 21534.32421875\n",
      "Epoch: 106, Batch number: 20, Loss: 20423.18359375\n",
      "Epoch: 107, Batch number: 44, Loss: 21248.83984375\n",
      "Epoch: 108, Batch number: 68, Loss: 21056.994140625\n",
      "Epoch: 110, Batch number: 16, Loss: 20773.3828125\n",
      "Epoch: 111, Batch number: 40, Loss: 21178.951171875\n",
      "Epoch: 112, Batch number: 64, Loss: 21109.80078125\n",
      "Epoch: 114, Batch number: 12, Loss: 20626.498046875\n",
      "Epoch: 115, Batch number: 36, Loss: 21316.021484375\n",
      "Epoch: 116, Batch number: 60, Loss: 21100.541015625\n",
      "Epoch: 118, Batch number: 8, Loss: 20603.2421875\n",
      "Epoch: 119, Batch number: 32, Loss: 21155.935546875\n",
      "Epoch: 120, Batch number: 56, Loss: 21575.994140625\n",
      "Epoch: 122, Batch number: 4, Loss: 20630.05078125\n",
      "Epoch: 123, Batch number: 28, Loss: 20795.822265625\n",
      "Epoch: 124, Batch number: 52, Loss: 21078.30859375\n",
      "Epoch: 126, Batch number: 0, Loss: 20596.78515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127, Batch number: 24, Loss: 20992.53515625\n",
      "Epoch: 128, Batch number: 48, Loss: 20962.91015625\n",
      "Epoch: 129, Batch number: 72, Loss: 21000.939453125\n",
      "Epoch: 131, Batch number: 20, Loss: 20985.759765625\n",
      "Epoch: 132, Batch number: 44, Loss: 20684.5\n",
      "Epoch: 133, Batch number: 68, Loss: 21299.75390625\n",
      "Epoch: 135, Batch number: 16, Loss: 21462.076171875\n",
      "Epoch: 136, Batch number: 40, Loss: 21097.111328125\n",
      "Epoch: 137, Batch number: 64, Loss: 21528.0078125\n",
      "Epoch: 139, Batch number: 12, Loss: 20790.751953125\n",
      "Epoch: 140, Batch number: 36, Loss: 20805.705078125\n",
      "Epoch: 141, Batch number: 60, Loss: 21414.869140625\n",
      "Epoch: 143, Batch number: 8, Loss: 21028.048828125\n",
      "Epoch: 144, Batch number: 32, Loss: 20833.7265625\n",
      "Epoch: 145, Batch number: 56, Loss: 21139.880859375\n",
      "Epoch: 147, Batch number: 4, Loss: 20608.794921875\n",
      "Epoch: 148, Batch number: 28, Loss: 20475.322265625\n",
      "Epoch: 149, Batch number: 52, Loss: 21099.732421875\n",
      "Epoch: 151, Batch number: 0, Loss: 21247.146484375\n",
      "Epoch: 152, Batch number: 24, Loss: 21196.078125\n",
      "Epoch: 153, Batch number: 48, Loss: 21234.908203125\n",
      "Epoch: 154, Batch number: 72, Loss: 20768.41796875\n",
      "Epoch: 156, Batch number: 20, Loss: 20592.423828125\n",
      "Epoch: 157, Batch number: 44, Loss: 20476.669921875\n",
      "Epoch: 158, Batch number: 68, Loss: 21316.591796875\n",
      "Epoch: 160, Batch number: 16, Loss: 20747.10546875\n",
      "Epoch: 161, Batch number: 40, Loss: 21020.697265625\n",
      "Epoch: 162, Batch number: 64, Loss: 21730.107421875\n",
      "Epoch: 164, Batch number: 12, Loss: 21219.36328125\n",
      "Epoch: 165, Batch number: 36, Loss: 20458.033203125\n",
      "Epoch: 166, Batch number: 60, Loss: 20989.060546875\n",
      "Epoch: 168, Batch number: 8, Loss: 20775.623046875\n",
      "Epoch: 169, Batch number: 32, Loss: 20221.748046875\n",
      "Epoch: 170, Batch number: 56, Loss: 20316.10546875\n",
      "Epoch: 172, Batch number: 4, Loss: 20365.220703125\n",
      "Epoch: 173, Batch number: 28, Loss: 20911.474609375\n",
      "Epoch: 174, Batch number: 52, Loss: 20772.40234375\n",
      "Epoch: 176, Batch number: 0, Loss: 20525.455078125\n",
      "Epoch: 177, Batch number: 24, Loss: 20939.6796875\n",
      "Epoch: 178, Batch number: 48, Loss: 21060.57421875\n",
      "Epoch: 179, Batch number: 72, Loss: 21053.927734375\n",
      "Epoch: 181, Batch number: 20, Loss: 21090.25\n",
      "Epoch: 182, Batch number: 44, Loss: 20773.755859375\n",
      "Epoch: 183, Batch number: 68, Loss: 21016.630859375\n",
      "Epoch: 185, Batch number: 16, Loss: 21107.46484375\n",
      "Epoch: 186, Batch number: 40, Loss: 20900.259765625\n",
      "Epoch: 187, Batch number: 64, Loss: 20674.837890625\n",
      "Epoch: 189, Batch number: 12, Loss: 20812.80078125\n",
      "Epoch: 190, Batch number: 36, Loss: 21342.66015625\n",
      "Epoch: 191, Batch number: 60, Loss: 20222.244140625\n",
      "Epoch: 193, Batch number: 8, Loss: 21117.048828125\n",
      "Epoch: 194, Batch number: 32, Loss: 20733.662109375\n",
      "Epoch: 195, Batch number: 56, Loss: 20475.20703125\n",
      "Epoch: 197, Batch number: 4, Loss: 20943.03125\n",
      "Epoch: 198, Batch number: 28, Loss: 21067.330078125\n",
      "Epoch: 199, Batch number: 52, Loss: 20696.046875\n",
      "Epoch: 201, Batch number: 0, Loss: 20571.09765625\n",
      "Epoch: 202, Batch number: 24, Loss: 20650.958984375\n",
      "Epoch: 203, Batch number: 48, Loss: 20644.68359375\n",
      "Epoch: 204, Batch number: 72, Loss: 20872.736328125\n",
      "Epoch: 206, Batch number: 20, Loss: 20975.263671875\n",
      "Epoch: 207, Batch number: 44, Loss: 20987.3515625\n",
      "Epoch: 208, Batch number: 68, Loss: 20941.826171875\n",
      "Epoch: 210, Batch number: 16, Loss: 21347.50390625\n",
      "Epoch: 211, Batch number: 40, Loss: 20653.44921875\n",
      "Epoch: 212, Batch number: 64, Loss: 20428.62109375\n",
      "Epoch: 214, Batch number: 12, Loss: 20792.259765625\n",
      "Epoch: 215, Batch number: 36, Loss: 20765.63671875\n",
      "Epoch: 216, Batch number: 60, Loss: 21183.21484375\n",
      "Epoch: 218, Batch number: 8, Loss: 20616.029296875\n",
      "Epoch: 219, Batch number: 32, Loss: 20974.33203125\n",
      "Epoch: 220, Batch number: 56, Loss: 20714.63671875\n",
      "Epoch: 222, Batch number: 4, Loss: 20564.779296875\n",
      "Epoch: 223, Batch number: 28, Loss: 20388.376953125\n",
      "Epoch: 224, Batch number: 52, Loss: 21229.41015625\n",
      "Epoch: 226, Batch number: 0, Loss: 21147.119140625\n",
      "Epoch: 227, Batch number: 24, Loss: 21123.798828125\n",
      "Epoch: 228, Batch number: 48, Loss: 20864.08203125\n",
      "Epoch: 229, Batch number: 72, Loss: 21169.9375\n",
      "Epoch: 231, Batch number: 20, Loss: 20371.359375\n",
      "Epoch: 232, Batch number: 44, Loss: 20697.677734375\n",
      "Epoch: 233, Batch number: 68, Loss: 21375.01953125\n",
      "Epoch: 235, Batch number: 16, Loss: 20646.25390625\n",
      "Epoch: 236, Batch number: 40, Loss: 21341.9296875\n",
      "Epoch: 237, Batch number: 64, Loss: 20649.822265625\n",
      "Epoch: 239, Batch number: 12, Loss: 19566.2265625\n",
      "Epoch: 240, Batch number: 36, Loss: 20339.078125\n",
      "Epoch: 241, Batch number: 60, Loss: 20714.947265625\n",
      "Epoch: 243, Batch number: 8, Loss: 20767.556640625\n",
      "Epoch: 244, Batch number: 32, Loss: 21613.154296875\n",
      "Epoch: 245, Batch number: 56, Loss: 20491.142578125\n",
      "Epoch: 247, Batch number: 4, Loss: 21006.2265625\n",
      "Epoch: 248, Batch number: 28, Loss: 20351.42578125\n",
      "Epoch: 249, Batch number: 52, Loss: 21048.833984375\n",
      "Epoch: 251, Batch number: 0, Loss: 20949.126953125\n",
      "Epoch: 252, Batch number: 24, Loss: 20834.40234375\n",
      "Epoch: 253, Batch number: 48, Loss: 21005.638671875\n",
      "Epoch: 254, Batch number: 72, Loss: 21209.255859375\n",
      "Epoch: 256, Batch number: 20, Loss: 20765.62109375\n",
      "Epoch: 257, Batch number: 44, Loss: 20928.345703125\n",
      "Epoch: 258, Batch number: 68, Loss: 21140.4296875\n",
      "Epoch: 260, Batch number: 16, Loss: 20825.134765625\n",
      "Epoch: 261, Batch number: 40, Loss: 20853.640625\n",
      "Epoch: 262, Batch number: 64, Loss: 20782.255859375\n",
      "Epoch: 264, Batch number: 12, Loss: 20987.505859375\n",
      "Epoch: 265, Batch number: 36, Loss: 20556.287109375\n",
      "Epoch: 266, Batch number: 60, Loss: 20813.640625\n",
      "Epoch: 268, Batch number: 8, Loss: 21023.482421875\n",
      "Epoch: 269, Batch number: 32, Loss: 20711.740234375\n",
      "Epoch: 270, Batch number: 56, Loss: 20985.482421875\n",
      "Epoch: 272, Batch number: 4, Loss: 20980.310546875\n",
      "Epoch: 273, Batch number: 28, Loss: 20926.533203125\n",
      "Epoch: 274, Batch number: 52, Loss: 20798.27734375\n",
      "Epoch: 276, Batch number: 0, Loss: 20826.748046875\n",
      "Epoch: 277, Batch number: 24, Loss: 21111.884765625\n",
      "Epoch: 278, Batch number: 48, Loss: 20769.7578125\n",
      "Epoch: 279, Batch number: 72, Loss: 21319.931640625\n",
      "Epoch: 281, Batch number: 20, Loss: 20561.732421875\n",
      "Epoch: 282, Batch number: 44, Loss: 20525.8125\n",
      "Epoch: 283, Batch number: 68, Loss: 20939.56640625\n",
      "Epoch: 285, Batch number: 16, Loss: 21194.158203125\n",
      "Epoch: 286, Batch number: 40, Loss: 21323.552734375\n",
      "Epoch: 287, Batch number: 64, Loss: 21116.333984375\n",
      "Epoch: 289, Batch number: 12, Loss: 20293.267578125\n",
      "Epoch: 290, Batch number: 36, Loss: 20930.326171875\n",
      "Epoch: 291, Batch number: 60, Loss: 20367.525390625\n",
      "Epoch: 293, Batch number: 8, Loss: 21450.58203125\n",
      "Epoch: 294, Batch number: 32, Loss: 20575.275390625\n",
      "Epoch: 295, Batch number: 56, Loss: 21055.298828125\n",
      "Epoch: 297, Batch number: 4, Loss: 20418.171875\n",
      "Epoch: 298, Batch number: 28, Loss: 20706.228515625\n",
      "Epoch: 299, Batch number: 52, Loss: 20811.076171875\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'Adam'\n",
    "epochs = 300\n",
    "sample_loss_every = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "for trainer_list in sk_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"900\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2fc9cf9b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (9., 9.)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# for trainer_list in sk_trainers:\n",
    "#     for trainer in trainer_list:\n",
    "#         ax.plot(trainer.loss_history['iter'],trainer.loss_history['loss'],\n",
    "#                 label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))\n",
    "# ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for trainer in sk_trainers[0]:\n",
    "    ax.plot(trainer.loss_history['iter'],trainer.loss_history['loss'],\n",
    "            label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 10\n",
      "Vocabulary Size: 2\n",
      "Number of batches: 1\n",
      "Number of samples per batch: 64\n",
      "\n",
      "Dispositivo seleccionado: cpu\n",
      "Dimensión del espacio de los embeddings: 10\n"
     ]
    }
   ],
   "source": [
    "#corpus = [['w1', 'w2', 'w3', 'w4'], ['w1', 'w3', 'w3', 'w3'], ['w1'], ['w1', 'w2', 'w3', 'w4', 'w1', 'w2', 'w3', 'w4']]\n",
    "corpus = GetTrainCorpus('./promptsl40.train')\n",
    "cutoff_freq = 0\n",
    "window_size_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "batch_size = 512\n",
    "\n",
    "state_dict = None\n",
    "device = 'cuda:1'\n",
    "paralelize = False\n",
    "embedding_dim_list = [50, 100, 150, 200, 300, 400]\n",
    "\n",
    "cbow_trainers = []\n",
    "for window_size in window_size_list:\n",
    "    embedding_dim_trainers = []\n",
    "    for embedding_dim in embedding_dim_list:\n",
    "        cbow_trainer = CBOWTrainer(corpus, cutoff_freq, window_size, batch_size)\n",
    "        cbow_trainer.InitModel(state_dict=state_dict, device=device, paralelize=paralelize, embedding_dim=embedding_dim)\n",
    "        embedding_dim_trainers.append(cbow_trainer)\n",
    "    cbow_trainers.append(embedding_dim_trainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Optimization method: SGD\n",
      "Learning Rate: 0.001\n",
      "Number of epochs: 1\n",
      "Running on device (cpu)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 7.79583740234375\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'Adam'\n",
    "epochs = 300\n",
    "sample_loss_every = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "for trainer_list in cbow_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANTE:\n",
    "\n",
    "1. Hicimos un modelo de lenguaje baseline con la instrucción `HBuild -s '<s>' '</s>' vocab wdnet_baseline`\n",
    "\n",
    "2. Hicimos un modelo de lenguaje frecuentista con `ngram-count` y `HBuild` de la siguiente manera:\n",
    "```\n",
    "export LC_CTYPE=ISO_8859_1\n",
    "awk '{for(i=2;i<=NF;i++){printf \"%s \", $i} printf \"\\n\"}' ../etc/promptsl40.train > trainLM.txt\n",
    "/usr/local/speechapp/srilm/bin/i686-m64/ngram-count -order 2 -text trainLM.txt -lm lm_freq -ukndiscount2 -vocab vocab\n",
    "HBuild -n lm_freq -s '<s>' '</s>' vocab wdnet\n",
    "```\n",
    "\n",
    "`vocab` fue generado como `cat ../etc/promptsl40.test | awk '{for(i=2;i<=NF;i++){print $i}}'| sort | uniq > vocab` y agregando manualmente `<s>` y `</s>`. \n",
    "\n",
    "3. Hicimos un modelo de lenguaje para cada uno de los entrenamientos de word-vectors. Los parámetros que se modificaron fueron cbow/sk, window size y embedding dim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con Wikipedia y las frases de train de L40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANTE:\n",
    "\n",
    "Probar con ed= 50, 100, 200, 300, 400 y con windows size bajos (ws = 1, 2, 3, 4) y con skipgram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = GetTrainCorpus('./promptsl40.train')\n",
    "with open('wiki', 'r') as wikifile:\n",
    "    corpus = [corpus[0] + wikifile.read().split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 4396714\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8588\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 4396714\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8588\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 4396714\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8588\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 4396714\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8588\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 4413495\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8621\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 4413495\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8621\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 4413495\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8621\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 4413495\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8621\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 4414375\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8622\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 4414375\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8622\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 4414375\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8622\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 4414375\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8622\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 4414541\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8623\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 4414541\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8623\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 4414541\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8623\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 4414541\n",
      "Vocabulary Size: 53277\n",
      "Number of batches: 8623\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 10968.919921875\n",
      "Epoch: 1, Batch number: 100, Loss: 10725.64453125\n",
      "Epoch: 1, Batch number: 200, Loss: 10595.3916015625\n",
      "Epoch: 1, Batch number: 300, Loss: 10244.736328125\n",
      "Epoch: 1, Batch number: 400, Loss: 10139.255859375\n",
      "Epoch: 1, Batch number: 500, Loss: 9973.279296875\n",
      "Epoch: 1, Batch number: 600, Loss: 9822.1396484375\n",
      "Epoch: 1, Batch number: 700, Loss: 9618.1015625\n",
      "Epoch: 1, Batch number: 800, Loss: 9318.2275390625\n",
      "Epoch: 1, Batch number: 900, Loss: 9219.0703125\n",
      "Epoch: 1, Batch number: 1000, Loss: 9099.3759765625\n",
      "Epoch: 1, Batch number: 1100, Loss: 9004.865234375\n",
      "Epoch: 1, Batch number: 1200, Loss: 8882.5078125\n",
      "Epoch: 1, Batch number: 1300, Loss: 8704.7021484375\n",
      "Epoch: 1, Batch number: 1400, Loss: 8834.384765625\n",
      "Epoch: 1, Batch number: 1500, Loss: 8752.705078125\n",
      "Epoch: 1, Batch number: 1600, Loss: 8552.1689453125\n",
      "Epoch: 1, Batch number: 1700, Loss: 8461.5654296875\n",
      "Epoch: 1, Batch number: 1800, Loss: 8218.4912109375\n",
      "Epoch: 1, Batch number: 1900, Loss: 8388.201171875\n",
      "Epoch: 1, Batch number: 2000, Loss: 8442.6572265625\n",
      "Epoch: 1, Batch number: 2100, Loss: 8156.54833984375\n",
      "Epoch: 1, Batch number: 2200, Loss: 8158.4912109375\n",
      "Epoch: 1, Batch number: 2300, Loss: 8064.16259765625\n",
      "Epoch: 1, Batch number: 2400, Loss: 7887.7275390625\n",
      "Epoch: 1, Batch number: 2500, Loss: 8093.25830078125\n",
      "Epoch: 1, Batch number: 2600, Loss: 7813.66845703125\n",
      "Epoch: 1, Batch number: 2700, Loss: 7765.18701171875\n",
      "Epoch: 1, Batch number: 2800, Loss: 7866.6396484375\n",
      "Epoch: 1, Batch number: 2900, Loss: 7854.0986328125\n",
      "Epoch: 1, Batch number: 3000, Loss: 7852.1640625\n",
      "Epoch: 1, Batch number: 3100, Loss: 7675.8271484375\n",
      "Epoch: 1, Batch number: 3200, Loss: 7852.60107421875\n",
      "Epoch: 1, Batch number: 3300, Loss: 7699.33642578125\n",
      "Epoch: 1, Batch number: 3400, Loss: 7643.2080078125\n",
      "Epoch: 1, Batch number: 3500, Loss: 7588.9228515625\n",
      "Epoch: 1, Batch number: 3600, Loss: 7469.52783203125\n",
      "Epoch: 1, Batch number: 3700, Loss: 7693.77392578125\n",
      "Epoch: 1, Batch number: 3800, Loss: 7659.07763671875\n",
      "Epoch: 1, Batch number: 3900, Loss: 7475.22021484375\n",
      "Epoch: 1, Batch number: 4000, Loss: 7533.732421875\n",
      "Epoch: 1, Batch number: 4100, Loss: 7572.87109375\n",
      "Epoch: 1, Batch number: 4200, Loss: 7495.75732421875\n",
      "Epoch: 1, Batch number: 4300, Loss: 7636.7451171875\n",
      "Epoch: 1, Batch number: 4400, Loss: 7451.89453125\n",
      "Epoch: 1, Batch number: 4500, Loss: 7465.93505859375\n",
      "Epoch: 1, Batch number: 4600, Loss: 7344.28564453125\n",
      "Epoch: 1, Batch number: 4700, Loss: 7305.93408203125\n",
      "Epoch: 1, Batch number: 4800, Loss: 7168.9111328125\n",
      "Epoch: 1, Batch number: 4900, Loss: 7401.970703125\n",
      "Epoch: 1, Batch number: 5000, Loss: 7510.59326171875\n",
      "Epoch: 1, Batch number: 5100, Loss: 7385.443359375\n",
      "Epoch: 1, Batch number: 5200, Loss: 7276.2275390625\n",
      "Epoch: 1, Batch number: 5300, Loss: 7224.44140625\n",
      "Epoch: 1, Batch number: 5400, Loss: 7119.50732421875\n",
      "Epoch: 1, Batch number: 5500, Loss: 7184.7080078125\n",
      "Epoch: 1, Batch number: 5600, Loss: 7129.8994140625\n",
      "Epoch: 1, Batch number: 5700, Loss: 7487.8310546875\n",
      "Epoch: 1, Batch number: 5800, Loss: 7167.6669921875\n",
      "Epoch: 1, Batch number: 5900, Loss: 7188.8447265625\n",
      "Epoch: 1, Batch number: 6000, Loss: 7173.78759765625\n",
      "Epoch: 1, Batch number: 6100, Loss: 7045.2626953125\n",
      "Epoch: 1, Batch number: 6200, Loss: 6991.7080078125\n",
      "Epoch: 1, Batch number: 6300, Loss: 7289.8740234375\n",
      "Epoch: 1, Batch number: 6400, Loss: 7364.37353515625\n",
      "Epoch: 1, Batch number: 6500, Loss: 6917.732421875\n",
      "Epoch: 1, Batch number: 6600, Loss: 7032.13623046875\n",
      "Epoch: 1, Batch number: 6700, Loss: 7055.60498046875\n",
      "Epoch: 1, Batch number: 6800, Loss: 7400.4091796875\n",
      "Epoch: 1, Batch number: 6900, Loss: 7233.3955078125\n",
      "Epoch: 1, Batch number: 7000, Loss: 7242.69140625\n",
      "Epoch: 1, Batch number: 7100, Loss: 7091.51904296875\n",
      "Epoch: 1, Batch number: 7200, Loss: 7306.26123046875\n",
      "Epoch: 1, Batch number: 7300, Loss: 6967.60595703125\n",
      "Epoch: 1, Batch number: 7400, Loss: 6981.08447265625\n",
      "Epoch: 1, Batch number: 7500, Loss: 7035.95556640625\n",
      "Epoch: 1, Batch number: 7600, Loss: 6923.7490234375\n",
      "Epoch: 1, Batch number: 7700, Loss: 7132.1337890625\n",
      "Epoch: 1, Batch number: 7800, Loss: 7059.31982421875\n",
      "Epoch: 1, Batch number: 7900, Loss: 7034.353515625\n",
      "Epoch: 1, Batch number: 8000, Loss: 7086.4599609375\n",
      "Epoch: 1, Batch number: 8100, Loss: 6896.701171875\n",
      "Epoch: 1, Batch number: 8200, Loss: 7073.64501953125\n",
      "Epoch: 1, Batch number: 8300, Loss: 6969.66455078125\n",
      "Epoch: 1, Batch number: 8400, Loss: 7052.23388671875\n",
      "Epoch: 1, Batch number: 8500, Loss: 7113.59716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 12, Loss: 6894.99755859375\n",
      "Epoch: 2, Batch number: 112, Loss: 6933.58154296875\n",
      "Epoch: 2, Batch number: 212, Loss: 6967.2724609375\n",
      "Epoch: 2, Batch number: 312, Loss: 6877.908203125\n",
      "Epoch: 2, Batch number: 412, Loss: 6861.57861328125\n",
      "Epoch: 2, Batch number: 512, Loss: 6833.83447265625\n",
      "Epoch: 2, Batch number: 612, Loss: 6922.453125\n",
      "Epoch: 2, Batch number: 712, Loss: 6993.90185546875\n",
      "Epoch: 2, Batch number: 812, Loss: 6879.76513671875\n",
      "Epoch: 2, Batch number: 912, Loss: 6962.74267578125\n",
      "Epoch: 2, Batch number: 1012, Loss: 6676.07763671875\n",
      "Epoch: 2, Batch number: 1112, Loss: 6704.89111328125\n",
      "Epoch: 2, Batch number: 1212, Loss: 7024.58349609375\n",
      "Epoch: 2, Batch number: 1312, Loss: 6834.54638671875\n",
      "Epoch: 2, Batch number: 1412, Loss: 6961.58642578125\n",
      "Epoch: 2, Batch number: 1512, Loss: 6914.6494140625\n",
      "Epoch: 2, Batch number: 1612, Loss: 6928.099609375\n",
      "Epoch: 2, Batch number: 1712, Loss: 6752.64892578125\n",
      "Epoch: 2, Batch number: 1812, Loss: 6708.3115234375\n",
      "Epoch: 2, Batch number: 1912, Loss: 6732.02880859375\n",
      "Epoch: 2, Batch number: 2012, Loss: 6874.341796875\n",
      "Epoch: 2, Batch number: 2112, Loss: 6746.93603515625\n",
      "Epoch: 2, Batch number: 2212, Loss: 6816.9638671875\n",
      "Epoch: 2, Batch number: 2312, Loss: 6750.04052734375\n",
      "Epoch: 2, Batch number: 2412, Loss: 6830.93212890625\n",
      "Epoch: 2, Batch number: 2512, Loss: 6909.79296875\n",
      "Epoch: 2, Batch number: 2612, Loss: 6957.25830078125\n",
      "Epoch: 2, Batch number: 2712, Loss: 6723.240234375\n",
      "Epoch: 2, Batch number: 2812, Loss: 6722.3994140625\n",
      "Epoch: 2, Batch number: 2912, Loss: 6787.56005859375\n",
      "Epoch: 2, Batch number: 3012, Loss: 6780.791015625\n",
      "Epoch: 2, Batch number: 3112, Loss: 6942.68115234375\n",
      "Epoch: 2, Batch number: 3212, Loss: 7026.87841796875\n",
      "Epoch: 2, Batch number: 3312, Loss: 6970.173828125\n",
      "Epoch: 2, Batch number: 3412, Loss: 6797.64208984375\n",
      "Epoch: 2, Batch number: 3512, Loss: 6809.79345703125\n",
      "Epoch: 2, Batch number: 3612, Loss: 6805.34130859375\n",
      "Epoch: 2, Batch number: 3712, Loss: 6726.162109375\n",
      "Epoch: 2, Batch number: 3812, Loss: 6840.93896484375\n",
      "Epoch: 2, Batch number: 3912, Loss: 6690.38427734375\n",
      "Epoch: 2, Batch number: 4012, Loss: 6819.3857421875\n",
      "Epoch: 2, Batch number: 4112, Loss: 6908.39306640625\n",
      "Epoch: 2, Batch number: 4212, Loss: 6787.21728515625\n",
      "Epoch: 2, Batch number: 4312, Loss: 6525.65966796875\n",
      "Epoch: 2, Batch number: 4412, Loss: 6764.87109375\n",
      "Epoch: 2, Batch number: 4512, Loss: 6689.17724609375\n",
      "Epoch: 2, Batch number: 4612, Loss: 6833.615234375\n",
      "Epoch: 2, Batch number: 4712, Loss: 6612.390625\n",
      "Epoch: 2, Batch number: 4812, Loss: 6761.51171875\n",
      "Epoch: 2, Batch number: 4912, Loss: 6778.92724609375\n",
      "Epoch: 2, Batch number: 5012, Loss: 6757.23193359375\n",
      "Epoch: 2, Batch number: 5112, Loss: 6789.4619140625\n",
      "Epoch: 2, Batch number: 5212, Loss: 6939.64208984375\n",
      "Epoch: 2, Batch number: 5312, Loss: 6743.09130859375\n",
      "Epoch: 2, Batch number: 5412, Loss: 6633.54052734375\n",
      "Epoch: 2, Batch number: 5512, Loss: 6845.99609375\n",
      "Epoch: 2, Batch number: 5612, Loss: 7037.93115234375\n",
      "Epoch: 2, Batch number: 5712, Loss: 6560.720703125\n",
      "Epoch: 2, Batch number: 5812, Loss: 6669.44921875\n",
      "Epoch: 2, Batch number: 5912, Loss: 6704.61083984375\n",
      "Epoch: 2, Batch number: 6012, Loss: 6749.03564453125\n",
      "Epoch: 2, Batch number: 6112, Loss: 6700.64111328125\n",
      "Epoch: 2, Batch number: 6212, Loss: 6764.767578125\n",
      "Epoch: 2, Batch number: 6312, Loss: 6867.15576171875\n",
      "Epoch: 2, Batch number: 6412, Loss: 6773.64306640625\n",
      "Epoch: 2, Batch number: 6512, Loss: 6719.7041015625\n",
      "Epoch: 2, Batch number: 6612, Loss: 6870.04736328125\n",
      "Epoch: 2, Batch number: 6712, Loss: 6631.716796875\n",
      "Epoch: 2, Batch number: 6812, Loss: 6678.4755859375\n",
      "Epoch: 2, Batch number: 6912, Loss: 6817.994140625\n",
      "Epoch: 2, Batch number: 7012, Loss: 6536.029296875\n",
      "Epoch: 2, Batch number: 7112, Loss: 6535.1943359375\n",
      "Epoch: 2, Batch number: 7212, Loss: 6975.47705078125\n",
      "Epoch: 2, Batch number: 7312, Loss: 6808.951171875\n",
      "Epoch: 2, Batch number: 7412, Loss: 6747.47900390625\n",
      "Epoch: 2, Batch number: 7512, Loss: 6639.408203125\n",
      "Epoch: 2, Batch number: 7612, Loss: 6508.31201171875\n",
      "Epoch: 2, Batch number: 7712, Loss: 6643.90087890625\n",
      "Epoch: 2, Batch number: 7812, Loss: 6782.54638671875\n",
      "Epoch: 2, Batch number: 7912, Loss: 6755.49609375\n",
      "Epoch: 2, Batch number: 8012, Loss: 6780.62109375\n",
      "Epoch: 2, Batch number: 8112, Loss: 6567.1083984375\n",
      "Epoch: 2, Batch number: 8212, Loss: 6812.587890625\n",
      "Epoch: 2, Batch number: 8312, Loss: 6680.8583984375\n",
      "Epoch: 2, Batch number: 8412, Loss: 6675.98388671875\n",
      "Epoch: 2, Batch number: 8512, Loss: 6681.490234375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 10837.509765625\n",
      "Epoch: 1, Batch number: 100, Loss: 10349.3876953125\n",
      "Epoch: 1, Batch number: 200, Loss: 10306.5517578125\n",
      "Epoch: 1, Batch number: 300, Loss: 9817.2998046875\n",
      "Epoch: 1, Batch number: 400, Loss: 9631.3232421875\n",
      "Epoch: 1, Batch number: 500, Loss: 9448.7451171875\n",
      "Epoch: 1, Batch number: 600, Loss: 9303.9736328125\n",
      "Epoch: 1, Batch number: 700, Loss: 9200.1416015625\n",
      "Epoch: 1, Batch number: 800, Loss: 9101.6357421875\n",
      "Epoch: 1, Batch number: 900, Loss: 8994.455078125\n",
      "Epoch: 1, Batch number: 1000, Loss: 8741.7919921875\n",
      "Epoch: 1, Batch number: 1100, Loss: 8672.7373046875\n",
      "Epoch: 1, Batch number: 1200, Loss: 8490.90625\n",
      "Epoch: 1, Batch number: 1300, Loss: 8642.2021484375\n",
      "Epoch: 1, Batch number: 1400, Loss: 7919.4716796875\n",
      "Epoch: 1, Batch number: 1500, Loss: 8154.58056640625\n",
      "Epoch: 1, Batch number: 1600, Loss: 8027.92041015625\n",
      "Epoch: 1, Batch number: 1700, Loss: 8114.7529296875\n",
      "Epoch: 1, Batch number: 1800, Loss: 7885.0556640625\n",
      "Epoch: 1, Batch number: 1900, Loss: 7916.39111328125\n",
      "Epoch: 1, Batch number: 2000, Loss: 7978.8662109375\n",
      "Epoch: 1, Batch number: 2100, Loss: 7893.99951171875\n",
      "Epoch: 1, Batch number: 2200, Loss: 7918.275390625\n",
      "Epoch: 1, Batch number: 2300, Loss: 7715.88427734375\n",
      "Epoch: 1, Batch number: 2400, Loss: 7578.14404296875\n",
      "Epoch: 1, Batch number: 2500, Loss: 7584.21826171875\n",
      "Epoch: 1, Batch number: 2600, Loss: 7576.92236328125\n",
      "Epoch: 1, Batch number: 2700, Loss: 7369.3466796875\n",
      "Epoch: 1, Batch number: 2800, Loss: 7383.99609375\n",
      "Epoch: 1, Batch number: 2900, Loss: 7508.41259765625\n",
      "Epoch: 1, Batch number: 3000, Loss: 7594.5576171875\n",
      "Epoch: 1, Batch number: 3100, Loss: 7695.2666015625\n",
      "Epoch: 1, Batch number: 3200, Loss: 7313.66455078125\n",
      "Epoch: 1, Batch number: 3300, Loss: 7217.05078125\n",
      "Epoch: 1, Batch number: 3400, Loss: 7211.63720703125\n",
      "Epoch: 1, Batch number: 3500, Loss: 7484.27490234375\n",
      "Epoch: 1, Batch number: 3600, Loss: 7266.29248046875\n",
      "Epoch: 1, Batch number: 3700, Loss: 7259.52880859375\n",
      "Epoch: 1, Batch number: 3800, Loss: 6986.37255859375\n",
      "Epoch: 1, Batch number: 3900, Loss: 7151.03125\n",
      "Epoch: 1, Batch number: 4000, Loss: 6956.95703125\n",
      "Epoch: 1, Batch number: 4100, Loss: 7549.9892578125\n",
      "Epoch: 1, Batch number: 4200, Loss: 7154.18603515625\n",
      "Epoch: 1, Batch number: 4300, Loss: 7050.27783203125\n",
      "Epoch: 1, Batch number: 4400, Loss: 7264.537109375\n",
      "Epoch: 1, Batch number: 4500, Loss: 7078.55908203125\n",
      "Epoch: 1, Batch number: 4600, Loss: 7094.67724609375\n",
      "Epoch: 1, Batch number: 4700, Loss: 7099.38134765625\n",
      "Epoch: 1, Batch number: 4800, Loss: 7340.6005859375\n",
      "Epoch: 1, Batch number: 4900, Loss: 6863.0419921875\n",
      "Epoch: 1, Batch number: 5000, Loss: 7224.39990234375\n",
      "Epoch: 1, Batch number: 5100, Loss: 6923.8857421875\n",
      "Epoch: 1, Batch number: 5200, Loss: 7100.0693359375\n",
      "Epoch: 1, Batch number: 5300, Loss: 6970.24853515625\n",
      "Epoch: 1, Batch number: 5400, Loss: 7138.19287109375\n",
      "Epoch: 1, Batch number: 5500, Loss: 7005.77001953125\n",
      "Epoch: 1, Batch number: 5600, Loss: 7099.74365234375\n",
      "Epoch: 1, Batch number: 5700, Loss: 6739.47705078125\n",
      "Epoch: 1, Batch number: 5800, Loss: 6900.96630859375\n",
      "Epoch: 1, Batch number: 5900, Loss: 7105.26171875\n",
      "Epoch: 1, Batch number: 6000, Loss: 7075.880859375\n",
      "Epoch: 1, Batch number: 6100, Loss: 6902.1513671875\n",
      "Epoch: 1, Batch number: 6200, Loss: 6615.21923828125\n",
      "Epoch: 1, Batch number: 6300, Loss: 6690.60400390625\n",
      "Epoch: 1, Batch number: 6400, Loss: 6879.53369140625\n",
      "Epoch: 1, Batch number: 6500, Loss: 6878.921875\n",
      "Epoch: 1, Batch number: 6600, Loss: 6880.802734375\n",
      "Epoch: 1, Batch number: 6700, Loss: 6945.09521484375\n",
      "Epoch: 1, Batch number: 6800, Loss: 7014.36669921875\n",
      "Epoch: 1, Batch number: 6900, Loss: 6931.42431640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 7000, Loss: 6709.99267578125\n",
      "Epoch: 1, Batch number: 7100, Loss: 6739.166015625\n",
      "Epoch: 1, Batch number: 7200, Loss: 6758.20166015625\n",
      "Epoch: 1, Batch number: 7300, Loss: 6630.3642578125\n",
      "Epoch: 1, Batch number: 7400, Loss: 6720.04736328125\n",
      "Epoch: 1, Batch number: 7500, Loss: 6716.56689453125\n",
      "Epoch: 1, Batch number: 7600, Loss: 6625.98388671875\n",
      "Epoch: 1, Batch number: 7700, Loss: 6782.81884765625\n",
      "Epoch: 1, Batch number: 7800, Loss: 6818.36767578125\n",
      "Epoch: 1, Batch number: 7900, Loss: 6767.86328125\n",
      "Epoch: 1, Batch number: 8000, Loss: 6919.2294921875\n",
      "Epoch: 1, Batch number: 8100, Loss: 6736.4453125\n",
      "Epoch: 1, Batch number: 8200, Loss: 6880.1953125\n",
      "Epoch: 1, Batch number: 8300, Loss: 6742.24267578125\n",
      "Epoch: 1, Batch number: 8400, Loss: 6595.46826171875\n",
      "Epoch: 1, Batch number: 8500, Loss: 6882.59228515625\n",
      "Epoch: 2, Batch number: 12, Loss: 6620.2939453125\n",
      "Epoch: 2, Batch number: 112, Loss: 6754.7314453125\n",
      "Epoch: 2, Batch number: 212, Loss: 6566.4833984375\n",
      "Epoch: 2, Batch number: 312, Loss: 6960.361328125\n",
      "Epoch: 2, Batch number: 412, Loss: 6814.2392578125\n",
      "Epoch: 2, Batch number: 512, Loss: 6443.88525390625\n",
      "Epoch: 2, Batch number: 612, Loss: 6773.2529296875\n",
      "Epoch: 2, Batch number: 712, Loss: 6662.2255859375\n",
      "Epoch: 2, Batch number: 812, Loss: 6792.3134765625\n",
      "Epoch: 2, Batch number: 912, Loss: 6779.3037109375\n",
      "Epoch: 2, Batch number: 1012, Loss: 6559.83203125\n",
      "Epoch: 2, Batch number: 1112, Loss: 6584.4609375\n",
      "Epoch: 2, Batch number: 1212, Loss: 6808.71044921875\n",
      "Epoch: 2, Batch number: 1312, Loss: 6714.333984375\n",
      "Epoch: 2, Batch number: 1412, Loss: 6410.62109375\n",
      "Epoch: 2, Batch number: 1512, Loss: 6654.92138671875\n",
      "Epoch: 2, Batch number: 1612, Loss: 6670.34619140625\n",
      "Epoch: 2, Batch number: 1712, Loss: 6564.66796875\n",
      "Epoch: 2, Batch number: 1812, Loss: 6782.54248046875\n",
      "Epoch: 2, Batch number: 1912, Loss: 6714.13623046875\n",
      "Epoch: 2, Batch number: 2012, Loss: 6650.62109375\n",
      "Epoch: 2, Batch number: 2112, Loss: 6451.62890625\n",
      "Epoch: 2, Batch number: 2212, Loss: 6687.712890625\n",
      "Epoch: 2, Batch number: 2312, Loss: 6389.75146484375\n",
      "Epoch: 2, Batch number: 2412, Loss: 6527.05029296875\n",
      "Epoch: 2, Batch number: 2512, Loss: 6569.00048828125\n",
      "Epoch: 2, Batch number: 2612, Loss: 6427.68359375\n",
      "Epoch: 2, Batch number: 2712, Loss: 6612.40966796875\n",
      "Epoch: 2, Batch number: 2812, Loss: 6703.93359375\n",
      "Epoch: 2, Batch number: 2912, Loss: 6560.92724609375\n",
      "Epoch: 2, Batch number: 3012, Loss: 6558.615234375\n",
      "Epoch: 2, Batch number: 3112, Loss: 6545.47412109375\n",
      "Epoch: 2, Batch number: 3212, Loss: 6628.2431640625\n",
      "Epoch: 2, Batch number: 3312, Loss: 6869.40771484375\n",
      "Epoch: 2, Batch number: 3412, Loss: 6478.3525390625\n",
      "Epoch: 2, Batch number: 3512, Loss: 6683.146484375\n",
      "Epoch: 2, Batch number: 3612, Loss: 6585.2958984375\n",
      "Epoch: 2, Batch number: 3712, Loss: 6524.31201171875\n",
      "Epoch: 2, Batch number: 3812, Loss: 6622.60546875\n",
      "Epoch: 2, Batch number: 3912, Loss: 6663.8203125\n",
      "Epoch: 2, Batch number: 4012, Loss: 6717.6142578125\n",
      "Epoch: 2, Batch number: 4112, Loss: 6399.2890625\n",
      "Epoch: 2, Batch number: 4212, Loss: 6705.94384765625\n",
      "Epoch: 2, Batch number: 4312, Loss: 6465.7236328125\n",
      "Epoch: 2, Batch number: 4412, Loss: 6622.75048828125\n",
      "Epoch: 2, Batch number: 4512, Loss: 6543.8427734375\n",
      "Epoch: 2, Batch number: 4612, Loss: 6582.169921875\n",
      "Epoch: 2, Batch number: 4712, Loss: 6357.60302734375\n",
      "Epoch: 2, Batch number: 4812, Loss: 6651.92724609375\n",
      "Epoch: 2, Batch number: 4912, Loss: 6366.80517578125\n",
      "Epoch: 2, Batch number: 5012, Loss: 6569.0947265625\n",
      "Epoch: 2, Batch number: 5112, Loss: 6556.2626953125\n",
      "Epoch: 2, Batch number: 5212, Loss: 6600.75732421875\n",
      "Epoch: 2, Batch number: 5312, Loss: 6441.89111328125\n",
      "Epoch: 2, Batch number: 5412, Loss: 6465.40185546875\n",
      "Epoch: 2, Batch number: 5512, Loss: 6597.02294921875\n",
      "Epoch: 2, Batch number: 5612, Loss: 6352.1962890625\n",
      "Epoch: 2, Batch number: 5712, Loss: 6589.0654296875\n",
      "Epoch: 2, Batch number: 5812, Loss: 6521.64501953125\n",
      "Epoch: 2, Batch number: 5912, Loss: 6437.17822265625\n",
      "Epoch: 2, Batch number: 6012, Loss: 6518.5478515625\n",
      "Epoch: 2, Batch number: 6112, Loss: 6405.08740234375\n",
      "Epoch: 2, Batch number: 6212, Loss: 6621.59716796875\n",
      "Epoch: 2, Batch number: 6312, Loss: 6314.353515625\n",
      "Epoch: 2, Batch number: 6412, Loss: 6580.13623046875\n",
      "Epoch: 2, Batch number: 6512, Loss: 6586.94775390625\n",
      "Epoch: 2, Batch number: 6612, Loss: 6663.2177734375\n",
      "Epoch: 2, Batch number: 6712, Loss: 6537.58203125\n",
      "Epoch: 2, Batch number: 6812, Loss: 6634.18310546875\n",
      "Epoch: 2, Batch number: 6912, Loss: 6412.9013671875\n",
      "Epoch: 2, Batch number: 7012, Loss: 6745.0439453125\n",
      "Epoch: 2, Batch number: 7112, Loss: 6336.80517578125\n",
      "Epoch: 2, Batch number: 7212, Loss: 6424.916015625\n",
      "Epoch: 2, Batch number: 7312, Loss: 6657.0380859375\n",
      "Epoch: 2, Batch number: 7412, Loss: 6511.56640625\n",
      "Epoch: 2, Batch number: 7512, Loss: 6468.48291015625\n",
      "Epoch: 2, Batch number: 7612, Loss: 6534.705078125\n",
      "Epoch: 2, Batch number: 7712, Loss: 6617.4921875\n",
      "Epoch: 2, Batch number: 7812, Loss: 6424.375\n",
      "Epoch: 2, Batch number: 7912, Loss: 6312.74609375\n",
      "Epoch: 2, Batch number: 8012, Loss: 6484.26513671875\n",
      "Epoch: 2, Batch number: 8112, Loss: 6228.3203125\n",
      "Epoch: 2, Batch number: 8212, Loss: 6334.4052734375\n",
      "Epoch: 2, Batch number: 8312, Loss: 6621.72216796875\n",
      "Epoch: 2, Batch number: 8412, Loss: 6639.12890625\n",
      "Epoch: 2, Batch number: 8512, Loss: 6576.23583984375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 10964.6767578125\n",
      "Epoch: 1, Batch number: 100, Loss: 10139.845703125\n",
      "Epoch: 1, Batch number: 200, Loss: 9813.0283203125\n",
      "Epoch: 1, Batch number: 300, Loss: 9462.9658203125\n",
      "Epoch: 1, Batch number: 400, Loss: 9330.21875\n",
      "Epoch: 1, Batch number: 500, Loss: 9101.3896484375\n",
      "Epoch: 1, Batch number: 600, Loss: 9071.3369140625\n",
      "Epoch: 1, Batch number: 700, Loss: 8857.59375\n",
      "Epoch: 1, Batch number: 800, Loss: 8630.9541015625\n",
      "Epoch: 1, Batch number: 900, Loss: 8485.1953125\n",
      "Epoch: 1, Batch number: 1000, Loss: 8206.84765625\n",
      "Epoch: 1, Batch number: 1100, Loss: 8209.822265625\n",
      "Epoch: 1, Batch number: 1200, Loss: 8086.76025390625\n",
      "Epoch: 1, Batch number: 1300, Loss: 8146.22607421875\n",
      "Epoch: 1, Batch number: 1400, Loss: 7983.89794921875\n",
      "Epoch: 1, Batch number: 1500, Loss: 7820.62255859375\n",
      "Epoch: 1, Batch number: 1600, Loss: 7751.47900390625\n",
      "Epoch: 1, Batch number: 1700, Loss: 7745.86767578125\n",
      "Epoch: 1, Batch number: 1800, Loss: 7583.10205078125\n",
      "Epoch: 1, Batch number: 1900, Loss: 7556.7041015625\n",
      "Epoch: 1, Batch number: 2000, Loss: 7611.525390625\n",
      "Epoch: 1, Batch number: 2100, Loss: 7561.83447265625\n",
      "Epoch: 1, Batch number: 2200, Loss: 7595.66943359375\n",
      "Epoch: 1, Batch number: 2300, Loss: 7493.22412109375\n",
      "Epoch: 1, Batch number: 2400, Loss: 7311.5107421875\n",
      "Epoch: 1, Batch number: 2500, Loss: 7434.32421875\n",
      "Epoch: 1, Batch number: 2600, Loss: 7326.9189453125\n",
      "Epoch: 1, Batch number: 2700, Loss: 7368.17138671875\n",
      "Epoch: 1, Batch number: 2800, Loss: 7268.240234375\n",
      "Epoch: 1, Batch number: 2900, Loss: 7275.6552734375\n",
      "Epoch: 1, Batch number: 3000, Loss: 7092.3701171875\n",
      "Epoch: 1, Batch number: 3100, Loss: 6904.8583984375\n",
      "Epoch: 1, Batch number: 3200, Loss: 7189.30712890625\n",
      "Epoch: 1, Batch number: 3300, Loss: 7098.796875\n",
      "Epoch: 1, Batch number: 3400, Loss: 7094.21533203125\n",
      "Epoch: 1, Batch number: 3500, Loss: 7015.5703125\n",
      "Epoch: 1, Batch number: 3600, Loss: 7153.0771484375\n",
      "Epoch: 1, Batch number: 3700, Loss: 7119.9453125\n",
      "Epoch: 1, Batch number: 3800, Loss: 6892.8388671875\n",
      "Epoch: 1, Batch number: 3900, Loss: 7115.89208984375\n",
      "Epoch: 1, Batch number: 4000, Loss: 6871.68212890625\n",
      "Epoch: 1, Batch number: 4100, Loss: 6755.49560546875\n",
      "Epoch: 1, Batch number: 4200, Loss: 6875.283203125\n",
      "Epoch: 1, Batch number: 4300, Loss: 6988.1591796875\n",
      "Epoch: 1, Batch number: 4400, Loss: 7044.81103515625\n",
      "Epoch: 1, Batch number: 4500, Loss: 7026.6865234375\n",
      "Epoch: 1, Batch number: 4600, Loss: 6742.6064453125\n",
      "Epoch: 1, Batch number: 4700, Loss: 6876.7744140625\n",
      "Epoch: 1, Batch number: 4800, Loss: 6901.40625\n",
      "Epoch: 1, Batch number: 4900, Loss: 6905.60302734375\n",
      "Epoch: 1, Batch number: 5000, Loss: 7031.31201171875\n",
      "Epoch: 1, Batch number: 5100, Loss: 6639.83349609375\n",
      "Epoch: 1, Batch number: 5200, Loss: 6705.03076171875\n",
      "Epoch: 1, Batch number: 5300, Loss: 7065.22998046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 5400, Loss: 7009.60791015625\n",
      "Epoch: 1, Batch number: 5500, Loss: 6857.02685546875\n",
      "Epoch: 1, Batch number: 5600, Loss: 6962.76416015625\n",
      "Epoch: 1, Batch number: 5700, Loss: 6674.662109375\n",
      "Epoch: 1, Batch number: 5800, Loss: 6754.6591796875\n",
      "Epoch: 1, Batch number: 5900, Loss: 6964.591796875\n",
      "Epoch: 1, Batch number: 6000, Loss: 6672.150390625\n",
      "Epoch: 1, Batch number: 6100, Loss: 6792.64208984375\n",
      "Epoch: 1, Batch number: 6200, Loss: 6536.70751953125\n",
      "Epoch: 1, Batch number: 6300, Loss: 6872.287109375\n",
      "Epoch: 1, Batch number: 6400, Loss: 6805.74609375\n",
      "Epoch: 1, Batch number: 6500, Loss: 6835.42578125\n",
      "Epoch: 1, Batch number: 6600, Loss: 6653.2685546875\n",
      "Epoch: 1, Batch number: 6700, Loss: 6670.2998046875\n",
      "Epoch: 1, Batch number: 6800, Loss: 6840.4912109375\n",
      "Epoch: 1, Batch number: 6900, Loss: 6756.49072265625\n",
      "Epoch: 1, Batch number: 7000, Loss: 6651.25390625\n",
      "Epoch: 1, Batch number: 7100, Loss: 6663.23486328125\n",
      "Epoch: 1, Batch number: 7200, Loss: 6719.3671875\n",
      "Epoch: 1, Batch number: 7300, Loss: 6752.5048828125\n",
      "Epoch: 1, Batch number: 7400, Loss: 6756.4794921875\n",
      "Epoch: 1, Batch number: 7500, Loss: 6592.16943359375\n",
      "Epoch: 1, Batch number: 7600, Loss: 6599.78271484375\n",
      "Epoch: 1, Batch number: 7700, Loss: 6519.056640625\n",
      "Epoch: 1, Batch number: 7800, Loss: 6748.41943359375\n",
      "Epoch: 1, Batch number: 7900, Loss: 6583.98974609375\n",
      "Epoch: 1, Batch number: 8000, Loss: 6485.71923828125\n",
      "Epoch: 1, Batch number: 8100, Loss: 6444.8544921875\n",
      "Epoch: 1, Batch number: 8200, Loss: 6410.666015625\n",
      "Epoch: 1, Batch number: 8300, Loss: 6422.22802734375\n",
      "Epoch: 1, Batch number: 8400, Loss: 6665.83447265625\n",
      "Epoch: 1, Batch number: 8500, Loss: 6539.84912109375\n",
      "Epoch: 2, Batch number: 12, Loss: 6355.17041015625\n",
      "Epoch: 2, Batch number: 112, Loss: 6322.8837890625\n",
      "Epoch: 2, Batch number: 212, Loss: 6476.1103515625\n",
      "Epoch: 2, Batch number: 312, Loss: 6633.560546875\n",
      "Epoch: 2, Batch number: 412, Loss: 6440.0048828125\n",
      "Epoch: 2, Batch number: 512, Loss: 6423.41259765625\n",
      "Epoch: 2, Batch number: 612, Loss: 6307.3369140625\n",
      "Epoch: 2, Batch number: 712, Loss: 6593.22509765625\n",
      "Epoch: 2, Batch number: 812, Loss: 6439.9169921875\n",
      "Epoch: 2, Batch number: 912, Loss: 6394.96337890625\n",
      "Epoch: 2, Batch number: 1012, Loss: 6412.91455078125\n",
      "Epoch: 2, Batch number: 1112, Loss: 6361.3671875\n",
      "Epoch: 2, Batch number: 1212, Loss: 6203.58349609375\n",
      "Epoch: 2, Batch number: 1312, Loss: 6314.9130859375\n",
      "Epoch: 2, Batch number: 1412, Loss: 6575.10498046875\n",
      "Epoch: 2, Batch number: 1512, Loss: 6439.64990234375\n",
      "Epoch: 2, Batch number: 1612, Loss: 6544.86279296875\n",
      "Epoch: 2, Batch number: 1712, Loss: 6580.0869140625\n",
      "Epoch: 2, Batch number: 1812, Loss: 6633.60595703125\n",
      "Epoch: 2, Batch number: 1912, Loss: 6516.900390625\n",
      "Epoch: 2, Batch number: 2012, Loss: 6263.53125\n",
      "Epoch: 2, Batch number: 2112, Loss: 6259.79638671875\n",
      "Epoch: 2, Batch number: 2212, Loss: 6442.9033203125\n",
      "Epoch: 2, Batch number: 2312, Loss: 6338.55859375\n",
      "Epoch: 2, Batch number: 2412, Loss: 6402.84130859375\n",
      "Epoch: 2, Batch number: 2512, Loss: 6142.443359375\n",
      "Epoch: 2, Batch number: 2612, Loss: 6461.30029296875\n",
      "Epoch: 2, Batch number: 2712, Loss: 6350.7041015625\n",
      "Epoch: 2, Batch number: 2812, Loss: 6373.4736328125\n",
      "Epoch: 2, Batch number: 2912, Loss: 6146.66015625\n",
      "Epoch: 2, Batch number: 3012, Loss: 6461.3955078125\n",
      "Epoch: 2, Batch number: 3112, Loss: 6361.9755859375\n",
      "Epoch: 2, Batch number: 3212, Loss: 6393.36669921875\n",
      "Epoch: 2, Batch number: 3312, Loss: 6498.90869140625\n",
      "Epoch: 2, Batch number: 3412, Loss: 6573.9404296875\n",
      "Epoch: 2, Batch number: 3512, Loss: 6244.90234375\n",
      "Epoch: 2, Batch number: 3612, Loss: 6415.17529296875\n",
      "Epoch: 2, Batch number: 3712, Loss: 6557.45556640625\n",
      "Epoch: 2, Batch number: 3812, Loss: 6387.494140625\n",
      "Epoch: 2, Batch number: 3912, Loss: 6259.4462890625\n",
      "Epoch: 2, Batch number: 4012, Loss: 6320.2822265625\n",
      "Epoch: 2, Batch number: 4112, Loss: 6261.216796875\n",
      "Epoch: 2, Batch number: 4212, Loss: 6551.208984375\n",
      "Epoch: 2, Batch number: 4312, Loss: 6372.3955078125\n",
      "Epoch: 2, Batch number: 4412, Loss: 6189.1357421875\n",
      "Epoch: 2, Batch number: 4512, Loss: 6704.34130859375\n",
      "Epoch: 2, Batch number: 4612, Loss: 6317.4716796875\n",
      "Epoch: 2, Batch number: 4712, Loss: 6453.52392578125\n",
      "Epoch: 2, Batch number: 4812, Loss: 6454.3623046875\n",
      "Epoch: 2, Batch number: 4912, Loss: 6242.05224609375\n",
      "Epoch: 2, Batch number: 5012, Loss: 6361.31884765625\n",
      "Epoch: 2, Batch number: 5112, Loss: 6434.40380859375\n",
      "Epoch: 2, Batch number: 5212, Loss: 6550.25048828125\n",
      "Epoch: 2, Batch number: 5312, Loss: 6280.77001953125\n",
      "Epoch: 2, Batch number: 5412, Loss: 6305.169921875\n",
      "Epoch: 2, Batch number: 5512, Loss: 6505.76806640625\n",
      "Epoch: 2, Batch number: 5612, Loss: 6530.99853515625\n",
      "Epoch: 2, Batch number: 5712, Loss: 6392.80859375\n",
      "Epoch: 2, Batch number: 5812, Loss: 6202.095703125\n",
      "Epoch: 2, Batch number: 5912, Loss: 6183.23828125\n",
      "Epoch: 2, Batch number: 6012, Loss: 6519.71923828125\n",
      "Epoch: 2, Batch number: 6112, Loss: 6385.22900390625\n",
      "Epoch: 2, Batch number: 6212, Loss: 6526.640625\n",
      "Epoch: 2, Batch number: 6312, Loss: 6486.04443359375\n",
      "Epoch: 2, Batch number: 6412, Loss: 6142.6318359375\n",
      "Epoch: 2, Batch number: 6512, Loss: 6564.31591796875\n",
      "Epoch: 2, Batch number: 6612, Loss: 6284.74658203125\n",
      "Epoch: 2, Batch number: 6712, Loss: 6267.88525390625\n",
      "Epoch: 2, Batch number: 6812, Loss: 6267.97998046875\n",
      "Epoch: 2, Batch number: 6912, Loss: 6367.18994140625\n",
      "Epoch: 2, Batch number: 7012, Loss: 6375.67919921875\n",
      "Epoch: 2, Batch number: 7112, Loss: 6518.48828125\n",
      "Epoch: 2, Batch number: 7212, Loss: 6335.59326171875\n",
      "Epoch: 2, Batch number: 7312, Loss: 6345.4189453125\n",
      "Epoch: 2, Batch number: 7412, Loss: 6096.43212890625\n",
      "Epoch: 2, Batch number: 7512, Loss: 6180.9384765625\n",
      "Epoch: 2, Batch number: 7612, Loss: 6386.5986328125\n",
      "Epoch: 2, Batch number: 7712, Loss: 6619.18798828125\n",
      "Epoch: 2, Batch number: 7812, Loss: 6230.2958984375\n",
      "Epoch: 2, Batch number: 7912, Loss: 6330.8037109375\n",
      "Epoch: 2, Batch number: 8012, Loss: 6253.82470703125\n",
      "Epoch: 2, Batch number: 8112, Loss: 6369.59033203125\n",
      "Epoch: 2, Batch number: 8212, Loss: 6319.48681640625\n",
      "Epoch: 2, Batch number: 8312, Loss: 6321.794921875\n",
      "Epoch: 2, Batch number: 8412, Loss: 6433.38525390625\n",
      "Epoch: 2, Batch number: 8512, Loss: 6479.13330078125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 10869.8525390625\n",
      "Epoch: 1, Batch number: 100, Loss: 10088.4755859375\n",
      "Epoch: 1, Batch number: 200, Loss: 9574.794921875\n",
      "Epoch: 1, Batch number: 300, Loss: 9376.890625\n",
      "Epoch: 1, Batch number: 400, Loss: 9253.2421875\n",
      "Epoch: 1, Batch number: 500, Loss: 8885.40625\n",
      "Epoch: 1, Batch number: 600, Loss: 8643.0263671875\n",
      "Epoch: 1, Batch number: 700, Loss: 8492.6220703125\n",
      "Epoch: 1, Batch number: 800, Loss: 8438.7666015625\n",
      "Epoch: 1, Batch number: 900, Loss: 8289.4775390625\n",
      "Epoch: 1, Batch number: 1000, Loss: 7966.82275390625\n",
      "Epoch: 1, Batch number: 1100, Loss: 7849.6220703125\n",
      "Epoch: 1, Batch number: 1200, Loss: 7827.7734375\n",
      "Epoch: 1, Batch number: 1300, Loss: 7908.732421875\n",
      "Epoch: 1, Batch number: 1400, Loss: 7666.00732421875\n",
      "Epoch: 1, Batch number: 1500, Loss: 7569.90478515625\n",
      "Epoch: 1, Batch number: 1600, Loss: 7611.76611328125\n",
      "Epoch: 1, Batch number: 1700, Loss: 7664.72119140625\n",
      "Epoch: 1, Batch number: 1800, Loss: 7277.60986328125\n",
      "Epoch: 1, Batch number: 1900, Loss: 7465.8857421875\n",
      "Epoch: 1, Batch number: 2000, Loss: 7323.54638671875\n",
      "Epoch: 1, Batch number: 2100, Loss: 7315.708984375\n",
      "Epoch: 1, Batch number: 2200, Loss: 7092.833984375\n",
      "Epoch: 1, Batch number: 2300, Loss: 7266.20263671875\n",
      "Epoch: 1, Batch number: 2400, Loss: 7224.48388671875\n",
      "Epoch: 1, Batch number: 2500, Loss: 7282.53466796875\n",
      "Epoch: 1, Batch number: 2600, Loss: 6975.1728515625\n",
      "Epoch: 1, Batch number: 2700, Loss: 7107.8720703125\n",
      "Epoch: 1, Batch number: 2800, Loss: 7149.55712890625\n",
      "Epoch: 1, Batch number: 2900, Loss: 6834.61572265625\n",
      "Epoch: 1, Batch number: 3000, Loss: 6992.60595703125\n",
      "Epoch: 1, Batch number: 3100, Loss: 7080.05908203125\n",
      "Epoch: 1, Batch number: 3200, Loss: 7038.3330078125\n",
      "Epoch: 1, Batch number: 3300, Loss: 6923.1396484375\n",
      "Epoch: 1, Batch number: 3400, Loss: 6854.3681640625\n",
      "Epoch: 1, Batch number: 3500, Loss: 7055.037109375\n",
      "Epoch: 1, Batch number: 3600, Loss: 6806.2216796875\n",
      "Epoch: 1, Batch number: 3700, Loss: 6903.462890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 3800, Loss: 6862.3134765625\n",
      "Epoch: 1, Batch number: 3900, Loss: 6835.86865234375\n",
      "Epoch: 1, Batch number: 4000, Loss: 6826.65771484375\n",
      "Epoch: 1, Batch number: 4100, Loss: 7072.49365234375\n",
      "Epoch: 1, Batch number: 4200, Loss: 6698.8984375\n",
      "Epoch: 1, Batch number: 4300, Loss: 7011.92236328125\n",
      "Epoch: 1, Batch number: 4400, Loss: 6994.2763671875\n",
      "Epoch: 1, Batch number: 4500, Loss: 6848.99462890625\n",
      "Epoch: 1, Batch number: 4600, Loss: 6928.287109375\n",
      "Epoch: 1, Batch number: 4700, Loss: 6746.8447265625\n",
      "Epoch: 1, Batch number: 4800, Loss: 6586.46435546875\n",
      "Epoch: 1, Batch number: 4900, Loss: 6749.14794921875\n",
      "Epoch: 1, Batch number: 5000, Loss: 6585.482421875\n",
      "Epoch: 1, Batch number: 5100, Loss: 6813.0126953125\n",
      "Epoch: 1, Batch number: 5200, Loss: 6618.20849609375\n",
      "Epoch: 1, Batch number: 5300, Loss: 6473.57763671875\n",
      "Epoch: 1, Batch number: 5400, Loss: 6704.216796875\n",
      "Epoch: 1, Batch number: 5500, Loss: 6718.78466796875\n",
      "Epoch: 1, Batch number: 5600, Loss: 6805.05126953125\n",
      "Epoch: 1, Batch number: 5700, Loss: 6765.2197265625\n",
      "Epoch: 1, Batch number: 5800, Loss: 6422.7041015625\n",
      "Epoch: 1, Batch number: 5900, Loss: 6741.7392578125\n",
      "Epoch: 1, Batch number: 6000, Loss: 6790.30517578125\n",
      "Epoch: 1, Batch number: 6100, Loss: 6627.42578125\n",
      "Epoch: 1, Batch number: 6200, Loss: 6667.7451171875\n",
      "Epoch: 1, Batch number: 6300, Loss: 6742.48193359375\n",
      "Epoch: 1, Batch number: 6400, Loss: 7084.01318359375\n",
      "Epoch: 1, Batch number: 6500, Loss: 6618.60302734375\n",
      "Epoch: 1, Batch number: 6600, Loss: 6591.89453125\n",
      "Epoch: 1, Batch number: 6700, Loss: 6760.58447265625\n",
      "Epoch: 1, Batch number: 6800, Loss: 6474.1083984375\n",
      "Epoch: 1, Batch number: 6900, Loss: 6679.275390625\n",
      "Epoch: 1, Batch number: 7000, Loss: 6404.46875\n",
      "Epoch: 1, Batch number: 7100, Loss: 6566.845703125\n",
      "Epoch: 1, Batch number: 7200, Loss: 6565.1201171875\n",
      "Epoch: 1, Batch number: 7300, Loss: 6541.720703125\n",
      "Epoch: 1, Batch number: 7400, Loss: 6688.36279296875\n",
      "Epoch: 1, Batch number: 7500, Loss: 6568.9765625\n",
      "Epoch: 1, Batch number: 7600, Loss: 6511.42333984375\n",
      "Epoch: 1, Batch number: 7700, Loss: 6501.45458984375\n",
      "Epoch: 1, Batch number: 7800, Loss: 6582.9609375\n",
      "Epoch: 1, Batch number: 7900, Loss: 6540.384765625\n",
      "Epoch: 1, Batch number: 8000, Loss: 6653.05224609375\n",
      "Epoch: 1, Batch number: 8100, Loss: 6496.583984375\n",
      "Epoch: 1, Batch number: 8200, Loss: 6618.595703125\n",
      "Epoch: 1, Batch number: 8300, Loss: 6461.40283203125\n",
      "Epoch: 1, Batch number: 8400, Loss: 6627.783203125\n",
      "Epoch: 1, Batch number: 8500, Loss: 6730.86572265625\n",
      "Epoch: 2, Batch number: 12, Loss: 6354.830078125\n",
      "Epoch: 2, Batch number: 112, Loss: 6195.51904296875\n",
      "Epoch: 2, Batch number: 212, Loss: 6241.83251953125\n",
      "Epoch: 2, Batch number: 312, Loss: 6458.53759765625\n",
      "Epoch: 2, Batch number: 412, Loss: 6172.40771484375\n",
      "Epoch: 2, Batch number: 512, Loss: 6259.447265625\n",
      "Epoch: 2, Batch number: 612, Loss: 6311.77587890625\n",
      "Epoch: 2, Batch number: 712, Loss: 6395.99267578125\n",
      "Epoch: 2, Batch number: 812, Loss: 6156.8349609375\n",
      "Epoch: 2, Batch number: 912, Loss: 6327.2060546875\n",
      "Epoch: 2, Batch number: 1012, Loss: 6370.2587890625\n",
      "Epoch: 2, Batch number: 1112, Loss: 6394.30712890625\n",
      "Epoch: 2, Batch number: 1212, Loss: 6167.87158203125\n",
      "Epoch: 2, Batch number: 1312, Loss: 6252.7890625\n",
      "Epoch: 2, Batch number: 1412, Loss: 6408.3369140625\n",
      "Epoch: 2, Batch number: 1512, Loss: 6390.6796875\n",
      "Epoch: 2, Batch number: 1612, Loss: 6240.783203125\n",
      "Epoch: 2, Batch number: 1712, Loss: 6227.98876953125\n",
      "Epoch: 2, Batch number: 1812, Loss: 6326.23388671875\n",
      "Epoch: 2, Batch number: 1912, Loss: 6477.60302734375\n",
      "Epoch: 2, Batch number: 2012, Loss: 6363.0107421875\n",
      "Epoch: 2, Batch number: 2112, Loss: 6319.37451171875\n",
      "Epoch: 2, Batch number: 2212, Loss: 6310.81103515625\n",
      "Epoch: 2, Batch number: 2312, Loss: 6206.66796875\n",
      "Epoch: 2, Batch number: 2412, Loss: 6378.73779296875\n",
      "Epoch: 2, Batch number: 2512, Loss: 6284.11865234375\n",
      "Epoch: 2, Batch number: 2612, Loss: 6276.97802734375\n",
      "Epoch: 2, Batch number: 2712, Loss: 6232.96630859375\n",
      "Epoch: 2, Batch number: 2812, Loss: 6245.64013671875\n",
      "Epoch: 2, Batch number: 2912, Loss: 6211.3330078125\n",
      "Epoch: 2, Batch number: 3012, Loss: 6024.0009765625\n",
      "Epoch: 2, Batch number: 3112, Loss: 6369.85693359375\n",
      "Epoch: 2, Batch number: 3212, Loss: 6455.20263671875\n",
      "Epoch: 2, Batch number: 3312, Loss: 6237.59814453125\n",
      "Epoch: 2, Batch number: 3412, Loss: 6407.65283203125\n",
      "Epoch: 2, Batch number: 3512, Loss: 6209.91650390625\n",
      "Epoch: 2, Batch number: 3612, Loss: 6352.4541015625\n",
      "Epoch: 2, Batch number: 3712, Loss: 6556.2529296875\n",
      "Epoch: 2, Batch number: 3812, Loss: 6029.853515625\n",
      "Epoch: 2, Batch number: 3912, Loss: 6137.74462890625\n",
      "Epoch: 2, Batch number: 4012, Loss: 6252.17138671875\n",
      "Epoch: 2, Batch number: 4112, Loss: 6246.052734375\n",
      "Epoch: 2, Batch number: 4212, Loss: 6296.67822265625\n",
      "Epoch: 2, Batch number: 4312, Loss: 6276.30126953125\n",
      "Epoch: 2, Batch number: 4412, Loss: 6368.74169921875\n",
      "Epoch: 2, Batch number: 4512, Loss: 5867.11474609375\n",
      "Epoch: 2, Batch number: 4612, Loss: 6312.22802734375\n",
      "Epoch: 2, Batch number: 4712, Loss: 6125.056640625\n",
      "Epoch: 2, Batch number: 4812, Loss: 6334.5546875\n",
      "Epoch: 2, Batch number: 4912, Loss: 6363.1298828125\n",
      "Epoch: 2, Batch number: 5012, Loss: 6203.89892578125\n",
      "Epoch: 2, Batch number: 5112, Loss: 6393.345703125\n",
      "Epoch: 2, Batch number: 5212, Loss: 6165.64794921875\n",
      "Epoch: 2, Batch number: 5312, Loss: 6354.87060546875\n",
      "Epoch: 2, Batch number: 5412, Loss: 6382.826171875\n",
      "Epoch: 2, Batch number: 5512, Loss: 6306.14697265625\n",
      "Epoch: 2, Batch number: 5612, Loss: 6177.9541015625\n",
      "Epoch: 2, Batch number: 5712, Loss: 6409.216796875\n",
      "Epoch: 2, Batch number: 5812, Loss: 6062.2158203125\n",
      "Epoch: 2, Batch number: 5912, Loss: 6256.599609375\n",
      "Epoch: 2, Batch number: 6012, Loss: 6291.60791015625\n",
      "Epoch: 2, Batch number: 6112, Loss: 6140.1923828125\n",
      "Epoch: 2, Batch number: 6212, Loss: 6380.2216796875\n",
      "Epoch: 2, Batch number: 6312, Loss: 6182.55859375\n",
      "Epoch: 2, Batch number: 6412, Loss: 6253.42626953125\n",
      "Epoch: 2, Batch number: 6512, Loss: 6171.5380859375\n",
      "Epoch: 2, Batch number: 6612, Loss: 6329.31396484375\n",
      "Epoch: 2, Batch number: 6712, Loss: 6301.396484375\n",
      "Epoch: 2, Batch number: 6812, Loss: 6264.55615234375\n",
      "Epoch: 2, Batch number: 6912, Loss: 6240.70263671875\n",
      "Epoch: 2, Batch number: 7012, Loss: 6215.00830078125\n",
      "Epoch: 2, Batch number: 7112, Loss: 6137.759765625\n",
      "Epoch: 2, Batch number: 7212, Loss: 6346.08837890625\n",
      "Epoch: 2, Batch number: 7312, Loss: 6094.0966796875\n",
      "Epoch: 2, Batch number: 7412, Loss: 6348.14208984375\n",
      "Epoch: 2, Batch number: 7512, Loss: 6450.16162109375\n",
      "Epoch: 2, Batch number: 7612, Loss: 6246.134765625\n",
      "Epoch: 2, Batch number: 7712, Loss: 6215.9052734375\n",
      "Epoch: 2, Batch number: 7812, Loss: 6536.51171875\n",
      "Epoch: 2, Batch number: 7912, Loss: 6075.4482421875\n",
      "Epoch: 2, Batch number: 8012, Loss: 6229.2939453125\n",
      "Epoch: 2, Batch number: 8112, Loss: 6092.84765625\n",
      "Epoch: 2, Batch number: 8212, Loss: 6110.826171875\n",
      "Epoch: 2, Batch number: 8312, Loss: 6103.40966796875\n",
      "Epoch: 2, Batch number: 8412, Loss: 6239.54296875\n",
      "Epoch: 2, Batch number: 8512, Loss: 6181.34228515625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21751.03515625\n",
      "Epoch: 1, Batch number: 100, Loss: 21282.427734375\n",
      "Epoch: 1, Batch number: 200, Loss: 20509.955078125\n",
      "Epoch: 1, Batch number: 300, Loss: 20455.583984375\n",
      "Epoch: 1, Batch number: 400, Loss: 19670.3046875\n",
      "Epoch: 1, Batch number: 500, Loss: 19200.87890625\n",
      "Epoch: 1, Batch number: 600, Loss: 19029.4140625\n",
      "Epoch: 1, Batch number: 700, Loss: 18106.06640625\n",
      "Epoch: 1, Batch number: 800, Loss: 18043.78515625\n",
      "Epoch: 1, Batch number: 900, Loss: 18366.48828125\n",
      "Epoch: 1, Batch number: 1000, Loss: 18075.96875\n",
      "Epoch: 1, Batch number: 1100, Loss: 17968.787109375\n",
      "Epoch: 1, Batch number: 1200, Loss: 17552.33984375\n",
      "Epoch: 1, Batch number: 1300, Loss: 17354.669921875\n",
      "Epoch: 1, Batch number: 1400, Loss: 17330.23828125\n",
      "Epoch: 1, Batch number: 1500, Loss: 17250.259765625\n",
      "Epoch: 1, Batch number: 1600, Loss: 16973.099609375\n",
      "Epoch: 1, Batch number: 1700, Loss: 16719.509765625\n",
      "Epoch: 1, Batch number: 1800, Loss: 16822.6796875\n",
      "Epoch: 1, Batch number: 1900, Loss: 16505.15625\n",
      "Epoch: 1, Batch number: 2000, Loss: 16462.6171875\n",
      "Epoch: 1, Batch number: 2100, Loss: 16233.4169921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 2200, Loss: 15814.1142578125\n",
      "Epoch: 1, Batch number: 2300, Loss: 16343.1669921875\n",
      "Epoch: 1, Batch number: 2400, Loss: 15909.6455078125\n",
      "Epoch: 1, Batch number: 2500, Loss: 16025.359375\n",
      "Epoch: 1, Batch number: 2600, Loss: 15699.6796875\n",
      "Epoch: 1, Batch number: 2700, Loss: 15811.0576171875\n",
      "Epoch: 1, Batch number: 2800, Loss: 15725.0029296875\n",
      "Epoch: 1, Batch number: 2900, Loss: 15516.88671875\n",
      "Epoch: 1, Batch number: 3000, Loss: 15466.9990234375\n",
      "Epoch: 1, Batch number: 3100, Loss: 15762.7392578125\n",
      "Epoch: 1, Batch number: 3200, Loss: 15712.3251953125\n",
      "Epoch: 1, Batch number: 3300, Loss: 15425.3671875\n",
      "Epoch: 1, Batch number: 3400, Loss: 15429.1552734375\n",
      "Epoch: 1, Batch number: 3500, Loss: 15467.88671875\n",
      "Epoch: 1, Batch number: 3600, Loss: 15319.8271484375\n",
      "Epoch: 1, Batch number: 3700, Loss: 15178.8525390625\n",
      "Epoch: 1, Batch number: 3800, Loss: 15143.197265625\n",
      "Epoch: 1, Batch number: 3900, Loss: 15402.14453125\n",
      "Epoch: 1, Batch number: 4000, Loss: 15550.73046875\n",
      "Epoch: 1, Batch number: 4100, Loss: 15090.3564453125\n",
      "Epoch: 1, Batch number: 4200, Loss: 15117.9267578125\n",
      "Epoch: 1, Batch number: 4300, Loss: 15080.427734375\n",
      "Epoch: 1, Batch number: 4400, Loss: 14932.37109375\n",
      "Epoch: 1, Batch number: 4500, Loss: 15028.0107421875\n",
      "Epoch: 1, Batch number: 4600, Loss: 14992.9345703125\n",
      "Epoch: 1, Batch number: 4700, Loss: 15123.2158203125\n",
      "Epoch: 1, Batch number: 4800, Loss: 15055.0546875\n",
      "Epoch: 1, Batch number: 4900, Loss: 14905.05078125\n",
      "Epoch: 1, Batch number: 5000, Loss: 14940.576171875\n",
      "Epoch: 1, Batch number: 5100, Loss: 14976.3720703125\n",
      "Epoch: 1, Batch number: 5200, Loss: 14807.6982421875\n",
      "Epoch: 1, Batch number: 5300, Loss: 14736.64453125\n",
      "Epoch: 1, Batch number: 5400, Loss: 14723.73828125\n",
      "Epoch: 1, Batch number: 5500, Loss: 14660.078125\n",
      "Epoch: 1, Batch number: 5600, Loss: 15053.83203125\n",
      "Epoch: 1, Batch number: 5700, Loss: 15139.23046875\n",
      "Epoch: 1, Batch number: 5800, Loss: 14900.2607421875\n",
      "Epoch: 1, Batch number: 5900, Loss: 15156.7607421875\n",
      "Epoch: 1, Batch number: 6000, Loss: 14558.3701171875\n",
      "Epoch: 1, Batch number: 6100, Loss: 14664.7109375\n",
      "Epoch: 1, Batch number: 6200, Loss: 14734.501953125\n",
      "Epoch: 1, Batch number: 6300, Loss: 14691.25390625\n",
      "Epoch: 1, Batch number: 6400, Loss: 14639.646484375\n",
      "Epoch: 1, Batch number: 6500, Loss: 14440.25\n",
      "Epoch: 1, Batch number: 6600, Loss: 14619.767578125\n",
      "Epoch: 1, Batch number: 6700, Loss: 14711.39453125\n",
      "Epoch: 1, Batch number: 6800, Loss: 14706.7119140625\n",
      "Epoch: 1, Batch number: 6900, Loss: 14546.349609375\n",
      "Epoch: 1, Batch number: 7000, Loss: 14485.3544921875\n",
      "Epoch: 1, Batch number: 7100, Loss: 14892.376953125\n",
      "Epoch: 1, Batch number: 7200, Loss: 14609.986328125\n",
      "Epoch: 1, Batch number: 7300, Loss: 14316.666015625\n",
      "Epoch: 1, Batch number: 7400, Loss: 14428.5625\n",
      "Epoch: 1, Batch number: 7500, Loss: 14366.3154296875\n",
      "Epoch: 1, Batch number: 7600, Loss: 14765.7685546875\n",
      "Epoch: 1, Batch number: 7700, Loss: 14133.716796875\n",
      "Epoch: 1, Batch number: 7800, Loss: 14633.3896484375\n",
      "Epoch: 1, Batch number: 7900, Loss: 14759.9111328125\n",
      "Epoch: 1, Batch number: 8000, Loss: 14724.1591796875\n",
      "Epoch: 1, Batch number: 8100, Loss: 14128.138671875\n",
      "Epoch: 1, Batch number: 8200, Loss: 14742.4287109375\n",
      "Epoch: 1, Batch number: 8300, Loss: 14495.1181640625\n",
      "Epoch: 1, Batch number: 8400, Loss: 14483.6826171875\n",
      "Epoch: 1, Batch number: 8500, Loss: 14498.7021484375\n",
      "Epoch: 1, Batch number: 8600, Loss: 14549.150390625\n",
      "Epoch: 2, Batch number: 79, Loss: 14228.68359375\n",
      "Epoch: 2, Batch number: 179, Loss: 14396.5419921875\n",
      "Epoch: 2, Batch number: 279, Loss: 14087.9873046875\n",
      "Epoch: 2, Batch number: 379, Loss: 14667.5322265625\n",
      "Epoch: 2, Batch number: 479, Loss: 14454.5634765625\n",
      "Epoch: 2, Batch number: 579, Loss: 14326.6669921875\n",
      "Epoch: 2, Batch number: 679, Loss: 14224.5791015625\n",
      "Epoch: 2, Batch number: 779, Loss: 14115.900390625\n",
      "Epoch: 2, Batch number: 879, Loss: 14268.28125\n",
      "Epoch: 2, Batch number: 979, Loss: 14253.3974609375\n",
      "Epoch: 2, Batch number: 1079, Loss: 14454.390625\n",
      "Epoch: 2, Batch number: 1179, Loss: 14212.82421875\n",
      "Epoch: 2, Batch number: 1279, Loss: 14214.87109375\n",
      "Epoch: 2, Batch number: 1379, Loss: 14458.4794921875\n",
      "Epoch: 2, Batch number: 1479, Loss: 14123.90234375\n",
      "Epoch: 2, Batch number: 1579, Loss: 14368.7060546875\n",
      "Epoch: 2, Batch number: 1679, Loss: 14092.6044921875\n",
      "Epoch: 2, Batch number: 1779, Loss: 14453.8427734375\n",
      "Epoch: 2, Batch number: 1879, Loss: 14460.349609375\n",
      "Epoch: 2, Batch number: 1979, Loss: 14267.345703125\n",
      "Epoch: 2, Batch number: 2079, Loss: 14320.125\n",
      "Epoch: 2, Batch number: 2179, Loss: 14550.6962890625\n",
      "Epoch: 2, Batch number: 2279, Loss: 14153.9638671875\n",
      "Epoch: 2, Batch number: 2379, Loss: 14368.8427734375\n",
      "Epoch: 2, Batch number: 2479, Loss: 14375.2021484375\n",
      "Epoch: 2, Batch number: 2579, Loss: 13888.89453125\n",
      "Epoch: 2, Batch number: 2679, Loss: 14353.4990234375\n",
      "Epoch: 2, Batch number: 2779, Loss: 14112.669921875\n",
      "Epoch: 2, Batch number: 2879, Loss: 14225.3017578125\n",
      "Epoch: 2, Batch number: 2979, Loss: 14084.150390625\n",
      "Epoch: 2, Batch number: 3079, Loss: 14134.001953125\n",
      "Epoch: 2, Batch number: 3179, Loss: 13910.6171875\n",
      "Epoch: 2, Batch number: 3279, Loss: 14376.7666015625\n",
      "Epoch: 2, Batch number: 3379, Loss: 14021.3388671875\n",
      "Epoch: 2, Batch number: 3479, Loss: 14014.1552734375\n",
      "Epoch: 2, Batch number: 3579, Loss: 14077.3095703125\n",
      "Epoch: 2, Batch number: 3679, Loss: 14097.9638671875\n",
      "Epoch: 2, Batch number: 3779, Loss: 14290.06640625\n",
      "Epoch: 2, Batch number: 3879, Loss: 14524.064453125\n",
      "Epoch: 2, Batch number: 3979, Loss: 14129.20703125\n",
      "Epoch: 2, Batch number: 4079, Loss: 14133.572265625\n",
      "Epoch: 2, Batch number: 4179, Loss: 14159.044921875\n",
      "Epoch: 2, Batch number: 4279, Loss: 14250.7509765625\n",
      "Epoch: 2, Batch number: 4379, Loss: 14185.69140625\n",
      "Epoch: 2, Batch number: 4479, Loss: 13960.0439453125\n",
      "Epoch: 2, Batch number: 4579, Loss: 13739.0693359375\n",
      "Epoch: 2, Batch number: 4679, Loss: 14170.9619140625\n",
      "Epoch: 2, Batch number: 4779, Loss: 14255.42578125\n",
      "Epoch: 2, Batch number: 4879, Loss: 14255.1494140625\n",
      "Epoch: 2, Batch number: 4979, Loss: 13769.12890625\n",
      "Epoch: 2, Batch number: 5079, Loss: 14220.3564453125\n",
      "Epoch: 2, Batch number: 5179, Loss: 13955.271484375\n",
      "Epoch: 2, Batch number: 5279, Loss: 14172.6416015625\n",
      "Epoch: 2, Batch number: 5379, Loss: 14399.9736328125\n",
      "Epoch: 2, Batch number: 5479, Loss: 13894.130859375\n",
      "Epoch: 2, Batch number: 5579, Loss: 14118.4208984375\n",
      "Epoch: 2, Batch number: 5679, Loss: 13933.248046875\n",
      "Epoch: 2, Batch number: 5779, Loss: 14007.6162109375\n",
      "Epoch: 2, Batch number: 5879, Loss: 14116.0205078125\n",
      "Epoch: 2, Batch number: 5979, Loss: 14139.0556640625\n",
      "Epoch: 2, Batch number: 6079, Loss: 13758.1376953125\n",
      "Epoch: 2, Batch number: 6179, Loss: 14105.4970703125\n",
      "Epoch: 2, Batch number: 6279, Loss: 14078.1552734375\n",
      "Epoch: 2, Batch number: 6379, Loss: 14043.1357421875\n",
      "Epoch: 2, Batch number: 6479, Loss: 14021.251953125\n",
      "Epoch: 2, Batch number: 6579, Loss: 14020.939453125\n",
      "Epoch: 2, Batch number: 6679, Loss: 13906.451171875\n",
      "Epoch: 2, Batch number: 6779, Loss: 14157.01171875\n",
      "Epoch: 2, Batch number: 6879, Loss: 14211.775390625\n",
      "Epoch: 2, Batch number: 6979, Loss: 14295.41015625\n",
      "Epoch: 2, Batch number: 7079, Loss: 14290.97265625\n",
      "Epoch: 2, Batch number: 7179, Loss: 14123.93359375\n",
      "Epoch: 2, Batch number: 7279, Loss: 14456.1728515625\n",
      "Epoch: 2, Batch number: 7379, Loss: 13548.6103515625\n",
      "Epoch: 2, Batch number: 7479, Loss: 13979.9833984375\n",
      "Epoch: 2, Batch number: 7579, Loss: 13986.025390625\n",
      "Epoch: 2, Batch number: 7679, Loss: 13767.8740234375\n",
      "Epoch: 2, Batch number: 7779, Loss: 14056.826171875\n",
      "Epoch: 2, Batch number: 7879, Loss: 14115.3984375\n",
      "Epoch: 2, Batch number: 7979, Loss: 14176.3583984375\n",
      "Epoch: 2, Batch number: 8079, Loss: 14046.7412109375\n",
      "Epoch: 2, Batch number: 8179, Loss: 14057.12109375\n",
      "Epoch: 2, Batch number: 8279, Loss: 14090.41015625\n",
      "Epoch: 2, Batch number: 8379, Loss: 14042.962890625\n",
      "Epoch: 2, Batch number: 8479, Loss: 14035.76953125\n",
      "Epoch: 2, Batch number: 8579, Loss: 13959.1650390625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21989.796875\n",
      "Epoch: 1, Batch number: 100, Loss: 20990.259765625\n",
      "Epoch: 1, Batch number: 200, Loss: 20280.826171875\n",
      "Epoch: 1, Batch number: 300, Loss: 19580.27734375\n",
      "Epoch: 1, Batch number: 400, Loss: 19152.064453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 500, Loss: 18511.6171875\n",
      "Epoch: 1, Batch number: 600, Loss: 17934.765625\n",
      "Epoch: 1, Batch number: 700, Loss: 17919.994140625\n",
      "Epoch: 1, Batch number: 800, Loss: 17905.85546875\n",
      "Epoch: 1, Batch number: 900, Loss: 17667.791015625\n",
      "Epoch: 1, Batch number: 1000, Loss: 17256.95703125\n",
      "Epoch: 1, Batch number: 1100, Loss: 17014.474609375\n",
      "Epoch: 1, Batch number: 1200, Loss: 16679.95703125\n",
      "Epoch: 1, Batch number: 1300, Loss: 16427.76953125\n",
      "Epoch: 1, Batch number: 1400, Loss: 16695.560546875\n",
      "Epoch: 1, Batch number: 1500, Loss: 16358.8125\n",
      "Epoch: 1, Batch number: 1600, Loss: 16393.2890625\n",
      "Epoch: 1, Batch number: 1700, Loss: 16145.0947265625\n",
      "Epoch: 1, Batch number: 1800, Loss: 16136.6015625\n",
      "Epoch: 1, Batch number: 1900, Loss: 15779.609375\n",
      "Epoch: 1, Batch number: 2000, Loss: 15247.4267578125\n",
      "Epoch: 1, Batch number: 2100, Loss: 15475.9228515625\n",
      "Epoch: 1, Batch number: 2200, Loss: 15452.6142578125\n",
      "Epoch: 1, Batch number: 2300, Loss: 15625.1875\n",
      "Epoch: 1, Batch number: 2400, Loss: 15106.4609375\n",
      "Epoch: 1, Batch number: 2500, Loss: 15387.470703125\n",
      "Epoch: 1, Batch number: 2600, Loss: 15523.5087890625\n",
      "Epoch: 1, Batch number: 2700, Loss: 15058.7001953125\n",
      "Epoch: 1, Batch number: 2800, Loss: 15235.5810546875\n",
      "Epoch: 1, Batch number: 2900, Loss: 15303.294921875\n",
      "Epoch: 1, Batch number: 3000, Loss: 14882.529296875\n",
      "Epoch: 1, Batch number: 3100, Loss: 14795.2978515625\n",
      "Epoch: 1, Batch number: 3200, Loss: 14686.310546875\n",
      "Epoch: 1, Batch number: 3300, Loss: 14917.2373046875\n",
      "Epoch: 1, Batch number: 3400, Loss: 15105.998046875\n",
      "Epoch: 1, Batch number: 3500, Loss: 14976.3818359375\n",
      "Epoch: 1, Batch number: 3600, Loss: 15068.216796875\n",
      "Epoch: 1, Batch number: 3700, Loss: 14696.0546875\n",
      "Epoch: 1, Batch number: 3800, Loss: 14865.9755859375\n",
      "Epoch: 1, Batch number: 3900, Loss: 14750.53125\n",
      "Epoch: 1, Batch number: 4000, Loss: 14684.9072265625\n",
      "Epoch: 1, Batch number: 4100, Loss: 14877.7841796875\n",
      "Epoch: 1, Batch number: 4200, Loss: 15002.4326171875\n",
      "Epoch: 1, Batch number: 4300, Loss: 14574.958984375\n",
      "Epoch: 1, Batch number: 4400, Loss: 14626.5126953125\n",
      "Epoch: 1, Batch number: 4500, Loss: 14482.2421875\n",
      "Epoch: 1, Batch number: 4600, Loss: 14609.2177734375\n",
      "Epoch: 1, Batch number: 4700, Loss: 14735.314453125\n",
      "Epoch: 1, Batch number: 4800, Loss: 14772.5009765625\n",
      "Epoch: 1, Batch number: 4900, Loss: 14243.646484375\n",
      "Epoch: 1, Batch number: 5000, Loss: 14568.4375\n",
      "Epoch: 1, Batch number: 5100, Loss: 14228.0087890625\n",
      "Epoch: 1, Batch number: 5200, Loss: 14660.1748046875\n",
      "Epoch: 1, Batch number: 5300, Loss: 14497.87890625\n",
      "Epoch: 1, Batch number: 5400, Loss: 14341.7412109375\n",
      "Epoch: 1, Batch number: 5500, Loss: 14223.56640625\n",
      "Epoch: 1, Batch number: 5600, Loss: 14485.642578125\n",
      "Epoch: 1, Batch number: 5700, Loss: 14633.2021484375\n",
      "Epoch: 1, Batch number: 5800, Loss: 14763.0908203125\n",
      "Epoch: 1, Batch number: 5900, Loss: 14379.8671875\n",
      "Epoch: 1, Batch number: 6000, Loss: 14449.529296875\n",
      "Epoch: 1, Batch number: 6100, Loss: 14341.8203125\n",
      "Epoch: 1, Batch number: 6200, Loss: 14447.5771484375\n",
      "Epoch: 1, Batch number: 6300, Loss: 14095.5810546875\n",
      "Epoch: 1, Batch number: 6400, Loss: 14640.75390625\n",
      "Epoch: 1, Batch number: 6500, Loss: 14650.6796875\n",
      "Epoch: 1, Batch number: 6600, Loss: 14277.697265625\n",
      "Epoch: 1, Batch number: 6700, Loss: 14430.4482421875\n",
      "Epoch: 1, Batch number: 6800, Loss: 13935.08984375\n",
      "Epoch: 1, Batch number: 6900, Loss: 14268.9541015625\n",
      "Epoch: 1, Batch number: 7000, Loss: 14438.720703125\n",
      "Epoch: 1, Batch number: 7100, Loss: 14229.8095703125\n",
      "Epoch: 1, Batch number: 7200, Loss: 14236.52734375\n",
      "Epoch: 1, Batch number: 7300, Loss: 14169.5869140625\n",
      "Epoch: 1, Batch number: 7400, Loss: 14113.970703125\n",
      "Epoch: 1, Batch number: 7500, Loss: 14068.2392578125\n",
      "Epoch: 1, Batch number: 7600, Loss: 14437.8232421875\n",
      "Epoch: 1, Batch number: 7700, Loss: 14092.7958984375\n",
      "Epoch: 1, Batch number: 7800, Loss: 13949.064453125\n",
      "Epoch: 1, Batch number: 7900, Loss: 14251.552734375\n",
      "Epoch: 1, Batch number: 8000, Loss: 14058.982421875\n",
      "Epoch: 1, Batch number: 8100, Loss: 13990.5966796875\n",
      "Epoch: 1, Batch number: 8200, Loss: 14129.8232421875\n",
      "Epoch: 1, Batch number: 8300, Loss: 14182.1923828125\n",
      "Epoch: 1, Batch number: 8400, Loss: 14198.8193359375\n",
      "Epoch: 1, Batch number: 8500, Loss: 13906.8388671875\n",
      "Epoch: 1, Batch number: 8600, Loss: 14456.0166015625\n",
      "Epoch: 2, Batch number: 79, Loss: 13851.6708984375\n",
      "Epoch: 2, Batch number: 179, Loss: 14022.267578125\n",
      "Epoch: 2, Batch number: 279, Loss: 14114.3818359375\n",
      "Epoch: 2, Batch number: 379, Loss: 14187.87890625\n",
      "Epoch: 2, Batch number: 479, Loss: 14218.1220703125\n",
      "Epoch: 2, Batch number: 579, Loss: 13896.3115234375\n",
      "Epoch: 2, Batch number: 679, Loss: 13806.982421875\n",
      "Epoch: 2, Batch number: 779, Loss: 13916.30859375\n",
      "Epoch: 2, Batch number: 879, Loss: 13956.78515625\n",
      "Epoch: 2, Batch number: 979, Loss: 13750.4306640625\n",
      "Epoch: 2, Batch number: 1079, Loss: 13978.009765625\n",
      "Epoch: 2, Batch number: 1179, Loss: 13825.0771484375\n",
      "Epoch: 2, Batch number: 1279, Loss: 13994.0458984375\n",
      "Epoch: 2, Batch number: 1379, Loss: 13671.94140625\n",
      "Epoch: 2, Batch number: 1479, Loss: 14164.7255859375\n",
      "Epoch: 2, Batch number: 1579, Loss: 13814.2021484375\n",
      "Epoch: 2, Batch number: 1679, Loss: 14046.1279296875\n",
      "Epoch: 2, Batch number: 1779, Loss: 13873.1298828125\n",
      "Epoch: 2, Batch number: 1879, Loss: 14013.875\n",
      "Epoch: 2, Batch number: 1979, Loss: 14020.88671875\n",
      "Epoch: 2, Batch number: 2079, Loss: 13789.7529296875\n",
      "Epoch: 2, Batch number: 2179, Loss: 13752.2275390625\n",
      "Epoch: 2, Batch number: 2279, Loss: 13828.13671875\n",
      "Epoch: 2, Batch number: 2379, Loss: 13998.8359375\n",
      "Epoch: 2, Batch number: 2479, Loss: 13919.0234375\n",
      "Epoch: 2, Batch number: 2579, Loss: 13992.89453125\n",
      "Epoch: 2, Batch number: 2679, Loss: 13969.939453125\n",
      "Epoch: 2, Batch number: 2779, Loss: 14115.6669921875\n",
      "Epoch: 2, Batch number: 2879, Loss: 13605.46484375\n",
      "Epoch: 2, Batch number: 2979, Loss: 13981.0576171875\n",
      "Epoch: 2, Batch number: 3079, Loss: 13848.7568359375\n",
      "Epoch: 2, Batch number: 3179, Loss: 13954.6689453125\n",
      "Epoch: 2, Batch number: 3279, Loss: 13980.033203125\n",
      "Epoch: 2, Batch number: 3379, Loss: 14054.083984375\n",
      "Epoch: 2, Batch number: 3479, Loss: 13846.978515625\n",
      "Epoch: 2, Batch number: 3579, Loss: 13593.1630859375\n",
      "Epoch: 2, Batch number: 3679, Loss: 13793.6171875\n",
      "Epoch: 2, Batch number: 3779, Loss: 13942.5966796875\n",
      "Epoch: 2, Batch number: 3879, Loss: 13878.60546875\n",
      "Epoch: 2, Batch number: 3979, Loss: 14052.5302734375\n",
      "Epoch: 2, Batch number: 4079, Loss: 13865.4697265625\n",
      "Epoch: 2, Batch number: 4179, Loss: 13659.4267578125\n",
      "Epoch: 2, Batch number: 4279, Loss: 14061.4130859375\n",
      "Epoch: 2, Batch number: 4379, Loss: 13977.3291015625\n",
      "Epoch: 2, Batch number: 4479, Loss: 13664.5537109375\n",
      "Epoch: 2, Batch number: 4579, Loss: 13962.1201171875\n",
      "Epoch: 2, Batch number: 4679, Loss: 13715.45703125\n",
      "Epoch: 2, Batch number: 4779, Loss: 13915.4130859375\n",
      "Epoch: 2, Batch number: 4879, Loss: 13765.23828125\n",
      "Epoch: 2, Batch number: 4979, Loss: 13667.6435546875\n",
      "Epoch: 2, Batch number: 5079, Loss: 13880.146484375\n",
      "Epoch: 2, Batch number: 5179, Loss: 13658.87109375\n",
      "Epoch: 2, Batch number: 5279, Loss: 13765.76171875\n",
      "Epoch: 2, Batch number: 5379, Loss: 13728.3017578125\n",
      "Epoch: 2, Batch number: 5479, Loss: 13929.650390625\n",
      "Epoch: 2, Batch number: 5579, Loss: 13868.7666015625\n",
      "Epoch: 2, Batch number: 5679, Loss: 13849.3203125\n",
      "Epoch: 2, Batch number: 5779, Loss: 13667.71484375\n",
      "Epoch: 2, Batch number: 5879, Loss: 14057.4619140625\n",
      "Epoch: 2, Batch number: 5979, Loss: 13772.62890625\n",
      "Epoch: 2, Batch number: 6079, Loss: 13823.8740234375\n",
      "Epoch: 2, Batch number: 6179, Loss: 13774.06640625\n",
      "Epoch: 2, Batch number: 6279, Loss: 13941.525390625\n",
      "Epoch: 2, Batch number: 6379, Loss: 13975.89453125\n",
      "Epoch: 2, Batch number: 6479, Loss: 13655.1328125\n",
      "Epoch: 2, Batch number: 6579, Loss: 13770.6845703125\n",
      "Epoch: 2, Batch number: 6679, Loss: 14064.6376953125\n",
      "Epoch: 2, Batch number: 6779, Loss: 13943.7841796875\n",
      "Epoch: 2, Batch number: 6879, Loss: 13861.6376953125\n",
      "Epoch: 2, Batch number: 6979, Loss: 13828.0693359375\n",
      "Epoch: 2, Batch number: 7079, Loss: 13519.8359375\n",
      "Epoch: 2, Batch number: 7179, Loss: 13714.53515625\n",
      "Epoch: 2, Batch number: 7279, Loss: 13720.2236328125\n",
      "Epoch: 2, Batch number: 7379, Loss: 13946.013671875\n",
      "Epoch: 2, Batch number: 7479, Loss: 13752.1025390625\n",
      "Epoch: 2, Batch number: 7579, Loss: 13512.1337890625\n",
      "Epoch: 2, Batch number: 7679, Loss: 13843.0849609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 7779, Loss: 13667.1953125\n",
      "Epoch: 2, Batch number: 7879, Loss: 13618.791015625\n",
      "Epoch: 2, Batch number: 7979, Loss: 13902.7939453125\n",
      "Epoch: 2, Batch number: 8079, Loss: 13940.013671875\n",
      "Epoch: 2, Batch number: 8179, Loss: 14007.8193359375\n",
      "Epoch: 2, Batch number: 8279, Loss: 13656.83984375\n",
      "Epoch: 2, Batch number: 8379, Loss: 13597.2802734375\n",
      "Epoch: 2, Batch number: 8479, Loss: 13603.888671875\n",
      "Epoch: 2, Batch number: 8579, Loss: 13972.49609375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21671.755859375\n",
      "Epoch: 1, Batch number: 100, Loss: 20411.244140625\n",
      "Epoch: 1, Batch number: 200, Loss: 19565.419921875\n",
      "Epoch: 1, Batch number: 300, Loss: 18772.638671875\n",
      "Epoch: 1, Batch number: 400, Loss: 18252.6875\n",
      "Epoch: 1, Batch number: 500, Loss: 18042.708984375\n",
      "Epoch: 1, Batch number: 600, Loss: 17764.44921875\n",
      "Epoch: 1, Batch number: 700, Loss: 17167.5\n",
      "Epoch: 1, Batch number: 800, Loss: 17320.677734375\n",
      "Epoch: 1, Batch number: 900, Loss: 16900.4453125\n",
      "Epoch: 1, Batch number: 1000, Loss: 16495.48828125\n",
      "Epoch: 1, Batch number: 1100, Loss: 16692.6953125\n",
      "Epoch: 1, Batch number: 1200, Loss: 16395.1328125\n",
      "Epoch: 1, Batch number: 1300, Loss: 16262.6591796875\n",
      "Epoch: 1, Batch number: 1400, Loss: 15886.1123046875\n",
      "Epoch: 1, Batch number: 1500, Loss: 15669.4111328125\n",
      "Epoch: 1, Batch number: 1600, Loss: 15425.5458984375\n",
      "Epoch: 1, Batch number: 1700, Loss: 15400.146484375\n",
      "Epoch: 1, Batch number: 1800, Loss: 15601.3916015625\n",
      "Epoch: 1, Batch number: 1900, Loss: 15562.8037109375\n",
      "Epoch: 1, Batch number: 2000, Loss: 15207.412109375\n",
      "Epoch: 1, Batch number: 2100, Loss: 15233.3876953125\n",
      "Epoch: 1, Batch number: 2200, Loss: 15212.3642578125\n",
      "Epoch: 1, Batch number: 2300, Loss: 15007.322265625\n",
      "Epoch: 1, Batch number: 2400, Loss: 15161.373046875\n",
      "Epoch: 1, Batch number: 2500, Loss: 14773.916015625\n",
      "Epoch: 1, Batch number: 2600, Loss: 14830.8876953125\n",
      "Epoch: 1, Batch number: 2700, Loss: 14836.775390625\n",
      "Epoch: 1, Batch number: 2800, Loss: 14767.525390625\n",
      "Epoch: 1, Batch number: 2900, Loss: 14842.6396484375\n",
      "Epoch: 1, Batch number: 3000, Loss: 14625.6455078125\n",
      "Epoch: 1, Batch number: 3100, Loss: 14592.12109375\n",
      "Epoch: 1, Batch number: 3200, Loss: 14690.2646484375\n",
      "Epoch: 1, Batch number: 3300, Loss: 14496.36328125\n",
      "Epoch: 1, Batch number: 3400, Loss: 14598.080078125\n",
      "Epoch: 1, Batch number: 3500, Loss: 14588.23046875\n",
      "Epoch: 1, Batch number: 3600, Loss: 14463.5361328125\n",
      "Epoch: 1, Batch number: 3700, Loss: 14176.0439453125\n",
      "Epoch: 1, Batch number: 3800, Loss: 14635.7958984375\n",
      "Epoch: 1, Batch number: 3900, Loss: 14389.048828125\n",
      "Epoch: 1, Batch number: 4000, Loss: 14446.431640625\n",
      "Epoch: 1, Batch number: 4100, Loss: 14122.3740234375\n",
      "Epoch: 1, Batch number: 4200, Loss: 14020.0546875\n",
      "Epoch: 1, Batch number: 4300, Loss: 14255.1201171875\n",
      "Epoch: 1, Batch number: 4400, Loss: 14257.603515625\n",
      "Epoch: 1, Batch number: 4500, Loss: 14458.1357421875\n",
      "Epoch: 1, Batch number: 4600, Loss: 14385.51171875\n",
      "Epoch: 1, Batch number: 4700, Loss: 14046.349609375\n",
      "Epoch: 1, Batch number: 4800, Loss: 14180.0927734375\n",
      "Epoch: 1, Batch number: 4900, Loss: 14203.048828125\n",
      "Epoch: 1, Batch number: 5000, Loss: 14081.9404296875\n",
      "Epoch: 1, Batch number: 5100, Loss: 14495.3564453125\n",
      "Epoch: 1, Batch number: 5200, Loss: 14292.283203125\n",
      "Epoch: 1, Batch number: 5300, Loss: 14480.15625\n",
      "Epoch: 1, Batch number: 5400, Loss: 14075.7109375\n",
      "Epoch: 1, Batch number: 5500, Loss: 14088.9501953125\n",
      "Epoch: 1, Batch number: 5600, Loss: 14095.2822265625\n",
      "Epoch: 1, Batch number: 5700, Loss: 14312.171875\n",
      "Epoch: 1, Batch number: 5800, Loss: 14317.2734375\n",
      "Epoch: 1, Batch number: 5900, Loss: 14321.89453125\n",
      "Epoch: 1, Batch number: 6000, Loss: 14029.26171875\n",
      "Epoch: 1, Batch number: 6100, Loss: 14296.451171875\n",
      "Epoch: 1, Batch number: 6200, Loss: 14124.91796875\n",
      "Epoch: 1, Batch number: 6300, Loss: 14153.3212890625\n",
      "Epoch: 1, Batch number: 6400, Loss: 14224.0419921875\n",
      "Epoch: 1, Batch number: 6500, Loss: 14091.8427734375\n",
      "Epoch: 1, Batch number: 6600, Loss: 14089.462890625\n",
      "Epoch: 1, Batch number: 6700, Loss: 14109.8046875\n",
      "Epoch: 1, Batch number: 6800, Loss: 13824.6826171875\n",
      "Epoch: 1, Batch number: 6900, Loss: 14245.0419921875\n",
      "Epoch: 1, Batch number: 7000, Loss: 13967.60546875\n",
      "Epoch: 1, Batch number: 7100, Loss: 14118.1376953125\n",
      "Epoch: 1, Batch number: 7200, Loss: 14013.8955078125\n",
      "Epoch: 1, Batch number: 7300, Loss: 14215.6875\n",
      "Epoch: 1, Batch number: 7400, Loss: 13801.7392578125\n",
      "Epoch: 1, Batch number: 7500, Loss: 13766.5771484375\n",
      "Epoch: 1, Batch number: 7600, Loss: 13970.3828125\n",
      "Epoch: 1, Batch number: 7700, Loss: 14047.158203125\n",
      "Epoch: 1, Batch number: 7800, Loss: 14100.3515625\n",
      "Epoch: 1, Batch number: 7900, Loss: 14086.6650390625\n",
      "Epoch: 1, Batch number: 8000, Loss: 13871.14453125\n",
      "Epoch: 1, Batch number: 8100, Loss: 13859.48046875\n",
      "Epoch: 1, Batch number: 8200, Loss: 14043.5458984375\n",
      "Epoch: 1, Batch number: 8300, Loss: 13895.3544921875\n",
      "Epoch: 1, Batch number: 8400, Loss: 14153.4814453125\n",
      "Epoch: 1, Batch number: 8500, Loss: 13962.7763671875\n",
      "Epoch: 1, Batch number: 8600, Loss: 13903.2861328125\n",
      "Epoch: 2, Batch number: 79, Loss: 13670.9755859375\n",
      "Epoch: 2, Batch number: 179, Loss: 13714.6748046875\n",
      "Epoch: 2, Batch number: 279, Loss: 13656.14453125\n",
      "Epoch: 2, Batch number: 379, Loss: 13738.875\n",
      "Epoch: 2, Batch number: 479, Loss: 13733.076171875\n",
      "Epoch: 2, Batch number: 579, Loss: 13640.69140625\n",
      "Epoch: 2, Batch number: 679, Loss: 13557.9990234375\n",
      "Epoch: 2, Batch number: 779, Loss: 13662.46875\n",
      "Epoch: 2, Batch number: 879, Loss: 13810.763671875\n",
      "Epoch: 2, Batch number: 979, Loss: 13503.302734375\n",
      "Epoch: 2, Batch number: 1079, Loss: 13724.130859375\n",
      "Epoch: 2, Batch number: 1179, Loss: 13563.4794921875\n",
      "Epoch: 2, Batch number: 1279, Loss: 13546.2998046875\n",
      "Epoch: 2, Batch number: 1379, Loss: 13646.8486328125\n",
      "Epoch: 2, Batch number: 1479, Loss: 13791.6962890625\n",
      "Epoch: 2, Batch number: 1579, Loss: 13657.107421875\n",
      "Epoch: 2, Batch number: 1679, Loss: 13733.9287109375\n",
      "Epoch: 2, Batch number: 1779, Loss: 13698.6435546875\n",
      "Epoch: 2, Batch number: 1879, Loss: 13587.2412109375\n",
      "Epoch: 2, Batch number: 1979, Loss: 13849.109375\n",
      "Epoch: 2, Batch number: 2079, Loss: 13883.6259765625\n",
      "Epoch: 2, Batch number: 2179, Loss: 13493.98046875\n",
      "Epoch: 2, Batch number: 2279, Loss: 13928.740234375\n",
      "Epoch: 2, Batch number: 2379, Loss: 13833.419921875\n",
      "Epoch: 2, Batch number: 2479, Loss: 13526.2236328125\n",
      "Epoch: 2, Batch number: 2579, Loss: 13698.583984375\n",
      "Epoch: 2, Batch number: 2679, Loss: 13830.46484375\n",
      "Epoch: 2, Batch number: 2779, Loss: 13451.2626953125\n",
      "Epoch: 2, Batch number: 2879, Loss: 13683.0068359375\n",
      "Epoch: 2, Batch number: 2979, Loss: 13702.2646484375\n",
      "Epoch: 2, Batch number: 3079, Loss: 13486.7392578125\n",
      "Epoch: 2, Batch number: 3179, Loss: 13625.7001953125\n",
      "Epoch: 2, Batch number: 3279, Loss: 13872.0458984375\n",
      "Epoch: 2, Batch number: 3379, Loss: 13642.0205078125\n",
      "Epoch: 2, Batch number: 3479, Loss: 13625.859375\n",
      "Epoch: 2, Batch number: 3579, Loss: 13713.9990234375\n",
      "Epoch: 2, Batch number: 3679, Loss: 13534.5498046875\n",
      "Epoch: 2, Batch number: 3779, Loss: 13639.587890625\n",
      "Epoch: 2, Batch number: 3879, Loss: 13718.6376953125\n",
      "Epoch: 2, Batch number: 3979, Loss: 13616.9267578125\n",
      "Epoch: 2, Batch number: 4079, Loss: 13701.7265625\n",
      "Epoch: 2, Batch number: 4179, Loss: 13578.0615234375\n",
      "Epoch: 2, Batch number: 4279, Loss: 13722.927734375\n",
      "Epoch: 2, Batch number: 4379, Loss: 13672.271484375\n",
      "Epoch: 2, Batch number: 4479, Loss: 13604.07421875\n",
      "Epoch: 2, Batch number: 4579, Loss: 13449.490234375\n",
      "Epoch: 2, Batch number: 4679, Loss: 13379.8251953125\n",
      "Epoch: 2, Batch number: 4779, Loss: 13920.9365234375\n",
      "Epoch: 2, Batch number: 4879, Loss: 13586.130859375\n",
      "Epoch: 2, Batch number: 4979, Loss: 13490.2705078125\n",
      "Epoch: 2, Batch number: 5079, Loss: 13490.0869140625\n",
      "Epoch: 2, Batch number: 5179, Loss: 13521.4560546875\n",
      "Epoch: 2, Batch number: 5279, Loss: 13471.958984375\n",
      "Epoch: 2, Batch number: 5379, Loss: 13510.267578125\n",
      "Epoch: 2, Batch number: 5479, Loss: 13314.861328125\n",
      "Epoch: 2, Batch number: 5579, Loss: 13644.189453125\n",
      "Epoch: 2, Batch number: 5679, Loss: 13486.857421875\n",
      "Epoch: 2, Batch number: 5779, Loss: 13755.6015625\n",
      "Epoch: 2, Batch number: 5879, Loss: 13709.138671875\n",
      "Epoch: 2, Batch number: 5979, Loss: 13864.0361328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 6079, Loss: 13595.34765625\n",
      "Epoch: 2, Batch number: 6179, Loss: 13287.353515625\n",
      "Epoch: 2, Batch number: 6279, Loss: 13279.3857421875\n",
      "Epoch: 2, Batch number: 6379, Loss: 13513.6962890625\n",
      "Epoch: 2, Batch number: 6479, Loss: 13738.28515625\n",
      "Epoch: 2, Batch number: 6579, Loss: 13385.2626953125\n",
      "Epoch: 2, Batch number: 6679, Loss: 13679.9306640625\n",
      "Epoch: 2, Batch number: 6779, Loss: 13374.0126953125\n",
      "Epoch: 2, Batch number: 6879, Loss: 13553.818359375\n",
      "Epoch: 2, Batch number: 6979, Loss: 13603.7685546875\n",
      "Epoch: 2, Batch number: 7079, Loss: 13588.18359375\n",
      "Epoch: 2, Batch number: 7179, Loss: 13481.634765625\n",
      "Epoch: 2, Batch number: 7279, Loss: 13436.2275390625\n",
      "Epoch: 2, Batch number: 7379, Loss: 13456.0517578125\n",
      "Epoch: 2, Batch number: 7479, Loss: 13596.337890625\n",
      "Epoch: 2, Batch number: 7579, Loss: 13770.30859375\n",
      "Epoch: 2, Batch number: 7679, Loss: 13685.2861328125\n",
      "Epoch: 2, Batch number: 7779, Loss: 13456.6015625\n",
      "Epoch: 2, Batch number: 7879, Loss: 13654.154296875\n",
      "Epoch: 2, Batch number: 7979, Loss: 13478.755859375\n",
      "Epoch: 2, Batch number: 8079, Loss: 13624.091796875\n",
      "Epoch: 2, Batch number: 8179, Loss: 13405.5068359375\n",
      "Epoch: 2, Batch number: 8279, Loss: 13531.3779296875\n",
      "Epoch: 2, Batch number: 8379, Loss: 13766.064453125\n",
      "Epoch: 2, Batch number: 8479, Loss: 13865.9296875\n",
      "Epoch: 2, Batch number: 8579, Loss: 13295.3994140625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21779.857421875\n",
      "Epoch: 1, Batch number: 100, Loss: 20258.67578125\n",
      "Epoch: 1, Batch number: 200, Loss: 18993.376953125\n",
      "Epoch: 1, Batch number: 300, Loss: 18614.916015625\n",
      "Epoch: 1, Batch number: 400, Loss: 18448.412109375\n",
      "Epoch: 1, Batch number: 500, Loss: 17481.275390625\n",
      "Epoch: 1, Batch number: 600, Loss: 17347.560546875\n",
      "Epoch: 1, Batch number: 700, Loss: 17251.111328125\n",
      "Epoch: 1, Batch number: 800, Loss: 16999.138671875\n",
      "Epoch: 1, Batch number: 900, Loss: 16126.6787109375\n",
      "Epoch: 1, Batch number: 1000, Loss: 16074.2265625\n",
      "Epoch: 1, Batch number: 1100, Loss: 15742.7587890625\n",
      "Epoch: 1, Batch number: 1200, Loss: 16091.314453125\n",
      "Epoch: 1, Batch number: 1300, Loss: 15656.1484375\n",
      "Epoch: 1, Batch number: 1400, Loss: 15689.15234375\n",
      "Epoch: 1, Batch number: 1500, Loss: 15655.3984375\n",
      "Epoch: 1, Batch number: 1600, Loss: 15447.90625\n",
      "Epoch: 1, Batch number: 1700, Loss: 15173.9326171875\n",
      "Epoch: 1, Batch number: 1800, Loss: 15187.728515625\n",
      "Epoch: 1, Batch number: 1900, Loss: 15359.8359375\n",
      "Epoch: 1, Batch number: 2000, Loss: 15081.5390625\n",
      "Epoch: 1, Batch number: 2100, Loss: 14885.7548828125\n",
      "Epoch: 1, Batch number: 2200, Loss: 14696.2236328125\n",
      "Epoch: 1, Batch number: 2300, Loss: 15040.2470703125\n",
      "Epoch: 1, Batch number: 2400, Loss: 14786.318359375\n",
      "Epoch: 1, Batch number: 2500, Loss: 14561.6943359375\n",
      "Epoch: 1, Batch number: 2600, Loss: 14834.076171875\n",
      "Epoch: 1, Batch number: 2700, Loss: 14737.48828125\n",
      "Epoch: 1, Batch number: 2800, Loss: 14578.56640625\n",
      "Epoch: 1, Batch number: 2900, Loss: 14607.107421875\n",
      "Epoch: 1, Batch number: 3000, Loss: 14538.49609375\n",
      "Epoch: 1, Batch number: 3100, Loss: 14518.923828125\n",
      "Epoch: 1, Batch number: 3200, Loss: 14608.83203125\n",
      "Epoch: 1, Batch number: 3300, Loss: 14571.41015625\n",
      "Epoch: 1, Batch number: 3400, Loss: 14383.82421875\n",
      "Epoch: 1, Batch number: 3500, Loss: 14494.0107421875\n",
      "Epoch: 1, Batch number: 3600, Loss: 14308.8349609375\n",
      "Epoch: 1, Batch number: 3700, Loss: 14577.662109375\n",
      "Epoch: 1, Batch number: 3800, Loss: 14536.673828125\n",
      "Epoch: 1, Batch number: 3900, Loss: 14235.3427734375\n",
      "Epoch: 1, Batch number: 4000, Loss: 14314.689453125\n",
      "Epoch: 1, Batch number: 4100, Loss: 14225.1533203125\n",
      "Epoch: 1, Batch number: 4200, Loss: 14073.486328125\n",
      "Epoch: 1, Batch number: 4300, Loss: 14176.55859375\n",
      "Epoch: 1, Batch number: 4400, Loss: 14276.81640625\n",
      "Epoch: 1, Batch number: 4500, Loss: 14037.65234375\n",
      "Epoch: 1, Batch number: 4600, Loss: 14325.29296875\n",
      "Epoch: 1, Batch number: 4700, Loss: 14211.0556640625\n",
      "Epoch: 1, Batch number: 4800, Loss: 14000.4814453125\n",
      "Epoch: 1, Batch number: 4900, Loss: 14202.37890625\n",
      "Epoch: 1, Batch number: 5000, Loss: 14066.958984375\n",
      "Epoch: 1, Batch number: 5100, Loss: 14109.9462890625\n",
      "Epoch: 1, Batch number: 5200, Loss: 14352.6396484375\n",
      "Epoch: 1, Batch number: 5300, Loss: 14062.701171875\n",
      "Epoch: 1, Batch number: 5400, Loss: 14157.2490234375\n",
      "Epoch: 1, Batch number: 5500, Loss: 14276.0703125\n",
      "Epoch: 1, Batch number: 5600, Loss: 14342.11328125\n",
      "Epoch: 1, Batch number: 5700, Loss: 14281.2998046875\n",
      "Epoch: 1, Batch number: 5800, Loss: 14076.837890625\n",
      "Epoch: 1, Batch number: 5900, Loss: 14199.5732421875\n",
      "Epoch: 1, Batch number: 6000, Loss: 13827.8134765625\n",
      "Epoch: 1, Batch number: 6100, Loss: 13861.353515625\n",
      "Epoch: 1, Batch number: 6200, Loss: 14084.625\n",
      "Epoch: 1, Batch number: 6300, Loss: 13854.6796875\n",
      "Epoch: 1, Batch number: 6400, Loss: 13831.4013671875\n",
      "Epoch: 1, Batch number: 6500, Loss: 13949.6171875\n",
      "Epoch: 1, Batch number: 6600, Loss: 13933.9384765625\n",
      "Epoch: 1, Batch number: 6700, Loss: 14096.7607421875\n",
      "Epoch: 1, Batch number: 6800, Loss: 14212.3935546875\n",
      "Epoch: 1, Batch number: 6900, Loss: 13724.68359375\n",
      "Epoch: 1, Batch number: 7000, Loss: 13794.466796875\n",
      "Epoch: 1, Batch number: 7100, Loss: 14410.4521484375\n",
      "Epoch: 1, Batch number: 7200, Loss: 14021.59375\n",
      "Epoch: 1, Batch number: 7300, Loss: 13859.23828125\n",
      "Epoch: 1, Batch number: 7400, Loss: 14051.1923828125\n",
      "Epoch: 1, Batch number: 7500, Loss: 14053.5498046875\n",
      "Epoch: 1, Batch number: 7600, Loss: 13852.5439453125\n",
      "Epoch: 1, Batch number: 7700, Loss: 14006.23828125\n",
      "Epoch: 1, Batch number: 7800, Loss: 13694.7109375\n",
      "Epoch: 1, Batch number: 7900, Loss: 13820.572265625\n",
      "Epoch: 1, Batch number: 8000, Loss: 14067.0615234375\n",
      "Epoch: 1, Batch number: 8100, Loss: 13823.1455078125\n",
      "Epoch: 1, Batch number: 8200, Loss: 13935.66015625\n",
      "Epoch: 1, Batch number: 8300, Loss: 13707.1376953125\n",
      "Epoch: 1, Batch number: 8400, Loss: 13772.376953125\n",
      "Epoch: 1, Batch number: 8500, Loss: 13724.302734375\n",
      "Epoch: 1, Batch number: 8600, Loss: 13821.0380859375\n",
      "Epoch: 2, Batch number: 79, Loss: 13441.8291015625\n",
      "Epoch: 2, Batch number: 179, Loss: 13625.869140625\n",
      "Epoch: 2, Batch number: 279, Loss: 13557.052734375\n",
      "Epoch: 2, Batch number: 379, Loss: 13572.5439453125\n",
      "Epoch: 2, Batch number: 479, Loss: 13314.2158203125\n",
      "Epoch: 2, Batch number: 579, Loss: 13578.2861328125\n",
      "Epoch: 2, Batch number: 679, Loss: 13432.5068359375\n",
      "Epoch: 2, Batch number: 779, Loss: 13486.423828125\n",
      "Epoch: 2, Batch number: 879, Loss: 13462.2236328125\n",
      "Epoch: 2, Batch number: 979, Loss: 13585.6845703125\n",
      "Epoch: 2, Batch number: 1079, Loss: 13606.439453125\n",
      "Epoch: 2, Batch number: 1179, Loss: 13414.931640625\n",
      "Epoch: 2, Batch number: 1279, Loss: 13368.2685546875\n",
      "Epoch: 2, Batch number: 1379, Loss: 13538.3359375\n",
      "Epoch: 2, Batch number: 1479, Loss: 13120.4990234375\n",
      "Epoch: 2, Batch number: 1579, Loss: 13501.140625\n",
      "Epoch: 2, Batch number: 1679, Loss: 13487.5537109375\n",
      "Epoch: 2, Batch number: 1779, Loss: 13682.87890625\n",
      "Epoch: 2, Batch number: 1879, Loss: 13711.6259765625\n",
      "Epoch: 2, Batch number: 1979, Loss: 13455.0107421875\n",
      "Epoch: 2, Batch number: 2079, Loss: 13527.77734375\n",
      "Epoch: 2, Batch number: 2179, Loss: 13487.763671875\n",
      "Epoch: 2, Batch number: 2279, Loss: 13289.4287109375\n",
      "Epoch: 2, Batch number: 2379, Loss: 13395.26171875\n",
      "Epoch: 2, Batch number: 2479, Loss: 13400.4140625\n",
      "Epoch: 2, Batch number: 2579, Loss: 13199.423828125\n",
      "Epoch: 2, Batch number: 2679, Loss: 13498.1650390625\n",
      "Epoch: 2, Batch number: 2779, Loss: 13324.947265625\n",
      "Epoch: 2, Batch number: 2879, Loss: 13532.7470703125\n",
      "Epoch: 2, Batch number: 2979, Loss: 13463.81640625\n",
      "Epoch: 2, Batch number: 3079, Loss: 13635.89453125\n",
      "Epoch: 2, Batch number: 3179, Loss: 13645.703125\n",
      "Epoch: 2, Batch number: 3279, Loss: 13244.0947265625\n",
      "Epoch: 2, Batch number: 3379, Loss: 13394.0859375\n",
      "Epoch: 2, Batch number: 3479, Loss: 13485.39453125\n",
      "Epoch: 2, Batch number: 3579, Loss: 13335.6181640625\n",
      "Epoch: 2, Batch number: 3679, Loss: 13381.626953125\n",
      "Epoch: 2, Batch number: 3779, Loss: 13443.84765625\n",
      "Epoch: 2, Batch number: 3879, Loss: 13337.5537109375\n",
      "Epoch: 2, Batch number: 3979, Loss: 13204.6943359375\n",
      "Epoch: 2, Batch number: 4079, Loss: 13372.3896484375\n",
      "Epoch: 2, Batch number: 4179, Loss: 13327.318359375\n",
      "Epoch: 2, Batch number: 4279, Loss: 13627.8701171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 4379, Loss: 13304.1494140625\n",
      "Epoch: 2, Batch number: 4479, Loss: 13502.6044921875\n",
      "Epoch: 2, Batch number: 4579, Loss: 13511.5634765625\n",
      "Epoch: 2, Batch number: 4679, Loss: 13255.71875\n",
      "Epoch: 2, Batch number: 4779, Loss: 13646.4658203125\n",
      "Epoch: 2, Batch number: 4879, Loss: 13488.115234375\n",
      "Epoch: 2, Batch number: 4979, Loss: 13443.6044921875\n",
      "Epoch: 2, Batch number: 5079, Loss: 13567.482421875\n",
      "Epoch: 2, Batch number: 5179, Loss: 13399.0224609375\n",
      "Epoch: 2, Batch number: 5279, Loss: 13611.7392578125\n",
      "Epoch: 2, Batch number: 5379, Loss: 13612.0126953125\n",
      "Epoch: 2, Batch number: 5479, Loss: 13381.1796875\n",
      "Epoch: 2, Batch number: 5579, Loss: 13517.0419921875\n",
      "Epoch: 2, Batch number: 5679, Loss: 13543.1337890625\n",
      "Epoch: 2, Batch number: 5779, Loss: 13415.43359375\n",
      "Epoch: 2, Batch number: 5879, Loss: 13371.556640625\n",
      "Epoch: 2, Batch number: 5979, Loss: 13169.0048828125\n",
      "Epoch: 2, Batch number: 6079, Loss: 13261.6123046875\n",
      "Epoch: 2, Batch number: 6179, Loss: 13592.0458984375\n",
      "Epoch: 2, Batch number: 6279, Loss: 13338.060546875\n",
      "Epoch: 2, Batch number: 6379, Loss: 13255.7412109375\n",
      "Epoch: 2, Batch number: 6479, Loss: 13619.4150390625\n",
      "Epoch: 2, Batch number: 6579, Loss: 13292.0615234375\n",
      "Epoch: 2, Batch number: 6679, Loss: 13749.5849609375\n",
      "Epoch: 2, Batch number: 6779, Loss: 13384.4365234375\n",
      "Epoch: 2, Batch number: 6879, Loss: 13375.45703125\n",
      "Epoch: 2, Batch number: 6979, Loss: 13738.5068359375\n",
      "Epoch: 2, Batch number: 7079, Loss: 13458.8359375\n",
      "Epoch: 2, Batch number: 7179, Loss: 13368.2119140625\n",
      "Epoch: 2, Batch number: 7279, Loss: 13299.169921875\n",
      "Epoch: 2, Batch number: 7379, Loss: 13814.0400390625\n",
      "Epoch: 2, Batch number: 7479, Loss: 13666.765625\n",
      "Epoch: 2, Batch number: 7579, Loss: 13557.40625\n",
      "Epoch: 2, Batch number: 7679, Loss: 13354.923828125\n",
      "Epoch: 2, Batch number: 7779, Loss: 13573.1787109375\n",
      "Epoch: 2, Batch number: 7879, Loss: 13102.345703125\n",
      "Epoch: 2, Batch number: 7979, Loss: 13434.9208984375\n",
      "Epoch: 2, Batch number: 8079, Loss: 13548.0185546875\n",
      "Epoch: 2, Batch number: 8179, Loss: 13677.568359375\n",
      "Epoch: 2, Batch number: 8279, Loss: 13612.8603515625\n",
      "Epoch: 2, Batch number: 8379, Loss: 13416.1640625\n",
      "Epoch: 2, Batch number: 8479, Loss: 13467.4716796875\n",
      "Epoch: 2, Batch number: 8579, Loss: 13266.8818359375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 32606.287109375\n",
      "Epoch: 1, Batch number: 100, Loss: 32119.111328125\n",
      "Epoch: 1, Batch number: 200, Loss: 31400.51953125\n",
      "Epoch: 1, Batch number: 300, Loss: 30690.59765625\n",
      "Epoch: 1, Batch number: 400, Loss: 29954.412109375\n",
      "Epoch: 1, Batch number: 500, Loss: 28522.580078125\n",
      "Epoch: 1, Batch number: 600, Loss: 28565.369140625\n",
      "Epoch: 1, Batch number: 700, Loss: 27872.53515625\n",
      "Epoch: 1, Batch number: 800, Loss: 26764.03515625\n",
      "Epoch: 1, Batch number: 900, Loss: 26735.80078125\n",
      "Epoch: 1, Batch number: 1000, Loss: 26257.087890625\n",
      "Epoch: 1, Batch number: 1100, Loss: 26198.91015625\n",
      "Epoch: 1, Batch number: 1200, Loss: 25813.607421875\n",
      "Epoch: 1, Batch number: 1300, Loss: 25540.07421875\n",
      "Epoch: 1, Batch number: 1400, Loss: 25276.45703125\n",
      "Epoch: 1, Batch number: 1500, Loss: 25559.6875\n",
      "Epoch: 1, Batch number: 1600, Loss: 25108.826171875\n",
      "Epoch: 1, Batch number: 1700, Loss: 24568.892578125\n",
      "Epoch: 1, Batch number: 1800, Loss: 24737.453125\n",
      "Epoch: 1, Batch number: 1900, Loss: 24704.146484375\n",
      "Epoch: 1, Batch number: 2000, Loss: 24146.876953125\n",
      "Epoch: 1, Batch number: 2100, Loss: 24268.048828125\n",
      "Epoch: 1, Batch number: 2200, Loss: 23593.31640625\n",
      "Epoch: 1, Batch number: 2300, Loss: 23765.6015625\n",
      "Epoch: 1, Batch number: 2400, Loss: 23615.3125\n",
      "Epoch: 1, Batch number: 2500, Loss: 23951.89453125\n",
      "Epoch: 1, Batch number: 2600, Loss: 23399.955078125\n",
      "Epoch: 1, Batch number: 2700, Loss: 23895.900390625\n",
      "Epoch: 1, Batch number: 2800, Loss: 23631.830078125\n",
      "Epoch: 1, Batch number: 2900, Loss: 23243.46875\n",
      "Epoch: 1, Batch number: 3000, Loss: 23511.94921875\n",
      "Epoch: 1, Batch number: 3100, Loss: 23536.09375\n",
      "Epoch: 1, Batch number: 3200, Loss: 23349.2109375\n",
      "Epoch: 1, Batch number: 3300, Loss: 22885.626953125\n",
      "Epoch: 1, Batch number: 3400, Loss: 22595.35546875\n",
      "Epoch: 1, Batch number: 3500, Loss: 23011.994140625\n",
      "Epoch: 1, Batch number: 3600, Loss: 22846.576171875\n",
      "Epoch: 1, Batch number: 3700, Loss: 23239.841796875\n",
      "Epoch: 1, Batch number: 3800, Loss: 22979.2734375\n",
      "Epoch: 1, Batch number: 3900, Loss: 23090.09375\n",
      "Epoch: 1, Batch number: 4000, Loss: 22762.751953125\n",
      "Epoch: 1, Batch number: 4100, Loss: 22690.458984375\n",
      "Epoch: 1, Batch number: 4200, Loss: 22390.86328125\n",
      "Epoch: 1, Batch number: 4300, Loss: 22780.005859375\n",
      "Epoch: 1, Batch number: 4400, Loss: 22723.166015625\n",
      "Epoch: 1, Batch number: 4500, Loss: 22445.046875\n",
      "Epoch: 1, Batch number: 4600, Loss: 22731.373046875\n",
      "Epoch: 1, Batch number: 4700, Loss: 22442.2578125\n",
      "Epoch: 1, Batch number: 4800, Loss: 22513.345703125\n",
      "Epoch: 1, Batch number: 4900, Loss: 22508.05859375\n",
      "Epoch: 1, Batch number: 5000, Loss: 22444.37890625\n",
      "Epoch: 1, Batch number: 5100, Loss: 22385.03515625\n",
      "Epoch: 1, Batch number: 5200, Loss: 22620.060546875\n",
      "Epoch: 1, Batch number: 5300, Loss: 22585.2265625\n",
      "Epoch: 1, Batch number: 5400, Loss: 22863.677734375\n",
      "Epoch: 1, Batch number: 5500, Loss: 22217.83984375\n",
      "Epoch: 1, Batch number: 5600, Loss: 22518.658203125\n",
      "Epoch: 1, Batch number: 5700, Loss: 22348.5\n",
      "Epoch: 1, Batch number: 5800, Loss: 22212.595703125\n",
      "Epoch: 1, Batch number: 5900, Loss: 22032.263671875\n",
      "Epoch: 1, Batch number: 6000, Loss: 22148.6171875\n",
      "Epoch: 1, Batch number: 6100, Loss: 22197.345703125\n",
      "Epoch: 1, Batch number: 6200, Loss: 22161.029296875\n",
      "Epoch: 1, Batch number: 6300, Loss: 22234.259765625\n",
      "Epoch: 1, Batch number: 6400, Loss: 22444.375\n",
      "Epoch: 1, Batch number: 6500, Loss: 22474.43359375\n",
      "Epoch: 1, Batch number: 6600, Loss: 22058.80859375\n",
      "Epoch: 1, Batch number: 6700, Loss: 22312.359375\n",
      "Epoch: 1, Batch number: 6800, Loss: 21784.2421875\n",
      "Epoch: 1, Batch number: 6900, Loss: 22079.60546875\n",
      "Epoch: 1, Batch number: 7000, Loss: 22212.625\n",
      "Epoch: 1, Batch number: 7100, Loss: 22143.591796875\n",
      "Epoch: 1, Batch number: 7200, Loss: 21905.458984375\n",
      "Epoch: 1, Batch number: 7300, Loss: 22162.427734375\n",
      "Epoch: 1, Batch number: 7400, Loss: 21584.248046875\n",
      "Epoch: 1, Batch number: 7500, Loss: 21912.73828125\n",
      "Epoch: 1, Batch number: 7600, Loss: 21748.40234375\n",
      "Epoch: 1, Batch number: 7700, Loss: 21668.275390625\n",
      "Epoch: 1, Batch number: 7800, Loss: 21998.80859375\n",
      "Epoch: 1, Batch number: 7900, Loss: 21941.310546875\n",
      "Epoch: 1, Batch number: 8000, Loss: 22466.681640625\n",
      "Epoch: 1, Batch number: 8100, Loss: 21916.119140625\n",
      "Epoch: 1, Batch number: 8200, Loss: 21616.43359375\n",
      "Epoch: 1, Batch number: 8300, Loss: 22013.5546875\n",
      "Epoch: 1, Batch number: 8400, Loss: 21785.8984375\n",
      "Epoch: 1, Batch number: 8500, Loss: 22088.390625\n",
      "Epoch: 1, Batch number: 8600, Loss: 21821.326171875\n",
      "Epoch: 2, Batch number: 78, Loss: 21491.232421875\n",
      "Epoch: 2, Batch number: 178, Loss: 21658.552734375\n",
      "Epoch: 2, Batch number: 278, Loss: 21262.587890625\n",
      "Epoch: 2, Batch number: 378, Loss: 21761.712890625\n",
      "Epoch: 2, Batch number: 478, Loss: 21829.05078125\n",
      "Epoch: 2, Batch number: 578, Loss: 22105.916015625\n",
      "Epoch: 2, Batch number: 678, Loss: 21376.80859375\n",
      "Epoch: 2, Batch number: 778, Loss: 21403.599609375\n",
      "Epoch: 2, Batch number: 878, Loss: 21918.296875\n",
      "Epoch: 2, Batch number: 978, Loss: 21866.228515625\n",
      "Epoch: 2, Batch number: 1078, Loss: 21537.146484375\n",
      "Epoch: 2, Batch number: 1178, Loss: 21709.361328125\n",
      "Epoch: 2, Batch number: 1278, Loss: 21580.326171875\n",
      "Epoch: 2, Batch number: 1378, Loss: 22210.830078125\n",
      "Epoch: 2, Batch number: 1478, Loss: 21840.064453125\n",
      "Epoch: 2, Batch number: 1578, Loss: 21584.892578125\n",
      "Epoch: 2, Batch number: 1678, Loss: 21791.404296875\n",
      "Epoch: 2, Batch number: 1778, Loss: 21852.625\n",
      "Epoch: 2, Batch number: 1878, Loss: 21549.939453125\n",
      "Epoch: 2, Batch number: 1978, Loss: 21554.177734375\n",
      "Epoch: 2, Batch number: 2078, Loss: 21903.1484375\n",
      "Epoch: 2, Batch number: 2178, Loss: 21856.529296875\n",
      "Epoch: 2, Batch number: 2278, Loss: 21931.12890625\n",
      "Epoch: 2, Batch number: 2378, Loss: 21675.98046875\n",
      "Epoch: 2, Batch number: 2478, Loss: 21480.001953125\n",
      "Epoch: 2, Batch number: 2578, Loss: 21226.873046875\n",
      "Epoch: 2, Batch number: 2678, Loss: 21537.494140625\n",
      "Epoch: 2, Batch number: 2778, Loss: 21778.685546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 2878, Loss: 21569.109375\n",
      "Epoch: 2, Batch number: 2978, Loss: 21625.646484375\n",
      "Epoch: 2, Batch number: 3078, Loss: 21612.8203125\n",
      "Epoch: 2, Batch number: 3178, Loss: 21467.828125\n",
      "Epoch: 2, Batch number: 3278, Loss: 21458.10546875\n",
      "Epoch: 2, Batch number: 3378, Loss: 21503.267578125\n",
      "Epoch: 2, Batch number: 3478, Loss: 21632.060546875\n",
      "Epoch: 2, Batch number: 3578, Loss: 21585.666015625\n",
      "Epoch: 2, Batch number: 3678, Loss: 21123.283203125\n",
      "Epoch: 2, Batch number: 3778, Loss: 21644.021484375\n",
      "Epoch: 2, Batch number: 3878, Loss: 21600.041015625\n",
      "Epoch: 2, Batch number: 3978, Loss: 21541.53515625\n",
      "Epoch: 2, Batch number: 4078, Loss: 21521.3125\n",
      "Epoch: 2, Batch number: 4178, Loss: 21381.19140625\n",
      "Epoch: 2, Batch number: 4278, Loss: 21415.875\n",
      "Epoch: 2, Batch number: 4378, Loss: 21548.548828125\n",
      "Epoch: 2, Batch number: 4478, Loss: 21733.26171875\n",
      "Epoch: 2, Batch number: 4578, Loss: 21260.251953125\n",
      "Epoch: 2, Batch number: 4678, Loss: 21232.55078125\n",
      "Epoch: 2, Batch number: 4778, Loss: 21206.431640625\n",
      "Epoch: 2, Batch number: 4878, Loss: 21305.931640625\n",
      "Epoch: 2, Batch number: 4978, Loss: 21438.6171875\n",
      "Epoch: 2, Batch number: 5078, Loss: 21659.466796875\n",
      "Epoch: 2, Batch number: 5178, Loss: 21652.130859375\n",
      "Epoch: 2, Batch number: 5278, Loss: 21728.19140625\n",
      "Epoch: 2, Batch number: 5378, Loss: 21546.3984375\n",
      "Epoch: 2, Batch number: 5478, Loss: 21269.375\n",
      "Epoch: 2, Batch number: 5578, Loss: 21510.337890625\n",
      "Epoch: 2, Batch number: 5678, Loss: 21249.017578125\n",
      "Epoch: 2, Batch number: 5778, Loss: 21623.205078125\n",
      "Epoch: 2, Batch number: 5878, Loss: 21210.23046875\n",
      "Epoch: 2, Batch number: 5978, Loss: 21389.185546875\n",
      "Epoch: 2, Batch number: 6078, Loss: 21225.84375\n",
      "Epoch: 2, Batch number: 6178, Loss: 21383.5625\n",
      "Epoch: 2, Batch number: 6278, Loss: 21358.7890625\n",
      "Epoch: 2, Batch number: 6378, Loss: 21418.328125\n",
      "Epoch: 2, Batch number: 6478, Loss: 21201.83203125\n",
      "Epoch: 2, Batch number: 6578, Loss: 21104.333984375\n",
      "Epoch: 2, Batch number: 6678, Loss: 21454.26171875\n",
      "Epoch: 2, Batch number: 6778, Loss: 21285.671875\n",
      "Epoch: 2, Batch number: 6878, Loss: 21472.03515625\n",
      "Epoch: 2, Batch number: 6978, Loss: 21660.505859375\n",
      "Epoch: 2, Batch number: 7078, Loss: 21089.69921875\n",
      "Epoch: 2, Batch number: 7178, Loss: 21422.1328125\n",
      "Epoch: 2, Batch number: 7278, Loss: 20958.138671875\n",
      "Epoch: 2, Batch number: 7378, Loss: 21447.263671875\n",
      "Epoch: 2, Batch number: 7478, Loss: 21058.728515625\n",
      "Epoch: 2, Batch number: 7578, Loss: 21473.09765625\n",
      "Epoch: 2, Batch number: 7678, Loss: 21159.30859375\n",
      "Epoch: 2, Batch number: 7778, Loss: 21631.345703125\n",
      "Epoch: 2, Batch number: 7878, Loss: 21008.73046875\n",
      "Epoch: 2, Batch number: 7978, Loss: 21506.783203125\n",
      "Epoch: 2, Batch number: 8078, Loss: 21474.294921875\n",
      "Epoch: 2, Batch number: 8178, Loss: 21342.505859375\n",
      "Epoch: 2, Batch number: 8278, Loss: 21098.0625\n",
      "Epoch: 2, Batch number: 8378, Loss: 21304.984375\n",
      "Epoch: 2, Batch number: 8478, Loss: 21241.302734375\n",
      "Epoch: 2, Batch number: 8578, Loss: 21264.189453125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 32500.826171875\n",
      "Epoch: 1, Batch number: 100, Loss: 31483.34765625\n",
      "Epoch: 1, Batch number: 200, Loss: 30270.330078125\n",
      "Epoch: 1, Batch number: 300, Loss: 29204.705078125\n",
      "Epoch: 1, Batch number: 400, Loss: 28062.845703125\n",
      "Epoch: 1, Batch number: 500, Loss: 27190.4765625\n",
      "Epoch: 1, Batch number: 600, Loss: 27057.22265625\n",
      "Epoch: 1, Batch number: 700, Loss: 26725.1484375\n",
      "Epoch: 1, Batch number: 800, Loss: 26669.525390625\n",
      "Epoch: 1, Batch number: 900, Loss: 25938.673828125\n",
      "Epoch: 1, Batch number: 1000, Loss: 25486.123046875\n",
      "Epoch: 1, Batch number: 1100, Loss: 25310.54296875\n",
      "Epoch: 1, Batch number: 1200, Loss: 25081.8515625\n",
      "Epoch: 1, Batch number: 1300, Loss: 24906.01953125\n",
      "Epoch: 1, Batch number: 1400, Loss: 24610.345703125\n",
      "Epoch: 1, Batch number: 1500, Loss: 24616.486328125\n",
      "Epoch: 1, Batch number: 1600, Loss: 23475.5703125\n",
      "Epoch: 1, Batch number: 1700, Loss: 23913.94140625\n",
      "Epoch: 1, Batch number: 1800, Loss: 23539.677734375\n",
      "Epoch: 1, Batch number: 1900, Loss: 24155.3125\n",
      "Epoch: 1, Batch number: 2000, Loss: 23954.888671875\n",
      "Epoch: 1, Batch number: 2100, Loss: 23439.798828125\n",
      "Epoch: 1, Batch number: 2200, Loss: 23321.802734375\n",
      "Epoch: 1, Batch number: 2300, Loss: 23902.2890625\n",
      "Epoch: 1, Batch number: 2400, Loss: 23348.029296875\n",
      "Epoch: 1, Batch number: 2500, Loss: 23113.375\n",
      "Epoch: 1, Batch number: 2600, Loss: 22935.28515625\n",
      "Epoch: 1, Batch number: 2700, Loss: 23313.537109375\n",
      "Epoch: 1, Batch number: 2800, Loss: 22614.119140625\n",
      "Epoch: 1, Batch number: 2900, Loss: 23036.748046875\n",
      "Epoch: 1, Batch number: 3000, Loss: 22952.794921875\n",
      "Epoch: 1, Batch number: 3100, Loss: 23002.61328125\n",
      "Epoch: 1, Batch number: 3200, Loss: 22565.962890625\n",
      "Epoch: 1, Batch number: 3300, Loss: 22697.814453125\n",
      "Epoch: 1, Batch number: 3400, Loss: 22860.068359375\n",
      "Epoch: 1, Batch number: 3500, Loss: 22207.06640625\n",
      "Epoch: 1, Batch number: 3600, Loss: 22662.45703125\n",
      "Epoch: 1, Batch number: 3700, Loss: 22704.884765625\n",
      "Epoch: 1, Batch number: 3800, Loss: 22245.384765625\n",
      "Epoch: 1, Batch number: 3900, Loss: 22036.69921875\n",
      "Epoch: 1, Batch number: 4000, Loss: 22456.794921875\n",
      "Epoch: 1, Batch number: 4100, Loss: 22059.4140625\n",
      "Epoch: 1, Batch number: 4200, Loss: 22007.783203125\n",
      "Epoch: 1, Batch number: 4300, Loss: 22321.765625\n",
      "Epoch: 1, Batch number: 4400, Loss: 22081.513671875\n",
      "Epoch: 1, Batch number: 4500, Loss: 22492.931640625\n",
      "Epoch: 1, Batch number: 4600, Loss: 22228.640625\n",
      "Epoch: 1, Batch number: 4700, Loss: 22456.275390625\n",
      "Epoch: 1, Batch number: 4800, Loss: 22024.341796875\n",
      "Epoch: 1, Batch number: 4900, Loss: 22029.380859375\n",
      "Epoch: 1, Batch number: 5000, Loss: 21899.1484375\n",
      "Epoch: 1, Batch number: 5100, Loss: 22203.8828125\n",
      "Epoch: 1, Batch number: 5200, Loss: 22060.291015625\n",
      "Epoch: 1, Batch number: 5300, Loss: 21650.517578125\n",
      "Epoch: 1, Batch number: 5400, Loss: 21954.255859375\n",
      "Epoch: 1, Batch number: 5500, Loss: 22005.798828125\n",
      "Epoch: 1, Batch number: 5600, Loss: 22409.65234375\n",
      "Epoch: 1, Batch number: 5700, Loss: 21947.291015625\n",
      "Epoch: 1, Batch number: 5800, Loss: 22151.3203125\n",
      "Epoch: 1, Batch number: 5900, Loss: 21852.0390625\n",
      "Epoch: 1, Batch number: 6000, Loss: 22008.5703125\n",
      "Epoch: 1, Batch number: 6100, Loss: 21757.341796875\n",
      "Epoch: 1, Batch number: 6200, Loss: 21952.673828125\n",
      "Epoch: 1, Batch number: 6300, Loss: 21894.5546875\n",
      "Epoch: 1, Batch number: 6400, Loss: 21769.8984375\n",
      "Epoch: 1, Batch number: 6500, Loss: 21768.66015625\n",
      "Epoch: 1, Batch number: 6600, Loss: 21649.34375\n",
      "Epoch: 1, Batch number: 6700, Loss: 21908.013671875\n",
      "Epoch: 1, Batch number: 6800, Loss: 21423.7265625\n",
      "Epoch: 1, Batch number: 6900, Loss: 21466.154296875\n",
      "Epoch: 1, Batch number: 7000, Loss: 21568.52734375\n",
      "Epoch: 1, Batch number: 7100, Loss: 21991.96875\n",
      "Epoch: 1, Batch number: 7200, Loss: 21739.17578125\n",
      "Epoch: 1, Batch number: 7300, Loss: 21916.65625\n",
      "Epoch: 1, Batch number: 7400, Loss: 21442.56640625\n",
      "Epoch: 1, Batch number: 7500, Loss: 21585.6171875\n",
      "Epoch: 1, Batch number: 7600, Loss: 21557.189453125\n",
      "Epoch: 1, Batch number: 7700, Loss: 21854.48046875\n",
      "Epoch: 1, Batch number: 7800, Loss: 21564.728515625\n",
      "Epoch: 1, Batch number: 7900, Loss: 21433.1328125\n",
      "Epoch: 1, Batch number: 8000, Loss: 21614.71484375\n",
      "Epoch: 1, Batch number: 8100, Loss: 21502.109375\n",
      "Epoch: 1, Batch number: 8200, Loss: 21543.15625\n",
      "Epoch: 1, Batch number: 8300, Loss: 21645.556640625\n",
      "Epoch: 1, Batch number: 8400, Loss: 21296.4921875\n",
      "Epoch: 1, Batch number: 8500, Loss: 21712.763671875\n",
      "Epoch: 1, Batch number: 8600, Loss: 21726.81640625\n",
      "Epoch: 2, Batch number: 78, Loss: 21338.833984375\n",
      "Epoch: 2, Batch number: 178, Loss: 21667.3828125\n",
      "Epoch: 2, Batch number: 278, Loss: 21279.263671875\n",
      "Epoch: 2, Batch number: 378, Loss: 21120.556640625\n",
      "Epoch: 2, Batch number: 478, Loss: 21194.71875\n",
      "Epoch: 2, Batch number: 578, Loss: 21475.419921875\n",
      "Epoch: 2, Batch number: 678, Loss: 21413.443359375\n",
      "Epoch: 2, Batch number: 778, Loss: 21325.509765625\n",
      "Epoch: 2, Batch number: 878, Loss: 21436.529296875\n",
      "Epoch: 2, Batch number: 978, Loss: 21167.103515625\n",
      "Epoch: 2, Batch number: 1078, Loss: 21342.912109375\n",
      "Epoch: 2, Batch number: 1178, Loss: 21168.876953125\n",
      "Epoch: 2, Batch number: 1278, Loss: 21229.734375\n",
      "Epoch: 2, Batch number: 1378, Loss: 21222.076171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 1478, Loss: 21185.140625\n",
      "Epoch: 2, Batch number: 1578, Loss: 21142.23828125\n",
      "Epoch: 2, Batch number: 1678, Loss: 21290.791015625\n",
      "Epoch: 2, Batch number: 1778, Loss: 21250.87109375\n",
      "Epoch: 2, Batch number: 1878, Loss: 21204.27734375\n",
      "Epoch: 2, Batch number: 1978, Loss: 21610.859375\n",
      "Epoch: 2, Batch number: 2078, Loss: 21449.7421875\n",
      "Epoch: 2, Batch number: 2178, Loss: 21383.201171875\n",
      "Epoch: 2, Batch number: 2278, Loss: 21188.53515625\n",
      "Epoch: 2, Batch number: 2378, Loss: 21224.708984375\n",
      "Epoch: 2, Batch number: 2478, Loss: 20999.318359375\n",
      "Epoch: 2, Batch number: 2578, Loss: 21349.3984375\n",
      "Epoch: 2, Batch number: 2678, Loss: 21398.009765625\n",
      "Epoch: 2, Batch number: 2778, Loss: 21291.71484375\n",
      "Epoch: 2, Batch number: 2878, Loss: 21132.634765625\n",
      "Epoch: 2, Batch number: 2978, Loss: 21231.83203125\n",
      "Epoch: 2, Batch number: 3078, Loss: 21261.564453125\n",
      "Epoch: 2, Batch number: 3178, Loss: 21193.24609375\n",
      "Epoch: 2, Batch number: 3278, Loss: 21723.69140625\n",
      "Epoch: 2, Batch number: 3378, Loss: 21454.685546875\n",
      "Epoch: 2, Batch number: 3478, Loss: 20969.015625\n",
      "Epoch: 2, Batch number: 3578, Loss: 21168.06640625\n",
      "Epoch: 2, Batch number: 3678, Loss: 21079.27734375\n",
      "Epoch: 2, Batch number: 3778, Loss: 21153.90625\n",
      "Epoch: 2, Batch number: 3878, Loss: 21121.455078125\n",
      "Epoch: 2, Batch number: 3978, Loss: 21536.548828125\n",
      "Epoch: 2, Batch number: 4078, Loss: 21343.5\n",
      "Epoch: 2, Batch number: 4178, Loss: 21190.005859375\n",
      "Epoch: 2, Batch number: 4278, Loss: 21328.25\n",
      "Epoch: 2, Batch number: 4378, Loss: 21310.8125\n",
      "Epoch: 2, Batch number: 4478, Loss: 21228.67578125\n",
      "Epoch: 2, Batch number: 4578, Loss: 21230.58203125\n",
      "Epoch: 2, Batch number: 4678, Loss: 21339.486328125\n",
      "Epoch: 2, Batch number: 4778, Loss: 21473.416015625\n",
      "Epoch: 2, Batch number: 4878, Loss: 21102.134765625\n",
      "Epoch: 2, Batch number: 4978, Loss: 21108.390625\n",
      "Epoch: 2, Batch number: 5078, Loss: 21134.11328125\n",
      "Epoch: 2, Batch number: 5178, Loss: 21090.017578125\n",
      "Epoch: 2, Batch number: 5278, Loss: 21529.66796875\n",
      "Epoch: 2, Batch number: 5378, Loss: 20877.6015625\n",
      "Epoch: 2, Batch number: 5478, Loss: 20930.583984375\n",
      "Epoch: 2, Batch number: 5578, Loss: 21093.544921875\n",
      "Epoch: 2, Batch number: 5678, Loss: 21326.12109375\n",
      "Epoch: 2, Batch number: 5778, Loss: 21424.037109375\n",
      "Epoch: 2, Batch number: 5878, Loss: 20976.19921875\n",
      "Epoch: 2, Batch number: 5978, Loss: 21263.14453125\n",
      "Epoch: 2, Batch number: 6078, Loss: 21038.142578125\n",
      "Epoch: 2, Batch number: 6178, Loss: 21065.509765625\n",
      "Epoch: 2, Batch number: 6278, Loss: 21109.1953125\n",
      "Epoch: 2, Batch number: 6378, Loss: 21381.498046875\n",
      "Epoch: 2, Batch number: 6478, Loss: 20987.767578125\n",
      "Epoch: 2, Batch number: 6578, Loss: 21211.650390625\n",
      "Epoch: 2, Batch number: 6678, Loss: 21277.259765625\n",
      "Epoch: 2, Batch number: 6778, Loss: 21312.4765625\n",
      "Epoch: 2, Batch number: 6878, Loss: 21082.3515625\n",
      "Epoch: 2, Batch number: 6978, Loss: 21456.48046875\n",
      "Epoch: 2, Batch number: 7078, Loss: 20873.6015625\n",
      "Epoch: 2, Batch number: 7178, Loss: 21109.9921875\n",
      "Epoch: 2, Batch number: 7278, Loss: 20700.6953125\n",
      "Epoch: 2, Batch number: 7378, Loss: 21114.73046875\n",
      "Epoch: 2, Batch number: 7478, Loss: 21297.37890625\n",
      "Epoch: 2, Batch number: 7578, Loss: 21009.4453125\n",
      "Epoch: 2, Batch number: 7678, Loss: 21065.576171875\n",
      "Epoch: 2, Batch number: 7778, Loss: 21366.0\n",
      "Epoch: 2, Batch number: 7878, Loss: 21167.17578125\n",
      "Epoch: 2, Batch number: 7978, Loss: 20873.220703125\n",
      "Epoch: 2, Batch number: 8078, Loss: 20976.46484375\n",
      "Epoch: 2, Batch number: 8178, Loss: 21052.552734375\n",
      "Epoch: 2, Batch number: 8278, Loss: 20802.716796875\n",
      "Epoch: 2, Batch number: 8378, Loss: 20851.37109375\n",
      "Epoch: 2, Batch number: 8478, Loss: 20663.58984375\n",
      "Epoch: 2, Batch number: 8578, Loss: 21034.765625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 32602.298828125\n",
      "Epoch: 1, Batch number: 100, Loss: 30584.27734375\n",
      "Epoch: 1, Batch number: 200, Loss: 29177.703125\n",
      "Epoch: 1, Batch number: 300, Loss: 28217.66796875\n",
      "Epoch: 1, Batch number: 400, Loss: 27462.513671875\n",
      "Epoch: 1, Batch number: 500, Loss: 26526.3203125\n",
      "Epoch: 1, Batch number: 600, Loss: 26586.482421875\n",
      "Epoch: 1, Batch number: 700, Loss: 25607.94921875\n",
      "Epoch: 1, Batch number: 800, Loss: 25102.65234375\n",
      "Epoch: 1, Batch number: 900, Loss: 24828.14453125\n",
      "Epoch: 1, Batch number: 1000, Loss: 24475.453125\n",
      "Epoch: 1, Batch number: 1100, Loss: 24522.609375\n",
      "Epoch: 1, Batch number: 1200, Loss: 24330.701171875\n",
      "Epoch: 1, Batch number: 1300, Loss: 23780.560546875\n",
      "Epoch: 1, Batch number: 1400, Loss: 23726.8515625\n",
      "Epoch: 1, Batch number: 1500, Loss: 23743.49609375\n",
      "Epoch: 1, Batch number: 1600, Loss: 23629.328125\n",
      "Epoch: 1, Batch number: 1700, Loss: 23541.2421875\n",
      "Epoch: 1, Batch number: 1800, Loss: 23468.5546875\n",
      "Epoch: 1, Batch number: 1900, Loss: 23260.861328125\n",
      "Epoch: 1, Batch number: 2000, Loss: 23177.126953125\n",
      "Epoch: 1, Batch number: 2100, Loss: 22557.82421875\n",
      "Epoch: 1, Batch number: 2200, Loss: 22943.41796875\n",
      "Epoch: 1, Batch number: 2300, Loss: 22498.37109375\n",
      "Epoch: 1, Batch number: 2400, Loss: 22476.46875\n",
      "Epoch: 1, Batch number: 2500, Loss: 22527.056640625\n",
      "Epoch: 1, Batch number: 2600, Loss: 22466.154296875\n",
      "Epoch: 1, Batch number: 2700, Loss: 22412.3515625\n",
      "Epoch: 1, Batch number: 2800, Loss: 22436.65234375\n",
      "Epoch: 1, Batch number: 2900, Loss: 22198.419921875\n",
      "Epoch: 1, Batch number: 3000, Loss: 22237.07421875\n",
      "Epoch: 1, Batch number: 3100, Loss: 22257.85546875\n",
      "Epoch: 1, Batch number: 3200, Loss: 22322.259765625\n",
      "Epoch: 1, Batch number: 3300, Loss: 22371.798828125\n",
      "Epoch: 1, Batch number: 3400, Loss: 22164.318359375\n",
      "Epoch: 1, Batch number: 3500, Loss: 22164.22265625\n",
      "Epoch: 1, Batch number: 3600, Loss: 22146.1171875\n",
      "Epoch: 1, Batch number: 3700, Loss: 22071.32421875\n",
      "Epoch: 1, Batch number: 3800, Loss: 22248.431640625\n",
      "Epoch: 1, Batch number: 3900, Loss: 21789.185546875\n",
      "Epoch: 1, Batch number: 4000, Loss: 22223.091796875\n",
      "Epoch: 1, Batch number: 4100, Loss: 21483.982421875\n",
      "Epoch: 1, Batch number: 4200, Loss: 21935.228515625\n",
      "Epoch: 1, Batch number: 4300, Loss: 21791.6328125\n",
      "Epoch: 1, Batch number: 4400, Loss: 22260.21484375\n",
      "Epoch: 1, Batch number: 4500, Loss: 21724.484375\n",
      "Epoch: 1, Batch number: 4600, Loss: 21756.1328125\n",
      "Epoch: 1, Batch number: 4700, Loss: 21907.32421875\n",
      "Epoch: 1, Batch number: 4800, Loss: 21598.689453125\n",
      "Epoch: 1, Batch number: 4900, Loss: 21793.544921875\n",
      "Epoch: 1, Batch number: 5000, Loss: 22043.40234375\n",
      "Epoch: 1, Batch number: 5100, Loss: 21912.126953125\n",
      "Epoch: 1, Batch number: 5200, Loss: 21553.548828125\n",
      "Epoch: 1, Batch number: 5300, Loss: 21570.859375\n",
      "Epoch: 1, Batch number: 5400, Loss: 21574.431640625\n",
      "Epoch: 1, Batch number: 5500, Loss: 21854.470703125\n",
      "Epoch: 1, Batch number: 5600, Loss: 21719.60546875\n",
      "Epoch: 1, Batch number: 5700, Loss: 21446.884765625\n",
      "Epoch: 1, Batch number: 5800, Loss: 21939.240234375\n",
      "Epoch: 1, Batch number: 5900, Loss: 21768.330078125\n",
      "Epoch: 1, Batch number: 6000, Loss: 21168.658203125\n",
      "Epoch: 1, Batch number: 6100, Loss: 21629.236328125\n",
      "Epoch: 1, Batch number: 6200, Loss: 21639.248046875\n",
      "Epoch: 1, Batch number: 6300, Loss: 21487.16796875\n",
      "Epoch: 1, Batch number: 6400, Loss: 21387.064453125\n",
      "Epoch: 1, Batch number: 6500, Loss: 21420.1171875\n",
      "Epoch: 1, Batch number: 6600, Loss: 21735.541015625\n",
      "Epoch: 1, Batch number: 6700, Loss: 21317.41015625\n",
      "Epoch: 1, Batch number: 6800, Loss: 21778.001953125\n",
      "Epoch: 1, Batch number: 6900, Loss: 21268.58203125\n",
      "Epoch: 1, Batch number: 7000, Loss: 21370.04296875\n",
      "Epoch: 1, Batch number: 7100, Loss: 21091.015625\n",
      "Epoch: 1, Batch number: 7200, Loss: 21000.724609375\n",
      "Epoch: 1, Batch number: 7300, Loss: 21432.162109375\n",
      "Epoch: 1, Batch number: 7400, Loss: 21670.69140625\n",
      "Epoch: 1, Batch number: 7500, Loss: 21234.900390625\n",
      "Epoch: 1, Batch number: 7600, Loss: 21430.671875\n",
      "Epoch: 1, Batch number: 7700, Loss: 21553.736328125\n",
      "Epoch: 1, Batch number: 7800, Loss: 21532.0\n",
      "Epoch: 1, Batch number: 7900, Loss: 21081.181640625\n",
      "Epoch: 1, Batch number: 8000, Loss: 21291.216796875\n",
      "Epoch: 1, Batch number: 8100, Loss: 21576.421875\n",
      "Epoch: 1, Batch number: 8200, Loss: 21283.951171875\n",
      "Epoch: 1, Batch number: 8300, Loss: 21434.640625\n",
      "Epoch: 1, Batch number: 8400, Loss: 21071.0546875\n",
      "Epoch: 1, Batch number: 8500, Loss: 21232.154296875\n",
      "Epoch: 1, Batch number: 8600, Loss: 21328.515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 78, Loss: 21042.44921875\n",
      "Epoch: 2, Batch number: 178, Loss: 20706.947265625\n",
      "Epoch: 2, Batch number: 278, Loss: 20953.802734375\n",
      "Epoch: 2, Batch number: 378, Loss: 21048.880859375\n",
      "Epoch: 2, Batch number: 478, Loss: 21119.17578125\n",
      "Epoch: 2, Batch number: 578, Loss: 20886.734375\n",
      "Epoch: 2, Batch number: 678, Loss: 20651.2734375\n",
      "Epoch: 2, Batch number: 778, Loss: 20850.041015625\n",
      "Epoch: 2, Batch number: 878, Loss: 20714.3359375\n",
      "Epoch: 2, Batch number: 978, Loss: 20865.447265625\n",
      "Epoch: 2, Batch number: 1078, Loss: 21307.669921875\n",
      "Epoch: 2, Batch number: 1178, Loss: 20965.68359375\n",
      "Epoch: 2, Batch number: 1278, Loss: 21117.416015625\n",
      "Epoch: 2, Batch number: 1378, Loss: 20978.59765625\n",
      "Epoch: 2, Batch number: 1478, Loss: 20808.015625\n",
      "Epoch: 2, Batch number: 1578, Loss: 20856.197265625\n",
      "Epoch: 2, Batch number: 1678, Loss: 20996.849609375\n",
      "Epoch: 2, Batch number: 1778, Loss: 20976.423828125\n",
      "Epoch: 2, Batch number: 1878, Loss: 21076.734375\n",
      "Epoch: 2, Batch number: 1978, Loss: 20617.72265625\n",
      "Epoch: 2, Batch number: 2078, Loss: 20678.98046875\n",
      "Epoch: 2, Batch number: 2178, Loss: 20891.708984375\n",
      "Epoch: 2, Batch number: 2278, Loss: 21011.2265625\n",
      "Epoch: 2, Batch number: 2378, Loss: 20889.236328125\n",
      "Epoch: 2, Batch number: 2478, Loss: 20783.51953125\n",
      "Epoch: 2, Batch number: 2578, Loss: 20743.5859375\n",
      "Epoch: 2, Batch number: 2678, Loss: 21236.505859375\n",
      "Epoch: 2, Batch number: 2778, Loss: 20835.58203125\n",
      "Epoch: 2, Batch number: 2878, Loss: 20855.580078125\n",
      "Epoch: 2, Batch number: 2978, Loss: 21071.994140625\n",
      "Epoch: 2, Batch number: 3078, Loss: 21246.3671875\n",
      "Epoch: 2, Batch number: 3178, Loss: 20714.583984375\n",
      "Epoch: 2, Batch number: 3278, Loss: 20676.990234375\n",
      "Epoch: 2, Batch number: 3378, Loss: 20583.84765625\n",
      "Epoch: 2, Batch number: 3478, Loss: 20880.435546875\n",
      "Epoch: 2, Batch number: 3578, Loss: 20964.455078125\n",
      "Epoch: 2, Batch number: 3678, Loss: 20851.984375\n",
      "Epoch: 2, Batch number: 3778, Loss: 20935.55859375\n",
      "Epoch: 2, Batch number: 3878, Loss: 21042.18359375\n",
      "Epoch: 2, Batch number: 3978, Loss: 21332.37109375\n",
      "Epoch: 2, Batch number: 4078, Loss: 20787.078125\n",
      "Epoch: 2, Batch number: 4178, Loss: 20610.341796875\n",
      "Epoch: 2, Batch number: 4278, Loss: 20726.173828125\n",
      "Epoch: 2, Batch number: 4378, Loss: 20946.6875\n",
      "Epoch: 2, Batch number: 4478, Loss: 21114.91015625\n",
      "Epoch: 2, Batch number: 4578, Loss: 20806.5078125\n",
      "Epoch: 2, Batch number: 4678, Loss: 20756.91796875\n",
      "Epoch: 2, Batch number: 4778, Loss: 20726.109375\n",
      "Epoch: 2, Batch number: 4878, Loss: 21061.5859375\n",
      "Epoch: 2, Batch number: 4978, Loss: 20408.81640625\n",
      "Epoch: 2, Batch number: 5078, Loss: 20771.6484375\n",
      "Epoch: 2, Batch number: 5178, Loss: 20617.732421875\n",
      "Epoch: 2, Batch number: 5278, Loss: 20709.05859375\n",
      "Epoch: 2, Batch number: 5378, Loss: 20854.802734375\n",
      "Epoch: 2, Batch number: 5478, Loss: 20811.5078125\n",
      "Epoch: 2, Batch number: 5578, Loss: 20664.763671875\n",
      "Epoch: 2, Batch number: 5678, Loss: 20869.240234375\n",
      "Epoch: 2, Batch number: 5778, Loss: 20505.724609375\n",
      "Epoch: 2, Batch number: 5878, Loss: 20694.427734375\n",
      "Epoch: 2, Batch number: 5978, Loss: 20925.021484375\n",
      "Epoch: 2, Batch number: 6078, Loss: 20924.13671875\n",
      "Epoch: 2, Batch number: 6178, Loss: 20774.9609375\n",
      "Epoch: 2, Batch number: 6278, Loss: 21029.169921875\n",
      "Epoch: 2, Batch number: 6378, Loss: 20913.421875\n",
      "Epoch: 2, Batch number: 6478, Loss: 20583.93359375\n",
      "Epoch: 2, Batch number: 6578, Loss: 21071.52734375\n",
      "Epoch: 2, Batch number: 6678, Loss: 21063.23828125\n",
      "Epoch: 2, Batch number: 6778, Loss: 20962.126953125\n",
      "Epoch: 2, Batch number: 6878, Loss: 21026.841796875\n",
      "Epoch: 2, Batch number: 6978, Loss: 20838.951171875\n",
      "Epoch: 2, Batch number: 7078, Loss: 20884.26953125\n",
      "Epoch: 2, Batch number: 7178, Loss: 20293.78515625\n",
      "Epoch: 2, Batch number: 7278, Loss: 20268.6875\n",
      "Epoch: 2, Batch number: 7378, Loss: 20603.0078125\n",
      "Epoch: 2, Batch number: 7478, Loss: 20845.083984375\n",
      "Epoch: 2, Batch number: 7578, Loss: 20727.125\n",
      "Epoch: 2, Batch number: 7678, Loss: 20918.732421875\n",
      "Epoch: 2, Batch number: 7778, Loss: 20701.1953125\n",
      "Epoch: 2, Batch number: 7878, Loss: 20811.94921875\n",
      "Epoch: 2, Batch number: 7978, Loss: 20513.07421875\n",
      "Epoch: 2, Batch number: 8078, Loss: 20660.697265625\n",
      "Epoch: 2, Batch number: 8178, Loss: 21536.515625\n",
      "Epoch: 2, Batch number: 8278, Loss: 20812.78515625\n",
      "Epoch: 2, Batch number: 8378, Loss: 21088.63671875\n",
      "Epoch: 2, Batch number: 8478, Loss: 20843.078125\n",
      "Epoch: 2, Batch number: 8578, Loss: 20950.234375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 32692.099609375\n",
      "Epoch: 1, Batch number: 100, Loss: 29674.373046875\n",
      "Epoch: 1, Batch number: 200, Loss: 28641.291015625\n",
      "Epoch: 1, Batch number: 300, Loss: 27241.6875\n",
      "Epoch: 1, Batch number: 400, Loss: 26974.505859375\n",
      "Epoch: 1, Batch number: 500, Loss: 26400.533203125\n",
      "Epoch: 1, Batch number: 600, Loss: 25744.216796875\n",
      "Epoch: 1, Batch number: 700, Loss: 25094.37109375\n",
      "Epoch: 1, Batch number: 800, Loss: 25073.203125\n",
      "Epoch: 1, Batch number: 900, Loss: 24190.47265625\n",
      "Epoch: 1, Batch number: 1000, Loss: 24040.69921875\n",
      "Epoch: 1, Batch number: 1100, Loss: 23988.623046875\n",
      "Epoch: 1, Batch number: 1200, Loss: 24177.2890625\n",
      "Epoch: 1, Batch number: 1300, Loss: 23813.6171875\n",
      "Epoch: 1, Batch number: 1400, Loss: 23208.666015625\n",
      "Epoch: 1, Batch number: 1500, Loss: 23141.46875\n",
      "Epoch: 1, Batch number: 1600, Loss: 23271.58984375\n",
      "Epoch: 1, Batch number: 1700, Loss: 22976.26171875\n",
      "Epoch: 1, Batch number: 1800, Loss: 22915.34765625\n",
      "Epoch: 1, Batch number: 1900, Loss: 23467.525390625\n",
      "Epoch: 1, Batch number: 2000, Loss: 22654.25390625\n",
      "Epoch: 1, Batch number: 2100, Loss: 22390.283203125\n",
      "Epoch: 1, Batch number: 2200, Loss: 22948.041015625\n",
      "Epoch: 1, Batch number: 2300, Loss: 22650.904296875\n",
      "Epoch: 1, Batch number: 2400, Loss: 22229.982421875\n",
      "Epoch: 1, Batch number: 2500, Loss: 22496.365234375\n",
      "Epoch: 1, Batch number: 2600, Loss: 22160.888671875\n",
      "Epoch: 1, Batch number: 2700, Loss: 22331.208984375\n",
      "Epoch: 1, Batch number: 2800, Loss: 21991.046875\n",
      "Epoch: 1, Batch number: 2900, Loss: 22096.30859375\n",
      "Epoch: 1, Batch number: 3000, Loss: 21998.287109375\n",
      "Epoch: 1, Batch number: 3100, Loss: 21913.150390625\n",
      "Epoch: 1, Batch number: 3200, Loss: 21755.884765625\n",
      "Epoch: 1, Batch number: 3300, Loss: 22184.76953125\n",
      "Epoch: 1, Batch number: 3400, Loss: 22215.490234375\n",
      "Epoch: 1, Batch number: 3500, Loss: 21845.154296875\n",
      "Epoch: 1, Batch number: 3600, Loss: 21861.466796875\n",
      "Epoch: 1, Batch number: 3700, Loss: 21808.7421875\n",
      "Epoch: 1, Batch number: 3800, Loss: 21879.54296875\n",
      "Epoch: 1, Batch number: 3900, Loss: 21568.94921875\n",
      "Epoch: 1, Batch number: 4000, Loss: 21569.306640625\n",
      "Epoch: 1, Batch number: 4100, Loss: 22250.55859375\n",
      "Epoch: 1, Batch number: 4200, Loss: 21894.216796875\n",
      "Epoch: 1, Batch number: 4300, Loss: 21591.98828125\n",
      "Epoch: 1, Batch number: 4400, Loss: 21832.0859375\n",
      "Epoch: 1, Batch number: 4500, Loss: 21636.10546875\n",
      "Epoch: 1, Batch number: 4600, Loss: 22002.685546875\n",
      "Epoch: 1, Batch number: 4700, Loss: 21757.75390625\n",
      "Epoch: 1, Batch number: 4800, Loss: 22084.45703125\n",
      "Epoch: 1, Batch number: 4900, Loss: 21693.705078125\n",
      "Epoch: 1, Batch number: 5000, Loss: 21483.494140625\n",
      "Epoch: 1, Batch number: 5100, Loss: 21472.140625\n",
      "Epoch: 1, Batch number: 5200, Loss: 21409.1484375\n",
      "Epoch: 1, Batch number: 5300, Loss: 21761.345703125\n",
      "Epoch: 1, Batch number: 5400, Loss: 20951.96875\n",
      "Epoch: 1, Batch number: 5500, Loss: 21261.71875\n",
      "Epoch: 1, Batch number: 5600, Loss: 21169.65234375\n",
      "Epoch: 1, Batch number: 5700, Loss: 21153.763671875\n",
      "Epoch: 1, Batch number: 5800, Loss: 21142.640625\n",
      "Epoch: 1, Batch number: 5900, Loss: 20966.361328125\n",
      "Epoch: 1, Batch number: 6000, Loss: 21239.6484375\n",
      "Epoch: 1, Batch number: 6100, Loss: 21391.517578125\n",
      "Epoch: 1, Batch number: 6200, Loss: 21247.943359375\n",
      "Epoch: 1, Batch number: 6300, Loss: 21266.9375\n",
      "Epoch: 1, Batch number: 6400, Loss: 21329.2578125\n",
      "Epoch: 1, Batch number: 6500, Loss: 21336.81640625\n",
      "Epoch: 1, Batch number: 6600, Loss: 21413.13671875\n",
      "Epoch: 1, Batch number: 6700, Loss: 20996.712890625\n",
      "Epoch: 1, Batch number: 6800, Loss: 21336.2734375\n",
      "Epoch: 1, Batch number: 6900, Loss: 21008.837890625\n",
      "Epoch: 1, Batch number: 7000, Loss: 21491.89453125\n",
      "Epoch: 1, Batch number: 7100, Loss: 21398.892578125\n",
      "Epoch: 1, Batch number: 7200, Loss: 21551.451171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 7300, Loss: 21614.978515625\n",
      "Epoch: 1, Batch number: 7400, Loss: 21097.884765625\n",
      "Epoch: 1, Batch number: 7500, Loss: 20993.4140625\n",
      "Epoch: 1, Batch number: 7600, Loss: 21299.98828125\n",
      "Epoch: 1, Batch number: 7700, Loss: 21000.974609375\n",
      "Epoch: 1, Batch number: 7800, Loss: 21062.2734375\n",
      "Epoch: 1, Batch number: 7900, Loss: 21172.328125\n",
      "Epoch: 1, Batch number: 8000, Loss: 21509.07421875\n",
      "Epoch: 1, Batch number: 8100, Loss: 21085.0234375\n",
      "Epoch: 1, Batch number: 8200, Loss: 21087.724609375\n",
      "Epoch: 1, Batch number: 8300, Loss: 21069.8828125\n",
      "Epoch: 1, Batch number: 8400, Loss: 21180.287109375\n",
      "Epoch: 1, Batch number: 8500, Loss: 21412.724609375\n",
      "Epoch: 1, Batch number: 8600, Loss: 21111.302734375\n",
      "Epoch: 2, Batch number: 78, Loss: 20315.888671875\n",
      "Epoch: 2, Batch number: 178, Loss: 20268.345703125\n",
      "Epoch: 2, Batch number: 278, Loss: 20792.564453125\n",
      "Epoch: 2, Batch number: 378, Loss: 20784.763671875\n",
      "Epoch: 2, Batch number: 478, Loss: 20692.533203125\n",
      "Epoch: 2, Batch number: 578, Loss: 20312.533203125\n",
      "Epoch: 2, Batch number: 678, Loss: 20752.259765625\n",
      "Epoch: 2, Batch number: 778, Loss: 20823.724609375\n",
      "Epoch: 2, Batch number: 878, Loss: 20883.45703125\n",
      "Epoch: 2, Batch number: 978, Loss: 20603.083984375\n",
      "Epoch: 2, Batch number: 1078, Loss: 20998.76171875\n",
      "Epoch: 2, Batch number: 1178, Loss: 20408.345703125\n",
      "Epoch: 2, Batch number: 1278, Loss: 20567.7734375\n",
      "Epoch: 2, Batch number: 1378, Loss: 20663.060546875\n",
      "Epoch: 2, Batch number: 1478, Loss: 20508.392578125\n",
      "Epoch: 2, Batch number: 1578, Loss: 20677.04296875\n",
      "Epoch: 2, Batch number: 1678, Loss: 20666.7421875\n",
      "Epoch: 2, Batch number: 1778, Loss: 20948.00390625\n",
      "Epoch: 2, Batch number: 1878, Loss: 20512.333984375\n",
      "Epoch: 2, Batch number: 1978, Loss: 20573.771484375\n",
      "Epoch: 2, Batch number: 2078, Loss: 20878.744140625\n",
      "Epoch: 2, Batch number: 2178, Loss: 20622.12109375\n",
      "Epoch: 2, Batch number: 2278, Loss: 20855.076171875\n",
      "Epoch: 2, Batch number: 2378, Loss: 20801.640625\n",
      "Epoch: 2, Batch number: 2478, Loss: 20683.376953125\n",
      "Epoch: 2, Batch number: 2578, Loss: 20675.65625\n",
      "Epoch: 2, Batch number: 2678, Loss: 20526.498046875\n",
      "Epoch: 2, Batch number: 2778, Loss: 21076.24609375\n",
      "Epoch: 2, Batch number: 2878, Loss: 20376.37890625\n",
      "Epoch: 2, Batch number: 2978, Loss: 20909.65625\n",
      "Epoch: 2, Batch number: 3078, Loss: 20534.71484375\n",
      "Epoch: 2, Batch number: 3178, Loss: 20398.392578125\n",
      "Epoch: 2, Batch number: 3278, Loss: 20753.576171875\n",
      "Epoch: 2, Batch number: 3378, Loss: 20522.87890625\n",
      "Epoch: 2, Batch number: 3478, Loss: 20764.158203125\n",
      "Epoch: 2, Batch number: 3578, Loss: 20562.87109375\n",
      "Epoch: 2, Batch number: 3678, Loss: 20677.501953125\n",
      "Epoch: 2, Batch number: 3778, Loss: 20682.0\n",
      "Epoch: 2, Batch number: 3878, Loss: 20521.091796875\n",
      "Epoch: 2, Batch number: 3978, Loss: 20866.310546875\n",
      "Epoch: 2, Batch number: 4078, Loss: 20734.3125\n",
      "Epoch: 2, Batch number: 4178, Loss: 20624.966796875\n",
      "Epoch: 2, Batch number: 4278, Loss: 20808.771484375\n",
      "Epoch: 2, Batch number: 4378, Loss: 20698.29296875\n",
      "Epoch: 2, Batch number: 4478, Loss: 20740.23046875\n",
      "Epoch: 2, Batch number: 4578, Loss: 20224.259765625\n",
      "Epoch: 2, Batch number: 4678, Loss: 20809.509765625\n",
      "Epoch: 2, Batch number: 4778, Loss: 20643.208984375\n",
      "Epoch: 2, Batch number: 4878, Loss: 20689.201171875\n",
      "Epoch: 2, Batch number: 4978, Loss: 20908.07421875\n",
      "Epoch: 2, Batch number: 5078, Loss: 20487.15625\n",
      "Epoch: 2, Batch number: 5178, Loss: 21035.9609375\n",
      "Epoch: 2, Batch number: 5278, Loss: 20208.92578125\n",
      "Epoch: 2, Batch number: 5378, Loss: 20535.44140625\n",
      "Epoch: 2, Batch number: 5478, Loss: 20695.587890625\n",
      "Epoch: 2, Batch number: 5578, Loss: 20381.03125\n",
      "Epoch: 2, Batch number: 5678, Loss: 20423.203125\n",
      "Epoch: 2, Batch number: 5778, Loss: 20818.16796875\n",
      "Epoch: 2, Batch number: 5878, Loss: 20838.572265625\n",
      "Epoch: 2, Batch number: 5978, Loss: 20401.533203125\n",
      "Epoch: 2, Batch number: 6078, Loss: 20677.931640625\n",
      "Epoch: 2, Batch number: 6178, Loss: 20738.74609375\n",
      "Epoch: 2, Batch number: 6278, Loss: 20809.001953125\n",
      "Epoch: 2, Batch number: 6378, Loss: 20539.265625\n",
      "Epoch: 2, Batch number: 6478, Loss: 20862.177734375\n",
      "Epoch: 2, Batch number: 6578, Loss: 20491.625\n",
      "Epoch: 2, Batch number: 6678, Loss: 20741.748046875\n",
      "Epoch: 2, Batch number: 6778, Loss: 20290.841796875\n",
      "Epoch: 2, Batch number: 6878, Loss: 20757.77734375\n",
      "Epoch: 2, Batch number: 6978, Loss: 20459.998046875\n",
      "Epoch: 2, Batch number: 7078, Loss: 20574.5\n",
      "Epoch: 2, Batch number: 7178, Loss: 20867.455078125\n",
      "Epoch: 2, Batch number: 7278, Loss: 20673.39453125\n",
      "Epoch: 2, Batch number: 7378, Loss: 20979.978515625\n",
      "Epoch: 2, Batch number: 7478, Loss: 20802.171875\n",
      "Epoch: 2, Batch number: 7578, Loss: 20836.31640625\n",
      "Epoch: 2, Batch number: 7678, Loss: 20429.619140625\n",
      "Epoch: 2, Batch number: 7778, Loss: 20509.974609375\n",
      "Epoch: 2, Batch number: 7878, Loss: 20840.2265625\n",
      "Epoch: 2, Batch number: 7978, Loss: 20818.810546875\n",
      "Epoch: 2, Batch number: 8078, Loss: 20175.224609375\n",
      "Epoch: 2, Batch number: 8178, Loss: 20744.306640625\n",
      "Epoch: 2, Batch number: 8278, Loss: 20793.298828125\n",
      "Epoch: 2, Batch number: 8378, Loss: 20733.96484375\n",
      "Epoch: 2, Batch number: 8478, Loss: 20853.685546875\n",
      "Epoch: 2, Batch number: 8578, Loss: 20271.140625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 43567.32421875\n",
      "Epoch: 1, Batch number: 100, Loss: 42921.00390625\n",
      "Epoch: 1, Batch number: 200, Loss: 42141.13671875\n",
      "Epoch: 1, Batch number: 300, Loss: 40725.82421875\n",
      "Epoch: 1, Batch number: 400, Loss: 39530.43359375\n",
      "Epoch: 1, Batch number: 500, Loss: 38176.5390625\n",
      "Epoch: 1, Batch number: 600, Loss: 37709.04296875\n",
      "Epoch: 1, Batch number: 700, Loss: 36892.609375\n",
      "Epoch: 1, Batch number: 800, Loss: 36393.23828125\n",
      "Epoch: 1, Batch number: 900, Loss: 35378.171875\n",
      "Epoch: 1, Batch number: 1000, Loss: 35061.296875\n",
      "Epoch: 1, Batch number: 1100, Loss: 34824.23828125\n",
      "Epoch: 1, Batch number: 1200, Loss: 34429.8515625\n",
      "Epoch: 1, Batch number: 1300, Loss: 33771.70703125\n",
      "Epoch: 1, Batch number: 1400, Loss: 33928.58203125\n",
      "Epoch: 1, Batch number: 1500, Loss: 33410.3046875\n",
      "Epoch: 1, Batch number: 1600, Loss: 34029.33203125\n",
      "Epoch: 1, Batch number: 1700, Loss: 33057.359375\n",
      "Epoch: 1, Batch number: 1800, Loss: 32947.4453125\n",
      "Epoch: 1, Batch number: 1900, Loss: 32791.9375\n",
      "Epoch: 1, Batch number: 2000, Loss: 32415.951171875\n",
      "Epoch: 1, Batch number: 2100, Loss: 32382.6796875\n",
      "Epoch: 1, Batch number: 2200, Loss: 32202.24609375\n",
      "Epoch: 1, Batch number: 2300, Loss: 32246.337890625\n",
      "Epoch: 1, Batch number: 2400, Loss: 32276.3046875\n",
      "Epoch: 1, Batch number: 2500, Loss: 31273.439453125\n",
      "Epoch: 1, Batch number: 2600, Loss: 31137.32421875\n",
      "Epoch: 1, Batch number: 2700, Loss: 31755.19140625\n",
      "Epoch: 1, Batch number: 2800, Loss: 31421.62109375\n",
      "Epoch: 1, Batch number: 2900, Loss: 31549.73828125\n",
      "Epoch: 1, Batch number: 3000, Loss: 31083.263671875\n",
      "Epoch: 1, Batch number: 3100, Loss: 31198.01953125\n",
      "Epoch: 1, Batch number: 3200, Loss: 31124.01953125\n",
      "Epoch: 1, Batch number: 3300, Loss: 30352.19921875\n",
      "Epoch: 1, Batch number: 3400, Loss: 30635.283203125\n",
      "Epoch: 1, Batch number: 3500, Loss: 30831.98828125\n",
      "Epoch: 1, Batch number: 3600, Loss: 30946.3828125\n",
      "Epoch: 1, Batch number: 3700, Loss: 31105.494140625\n",
      "Epoch: 1, Batch number: 3800, Loss: 30534.93359375\n",
      "Epoch: 1, Batch number: 3900, Loss: 30749.5234375\n",
      "Epoch: 1, Batch number: 4000, Loss: 30642.359375\n",
      "Epoch: 1, Batch number: 4100, Loss: 30456.494140625\n",
      "Epoch: 1, Batch number: 4200, Loss: 30098.92578125\n",
      "Epoch: 1, Batch number: 4300, Loss: 30333.998046875\n",
      "Epoch: 1, Batch number: 4400, Loss: 30217.13671875\n",
      "Epoch: 1, Batch number: 4500, Loss: 30221.873046875\n",
      "Epoch: 1, Batch number: 4600, Loss: 30518.341796875\n",
      "Epoch: 1, Batch number: 4700, Loss: 30294.4296875\n",
      "Epoch: 1, Batch number: 4800, Loss: 29624.556640625\n",
      "Epoch: 1, Batch number: 4900, Loss: 29864.2265625\n",
      "Epoch: 1, Batch number: 5000, Loss: 30000.072265625\n",
      "Epoch: 1, Batch number: 5100, Loss: 29514.501953125\n",
      "Epoch: 1, Batch number: 5200, Loss: 30006.55078125\n",
      "Epoch: 1, Batch number: 5300, Loss: 29947.994140625\n",
      "Epoch: 1, Batch number: 5400, Loss: 30036.455078125\n",
      "Epoch: 1, Batch number: 5500, Loss: 29980.732421875\n",
      "Epoch: 1, Batch number: 5600, Loss: 29874.8125\n",
      "Epoch: 1, Batch number: 5700, Loss: 29728.759765625\n",
      "Epoch: 1, Batch number: 5800, Loss: 30105.107421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 5900, Loss: 29739.38671875\n",
      "Epoch: 1, Batch number: 6000, Loss: 29893.751953125\n",
      "Epoch: 1, Batch number: 6100, Loss: 29727.30078125\n",
      "Epoch: 1, Batch number: 6200, Loss: 29515.373046875\n",
      "Epoch: 1, Batch number: 6300, Loss: 29404.3515625\n",
      "Epoch: 1, Batch number: 6400, Loss: 29357.0703125\n",
      "Epoch: 1, Batch number: 6500, Loss: 29486.515625\n",
      "Epoch: 1, Batch number: 6600, Loss: 29372.826171875\n",
      "Epoch: 1, Batch number: 6700, Loss: 29964.701171875\n",
      "Epoch: 1, Batch number: 6800, Loss: 29290.6484375\n",
      "Epoch: 1, Batch number: 6900, Loss: 29384.890625\n",
      "Epoch: 1, Batch number: 7000, Loss: 29263.630859375\n",
      "Epoch: 1, Batch number: 7100, Loss: 29713.205078125\n",
      "Epoch: 1, Batch number: 7200, Loss: 30250.169921875\n",
      "Epoch: 1, Batch number: 7300, Loss: 29976.76171875\n",
      "Epoch: 1, Batch number: 7400, Loss: 29337.501953125\n",
      "Epoch: 1, Batch number: 7500, Loss: 29219.29296875\n",
      "Epoch: 1, Batch number: 7600, Loss: 29604.18359375\n",
      "Epoch: 1, Batch number: 7700, Loss: 28991.919921875\n",
      "Epoch: 1, Batch number: 7800, Loss: 29030.4453125\n",
      "Epoch: 1, Batch number: 7900, Loss: 29399.138671875\n",
      "Epoch: 1, Batch number: 8000, Loss: 29080.666015625\n",
      "Epoch: 1, Batch number: 8100, Loss: 29463.255859375\n",
      "Epoch: 1, Batch number: 8200, Loss: 29313.005859375\n",
      "Epoch: 1, Batch number: 8300, Loss: 29455.994140625\n",
      "Epoch: 1, Batch number: 8400, Loss: 29007.3359375\n",
      "Epoch: 1, Batch number: 8500, Loss: 29654.443359375\n",
      "Epoch: 1, Batch number: 8600, Loss: 29182.052734375\n",
      "Epoch: 2, Batch number: 77, Loss: 28861.1640625\n",
      "Epoch: 2, Batch number: 177, Loss: 29351.46875\n",
      "Epoch: 2, Batch number: 277, Loss: 28995.48828125\n",
      "Epoch: 2, Batch number: 377, Loss: 28711.63671875\n",
      "Epoch: 2, Batch number: 477, Loss: 29470.22265625\n",
      "Epoch: 2, Batch number: 577, Loss: 28486.513671875\n",
      "Epoch: 2, Batch number: 677, Loss: 28720.373046875\n",
      "Epoch: 2, Batch number: 777, Loss: 29074.8203125\n",
      "Epoch: 2, Batch number: 877, Loss: 28906.66796875\n",
      "Epoch: 2, Batch number: 977, Loss: 28748.978515625\n",
      "Epoch: 2, Batch number: 1077, Loss: 29071.873046875\n",
      "Epoch: 2, Batch number: 1177, Loss: 29111.6328125\n",
      "Epoch: 2, Batch number: 1277, Loss: 28900.59765625\n",
      "Epoch: 2, Batch number: 1377, Loss: 29279.6796875\n",
      "Epoch: 2, Batch number: 1477, Loss: 28922.322265625\n",
      "Epoch: 2, Batch number: 1577, Loss: 28727.97265625\n",
      "Epoch: 2, Batch number: 1677, Loss: 28764.48828125\n",
      "Epoch: 2, Batch number: 1777, Loss: 28928.94140625\n",
      "Epoch: 2, Batch number: 1877, Loss: 29041.890625\n",
      "Epoch: 2, Batch number: 1977, Loss: 29155.078125\n",
      "Epoch: 2, Batch number: 2077, Loss: 28709.609375\n",
      "Epoch: 2, Batch number: 2177, Loss: 29036.99609375\n",
      "Epoch: 2, Batch number: 2277, Loss: 29323.078125\n",
      "Epoch: 2, Batch number: 2377, Loss: 29381.12109375\n",
      "Epoch: 2, Batch number: 2477, Loss: 28771.205078125\n",
      "Epoch: 2, Batch number: 2577, Loss: 29131.7890625\n",
      "Epoch: 2, Batch number: 2677, Loss: 28621.41015625\n",
      "Epoch: 2, Batch number: 2777, Loss: 28902.908203125\n",
      "Epoch: 2, Batch number: 2877, Loss: 28988.08203125\n",
      "Epoch: 2, Batch number: 2977, Loss: 28812.705078125\n",
      "Epoch: 2, Batch number: 3077, Loss: 28898.328125\n",
      "Epoch: 2, Batch number: 3177, Loss: 29048.904296875\n",
      "Epoch: 2, Batch number: 3277, Loss: 28815.984375\n",
      "Epoch: 2, Batch number: 3377, Loss: 28677.916015625\n",
      "Epoch: 2, Batch number: 3477, Loss: 29039.458984375\n",
      "Epoch: 2, Batch number: 3577, Loss: 28696.966796875\n",
      "Epoch: 2, Batch number: 3677, Loss: 28611.783203125\n",
      "Epoch: 2, Batch number: 3777, Loss: 28734.26953125\n",
      "Epoch: 2, Batch number: 3877, Loss: 28935.58203125\n",
      "Epoch: 2, Batch number: 3977, Loss: 28635.87890625\n",
      "Epoch: 2, Batch number: 4077, Loss: 28891.515625\n",
      "Epoch: 2, Batch number: 4177, Loss: 28382.353515625\n",
      "Epoch: 2, Batch number: 4277, Loss: 28911.73046875\n",
      "Epoch: 2, Batch number: 4377, Loss: 28766.1875\n",
      "Epoch: 2, Batch number: 4477, Loss: 28855.06640625\n",
      "Epoch: 2, Batch number: 4577, Loss: 28716.30859375\n",
      "Epoch: 2, Batch number: 4677, Loss: 28766.318359375\n",
      "Epoch: 2, Batch number: 4777, Loss: 28843.763671875\n",
      "Epoch: 2, Batch number: 4877, Loss: 28882.646484375\n",
      "Epoch: 2, Batch number: 4977, Loss: 28601.052734375\n",
      "Epoch: 2, Batch number: 5077, Loss: 28452.376953125\n",
      "Epoch: 2, Batch number: 5177, Loss: 28291.451171875\n",
      "Epoch: 2, Batch number: 5277, Loss: 28898.04296875\n",
      "Epoch: 2, Batch number: 5377, Loss: 28746.68359375\n",
      "Epoch: 2, Batch number: 5477, Loss: 28973.048828125\n",
      "Epoch: 2, Batch number: 5577, Loss: 28542.654296875\n",
      "Epoch: 2, Batch number: 5677, Loss: 28483.8828125\n",
      "Epoch: 2, Batch number: 5777, Loss: 28632.19921875\n",
      "Epoch: 2, Batch number: 5877, Loss: 28506.08984375\n",
      "Epoch: 2, Batch number: 5977, Loss: 28573.2890625\n",
      "Epoch: 2, Batch number: 6077, Loss: 28421.7890625\n",
      "Epoch: 2, Batch number: 6177, Loss: 28856.802734375\n",
      "Epoch: 2, Batch number: 6277, Loss: 28431.8203125\n",
      "Epoch: 2, Batch number: 6377, Loss: 28335.958984375\n",
      "Epoch: 2, Batch number: 6477, Loss: 28872.74609375\n",
      "Epoch: 2, Batch number: 6577, Loss: 28512.431640625\n",
      "Epoch: 2, Batch number: 6677, Loss: 28598.71875\n",
      "Epoch: 2, Batch number: 6777, Loss: 28686.39453125\n",
      "Epoch: 2, Batch number: 6877, Loss: 29005.630859375\n",
      "Epoch: 2, Batch number: 6977, Loss: 28644.76953125\n",
      "Epoch: 2, Batch number: 7077, Loss: 28685.779296875\n",
      "Epoch: 2, Batch number: 7177, Loss: 28674.619140625\n",
      "Epoch: 2, Batch number: 7277, Loss: 28972.3359375\n",
      "Epoch: 2, Batch number: 7377, Loss: 28601.005859375\n",
      "Epoch: 2, Batch number: 7477, Loss: 28460.693359375\n",
      "Epoch: 2, Batch number: 7577, Loss: 28514.890625\n",
      "Epoch: 2, Batch number: 7677, Loss: 28756.626953125\n",
      "Epoch: 2, Batch number: 7777, Loss: 28442.501953125\n",
      "Epoch: 2, Batch number: 7877, Loss: 28672.923828125\n",
      "Epoch: 2, Batch number: 7977, Loss: 28805.201171875\n",
      "Epoch: 2, Batch number: 8077, Loss: 28578.826171875\n",
      "Epoch: 2, Batch number: 8177, Loss: 28617.03515625\n",
      "Epoch: 2, Batch number: 8277, Loss: 28539.185546875\n",
      "Epoch: 2, Batch number: 8377, Loss: 28875.396484375\n",
      "Epoch: 2, Batch number: 8477, Loss: 28457.76953125\n",
      "Epoch: 2, Batch number: 8577, Loss: 28509.771484375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 43390.7421875\n",
      "Epoch: 1, Batch number: 100, Loss: 41897.45703125\n",
      "Epoch: 1, Batch number: 200, Loss: 39891.4765625\n",
      "Epoch: 1, Batch number: 300, Loss: 38786.65234375\n",
      "Epoch: 1, Batch number: 400, Loss: 37324.9453125\n",
      "Epoch: 1, Batch number: 500, Loss: 36546.1484375\n",
      "Epoch: 1, Batch number: 600, Loss: 35712.41796875\n",
      "Epoch: 1, Batch number: 700, Loss: 35580.48046875\n",
      "Epoch: 1, Batch number: 800, Loss: 34940.08984375\n",
      "Epoch: 1, Batch number: 900, Loss: 33989.171875\n",
      "Epoch: 1, Batch number: 1000, Loss: 33744.9296875\n",
      "Epoch: 1, Batch number: 1100, Loss: 33507.890625\n",
      "Epoch: 1, Batch number: 1200, Loss: 33502.22265625\n",
      "Epoch: 1, Batch number: 1300, Loss: 33201.734375\n",
      "Epoch: 1, Batch number: 1400, Loss: 32277.658203125\n",
      "Epoch: 1, Batch number: 1500, Loss: 31712.8828125\n",
      "Epoch: 1, Batch number: 1600, Loss: 31998.24609375\n",
      "Epoch: 1, Batch number: 1700, Loss: 31945.478515625\n",
      "Epoch: 1, Batch number: 1800, Loss: 31855.98046875\n",
      "Epoch: 1, Batch number: 1900, Loss: 31073.4140625\n",
      "Epoch: 1, Batch number: 2000, Loss: 31728.04296875\n",
      "Epoch: 1, Batch number: 2100, Loss: 31145.185546875\n",
      "Epoch: 1, Batch number: 2200, Loss: 31042.67578125\n",
      "Epoch: 1, Batch number: 2300, Loss: 31121.2265625\n",
      "Epoch: 1, Batch number: 2400, Loss: 30693.734375\n",
      "Epoch: 1, Batch number: 2500, Loss: 30722.66796875\n",
      "Epoch: 1, Batch number: 2600, Loss: 30635.912109375\n",
      "Epoch: 1, Batch number: 2700, Loss: 30317.5703125\n",
      "Epoch: 1, Batch number: 2800, Loss: 30206.150390625\n",
      "Epoch: 1, Batch number: 2900, Loss: 30683.3125\n",
      "Epoch: 1, Batch number: 3000, Loss: 30518.36328125\n",
      "Epoch: 1, Batch number: 3100, Loss: 30420.126953125\n",
      "Epoch: 1, Batch number: 3200, Loss: 30426.525390625\n",
      "Epoch: 1, Batch number: 3300, Loss: 29763.568359375\n",
      "Epoch: 1, Batch number: 3400, Loss: 30554.216796875\n",
      "Epoch: 1, Batch number: 3500, Loss: 29793.984375\n",
      "Epoch: 1, Batch number: 3600, Loss: 30063.931640625\n",
      "Epoch: 1, Batch number: 3700, Loss: 30203.47265625\n",
      "Epoch: 1, Batch number: 3800, Loss: 29930.744140625\n",
      "Epoch: 1, Batch number: 3900, Loss: 29787.00390625\n",
      "Epoch: 1, Batch number: 4000, Loss: 29888.44921875\n",
      "Epoch: 1, Batch number: 4100, Loss: 29400.4765625\n",
      "Epoch: 1, Batch number: 4200, Loss: 30225.380859375\n",
      "Epoch: 1, Batch number: 4300, Loss: 29563.58203125\n",
      "Epoch: 1, Batch number: 4400, Loss: 30047.2109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 4500, Loss: 29954.99609375\n",
      "Epoch: 1, Batch number: 4600, Loss: 29331.916015625\n",
      "Epoch: 1, Batch number: 4700, Loss: 29630.103515625\n",
      "Epoch: 1, Batch number: 4800, Loss: 29157.26953125\n",
      "Epoch: 1, Batch number: 4900, Loss: 29264.822265625\n",
      "Epoch: 1, Batch number: 5000, Loss: 29763.0546875\n",
      "Epoch: 1, Batch number: 5100, Loss: 29444.107421875\n",
      "Epoch: 1, Batch number: 5200, Loss: 29566.412109375\n",
      "Epoch: 1, Batch number: 5300, Loss: 29759.017578125\n",
      "Epoch: 1, Batch number: 5400, Loss: 29248.330078125\n",
      "Epoch: 1, Batch number: 5500, Loss: 29958.302734375\n",
      "Epoch: 1, Batch number: 5600, Loss: 29324.947265625\n",
      "Epoch: 1, Batch number: 5700, Loss: 28827.8515625\n",
      "Epoch: 1, Batch number: 5800, Loss: 29507.677734375\n",
      "Epoch: 1, Batch number: 5900, Loss: 29721.8984375\n",
      "Epoch: 1, Batch number: 6000, Loss: 29318.98046875\n",
      "Epoch: 1, Batch number: 6100, Loss: 29564.931640625\n",
      "Epoch: 1, Batch number: 6200, Loss: 29242.462890625\n",
      "Epoch: 1, Batch number: 6300, Loss: 28699.8671875\n",
      "Epoch: 1, Batch number: 6400, Loss: 28853.203125\n",
      "Epoch: 1, Batch number: 6500, Loss: 29498.333984375\n",
      "Epoch: 1, Batch number: 6600, Loss: 29406.4453125\n",
      "Epoch: 1, Batch number: 6700, Loss: 29349.623046875\n",
      "Epoch: 1, Batch number: 6800, Loss: 28864.455078125\n",
      "Epoch: 1, Batch number: 6900, Loss: 29250.724609375\n",
      "Epoch: 1, Batch number: 7000, Loss: 29235.41796875\n",
      "Epoch: 1, Batch number: 7100, Loss: 28974.734375\n",
      "Epoch: 1, Batch number: 7200, Loss: 29098.302734375\n",
      "Epoch: 1, Batch number: 7300, Loss: 28840.130859375\n",
      "Epoch: 1, Batch number: 7400, Loss: 28783.685546875\n",
      "Epoch: 1, Batch number: 7500, Loss: 28898.4296875\n",
      "Epoch: 1, Batch number: 7600, Loss: 29508.3984375\n",
      "Epoch: 1, Batch number: 7700, Loss: 28862.99609375\n",
      "Epoch: 1, Batch number: 7800, Loss: 29025.263671875\n",
      "Epoch: 1, Batch number: 7900, Loss: 28640.595703125\n",
      "Epoch: 1, Batch number: 8000, Loss: 28706.10546875\n",
      "Epoch: 1, Batch number: 8100, Loss: 28922.205078125\n",
      "Epoch: 1, Batch number: 8200, Loss: 28992.287109375\n",
      "Epoch: 1, Batch number: 8300, Loss: 28346.029296875\n",
      "Epoch: 1, Batch number: 8400, Loss: 28583.03515625\n",
      "Epoch: 1, Batch number: 8500, Loss: 28324.197265625\n",
      "Epoch: 1, Batch number: 8600, Loss: 28891.73828125\n",
      "Epoch: 2, Batch number: 77, Loss: 28451.927734375\n",
      "Epoch: 2, Batch number: 177, Loss: 28727.900390625\n",
      "Epoch: 2, Batch number: 277, Loss: 28621.037109375\n",
      "Epoch: 2, Batch number: 377, Loss: 28856.25390625\n",
      "Epoch: 2, Batch number: 477, Loss: 28369.62109375\n",
      "Epoch: 2, Batch number: 577, Loss: 28800.095703125\n",
      "Epoch: 2, Batch number: 677, Loss: 28725.892578125\n",
      "Epoch: 2, Batch number: 777, Loss: 28724.841796875\n",
      "Epoch: 2, Batch number: 877, Loss: 28691.50390625\n",
      "Epoch: 2, Batch number: 977, Loss: 28900.533203125\n",
      "Epoch: 2, Batch number: 1077, Loss: 28547.07421875\n",
      "Epoch: 2, Batch number: 1177, Loss: 28395.48046875\n",
      "Epoch: 2, Batch number: 1277, Loss: 28855.44921875\n",
      "Epoch: 2, Batch number: 1377, Loss: 28501.904296875\n",
      "Epoch: 2, Batch number: 1477, Loss: 28568.15234375\n",
      "Epoch: 2, Batch number: 1577, Loss: 28336.466796875\n",
      "Epoch: 2, Batch number: 1677, Loss: 28315.224609375\n",
      "Epoch: 2, Batch number: 1777, Loss: 28934.671875\n",
      "Epoch: 2, Batch number: 1877, Loss: 28893.0546875\n",
      "Epoch: 2, Batch number: 1977, Loss: 28372.224609375\n",
      "Epoch: 2, Batch number: 2077, Loss: 28684.287109375\n",
      "Epoch: 2, Batch number: 2177, Loss: 28427.177734375\n",
      "Epoch: 2, Batch number: 2277, Loss: 28489.7421875\n",
      "Epoch: 2, Batch number: 2377, Loss: 28167.513671875\n",
      "Epoch: 2, Batch number: 2477, Loss: 28692.1953125\n",
      "Epoch: 2, Batch number: 2577, Loss: 28333.48046875\n",
      "Epoch: 2, Batch number: 2677, Loss: 28273.91796875\n",
      "Epoch: 2, Batch number: 2777, Loss: 28493.224609375\n",
      "Epoch: 2, Batch number: 2877, Loss: 28392.626953125\n",
      "Epoch: 2, Batch number: 2977, Loss: 28344.083984375\n",
      "Epoch: 2, Batch number: 3077, Loss: 28092.7265625\n",
      "Epoch: 2, Batch number: 3177, Loss: 28449.69140625\n",
      "Epoch: 2, Batch number: 3277, Loss: 28482.17578125\n",
      "Epoch: 2, Batch number: 3377, Loss: 27968.701171875\n",
      "Epoch: 2, Batch number: 3477, Loss: 28222.095703125\n",
      "Epoch: 2, Batch number: 3577, Loss: 28512.400390625\n",
      "Epoch: 2, Batch number: 3677, Loss: 28533.12890625\n",
      "Epoch: 2, Batch number: 3777, Loss: 28341.419921875\n",
      "Epoch: 2, Batch number: 3877, Loss: 28831.32421875\n",
      "Epoch: 2, Batch number: 3977, Loss: 28566.962890625\n",
      "Epoch: 2, Batch number: 4077, Loss: 28744.16796875\n",
      "Epoch: 2, Batch number: 4177, Loss: 28229.279296875\n",
      "Epoch: 2, Batch number: 4277, Loss: 28442.439453125\n",
      "Epoch: 2, Batch number: 4377, Loss: 28512.560546875\n",
      "Epoch: 2, Batch number: 4477, Loss: 28005.51171875\n",
      "Epoch: 2, Batch number: 4577, Loss: 28530.98828125\n",
      "Epoch: 2, Batch number: 4677, Loss: 28524.21484375\n",
      "Epoch: 2, Batch number: 4777, Loss: 28403.146484375\n",
      "Epoch: 2, Batch number: 4877, Loss: 28032.9921875\n",
      "Epoch: 2, Batch number: 4977, Loss: 28440.548828125\n",
      "Epoch: 2, Batch number: 5077, Loss: 28526.544921875\n",
      "Epoch: 2, Batch number: 5177, Loss: 28002.572265625\n",
      "Epoch: 2, Batch number: 5277, Loss: 28336.873046875\n",
      "Epoch: 2, Batch number: 5377, Loss: 27879.591796875\n",
      "Epoch: 2, Batch number: 5477, Loss: 27944.525390625\n",
      "Epoch: 2, Batch number: 5577, Loss: 28190.9765625\n",
      "Epoch: 2, Batch number: 5677, Loss: 28778.73828125\n",
      "Epoch: 2, Batch number: 5777, Loss: 28084.931640625\n",
      "Epoch: 2, Batch number: 5877, Loss: 28425.693359375\n",
      "Epoch: 2, Batch number: 5977, Loss: 28377.6171875\n",
      "Epoch: 2, Batch number: 6077, Loss: 28366.83984375\n",
      "Epoch: 2, Batch number: 6177, Loss: 28495.466796875\n",
      "Epoch: 2, Batch number: 6277, Loss: 28336.744140625\n",
      "Epoch: 2, Batch number: 6377, Loss: 28174.03125\n",
      "Epoch: 2, Batch number: 6477, Loss: 28215.259765625\n",
      "Epoch: 2, Batch number: 6577, Loss: 28449.919921875\n",
      "Epoch: 2, Batch number: 6677, Loss: 28411.0234375\n",
      "Epoch: 2, Batch number: 6777, Loss: 28445.447265625\n",
      "Epoch: 2, Batch number: 6877, Loss: 27773.30859375\n",
      "Epoch: 2, Batch number: 6977, Loss: 28495.548828125\n",
      "Epoch: 2, Batch number: 7077, Loss: 28131.197265625\n",
      "Epoch: 2, Batch number: 7177, Loss: 28607.521484375\n",
      "Epoch: 2, Batch number: 7277, Loss: 28093.939453125\n",
      "Epoch: 2, Batch number: 7377, Loss: 28412.435546875\n",
      "Epoch: 2, Batch number: 7477, Loss: 28118.328125\n",
      "Epoch: 2, Batch number: 7577, Loss: 28421.759765625\n",
      "Epoch: 2, Batch number: 7677, Loss: 28357.9609375\n",
      "Epoch: 2, Batch number: 7777, Loss: 28262.93359375\n",
      "Epoch: 2, Batch number: 7877, Loss: 28342.00390625\n",
      "Epoch: 2, Batch number: 7977, Loss: 28498.787109375\n",
      "Epoch: 2, Batch number: 8077, Loss: 28520.337890625\n",
      "Epoch: 2, Batch number: 8177, Loss: 28561.759765625\n",
      "Epoch: 2, Batch number: 8277, Loss: 28487.84375\n",
      "Epoch: 2, Batch number: 8377, Loss: 28158.65234375\n",
      "Epoch: 2, Batch number: 8477, Loss: 27982.794921875\n",
      "Epoch: 2, Batch number: 8577, Loss: 28549.740234375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 43183.09765625\n",
      "Epoch: 1, Batch number: 100, Loss: 40536.9140625\n",
      "Epoch: 1, Batch number: 200, Loss: 37655.90625\n",
      "Epoch: 1, Batch number: 300, Loss: 37011.22265625\n",
      "Epoch: 1, Batch number: 400, Loss: 35590.2421875\n",
      "Epoch: 1, Batch number: 500, Loss: 35009.13671875\n",
      "Epoch: 1, Batch number: 600, Loss: 34892.58984375\n",
      "Epoch: 1, Batch number: 700, Loss: 34560.25\n",
      "Epoch: 1, Batch number: 800, Loss: 34096.70703125\n",
      "Epoch: 1, Batch number: 900, Loss: 34129.78125\n",
      "Epoch: 1, Batch number: 1000, Loss: 32449.02734375\n",
      "Epoch: 1, Batch number: 1100, Loss: 32337.96875\n",
      "Epoch: 1, Batch number: 1200, Loss: 31504.07421875\n",
      "Epoch: 1, Batch number: 1300, Loss: 31905.111328125\n",
      "Epoch: 1, Batch number: 1400, Loss: 31646.90625\n",
      "Epoch: 1, Batch number: 1500, Loss: 31484.7578125\n",
      "Epoch: 1, Batch number: 1600, Loss: 31723.626953125\n",
      "Epoch: 1, Batch number: 1700, Loss: 30969.728515625\n",
      "Epoch: 1, Batch number: 1800, Loss: 31068.205078125\n",
      "Epoch: 1, Batch number: 1900, Loss: 31046.748046875\n",
      "Epoch: 1, Batch number: 2000, Loss: 30999.833984375\n",
      "Epoch: 1, Batch number: 2100, Loss: 30605.42578125\n",
      "Epoch: 1, Batch number: 2200, Loss: 30012.431640625\n",
      "Epoch: 1, Batch number: 2300, Loss: 30348.40234375\n",
      "Epoch: 1, Batch number: 2400, Loss: 29997.47265625\n",
      "Epoch: 1, Batch number: 2500, Loss: 29687.2265625\n",
      "Epoch: 1, Batch number: 2600, Loss: 30140.640625\n",
      "Epoch: 1, Batch number: 2700, Loss: 30119.279296875\n",
      "Epoch: 1, Batch number: 2800, Loss: 29584.14453125\n",
      "Epoch: 1, Batch number: 2900, Loss: 29688.685546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 3000, Loss: 29664.787109375\n",
      "Epoch: 1, Batch number: 3100, Loss: 29937.509765625\n",
      "Epoch: 1, Batch number: 3200, Loss: 29595.427734375\n",
      "Epoch: 1, Batch number: 3300, Loss: 29955.212890625\n",
      "Epoch: 1, Batch number: 3400, Loss: 29782.29296875\n",
      "Epoch: 1, Batch number: 3500, Loss: 29424.490234375\n",
      "Epoch: 1, Batch number: 3600, Loss: 29689.201171875\n",
      "Epoch: 1, Batch number: 3700, Loss: 29659.94140625\n",
      "Epoch: 1, Batch number: 3800, Loss: 29441.330078125\n",
      "Epoch: 1, Batch number: 3900, Loss: 29513.2734375\n",
      "Epoch: 1, Batch number: 4000, Loss: 29311.04296875\n",
      "Epoch: 1, Batch number: 4100, Loss: 29281.064453125\n",
      "Epoch: 1, Batch number: 4200, Loss: 29468.388671875\n",
      "Epoch: 1, Batch number: 4300, Loss: 29291.794921875\n",
      "Epoch: 1, Batch number: 4400, Loss: 29102.513671875\n",
      "Epoch: 1, Batch number: 4500, Loss: 29836.478515625\n",
      "Epoch: 1, Batch number: 4600, Loss: 29665.689453125\n",
      "Epoch: 1, Batch number: 4700, Loss: 29332.916015625\n",
      "Epoch: 1, Batch number: 4800, Loss: 28837.373046875\n",
      "Epoch: 1, Batch number: 4900, Loss: 29228.828125\n",
      "Epoch: 1, Batch number: 5000, Loss: 28994.056640625\n",
      "Epoch: 1, Batch number: 5100, Loss: 29222.861328125\n",
      "Epoch: 1, Batch number: 5200, Loss: 29128.244140625\n",
      "Epoch: 1, Batch number: 5300, Loss: 29109.0\n",
      "Epoch: 1, Batch number: 5400, Loss: 28901.59375\n",
      "Epoch: 1, Batch number: 5500, Loss: 29022.255859375\n",
      "Epoch: 1, Batch number: 5600, Loss: 29160.181640625\n",
      "Epoch: 1, Batch number: 5700, Loss: 29107.845703125\n",
      "Epoch: 1, Batch number: 5800, Loss: 28949.423828125\n",
      "Epoch: 1, Batch number: 5900, Loss: 28776.650390625\n",
      "Epoch: 1, Batch number: 6000, Loss: 29015.5078125\n",
      "Epoch: 1, Batch number: 6100, Loss: 28993.404296875\n",
      "Epoch: 1, Batch number: 6200, Loss: 28498.0859375\n",
      "Epoch: 1, Batch number: 6300, Loss: 28688.888671875\n",
      "Epoch: 1, Batch number: 6400, Loss: 28222.298828125\n",
      "Epoch: 1, Batch number: 6500, Loss: 28751.66015625\n",
      "Epoch: 1, Batch number: 6600, Loss: 28529.3671875\n",
      "Epoch: 1, Batch number: 6700, Loss: 29307.037109375\n",
      "Epoch: 1, Batch number: 6800, Loss: 28727.796875\n",
      "Epoch: 1, Batch number: 6900, Loss: 28891.572265625\n",
      "Epoch: 1, Batch number: 7000, Loss: 29005.75390625\n",
      "Epoch: 1, Batch number: 7100, Loss: 28718.83203125\n",
      "Epoch: 1, Batch number: 7200, Loss: 28567.03515625\n",
      "Epoch: 1, Batch number: 7300, Loss: 28751.83203125\n",
      "Epoch: 1, Batch number: 7400, Loss: 29340.931640625\n",
      "Epoch: 1, Batch number: 7500, Loss: 28707.47265625\n",
      "Epoch: 1, Batch number: 7600, Loss: 28204.697265625\n",
      "Epoch: 1, Batch number: 7700, Loss: 28489.6015625\n",
      "Epoch: 1, Batch number: 7800, Loss: 28326.525390625\n",
      "Epoch: 1, Batch number: 7900, Loss: 28545.951171875\n",
      "Epoch: 1, Batch number: 8000, Loss: 27973.755859375\n",
      "Epoch: 1, Batch number: 8100, Loss: 29026.841796875\n",
      "Epoch: 1, Batch number: 8200, Loss: 28505.083984375\n",
      "Epoch: 1, Batch number: 8300, Loss: 28056.314453125\n",
      "Epoch: 1, Batch number: 8400, Loss: 28429.80859375\n",
      "Epoch: 1, Batch number: 8500, Loss: 28088.822265625\n",
      "Epoch: 1, Batch number: 8600, Loss: 28086.298828125\n",
      "Epoch: 2, Batch number: 77, Loss: 27711.791015625\n",
      "Epoch: 2, Batch number: 177, Loss: 28317.4375\n",
      "Epoch: 2, Batch number: 277, Loss: 27985.34375\n",
      "Epoch: 2, Batch number: 377, Loss: 28020.923828125\n",
      "Epoch: 2, Batch number: 477, Loss: 28161.90625\n",
      "Epoch: 2, Batch number: 577, Loss: 28318.888671875\n",
      "Epoch: 2, Batch number: 677, Loss: 28095.40234375\n",
      "Epoch: 2, Batch number: 777, Loss: 28394.548828125\n",
      "Epoch: 2, Batch number: 877, Loss: 28706.607421875\n",
      "Epoch: 2, Batch number: 977, Loss: 28114.7734375\n",
      "Epoch: 2, Batch number: 1077, Loss: 27988.798828125\n",
      "Epoch: 2, Batch number: 1177, Loss: 28187.359375\n",
      "Epoch: 2, Batch number: 1277, Loss: 27745.90625\n",
      "Epoch: 2, Batch number: 1377, Loss: 27561.84375\n",
      "Epoch: 2, Batch number: 1477, Loss: 27679.66015625\n",
      "Epoch: 2, Batch number: 1577, Loss: 27988.681640625\n",
      "Epoch: 2, Batch number: 1677, Loss: 28551.48046875\n",
      "Epoch: 2, Batch number: 1777, Loss: 28250.26953125\n",
      "Epoch: 2, Batch number: 1877, Loss: 28389.501953125\n",
      "Epoch: 2, Batch number: 1977, Loss: 28610.404296875\n",
      "Epoch: 2, Batch number: 2077, Loss: 28250.376953125\n",
      "Epoch: 2, Batch number: 2177, Loss: 27534.9765625\n",
      "Epoch: 2, Batch number: 2277, Loss: 28204.541015625\n",
      "Epoch: 2, Batch number: 2377, Loss: 27860.033203125\n",
      "Epoch: 2, Batch number: 2477, Loss: 27764.205078125\n",
      "Epoch: 2, Batch number: 2577, Loss: 28044.681640625\n",
      "Epoch: 2, Batch number: 2677, Loss: 28196.048828125\n",
      "Epoch: 2, Batch number: 2777, Loss: 27665.1953125\n",
      "Epoch: 2, Batch number: 2877, Loss: 28510.4453125\n",
      "Epoch: 2, Batch number: 2977, Loss: 28237.744140625\n",
      "Epoch: 2, Batch number: 3077, Loss: 28435.796875\n",
      "Epoch: 2, Batch number: 3177, Loss: 28285.177734375\n",
      "Epoch: 2, Batch number: 3277, Loss: 28048.890625\n",
      "Epoch: 2, Batch number: 3377, Loss: 27948.763671875\n",
      "Epoch: 2, Batch number: 3477, Loss: 28181.59375\n",
      "Epoch: 2, Batch number: 3577, Loss: 27817.3203125\n",
      "Epoch: 2, Batch number: 3677, Loss: 28237.083984375\n",
      "Epoch: 2, Batch number: 3777, Loss: 27683.109375\n",
      "Epoch: 2, Batch number: 3877, Loss: 28204.958984375\n",
      "Epoch: 2, Batch number: 3977, Loss: 28092.95703125\n",
      "Epoch: 2, Batch number: 4077, Loss: 28225.83203125\n",
      "Epoch: 2, Batch number: 4177, Loss: 27960.318359375\n",
      "Epoch: 2, Batch number: 4277, Loss: 27764.40234375\n",
      "Epoch: 2, Batch number: 4377, Loss: 28062.03515625\n",
      "Epoch: 2, Batch number: 4477, Loss: 28457.0078125\n",
      "Epoch: 2, Batch number: 4577, Loss: 27886.583984375\n",
      "Epoch: 2, Batch number: 4677, Loss: 28065.716796875\n",
      "Epoch: 2, Batch number: 4777, Loss: 27896.892578125\n",
      "Epoch: 2, Batch number: 4877, Loss: 27811.40234375\n",
      "Epoch: 2, Batch number: 4977, Loss: 27958.46484375\n",
      "Epoch: 2, Batch number: 5077, Loss: 28054.013671875\n",
      "Epoch: 2, Batch number: 5177, Loss: 28011.439453125\n",
      "Epoch: 2, Batch number: 5277, Loss: 28208.10546875\n",
      "Epoch: 2, Batch number: 5377, Loss: 28106.978515625\n",
      "Epoch: 2, Batch number: 5477, Loss: 28337.6796875\n",
      "Epoch: 2, Batch number: 5577, Loss: 27694.1953125\n",
      "Epoch: 2, Batch number: 5677, Loss: 27921.435546875\n",
      "Epoch: 2, Batch number: 5777, Loss: 27818.357421875\n",
      "Epoch: 2, Batch number: 5877, Loss: 28094.65234375\n",
      "Epoch: 2, Batch number: 5977, Loss: 27818.71484375\n",
      "Epoch: 2, Batch number: 6077, Loss: 27947.783203125\n",
      "Epoch: 2, Batch number: 6177, Loss: 27803.09375\n",
      "Epoch: 2, Batch number: 6277, Loss: 27905.876953125\n",
      "Epoch: 2, Batch number: 6377, Loss: 27873.42578125\n",
      "Epoch: 2, Batch number: 6477, Loss: 27908.59375\n",
      "Epoch: 2, Batch number: 6577, Loss: 28531.98046875\n",
      "Epoch: 2, Batch number: 6677, Loss: 28155.72265625\n",
      "Epoch: 2, Batch number: 6777, Loss: 28246.5859375\n",
      "Epoch: 2, Batch number: 6877, Loss: 27996.529296875\n",
      "Epoch: 2, Batch number: 6977, Loss: 27588.55859375\n",
      "Epoch: 2, Batch number: 7077, Loss: 28276.0546875\n",
      "Epoch: 2, Batch number: 7177, Loss: 27766.251953125\n",
      "Epoch: 2, Batch number: 7277, Loss: 28050.431640625\n",
      "Epoch: 2, Batch number: 7377, Loss: 28279.79296875\n",
      "Epoch: 2, Batch number: 7477, Loss: 28094.93359375\n",
      "Epoch: 2, Batch number: 7577, Loss: 27943.7890625\n",
      "Epoch: 2, Batch number: 7677, Loss: 28219.775390625\n",
      "Epoch: 2, Batch number: 7777, Loss: 27817.396484375\n",
      "Epoch: 2, Batch number: 7877, Loss: 28068.337890625\n",
      "Epoch: 2, Batch number: 7977, Loss: 28251.7734375\n",
      "Epoch: 2, Batch number: 8077, Loss: 28323.224609375\n",
      "Epoch: 2, Batch number: 8177, Loss: 28484.50390625\n",
      "Epoch: 2, Batch number: 8277, Loss: 28376.2734375\n",
      "Epoch: 2, Batch number: 8377, Loss: 28202.505859375\n",
      "Epoch: 2, Batch number: 8477, Loss: 27821.4140625\n",
      "Epoch: 2, Batch number: 8577, Loss: 27896.587890625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 43737.171875\n",
      "Epoch: 1, Batch number: 100, Loss: 40006.62109375\n",
      "Epoch: 1, Batch number: 200, Loss: 37632.70703125\n",
      "Epoch: 1, Batch number: 300, Loss: 37567.62109375\n",
      "Epoch: 1, Batch number: 400, Loss: 36058.859375\n",
      "Epoch: 1, Batch number: 500, Loss: 35042.578125\n",
      "Epoch: 1, Batch number: 600, Loss: 34483.5\n",
      "Epoch: 1, Batch number: 700, Loss: 33813.54296875\n",
      "Epoch: 1, Batch number: 800, Loss: 32987.015625\n",
      "Epoch: 1, Batch number: 900, Loss: 32301.56640625\n",
      "Epoch: 1, Batch number: 1000, Loss: 32551.453125\n",
      "Epoch: 1, Batch number: 1100, Loss: 32401.865234375\n",
      "Epoch: 1, Batch number: 1200, Loss: 31583.5234375\n",
      "Epoch: 1, Batch number: 1300, Loss: 31458.619140625\n",
      "Epoch: 1, Batch number: 1400, Loss: 31471.62890625\n",
      "Epoch: 1, Batch number: 1500, Loss: 30887.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 1600, Loss: 30809.0078125\n",
      "Epoch: 1, Batch number: 1700, Loss: 30955.927734375\n",
      "Epoch: 1, Batch number: 1800, Loss: 30161.462890625\n",
      "Epoch: 1, Batch number: 1900, Loss: 30577.83203125\n",
      "Epoch: 1, Batch number: 2000, Loss: 30098.396484375\n",
      "Epoch: 1, Batch number: 2100, Loss: 29653.865234375\n",
      "Epoch: 1, Batch number: 2200, Loss: 30368.587890625\n",
      "Epoch: 1, Batch number: 2300, Loss: 29987.689453125\n",
      "Epoch: 1, Batch number: 2400, Loss: 30013.81640625\n",
      "Epoch: 1, Batch number: 2500, Loss: 29875.9375\n",
      "Epoch: 1, Batch number: 2600, Loss: 29957.00390625\n",
      "Epoch: 1, Batch number: 2700, Loss: 29996.56640625\n",
      "Epoch: 1, Batch number: 2800, Loss: 28988.576171875\n",
      "Epoch: 1, Batch number: 2900, Loss: 29910.26953125\n",
      "Epoch: 1, Batch number: 3000, Loss: 29357.66796875\n",
      "Epoch: 1, Batch number: 3100, Loss: 29427.005859375\n",
      "Epoch: 1, Batch number: 3200, Loss: 30156.076171875\n",
      "Epoch: 1, Batch number: 3300, Loss: 28943.84375\n",
      "Epoch: 1, Batch number: 3400, Loss: 29067.021484375\n",
      "Epoch: 1, Batch number: 3500, Loss: 29210.435546875\n",
      "Epoch: 1, Batch number: 3600, Loss: 28525.654296875\n",
      "Epoch: 1, Batch number: 3700, Loss: 28896.224609375\n",
      "Epoch: 1, Batch number: 3800, Loss: 29037.779296875\n",
      "Epoch: 1, Batch number: 3900, Loss: 29498.068359375\n",
      "Epoch: 1, Batch number: 4000, Loss: 29070.533203125\n",
      "Epoch: 1, Batch number: 4100, Loss: 28875.01953125\n",
      "Epoch: 1, Batch number: 4200, Loss: 28930.21875\n",
      "Epoch: 1, Batch number: 4300, Loss: 29087.1875\n",
      "Epoch: 1, Batch number: 4400, Loss: 28727.724609375\n",
      "Epoch: 1, Batch number: 4500, Loss: 29022.53515625\n",
      "Epoch: 1, Batch number: 4600, Loss: 29040.1015625\n",
      "Epoch: 1, Batch number: 4700, Loss: 28824.974609375\n",
      "Epoch: 1, Batch number: 4800, Loss: 28764.97265625\n",
      "Epoch: 1, Batch number: 4900, Loss: 29185.26953125\n",
      "Epoch: 1, Batch number: 5000, Loss: 28691.685546875\n",
      "Epoch: 1, Batch number: 5100, Loss: 28874.419921875\n",
      "Epoch: 1, Batch number: 5200, Loss: 29432.95703125\n",
      "Epoch: 1, Batch number: 5300, Loss: 28941.33984375\n",
      "Epoch: 1, Batch number: 5400, Loss: 29035.587890625\n",
      "Epoch: 1, Batch number: 5500, Loss: 28795.427734375\n",
      "Epoch: 1, Batch number: 5600, Loss: 28996.419921875\n",
      "Epoch: 1, Batch number: 5700, Loss: 29012.203125\n",
      "Epoch: 1, Batch number: 5800, Loss: 28765.2890625\n",
      "Epoch: 1, Batch number: 5900, Loss: 28459.654296875\n",
      "Epoch: 1, Batch number: 6000, Loss: 28324.3828125\n",
      "Epoch: 1, Batch number: 6100, Loss: 28392.986328125\n",
      "Epoch: 1, Batch number: 6200, Loss: 28364.55859375\n",
      "Epoch: 1, Batch number: 6300, Loss: 28597.501953125\n",
      "Epoch: 1, Batch number: 6400, Loss: 29225.66015625\n",
      "Epoch: 1, Batch number: 6500, Loss: 28585.0\n",
      "Epoch: 1, Batch number: 6600, Loss: 28904.494140625\n",
      "Epoch: 1, Batch number: 6700, Loss: 28792.671875\n",
      "Epoch: 1, Batch number: 6800, Loss: 28468.1171875\n",
      "Epoch: 1, Batch number: 6900, Loss: 28880.615234375\n",
      "Epoch: 1, Batch number: 7000, Loss: 28422.4140625\n",
      "Epoch: 1, Batch number: 7100, Loss: 28223.123046875\n",
      "Epoch: 1, Batch number: 7200, Loss: 28354.333984375\n",
      "Epoch: 1, Batch number: 7300, Loss: 28419.912109375\n",
      "Epoch: 1, Batch number: 7400, Loss: 28394.146484375\n",
      "Epoch: 1, Batch number: 7500, Loss: 28129.96484375\n",
      "Epoch: 1, Batch number: 7600, Loss: 28197.65234375\n",
      "Epoch: 1, Batch number: 7700, Loss: 28426.91796875\n",
      "Epoch: 1, Batch number: 7800, Loss: 28497.97265625\n",
      "Epoch: 1, Batch number: 7900, Loss: 28496.958984375\n",
      "Epoch: 1, Batch number: 8000, Loss: 28679.58984375\n",
      "Epoch: 1, Batch number: 8100, Loss: 28549.890625\n",
      "Epoch: 1, Batch number: 8200, Loss: 28379.39453125\n",
      "Epoch: 1, Batch number: 8300, Loss: 28183.685546875\n",
      "Epoch: 1, Batch number: 8400, Loss: 28220.97265625\n",
      "Epoch: 1, Batch number: 8500, Loss: 28539.08203125\n",
      "Epoch: 1, Batch number: 8600, Loss: 28181.14453125\n",
      "Epoch: 2, Batch number: 77, Loss: 28102.18359375\n",
      "Epoch: 2, Batch number: 177, Loss: 28129.83984375\n",
      "Epoch: 2, Batch number: 277, Loss: 28229.619140625\n",
      "Epoch: 2, Batch number: 377, Loss: 27854.345703125\n",
      "Epoch: 2, Batch number: 477, Loss: 28210.251953125\n",
      "Epoch: 2, Batch number: 577, Loss: 28175.845703125\n",
      "Epoch: 2, Batch number: 677, Loss: 27736.880859375\n",
      "Epoch: 2, Batch number: 777, Loss: 27814.47265625\n",
      "Epoch: 2, Batch number: 877, Loss: 27769.134765625\n",
      "Epoch: 2, Batch number: 977, Loss: 28323.2890625\n",
      "Epoch: 2, Batch number: 1077, Loss: 27966.494140625\n",
      "Epoch: 2, Batch number: 1177, Loss: 27514.912109375\n",
      "Epoch: 2, Batch number: 1277, Loss: 28288.291015625\n",
      "Epoch: 2, Batch number: 1377, Loss: 27591.259765625\n",
      "Epoch: 2, Batch number: 1477, Loss: 28133.478515625\n",
      "Epoch: 2, Batch number: 1577, Loss: 27644.2421875\n",
      "Epoch: 2, Batch number: 1677, Loss: 27706.322265625\n",
      "Epoch: 2, Batch number: 1777, Loss: 27839.06640625\n",
      "Epoch: 2, Batch number: 1877, Loss: 27715.873046875\n",
      "Epoch: 2, Batch number: 1977, Loss: 27675.978515625\n",
      "Epoch: 2, Batch number: 2077, Loss: 27723.203125\n",
      "Epoch: 2, Batch number: 2177, Loss: 27918.30859375\n",
      "Epoch: 2, Batch number: 2277, Loss: 28444.736328125\n",
      "Epoch: 2, Batch number: 2377, Loss: 27924.03515625\n",
      "Epoch: 2, Batch number: 2477, Loss: 27883.73828125\n",
      "Epoch: 2, Batch number: 2577, Loss: 27598.8359375\n",
      "Epoch: 2, Batch number: 2677, Loss: 28139.28515625\n",
      "Epoch: 2, Batch number: 2777, Loss: 27600.462890625\n",
      "Epoch: 2, Batch number: 2877, Loss: 27801.39453125\n",
      "Epoch: 2, Batch number: 2977, Loss: 27536.806640625\n",
      "Epoch: 2, Batch number: 3077, Loss: 27665.76953125\n",
      "Epoch: 2, Batch number: 3177, Loss: 27952.802734375\n",
      "Epoch: 2, Batch number: 3277, Loss: 27872.859375\n",
      "Epoch: 2, Batch number: 3377, Loss: 28287.048828125\n",
      "Epoch: 2, Batch number: 3477, Loss: 27725.21875\n",
      "Epoch: 2, Batch number: 3577, Loss: 27911.26171875\n",
      "Epoch: 2, Batch number: 3677, Loss: 27756.650390625\n",
      "Epoch: 2, Batch number: 3777, Loss: 28049.029296875\n",
      "Epoch: 2, Batch number: 3877, Loss: 27993.501953125\n",
      "Epoch: 2, Batch number: 3977, Loss: 28188.841796875\n",
      "Epoch: 2, Batch number: 4077, Loss: 27648.35546875\n",
      "Epoch: 2, Batch number: 4177, Loss: 27889.732421875\n",
      "Epoch: 2, Batch number: 4277, Loss: 27647.677734375\n",
      "Epoch: 2, Batch number: 4377, Loss: 27990.865234375\n",
      "Epoch: 2, Batch number: 4477, Loss: 27776.787109375\n",
      "Epoch: 2, Batch number: 4577, Loss: 28000.578125\n",
      "Epoch: 2, Batch number: 4677, Loss: 28047.46875\n",
      "Epoch: 2, Batch number: 4777, Loss: 27967.93359375\n",
      "Epoch: 2, Batch number: 4877, Loss: 27951.9765625\n",
      "Epoch: 2, Batch number: 4977, Loss: 27272.58984375\n",
      "Epoch: 2, Batch number: 5077, Loss: 27256.072265625\n",
      "Epoch: 2, Batch number: 5177, Loss: 27446.0390625\n",
      "Epoch: 2, Batch number: 5277, Loss: 27678.890625\n",
      "Epoch: 2, Batch number: 5377, Loss: 28179.67578125\n",
      "Epoch: 2, Batch number: 5477, Loss: 27677.69921875\n",
      "Epoch: 2, Batch number: 5577, Loss: 27938.126953125\n",
      "Epoch: 2, Batch number: 5677, Loss: 27858.142578125\n",
      "Epoch: 2, Batch number: 5777, Loss: 27921.408203125\n",
      "Epoch: 2, Batch number: 5877, Loss: 28052.14453125\n",
      "Epoch: 2, Batch number: 5977, Loss: 27687.49609375\n",
      "Epoch: 2, Batch number: 6077, Loss: 28050.88671875\n",
      "Epoch: 2, Batch number: 6177, Loss: 27964.650390625\n",
      "Epoch: 2, Batch number: 6277, Loss: 27961.349609375\n",
      "Epoch: 2, Batch number: 6377, Loss: 27632.654296875\n",
      "Epoch: 2, Batch number: 6477, Loss: 28030.763671875\n",
      "Epoch: 2, Batch number: 6577, Loss: 27749.642578125\n",
      "Epoch: 2, Batch number: 6677, Loss: 28006.55078125\n",
      "Epoch: 2, Batch number: 6777, Loss: 27689.279296875\n",
      "Epoch: 2, Batch number: 6877, Loss: 27868.71484375\n",
      "Epoch: 2, Batch number: 6977, Loss: 27841.875\n",
      "Epoch: 2, Batch number: 7077, Loss: 27438.765625\n",
      "Epoch: 2, Batch number: 7177, Loss: 27753.1328125\n",
      "Epoch: 2, Batch number: 7277, Loss: 27873.201171875\n",
      "Epoch: 2, Batch number: 7377, Loss: 27869.958984375\n",
      "Epoch: 2, Batch number: 7477, Loss: 27886.990234375\n",
      "Epoch: 2, Batch number: 7577, Loss: 28059.23046875\n",
      "Epoch: 2, Batch number: 7677, Loss: 27843.533203125\n",
      "Epoch: 2, Batch number: 7777, Loss: 28123.4765625\n",
      "Epoch: 2, Batch number: 7877, Loss: 27923.4375\n",
      "Epoch: 2, Batch number: 7977, Loss: 27846.7421875\n",
      "Epoch: 2, Batch number: 8077, Loss: 27788.93359375\n",
      "Epoch: 2, Batch number: 8177, Loss: 27853.46875\n",
      "Epoch: 2, Batch number: 8277, Loss: 27604.439453125\n",
      "Epoch: 2, Batch number: 8377, Loss: 27487.251953125\n",
      "Epoch: 2, Batch number: 8477, Loss: 27893.822265625\n",
      "Epoch: 2, Batch number: 8577, Loss: 27655.564453125\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#corpus = GetTrainCorpus('./promptsl40.train')\n",
    "cutoff_freq = 3\n",
    "window_size_list = [1, 2, 3, 4]\n",
    "batch_size = 512\n",
    "\n",
    "state_dict = None\n",
    "device = 'cuda:1'\n",
    "paralelize = False\n",
    "embedding_dim_list = [50, 100, 200, 300]\n",
    "\n",
    "sk_trainers = []\n",
    "for window_size in window_size_list:\n",
    "    embedding_dim_trainers = []\n",
    "    for embedding_dim in embedding_dim_list:\n",
    "        sk_trainer = SkipGramTrainer(corpus, cutoff_freq, window_size, batch_size)\n",
    "        sk_trainer.InitModel(state_dict=state_dict, device=device, paralelize=paralelize, embedding_dim=embedding_dim)\n",
    "        embedding_dim_trainers.append(sk_trainer)\n",
    "    sk_trainers.append(embedding_dim_trainers)\n",
    "\n",
    "algorithm = 'Adam'\n",
    "epochs = 2\n",
    "sample_loss_every = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "for trainer_list in sk_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)\n",
    "        \n",
    "import pickle\n",
    "\n",
    "with open('sk_trainers_wiki.bin', 'wb') as sk_trainers_file:\n",
    "    pickle.dump(sk_trainers, sk_trainers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"900\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4c12920358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (9., 9.)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for trainer_list in sk_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        ax.plot(trainer.loss_history['iter'],trainer.loss_history['loss'],\n",
    "                label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = './promptsl40.test'\n",
    "for embedding_dim_list in sk_trainers:\n",
    "    for trainer in embedding_dim_list:\n",
    "        output_file = '/home/lestien/final/lm/lm_word_vectors/sk_wiki_ws_{}_ed_{}'.format(trainer.window_size,trainer.embedding_dim)\n",
    "        GetARPAFile(trainer, test_filename, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver!!\n",
    "corpus = GetTrainCorpus('./promptsl40.train')\n",
    "with open('wiki', 'r') as wikifile:\n",
    "    corpus = [corpus[0] + wikifile.read().split(' ')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
