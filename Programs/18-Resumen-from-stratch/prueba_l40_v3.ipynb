{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('trainers1.bin', 'wb') as trainers_file:\n",
    "#     pickle.dump(trainers1, trainers_file)\n",
    "\n",
    "# with open('trainers2.bin', 'wb') as trainers_file:\n",
    "#     pickle.dump(trainers2, trainers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_corpus = Corpus.from_text_files(['./wiki-corpus/{}_cleaned.txt'.format(i) for i in range(1,1)] \\\n",
    "#                                       + ['./promptsl40_train_cleaned.txt'], r'[ \\s]+', 3)\n",
    "# # print(train_corpus.vocabulary)\n",
    "# # print(train_corpus)\n",
    "# # train_corpus.vocabulary\n",
    "\n",
    "# model = 'SkipGram'\n",
    "# window_size_list = [2,3,4,5]\n",
    "# embedding_dim_list = [50,100,200,300]\n",
    "# batch_size = 512\n",
    "# device = 'cuda:1'\n",
    "\n",
    "# trainers1 = []\n",
    "# for window_size in window_size_list:\n",
    "#     for embedding_dim in embedding_dim_list:\n",
    "#         trainer =  Word2VecTrainer(model, train_corpus, window_size, embedding_dim, batch_size, device)\n",
    "#         trainers1.append(trainer)\n",
    "\n",
    "# algorithm = 'Adam'\n",
    "# epochs = 100\n",
    "# sample_loss_every = 100\n",
    "# learning_rate = 5e-4\n",
    "\n",
    "# for trainer in trainers1:\n",
    "#     trainer.Train(algorithm, epochs, sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# for trainer in trainers1:\n",
    "#     trainer.plot_loss_history(ax=ax,label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_corpus = Corpus.from_text_files(['./wiki-corpus/{}_cleaned.txt'.format(i) for i in range(1,2)] \\\n",
    "#                                       + ['./promptsl40_train_cleaned.txt'], r'[ \\s]+', 3)\n",
    "# # print(train_corpus.vocabulary)\n",
    "# # print(train_corpus)\n",
    "# # train_corpus.vocabulary\n",
    "\n",
    "# model = 'SkipGram'\n",
    "# window_size_list = [2,3,4,5]\n",
    "# embedding_dim_list = [50,100,200,300]\n",
    "# batch_size = 512\n",
    "# device = 'cuda:1'\n",
    "\n",
    "# trainers2 = []\n",
    "# for window_size in window_size_list:\n",
    "#     for embedding_dim in embedding_dim_list:\n",
    "#         trainer =  Word2VecTrainer(model, train_corpus, window_size, embedding_dim, batch_size, device)\n",
    "#         trainers2.append(trainer)\n",
    "\n",
    "# algorithm = 'Adam'\n",
    "# epochs = 3\n",
    "# sample_loss_every = 100\n",
    "# learning_rate = 5e-4\n",
    "\n",
    "# for trainer in trainers2:\n",
    "#     trainer.Train(algorithm, epochs, sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# for trainer in trainers2:\n",
    "#     trainer.plot_loss_history(ax=ax,label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = Corpus.from_text_files(['./wiki-corpus/{}_cleaned.txt'.format(i) for i in range(1,3)] \\\n",
    "                                      + ['./promptsl40_train_cleaned.txt'], r'[ \\s]+', 3)\n",
    "# print(train_corpus.vocabulary)\n",
    "# print(train_corpus)\n",
    "# train_corpus.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "model = 'SkipGram'\n",
    "window_size_list = [2,3,4,5]\n",
    "embedding_dim_list = [300]\n",
    "batch_size = 512\n",
    "device = 'cuda:1'\n",
    "\n",
    "trainers3 = []\n",
    "for window_size in window_size_list:\n",
    "    for embedding_dim in embedding_dim_list:\n",
    "        print(embedding_dim)\n",
    "        trainer =  Word2VecTrainer(model, train_corpus, window_size, embedding_dim, batch_size, device)\n",
    "        trainers3.append(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 11.28950023651123\n",
      "Epoch: 1, Batch number: 100, Loss: 10.632332801818848\n",
      "Epoch: 1, Batch number: 200, Loss: 10.140185356140137\n",
      "Epoch: 1, Batch number: 300, Loss: 9.969393730163574\n",
      "Epoch: 1, Batch number: 400, Loss: 9.694226264953613\n",
      "Epoch: 1, Batch number: 500, Loss: 9.528447151184082\n",
      "Epoch: 1, Batch number: 600, Loss: 9.301994323730469\n",
      "Epoch: 1, Batch number: 700, Loss: 8.95426082611084\n",
      "Epoch: 1, Batch number: 800, Loss: 9.046049118041992\n",
      "Epoch: 1, Batch number: 900, Loss: 8.755873680114746\n",
      "Epoch: 1, Batch number: 1000, Loss: 8.680800437927246\n",
      "Epoch: 1, Batch number: 1100, Loss: 8.742939949035645\n",
      "Epoch: 1, Batch number: 1200, Loss: 8.356090545654297\n",
      "Epoch: 1, Batch number: 1300, Loss: 8.232892990112305\n",
      "Epoch: 1, Batch number: 1400, Loss: 8.419295310974121\n",
      "Epoch: 1, Batch number: 1500, Loss: 8.175122261047363\n",
      "Epoch: 1, Batch number: 1600, Loss: 8.334644317626953\n",
      "Epoch: 1, Batch number: 1700, Loss: 7.987701892852783\n",
      "Epoch: 1, Batch number: 1800, Loss: 8.081174850463867\n",
      "Epoch: 1, Batch number: 1900, Loss: 7.858127593994141\n",
      "Epoch: 1, Batch number: 2000, Loss: 8.097886085510254\n",
      "Epoch: 1, Batch number: 2100, Loss: 7.91325044631958\n",
      "Epoch: 1, Batch number: 2200, Loss: 7.99496603012085\n",
      "Epoch: 1, Batch number: 2300, Loss: 7.6065850257873535\n",
      "Epoch: 1, Batch number: 2400, Loss: 7.766757488250732\n",
      "Epoch: 1, Batch number: 2500, Loss: 7.881195068359375\n",
      "Epoch: 1, Batch number: 2600, Loss: 7.576796054840088\n",
      "Epoch: 1, Batch number: 2700, Loss: 8.075591087341309\n",
      "Epoch: 1, Batch number: 2800, Loss: 7.745113849639893\n",
      "Epoch: 1, Batch number: 2900, Loss: 7.667795181274414\n",
      "Epoch: 1, Batch number: 3000, Loss: 7.809272766113281\n",
      "Epoch: 1, Batch number: 3100, Loss: 7.773891448974609\n",
      "Epoch: 1, Batch number: 3200, Loss: 7.590245723724365\n",
      "Epoch: 1, Batch number: 3300, Loss: 7.513200283050537\n",
      "Epoch: 1, Batch number: 3400, Loss: 7.785904407501221\n",
      "Epoch: 1, Batch number: 3500, Loss: 7.642146587371826\n",
      "Epoch: 1, Batch number: 3600, Loss: 7.734647274017334\n",
      "Epoch: 1, Batch number: 3700, Loss: 7.614359378814697\n",
      "Epoch: 1, Batch number: 3800, Loss: 7.486147403717041\n",
      "Epoch: 1, Batch number: 3900, Loss: 7.740194320678711\n",
      "Epoch: 1, Batch number: 4000, Loss: 7.545373916625977\n",
      "Epoch: 1, Batch number: 4100, Loss: 7.601768970489502\n",
      "Epoch: 1, Batch number: 4200, Loss: 7.5185465812683105\n",
      "Epoch: 1, Batch number: 4300, Loss: 7.559459209442139\n",
      "Epoch: 1, Batch number: 4400, Loss: 7.515646934509277\n",
      "Epoch: 1, Batch number: 4500, Loss: 7.458250999450684\n",
      "Epoch: 1, Batch number: 4600, Loss: 7.618681907653809\n",
      "Epoch: 1, Batch number: 4700, Loss: 7.499845504760742\n",
      "Epoch: 1, Batch number: 4800, Loss: 7.238733291625977\n",
      "Epoch: 1, Batch number: 4900, Loss: 7.412636756896973\n",
      "Epoch: 1, Batch number: 5000, Loss: 7.3111653327941895\n",
      "Epoch: 1, Batch number: 5100, Loss: 7.420143127441406\n",
      "Epoch: 1, Batch number: 5200, Loss: 7.4169745445251465\n",
      "Epoch: 1, Batch number: 5300, Loss: 7.204478740692139\n",
      "Epoch: 1, Batch number: 5400, Loss: 7.321381568908691\n",
      "Epoch: 1, Batch number: 5500, Loss: 7.600586891174316\n",
      "Epoch: 1, Batch number: 5600, Loss: 7.537430286407471\n",
      "Epoch: 1, Batch number: 5700, Loss: 7.3225483894348145\n",
      "Epoch: 1, Batch number: 5800, Loss: 7.299911022186279\n",
      "Epoch: 1, Batch number: 5900, Loss: 7.339564323425293\n",
      "Epoch: 1, Batch number: 6000, Loss: 7.232970714569092\n",
      "Epoch: 1, Batch number: 6100, Loss: 7.457671165466309\n",
      "Epoch: 1, Batch number: 6200, Loss: 7.416043281555176\n",
      "Epoch: 1, Batch number: 6300, Loss: 7.58180046081543\n",
      "Epoch: 1, Batch number: 6400, Loss: 7.30947732925415\n",
      "Epoch: 1, Batch number: 6500, Loss: 7.196353435516357\n",
      "Epoch: 1, Batch number: 6600, Loss: 7.23087739944458\n",
      "Epoch: 1, Batch number: 6700, Loss: 7.16262674331665\n",
      "Epoch: 1, Batch number: 6800, Loss: 7.175379276275635\n",
      "Epoch: 1, Batch number: 6900, Loss: 7.166141986846924\n",
      "Epoch: 1, Batch number: 7000, Loss: 7.185338497161865\n",
      "Epoch: 1, Batch number: 7100, Loss: 7.0831451416015625\n",
      "Epoch: 1, Batch number: 7200, Loss: 7.2042622566223145\n",
      "Epoch: 1, Batch number: 7300, Loss: 7.302741527557373\n",
      "Epoch: 1, Batch number: 7400, Loss: 7.451459884643555\n",
      "Epoch: 1, Batch number: 7500, Loss: 7.312943935394287\n",
      "Epoch: 1, Batch number: 7600, Loss: 7.018996715545654\n",
      "Epoch: 1, Batch number: 7700, Loss: 7.070863246917725\n",
      "Epoch: 1, Batch number: 7800, Loss: 7.340492248535156\n",
      "Epoch: 1, Batch number: 7900, Loss: 7.291995525360107\n",
      "Epoch: 1, Batch number: 8000, Loss: 7.099544048309326\n",
      "Epoch: 1, Batch number: 8100, Loss: 7.433532238006592\n",
      "Epoch: 1, Batch number: 8200, Loss: 6.987728595733643\n",
      "Epoch: 1, Batch number: 8300, Loss: 7.201381206512451\n",
      "Epoch: 1, Batch number: 8400, Loss: 7.372385501861572\n",
      "Epoch: 1, Batch number: 8500, Loss: 7.44508695602417\n",
      "Epoch: 1, Batch number: 8600, Loss: 7.460346221923828\n",
      "Epoch: 1, Batch number: 8700, Loss: 7.051301956176758\n",
      "Epoch: 1, Batch number: 8800, Loss: 7.205737590789795\n",
      "Epoch: 1, Batch number: 8900, Loss: 7.117369174957275\n",
      "Epoch: 1, Batch number: 9000, Loss: 6.86243200302124\n",
      "Epoch: 1, Batch number: 9100, Loss: 7.45538330078125\n",
      "Epoch: 1, Batch number: 9200, Loss: 7.02405309677124\n",
      "Epoch: 1, Batch number: 9300, Loss: 7.367507457733154\n",
      "Epoch: 1, Batch number: 9400, Loss: 7.036123275756836\n",
      "Epoch: 1, Batch number: 9500, Loss: 7.431203365325928\n",
      "Epoch: 1, Batch number: 9600, Loss: 7.260672092437744\n",
      "Epoch: 1, Batch number: 9700, Loss: 7.011229515075684\n",
      "Epoch: 1, Batch number: 9800, Loss: 7.282417297363281\n",
      "Epoch: 1, Batch number: 9900, Loss: 7.2465291023254395\n",
      "Epoch: 1, Batch number: 10000, Loss: 7.016703128814697\n",
      "Epoch: 1, Batch number: 10100, Loss: 7.301002502441406\n",
      "Epoch: 1, Batch number: 10200, Loss: 6.9488301277160645\n",
      "Epoch: 1, Batch number: 10300, Loss: 7.180734634399414\n",
      "Epoch: 1, Batch number: 10400, Loss: 7.392534255981445\n",
      "Epoch: 1, Batch number: 10500, Loss: 7.297214984893799\n",
      "Epoch: 1, Batch number: 10600, Loss: 7.281781196594238\n",
      "Epoch: 1, Batch number: 10700, Loss: 7.128006935119629\n",
      "Epoch: 1, Batch number: 10800, Loss: 7.124159812927246\n",
      "Epoch: 1, Batch number: 10900, Loss: 7.238468170166016\n",
      "Epoch: 1, Batch number: 11000, Loss: 7.34224271774292\n",
      "Epoch: 1, Batch number: 11100, Loss: 6.904420852661133\n",
      "Epoch: 1, Batch number: 11200, Loss: 7.224882125854492\n",
      "Epoch: 1, Batch number: 11300, Loss: 7.005713939666748\n",
      "Epoch: 1, Batch number: 11400, Loss: 7.157195568084717\n",
      "Epoch: 1, Batch number: 11500, Loss: 7.089545249938965\n",
      "Epoch: 1, Batch number: 11600, Loss: 7.076045036315918\n",
      "Epoch: 1, Batch number: 11700, Loss: 7.344641208648682\n",
      "Epoch: 1, Batch number: 11800, Loss: 6.98631477355957\n",
      "Epoch: 1, Batch number: 11900, Loss: 6.955104827880859\n",
      "Epoch: 1, Batch number: 12000, Loss: 7.168493270874023\n",
      "Epoch: 1, Batch number: 12100, Loss: 6.933007717132568\n",
      "Epoch: 1, Batch number: 12200, Loss: 7.129646301269531\n",
      "Epoch: 1, Batch number: 12300, Loss: 7.213367462158203\n",
      "Epoch: 1, Batch number: 12400, Loss: 7.127621650695801\n",
      "Epoch: 1, Batch number: 12500, Loss: 6.921807289123535\n",
      "Epoch: 1, Batch number: 12600, Loss: 6.655428409576416\n",
      "Epoch: 1, Batch number: 12700, Loss: 6.952238082885742\n",
      "Epoch: 1, Batch number: 12800, Loss: 7.294378280639648\n",
      "Epoch: 1, Batch number: 12900, Loss: 6.966775894165039\n",
      "Epoch: 1, Batch number: 13000, Loss: 7.327147483825684\n",
      "Epoch: 1, Batch number: 13100, Loss: 6.923483371734619\n",
      "Epoch: 1, Batch number: 13200, Loss: 7.16052770614624\n",
      "Epoch: 1, Batch number: 13300, Loss: 6.916375637054443\n",
      "Epoch: 1, Batch number: 13400, Loss: 6.798741817474365\n",
      "Epoch: 1, Batch number: 13500, Loss: 7.023501396179199\n",
      "Epoch: 1, Batch number: 13600, Loss: 7.066722393035889\n",
      "Epoch: 1, Batch number: 13700, Loss: 7.100318908691406\n",
      "Epoch: 1, Batch number: 13800, Loss: 7.342308044433594\n",
      "Epoch: 1, Batch number: 13900, Loss: 7.3016357421875\n",
      "Epoch: 1, Batch number: 14000, Loss: 7.052091121673584\n",
      "Epoch: 1, Batch number: 14100, Loss: 7.046751976013184\n",
      "Epoch: 1, Batch number: 14200, Loss: 7.20729398727417\n",
      "Epoch: 1, Batch number: 14300, Loss: 7.077306747436523\n",
      "Epoch: 1, Batch number: 14400, Loss: 6.8770365715026855\n",
      "Epoch: 1, Batch number: 14500, Loss: 7.129720687866211\n",
      "Epoch: 1, Batch number: 14600, Loss: 6.946852207183838\n",
      "Epoch: 1, Batch number: 14700, Loss: 7.246610641479492\n",
      "Epoch: 1, Batch number: 14800, Loss: 7.110480308532715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 14900, Loss: 6.852187156677246\n",
      "Epoch: 1, Batch number: 15000, Loss: 6.969915390014648\n",
      "Epoch: 1, Batch number: 15100, Loss: 7.087820053100586\n",
      "Epoch: 1, Batch number: 15200, Loss: 6.827408790588379\n",
      "Epoch: 1, Batch number: 15300, Loss: 6.88826322555542\n",
      "Epoch: 1, Batch number: 15400, Loss: 6.944972038269043\n",
      "Epoch: 1, Batch number: 15500, Loss: 7.354339122772217\n",
      "Epoch: 1, Batch number: 15600, Loss: 7.009792327880859\n",
      "Epoch: 1, Batch number: 15700, Loss: 6.96963357925415\n",
      "Epoch: 1, Batch number: 15800, Loss: 6.954014301300049\n",
      "Epoch: 1, Batch number: 15900, Loss: 7.232941150665283\n",
      "Epoch: 1, Batch number: 16000, Loss: 7.174981594085693\n",
      "Epoch: 1, Batch number: 16100, Loss: 7.179012298583984\n",
      "Epoch: 1, Batch number: 16200, Loss: 7.284945487976074\n",
      "Epoch: 1, Batch number: 16300, Loss: 6.967737197875977\n",
      "Epoch: 1, Batch number: 16400, Loss: 7.0671305656433105\n",
      "Epoch: 1, Batch number: 16500, Loss: 7.127837181091309\n",
      "Epoch: 1, Batch number: 16600, Loss: 6.5938262939453125\n",
      "Epoch: 1, Batch number: 16700, Loss: 6.906072616577148\n",
      "Epoch: 1, Batch number: 16800, Loss: 6.836678981781006\n",
      "Epoch: 1, Batch number: 16900, Loss: 6.896781921386719\n",
      "Epoch: 1, Batch number: 17000, Loss: 7.046898365020752\n",
      "Epoch: 1, Batch number: 17100, Loss: 6.735202312469482\n",
      "Epoch: 1, Batch number: 17200, Loss: 7.011476039886475\n",
      "Epoch: 1, Batch number: 17300, Loss: 6.926113605499268\n",
      "Epoch: 1, Batch number: 17400, Loss: 6.783856391906738\n",
      "Epoch: 1, Batch number: 17500, Loss: 6.837795257568359\n",
      "Epoch: 1, Batch number: 17600, Loss: 7.17216157913208\n",
      "Epoch: 1, Batch number: 17700, Loss: 7.114937782287598\n",
      "Epoch: 1, Batch number: 17800, Loss: 7.066151142120361\n",
      "Epoch: 1, Batch number: 17900, Loss: 7.080827236175537\n",
      "Epoch: 1, Batch number: 18000, Loss: 7.087294101715088\n",
      "Epoch: 1, Batch number: 18100, Loss: 6.932480335235596\n",
      "Epoch: 1, Batch number: 18200, Loss: 6.983059406280518\n",
      "Epoch: 1, Batch number: 18300, Loss: 7.080827713012695\n",
      "Epoch: 1, Batch number: 18400, Loss: 6.924508571624756\n",
      "Epoch: 1, Batch number: 18500, Loss: 7.055428504943848\n",
      "Epoch: 1, Batch number: 18600, Loss: 7.182829856872559\n",
      "Epoch: 1, Batch number: 18700, Loss: 7.318309783935547\n",
      "Epoch: 1, Batch number: 18800, Loss: 6.831390857696533\n",
      "Epoch: 1, Batch number: 18900, Loss: 7.065352439880371\n",
      "Epoch: 1, Batch number: 19000, Loss: 6.803523540496826\n",
      "Epoch: 1, Batch number: 19100, Loss: 6.875960350036621\n",
      "Epoch: 1, Batch number: 19200, Loss: 7.007408618927002\n",
      "Epoch: 1, Batch number: 19300, Loss: 7.1614909172058105\n",
      "Epoch: 1, Batch number: 19400, Loss: 7.135166645050049\n",
      "Epoch: 1, Batch number: 19500, Loss: 7.149517059326172\n",
      "Epoch: 1, Batch number: 19600, Loss: 6.748365879058838\n",
      "Epoch: 1, Batch number: 19700, Loss: 6.897801876068115\n",
      "Epoch: 1, Batch number: 19800, Loss: 6.882232666015625\n",
      "Epoch: 1, Batch number: 19900, Loss: 6.820858478546143\n",
      "Epoch: 1, Batch number: 20000, Loss: 7.167197227478027\n",
      "Epoch: 1, Batch number: 20100, Loss: 6.623079776763916\n",
      "Epoch: 1, Batch number: 20200, Loss: 6.82899284362793\n",
      "Epoch: 1, Batch number: 20300, Loss: 6.896317481994629\n",
      "Epoch: 1, Batch number: 20400, Loss: 7.0828447341918945\n",
      "Epoch: 1, Batch number: 20500, Loss: 6.832846164703369\n",
      "Epoch: 1, Batch number: 20600, Loss: 7.0500030517578125\n",
      "Epoch: 1, Batch number: 20700, Loss: 6.7978668212890625\n",
      "Epoch: 1, Batch number: 20800, Loss: 7.037232875823975\n",
      "Epoch: 1, Batch number: 20900, Loss: 7.076934337615967\n",
      "Epoch: 1, Batch number: 21000, Loss: 6.827731132507324\n",
      "Epoch: 1, Batch number: 21100, Loss: 7.018454074859619\n",
      "Epoch: 1, Batch number: 21200, Loss: 6.96368408203125\n",
      "Epoch: 1, Batch number: 21300, Loss: 6.986527442932129\n",
      "Epoch: 1, Batch number: 21400, Loss: 7.216771602630615\n",
      "Epoch: 1, Batch number: 21500, Loss: 6.78914213180542\n",
      "Epoch: 1, Batch number: 21600, Loss: 6.736339092254639\n",
      "Epoch: 1, Batch number: 21700, Loss: 6.622489929199219\n",
      "Epoch: 1, Batch number: 21800, Loss: 7.0457072257995605\n",
      "Epoch: 1, Batch number: 21900, Loss: 6.9800920486450195\n",
      "Epoch: 1, Batch number: 22000, Loss: 7.138798236846924\n",
      "Epoch: 1, Batch number: 22100, Loss: 7.20529317855835\n",
      "Epoch: 1, Batch number: 22200, Loss: 7.263246536254883\n",
      "Epoch: 1, Batch number: 22300, Loss: 6.8964152336120605\n",
      "Epoch: 1, Batch number: 22400, Loss: 6.850008010864258\n",
      "Epoch: 1, Batch number: 22500, Loss: 7.109104156494141\n",
      "Epoch: 1, Batch number: 22600, Loss: 7.022953033447266\n",
      "Epoch: 1, Batch number: 22700, Loss: 7.012762069702148\n",
      "Epoch: 1, Batch number: 22800, Loss: 7.0466766357421875\n",
      "Epoch: 1, Batch number: 22900, Loss: 6.915831565856934\n",
      "Epoch: 1, Batch number: 23000, Loss: 6.903065204620361\n",
      "Epoch: 1, Batch number: 23100, Loss: 6.831846237182617\n",
      "Epoch: 1, Batch number: 23200, Loss: 6.931718349456787\n",
      "Epoch: 1, Batch number: 23300, Loss: 7.022448539733887\n",
      "Epoch: 1, Batch number: 23400, Loss: 6.796937465667725\n",
      "Epoch: 1, Batch number: 23500, Loss: 6.616663455963135\n",
      "Epoch: 1, Batch number: 23600, Loss: 6.9148173332214355\n",
      "Epoch: 1, Batch number: 23700, Loss: 7.012913703918457\n",
      "Epoch: 1, Batch number: 23800, Loss: 6.841100215911865\n",
      "Epoch: 1, Batch number: 23900, Loss: 6.699167728424072\n",
      "Epoch: 1, Batch number: 24000, Loss: 6.944307327270508\n",
      "Epoch: 1, Batch number: 24100, Loss: 6.586320400238037\n",
      "Epoch: 1, Batch number: 24200, Loss: 7.018045425415039\n",
      "Epoch: 1, Batch number: 24300, Loss: 7.063685894012451\n",
      "Epoch: 1, Batch number: 24400, Loss: 7.03359317779541\n",
      "Epoch: 1, Batch number: 24500, Loss: 6.870223522186279\n",
      "Epoch: 1, Batch number: 24600, Loss: 6.884248733520508\n",
      "Epoch: 1, Batch number: 24700, Loss: 7.180049896240234\n",
      "Epoch: 1, Batch number: 24800, Loss: 6.985278606414795\n",
      "Epoch: 1, Batch number: 24900, Loss: 6.818384647369385\n",
      "Epoch: 1, Batch number: 25000, Loss: 6.917143821716309\n",
      "Epoch: 1, Batch number: 25100, Loss: 6.991950035095215\n",
      "Epoch: 1, Batch number: 25200, Loss: 6.840489387512207\n",
      "Epoch: 1, Batch number: 25300, Loss: 6.857159614562988\n",
      "Epoch: 1, Batch number: 25400, Loss: 6.981610298156738\n",
      "Epoch: 1, Batch number: 25500, Loss: 7.100045680999756\n",
      "Epoch: 1, Batch number: 25600, Loss: 6.790809154510498\n",
      "Epoch: 1, Batch number: 25700, Loss: 6.828031063079834\n",
      "Epoch: 1, Batch number: 25800, Loss: 6.8072285652160645\n",
      "Epoch: 1, Batch number: 25900, Loss: 6.828039646148682\n",
      "Epoch: 1, Batch number: 26000, Loss: 7.181187629699707\n",
      "Epoch: 1, Batch number: 26100, Loss: 6.940057277679443\n",
      "Epoch: 1, Batch number: 26200, Loss: 6.979145526885986\n",
      "Epoch: 1, Batch number: 26300, Loss: 6.953497886657715\n",
      "Epoch: 1, Batch number: 26400, Loss: 6.852633953094482\n",
      "Epoch: 1, Batch number: 26500, Loss: 6.838737487792969\n",
      "Epoch: 1, Batch number: 26600, Loss: 6.6817545890808105\n",
      "Epoch: 1, Batch number: 26700, Loss: 6.648291110992432\n",
      "Epoch: 1, Batch number: 26800, Loss: 7.143487930297852\n",
      "Epoch: 1, Batch number: 26900, Loss: 6.806993007659912\n",
      "Epoch: 1, Batch number: 27000, Loss: 6.756390571594238\n",
      "Epoch: 1, Batch number: 27100, Loss: 7.278161525726318\n",
      "Epoch: 1, Batch number: 27200, Loss: 6.9477152824401855\n",
      "Epoch: 1, Batch number: 27300, Loss: 7.193968296051025\n",
      "Epoch: 1, Batch number: 27400, Loss: 6.859763145446777\n",
      "Epoch: 1, Batch number: 27500, Loss: 6.874398231506348\n",
      "Epoch: 1, Batch number: 27600, Loss: 6.850188255310059\n",
      "Epoch: 1, Batch number: 27700, Loss: 6.841935634613037\n",
      "Epoch: 1, Batch number: 27800, Loss: 6.896722793579102\n",
      "Epoch: 1, Batch number: 27900, Loss: 6.827426910400391\n",
      "Epoch: 1, Batch number: 28000, Loss: 6.874221324920654\n",
      "Epoch: 1, Batch number: 28100, Loss: 6.8420305252075195\n",
      "Epoch: 1, Batch number: 28200, Loss: 7.012246608734131\n",
      "Epoch: 1, Batch number: 28300, Loss: 6.8888397216796875\n",
      "Epoch: 1, Batch number: 28400, Loss: 6.940737247467041\n",
      "Epoch: 1, Batch number: 28500, Loss: 6.7420759201049805\n",
      "Epoch: 1, Batch number: 28600, Loss: 6.868462085723877\n",
      "Epoch: 1, Batch number: 28700, Loss: 6.9174699783325195\n",
      "Epoch: 1, Batch number: 28800, Loss: 7.059449672698975\n",
      "Epoch: 1, Batch number: 28900, Loss: 6.998891830444336\n",
      "Epoch: 1, Batch number: 29000, Loss: 6.694277763366699\n",
      "Epoch: 1, Batch number: 29100, Loss: 7.062828063964844\n",
      "Epoch: 1, Batch number: 29200, Loss: 6.999892711639404\n",
      "Epoch: 1, Batch number: 29300, Loss: 6.608760356903076\n",
      "Epoch: 1, Batch number: 29400, Loss: 6.620278835296631\n",
      "Epoch: 1, Batch number: 29500, Loss: 6.890105247497559\n",
      "Epoch: 1, Batch number: 29600, Loss: 6.880990505218506\n",
      "Epoch: 1, Batch number: 29700, Loss: 6.792245388031006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 29800, Loss: 6.675813674926758\n",
      "Epoch: 1, Batch number: 29900, Loss: 7.0943074226379395\n",
      "Epoch: 1, Batch number: 30000, Loss: 6.999815940856934\n",
      "Epoch: 1, Batch number: 30100, Loss: 6.80131196975708\n",
      "Epoch: 1, Batch number: 30200, Loss: 6.723803520202637\n",
      "Epoch: 1, Batch number: 30300, Loss: 6.759875297546387\n",
      "Epoch: 1, Batch number: 30400, Loss: 6.617346286773682\n",
      "Epoch: 1, Batch number: 30500, Loss: 6.977542400360107\n",
      "Epoch: 1, Batch number: 30600, Loss: 6.69016170501709\n",
      "Epoch: 1, Batch number: 30700, Loss: 6.947352409362793\n",
      "Epoch: 1, Batch number: 30800, Loss: 6.688597679138184\n",
      "Epoch: 1, Batch number: 30900, Loss: 6.708840847015381\n",
      "Epoch: 1, Batch number: 31000, Loss: 6.782525062561035\n",
      "Epoch: 1, Batch number: 31100, Loss: 6.748743534088135\n",
      "Epoch: 1, Batch number: 31200, Loss: 7.134555816650391\n",
      "Epoch: 1, Batch number: 31300, Loss: 7.104257106781006\n",
      "Epoch: 1, Batch number: 31400, Loss: 6.636387348175049\n",
      "Epoch: 1, Batch number: 31500, Loss: 6.994083881378174\n",
      "Epoch: 1, Batch number: 31600, Loss: 7.138286113739014\n",
      "Epoch: 1, Batch number: 31700, Loss: 6.767673969268799\n",
      "Epoch: 1, Batch number: 31800, Loss: 6.782955169677734\n",
      "Epoch: 1, Batch number: 31900, Loss: 6.946146011352539\n",
      "Epoch: 1, Batch number: 32000, Loss: 6.861300945281982\n",
      "Epoch: 1, Batch number: 32100, Loss: 6.925967693328857\n",
      "Epoch: 1, Batch number: 32200, Loss: 7.039394855499268\n",
      "Epoch: 1, Batch number: 32300, Loss: 6.7965312004089355\n",
      "Epoch: 1, Batch number: 32400, Loss: 6.56974983215332\n",
      "Epoch: 1, Batch number: 32500, Loss: 6.926741600036621\n",
      "Epoch: 1, Batch number: 32600, Loss: 6.75303840637207\n",
      "Epoch: 1, Batch number: 32700, Loss: 6.6768317222595215\n",
      "Epoch: 1, Batch number: 32800, Loss: 6.717190742492676\n",
      "Epoch: 1, Batch number: 32900, Loss: 6.689487457275391\n",
      "Epoch: 1, Batch number: 33000, Loss: 6.899412155151367\n",
      "Epoch: 1, Batch number: 33100, Loss: 6.703757286071777\n",
      "Epoch: 1, Batch number: 33200, Loss: 6.797601699829102\n",
      "Epoch: 1, Batch number: 33300, Loss: 7.103375434875488\n",
      "Epoch: 1, Batch number: 33400, Loss: 6.855861663818359\n",
      "Epoch: 1, Batch number: 33500, Loss: 6.878174781799316\n",
      "Epoch: 1, Batch number: 33600, Loss: 6.908384323120117\n",
      "Epoch: 1, Batch number: 33700, Loss: 6.876217842102051\n",
      "Epoch: 1, Batch number: 33800, Loss: 6.886169910430908\n",
      "Epoch: 1, Batch number: 33900, Loss: 6.908004283905029\n",
      "Epoch: 1, Batch number: 34000, Loss: 6.684780597686768\n",
      "Epoch: 1, Batch number: 34100, Loss: 6.8594818115234375\n",
      "Epoch: 1, Batch number: 34200, Loss: 6.798274040222168\n",
      "Epoch: 1, Batch number: 34300, Loss: 6.752532482147217\n",
      "Epoch: 1, Batch number: 34400, Loss: 6.825422763824463\n",
      "Epoch: 1, Batch number: 34500, Loss: 7.301727294921875\n",
      "Epoch: 1, Batch number: 34600, Loss: 6.5751142501831055\n",
      "Epoch: 1, Batch number: 34700, Loss: 6.9762797355651855\n",
      "Epoch: 1, Batch number: 34800, Loss: 6.895744323730469\n",
      "Epoch: 1, Batch number: 34900, Loss: 7.132759094238281\n",
      "Epoch: 1, Batch number: 35000, Loss: 6.760303497314453\n",
      "Epoch: 1, Batch number: 35100, Loss: 6.738962173461914\n",
      "Epoch: 1, Batch number: 35200, Loss: 6.662705421447754\n",
      "Epoch: 1, Batch number: 35300, Loss: 7.151393890380859\n",
      "Epoch: 1, Batch number: 35400, Loss: 6.803150653839111\n",
      "Epoch: 1, Batch number: 35500, Loss: 6.646330833435059\n",
      "Epoch: 1, Batch number: 35600, Loss: 7.026278972625732\n",
      "Epoch: 1, Batch number: 35700, Loss: 6.781942367553711\n",
      "Epoch: 1, Batch number: 35800, Loss: 6.863533973693848\n",
      "Epoch: 1, Batch number: 35900, Loss: 7.042741775512695\n",
      "Epoch: 1, Batch number: 36000, Loss: 7.0244646072387695\n",
      "Epoch: 1, Batch number: 36100, Loss: 7.060910224914551\n",
      "Epoch: 1, Batch number: 36200, Loss: 6.869326114654541\n",
      "Epoch: 1, Batch number: 36300, Loss: 6.703930854797363\n",
      "Epoch: 1, Batch number: 36400, Loss: 6.669886112213135\n",
      "Epoch: 1, Batch number: 36500, Loss: 6.741792678833008\n",
      "Epoch: 1, Batch number: 36600, Loss: 6.929426670074463\n",
      "Epoch: 1, Batch number: 36700, Loss: 6.7297682762146\n",
      "Epoch: 1, Batch number: 36800, Loss: 6.8298845291137695\n",
      "Epoch: 1, Batch number: 36900, Loss: 6.801930904388428\n",
      "Epoch: 1, Batch number: 37000, Loss: 6.703287124633789\n",
      "Epoch: 1, Batch number: 37100, Loss: 6.811068534851074\n",
      "Epoch: 1, Batch number: 37200, Loss: 6.887074947357178\n",
      "Epoch: 1, Batch number: 37300, Loss: 6.653024196624756\n",
      "Epoch: 1, Batch number: 37400, Loss: 7.031504154205322\n",
      "Epoch: 1, Batch number: 37500, Loss: 6.645762920379639\n",
      "Epoch: 1, Batch number: 37600, Loss: 6.673569202423096\n",
      "Epoch: 1, Batch number: 37700, Loss: 6.858902454376221\n",
      "Epoch: 1, Batch number: 37800, Loss: 6.993301868438721\n",
      "Epoch: 1, Batch number: 37900, Loss: 7.070300579071045\n",
      "Epoch: 1, Batch number: 38000, Loss: 6.989138603210449\n",
      "Epoch: 1, Batch number: 38100, Loss: 6.927042007446289\n",
      "Epoch: 1, Batch number: 38200, Loss: 6.805339336395264\n",
      "Epoch: 1, Batch number: 38300, Loss: 6.9121880531311035\n",
      "Epoch: 1, Batch number: 38400, Loss: 6.754189491271973\n",
      "Epoch: 1, Batch number: 38500, Loss: 6.918046474456787\n",
      "Epoch: 1, Batch number: 38600, Loss: 6.874374866485596\n",
      "Epoch: 1, Batch number: 38700, Loss: 6.835283279418945\n",
      "Epoch: 1, Batch number: 38800, Loss: 7.185870170593262\n",
      "Epoch: 1, Batch number: 38900, Loss: 6.719404220581055\n",
      "Epoch: 1, Batch number: 39000, Loss: 6.873727321624756\n",
      "Epoch: 1, Batch number: 39100, Loss: 6.774418830871582\n",
      "Epoch: 1, Batch number: 39200, Loss: 6.950063228607178\n",
      "Epoch: 1, Batch number: 39300, Loss: 7.006531715393066\n",
      "Epoch: 1, Batch number: 39400, Loss: 6.7670722007751465\n",
      "Epoch: 1, Batch number: 39500, Loss: 6.990318298339844\n",
      "Epoch: 1, Batch number: 39600, Loss: 7.258724212646484\n",
      "Epoch: 1, Batch number: 39700, Loss: 6.918743133544922\n",
      "Epoch: 1, Batch number: 39800, Loss: 6.940188884735107\n",
      "Epoch: 1, Batch number: 39900, Loss: 6.722464084625244\n",
      "Epoch: 1, Batch number: 40000, Loss: 6.742442607879639\n",
      "Epoch: 1, Batch number: 40100, Loss: 6.759908199310303\n",
      "Epoch: 1, Batch number: 40200, Loss: 6.959201812744141\n",
      "Epoch: 1, Batch number: 40300, Loss: 6.860530376434326\n",
      "Epoch: 1, Batch number: 40400, Loss: 6.708610534667969\n",
      "Epoch: 1, Batch number: 40500, Loss: 6.706882476806641\n",
      "Epoch: 1, Batch number: 40600, Loss: 6.867142677307129\n",
      "Epoch: 1, Batch number: 40700, Loss: 6.89774227142334\n",
      "Epoch: 1, Batch number: 40800, Loss: 7.0416789054870605\n",
      "Epoch: 1, Batch number: 40900, Loss: 7.097243309020996\n",
      "Epoch: 1, Batch number: 41000, Loss: 6.918685436248779\n",
      "Epoch: 1, Batch number: 41100, Loss: 6.832007884979248\n",
      "Epoch: 1, Batch number: 41200, Loss: 7.038725852966309\n",
      "Epoch: 1, Batch number: 41300, Loss: 6.593977928161621\n",
      "Epoch: 1, Batch number: 41400, Loss: 6.741365432739258\n",
      "Epoch: 1, Batch number: 41500, Loss: 6.504574298858643\n",
      "Epoch: 1, Batch number: 41600, Loss: 6.564801216125488\n",
      "Epoch: 1, Batch number: 41700, Loss: 6.577996730804443\n",
      "Epoch: 1, Batch number: 41800, Loss: 6.976567268371582\n",
      "Epoch: 1, Batch number: 41900, Loss: 6.251795291900635\n",
      "Epoch: 1, Batch number: 42000, Loss: 7.078909873962402\n",
      "Epoch: 1, Batch number: 42100, Loss: 6.928150653839111\n",
      "Epoch: 1, Batch number: 42200, Loss: 6.803313732147217\n",
      "Epoch: 1, Batch number: 42300, Loss: 6.7933783531188965\n",
      "Epoch: 1, Batch number: 42400, Loss: 7.109778881072998\n",
      "Epoch: 1, Batch number: 42500, Loss: 6.506953716278076\n",
      "Epoch: 1, Batch number: 42600, Loss: 6.672423362731934\n",
      "Epoch: 1, Batch number: 42700, Loss: 6.723262310028076\n",
      "Epoch: 1, Batch number: 42800, Loss: 6.764677047729492\n",
      "Epoch: 1, Batch number: 42900, Loss: 6.848484992980957\n",
      "Epoch: 1, Batch number: 43000, Loss: 6.891881942749023\n",
      "Epoch: 1, Batch number: 43100, Loss: 6.7985124588012695\n",
      "Epoch: 1, Batch number: 43200, Loss: 6.7572340965271\n",
      "Epoch: 1, Batch number: 43300, Loss: 7.2289252281188965\n",
      "Epoch: 1, Batch number: 43400, Loss: 6.711665630340576\n",
      "Epoch: 1, Batch number: 43500, Loss: 7.0621538162231445\n",
      "Epoch: 1, Batch number: 43600, Loss: 6.952089309692383\n",
      "Epoch: 1, Batch number: 43700, Loss: 6.705505847930908\n",
      "Epoch: 1, Batch number: 43800, Loss: 6.91681432723999\n",
      "Epoch: 1, Batch number: 43900, Loss: 6.877677917480469\n",
      "Epoch: 1, Batch number: 44000, Loss: 6.921078681945801\n",
      "Epoch: 1, Batch number: 44100, Loss: 6.878523349761963\n",
      "Epoch: 1, Batch number: 44200, Loss: 6.789395332336426\n",
      "Epoch: 1, Batch number: 44300, Loss: 7.0720953941345215\n",
      "Epoch: 1, Batch number: 44400, Loss: 6.8253703117370605\n",
      "Epoch: 1, Batch number: 44500, Loss: 7.102173805236816\n",
      "Epoch: 1, Batch number: 44600, Loss: 6.997607231140137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 44700, Loss: 6.834624290466309\n",
      "Epoch: 2, Batch number: 0, Loss: 6.426412582397461\n",
      "Epoch: 2, Batch number: 100, Loss: 6.564809799194336\n",
      "Epoch: 2, Batch number: 200, Loss: 6.871896743774414\n",
      "Epoch: 2, Batch number: 300, Loss: 6.307310581207275\n",
      "Epoch: 2, Batch number: 400, Loss: 6.894947052001953\n",
      "Epoch: 2, Batch number: 500, Loss: 6.781628131866455\n",
      "Epoch: 2, Batch number: 600, Loss: 6.6870598793029785\n",
      "Epoch: 2, Batch number: 700, Loss: 6.71704626083374\n",
      "Epoch: 2, Batch number: 800, Loss: 6.7014479637146\n",
      "Epoch: 2, Batch number: 900, Loss: 6.620658874511719\n",
      "Epoch: 2, Batch number: 1000, Loss: 6.573426723480225\n",
      "Epoch: 2, Batch number: 1100, Loss: 6.861417770385742\n",
      "Epoch: 2, Batch number: 1200, Loss: 6.549686908721924\n",
      "Epoch: 2, Batch number: 1300, Loss: 6.581820964813232\n",
      "Epoch: 2, Batch number: 1400, Loss: 6.617428302764893\n",
      "Epoch: 2, Batch number: 1500, Loss: 6.4422149658203125\n",
      "Epoch: 2, Batch number: 1600, Loss: 6.682975769042969\n",
      "Epoch: 2, Batch number: 1700, Loss: 6.493043899536133\n",
      "Epoch: 2, Batch number: 1800, Loss: 6.712701320648193\n",
      "Epoch: 2, Batch number: 1900, Loss: 6.67461633682251\n",
      "Epoch: 2, Batch number: 2000, Loss: 6.5609965324401855\n",
      "Epoch: 2, Batch number: 2100, Loss: 6.6393232345581055\n",
      "Epoch: 2, Batch number: 2200, Loss: 6.744905471801758\n",
      "Epoch: 2, Batch number: 2300, Loss: 6.950373649597168\n",
      "Epoch: 2, Batch number: 2400, Loss: 6.640048980712891\n",
      "Epoch: 2, Batch number: 2500, Loss: 6.540799140930176\n",
      "Epoch: 2, Batch number: 2600, Loss: 6.958101272583008\n",
      "Epoch: 2, Batch number: 2700, Loss: 6.828233242034912\n",
      "Epoch: 2, Batch number: 2800, Loss: 6.845738887786865\n",
      "Epoch: 2, Batch number: 2900, Loss: 6.559035778045654\n",
      "Epoch: 2, Batch number: 3000, Loss: 6.596607208251953\n",
      "Epoch: 2, Batch number: 3100, Loss: 6.851982116699219\n",
      "Epoch: 2, Batch number: 3200, Loss: 6.604388236999512\n",
      "Epoch: 2, Batch number: 3300, Loss: 6.491096019744873\n",
      "Epoch: 2, Batch number: 3400, Loss: 6.421250820159912\n",
      "Epoch: 2, Batch number: 3500, Loss: 6.635490894317627\n",
      "Epoch: 2, Batch number: 3600, Loss: 6.376430988311768\n",
      "Epoch: 2, Batch number: 3700, Loss: 6.555051803588867\n",
      "Epoch: 2, Batch number: 3800, Loss: 6.577182292938232\n",
      "Epoch: 2, Batch number: 3900, Loss: 6.797292232513428\n",
      "Epoch: 2, Batch number: 4000, Loss: 6.506320476531982\n",
      "Epoch: 2, Batch number: 4100, Loss: 6.8318586349487305\n",
      "Epoch: 2, Batch number: 4200, Loss: 6.678805351257324\n",
      "Epoch: 2, Batch number: 4300, Loss: 6.767781734466553\n",
      "Epoch: 2, Batch number: 4400, Loss: 6.505818843841553\n",
      "Epoch: 2, Batch number: 4500, Loss: 6.469635963439941\n",
      "Epoch: 2, Batch number: 4600, Loss: 6.469206809997559\n",
      "Epoch: 2, Batch number: 4700, Loss: 6.737929344177246\n",
      "Epoch: 2, Batch number: 4800, Loss: 6.589716911315918\n",
      "Epoch: 2, Batch number: 4900, Loss: 6.522478103637695\n",
      "Epoch: 2, Batch number: 5000, Loss: 6.514135360717773\n",
      "Epoch: 2, Batch number: 5100, Loss: 6.878424167633057\n",
      "Epoch: 2, Batch number: 5200, Loss: 6.425081729888916\n",
      "Epoch: 2, Batch number: 5300, Loss: 6.761373996734619\n",
      "Epoch: 2, Batch number: 5400, Loss: 6.510193824768066\n",
      "Epoch: 2, Batch number: 5500, Loss: 6.8120951652526855\n",
      "Epoch: 2, Batch number: 5600, Loss: 6.290020942687988\n",
      "Epoch: 2, Batch number: 5700, Loss: 6.820739269256592\n",
      "Epoch: 2, Batch number: 5800, Loss: 6.6867780685424805\n",
      "Epoch: 2, Batch number: 5900, Loss: 6.749688148498535\n",
      "Epoch: 2, Batch number: 6000, Loss: 6.667593479156494\n",
      "Epoch: 2, Batch number: 6100, Loss: 7.0118231773376465\n",
      "Epoch: 2, Batch number: 6200, Loss: 6.583405017852783\n",
      "Epoch: 2, Batch number: 6300, Loss: 6.873598575592041\n",
      "Epoch: 2, Batch number: 6400, Loss: 6.708096981048584\n",
      "Epoch: 2, Batch number: 6500, Loss: 6.765379428863525\n",
      "Epoch: 2, Batch number: 6600, Loss: 6.729226589202881\n",
      "Epoch: 2, Batch number: 6700, Loss: 6.691725254058838\n",
      "Epoch: 2, Batch number: 6800, Loss: 6.9969587326049805\n",
      "Epoch: 2, Batch number: 6900, Loss: 6.472113132476807\n",
      "Epoch: 2, Batch number: 7000, Loss: 6.61491584777832\n",
      "Epoch: 2, Batch number: 7100, Loss: 6.6931352615356445\n",
      "Epoch: 2, Batch number: 7200, Loss: 6.6432719230651855\n",
      "Epoch: 2, Batch number: 7300, Loss: 6.950545310974121\n",
      "Epoch: 2, Batch number: 7400, Loss: 6.756715297698975\n",
      "Epoch: 2, Batch number: 7500, Loss: 6.603102684020996\n",
      "Epoch: 2, Batch number: 7600, Loss: 6.834582805633545\n",
      "Epoch: 2, Batch number: 7700, Loss: 6.481276512145996\n",
      "Epoch: 2, Batch number: 7800, Loss: 6.748410701751709\n",
      "Epoch: 2, Batch number: 7900, Loss: 6.817136287689209\n",
      "Epoch: 2, Batch number: 8000, Loss: 6.525675296783447\n",
      "Epoch: 2, Batch number: 8100, Loss: 6.400538921356201\n",
      "Epoch: 2, Batch number: 8200, Loss: 6.6812663078308105\n",
      "Epoch: 2, Batch number: 8300, Loss: 6.7488861083984375\n",
      "Epoch: 2, Batch number: 8400, Loss: 6.514225006103516\n",
      "Epoch: 2, Batch number: 8500, Loss: 6.511841297149658\n",
      "Epoch: 2, Batch number: 8600, Loss: 6.470902442932129\n",
      "Epoch: 2, Batch number: 8700, Loss: 7.017193794250488\n",
      "Epoch: 2, Batch number: 8800, Loss: 6.577500820159912\n",
      "Epoch: 2, Batch number: 8900, Loss: 6.684524059295654\n",
      "Epoch: 2, Batch number: 9000, Loss: 6.710030555725098\n",
      "Epoch: 2, Batch number: 9100, Loss: 6.687900543212891\n",
      "Epoch: 2, Batch number: 9200, Loss: 6.717170715332031\n",
      "Epoch: 2, Batch number: 9300, Loss: 6.711806297302246\n",
      "Epoch: 2, Batch number: 9400, Loss: 6.597741603851318\n",
      "Epoch: 2, Batch number: 9500, Loss: 6.522359371185303\n",
      "Epoch: 2, Batch number: 9600, Loss: 6.5792012214660645\n",
      "Epoch: 2, Batch number: 9700, Loss: 6.684596538543701\n",
      "Epoch: 2, Batch number: 9800, Loss: 6.643219947814941\n",
      "Epoch: 2, Batch number: 9900, Loss: 6.549182891845703\n",
      "Epoch: 2, Batch number: 10000, Loss: 6.636496543884277\n",
      "Epoch: 2, Batch number: 10100, Loss: 6.651782989501953\n",
      "Epoch: 2, Batch number: 10200, Loss: 6.62357234954834\n",
      "Epoch: 2, Batch number: 10300, Loss: 6.6910905838012695\n",
      "Epoch: 2, Batch number: 10400, Loss: 6.882253170013428\n",
      "Epoch: 2, Batch number: 10500, Loss: 6.492337703704834\n",
      "Epoch: 2, Batch number: 10600, Loss: 6.74603271484375\n",
      "Epoch: 2, Batch number: 10700, Loss: 6.813084602355957\n",
      "Epoch: 2, Batch number: 10800, Loss: 6.474313259124756\n",
      "Epoch: 2, Batch number: 10900, Loss: 6.712441921234131\n",
      "Epoch: 2, Batch number: 11000, Loss: 6.820328712463379\n",
      "Epoch: 2, Batch number: 11100, Loss: 6.4850029945373535\n",
      "Epoch: 2, Batch number: 11200, Loss: 6.5990824699401855\n",
      "Epoch: 2, Batch number: 11300, Loss: 6.650082588195801\n",
      "Epoch: 2, Batch number: 11400, Loss: 6.568943023681641\n",
      "Epoch: 2, Batch number: 11500, Loss: 6.729518413543701\n",
      "Epoch: 2, Batch number: 11600, Loss: 6.801278591156006\n",
      "Epoch: 2, Batch number: 11700, Loss: 6.683426856994629\n",
      "Epoch: 2, Batch number: 11800, Loss: 6.6490559577941895\n",
      "Epoch: 2, Batch number: 11900, Loss: 6.794681072235107\n",
      "Epoch: 2, Batch number: 12000, Loss: 6.44608211517334\n",
      "Epoch: 2, Batch number: 12100, Loss: 6.83969259262085\n",
      "Epoch: 2, Batch number: 12200, Loss: 6.805939674377441\n",
      "Epoch: 2, Batch number: 12300, Loss: 6.655073165893555\n",
      "Epoch: 2, Batch number: 12400, Loss: 6.608499526977539\n",
      "Epoch: 2, Batch number: 12500, Loss: 6.607824325561523\n",
      "Epoch: 2, Batch number: 12600, Loss: 6.567421913146973\n",
      "Epoch: 2, Batch number: 12700, Loss: 6.556328773498535\n",
      "Epoch: 2, Batch number: 12800, Loss: 6.845867156982422\n",
      "Epoch: 2, Batch number: 12900, Loss: 6.922587871551514\n",
      "Epoch: 2, Batch number: 13000, Loss: 6.805497169494629\n",
      "Epoch: 2, Batch number: 13100, Loss: 6.918012619018555\n",
      "Epoch: 2, Batch number: 13200, Loss: 6.593830108642578\n",
      "Epoch: 2, Batch number: 13300, Loss: 6.526407718658447\n",
      "Epoch: 2, Batch number: 13400, Loss: 6.654090404510498\n",
      "Epoch: 2, Batch number: 13500, Loss: 6.647807598114014\n",
      "Epoch: 2, Batch number: 13600, Loss: 6.751737594604492\n",
      "Epoch: 2, Batch number: 13700, Loss: 6.858000755310059\n",
      "Epoch: 2, Batch number: 13800, Loss: 6.679329872131348\n",
      "Epoch: 2, Batch number: 13900, Loss: 6.760086536407471\n",
      "Epoch: 2, Batch number: 14000, Loss: 6.703316688537598\n",
      "Epoch: 2, Batch number: 14100, Loss: 6.488675117492676\n",
      "Epoch: 2, Batch number: 14200, Loss: 6.840127944946289\n",
      "Epoch: 2, Batch number: 14300, Loss: 6.412895679473877\n",
      "Epoch: 2, Batch number: 14400, Loss: 6.546723365783691\n",
      "Epoch: 2, Batch number: 14500, Loss: 6.489354610443115\n",
      "Epoch: 2, Batch number: 14600, Loss: 6.741035461425781\n",
      "Epoch: 2, Batch number: 14700, Loss: 6.60871696472168\n",
      "Epoch: 2, Batch number: 14800, Loss: 6.578263282775879\n",
      "Epoch: 2, Batch number: 14900, Loss: 6.657068252563477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 15000, Loss: 6.62533712387085\n",
      "Epoch: 2, Batch number: 15100, Loss: 6.764272689819336\n",
      "Epoch: 2, Batch number: 15200, Loss: 6.633866786956787\n",
      "Epoch: 2, Batch number: 15300, Loss: 6.624240398406982\n",
      "Epoch: 2, Batch number: 15400, Loss: 6.879660129547119\n",
      "Epoch: 2, Batch number: 15500, Loss: 6.63853120803833\n",
      "Epoch: 2, Batch number: 15600, Loss: 6.472717761993408\n",
      "Epoch: 2, Batch number: 15700, Loss: 6.615906238555908\n",
      "Epoch: 2, Batch number: 15800, Loss: 6.766310691833496\n",
      "Epoch: 2, Batch number: 15900, Loss: 6.7013773918151855\n",
      "Epoch: 2, Batch number: 16000, Loss: 6.433745861053467\n",
      "Epoch: 2, Batch number: 16100, Loss: 6.656838893890381\n",
      "Epoch: 2, Batch number: 16200, Loss: 6.709793567657471\n",
      "Epoch: 2, Batch number: 16300, Loss: 6.64070987701416\n",
      "Epoch: 2, Batch number: 16400, Loss: 6.752035140991211\n",
      "Epoch: 2, Batch number: 16500, Loss: 6.67489767074585\n",
      "Epoch: 2, Batch number: 16600, Loss: 6.757265090942383\n",
      "Epoch: 2, Batch number: 16700, Loss: 6.591881275177002\n",
      "Epoch: 2, Batch number: 16800, Loss: 6.416411876678467\n",
      "Epoch: 2, Batch number: 16900, Loss: 6.61527156829834\n",
      "Epoch: 2, Batch number: 17000, Loss: 6.698220729827881\n",
      "Epoch: 2, Batch number: 17100, Loss: 6.750334739685059\n",
      "Epoch: 2, Batch number: 17200, Loss: 6.77314567565918\n",
      "Epoch: 2, Batch number: 17300, Loss: 6.454410076141357\n",
      "Epoch: 2, Batch number: 17400, Loss: 6.427643775939941\n",
      "Epoch: 2, Batch number: 17500, Loss: 6.460749626159668\n",
      "Epoch: 2, Batch number: 17600, Loss: 6.454495429992676\n",
      "Epoch: 2, Batch number: 17700, Loss: 6.665773868560791\n",
      "Epoch: 2, Batch number: 17800, Loss: 6.805140972137451\n",
      "Epoch: 2, Batch number: 17900, Loss: 6.58131742477417\n",
      "Epoch: 2, Batch number: 18000, Loss: 6.360350608825684\n",
      "Epoch: 2, Batch number: 18100, Loss: 6.404757499694824\n",
      "Epoch: 2, Batch number: 18200, Loss: 6.497023582458496\n",
      "Epoch: 2, Batch number: 18300, Loss: 6.704145908355713\n",
      "Epoch: 2, Batch number: 18400, Loss: 6.809139251708984\n",
      "Epoch: 2, Batch number: 18500, Loss: 6.668429374694824\n",
      "Epoch: 2, Batch number: 18600, Loss: 6.486922264099121\n",
      "Epoch: 2, Batch number: 18700, Loss: 6.544370651245117\n",
      "Epoch: 2, Batch number: 18800, Loss: 6.480268955230713\n",
      "Epoch: 2, Batch number: 18900, Loss: 6.534770965576172\n",
      "Epoch: 2, Batch number: 19000, Loss: 6.917514324188232\n",
      "Epoch: 2, Batch number: 19100, Loss: 6.724420547485352\n",
      "Epoch: 2, Batch number: 19200, Loss: 6.6139726638793945\n",
      "Epoch: 2, Batch number: 19300, Loss: 6.544758319854736\n",
      "Epoch: 2, Batch number: 19400, Loss: 6.943076133728027\n",
      "Epoch: 2, Batch number: 19500, Loss: 6.478899955749512\n",
      "Epoch: 2, Batch number: 19600, Loss: 6.583293914794922\n",
      "Epoch: 2, Batch number: 19700, Loss: 6.5757622718811035\n",
      "Epoch: 2, Batch number: 19800, Loss: 6.538468360900879\n",
      "Epoch: 2, Batch number: 19900, Loss: 6.438015460968018\n",
      "Epoch: 2, Batch number: 20000, Loss: 6.81504487991333\n",
      "Epoch: 2, Batch number: 20100, Loss: 6.647921085357666\n",
      "Epoch: 2, Batch number: 20200, Loss: 6.985864639282227\n",
      "Epoch: 2, Batch number: 20300, Loss: 6.571329116821289\n",
      "Epoch: 2, Batch number: 20400, Loss: 6.5108466148376465\n",
      "Epoch: 2, Batch number: 20500, Loss: 6.858432769775391\n",
      "Epoch: 2, Batch number: 20600, Loss: 6.662066459655762\n",
      "Epoch: 2, Batch number: 20700, Loss: 6.5660223960876465\n",
      "Epoch: 2, Batch number: 20800, Loss: 6.622469425201416\n",
      "Epoch: 2, Batch number: 20900, Loss: 6.749687671661377\n",
      "Epoch: 2, Batch number: 21000, Loss: 6.829281330108643\n",
      "Epoch: 2, Batch number: 21100, Loss: 6.855515003204346\n",
      "Epoch: 2, Batch number: 21200, Loss: 6.481078624725342\n",
      "Epoch: 2, Batch number: 21300, Loss: 6.635124206542969\n",
      "Epoch: 2, Batch number: 21400, Loss: 6.602493762969971\n",
      "Epoch: 2, Batch number: 21500, Loss: 6.798111438751221\n",
      "Epoch: 2, Batch number: 21600, Loss: 6.7754387855529785\n",
      "Epoch: 2, Batch number: 21700, Loss: 6.961094856262207\n",
      "Epoch: 2, Batch number: 21800, Loss: 6.988273620605469\n",
      "Epoch: 2, Batch number: 21900, Loss: 6.650945663452148\n",
      "Epoch: 2, Batch number: 22000, Loss: 6.577403545379639\n",
      "Epoch: 2, Batch number: 22100, Loss: 6.641688346862793\n",
      "Epoch: 2, Batch number: 22200, Loss: 6.539412498474121\n",
      "Epoch: 2, Batch number: 22300, Loss: 6.641314506530762\n",
      "Epoch: 2, Batch number: 22400, Loss: 6.899373531341553\n",
      "Epoch: 2, Batch number: 22500, Loss: 6.521040439605713\n",
      "Epoch: 2, Batch number: 22600, Loss: 6.8638434410095215\n",
      "Epoch: 2, Batch number: 22700, Loss: 6.6091508865356445\n",
      "Epoch: 2, Batch number: 22800, Loss: 6.713334560394287\n",
      "Epoch: 2, Batch number: 22900, Loss: 6.602934837341309\n",
      "Epoch: 2, Batch number: 23000, Loss: 6.718314170837402\n",
      "Epoch: 2, Batch number: 23100, Loss: 6.712924480438232\n",
      "Epoch: 2, Batch number: 23200, Loss: 6.580413818359375\n",
      "Epoch: 2, Batch number: 23300, Loss: 6.571115970611572\n",
      "Epoch: 2, Batch number: 23400, Loss: 6.607327938079834\n",
      "Epoch: 2, Batch number: 23500, Loss: 6.794858455657959\n",
      "Epoch: 2, Batch number: 23600, Loss: 6.6978912353515625\n",
      "Epoch: 2, Batch number: 23700, Loss: 6.922557353973389\n",
      "Epoch: 2, Batch number: 23800, Loss: 6.573983669281006\n",
      "Epoch: 2, Batch number: 23900, Loss: 6.720371246337891\n",
      "Epoch: 2, Batch number: 24000, Loss: 6.487363338470459\n",
      "Epoch: 2, Batch number: 24100, Loss: 6.508277416229248\n",
      "Epoch: 2, Batch number: 24200, Loss: 6.701722145080566\n",
      "Epoch: 2, Batch number: 24300, Loss: 6.297027111053467\n",
      "Epoch: 2, Batch number: 24400, Loss: 6.604369163513184\n",
      "Epoch: 2, Batch number: 24500, Loss: 6.526771545410156\n",
      "Epoch: 2, Batch number: 24600, Loss: 6.514203071594238\n",
      "Epoch: 2, Batch number: 24700, Loss: 6.6861572265625\n",
      "Epoch: 2, Batch number: 24800, Loss: 6.607701301574707\n",
      "Epoch: 2, Batch number: 24900, Loss: 6.348100185394287\n",
      "Epoch: 2, Batch number: 25000, Loss: 6.649176120758057\n",
      "Epoch: 2, Batch number: 25100, Loss: 6.6112236976623535\n",
      "Epoch: 2, Batch number: 25200, Loss: 6.5677642822265625\n",
      "Epoch: 2, Batch number: 25300, Loss: 6.81925106048584\n",
      "Epoch: 2, Batch number: 25400, Loss: 6.790069103240967\n",
      "Epoch: 2, Batch number: 25500, Loss: 6.609970569610596\n",
      "Epoch: 2, Batch number: 25600, Loss: 6.6122965812683105\n",
      "Epoch: 2, Batch number: 25700, Loss: 6.364799499511719\n",
      "Epoch: 2, Batch number: 25800, Loss: 6.971020221710205\n",
      "Epoch: 2, Batch number: 25900, Loss: 6.481721878051758\n",
      "Epoch: 2, Batch number: 26000, Loss: 6.530292987823486\n",
      "Epoch: 2, Batch number: 26100, Loss: 6.414272785186768\n",
      "Epoch: 2, Batch number: 26200, Loss: 6.52570104598999\n",
      "Epoch: 2, Batch number: 26300, Loss: 6.871321201324463\n",
      "Epoch: 2, Batch number: 26400, Loss: 6.5857834815979\n",
      "Epoch: 2, Batch number: 26500, Loss: 6.591588497161865\n",
      "Epoch: 2, Batch number: 26600, Loss: 6.735198974609375\n",
      "Epoch: 2, Batch number: 26700, Loss: 6.5547709465026855\n",
      "Epoch: 2, Batch number: 26800, Loss: 6.835873126983643\n",
      "Epoch: 2, Batch number: 26900, Loss: 6.672431468963623\n",
      "Epoch: 2, Batch number: 27000, Loss: 6.569239139556885\n",
      "Epoch: 2, Batch number: 27100, Loss: 6.917126178741455\n",
      "Epoch: 2, Batch number: 27200, Loss: 6.668372631072998\n",
      "Epoch: 2, Batch number: 27300, Loss: 6.805943965911865\n",
      "Epoch: 2, Batch number: 27400, Loss: 6.661625862121582\n",
      "Epoch: 2, Batch number: 27500, Loss: 6.618948936462402\n",
      "Epoch: 2, Batch number: 27600, Loss: 6.766808986663818\n",
      "Epoch: 2, Batch number: 27700, Loss: 6.652249336242676\n",
      "Epoch: 2, Batch number: 27800, Loss: 6.651960849761963\n",
      "Epoch: 2, Batch number: 27900, Loss: 6.996814727783203\n",
      "Epoch: 2, Batch number: 28000, Loss: 6.687893390655518\n",
      "Epoch: 2, Batch number: 28100, Loss: 6.86433219909668\n",
      "Epoch: 2, Batch number: 28200, Loss: 6.591948986053467\n",
      "Epoch: 2, Batch number: 28300, Loss: 6.8185038566589355\n",
      "Epoch: 2, Batch number: 28400, Loss: 6.523561954498291\n",
      "Epoch: 2, Batch number: 28500, Loss: 6.827890396118164\n",
      "Epoch: 2, Batch number: 28600, Loss: 6.583763599395752\n",
      "Epoch: 2, Batch number: 28700, Loss: 6.53063440322876\n",
      "Epoch: 2, Batch number: 28800, Loss: 6.787686824798584\n",
      "Epoch: 2, Batch number: 28900, Loss: 6.434240818023682\n",
      "Epoch: 2, Batch number: 29000, Loss: 6.935595512390137\n",
      "Epoch: 2, Batch number: 29100, Loss: 6.893198490142822\n",
      "Epoch: 2, Batch number: 29200, Loss: 6.533802509307861\n",
      "Epoch: 2, Batch number: 29300, Loss: 7.0453643798828125\n",
      "Epoch: 2, Batch number: 29400, Loss: 6.600603103637695\n",
      "Epoch: 2, Batch number: 29500, Loss: 6.551372528076172\n",
      "Epoch: 2, Batch number: 29600, Loss: 6.802590370178223\n",
      "Epoch: 2, Batch number: 29700, Loss: 6.872747898101807\n",
      "Epoch: 2, Batch number: 29800, Loss: 6.882227897644043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 29900, Loss: 6.9258294105529785\n",
      "Epoch: 2, Batch number: 30000, Loss: 6.621809482574463\n",
      "Epoch: 2, Batch number: 30100, Loss: 6.387208938598633\n",
      "Epoch: 2, Batch number: 30200, Loss: 6.752285957336426\n",
      "Epoch: 2, Batch number: 30300, Loss: 6.705167770385742\n",
      "Epoch: 2, Batch number: 30400, Loss: 6.646442890167236\n",
      "Epoch: 2, Batch number: 30500, Loss: 6.524409294128418\n",
      "Epoch: 2, Batch number: 30600, Loss: 6.4721550941467285\n",
      "Epoch: 2, Batch number: 30700, Loss: 6.89391565322876\n",
      "Epoch: 2, Batch number: 30800, Loss: 6.511575698852539\n",
      "Epoch: 2, Batch number: 30900, Loss: 6.711012363433838\n",
      "Epoch: 2, Batch number: 31000, Loss: 6.577766418457031\n",
      "Epoch: 2, Batch number: 31100, Loss: 6.690854072570801\n",
      "Epoch: 2, Batch number: 31200, Loss: 6.488370895385742\n",
      "Epoch: 2, Batch number: 31300, Loss: 6.6207685470581055\n",
      "Epoch: 2, Batch number: 31400, Loss: 6.578052043914795\n",
      "Epoch: 2, Batch number: 31500, Loss: 6.758340358734131\n",
      "Epoch: 2, Batch number: 31600, Loss: 6.620129108428955\n",
      "Epoch: 2, Batch number: 31700, Loss: 6.980621337890625\n",
      "Epoch: 2, Batch number: 31800, Loss: 6.439242362976074\n",
      "Epoch: 2, Batch number: 31900, Loss: 6.605607986450195\n",
      "Epoch: 2, Batch number: 32000, Loss: 6.435816287994385\n",
      "Epoch: 2, Batch number: 32100, Loss: 6.583592414855957\n",
      "Epoch: 2, Batch number: 32200, Loss: 6.448043346405029\n",
      "Epoch: 2, Batch number: 32300, Loss: 6.600109100341797\n",
      "Epoch: 2, Batch number: 32400, Loss: 6.5682268142700195\n",
      "Epoch: 2, Batch number: 32500, Loss: 6.716604709625244\n",
      "Epoch: 2, Batch number: 32600, Loss: 6.735304355621338\n",
      "Epoch: 2, Batch number: 32700, Loss: 6.743495941162109\n",
      "Epoch: 2, Batch number: 32800, Loss: 6.554622650146484\n",
      "Epoch: 2, Batch number: 32900, Loss: 6.926950454711914\n",
      "Epoch: 2, Batch number: 33000, Loss: 6.479902267456055\n",
      "Epoch: 2, Batch number: 33100, Loss: 6.633138656616211\n",
      "Epoch: 2, Batch number: 33200, Loss: 6.729239463806152\n",
      "Epoch: 2, Batch number: 33300, Loss: 6.463472366333008\n",
      "Epoch: 2, Batch number: 33400, Loss: 6.522151947021484\n",
      "Epoch: 2, Batch number: 33500, Loss: 6.709108352661133\n",
      "Epoch: 2, Batch number: 33600, Loss: 6.426718711853027\n",
      "Epoch: 2, Batch number: 33700, Loss: 6.672410011291504\n",
      "Epoch: 2, Batch number: 33800, Loss: 6.636945724487305\n",
      "Epoch: 2, Batch number: 33900, Loss: 6.571930408477783\n",
      "Epoch: 2, Batch number: 34000, Loss: 6.711273670196533\n",
      "Epoch: 2, Batch number: 34100, Loss: 6.542513847351074\n",
      "Epoch: 2, Batch number: 34200, Loss: 6.536791801452637\n",
      "Epoch: 2, Batch number: 34300, Loss: 6.573369026184082\n",
      "Epoch: 2, Batch number: 34400, Loss: 6.517292022705078\n",
      "Epoch: 2, Batch number: 34500, Loss: 6.924143314361572\n",
      "Epoch: 2, Batch number: 34600, Loss: 6.841176986694336\n",
      "Epoch: 2, Batch number: 34700, Loss: 6.72141695022583\n",
      "Epoch: 2, Batch number: 34800, Loss: 6.7214813232421875\n",
      "Epoch: 2, Batch number: 34900, Loss: 6.706019878387451\n",
      "Epoch: 2, Batch number: 35000, Loss: 6.62396764755249\n",
      "Epoch: 2, Batch number: 35100, Loss: 6.5251641273498535\n",
      "Epoch: 2, Batch number: 35200, Loss: 6.617164134979248\n",
      "Epoch: 2, Batch number: 35300, Loss: 6.673372745513916\n",
      "Epoch: 2, Batch number: 35400, Loss: 6.571502685546875\n",
      "Epoch: 2, Batch number: 35500, Loss: 6.510034084320068\n",
      "Epoch: 2, Batch number: 35600, Loss: 6.317915439605713\n",
      "Epoch: 2, Batch number: 35700, Loss: 6.465743064880371\n",
      "Epoch: 2, Batch number: 35800, Loss: 6.7104105949401855\n",
      "Epoch: 2, Batch number: 35900, Loss: 6.721728324890137\n",
      "Epoch: 2, Batch number: 36000, Loss: 6.817333221435547\n",
      "Epoch: 2, Batch number: 36100, Loss: 6.616069316864014\n",
      "Epoch: 2, Batch number: 36200, Loss: 6.635165691375732\n",
      "Epoch: 2, Batch number: 36300, Loss: 6.433052062988281\n",
      "Epoch: 2, Batch number: 36400, Loss: 6.5530571937561035\n",
      "Epoch: 2, Batch number: 36500, Loss: 6.678345680236816\n",
      "Epoch: 2, Batch number: 36600, Loss: 6.727485656738281\n",
      "Epoch: 2, Batch number: 36700, Loss: 6.645534038543701\n",
      "Epoch: 2, Batch number: 36800, Loss: 6.861619472503662\n",
      "Epoch: 2, Batch number: 36900, Loss: 6.535573482513428\n",
      "Epoch: 2, Batch number: 37000, Loss: 6.500242233276367\n",
      "Epoch: 2, Batch number: 37100, Loss: 6.680068492889404\n",
      "Epoch: 2, Batch number: 37200, Loss: 6.652144432067871\n",
      "Epoch: 2, Batch number: 37300, Loss: 6.343233108520508\n",
      "Epoch: 2, Batch number: 37400, Loss: 6.6988677978515625\n",
      "Epoch: 2, Batch number: 37500, Loss: 6.3901047706604\n",
      "Epoch: 2, Batch number: 37600, Loss: 6.5990071296691895\n",
      "Epoch: 2, Batch number: 37700, Loss: 6.69459342956543\n",
      "Epoch: 2, Batch number: 37800, Loss: 6.399895191192627\n",
      "Epoch: 2, Batch number: 37900, Loss: 6.665947437286377\n",
      "Epoch: 2, Batch number: 38000, Loss: 6.426419258117676\n",
      "Epoch: 2, Batch number: 38100, Loss: 6.659553527832031\n",
      "Epoch: 2, Batch number: 38200, Loss: 6.641968250274658\n",
      "Epoch: 2, Batch number: 38300, Loss: 6.60869026184082\n",
      "Epoch: 2, Batch number: 38400, Loss: 6.612220764160156\n",
      "Epoch: 2, Batch number: 38500, Loss: 6.6077494621276855\n",
      "Epoch: 2, Batch number: 38600, Loss: 6.713868141174316\n",
      "Epoch: 2, Batch number: 38700, Loss: 6.611036777496338\n",
      "Epoch: 2, Batch number: 38800, Loss: 6.585958957672119\n",
      "Epoch: 2, Batch number: 38900, Loss: 6.435792446136475\n",
      "Epoch: 2, Batch number: 39000, Loss: 6.768268585205078\n",
      "Epoch: 2, Batch number: 39100, Loss: 6.650933265686035\n",
      "Epoch: 2, Batch number: 39200, Loss: 6.614978790283203\n",
      "Epoch: 2, Batch number: 39300, Loss: 6.743312358856201\n",
      "Epoch: 2, Batch number: 39400, Loss: 6.460663795471191\n",
      "Epoch: 2, Batch number: 39500, Loss: 6.802430152893066\n",
      "Epoch: 2, Batch number: 39600, Loss: 6.459673881530762\n",
      "Epoch: 2, Batch number: 39700, Loss: 6.551877021789551\n",
      "Epoch: 2, Batch number: 39800, Loss: 6.932259559631348\n",
      "Epoch: 2, Batch number: 39900, Loss: 6.686450004577637\n",
      "Epoch: 2, Batch number: 40000, Loss: 6.66021203994751\n",
      "Epoch: 2, Batch number: 40100, Loss: 6.6244916915893555\n",
      "Epoch: 2, Batch number: 40200, Loss: 6.4582319259643555\n",
      "Epoch: 2, Batch number: 40300, Loss: 6.7788286209106445\n",
      "Epoch: 2, Batch number: 40400, Loss: 6.736209869384766\n",
      "Epoch: 2, Batch number: 40500, Loss: 6.49343204498291\n",
      "Epoch: 2, Batch number: 40600, Loss: 6.841374397277832\n",
      "Epoch: 2, Batch number: 40700, Loss: 6.646939754486084\n",
      "Epoch: 2, Batch number: 40800, Loss: 6.7582831382751465\n",
      "Epoch: 2, Batch number: 40900, Loss: 6.453733444213867\n",
      "Epoch: 2, Batch number: 41000, Loss: 6.610803604125977\n",
      "Epoch: 2, Batch number: 41100, Loss: 6.3863139152526855\n",
      "Epoch: 2, Batch number: 41200, Loss: 6.549030303955078\n",
      "Epoch: 2, Batch number: 41300, Loss: 6.994068622589111\n",
      "Epoch: 2, Batch number: 41400, Loss: 6.534483909606934\n",
      "Epoch: 2, Batch number: 41500, Loss: 6.628318786621094\n",
      "Epoch: 2, Batch number: 41600, Loss: 6.4921112060546875\n",
      "Epoch: 2, Batch number: 41700, Loss: 6.774655342102051\n",
      "Epoch: 2, Batch number: 41800, Loss: 6.564289569854736\n",
      "Epoch: 2, Batch number: 41900, Loss: 6.569415092468262\n",
      "Epoch: 2, Batch number: 42000, Loss: 6.370640277862549\n",
      "Epoch: 2, Batch number: 42100, Loss: 6.8375959396362305\n",
      "Epoch: 2, Batch number: 42200, Loss: 6.938821792602539\n",
      "Epoch: 2, Batch number: 42300, Loss: 6.500753879547119\n",
      "Epoch: 2, Batch number: 42400, Loss: 6.656477928161621\n",
      "Epoch: 2, Batch number: 42500, Loss: 6.930141448974609\n",
      "Epoch: 2, Batch number: 42600, Loss: 6.651707172393799\n",
      "Epoch: 2, Batch number: 42700, Loss: 6.5868425369262695\n",
      "Epoch: 2, Batch number: 42800, Loss: 6.486191749572754\n",
      "Epoch: 2, Batch number: 42900, Loss: 6.540387153625488\n",
      "Epoch: 2, Batch number: 43000, Loss: 6.433537483215332\n",
      "Epoch: 2, Batch number: 43100, Loss: 6.5187153816223145\n",
      "Epoch: 2, Batch number: 43200, Loss: 6.693053245544434\n",
      "Epoch: 2, Batch number: 43300, Loss: 6.609324932098389\n",
      "Epoch: 2, Batch number: 43400, Loss: 6.722696781158447\n",
      "Epoch: 2, Batch number: 43500, Loss: 6.636664390563965\n",
      "Epoch: 2, Batch number: 43600, Loss: 6.559404373168945\n",
      "Epoch: 2, Batch number: 43700, Loss: 6.58329439163208\n",
      "Epoch: 2, Batch number: 43800, Loss: 6.750702857971191\n",
      "Epoch: 2, Batch number: 43900, Loss: 6.723453044891357\n",
      "Epoch: 2, Batch number: 44000, Loss: 6.573716163635254\n",
      "Epoch: 2, Batch number: 44100, Loss: 6.5472331047058105\n",
      "Epoch: 2, Batch number: 44200, Loss: 6.705060005187988\n",
      "Epoch: 2, Batch number: 44300, Loss: 6.389520645141602\n",
      "Epoch: 2, Batch number: 44400, Loss: 6.46366024017334\n",
      "Epoch: 2, Batch number: 44500, Loss: 6.646855354309082\n",
      "Epoch: 2, Batch number: 44600, Loss: 6.828153133392334\n",
      "Epoch: 2, Batch number: 44700, Loss: 6.710823059082031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 11.282361030578613\n",
      "Epoch: 1, Batch number: 100, Loss: 10.43553638458252\n",
      "Epoch: 1, Batch number: 200, Loss: 10.185223579406738\n",
      "Epoch: 1, Batch number: 300, Loss: 9.707119941711426\n",
      "Epoch: 1, Batch number: 400, Loss: 9.366074562072754\n",
      "Epoch: 1, Batch number: 500, Loss: 9.200397491455078\n",
      "Epoch: 1, Batch number: 600, Loss: 9.242342948913574\n",
      "Epoch: 1, Batch number: 700, Loss: 8.95497989654541\n",
      "Epoch: 1, Batch number: 800, Loss: 8.957825660705566\n",
      "Epoch: 1, Batch number: 900, Loss: 8.667206764221191\n",
      "Epoch: 1, Batch number: 1000, Loss: 8.736563682556152\n",
      "Epoch: 1, Batch number: 1100, Loss: 8.71469497680664\n",
      "Epoch: 1, Batch number: 1200, Loss: 8.48714542388916\n",
      "Epoch: 1, Batch number: 1300, Loss: 8.44318675994873\n",
      "Epoch: 1, Batch number: 1400, Loss: 8.529589653015137\n",
      "Epoch: 1, Batch number: 1500, Loss: 8.247114181518555\n",
      "Epoch: 1, Batch number: 1600, Loss: 8.402544021606445\n",
      "Epoch: 1, Batch number: 1700, Loss: 8.002906799316406\n",
      "Epoch: 1, Batch number: 1800, Loss: 7.894436836242676\n",
      "Epoch: 1, Batch number: 1900, Loss: 8.013158798217773\n",
      "Epoch: 1, Batch number: 2000, Loss: 8.25656795501709\n",
      "Epoch: 1, Batch number: 2100, Loss: 7.915492057800293\n",
      "Epoch: 1, Batch number: 2200, Loss: 7.893569469451904\n",
      "Epoch: 1, Batch number: 2300, Loss: 8.194262504577637\n",
      "Epoch: 1, Batch number: 2400, Loss: 8.048839569091797\n",
      "Epoch: 1, Batch number: 2500, Loss: 7.778324127197266\n",
      "Epoch: 1, Batch number: 2600, Loss: 7.612253665924072\n",
      "Epoch: 1, Batch number: 2700, Loss: 7.664286136627197\n",
      "Epoch: 1, Batch number: 2800, Loss: 7.7673163414001465\n",
      "Epoch: 1, Batch number: 2900, Loss: 8.005706787109375\n",
      "Epoch: 1, Batch number: 3000, Loss: 7.791650772094727\n",
      "Epoch: 1, Batch number: 3100, Loss: 7.710512638092041\n",
      "Epoch: 1, Batch number: 3200, Loss: 7.941218376159668\n",
      "Epoch: 1, Batch number: 3300, Loss: 7.909698009490967\n",
      "Epoch: 1, Batch number: 3400, Loss: 7.742575645446777\n",
      "Epoch: 1, Batch number: 3500, Loss: 7.618964672088623\n",
      "Epoch: 1, Batch number: 3600, Loss: 7.9134721755981445\n",
      "Epoch: 1, Batch number: 3700, Loss: 7.72219181060791\n",
      "Epoch: 1, Batch number: 3800, Loss: 7.638448715209961\n",
      "Epoch: 1, Batch number: 3900, Loss: 7.61326265335083\n",
      "Epoch: 1, Batch number: 4000, Loss: 7.619380950927734\n",
      "Epoch: 1, Batch number: 4100, Loss: 7.62346076965332\n",
      "Epoch: 1, Batch number: 4200, Loss: 7.909026622772217\n",
      "Epoch: 1, Batch number: 4300, Loss: 7.6427154541015625\n",
      "Epoch: 1, Batch number: 4400, Loss: 7.524800777435303\n",
      "Epoch: 1, Batch number: 4500, Loss: 7.560317039489746\n",
      "Epoch: 1, Batch number: 4600, Loss: 7.86355447769165\n",
      "Epoch: 1, Batch number: 4700, Loss: 7.227884769439697\n",
      "Epoch: 1, Batch number: 4800, Loss: 7.545773029327393\n",
      "Epoch: 1, Batch number: 4900, Loss: 7.5071702003479\n",
      "Epoch: 1, Batch number: 5000, Loss: 7.623956680297852\n",
      "Epoch: 1, Batch number: 5100, Loss: 7.531835556030273\n",
      "Epoch: 1, Batch number: 5200, Loss: 7.236187934875488\n",
      "Epoch: 1, Batch number: 5300, Loss: 7.4473557472229\n",
      "Epoch: 1, Batch number: 5400, Loss: 7.495224952697754\n",
      "Epoch: 1, Batch number: 5500, Loss: 7.429932594299316\n",
      "Epoch: 1, Batch number: 5600, Loss: 7.731727600097656\n",
      "Epoch: 1, Batch number: 5700, Loss: 7.417723655700684\n",
      "Epoch: 1, Batch number: 5800, Loss: 7.351251125335693\n",
      "Epoch: 1, Batch number: 5900, Loss: 7.303517818450928\n",
      "Epoch: 1, Batch number: 6000, Loss: 7.697176456451416\n",
      "Epoch: 1, Batch number: 6100, Loss: 7.545951843261719\n",
      "Epoch: 1, Batch number: 6200, Loss: 7.529987812042236\n",
      "Epoch: 1, Batch number: 6300, Loss: 7.770668983459473\n",
      "Epoch: 1, Batch number: 6400, Loss: 7.593539714813232\n",
      "Epoch: 1, Batch number: 6500, Loss: 7.603010654449463\n",
      "Epoch: 1, Batch number: 6600, Loss: 7.501802921295166\n",
      "Epoch: 1, Batch number: 6700, Loss: 7.465667724609375\n",
      "Epoch: 1, Batch number: 6800, Loss: 7.66248893737793\n",
      "Epoch: 1, Batch number: 6900, Loss: 7.6520891189575195\n",
      "Epoch: 1, Batch number: 7000, Loss: 7.292082786560059\n",
      "Epoch: 1, Batch number: 7100, Loss: 7.339291095733643\n",
      "Epoch: 1, Batch number: 7200, Loss: 7.2194952964782715\n",
      "Epoch: 1, Batch number: 7300, Loss: 7.5530171394348145\n",
      "Epoch: 1, Batch number: 7400, Loss: 7.303584575653076\n",
      "Epoch: 1, Batch number: 7500, Loss: 7.258551120758057\n",
      "Epoch: 1, Batch number: 7600, Loss: 7.350036144256592\n",
      "Epoch: 1, Batch number: 7700, Loss: 7.540108680725098\n",
      "Epoch: 1, Batch number: 7800, Loss: 7.620890140533447\n",
      "Epoch: 1, Batch number: 7900, Loss: 7.8467936515808105\n",
      "Epoch: 1, Batch number: 8000, Loss: 7.317188262939453\n",
      "Epoch: 1, Batch number: 8100, Loss: 7.635285377502441\n",
      "Epoch: 1, Batch number: 8200, Loss: 7.05980920791626\n",
      "Epoch: 1, Batch number: 8300, Loss: 7.5477447509765625\n",
      "Epoch: 1, Batch number: 8400, Loss: 7.528545379638672\n",
      "Epoch: 1, Batch number: 8500, Loss: 7.327001094818115\n",
      "Epoch: 1, Batch number: 8600, Loss: 7.163093566894531\n",
      "Epoch: 1, Batch number: 8700, Loss: 7.176666736602783\n",
      "Epoch: 1, Batch number: 8800, Loss: 7.410809516906738\n",
      "Epoch: 1, Batch number: 8900, Loss: 7.106421947479248\n",
      "Epoch: 1, Batch number: 9000, Loss: 7.688697338104248\n",
      "Epoch: 1, Batch number: 9100, Loss: 7.145772933959961\n",
      "Epoch: 1, Batch number: 9200, Loss: 7.427208423614502\n",
      "Epoch: 1, Batch number: 9300, Loss: 7.183586597442627\n",
      "Epoch: 1, Batch number: 9400, Loss: 7.475860118865967\n",
      "Epoch: 1, Batch number: 9500, Loss: 7.241530895233154\n",
      "Epoch: 1, Batch number: 9600, Loss: 7.173120975494385\n",
      "Epoch: 1, Batch number: 9700, Loss: 7.1038360595703125\n",
      "Epoch: 1, Batch number: 9800, Loss: 7.349624156951904\n",
      "Epoch: 1, Batch number: 9900, Loss: 7.252479553222656\n",
      "Epoch: 1, Batch number: 10000, Loss: 7.113009452819824\n",
      "Epoch: 1, Batch number: 10100, Loss: 7.289021968841553\n",
      "Epoch: 1, Batch number: 10200, Loss: 7.359236717224121\n",
      "Epoch: 1, Batch number: 10300, Loss: 7.1596760749816895\n",
      "Epoch: 1, Batch number: 10400, Loss: 7.347633361816406\n",
      "Epoch: 1, Batch number: 10500, Loss: 7.386660099029541\n",
      "Epoch: 1, Batch number: 10600, Loss: 7.439027309417725\n",
      "Epoch: 1, Batch number: 10700, Loss: 7.2034993171691895\n",
      "Epoch: 1, Batch number: 10800, Loss: 7.555011749267578\n",
      "Epoch: 1, Batch number: 10900, Loss: 7.2851433753967285\n",
      "Epoch: 1, Batch number: 11000, Loss: 7.529260635375977\n",
      "Epoch: 1, Batch number: 11100, Loss: 7.4041643142700195\n",
      "Epoch: 1, Batch number: 11200, Loss: 7.450214385986328\n",
      "Epoch: 1, Batch number: 11300, Loss: 7.231273174285889\n",
      "Epoch: 1, Batch number: 11400, Loss: 7.2239484786987305\n",
      "Epoch: 1, Batch number: 11500, Loss: 7.255654335021973\n",
      "Epoch: 1, Batch number: 11600, Loss: 7.243973255157471\n",
      "Epoch: 1, Batch number: 11700, Loss: 7.216818332672119\n",
      "Epoch: 1, Batch number: 11800, Loss: 7.430828094482422\n",
      "Epoch: 1, Batch number: 11900, Loss: 7.266512393951416\n",
      "Epoch: 1, Batch number: 12000, Loss: 7.373019695281982\n",
      "Epoch: 1, Batch number: 12100, Loss: 7.642455101013184\n",
      "Epoch: 1, Batch number: 12200, Loss: 7.439858436584473\n",
      "Epoch: 1, Batch number: 12300, Loss: 6.901012420654297\n",
      "Epoch: 1, Batch number: 12400, Loss: 7.797123432159424\n",
      "Epoch: 1, Batch number: 12500, Loss: 7.203664302825928\n",
      "Epoch: 1, Batch number: 12600, Loss: 7.122300148010254\n",
      "Epoch: 1, Batch number: 12700, Loss: 7.224514484405518\n",
      "Epoch: 1, Batch number: 12800, Loss: 7.3054327964782715\n",
      "Epoch: 1, Batch number: 12900, Loss: 7.291095733642578\n",
      "Epoch: 1, Batch number: 13000, Loss: 7.365713596343994\n",
      "Epoch: 1, Batch number: 13100, Loss: 7.243955612182617\n",
      "Epoch: 1, Batch number: 13200, Loss: 7.01820707321167\n",
      "Epoch: 1, Batch number: 13300, Loss: 7.180972576141357\n",
      "Epoch: 1, Batch number: 13400, Loss: 7.210455417633057\n",
      "Epoch: 1, Batch number: 13500, Loss: 7.225751876831055\n",
      "Epoch: 1, Batch number: 13600, Loss: 7.3034749031066895\n",
      "Epoch: 1, Batch number: 13700, Loss: 7.3869428634643555\n",
      "Epoch: 1, Batch number: 13800, Loss: 7.225590705871582\n",
      "Epoch: 1, Batch number: 13900, Loss: 7.375012397766113\n",
      "Epoch: 1, Batch number: 14000, Loss: 7.44381856918335\n",
      "Epoch: 1, Batch number: 14100, Loss: 7.30238151550293\n",
      "Epoch: 1, Batch number: 14200, Loss: 7.400712966918945\n",
      "Epoch: 1, Batch number: 14300, Loss: 7.389585494995117\n",
      "Epoch: 1, Batch number: 14400, Loss: 7.430682182312012\n",
      "Epoch: 1, Batch number: 14500, Loss: 6.969414710998535\n",
      "Epoch: 1, Batch number: 14600, Loss: 7.279683589935303\n",
      "Epoch: 1, Batch number: 14700, Loss: 7.266677379608154\n",
      "Epoch: 1, Batch number: 14800, Loss: 7.3334245681762695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 14900, Loss: 7.387159824371338\n",
      "Epoch: 1, Batch number: 15000, Loss: 7.038942337036133\n",
      "Epoch: 1, Batch number: 15100, Loss: 7.327005386352539\n",
      "Epoch: 1, Batch number: 15200, Loss: 6.976434230804443\n",
      "Epoch: 1, Batch number: 15300, Loss: 7.298124313354492\n",
      "Epoch: 1, Batch number: 15400, Loss: 7.106997966766357\n",
      "Epoch: 1, Batch number: 15500, Loss: 7.084569931030273\n",
      "Epoch: 1, Batch number: 15600, Loss: 6.932328701019287\n",
      "Epoch: 1, Batch number: 15700, Loss: 7.0018463134765625\n",
      "Epoch: 1, Batch number: 15800, Loss: 7.010477066040039\n",
      "Epoch: 1, Batch number: 15900, Loss: 7.512277126312256\n",
      "Epoch: 1, Batch number: 16000, Loss: 7.174769401550293\n",
      "Epoch: 1, Batch number: 16100, Loss: 7.321500778198242\n",
      "Epoch: 1, Batch number: 16200, Loss: 7.269876480102539\n",
      "Epoch: 1, Batch number: 16300, Loss: 7.178070068359375\n",
      "Epoch: 1, Batch number: 16400, Loss: 7.031686305999756\n",
      "Epoch: 1, Batch number: 16500, Loss: 7.501752853393555\n",
      "Epoch: 1, Batch number: 16600, Loss: 7.55141019821167\n",
      "Epoch: 1, Batch number: 16700, Loss: 7.194787502288818\n",
      "Epoch: 1, Batch number: 16800, Loss: 7.1243438720703125\n",
      "Epoch: 1, Batch number: 16900, Loss: 7.17886209487915\n",
      "Epoch: 1, Batch number: 17000, Loss: 6.878934383392334\n",
      "Epoch: 1, Batch number: 17100, Loss: 7.066952228546143\n",
      "Epoch: 1, Batch number: 17200, Loss: 6.979977607727051\n",
      "Epoch: 1, Batch number: 17300, Loss: 6.993797779083252\n",
      "Epoch: 1, Batch number: 17400, Loss: 6.910467147827148\n",
      "Epoch: 1, Batch number: 17500, Loss: 7.165860652923584\n",
      "Epoch: 1, Batch number: 17600, Loss: 7.080960750579834\n",
      "Epoch: 1, Batch number: 17700, Loss: 7.153947830200195\n",
      "Epoch: 1, Batch number: 17800, Loss: 7.386131286621094\n",
      "Epoch: 1, Batch number: 17900, Loss: 6.9938740730285645\n",
      "Epoch: 1, Batch number: 18000, Loss: 7.283542633056641\n",
      "Epoch: 1, Batch number: 18100, Loss: 7.172230243682861\n",
      "Epoch: 1, Batch number: 18200, Loss: 7.1119065284729\n",
      "Epoch: 1, Batch number: 18300, Loss: 7.273787975311279\n",
      "Epoch: 1, Batch number: 18400, Loss: 7.359533786773682\n",
      "Epoch: 1, Batch number: 18500, Loss: 7.019535541534424\n",
      "Epoch: 1, Batch number: 18600, Loss: 7.255078315734863\n",
      "Epoch: 1, Batch number: 18700, Loss: 6.885129451751709\n",
      "Epoch: 1, Batch number: 18800, Loss: 7.295106410980225\n",
      "Epoch: 1, Batch number: 18900, Loss: 7.089571952819824\n",
      "Epoch: 1, Batch number: 19000, Loss: 7.3395209312438965\n",
      "Epoch: 1, Batch number: 19100, Loss: 7.390651702880859\n",
      "Epoch: 1, Batch number: 19200, Loss: 7.214563369750977\n",
      "Epoch: 1, Batch number: 19300, Loss: 6.98252534866333\n",
      "Epoch: 1, Batch number: 19400, Loss: 7.4486236572265625\n",
      "Epoch: 1, Batch number: 19500, Loss: 7.259873867034912\n",
      "Epoch: 1, Batch number: 19600, Loss: 7.265122413635254\n",
      "Epoch: 1, Batch number: 19700, Loss: 7.111143589019775\n",
      "Epoch: 1, Batch number: 19800, Loss: 7.31986665725708\n",
      "Epoch: 1, Batch number: 19900, Loss: 7.229584693908691\n",
      "Epoch: 1, Batch number: 20000, Loss: 7.393939971923828\n",
      "Epoch: 1, Batch number: 20100, Loss: 7.116666316986084\n",
      "Epoch: 1, Batch number: 20200, Loss: 7.10243558883667\n",
      "Epoch: 1, Batch number: 20300, Loss: 7.070900917053223\n",
      "Epoch: 1, Batch number: 20400, Loss: 7.322683811187744\n",
      "Epoch: 1, Batch number: 20500, Loss: 7.082817554473877\n",
      "Epoch: 1, Batch number: 20600, Loss: 7.208014488220215\n",
      "Epoch: 1, Batch number: 20700, Loss: 7.099217414855957\n",
      "Epoch: 1, Batch number: 20800, Loss: 6.9470601081848145\n",
      "Epoch: 1, Batch number: 20900, Loss: 7.041703224182129\n",
      "Epoch: 1, Batch number: 21000, Loss: 7.028295516967773\n",
      "Epoch: 1, Batch number: 21100, Loss: 7.341635227203369\n",
      "Epoch: 1, Batch number: 21200, Loss: 7.4318928718566895\n",
      "Epoch: 1, Batch number: 21300, Loss: 7.206448554992676\n",
      "Epoch: 1, Batch number: 21400, Loss: 7.195170879364014\n",
      "Epoch: 1, Batch number: 21500, Loss: 6.909459114074707\n",
      "Epoch: 1, Batch number: 21600, Loss: 7.228453636169434\n",
      "Epoch: 1, Batch number: 21700, Loss: 6.896712303161621\n",
      "Epoch: 1, Batch number: 21800, Loss: 7.577056884765625\n",
      "Epoch: 1, Batch number: 21900, Loss: 7.138684272766113\n",
      "Epoch: 1, Batch number: 22000, Loss: 7.161083221435547\n",
      "Epoch: 1, Batch number: 22100, Loss: 7.2206645011901855\n",
      "Epoch: 1, Batch number: 22200, Loss: 7.2679219245910645\n",
      "Epoch: 1, Batch number: 22300, Loss: 7.336916446685791\n",
      "Epoch: 1, Batch number: 22400, Loss: 7.1714959144592285\n",
      "Epoch: 1, Batch number: 22500, Loss: 7.325307369232178\n",
      "Epoch: 1, Batch number: 22600, Loss: 7.132599353790283\n",
      "Epoch: 1, Batch number: 22700, Loss: 7.06779146194458\n",
      "Epoch: 1, Batch number: 22800, Loss: 7.430293083190918\n",
      "Epoch: 1, Batch number: 22900, Loss: 7.0678300857543945\n",
      "Epoch: 1, Batch number: 23000, Loss: 7.148679733276367\n",
      "Epoch: 1, Batch number: 23100, Loss: 7.137388706207275\n",
      "Epoch: 1, Batch number: 23200, Loss: 7.3371148109436035\n",
      "Epoch: 1, Batch number: 23300, Loss: 7.116766452789307\n",
      "Epoch: 1, Batch number: 23400, Loss: 7.1582536697387695\n",
      "Epoch: 1, Batch number: 23500, Loss: 7.257434844970703\n",
      "Epoch: 1, Batch number: 23600, Loss: 7.293376445770264\n",
      "Epoch: 1, Batch number: 23700, Loss: 7.491674900054932\n",
      "Epoch: 1, Batch number: 23800, Loss: 7.1398797035217285\n",
      "Epoch: 1, Batch number: 23900, Loss: 7.04164981842041\n",
      "Epoch: 1, Batch number: 24000, Loss: 7.1745285987854\n",
      "Epoch: 1, Batch number: 24100, Loss: 7.027149200439453\n",
      "Epoch: 1, Batch number: 24200, Loss: 7.424275875091553\n",
      "Epoch: 1, Batch number: 24300, Loss: 6.97713565826416\n",
      "Epoch: 1, Batch number: 24400, Loss: 7.098284721374512\n",
      "Epoch: 1, Batch number: 24500, Loss: 7.226243019104004\n",
      "Epoch: 1, Batch number: 24600, Loss: 7.053335189819336\n",
      "Epoch: 1, Batch number: 24700, Loss: 7.3522047996521\n",
      "Epoch: 1, Batch number: 24800, Loss: 7.231163024902344\n",
      "Epoch: 1, Batch number: 24900, Loss: 7.013975143432617\n",
      "Epoch: 1, Batch number: 25000, Loss: 6.947718143463135\n",
      "Epoch: 1, Batch number: 25100, Loss: 7.394834995269775\n",
      "Epoch: 1, Batch number: 25200, Loss: 7.1952667236328125\n",
      "Epoch: 1, Batch number: 25300, Loss: 6.863305568695068\n",
      "Epoch: 1, Batch number: 25400, Loss: 6.908590316772461\n",
      "Epoch: 1, Batch number: 25500, Loss: 6.911224365234375\n",
      "Epoch: 1, Batch number: 25600, Loss: 7.259783744812012\n",
      "Epoch: 1, Batch number: 25700, Loss: 7.111974716186523\n",
      "Epoch: 1, Batch number: 25800, Loss: 7.0753302574157715\n",
      "Epoch: 1, Batch number: 25900, Loss: 7.245416641235352\n",
      "Epoch: 1, Batch number: 26000, Loss: 7.234091758728027\n",
      "Epoch: 1, Batch number: 26100, Loss: 6.997570991516113\n",
      "Epoch: 1, Batch number: 26200, Loss: 7.017965316772461\n",
      "Epoch: 1, Batch number: 26300, Loss: 7.268135070800781\n",
      "Epoch: 1, Batch number: 26400, Loss: 7.462185382843018\n",
      "Epoch: 1, Batch number: 26500, Loss: 7.283984661102295\n",
      "Epoch: 1, Batch number: 26600, Loss: 7.193119049072266\n",
      "Epoch: 1, Batch number: 26700, Loss: 7.0928850173950195\n",
      "Epoch: 1, Batch number: 26800, Loss: 6.983842849731445\n",
      "Epoch: 1, Batch number: 26900, Loss: 7.380862712860107\n",
      "Epoch: 1, Batch number: 27000, Loss: 7.065685272216797\n",
      "Epoch: 1, Batch number: 27100, Loss: 7.211788177490234\n",
      "Epoch: 1, Batch number: 27200, Loss: 7.0067572593688965\n",
      "Epoch: 1, Batch number: 27300, Loss: 7.145237445831299\n",
      "Epoch: 1, Batch number: 27400, Loss: 7.176084041595459\n",
      "Epoch: 1, Batch number: 27500, Loss: 7.025899410247803\n",
      "Epoch: 1, Batch number: 27600, Loss: 7.147570610046387\n",
      "Epoch: 1, Batch number: 27700, Loss: 7.065207481384277\n",
      "Epoch: 1, Batch number: 27800, Loss: 6.8990936279296875\n",
      "Epoch: 1, Batch number: 27900, Loss: 6.846742153167725\n",
      "Epoch: 1, Batch number: 28000, Loss: 6.9940996170043945\n",
      "Epoch: 1, Batch number: 28100, Loss: 7.059761047363281\n",
      "Epoch: 1, Batch number: 28200, Loss: 6.894061088562012\n",
      "Epoch: 1, Batch number: 28300, Loss: 7.005845069885254\n",
      "Epoch: 1, Batch number: 28400, Loss: 7.327868938446045\n",
      "Epoch: 1, Batch number: 28500, Loss: 7.079348564147949\n",
      "Epoch: 1, Batch number: 28600, Loss: 7.1554274559021\n",
      "Epoch: 1, Batch number: 28700, Loss: 7.191858291625977\n",
      "Epoch: 1, Batch number: 28800, Loss: 7.049798488616943\n",
      "Epoch: 1, Batch number: 28900, Loss: 7.1633172035217285\n",
      "Epoch: 1, Batch number: 29000, Loss: 7.195134162902832\n",
      "Epoch: 1, Batch number: 29100, Loss: 7.131231307983398\n",
      "Epoch: 1, Batch number: 29200, Loss: 7.03269624710083\n",
      "Epoch: 1, Batch number: 29300, Loss: 7.231871604919434\n",
      "Epoch: 1, Batch number: 29400, Loss: 7.043525695800781\n",
      "Epoch: 1, Batch number: 29500, Loss: 7.120933532714844\n",
      "Epoch: 1, Batch number: 29600, Loss: 7.084968566894531\n",
      "Epoch: 1, Batch number: 29700, Loss: 7.104457378387451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 29800, Loss: 7.256627559661865\n",
      "Epoch: 1, Batch number: 29900, Loss: 6.9887824058532715\n",
      "Epoch: 1, Batch number: 30000, Loss: 7.191625595092773\n",
      "Epoch: 1, Batch number: 30100, Loss: 7.172019004821777\n",
      "Epoch: 1, Batch number: 30200, Loss: 7.305650234222412\n",
      "Epoch: 1, Batch number: 30300, Loss: 7.213263511657715\n",
      "Epoch: 1, Batch number: 30400, Loss: 7.024263858795166\n",
      "Epoch: 1, Batch number: 30500, Loss: 7.17823600769043\n",
      "Epoch: 1, Batch number: 30600, Loss: 7.299263954162598\n",
      "Epoch: 1, Batch number: 30700, Loss: 6.778141021728516\n",
      "Epoch: 1, Batch number: 30800, Loss: 7.170833587646484\n",
      "Epoch: 1, Batch number: 30900, Loss: 7.032758712768555\n",
      "Epoch: 1, Batch number: 31000, Loss: 7.44708776473999\n",
      "Epoch: 1, Batch number: 31100, Loss: 7.398467540740967\n",
      "Epoch: 1, Batch number: 31200, Loss: 7.098665714263916\n",
      "Epoch: 1, Batch number: 31300, Loss: 6.8241801261901855\n",
      "Epoch: 1, Batch number: 31400, Loss: 6.950544357299805\n",
      "Epoch: 1, Batch number: 31500, Loss: 7.109339714050293\n",
      "Epoch: 1, Batch number: 31600, Loss: 7.178741455078125\n",
      "Epoch: 1, Batch number: 31700, Loss: 7.2670722007751465\n",
      "Epoch: 1, Batch number: 31800, Loss: 7.286114692687988\n",
      "Epoch: 1, Batch number: 31900, Loss: 7.096014499664307\n",
      "Epoch: 1, Batch number: 32000, Loss: 6.856879711151123\n",
      "Epoch: 1, Batch number: 32100, Loss: 6.9836602210998535\n",
      "Epoch: 1, Batch number: 32200, Loss: 7.051377296447754\n",
      "Epoch: 1, Batch number: 32300, Loss: 7.209420680999756\n",
      "Epoch: 1, Batch number: 32400, Loss: 6.7153849601745605\n",
      "Epoch: 1, Batch number: 32500, Loss: 7.0676116943359375\n",
      "Epoch: 1, Batch number: 32600, Loss: 7.112737655639648\n",
      "Epoch: 1, Batch number: 32700, Loss: 6.988700866699219\n",
      "Epoch: 1, Batch number: 32800, Loss: 7.44510555267334\n",
      "Epoch: 1, Batch number: 32900, Loss: 6.924918174743652\n",
      "Epoch: 1, Batch number: 33000, Loss: 7.22242546081543\n",
      "Epoch: 1, Batch number: 33100, Loss: 7.057295799255371\n",
      "Epoch: 1, Batch number: 33200, Loss: 7.010966777801514\n",
      "Epoch: 1, Batch number: 33300, Loss: 7.226186275482178\n",
      "Epoch: 1, Batch number: 33400, Loss: 7.2810492515563965\n",
      "Epoch: 1, Batch number: 33500, Loss: 7.096122741699219\n",
      "Epoch: 1, Batch number: 33600, Loss: 6.827051162719727\n",
      "Epoch: 1, Batch number: 33700, Loss: 6.943982124328613\n",
      "Epoch: 1, Batch number: 33800, Loss: 7.051025390625\n",
      "Epoch: 1, Batch number: 33900, Loss: 6.869557857513428\n",
      "Epoch: 1, Batch number: 34000, Loss: 7.036001682281494\n",
      "Epoch: 1, Batch number: 34100, Loss: 6.986211776733398\n",
      "Epoch: 1, Batch number: 34200, Loss: 7.2721991539001465\n",
      "Epoch: 1, Batch number: 34300, Loss: 6.92110538482666\n",
      "Epoch: 1, Batch number: 34400, Loss: 6.997210502624512\n",
      "Epoch: 1, Batch number: 34500, Loss: 7.178786277770996\n",
      "Epoch: 1, Batch number: 34600, Loss: 7.033919334411621\n",
      "Epoch: 1, Batch number: 34700, Loss: 7.20754861831665\n",
      "Epoch: 1, Batch number: 34800, Loss: 7.2961249351501465\n",
      "Epoch: 1, Batch number: 34900, Loss: 7.13119649887085\n",
      "Epoch: 1, Batch number: 35000, Loss: 6.9373459815979\n",
      "Epoch: 1, Batch number: 35100, Loss: 7.040923118591309\n",
      "Epoch: 1, Batch number: 35200, Loss: 7.298724174499512\n",
      "Epoch: 1, Batch number: 35300, Loss: 6.872491359710693\n",
      "Epoch: 1, Batch number: 35400, Loss: 6.93610954284668\n",
      "Epoch: 1, Batch number: 35500, Loss: 7.2940778732299805\n",
      "Epoch: 1, Batch number: 35600, Loss: 7.0015130043029785\n",
      "Epoch: 1, Batch number: 35700, Loss: 6.804069995880127\n",
      "Epoch: 1, Batch number: 35800, Loss: 7.314534664154053\n",
      "Epoch: 1, Batch number: 35900, Loss: 6.936049461364746\n",
      "Epoch: 1, Batch number: 36000, Loss: 7.27048921585083\n",
      "Epoch: 1, Batch number: 36100, Loss: 7.070969581604004\n",
      "Epoch: 1, Batch number: 36200, Loss: 7.068058967590332\n",
      "Epoch: 1, Batch number: 36300, Loss: 7.062087535858154\n",
      "Epoch: 1, Batch number: 36400, Loss: 7.020048141479492\n",
      "Epoch: 1, Batch number: 36500, Loss: 6.9816718101501465\n",
      "Epoch: 1, Batch number: 36600, Loss: 7.243373870849609\n",
      "Epoch: 1, Batch number: 36700, Loss: 7.248483180999756\n",
      "Epoch: 1, Batch number: 36800, Loss: 7.125140190124512\n",
      "Epoch: 1, Batch number: 36900, Loss: 7.209501266479492\n",
      "Epoch: 1, Batch number: 37000, Loss: 7.419989585876465\n",
      "Epoch: 1, Batch number: 37100, Loss: 7.007475852966309\n",
      "Epoch: 1, Batch number: 37200, Loss: 6.911799907684326\n",
      "Epoch: 1, Batch number: 37300, Loss: 6.9786295890808105\n",
      "Epoch: 1, Batch number: 37400, Loss: 7.085536956787109\n",
      "Epoch: 1, Batch number: 37500, Loss: 7.128058910369873\n",
      "Epoch: 1, Batch number: 37600, Loss: 7.226762294769287\n",
      "Epoch: 1, Batch number: 37700, Loss: 6.783172130584717\n",
      "Epoch: 1, Batch number: 37800, Loss: 6.7828497886657715\n",
      "Epoch: 1, Batch number: 37900, Loss: 7.157735824584961\n",
      "Epoch: 1, Batch number: 38000, Loss: 7.346775054931641\n",
      "Epoch: 1, Batch number: 38100, Loss: 6.944535255432129\n",
      "Epoch: 1, Batch number: 38200, Loss: 7.036060810089111\n",
      "Epoch: 1, Batch number: 38300, Loss: 7.1424641609191895\n",
      "Epoch: 1, Batch number: 38400, Loss: 6.907834529876709\n",
      "Epoch: 1, Batch number: 38500, Loss: 6.7437052726745605\n",
      "Epoch: 1, Batch number: 38600, Loss: 7.1039652824401855\n",
      "Epoch: 1, Batch number: 38700, Loss: 7.029670238494873\n",
      "Epoch: 1, Batch number: 38800, Loss: 6.943000793457031\n",
      "Epoch: 1, Batch number: 38900, Loss: 7.061267852783203\n",
      "Epoch: 1, Batch number: 39000, Loss: 6.8466105461120605\n",
      "Epoch: 1, Batch number: 39100, Loss: 7.158329963684082\n",
      "Epoch: 1, Batch number: 39200, Loss: 7.223748683929443\n",
      "Epoch: 1, Batch number: 39300, Loss: 7.027044296264648\n",
      "Epoch: 1, Batch number: 39400, Loss: 7.026071548461914\n",
      "Epoch: 1, Batch number: 39500, Loss: 6.936404228210449\n",
      "Epoch: 1, Batch number: 39600, Loss: 6.896759986877441\n",
      "Epoch: 1, Batch number: 39700, Loss: 6.904153347015381\n",
      "Epoch: 1, Batch number: 39800, Loss: 6.769181728363037\n",
      "Epoch: 1, Batch number: 39900, Loss: 7.031463623046875\n",
      "Epoch: 1, Batch number: 40000, Loss: 7.2902750968933105\n",
      "Epoch: 1, Batch number: 40100, Loss: 7.124727725982666\n",
      "Epoch: 1, Batch number: 40200, Loss: 6.805530071258545\n",
      "Epoch: 1, Batch number: 40300, Loss: 7.045596599578857\n",
      "Epoch: 1, Batch number: 40400, Loss: 7.017630577087402\n",
      "Epoch: 1, Batch number: 40500, Loss: 7.0341668128967285\n",
      "Epoch: 1, Batch number: 40600, Loss: 6.836446762084961\n",
      "Epoch: 1, Batch number: 40700, Loss: 7.151889324188232\n",
      "Epoch: 1, Batch number: 40800, Loss: 6.827592849731445\n",
      "Epoch: 1, Batch number: 40900, Loss: 7.12895393371582\n",
      "Epoch: 1, Batch number: 41000, Loss: 7.241672515869141\n",
      "Epoch: 1, Batch number: 41100, Loss: 7.102993965148926\n",
      "Epoch: 1, Batch number: 41200, Loss: 7.208466529846191\n",
      "Epoch: 1, Batch number: 41300, Loss: 7.015997409820557\n",
      "Epoch: 1, Batch number: 41400, Loss: 7.0291266441345215\n",
      "Epoch: 1, Batch number: 41500, Loss: 6.975118160247803\n",
      "Epoch: 1, Batch number: 41600, Loss: 7.020280838012695\n",
      "Epoch: 1, Batch number: 41700, Loss: 7.169232368469238\n",
      "Epoch: 1, Batch number: 41800, Loss: 6.94025993347168\n",
      "Epoch: 1, Batch number: 41900, Loss: 7.117628574371338\n",
      "Epoch: 1, Batch number: 42000, Loss: 7.150601863861084\n",
      "Epoch: 1, Batch number: 42100, Loss: 7.016282081604004\n",
      "Epoch: 1, Batch number: 42200, Loss: 7.103418827056885\n",
      "Epoch: 1, Batch number: 42300, Loss: 7.060617923736572\n",
      "Epoch: 1, Batch number: 42400, Loss: 7.178173542022705\n",
      "Epoch: 1, Batch number: 42500, Loss: 6.82660436630249\n",
      "Epoch: 1, Batch number: 42600, Loss: 7.318166255950928\n",
      "Epoch: 1, Batch number: 42700, Loss: 6.976199150085449\n",
      "Epoch: 1, Batch number: 42800, Loss: 7.016180515289307\n",
      "Epoch: 1, Batch number: 42900, Loss: 7.242860794067383\n",
      "Epoch: 1, Batch number: 43000, Loss: 7.07138729095459\n",
      "Epoch: 1, Batch number: 43100, Loss: 6.936954021453857\n",
      "Epoch: 1, Batch number: 43200, Loss: 6.899637222290039\n",
      "Epoch: 1, Batch number: 43300, Loss: 7.155503273010254\n",
      "Epoch: 1, Batch number: 43400, Loss: 7.343502521514893\n",
      "Epoch: 1, Batch number: 43500, Loss: 7.110941410064697\n",
      "Epoch: 1, Batch number: 43600, Loss: 7.0099873542785645\n",
      "Epoch: 1, Batch number: 43700, Loss: 6.933044910430908\n",
      "Epoch: 1, Batch number: 43800, Loss: 7.360051155090332\n",
      "Epoch: 1, Batch number: 43900, Loss: 7.160120487213135\n",
      "Epoch: 1, Batch number: 44000, Loss: 6.868849277496338\n",
      "Epoch: 1, Batch number: 44100, Loss: 7.073821067810059\n",
      "Epoch: 1, Batch number: 44200, Loss: 6.994266033172607\n",
      "Epoch: 1, Batch number: 44300, Loss: 6.9436235427856445\n",
      "Epoch: 1, Batch number: 44400, Loss: 6.999178409576416\n",
      "Epoch: 1, Batch number: 44500, Loss: 7.118539810180664\n",
      "Epoch: 1, Batch number: 44600, Loss: 6.772612571716309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 44700, Loss: 7.00887393951416\n",
      "Epoch: 1, Batch number: 44800, Loss: 6.884776592254639\n",
      "Epoch: 1, Batch number: 44900, Loss: 7.201094627380371\n",
      "Epoch: 1, Batch number: 45000, Loss: 7.2451581954956055\n",
      "Epoch: 1, Batch number: 45100, Loss: 7.058703422546387\n",
      "Epoch: 1, Batch number: 45200, Loss: 7.023379802703857\n",
      "Epoch: 1, Batch number: 45300, Loss: 7.277583122253418\n",
      "Epoch: 1, Batch number: 45400, Loss: 6.668401718139648\n",
      "Epoch: 1, Batch number: 45500, Loss: 7.1157355308532715\n",
      "Epoch: 1, Batch number: 45600, Loss: 6.980191230773926\n",
      "Epoch: 1, Batch number: 45700, Loss: 6.866124153137207\n",
      "Epoch: 1, Batch number: 45800, Loss: 7.069558143615723\n",
      "Epoch: 1, Batch number: 45900, Loss: 7.136786460876465\n",
      "Epoch: 1, Batch number: 46000, Loss: 7.1848320960998535\n",
      "Epoch: 1, Batch number: 46100, Loss: 6.9667277336120605\n",
      "Epoch: 1, Batch number: 46200, Loss: 6.9800004959106445\n",
      "Epoch: 1, Batch number: 46300, Loss: 7.2212677001953125\n",
      "Epoch: 1, Batch number: 46400, Loss: 6.955974102020264\n",
      "Epoch: 1, Batch number: 46500, Loss: 6.947712421417236\n",
      "Epoch: 1, Batch number: 46600, Loss: 7.083649635314941\n",
      "Epoch: 1, Batch number: 46700, Loss: 6.999693870544434\n",
      "Epoch: 1, Batch number: 46800, Loss: 7.010484218597412\n",
      "Epoch: 1, Batch number: 46900, Loss: 6.9327850341796875\n",
      "Epoch: 1, Batch number: 47000, Loss: 7.053396224975586\n",
      "Epoch: 1, Batch number: 47100, Loss: 7.135508060455322\n",
      "Epoch: 1, Batch number: 47200, Loss: 6.943455696105957\n",
      "Epoch: 1, Batch number: 47300, Loss: 7.050666332244873\n",
      "Epoch: 1, Batch number: 47400, Loss: 7.04941463470459\n",
      "Epoch: 1, Batch number: 47500, Loss: 7.146349906921387\n",
      "Epoch: 1, Batch number: 47600, Loss: 7.024968147277832\n",
      "Epoch: 1, Batch number: 47700, Loss: 7.181384563446045\n",
      "Epoch: 1, Batch number: 47800, Loss: 6.810055732727051\n",
      "Epoch: 1, Batch number: 47900, Loss: 6.978588104248047\n",
      "Epoch: 1, Batch number: 48000, Loss: 7.134628772735596\n",
      "Epoch: 1, Batch number: 48100, Loss: 6.8632283210754395\n",
      "Epoch: 1, Batch number: 48200, Loss: 7.174716949462891\n",
      "Epoch: 1, Batch number: 48300, Loss: 7.298635005950928\n",
      "Epoch: 1, Batch number: 48400, Loss: 6.787502288818359\n",
      "Epoch: 1, Batch number: 48500, Loss: 6.792421340942383\n",
      "Epoch: 1, Batch number: 48600, Loss: 7.02928352355957\n",
      "Epoch: 1, Batch number: 48700, Loss: 6.918111801147461\n",
      "Epoch: 1, Batch number: 48800, Loss: 6.8339128494262695\n",
      "Epoch: 1, Batch number: 48900, Loss: 6.867546558380127\n",
      "Epoch: 1, Batch number: 49000, Loss: 7.130911350250244\n",
      "Epoch: 1, Batch number: 49100, Loss: 6.991976261138916\n",
      "Epoch: 1, Batch number: 49200, Loss: 7.01885461807251\n",
      "Epoch: 1, Batch number: 49300, Loss: 6.886887073516846\n",
      "Epoch: 1, Batch number: 49400, Loss: 7.260403633117676\n",
      "Epoch: 1, Batch number: 49500, Loss: 7.061357498168945\n",
      "Epoch: 1, Batch number: 49600, Loss: 7.110787868499756\n",
      "Epoch: 1, Batch number: 49700, Loss: 7.155584812164307\n",
      "Epoch: 1, Batch number: 49800, Loss: 7.197506904602051\n",
      "Epoch: 1, Batch number: 49900, Loss: 7.2845683097839355\n",
      "Epoch: 1, Batch number: 50000, Loss: 7.034806251525879\n",
      "Epoch: 1, Batch number: 50100, Loss: 6.961730480194092\n",
      "Epoch: 1, Batch number: 50200, Loss: 7.08193826675415\n",
      "Epoch: 1, Batch number: 50300, Loss: 7.185420513153076\n",
      "Epoch: 1, Batch number: 50400, Loss: 7.093210697174072\n",
      "Epoch: 1, Batch number: 50500, Loss: 6.98626708984375\n",
      "Epoch: 1, Batch number: 50600, Loss: 6.932830810546875\n",
      "Epoch: 1, Batch number: 50700, Loss: 7.001302242279053\n",
      "Epoch: 1, Batch number: 50800, Loss: 6.8449602127075195\n",
      "Epoch: 1, Batch number: 50900, Loss: 6.699199676513672\n",
      "Epoch: 1, Batch number: 51000, Loss: 7.004349708557129\n",
      "Epoch: 1, Batch number: 51100, Loss: 7.0048112869262695\n",
      "Epoch: 1, Batch number: 51200, Loss: 6.968692779541016\n",
      "Epoch: 1, Batch number: 51300, Loss: 7.177716255187988\n",
      "Epoch: 1, Batch number: 51400, Loss: 6.755127429962158\n",
      "Epoch: 1, Batch number: 51500, Loss: 6.956303119659424\n",
      "Epoch: 1, Batch number: 51600, Loss: 6.945573806762695\n",
      "Epoch: 1, Batch number: 51700, Loss: 6.9891438484191895\n",
      "Epoch: 1, Batch number: 51800, Loss: 6.889589786529541\n",
      "Epoch: 1, Batch number: 51900, Loss: 7.076596736907959\n",
      "Epoch: 1, Batch number: 52000, Loss: 7.170176982879639\n",
      "Epoch: 1, Batch number: 52100, Loss: 6.835450649261475\n",
      "Epoch: 1, Batch number: 52200, Loss: 6.865915298461914\n",
      "Epoch: 1, Batch number: 52300, Loss: 6.943709373474121\n",
      "Epoch: 1, Batch number: 52400, Loss: 7.2641377449035645\n",
      "Epoch: 1, Batch number: 52500, Loss: 7.309314250946045\n",
      "Epoch: 1, Batch number: 52600, Loss: 7.034196853637695\n",
      "Epoch: 1, Batch number: 52700, Loss: 7.036270618438721\n",
      "Epoch: 1, Batch number: 52800, Loss: 6.950070858001709\n",
      "Epoch: 1, Batch number: 52900, Loss: 6.674716472625732\n",
      "Epoch: 1, Batch number: 53000, Loss: 6.848276138305664\n",
      "Epoch: 1, Batch number: 53100, Loss: 6.895584583282471\n",
      "Epoch: 1, Batch number: 53200, Loss: 7.104968547821045\n",
      "Epoch: 1, Batch number: 53300, Loss: 6.975390911102295\n",
      "Epoch: 1, Batch number: 53400, Loss: 7.015542030334473\n",
      "Epoch: 1, Batch number: 53500, Loss: 7.086202144622803\n",
      "Epoch: 1, Batch number: 53600, Loss: 6.94747257232666\n",
      "Epoch: 1, Batch number: 53700, Loss: 7.178182601928711\n",
      "Epoch: 1, Batch number: 53800, Loss: 7.089033603668213\n",
      "Epoch: 1, Batch number: 53900, Loss: 6.9692254066467285\n",
      "Epoch: 1, Batch number: 54000, Loss: 7.156574726104736\n",
      "Epoch: 1, Batch number: 54100, Loss: 6.705726146697998\n",
      "Epoch: 1, Batch number: 54200, Loss: 7.101248741149902\n",
      "Epoch: 1, Batch number: 54300, Loss: 6.887648582458496\n",
      "Epoch: 1, Batch number: 54400, Loss: 6.986193656921387\n",
      "Epoch: 1, Batch number: 54500, Loss: 7.022993087768555\n",
      "Epoch: 1, Batch number: 54600, Loss: 7.168485164642334\n",
      "Epoch: 1, Batch number: 54700, Loss: 6.938482761383057\n",
      "Epoch: 1, Batch number: 54800, Loss: 6.889956474304199\n",
      "Epoch: 1, Batch number: 54900, Loss: 7.151116371154785\n",
      "Epoch: 1, Batch number: 55000, Loss: 7.0432586669921875\n",
      "Epoch: 1, Batch number: 55100, Loss: 6.8052077293396\n",
      "Epoch: 1, Batch number: 55200, Loss: 6.751718521118164\n",
      "Epoch: 1, Batch number: 55300, Loss: 6.89661979675293\n",
      "Epoch: 1, Batch number: 55400, Loss: 7.138930797576904\n",
      "Epoch: 1, Batch number: 55500, Loss: 6.895405292510986\n",
      "Epoch: 1, Batch number: 55600, Loss: 7.316608428955078\n",
      "Epoch: 1, Batch number: 55700, Loss: 6.98925256729126\n",
      "Epoch: 1, Batch number: 55800, Loss: 6.988425254821777\n",
      "Epoch: 1, Batch number: 55900, Loss: 6.7920074462890625\n",
      "Epoch: 1, Batch number: 56000, Loss: 6.757533073425293\n",
      "Epoch: 1, Batch number: 56100, Loss: 7.210892200469971\n",
      "Epoch: 1, Batch number: 56200, Loss: 7.443318843841553\n",
      "Epoch: 1, Batch number: 56300, Loss: 7.261329650878906\n",
      "Epoch: 1, Batch number: 56400, Loss: 6.999911785125732\n",
      "Epoch: 1, Batch number: 56500, Loss: 7.12111234664917\n",
      "Epoch: 1, Batch number: 56600, Loss: 7.0818328857421875\n",
      "Epoch: 1, Batch number: 56700, Loss: 7.070703506469727\n",
      "Epoch: 1, Batch number: 56800, Loss: 6.976846218109131\n",
      "Epoch: 1, Batch number: 56900, Loss: 6.84926700592041\n",
      "Epoch: 1, Batch number: 57000, Loss: 6.77233362197876\n",
      "Epoch: 1, Batch number: 57100, Loss: 6.795453071594238\n",
      "Epoch: 1, Batch number: 57200, Loss: 7.045562267303467\n",
      "Epoch: 1, Batch number: 57300, Loss: 7.169239521026611\n",
      "Epoch: 1, Batch number: 57400, Loss: 6.813126564025879\n",
      "Epoch: 1, Batch number: 57500, Loss: 6.939821243286133\n",
      "Epoch: 1, Batch number: 57600, Loss: 6.779726505279541\n",
      "Epoch: 1, Batch number: 57700, Loss: 7.0763068199157715\n",
      "Epoch: 1, Batch number: 57800, Loss: 7.069856643676758\n",
      "Epoch: 1, Batch number: 57900, Loss: 7.000116348266602\n",
      "Epoch: 1, Batch number: 58000, Loss: 7.125829696655273\n",
      "Epoch: 1, Batch number: 58100, Loss: 7.0455169677734375\n",
      "Epoch: 1, Batch number: 58200, Loss: 7.172774314880371\n",
      "Epoch: 1, Batch number: 58300, Loss: 7.313746929168701\n",
      "Epoch: 1, Batch number: 58400, Loss: 6.982824325561523\n",
      "Epoch: 1, Batch number: 58500, Loss: 6.944494724273682\n",
      "Epoch: 1, Batch number: 58600, Loss: 7.409931659698486\n",
      "Epoch: 1, Batch number: 58700, Loss: 6.973632335662842\n",
      "Epoch: 1, Batch number: 58800, Loss: 7.11132287979126\n",
      "Epoch: 1, Batch number: 58900, Loss: 7.154306411743164\n",
      "Epoch: 1, Batch number: 59000, Loss: 7.032477378845215\n",
      "Epoch: 1, Batch number: 59100, Loss: 7.408486366271973\n",
      "Epoch: 1, Batch number: 59200, Loss: 7.13464879989624\n",
      "Epoch: 1, Batch number: 59300, Loss: 6.925392150878906\n",
      "Epoch: 1, Batch number: 59400, Loss: 7.053971290588379\n",
      "Epoch: 1, Batch number: 59500, Loss: 7.106362819671631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 59600, Loss: 7.30368185043335\n",
      "Epoch: 1, Batch number: 59700, Loss: 7.508675575256348\n",
      "Epoch: 1, Batch number: 59800, Loss: 7.076808929443359\n",
      "Epoch: 1, Batch number: 59900, Loss: 6.9756011962890625\n",
      "Epoch: 1, Batch number: 60000, Loss: 6.858508586883545\n",
      "Epoch: 1, Batch number: 60100, Loss: 6.873133182525635\n",
      "Epoch: 1, Batch number: 60200, Loss: 6.913931846618652\n",
      "Epoch: 1, Batch number: 60300, Loss: 6.802792072296143\n",
      "Epoch: 1, Batch number: 60400, Loss: 7.038946628570557\n",
      "Epoch: 1, Batch number: 60500, Loss: 6.8767523765563965\n",
      "Epoch: 1, Batch number: 60600, Loss: 6.967369556427002\n",
      "Epoch: 1, Batch number: 60700, Loss: 6.884896278381348\n",
      "Epoch: 1, Batch number: 60800, Loss: 6.917499542236328\n",
      "Epoch: 1, Batch number: 60900, Loss: 6.827227592468262\n",
      "Epoch: 1, Batch number: 61000, Loss: 7.230170726776123\n",
      "Epoch: 1, Batch number: 61100, Loss: 7.229545593261719\n",
      "Epoch: 1, Batch number: 61200, Loss: 6.754110336303711\n",
      "Epoch: 1, Batch number: 61300, Loss: 7.055742263793945\n",
      "Epoch: 1, Batch number: 61400, Loss: 6.86344051361084\n",
      "Epoch: 1, Batch number: 61500, Loss: 7.214512348175049\n",
      "Epoch: 1, Batch number: 61600, Loss: 6.953514575958252\n",
      "Epoch: 1, Batch number: 61700, Loss: 7.224719524383545\n",
      "Epoch: 1, Batch number: 61800, Loss: 6.947786331176758\n",
      "Epoch: 1, Batch number: 61900, Loss: 7.0301713943481445\n",
      "Epoch: 1, Batch number: 62000, Loss: 7.069200038909912\n",
      "Epoch: 1, Batch number: 62100, Loss: 7.069862365722656\n",
      "Epoch: 1, Batch number: 62200, Loss: 6.826748847961426\n",
      "Epoch: 1, Batch number: 62300, Loss: 6.9594621658325195\n",
      "Epoch: 1, Batch number: 62400, Loss: 6.982414245605469\n",
      "Epoch: 1, Batch number: 62500, Loss: 7.054610252380371\n",
      "Epoch: 1, Batch number: 62600, Loss: 6.836222171783447\n",
      "Epoch: 1, Batch number: 62700, Loss: 7.078117847442627\n",
      "Epoch: 1, Batch number: 62800, Loss: 7.120384216308594\n",
      "Epoch: 1, Batch number: 62900, Loss: 6.9339141845703125\n",
      "Epoch: 1, Batch number: 63000, Loss: 7.291919231414795\n",
      "Epoch: 1, Batch number: 63100, Loss: 7.04764986038208\n",
      "Epoch: 1, Batch number: 63200, Loss: 7.160025596618652\n",
      "Epoch: 1, Batch number: 63300, Loss: 6.686794757843018\n",
      "Epoch: 1, Batch number: 63400, Loss: 6.885261058807373\n",
      "Epoch: 1, Batch number: 63500, Loss: 6.857429027557373\n",
      "Epoch: 1, Batch number: 63600, Loss: 7.133037567138672\n",
      "Epoch: 1, Batch number: 63700, Loss: 6.8757734298706055\n",
      "Epoch: 1, Batch number: 63800, Loss: 6.5905022621154785\n",
      "Epoch: 1, Batch number: 63900, Loss: 7.047400951385498\n",
      "Epoch: 1, Batch number: 64000, Loss: 7.035989284515381\n",
      "Epoch: 1, Batch number: 64100, Loss: 7.169035911560059\n",
      "Epoch: 1, Batch number: 64200, Loss: 7.267683029174805\n",
      "Epoch: 1, Batch number: 64300, Loss: 6.947273254394531\n",
      "Epoch: 1, Batch number: 64400, Loss: 7.1774702072143555\n",
      "Epoch: 1, Batch number: 64500, Loss: 6.9910149574279785\n",
      "Epoch: 1, Batch number: 64600, Loss: 7.215188980102539\n",
      "Epoch: 1, Batch number: 64700, Loss: 6.904151439666748\n",
      "Epoch: 1, Batch number: 64800, Loss: 6.94875431060791\n",
      "Epoch: 1, Batch number: 64900, Loss: 7.148090362548828\n",
      "Epoch: 1, Batch number: 65000, Loss: 6.800536155700684\n",
      "Epoch: 1, Batch number: 65100, Loss: 7.131444931030273\n",
      "Epoch: 1, Batch number: 65200, Loss: 6.939375877380371\n",
      "Epoch: 1, Batch number: 65300, Loss: 7.011146545410156\n",
      "Epoch: 1, Batch number: 65400, Loss: 6.883857250213623\n",
      "Epoch: 1, Batch number: 65500, Loss: 6.963831901550293\n",
      "Epoch: 1, Batch number: 65600, Loss: 6.963881969451904\n",
      "Epoch: 1, Batch number: 65700, Loss: 6.706439018249512\n",
      "Epoch: 1, Batch number: 65800, Loss: 6.949808120727539\n",
      "Epoch: 1, Batch number: 65900, Loss: 6.85027551651001\n",
      "Epoch: 1, Batch number: 66000, Loss: 6.945917129516602\n",
      "Epoch: 1, Batch number: 66100, Loss: 6.586373329162598\n",
      "Epoch: 1, Batch number: 66200, Loss: 6.998476028442383\n",
      "Epoch: 1, Batch number: 66300, Loss: 6.855074882507324\n",
      "Epoch: 1, Batch number: 66400, Loss: 7.459965705871582\n",
      "Epoch: 1, Batch number: 66500, Loss: 6.733924388885498\n",
      "Epoch: 1, Batch number: 66600, Loss: 6.898769378662109\n",
      "Epoch: 1, Batch number: 66700, Loss: 6.933306694030762\n",
      "Epoch: 1, Batch number: 66800, Loss: 7.0004963874816895\n",
      "Epoch: 1, Batch number: 66900, Loss: 6.9271559715271\n",
      "Epoch: 1, Batch number: 67000, Loss: 7.033622741699219\n",
      "Epoch: 1, Batch number: 67100, Loss: 6.979956150054932\n",
      "Epoch: 2, Batch number: 6, Loss: 6.812978744506836\n",
      "Epoch: 2, Batch number: 106, Loss: 6.899212837219238\n",
      "Epoch: 2, Batch number: 206, Loss: 6.995811462402344\n",
      "Epoch: 2, Batch number: 306, Loss: 6.637137413024902\n",
      "Epoch: 2, Batch number: 406, Loss: 6.994287967681885\n",
      "Epoch: 2, Batch number: 506, Loss: 6.95448112487793\n",
      "Epoch: 2, Batch number: 606, Loss: 6.900002956390381\n",
      "Epoch: 2, Batch number: 706, Loss: 6.740152359008789\n",
      "Epoch: 2, Batch number: 806, Loss: 6.916053771972656\n",
      "Epoch: 2, Batch number: 906, Loss: 6.618142604827881\n",
      "Epoch: 2, Batch number: 1006, Loss: 6.702781677246094\n",
      "Epoch: 2, Batch number: 1106, Loss: 6.8855814933776855\n",
      "Epoch: 2, Batch number: 1206, Loss: 6.780402183532715\n",
      "Epoch: 2, Batch number: 1306, Loss: 6.833467960357666\n",
      "Epoch: 2, Batch number: 1406, Loss: 6.699901580810547\n",
      "Epoch: 2, Batch number: 1506, Loss: 6.941545009613037\n",
      "Epoch: 2, Batch number: 1606, Loss: 6.879726409912109\n",
      "Epoch: 2, Batch number: 1706, Loss: 6.72127628326416\n",
      "Epoch: 2, Batch number: 1806, Loss: 6.820822238922119\n",
      "Epoch: 2, Batch number: 1906, Loss: 6.871600151062012\n",
      "Epoch: 2, Batch number: 2006, Loss: 6.754293441772461\n",
      "Epoch: 2, Batch number: 2106, Loss: 6.994434356689453\n",
      "Epoch: 2, Batch number: 2206, Loss: 6.837467193603516\n",
      "Epoch: 2, Batch number: 2306, Loss: 6.948398113250732\n",
      "Epoch: 2, Batch number: 2406, Loss: 6.881035804748535\n",
      "Epoch: 2, Batch number: 2506, Loss: 6.685337543487549\n",
      "Epoch: 2, Batch number: 2606, Loss: 6.9238996505737305\n",
      "Epoch: 2, Batch number: 2706, Loss: 6.688908100128174\n",
      "Epoch: 2, Batch number: 2806, Loss: 6.904273509979248\n",
      "Epoch: 2, Batch number: 2906, Loss: 6.788764953613281\n",
      "Epoch: 2, Batch number: 3006, Loss: 6.775439739227295\n",
      "Epoch: 2, Batch number: 3106, Loss: 6.727461338043213\n",
      "Epoch: 2, Batch number: 3206, Loss: 6.986931324005127\n",
      "Epoch: 2, Batch number: 3306, Loss: 7.084630966186523\n",
      "Epoch: 2, Batch number: 3406, Loss: 6.983352184295654\n",
      "Epoch: 2, Batch number: 3506, Loss: 6.927677154541016\n",
      "Epoch: 2, Batch number: 3606, Loss: 6.925412654876709\n",
      "Epoch: 2, Batch number: 3706, Loss: 6.881433963775635\n",
      "Epoch: 2, Batch number: 3806, Loss: 6.992835998535156\n",
      "Epoch: 2, Batch number: 3906, Loss: 7.07287073135376\n",
      "Epoch: 2, Batch number: 4006, Loss: 7.175477027893066\n",
      "Epoch: 2, Batch number: 4106, Loss: 6.765012264251709\n",
      "Epoch: 2, Batch number: 4206, Loss: 6.935061454772949\n",
      "Epoch: 2, Batch number: 4306, Loss: 6.869792461395264\n",
      "Epoch: 2, Batch number: 4406, Loss: 6.633517265319824\n",
      "Epoch: 2, Batch number: 4506, Loss: 6.939744472503662\n",
      "Epoch: 2, Batch number: 4606, Loss: 6.843420505523682\n",
      "Epoch: 2, Batch number: 4706, Loss: 6.893779277801514\n",
      "Epoch: 2, Batch number: 4806, Loss: 7.1145920753479\n",
      "Epoch: 2, Batch number: 4906, Loss: 6.807709693908691\n",
      "Epoch: 2, Batch number: 5006, Loss: 6.809260845184326\n",
      "Epoch: 2, Batch number: 5106, Loss: 6.67781925201416\n",
      "Epoch: 2, Batch number: 5206, Loss: 7.0736403465271\n",
      "Epoch: 2, Batch number: 5306, Loss: 6.827307224273682\n",
      "Epoch: 2, Batch number: 5406, Loss: 6.745731353759766\n",
      "Epoch: 2, Batch number: 5506, Loss: 6.762763977050781\n",
      "Epoch: 2, Batch number: 5606, Loss: 6.81363582611084\n",
      "Epoch: 2, Batch number: 5706, Loss: 7.151670455932617\n",
      "Epoch: 2, Batch number: 5806, Loss: 6.685258388519287\n",
      "Epoch: 2, Batch number: 5906, Loss: 7.010434627532959\n",
      "Epoch: 2, Batch number: 6006, Loss: 6.770598411560059\n",
      "Epoch: 2, Batch number: 6106, Loss: 7.075129985809326\n",
      "Epoch: 2, Batch number: 6206, Loss: 6.547318935394287\n",
      "Epoch: 2, Batch number: 6306, Loss: 6.807353496551514\n",
      "Epoch: 2, Batch number: 6406, Loss: 6.864357948303223\n",
      "Epoch: 2, Batch number: 6506, Loss: 6.712458610534668\n",
      "Epoch: 2, Batch number: 6606, Loss: 6.8462815284729\n",
      "Epoch: 2, Batch number: 6706, Loss: 6.977027893066406\n",
      "Epoch: 2, Batch number: 6806, Loss: 6.865375995635986\n",
      "Epoch: 2, Batch number: 6906, Loss: 6.99552059173584\n",
      "Epoch: 2, Batch number: 7006, Loss: 6.655094623565674\n",
      "Epoch: 2, Batch number: 7106, Loss: 6.846088409423828\n",
      "Epoch: 2, Batch number: 7206, Loss: 6.821420669555664\n",
      "Epoch: 2, Batch number: 7306, Loss: 6.959965705871582\n",
      "Epoch: 2, Batch number: 7406, Loss: 6.896692752838135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 7506, Loss: 6.996132850646973\n",
      "Epoch: 2, Batch number: 7606, Loss: 6.804781913757324\n",
      "Epoch: 2, Batch number: 7706, Loss: 6.976777076721191\n",
      "Epoch: 2, Batch number: 7806, Loss: 6.998786449432373\n",
      "Epoch: 2, Batch number: 7906, Loss: 7.095037937164307\n",
      "Epoch: 2, Batch number: 8006, Loss: 6.837515354156494\n",
      "Epoch: 2, Batch number: 8106, Loss: 6.881860733032227\n",
      "Epoch: 2, Batch number: 8206, Loss: 6.9133710861206055\n",
      "Epoch: 2, Batch number: 8306, Loss: 6.719438552856445\n",
      "Epoch: 2, Batch number: 8406, Loss: 6.6578168869018555\n",
      "Epoch: 2, Batch number: 8506, Loss: 6.861516952514648\n",
      "Epoch: 2, Batch number: 8606, Loss: 6.999195098876953\n",
      "Epoch: 2, Batch number: 8706, Loss: 6.900684833526611\n",
      "Epoch: 2, Batch number: 8806, Loss: 6.921706676483154\n",
      "Epoch: 2, Batch number: 8906, Loss: 6.78377103805542\n",
      "Epoch: 2, Batch number: 9006, Loss: 6.898635387420654\n",
      "Epoch: 2, Batch number: 9106, Loss: 6.906991958618164\n",
      "Epoch: 2, Batch number: 9206, Loss: 6.911494255065918\n",
      "Epoch: 2, Batch number: 9306, Loss: 6.9222869873046875\n",
      "Epoch: 2, Batch number: 9406, Loss: 6.881335735321045\n",
      "Epoch: 2, Batch number: 9506, Loss: 6.911250114440918\n",
      "Epoch: 2, Batch number: 9606, Loss: 7.051695346832275\n",
      "Epoch: 2, Batch number: 9706, Loss: 7.036010265350342\n",
      "Epoch: 2, Batch number: 9806, Loss: 6.843191146850586\n",
      "Epoch: 2, Batch number: 9906, Loss: 6.8464741706848145\n",
      "Epoch: 2, Batch number: 10006, Loss: 6.826052665710449\n",
      "Epoch: 2, Batch number: 10106, Loss: 6.663863182067871\n",
      "Epoch: 2, Batch number: 10206, Loss: 6.721027374267578\n",
      "Epoch: 2, Batch number: 10306, Loss: 7.000585079193115\n",
      "Epoch: 2, Batch number: 10406, Loss: 6.932624340057373\n",
      "Epoch: 2, Batch number: 10506, Loss: 6.934478282928467\n",
      "Epoch: 2, Batch number: 10606, Loss: 6.847805023193359\n",
      "Epoch: 2, Batch number: 10706, Loss: 6.631587028503418\n",
      "Epoch: 2, Batch number: 10806, Loss: 6.5833420753479\n",
      "Epoch: 2, Batch number: 10906, Loss: 7.059402942657471\n",
      "Epoch: 2, Batch number: 11006, Loss: 6.721184730529785\n",
      "Epoch: 2, Batch number: 11106, Loss: 6.984395503997803\n",
      "Epoch: 2, Batch number: 11206, Loss: 6.989933490753174\n",
      "Epoch: 2, Batch number: 11306, Loss: 6.770937919616699\n",
      "Epoch: 2, Batch number: 11406, Loss: 7.0500688552856445\n",
      "Epoch: 2, Batch number: 11506, Loss: 6.9843268394470215\n",
      "Epoch: 2, Batch number: 11606, Loss: 7.057117938995361\n",
      "Epoch: 2, Batch number: 11706, Loss: 6.820457458496094\n",
      "Epoch: 2, Batch number: 11806, Loss: 6.881536960601807\n",
      "Epoch: 2, Batch number: 11906, Loss: 6.8206963539123535\n",
      "Epoch: 2, Batch number: 12006, Loss: 6.985095024108887\n",
      "Epoch: 2, Batch number: 12106, Loss: 6.890033721923828\n",
      "Epoch: 2, Batch number: 12206, Loss: 6.6385955810546875\n",
      "Epoch: 2, Batch number: 12306, Loss: 7.15535306930542\n",
      "Epoch: 2, Batch number: 12406, Loss: 6.704414367675781\n",
      "Epoch: 2, Batch number: 12506, Loss: 6.83351993560791\n",
      "Epoch: 2, Batch number: 12606, Loss: 6.993662357330322\n",
      "Epoch: 2, Batch number: 12706, Loss: 7.026328086853027\n",
      "Epoch: 2, Batch number: 12806, Loss: 6.792974948883057\n",
      "Epoch: 2, Batch number: 12906, Loss: 7.076468467712402\n",
      "Epoch: 2, Batch number: 13006, Loss: 6.905389308929443\n",
      "Epoch: 2, Batch number: 13106, Loss: 6.84754753112793\n",
      "Epoch: 2, Batch number: 13206, Loss: 7.084631443023682\n",
      "Epoch: 2, Batch number: 13306, Loss: 6.668802738189697\n",
      "Epoch: 2, Batch number: 13406, Loss: 6.843748092651367\n",
      "Epoch: 2, Batch number: 13506, Loss: 6.8948073387146\n",
      "Epoch: 2, Batch number: 13606, Loss: 6.838740348815918\n",
      "Epoch: 2, Batch number: 13706, Loss: 6.68453311920166\n",
      "Epoch: 2, Batch number: 13806, Loss: 6.968891143798828\n",
      "Epoch: 2, Batch number: 13906, Loss: 6.857184886932373\n",
      "Epoch: 2, Batch number: 14006, Loss: 6.653527736663818\n",
      "Epoch: 2, Batch number: 14106, Loss: 6.607905864715576\n",
      "Epoch: 2, Batch number: 14206, Loss: 6.718409061431885\n",
      "Epoch: 2, Batch number: 14306, Loss: 6.9006805419921875\n",
      "Epoch: 2, Batch number: 14406, Loss: 7.026495456695557\n",
      "Epoch: 2, Batch number: 14506, Loss: 6.826901912689209\n",
      "Epoch: 2, Batch number: 14606, Loss: 6.724582672119141\n",
      "Epoch: 2, Batch number: 14706, Loss: 6.935288906097412\n",
      "Epoch: 2, Batch number: 14806, Loss: 7.010903835296631\n",
      "Epoch: 2, Batch number: 14906, Loss: 6.819761753082275\n",
      "Epoch: 2, Batch number: 15006, Loss: 6.919271945953369\n",
      "Epoch: 2, Batch number: 15106, Loss: 6.816808223724365\n",
      "Epoch: 2, Batch number: 15206, Loss: 6.8324079513549805\n",
      "Epoch: 2, Batch number: 15306, Loss: 6.734521389007568\n",
      "Epoch: 2, Batch number: 15406, Loss: 6.811452865600586\n",
      "Epoch: 2, Batch number: 15506, Loss: 7.207967281341553\n",
      "Epoch: 2, Batch number: 15606, Loss: 6.800980091094971\n",
      "Epoch: 2, Batch number: 15706, Loss: 6.98102331161499\n",
      "Epoch: 2, Batch number: 15806, Loss: 6.8631415367126465\n",
      "Epoch: 2, Batch number: 15906, Loss: 7.208460330963135\n",
      "Epoch: 2, Batch number: 16006, Loss: 6.669000625610352\n",
      "Epoch: 2, Batch number: 16106, Loss: 6.975653648376465\n",
      "Epoch: 2, Batch number: 16206, Loss: 6.72772216796875\n",
      "Epoch: 2, Batch number: 16306, Loss: 6.603662490844727\n",
      "Epoch: 2, Batch number: 16406, Loss: 6.87117338180542\n",
      "Epoch: 2, Batch number: 16506, Loss: 6.886045455932617\n",
      "Epoch: 2, Batch number: 16606, Loss: 6.691163539886475\n",
      "Epoch: 2, Batch number: 16706, Loss: 6.684777736663818\n",
      "Epoch: 2, Batch number: 16806, Loss: 6.587955474853516\n",
      "Epoch: 2, Batch number: 16906, Loss: 6.769918441772461\n",
      "Epoch: 2, Batch number: 17006, Loss: 6.4864935874938965\n",
      "Epoch: 2, Batch number: 17106, Loss: 6.763854503631592\n",
      "Epoch: 2, Batch number: 17206, Loss: 6.911019325256348\n",
      "Epoch: 2, Batch number: 17306, Loss: 7.252104759216309\n",
      "Epoch: 2, Batch number: 17406, Loss: 6.913997650146484\n",
      "Epoch: 2, Batch number: 17506, Loss: 7.016750335693359\n",
      "Epoch: 2, Batch number: 17606, Loss: 6.997314929962158\n",
      "Epoch: 2, Batch number: 17706, Loss: 6.885344505310059\n",
      "Epoch: 2, Batch number: 17806, Loss: 6.73520040512085\n",
      "Epoch: 2, Batch number: 17906, Loss: 6.826472759246826\n",
      "Epoch: 2, Batch number: 18006, Loss: 6.468562126159668\n",
      "Epoch: 2, Batch number: 18106, Loss: 7.020439624786377\n",
      "Epoch: 2, Batch number: 18206, Loss: 7.10604190826416\n",
      "Epoch: 2, Batch number: 18306, Loss: 6.852219581604004\n",
      "Epoch: 2, Batch number: 18406, Loss: 6.780957221984863\n",
      "Epoch: 2, Batch number: 18506, Loss: 6.865616321563721\n",
      "Epoch: 2, Batch number: 18606, Loss: 6.872519493103027\n",
      "Epoch: 2, Batch number: 18706, Loss: 7.182518482208252\n",
      "Epoch: 2, Batch number: 18806, Loss: 6.825284481048584\n",
      "Epoch: 2, Batch number: 18906, Loss: 6.796029090881348\n",
      "Epoch: 2, Batch number: 19006, Loss: 7.002768039703369\n",
      "Epoch: 2, Batch number: 19106, Loss: 6.860432147979736\n",
      "Epoch: 2, Batch number: 19206, Loss: 6.7200927734375\n",
      "Epoch: 2, Batch number: 19306, Loss: 6.679690361022949\n",
      "Epoch: 2, Batch number: 19406, Loss: 6.984378337860107\n",
      "Epoch: 2, Batch number: 19506, Loss: 6.809250831604004\n",
      "Epoch: 2, Batch number: 19606, Loss: 6.919259071350098\n",
      "Epoch: 2, Batch number: 19706, Loss: 6.690108776092529\n",
      "Epoch: 2, Batch number: 19806, Loss: 6.6230292320251465\n",
      "Epoch: 2, Batch number: 19906, Loss: 7.07942533493042\n",
      "Epoch: 2, Batch number: 20006, Loss: 7.0061163902282715\n",
      "Epoch: 2, Batch number: 20106, Loss: 7.069290637969971\n",
      "Epoch: 2, Batch number: 20206, Loss: 7.012703895568848\n",
      "Epoch: 2, Batch number: 20306, Loss: 7.151548862457275\n",
      "Epoch: 2, Batch number: 20406, Loss: 6.821534633636475\n",
      "Epoch: 2, Batch number: 20506, Loss: 7.029644966125488\n",
      "Epoch: 2, Batch number: 20606, Loss: 7.065001010894775\n",
      "Epoch: 2, Batch number: 20706, Loss: 7.1214141845703125\n",
      "Epoch: 2, Batch number: 20806, Loss: 6.970179080963135\n",
      "Epoch: 2, Batch number: 20906, Loss: 7.0153117179870605\n",
      "Epoch: 2, Batch number: 21006, Loss: 6.895240783691406\n",
      "Epoch: 2, Batch number: 21106, Loss: 6.864774703979492\n",
      "Epoch: 2, Batch number: 21206, Loss: 7.120809555053711\n",
      "Epoch: 2, Batch number: 21306, Loss: 7.172426223754883\n",
      "Epoch: 2, Batch number: 21406, Loss: 6.735982418060303\n",
      "Epoch: 2, Batch number: 21506, Loss: 7.028134346008301\n",
      "Epoch: 2, Batch number: 21606, Loss: 6.751038551330566\n",
      "Epoch: 2, Batch number: 21706, Loss: 6.910273551940918\n",
      "Epoch: 2, Batch number: 21806, Loss: 6.993445873260498\n",
      "Epoch: 2, Batch number: 21906, Loss: 6.98410177230835\n",
      "Epoch: 2, Batch number: 22006, Loss: 6.8671674728393555\n",
      "Epoch: 2, Batch number: 22106, Loss: 6.918906211853027\n",
      "Epoch: 2, Batch number: 22206, Loss: 6.97116756439209\n",
      "Epoch: 2, Batch number: 22306, Loss: 6.67503023147583\n",
      "Epoch: 2, Batch number: 22406, Loss: 6.9611639976501465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 22506, Loss: 6.585051536560059\n",
      "Epoch: 2, Batch number: 22606, Loss: 6.887794017791748\n",
      "Epoch: 2, Batch number: 22706, Loss: 6.907588481903076\n",
      "Epoch: 2, Batch number: 22806, Loss: 6.796841144561768\n",
      "Epoch: 2, Batch number: 22906, Loss: 7.059873580932617\n",
      "Epoch: 2, Batch number: 23006, Loss: 7.193530559539795\n",
      "Epoch: 2, Batch number: 23106, Loss: 6.673730373382568\n",
      "Epoch: 2, Batch number: 23206, Loss: 6.737547874450684\n",
      "Epoch: 2, Batch number: 23306, Loss: 6.774444103240967\n",
      "Epoch: 2, Batch number: 23406, Loss: 6.941900730133057\n",
      "Epoch: 2, Batch number: 23506, Loss: 6.883090496063232\n",
      "Epoch: 2, Batch number: 23606, Loss: 6.907120227813721\n",
      "Epoch: 2, Batch number: 23706, Loss: 6.937511444091797\n",
      "Epoch: 2, Batch number: 23806, Loss: 6.6730875968933105\n",
      "Epoch: 2, Batch number: 23906, Loss: 6.864669322967529\n",
      "Epoch: 2, Batch number: 24006, Loss: 6.788784503936768\n",
      "Epoch: 2, Batch number: 24106, Loss: 6.85750675201416\n",
      "Epoch: 2, Batch number: 24206, Loss: 6.8940205574035645\n",
      "Epoch: 2, Batch number: 24306, Loss: 6.548305034637451\n",
      "Epoch: 2, Batch number: 24406, Loss: 6.846704483032227\n",
      "Epoch: 2, Batch number: 24506, Loss: 6.595090866088867\n",
      "Epoch: 2, Batch number: 24606, Loss: 6.931125640869141\n",
      "Epoch: 2, Batch number: 24706, Loss: 6.764894962310791\n",
      "Epoch: 2, Batch number: 24806, Loss: 7.0360870361328125\n",
      "Epoch: 2, Batch number: 24906, Loss: 6.7782135009765625\n",
      "Epoch: 2, Batch number: 25006, Loss: 7.080398082733154\n",
      "Epoch: 2, Batch number: 25106, Loss: 6.875422954559326\n",
      "Epoch: 2, Batch number: 25206, Loss: 6.755868434906006\n",
      "Epoch: 2, Batch number: 25306, Loss: 6.438094615936279\n",
      "Epoch: 2, Batch number: 25406, Loss: 6.864431381225586\n",
      "Epoch: 2, Batch number: 25506, Loss: 6.888912677764893\n",
      "Epoch: 2, Batch number: 25606, Loss: 6.7671122550964355\n",
      "Epoch: 2, Batch number: 25706, Loss: 6.811799049377441\n",
      "Epoch: 2, Batch number: 25806, Loss: 7.044468402862549\n",
      "Epoch: 2, Batch number: 25906, Loss: 6.826664447784424\n",
      "Epoch: 2, Batch number: 26006, Loss: 6.932631969451904\n",
      "Epoch: 2, Batch number: 26106, Loss: 6.845980644226074\n",
      "Epoch: 2, Batch number: 26206, Loss: 6.7459869384765625\n",
      "Epoch: 2, Batch number: 26306, Loss: 6.9146623611450195\n",
      "Epoch: 2, Batch number: 26406, Loss: 7.045804500579834\n",
      "Epoch: 2, Batch number: 26506, Loss: 6.892935276031494\n",
      "Epoch: 2, Batch number: 26606, Loss: 6.905363082885742\n",
      "Epoch: 2, Batch number: 26706, Loss: 6.676449775695801\n",
      "Epoch: 2, Batch number: 26806, Loss: 6.702445983886719\n",
      "Epoch: 2, Batch number: 26906, Loss: 6.811135768890381\n",
      "Epoch: 2, Batch number: 27006, Loss: 6.9006218910217285\n",
      "Epoch: 2, Batch number: 27106, Loss: 6.642682075500488\n",
      "Epoch: 2, Batch number: 27206, Loss: 6.744224548339844\n",
      "Epoch: 2, Batch number: 27306, Loss: 6.800377368927002\n",
      "Epoch: 2, Batch number: 27406, Loss: 7.022743225097656\n",
      "Epoch: 2, Batch number: 27506, Loss: 6.843711853027344\n",
      "Epoch: 2, Batch number: 27606, Loss: 6.630947113037109\n",
      "Epoch: 2, Batch number: 27706, Loss: 6.9530768394470215\n",
      "Epoch: 2, Batch number: 27806, Loss: 7.028326511383057\n",
      "Epoch: 2, Batch number: 27906, Loss: 6.930564880371094\n",
      "Epoch: 2, Batch number: 28006, Loss: 6.795897960662842\n",
      "Epoch: 2, Batch number: 28106, Loss: 6.875986576080322\n",
      "Epoch: 2, Batch number: 28206, Loss: 7.296463489532471\n",
      "Epoch: 2, Batch number: 28306, Loss: 6.946230411529541\n",
      "Epoch: 2, Batch number: 28406, Loss: 6.854909896850586\n",
      "Epoch: 2, Batch number: 28506, Loss: 6.749880313873291\n",
      "Epoch: 2, Batch number: 28606, Loss: 6.835872173309326\n",
      "Epoch: 2, Batch number: 28706, Loss: 7.045748710632324\n",
      "Epoch: 2, Batch number: 28806, Loss: 6.94465446472168\n",
      "Epoch: 2, Batch number: 28906, Loss: 6.822579383850098\n",
      "Epoch: 2, Batch number: 29006, Loss: 7.254754066467285\n",
      "Epoch: 2, Batch number: 29106, Loss: 6.895681858062744\n",
      "Epoch: 2, Batch number: 29206, Loss: 6.665372848510742\n",
      "Epoch: 2, Batch number: 29306, Loss: 7.035390377044678\n",
      "Epoch: 2, Batch number: 29406, Loss: 6.868135929107666\n",
      "Epoch: 2, Batch number: 29506, Loss: 6.698431491851807\n",
      "Epoch: 2, Batch number: 29606, Loss: 6.8120317459106445\n",
      "Epoch: 2, Batch number: 29706, Loss: 7.068148612976074\n",
      "Epoch: 2, Batch number: 29806, Loss: 7.194010257720947\n",
      "Epoch: 2, Batch number: 29906, Loss: 7.073958873748779\n",
      "Epoch: 2, Batch number: 30006, Loss: 6.4661359786987305\n",
      "Epoch: 2, Batch number: 30106, Loss: 6.911005973815918\n",
      "Epoch: 2, Batch number: 30206, Loss: 6.840402126312256\n",
      "Epoch: 2, Batch number: 30306, Loss: 6.6305317878723145\n",
      "Epoch: 2, Batch number: 30406, Loss: 6.95374059677124\n",
      "Epoch: 2, Batch number: 30506, Loss: 6.641314506530762\n",
      "Epoch: 2, Batch number: 30606, Loss: 6.811304569244385\n",
      "Epoch: 2, Batch number: 30706, Loss: 6.984397888183594\n",
      "Epoch: 2, Batch number: 30806, Loss: 6.652807712554932\n",
      "Epoch: 2, Batch number: 30906, Loss: 6.8238983154296875\n",
      "Epoch: 2, Batch number: 31006, Loss: 6.825617790222168\n",
      "Epoch: 2, Batch number: 31106, Loss: 6.9047417640686035\n",
      "Epoch: 2, Batch number: 31206, Loss: 6.744580268859863\n",
      "Epoch: 2, Batch number: 31306, Loss: 6.659574031829834\n",
      "Epoch: 2, Batch number: 31406, Loss: 7.024518966674805\n",
      "Epoch: 2, Batch number: 31506, Loss: 7.182684421539307\n",
      "Epoch: 2, Batch number: 31606, Loss: 6.8321380615234375\n",
      "Epoch: 2, Batch number: 31706, Loss: 7.018046855926514\n",
      "Epoch: 2, Batch number: 31806, Loss: 6.843676567077637\n",
      "Epoch: 2, Batch number: 31906, Loss: 6.750331401824951\n",
      "Epoch: 2, Batch number: 32006, Loss: 6.834789752960205\n",
      "Epoch: 2, Batch number: 32106, Loss: 6.745171070098877\n",
      "Epoch: 2, Batch number: 32206, Loss: 6.757589817047119\n",
      "Epoch: 2, Batch number: 32306, Loss: 7.072998523712158\n",
      "Epoch: 2, Batch number: 32406, Loss: 6.539498805999756\n",
      "Epoch: 2, Batch number: 32506, Loss: 6.755837917327881\n",
      "Epoch: 2, Batch number: 32606, Loss: 6.695523738861084\n",
      "Epoch: 2, Batch number: 32706, Loss: 7.088362693786621\n",
      "Epoch: 2, Batch number: 32806, Loss: 7.0217108726501465\n",
      "Epoch: 2, Batch number: 32906, Loss: 6.848386287689209\n",
      "Epoch: 2, Batch number: 33006, Loss: 6.950047016143799\n",
      "Epoch: 2, Batch number: 33106, Loss: 6.954423904418945\n",
      "Epoch: 2, Batch number: 33206, Loss: 6.885838985443115\n",
      "Epoch: 2, Batch number: 33306, Loss: 6.956721305847168\n",
      "Epoch: 2, Batch number: 33406, Loss: 6.726558685302734\n",
      "Epoch: 2, Batch number: 33506, Loss: 6.894894123077393\n",
      "Epoch: 2, Batch number: 33606, Loss: 6.923017978668213\n",
      "Epoch: 2, Batch number: 33706, Loss: 6.9159369468688965\n",
      "Epoch: 2, Batch number: 33806, Loss: 6.9810471534729\n",
      "Epoch: 2, Batch number: 33906, Loss: 6.95617151260376\n",
      "Epoch: 2, Batch number: 34006, Loss: 6.849997520446777\n",
      "Epoch: 2, Batch number: 34106, Loss: 6.935403823852539\n",
      "Epoch: 2, Batch number: 34206, Loss: 6.720444202423096\n",
      "Epoch: 2, Batch number: 34306, Loss: 6.993817329406738\n",
      "Epoch: 2, Batch number: 34406, Loss: 7.126333236694336\n",
      "Epoch: 2, Batch number: 34506, Loss: 6.7344255447387695\n",
      "Epoch: 2, Batch number: 34606, Loss: 7.058650493621826\n",
      "Epoch: 2, Batch number: 34706, Loss: 6.873893737792969\n",
      "Epoch: 2, Batch number: 34806, Loss: 6.943443775177002\n",
      "Epoch: 2, Batch number: 34906, Loss: 6.882993698120117\n",
      "Epoch: 2, Batch number: 35006, Loss: 6.837277889251709\n",
      "Epoch: 2, Batch number: 35106, Loss: 6.65043830871582\n",
      "Epoch: 2, Batch number: 35206, Loss: 6.6807942390441895\n",
      "Epoch: 2, Batch number: 35306, Loss: 6.8693389892578125\n",
      "Epoch: 2, Batch number: 35406, Loss: 6.9117231369018555\n",
      "Epoch: 2, Batch number: 35506, Loss: 6.93705415725708\n",
      "Epoch: 2, Batch number: 35606, Loss: 6.7456254959106445\n",
      "Epoch: 2, Batch number: 35706, Loss: 6.968351364135742\n",
      "Epoch: 2, Batch number: 35806, Loss: 6.9175262451171875\n",
      "Epoch: 2, Batch number: 35906, Loss: 6.793514251708984\n",
      "Epoch: 2, Batch number: 36006, Loss: 6.93525505065918\n",
      "Epoch: 2, Batch number: 36106, Loss: 6.994629383087158\n",
      "Epoch: 2, Batch number: 36206, Loss: 7.083595275878906\n",
      "Epoch: 2, Batch number: 36306, Loss: 6.703437328338623\n",
      "Epoch: 2, Batch number: 36406, Loss: 7.019678592681885\n",
      "Epoch: 2, Batch number: 36506, Loss: 6.761163711547852\n",
      "Epoch: 2, Batch number: 36606, Loss: 7.013132572174072\n",
      "Epoch: 2, Batch number: 36706, Loss: 6.880859851837158\n",
      "Epoch: 2, Batch number: 36806, Loss: 6.947445392608643\n",
      "Epoch: 2, Batch number: 36906, Loss: 6.716876983642578\n",
      "Epoch: 2, Batch number: 37006, Loss: 6.8114752769470215\n",
      "Epoch: 2, Batch number: 37106, Loss: 6.802248001098633\n",
      "Epoch: 2, Batch number: 37206, Loss: 6.913133144378662\n",
      "Epoch: 2, Batch number: 37306, Loss: 7.165369510650635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 37406, Loss: 6.62744140625\n",
      "Epoch: 2, Batch number: 37506, Loss: 6.772155284881592\n",
      "Epoch: 2, Batch number: 37606, Loss: 6.8599395751953125\n",
      "Epoch: 2, Batch number: 37706, Loss: 7.034674644470215\n",
      "Epoch: 2, Batch number: 37806, Loss: 6.995048522949219\n",
      "Epoch: 2, Batch number: 37906, Loss: 6.700709342956543\n",
      "Epoch: 2, Batch number: 38006, Loss: 6.862504959106445\n",
      "Epoch: 2, Batch number: 38106, Loss: 6.894369125366211\n",
      "Epoch: 2, Batch number: 38206, Loss: 6.930624008178711\n",
      "Epoch: 2, Batch number: 38306, Loss: 6.722970008850098\n",
      "Epoch: 2, Batch number: 38406, Loss: 6.901302814483643\n",
      "Epoch: 2, Batch number: 38506, Loss: 6.947977542877197\n",
      "Epoch: 2, Batch number: 38606, Loss: 6.8539934158325195\n",
      "Epoch: 2, Batch number: 38706, Loss: 6.881092548370361\n",
      "Epoch: 2, Batch number: 38806, Loss: 6.8168840408325195\n",
      "Epoch: 2, Batch number: 38906, Loss: 6.800664901733398\n",
      "Epoch: 2, Batch number: 39006, Loss: 6.871983051300049\n",
      "Epoch: 2, Batch number: 39106, Loss: 7.010468482971191\n",
      "Epoch: 2, Batch number: 39206, Loss: 6.919120788574219\n",
      "Epoch: 2, Batch number: 39306, Loss: 7.072269439697266\n",
      "Epoch: 2, Batch number: 39406, Loss: 6.7762675285339355\n",
      "Epoch: 2, Batch number: 39506, Loss: 6.9892897605896\n",
      "Epoch: 2, Batch number: 39606, Loss: 6.875398635864258\n",
      "Epoch: 2, Batch number: 39706, Loss: 6.765044689178467\n",
      "Epoch: 2, Batch number: 39806, Loss: 6.73051118850708\n",
      "Epoch: 2, Batch number: 39906, Loss: 6.936948776245117\n",
      "Epoch: 2, Batch number: 40006, Loss: 6.937844753265381\n",
      "Epoch: 2, Batch number: 40106, Loss: 6.850675582885742\n",
      "Epoch: 2, Batch number: 40206, Loss: 6.961792945861816\n",
      "Epoch: 2, Batch number: 40306, Loss: 6.59705114364624\n",
      "Epoch: 2, Batch number: 40406, Loss: 6.687140941619873\n",
      "Epoch: 2, Batch number: 40506, Loss: 7.063483715057373\n",
      "Epoch: 2, Batch number: 40606, Loss: 6.772165298461914\n",
      "Epoch: 2, Batch number: 40706, Loss: 6.990035533905029\n",
      "Epoch: 2, Batch number: 40806, Loss: 6.798427581787109\n",
      "Epoch: 2, Batch number: 40906, Loss: 6.876441955566406\n",
      "Epoch: 2, Batch number: 41006, Loss: 7.0370001792907715\n",
      "Epoch: 2, Batch number: 41106, Loss: 6.9145307540893555\n",
      "Epoch: 2, Batch number: 41206, Loss: 6.564455032348633\n",
      "Epoch: 2, Batch number: 41306, Loss: 6.7228546142578125\n",
      "Epoch: 2, Batch number: 41406, Loss: 7.06006383895874\n",
      "Epoch: 2, Batch number: 41506, Loss: 6.821925163269043\n",
      "Epoch: 2, Batch number: 41606, Loss: 6.842219352722168\n",
      "Epoch: 2, Batch number: 41706, Loss: 6.947601318359375\n",
      "Epoch: 2, Batch number: 41806, Loss: 6.820223808288574\n",
      "Epoch: 2, Batch number: 41906, Loss: 6.8469929695129395\n",
      "Epoch: 2, Batch number: 42006, Loss: 6.975151062011719\n",
      "Epoch: 2, Batch number: 42106, Loss: 7.003120422363281\n",
      "Epoch: 2, Batch number: 42206, Loss: 7.029923439025879\n",
      "Epoch: 2, Batch number: 42306, Loss: 6.695055961608887\n",
      "Epoch: 2, Batch number: 42406, Loss: 6.942541122436523\n",
      "Epoch: 2, Batch number: 42506, Loss: 6.9994025230407715\n",
      "Epoch: 2, Batch number: 42606, Loss: 7.013418197631836\n",
      "Epoch: 2, Batch number: 42706, Loss: 7.0868000984191895\n",
      "Epoch: 2, Batch number: 42806, Loss: 6.973416328430176\n",
      "Epoch: 2, Batch number: 42906, Loss: 6.998854160308838\n",
      "Epoch: 2, Batch number: 43006, Loss: 6.940427780151367\n",
      "Epoch: 2, Batch number: 43106, Loss: 7.063762187957764\n",
      "Epoch: 2, Batch number: 43206, Loss: 6.863290786743164\n",
      "Epoch: 2, Batch number: 43306, Loss: 6.873125076293945\n",
      "Epoch: 2, Batch number: 43406, Loss: 6.7485480308532715\n",
      "Epoch: 2, Batch number: 43506, Loss: 6.728051662445068\n",
      "Epoch: 2, Batch number: 43606, Loss: 6.736447811126709\n",
      "Epoch: 2, Batch number: 43706, Loss: 6.654574394226074\n",
      "Epoch: 2, Batch number: 43806, Loss: 6.826725006103516\n",
      "Epoch: 2, Batch number: 43906, Loss: 6.803292751312256\n",
      "Epoch: 2, Batch number: 44006, Loss: 6.914085388183594\n",
      "Epoch: 2, Batch number: 44106, Loss: 7.014740943908691\n",
      "Epoch: 2, Batch number: 44206, Loss: 6.821382522583008\n",
      "Epoch: 2, Batch number: 44306, Loss: 6.70152473449707\n",
      "Epoch: 2, Batch number: 44406, Loss: 6.887369155883789\n",
      "Epoch: 2, Batch number: 44506, Loss: 6.764258861541748\n",
      "Epoch: 2, Batch number: 44606, Loss: 6.681328773498535\n",
      "Epoch: 2, Batch number: 44706, Loss: 6.839711666107178\n",
      "Epoch: 2, Batch number: 44806, Loss: 7.047565937042236\n",
      "Epoch: 2, Batch number: 44906, Loss: 7.042438507080078\n",
      "Epoch: 2, Batch number: 45006, Loss: 6.829784393310547\n",
      "Epoch: 2, Batch number: 45106, Loss: 6.769965171813965\n",
      "Epoch: 2, Batch number: 45206, Loss: 6.554935455322266\n",
      "Epoch: 2, Batch number: 45306, Loss: 7.015633583068848\n",
      "Epoch: 2, Batch number: 45406, Loss: 7.016841888427734\n",
      "Epoch: 2, Batch number: 45506, Loss: 6.826179027557373\n",
      "Epoch: 2, Batch number: 45606, Loss: 6.786379337310791\n",
      "Epoch: 2, Batch number: 45706, Loss: 6.889566898345947\n",
      "Epoch: 2, Batch number: 45806, Loss: 6.780763626098633\n",
      "Epoch: 2, Batch number: 45906, Loss: 7.1708478927612305\n",
      "Epoch: 2, Batch number: 46006, Loss: 6.88677978515625\n",
      "Epoch: 2, Batch number: 46106, Loss: 6.50581693649292\n",
      "Epoch: 2, Batch number: 46206, Loss: 7.098272323608398\n",
      "Epoch: 2, Batch number: 46306, Loss: 6.862241268157959\n",
      "Epoch: 2, Batch number: 46406, Loss: 6.977475643157959\n",
      "Epoch: 2, Batch number: 46506, Loss: 6.872157573699951\n",
      "Epoch: 2, Batch number: 46606, Loss: 6.762217998504639\n",
      "Epoch: 2, Batch number: 46706, Loss: 7.039808750152588\n",
      "Epoch: 2, Batch number: 46806, Loss: 6.852514743804932\n",
      "Epoch: 2, Batch number: 46906, Loss: 6.958009243011475\n",
      "Epoch: 2, Batch number: 47006, Loss: 6.995314121246338\n",
      "Epoch: 2, Batch number: 47106, Loss: 6.787428379058838\n",
      "Epoch: 2, Batch number: 47206, Loss: 6.846138954162598\n",
      "Epoch: 2, Batch number: 47306, Loss: 7.09624719619751\n",
      "Epoch: 2, Batch number: 47406, Loss: 7.024716854095459\n",
      "Epoch: 2, Batch number: 47506, Loss: 6.529848575592041\n",
      "Epoch: 2, Batch number: 47606, Loss: 7.089920520782471\n",
      "Epoch: 2, Batch number: 47706, Loss: 6.937419891357422\n",
      "Epoch: 2, Batch number: 47806, Loss: 6.733147621154785\n",
      "Epoch: 2, Batch number: 47906, Loss: 6.986502170562744\n",
      "Epoch: 2, Batch number: 48006, Loss: 7.030567169189453\n",
      "Epoch: 2, Batch number: 48106, Loss: 7.049315929412842\n",
      "Epoch: 2, Batch number: 48206, Loss: 6.774318218231201\n",
      "Epoch: 2, Batch number: 48306, Loss: 6.838611602783203\n",
      "Epoch: 2, Batch number: 48406, Loss: 7.02144193649292\n",
      "Epoch: 2, Batch number: 48506, Loss: 6.772696018218994\n",
      "Epoch: 2, Batch number: 48606, Loss: 6.5838541984558105\n",
      "Epoch: 2, Batch number: 48706, Loss: 6.948068141937256\n",
      "Epoch: 2, Batch number: 48806, Loss: 6.828324794769287\n",
      "Epoch: 2, Batch number: 48906, Loss: 7.050620079040527\n",
      "Epoch: 2, Batch number: 49006, Loss: 6.682737827301025\n",
      "Epoch: 2, Batch number: 49106, Loss: 6.712901592254639\n",
      "Epoch: 2, Batch number: 49206, Loss: 6.846712112426758\n",
      "Epoch: 2, Batch number: 49306, Loss: 7.0270280838012695\n",
      "Epoch: 2, Batch number: 49406, Loss: 6.936172962188721\n",
      "Epoch: 2, Batch number: 49506, Loss: 6.72881555557251\n",
      "Epoch: 2, Batch number: 49606, Loss: 6.831436634063721\n",
      "Epoch: 2, Batch number: 49706, Loss: 6.977687358856201\n",
      "Epoch: 2, Batch number: 49806, Loss: 6.740198135375977\n",
      "Epoch: 2, Batch number: 49906, Loss: 7.066812515258789\n",
      "Epoch: 2, Batch number: 50006, Loss: 6.946025371551514\n",
      "Epoch: 2, Batch number: 50106, Loss: 6.765927791595459\n",
      "Epoch: 2, Batch number: 50206, Loss: 6.75335168838501\n",
      "Epoch: 2, Batch number: 50306, Loss: 6.970351219177246\n",
      "Epoch: 2, Batch number: 50406, Loss: 6.908454895019531\n",
      "Epoch: 2, Batch number: 50506, Loss: 6.857388019561768\n",
      "Epoch: 2, Batch number: 50606, Loss: 6.832027912139893\n",
      "Epoch: 2, Batch number: 50706, Loss: 6.884794235229492\n",
      "Epoch: 2, Batch number: 50806, Loss: 6.8534674644470215\n",
      "Epoch: 2, Batch number: 50906, Loss: 7.094176292419434\n",
      "Epoch: 2, Batch number: 51006, Loss: 6.861187934875488\n",
      "Epoch: 2, Batch number: 51106, Loss: 6.754947662353516\n",
      "Epoch: 2, Batch number: 51206, Loss: 7.023994445800781\n",
      "Epoch: 2, Batch number: 51306, Loss: 6.893367767333984\n",
      "Epoch: 2, Batch number: 51406, Loss: 6.896237373352051\n",
      "Epoch: 2, Batch number: 51506, Loss: 6.879302978515625\n",
      "Epoch: 2, Batch number: 51606, Loss: 6.803513526916504\n",
      "Epoch: 2, Batch number: 51706, Loss: 6.572747707366943\n",
      "Epoch: 2, Batch number: 51806, Loss: 6.850432872772217\n",
      "Epoch: 2, Batch number: 51906, Loss: 7.026604652404785\n",
      "Epoch: 2, Batch number: 52006, Loss: 7.030566692352295\n",
      "Epoch: 2, Batch number: 52106, Loss: 6.887970924377441\n",
      "Epoch: 2, Batch number: 52206, Loss: 6.844526290893555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 52306, Loss: 6.992856502532959\n",
      "Epoch: 2, Batch number: 52406, Loss: 6.848556041717529\n",
      "Epoch: 2, Batch number: 52506, Loss: 6.793032646179199\n",
      "Epoch: 2, Batch number: 52606, Loss: 6.89056396484375\n",
      "Epoch: 2, Batch number: 52706, Loss: 6.890944957733154\n",
      "Epoch: 2, Batch number: 52806, Loss: 6.917304515838623\n",
      "Epoch: 2, Batch number: 52906, Loss: 6.868261337280273\n",
      "Epoch: 2, Batch number: 53006, Loss: 7.0128326416015625\n",
      "Epoch: 2, Batch number: 53106, Loss: 6.831396102905273\n",
      "Epoch: 2, Batch number: 53206, Loss: 6.790940284729004\n",
      "Epoch: 2, Batch number: 53306, Loss: 6.887986183166504\n",
      "Epoch: 2, Batch number: 53406, Loss: 6.781782150268555\n",
      "Epoch: 2, Batch number: 53506, Loss: 6.967226982116699\n",
      "Epoch: 2, Batch number: 53606, Loss: 6.769846439361572\n",
      "Epoch: 2, Batch number: 53706, Loss: 6.890647888183594\n",
      "Epoch: 2, Batch number: 53806, Loss: 6.974177837371826\n",
      "Epoch: 2, Batch number: 53906, Loss: 6.963809013366699\n",
      "Epoch: 2, Batch number: 54006, Loss: 7.100035667419434\n",
      "Epoch: 2, Batch number: 54106, Loss: 6.971465110778809\n",
      "Epoch: 2, Batch number: 54206, Loss: 6.608218193054199\n",
      "Epoch: 2, Batch number: 54306, Loss: 6.994043827056885\n",
      "Epoch: 2, Batch number: 54406, Loss: 6.829020023345947\n",
      "Epoch: 2, Batch number: 54506, Loss: 6.791102886199951\n",
      "Epoch: 2, Batch number: 54606, Loss: 6.721371650695801\n",
      "Epoch: 2, Batch number: 54706, Loss: 6.857311725616455\n",
      "Epoch: 2, Batch number: 54806, Loss: 6.910959243774414\n",
      "Epoch: 2, Batch number: 54906, Loss: 6.898999214172363\n",
      "Epoch: 2, Batch number: 55006, Loss: 6.767269611358643\n",
      "Epoch: 2, Batch number: 55106, Loss: 6.961809158325195\n",
      "Epoch: 2, Batch number: 55206, Loss: 6.7619709968566895\n",
      "Epoch: 2, Batch number: 55306, Loss: 7.202677249908447\n",
      "Epoch: 2, Batch number: 55406, Loss: 6.744278907775879\n",
      "Epoch: 2, Batch number: 55506, Loss: 6.881988525390625\n",
      "Epoch: 2, Batch number: 55606, Loss: 6.727621078491211\n",
      "Epoch: 2, Batch number: 55706, Loss: 6.747045516967773\n",
      "Epoch: 2, Batch number: 55806, Loss: 6.686997890472412\n",
      "Epoch: 2, Batch number: 55906, Loss: 6.804851055145264\n",
      "Epoch: 2, Batch number: 56006, Loss: 6.734726905822754\n",
      "Epoch: 2, Batch number: 56106, Loss: 6.639615058898926\n",
      "Epoch: 2, Batch number: 56206, Loss: 6.917613506317139\n",
      "Epoch: 2, Batch number: 56306, Loss: 7.060724258422852\n",
      "Epoch: 2, Batch number: 56406, Loss: 7.193742275238037\n",
      "Epoch: 2, Batch number: 56506, Loss: 7.018310546875\n",
      "Epoch: 2, Batch number: 56606, Loss: 6.7709550857543945\n",
      "Epoch: 2, Batch number: 56706, Loss: 6.836000442504883\n",
      "Epoch: 2, Batch number: 56806, Loss: 7.002933025360107\n",
      "Epoch: 2, Batch number: 56906, Loss: 6.925591945648193\n",
      "Epoch: 2, Batch number: 57006, Loss: 6.687479496002197\n",
      "Epoch: 2, Batch number: 57106, Loss: 6.668416500091553\n",
      "Epoch: 2, Batch number: 57206, Loss: 6.749909400939941\n",
      "Epoch: 2, Batch number: 57306, Loss: 7.06056022644043\n",
      "Epoch: 2, Batch number: 57406, Loss: 6.821194171905518\n",
      "Epoch: 2, Batch number: 57506, Loss: 6.925703048706055\n",
      "Epoch: 2, Batch number: 57606, Loss: 6.872437477111816\n",
      "Epoch: 2, Batch number: 57706, Loss: 6.850348949432373\n",
      "Epoch: 2, Batch number: 57806, Loss: 6.552425861358643\n",
      "Epoch: 2, Batch number: 57906, Loss: 6.965005874633789\n",
      "Epoch: 2, Batch number: 58006, Loss: 6.7347798347473145\n",
      "Epoch: 2, Batch number: 58106, Loss: 6.7742486000061035\n",
      "Epoch: 2, Batch number: 58206, Loss: 6.716948986053467\n",
      "Epoch: 2, Batch number: 58306, Loss: 6.766721248626709\n",
      "Epoch: 2, Batch number: 58406, Loss: 6.9973859786987305\n",
      "Epoch: 2, Batch number: 58506, Loss: 6.900796890258789\n",
      "Epoch: 2, Batch number: 58606, Loss: 6.887197494506836\n",
      "Epoch: 2, Batch number: 58706, Loss: 6.982088565826416\n",
      "Epoch: 2, Batch number: 58806, Loss: 6.851272106170654\n",
      "Epoch: 2, Batch number: 58906, Loss: 6.798441410064697\n",
      "Epoch: 2, Batch number: 59006, Loss: 7.0180840492248535\n",
      "Epoch: 2, Batch number: 59106, Loss: 6.788856029510498\n",
      "Epoch: 2, Batch number: 59206, Loss: 6.981163024902344\n",
      "Epoch: 2, Batch number: 59306, Loss: 7.094930171966553\n",
      "Epoch: 2, Batch number: 59406, Loss: 6.743494033813477\n",
      "Epoch: 2, Batch number: 59506, Loss: 6.772665977478027\n",
      "Epoch: 2, Batch number: 59606, Loss: 6.964238166809082\n",
      "Epoch: 2, Batch number: 59706, Loss: 6.802631378173828\n",
      "Epoch: 2, Batch number: 59806, Loss: 6.760383129119873\n",
      "Epoch: 2, Batch number: 59906, Loss: 6.505753040313721\n",
      "Epoch: 2, Batch number: 60006, Loss: 7.025381565093994\n",
      "Epoch: 2, Batch number: 60106, Loss: 6.900470733642578\n",
      "Epoch: 2, Batch number: 60206, Loss: 6.846067905426025\n",
      "Epoch: 2, Batch number: 60306, Loss: 6.953462600708008\n",
      "Epoch: 2, Batch number: 60406, Loss: 6.871243953704834\n",
      "Epoch: 2, Batch number: 60506, Loss: 6.582118034362793\n",
      "Epoch: 2, Batch number: 60606, Loss: 6.661458492279053\n",
      "Epoch: 2, Batch number: 60706, Loss: 6.996171474456787\n",
      "Epoch: 2, Batch number: 60806, Loss: 7.075228214263916\n",
      "Epoch: 2, Batch number: 60906, Loss: 6.904932975769043\n",
      "Epoch: 2, Batch number: 61006, Loss: 6.783074378967285\n",
      "Epoch: 2, Batch number: 61106, Loss: 6.616353988647461\n",
      "Epoch: 2, Batch number: 61206, Loss: 6.7717695236206055\n",
      "Epoch: 2, Batch number: 61306, Loss: 6.925264358520508\n",
      "Epoch: 2, Batch number: 61406, Loss: 6.895627498626709\n",
      "Epoch: 2, Batch number: 61506, Loss: 7.042695999145508\n",
      "Epoch: 2, Batch number: 61606, Loss: 6.80894136428833\n",
      "Epoch: 2, Batch number: 61706, Loss: 7.0298967361450195\n",
      "Epoch: 2, Batch number: 61806, Loss: 6.689972400665283\n",
      "Epoch: 2, Batch number: 61906, Loss: 6.892816066741943\n",
      "Epoch: 2, Batch number: 62006, Loss: 6.940812587738037\n",
      "Epoch: 2, Batch number: 62106, Loss: 6.917265892028809\n",
      "Epoch: 2, Batch number: 62206, Loss: 6.628732204437256\n",
      "Epoch: 2, Batch number: 62306, Loss: 7.004136562347412\n",
      "Epoch: 2, Batch number: 62406, Loss: 6.944428443908691\n",
      "Epoch: 2, Batch number: 62506, Loss: 6.693564414978027\n",
      "Epoch: 2, Batch number: 62606, Loss: 6.6469855308532715\n",
      "Epoch: 2, Batch number: 62706, Loss: 6.773372650146484\n",
      "Epoch: 2, Batch number: 62806, Loss: 6.899590492248535\n",
      "Epoch: 2, Batch number: 62906, Loss: 6.791993141174316\n",
      "Epoch: 2, Batch number: 63006, Loss: 6.6011223793029785\n",
      "Epoch: 2, Batch number: 63106, Loss: 6.77402925491333\n",
      "Epoch: 2, Batch number: 63206, Loss: 7.308593273162842\n",
      "Epoch: 2, Batch number: 63306, Loss: 6.975016117095947\n",
      "Epoch: 2, Batch number: 63406, Loss: 6.7100090980529785\n",
      "Epoch: 2, Batch number: 63506, Loss: 6.877714157104492\n",
      "Epoch: 2, Batch number: 63606, Loss: 7.127586841583252\n",
      "Epoch: 2, Batch number: 63706, Loss: 7.112559795379639\n",
      "Epoch: 2, Batch number: 63806, Loss: 6.972367286682129\n",
      "Epoch: 2, Batch number: 63906, Loss: 6.884366512298584\n",
      "Epoch: 2, Batch number: 64006, Loss: 6.888213157653809\n",
      "Epoch: 2, Batch number: 64106, Loss: 6.909687042236328\n",
      "Epoch: 2, Batch number: 64206, Loss: 6.842467308044434\n",
      "Epoch: 2, Batch number: 64306, Loss: 6.9678850173950195\n",
      "Epoch: 2, Batch number: 64406, Loss: 6.796390056610107\n",
      "Epoch: 2, Batch number: 64506, Loss: 6.808477878570557\n",
      "Epoch: 2, Batch number: 64606, Loss: 6.859531402587891\n",
      "Epoch: 2, Batch number: 64706, Loss: 7.106082439422607\n",
      "Epoch: 2, Batch number: 64806, Loss: 6.953312873840332\n",
      "Epoch: 2, Batch number: 64906, Loss: 6.872905254364014\n",
      "Epoch: 2, Batch number: 65006, Loss: 6.8241963386535645\n",
      "Epoch: 2, Batch number: 65106, Loss: 6.692894458770752\n",
      "Epoch: 2, Batch number: 65206, Loss: 6.663807392120361\n",
      "Epoch: 2, Batch number: 65306, Loss: 7.147465705871582\n",
      "Epoch: 2, Batch number: 65406, Loss: 6.870488166809082\n",
      "Epoch: 2, Batch number: 65506, Loss: 6.981414318084717\n",
      "Epoch: 2, Batch number: 65606, Loss: 6.995436191558838\n",
      "Epoch: 2, Batch number: 65706, Loss: 6.823337078094482\n",
      "Epoch: 2, Batch number: 65806, Loss: 6.500351428985596\n",
      "Epoch: 2, Batch number: 65906, Loss: 6.79355525970459\n",
      "Epoch: 2, Batch number: 66006, Loss: 6.929867267608643\n",
      "Epoch: 2, Batch number: 66106, Loss: 6.722108840942383\n",
      "Epoch: 2, Batch number: 66206, Loss: 7.036920547485352\n",
      "Epoch: 2, Batch number: 66306, Loss: 6.5356903076171875\n",
      "Epoch: 2, Batch number: 66406, Loss: 6.782001495361328\n",
      "Epoch: 2, Batch number: 66506, Loss: 6.881960391998291\n",
      "Epoch: 2, Batch number: 66606, Loss: 7.077659606933594\n",
      "Epoch: 2, Batch number: 66706, Loss: 6.87172794342041\n",
      "Epoch: 2, Batch number: 66806, Loss: 6.72258186340332\n",
      "Epoch: 2, Batch number: 66906, Loss: 6.885861396789551\n",
      "Epoch: 2, Batch number: 67006, Loss: 6.922795295715332\n",
      "Epoch: 2, Batch number: 67106, Loss: 6.979756832122803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 11.288886070251465\n",
      "Epoch: 1, Batch number: 100, Loss: 10.439794540405273\n",
      "Epoch: 1, Batch number: 200, Loss: 10.05953598022461\n",
      "Epoch: 1, Batch number: 300, Loss: 9.823948860168457\n",
      "Epoch: 1, Batch number: 400, Loss: 9.574867248535156\n",
      "Epoch: 1, Batch number: 500, Loss: 9.330179214477539\n",
      "Epoch: 1, Batch number: 600, Loss: 9.363945007324219\n",
      "Epoch: 1, Batch number: 700, Loss: 9.224475860595703\n",
      "Epoch: 1, Batch number: 800, Loss: 9.158244132995605\n",
      "Epoch: 1, Batch number: 900, Loss: 8.82307243347168\n",
      "Epoch: 1, Batch number: 1000, Loss: 8.593598365783691\n",
      "Epoch: 1, Batch number: 1100, Loss: 8.56874942779541\n",
      "Epoch: 1, Batch number: 1200, Loss: 8.678674697875977\n",
      "Epoch: 1, Batch number: 1300, Loss: 8.344133377075195\n",
      "Epoch: 1, Batch number: 1400, Loss: 8.54561996459961\n",
      "Epoch: 1, Batch number: 1500, Loss: 8.107950210571289\n",
      "Epoch: 1, Batch number: 1600, Loss: 8.167169570922852\n",
      "Epoch: 1, Batch number: 1700, Loss: 8.114290237426758\n",
      "Epoch: 1, Batch number: 1800, Loss: 7.962368488311768\n",
      "Epoch: 1, Batch number: 1900, Loss: 8.207857131958008\n",
      "Epoch: 1, Batch number: 2000, Loss: 8.059453964233398\n",
      "Epoch: 1, Batch number: 2100, Loss: 8.17133617401123\n",
      "Epoch: 1, Batch number: 2200, Loss: 8.075153350830078\n",
      "Epoch: 1, Batch number: 2300, Loss: 7.779566287994385\n",
      "Epoch: 1, Batch number: 2400, Loss: 7.881053924560547\n",
      "Epoch: 1, Batch number: 2500, Loss: 7.950665473937988\n",
      "Epoch: 1, Batch number: 2600, Loss: 7.848119735717773\n",
      "Epoch: 1, Batch number: 2700, Loss: 7.893894672393799\n",
      "Epoch: 1, Batch number: 2800, Loss: 7.545893669128418\n",
      "Epoch: 1, Batch number: 2900, Loss: 7.824826717376709\n",
      "Epoch: 1, Batch number: 3000, Loss: 7.639137268066406\n",
      "Epoch: 1, Batch number: 3100, Loss: 7.727108955383301\n",
      "Epoch: 1, Batch number: 3200, Loss: 7.839709281921387\n",
      "Epoch: 1, Batch number: 3300, Loss: 7.645840167999268\n",
      "Epoch: 1, Batch number: 3400, Loss: 7.593940258026123\n",
      "Epoch: 1, Batch number: 3500, Loss: 7.679920673370361\n",
      "Epoch: 1, Batch number: 3600, Loss: 7.872904300689697\n",
      "Epoch: 1, Batch number: 3700, Loss: 7.735294818878174\n",
      "Epoch: 1, Batch number: 3800, Loss: 7.889394760131836\n",
      "Epoch: 1, Batch number: 3900, Loss: 7.704705238342285\n",
      "Epoch: 1, Batch number: 4000, Loss: 7.596077919006348\n",
      "Epoch: 1, Batch number: 4100, Loss: 7.8429131507873535\n",
      "Epoch: 1, Batch number: 4200, Loss: 7.830745697021484\n",
      "Epoch: 1, Batch number: 4300, Loss: 7.467105865478516\n",
      "Epoch: 1, Batch number: 4400, Loss: 7.459853172302246\n",
      "Epoch: 1, Batch number: 4500, Loss: 7.60873556137085\n",
      "Epoch: 1, Batch number: 4600, Loss: 7.627410888671875\n",
      "Epoch: 1, Batch number: 4700, Loss: 7.688004016876221\n",
      "Epoch: 1, Batch number: 4800, Loss: 7.71594762802124\n",
      "Epoch: 1, Batch number: 4900, Loss: 7.73859167098999\n",
      "Epoch: 1, Batch number: 5000, Loss: 7.708988666534424\n",
      "Epoch: 1, Batch number: 5100, Loss: 7.698289394378662\n",
      "Epoch: 1, Batch number: 5200, Loss: 7.444375038146973\n",
      "Epoch: 1, Batch number: 5300, Loss: 7.54682731628418\n",
      "Epoch: 1, Batch number: 5400, Loss: 7.654306411743164\n",
      "Epoch: 1, Batch number: 5500, Loss: 7.237695693969727\n",
      "Epoch: 1, Batch number: 5600, Loss: 7.832570552825928\n",
      "Epoch: 1, Batch number: 5700, Loss: 7.739701271057129\n",
      "Epoch: 1, Batch number: 5800, Loss: 7.794294834136963\n",
      "Epoch: 1, Batch number: 5900, Loss: 7.707277297973633\n",
      "Epoch: 1, Batch number: 6000, Loss: 7.42728328704834\n",
      "Epoch: 1, Batch number: 6100, Loss: 7.663098335266113\n",
      "Epoch: 1, Batch number: 6200, Loss: 7.742408752441406\n",
      "Epoch: 1, Batch number: 6300, Loss: 7.194840431213379\n",
      "Epoch: 1, Batch number: 6400, Loss: 7.736014366149902\n",
      "Epoch: 1, Batch number: 6500, Loss: 7.10121488571167\n",
      "Epoch: 1, Batch number: 6600, Loss: 7.54826021194458\n",
      "Epoch: 1, Batch number: 6700, Loss: 7.768040657043457\n",
      "Epoch: 1, Batch number: 6800, Loss: 7.558547019958496\n",
      "Epoch: 1, Batch number: 6900, Loss: 7.45954704284668\n",
      "Epoch: 1, Batch number: 7000, Loss: 7.709653854370117\n",
      "Epoch: 1, Batch number: 7100, Loss: 7.2996954917907715\n",
      "Epoch: 1, Batch number: 7200, Loss: 7.515032768249512\n",
      "Epoch: 1, Batch number: 7300, Loss: 7.545623302459717\n",
      "Epoch: 1, Batch number: 7400, Loss: 7.587774276733398\n",
      "Epoch: 1, Batch number: 7500, Loss: 7.553681373596191\n",
      "Epoch: 1, Batch number: 7600, Loss: 7.2334699630737305\n",
      "Epoch: 1, Batch number: 7700, Loss: 7.643401622772217\n",
      "Epoch: 1, Batch number: 7800, Loss: 7.431875705718994\n",
      "Epoch: 1, Batch number: 7900, Loss: 7.392328262329102\n",
      "Epoch: 1, Batch number: 8000, Loss: 7.310105323791504\n",
      "Epoch: 1, Batch number: 8100, Loss: 7.686012268066406\n",
      "Epoch: 1, Batch number: 8200, Loss: 7.472311973571777\n",
      "Epoch: 1, Batch number: 8300, Loss: 7.596263408660889\n",
      "Epoch: 1, Batch number: 8400, Loss: 7.479097366333008\n",
      "Epoch: 1, Batch number: 8500, Loss: 7.233503818511963\n",
      "Epoch: 1, Batch number: 8600, Loss: 7.325944900512695\n",
      "Epoch: 1, Batch number: 8700, Loss: 7.498046398162842\n",
      "Epoch: 1, Batch number: 8800, Loss: 7.534346580505371\n",
      "Epoch: 1, Batch number: 8900, Loss: 7.40781307220459\n",
      "Epoch: 1, Batch number: 9000, Loss: 7.473259925842285\n",
      "Epoch: 1, Batch number: 9100, Loss: 7.61122989654541\n",
      "Epoch: 1, Batch number: 9200, Loss: 7.33847188949585\n",
      "Epoch: 1, Batch number: 9300, Loss: 7.578374862670898\n",
      "Epoch: 1, Batch number: 9400, Loss: 7.408113956451416\n",
      "Epoch: 1, Batch number: 9500, Loss: 7.428205966949463\n",
      "Epoch: 1, Batch number: 9600, Loss: 7.367839813232422\n",
      "Epoch: 1, Batch number: 9700, Loss: 7.227412700653076\n",
      "Epoch: 1, Batch number: 9800, Loss: 7.316081523895264\n",
      "Epoch: 1, Batch number: 9900, Loss: 7.711331367492676\n",
      "Epoch: 1, Batch number: 10000, Loss: 7.367583751678467\n",
      "Epoch: 1, Batch number: 10100, Loss: 7.523727893829346\n",
      "Epoch: 1, Batch number: 10200, Loss: 7.368451118469238\n",
      "Epoch: 1, Batch number: 10300, Loss: 7.2692155838012695\n",
      "Epoch: 1, Batch number: 10400, Loss: 7.147775650024414\n",
      "Epoch: 1, Batch number: 10500, Loss: 7.426056385040283\n",
      "Epoch: 1, Batch number: 10600, Loss: 7.523705959320068\n",
      "Epoch: 1, Batch number: 10700, Loss: 7.40620231628418\n",
      "Epoch: 1, Batch number: 10800, Loss: 7.289721488952637\n",
      "Epoch: 1, Batch number: 10900, Loss: 6.949521064758301\n",
      "Epoch: 1, Batch number: 11000, Loss: 7.50360631942749\n",
      "Epoch: 1, Batch number: 11100, Loss: 7.296234130859375\n",
      "Epoch: 1, Batch number: 11200, Loss: 7.359404563903809\n",
      "Epoch: 1, Batch number: 11300, Loss: 7.119937896728516\n",
      "Epoch: 1, Batch number: 11400, Loss: 7.5264573097229\n",
      "Epoch: 1, Batch number: 11500, Loss: 7.21092414855957\n",
      "Epoch: 1, Batch number: 11600, Loss: 7.394153594970703\n",
      "Epoch: 1, Batch number: 11700, Loss: 7.404003143310547\n",
      "Epoch: 1, Batch number: 11800, Loss: 7.302148818969727\n",
      "Epoch: 1, Batch number: 11900, Loss: 7.631576061248779\n",
      "Epoch: 1, Batch number: 12000, Loss: 7.434311389923096\n",
      "Epoch: 1, Batch number: 12100, Loss: 7.373542308807373\n",
      "Epoch: 1, Batch number: 12200, Loss: 7.329983711242676\n",
      "Epoch: 1, Batch number: 12300, Loss: 7.5727128982543945\n",
      "Epoch: 1, Batch number: 12400, Loss: 7.175915241241455\n",
      "Epoch: 1, Batch number: 12500, Loss: 7.28309965133667\n",
      "Epoch: 1, Batch number: 12600, Loss: 7.342004299163818\n",
      "Epoch: 1, Batch number: 12700, Loss: 7.300072193145752\n",
      "Epoch: 1, Batch number: 12800, Loss: 7.283383846282959\n",
      "Epoch: 1, Batch number: 12900, Loss: 7.284924507141113\n",
      "Epoch: 1, Batch number: 13000, Loss: 7.444183349609375\n",
      "Epoch: 1, Batch number: 13100, Loss: 7.320307731628418\n",
      "Epoch: 1, Batch number: 13200, Loss: 7.364370346069336\n",
      "Epoch: 1, Batch number: 13300, Loss: 7.322850227355957\n",
      "Epoch: 1, Batch number: 13400, Loss: 7.56049108505249\n",
      "Epoch: 1, Batch number: 13500, Loss: 7.110641956329346\n",
      "Epoch: 1, Batch number: 13600, Loss: 7.319885730743408\n",
      "Epoch: 1, Batch number: 13700, Loss: 7.2221999168396\n",
      "Epoch: 1, Batch number: 13800, Loss: 7.538858890533447\n",
      "Epoch: 1, Batch number: 13900, Loss: 7.3951005935668945\n",
      "Epoch: 1, Batch number: 14000, Loss: 7.24711799621582\n",
      "Epoch: 1, Batch number: 14100, Loss: 7.6362080574035645\n",
      "Epoch: 1, Batch number: 14200, Loss: 7.371578216552734\n",
      "Epoch: 1, Batch number: 14300, Loss: 7.282600402832031\n",
      "Epoch: 1, Batch number: 14400, Loss: 7.141274929046631\n",
      "Epoch: 1, Batch number: 14500, Loss: 7.4966607093811035\n",
      "Epoch: 1, Batch number: 14600, Loss: 7.290808200836182\n",
      "Epoch: 1, Batch number: 14700, Loss: 7.406477928161621\n",
      "Epoch: 1, Batch number: 14800, Loss: 7.1458587646484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 14900, Loss: 7.029708385467529\n",
      "Epoch: 1, Batch number: 15000, Loss: 7.344101428985596\n",
      "Epoch: 1, Batch number: 15100, Loss: 7.32731294631958\n",
      "Epoch: 1, Batch number: 15200, Loss: 7.178784370422363\n",
      "Epoch: 1, Batch number: 15300, Loss: 7.408847332000732\n",
      "Epoch: 1, Batch number: 15400, Loss: 7.356213569641113\n",
      "Epoch: 1, Batch number: 15500, Loss: 7.091395854949951\n",
      "Epoch: 1, Batch number: 15600, Loss: 7.362981796264648\n",
      "Epoch: 1, Batch number: 15700, Loss: 7.172654151916504\n",
      "Epoch: 1, Batch number: 15800, Loss: 7.298945903778076\n",
      "Epoch: 1, Batch number: 15900, Loss: 7.404816627502441\n",
      "Epoch: 1, Batch number: 16000, Loss: 7.285478115081787\n",
      "Epoch: 1, Batch number: 16100, Loss: 7.161299228668213\n",
      "Epoch: 1, Batch number: 16200, Loss: 7.286710739135742\n",
      "Epoch: 1, Batch number: 16300, Loss: 7.255690574645996\n",
      "Epoch: 1, Batch number: 16400, Loss: 7.415438652038574\n",
      "Epoch: 1, Batch number: 16500, Loss: 7.301964282989502\n",
      "Epoch: 1, Batch number: 16600, Loss: 7.386495590209961\n",
      "Epoch: 1, Batch number: 16700, Loss: 7.583664417266846\n",
      "Epoch: 1, Batch number: 16800, Loss: 7.196461200714111\n",
      "Epoch: 1, Batch number: 16900, Loss: 7.064485549926758\n",
      "Epoch: 1, Batch number: 17000, Loss: 7.336377143859863\n",
      "Epoch: 1, Batch number: 17100, Loss: 7.372278690338135\n",
      "Epoch: 1, Batch number: 17200, Loss: 7.306148052215576\n",
      "Epoch: 1, Batch number: 17300, Loss: 7.271044731140137\n",
      "Epoch: 1, Batch number: 17400, Loss: 7.470012664794922\n",
      "Epoch: 1, Batch number: 17500, Loss: 7.240650653839111\n",
      "Epoch: 1, Batch number: 17600, Loss: 7.382790565490723\n",
      "Epoch: 1, Batch number: 17700, Loss: 7.508871555328369\n",
      "Epoch: 1, Batch number: 17800, Loss: 7.160592555999756\n",
      "Epoch: 1, Batch number: 17900, Loss: 7.399141311645508\n",
      "Epoch: 1, Batch number: 18000, Loss: 7.277593612670898\n",
      "Epoch: 1, Batch number: 18100, Loss: 7.391390323638916\n",
      "Epoch: 1, Batch number: 18200, Loss: 7.232926845550537\n",
      "Epoch: 1, Batch number: 18300, Loss: 7.43332576751709\n",
      "Epoch: 1, Batch number: 18400, Loss: 7.276037216186523\n",
      "Epoch: 1, Batch number: 18500, Loss: 7.489681243896484\n",
      "Epoch: 1, Batch number: 18600, Loss: 7.255953311920166\n",
      "Epoch: 1, Batch number: 18700, Loss: 7.455615997314453\n",
      "Epoch: 1, Batch number: 18800, Loss: 7.187189102172852\n",
      "Epoch: 1, Batch number: 18900, Loss: 7.043031692504883\n",
      "Epoch: 1, Batch number: 19000, Loss: 7.1062846183776855\n",
      "Epoch: 1, Batch number: 19100, Loss: 7.59059476852417\n",
      "Epoch: 1, Batch number: 19200, Loss: 7.517173767089844\n",
      "Epoch: 1, Batch number: 19300, Loss: 7.211039066314697\n",
      "Epoch: 1, Batch number: 19400, Loss: 7.254923343658447\n",
      "Epoch: 1, Batch number: 19500, Loss: 7.139004230499268\n",
      "Epoch: 1, Batch number: 19600, Loss: 7.298967361450195\n",
      "Epoch: 1, Batch number: 19700, Loss: 7.392218589782715\n",
      "Epoch: 1, Batch number: 19800, Loss: 7.298012733459473\n",
      "Epoch: 1, Batch number: 19900, Loss: 7.48785924911499\n",
      "Epoch: 1, Batch number: 20000, Loss: 7.328481674194336\n",
      "Epoch: 1, Batch number: 20100, Loss: 7.225139141082764\n",
      "Epoch: 1, Batch number: 20200, Loss: 7.355805397033691\n",
      "Epoch: 1, Batch number: 20300, Loss: 7.145399570465088\n",
      "Epoch: 1, Batch number: 20400, Loss: 7.312967300415039\n",
      "Epoch: 1, Batch number: 20500, Loss: 7.449555397033691\n",
      "Epoch: 1, Batch number: 20600, Loss: 6.91418981552124\n",
      "Epoch: 1, Batch number: 20700, Loss: 7.153200149536133\n",
      "Epoch: 1, Batch number: 20800, Loss: 7.148504257202148\n",
      "Epoch: 1, Batch number: 20900, Loss: 7.095408916473389\n",
      "Epoch: 1, Batch number: 21000, Loss: 7.336888790130615\n",
      "Epoch: 1, Batch number: 21100, Loss: 7.361958980560303\n",
      "Epoch: 1, Batch number: 21200, Loss: 7.436774253845215\n",
      "Epoch: 1, Batch number: 21300, Loss: 7.129976749420166\n",
      "Epoch: 1, Batch number: 21400, Loss: 7.268978595733643\n",
      "Epoch: 1, Batch number: 21500, Loss: 7.303949356079102\n",
      "Epoch: 1, Batch number: 21600, Loss: 7.504283428192139\n",
      "Epoch: 1, Batch number: 21700, Loss: 7.1703782081604\n",
      "Epoch: 1, Batch number: 21800, Loss: 7.3230061531066895\n",
      "Epoch: 1, Batch number: 21900, Loss: 6.955028533935547\n",
      "Epoch: 1, Batch number: 22000, Loss: 7.23150634765625\n",
      "Epoch: 1, Batch number: 22100, Loss: 7.377069473266602\n",
      "Epoch: 1, Batch number: 22200, Loss: 7.193179607391357\n",
      "Epoch: 1, Batch number: 22300, Loss: 7.062524318695068\n",
      "Epoch: 1, Batch number: 22400, Loss: 7.137784481048584\n",
      "Epoch: 1, Batch number: 22500, Loss: 7.143575668334961\n",
      "Epoch: 1, Batch number: 22600, Loss: 7.194175720214844\n",
      "Epoch: 1, Batch number: 22700, Loss: 7.500234603881836\n",
      "Epoch: 1, Batch number: 22800, Loss: 7.293832302093506\n",
      "Epoch: 1, Batch number: 22900, Loss: 7.200353622436523\n",
      "Epoch: 1, Batch number: 23000, Loss: 7.366900444030762\n",
      "Epoch: 1, Batch number: 23100, Loss: 7.2495012283325195\n",
      "Epoch: 1, Batch number: 23200, Loss: 7.619729042053223\n",
      "Epoch: 1, Batch number: 23300, Loss: 7.330033302307129\n",
      "Epoch: 1, Batch number: 23400, Loss: 7.326958656311035\n",
      "Epoch: 1, Batch number: 23500, Loss: 7.33378791809082\n",
      "Epoch: 1, Batch number: 23600, Loss: 7.371810436248779\n",
      "Epoch: 1, Batch number: 23700, Loss: 7.347769737243652\n",
      "Epoch: 1, Batch number: 23800, Loss: 7.204545497894287\n",
      "Epoch: 1, Batch number: 23900, Loss: 7.275708198547363\n",
      "Epoch: 1, Batch number: 24000, Loss: 7.050254821777344\n",
      "Epoch: 1, Batch number: 24100, Loss: 7.218257427215576\n",
      "Epoch: 1, Batch number: 24200, Loss: 7.445038795471191\n",
      "Epoch: 1, Batch number: 24300, Loss: 7.020956993103027\n",
      "Epoch: 1, Batch number: 24400, Loss: 7.144362926483154\n",
      "Epoch: 1, Batch number: 24500, Loss: 7.489494323730469\n",
      "Epoch: 1, Batch number: 24600, Loss: 7.4683518409729\n",
      "Epoch: 1, Batch number: 24700, Loss: 7.204806804656982\n",
      "Epoch: 1, Batch number: 24800, Loss: 7.066473484039307\n",
      "Epoch: 1, Batch number: 24900, Loss: 7.226983547210693\n",
      "Epoch: 1, Batch number: 25000, Loss: 7.2863078117370605\n",
      "Epoch: 1, Batch number: 25100, Loss: 7.256509780883789\n",
      "Epoch: 1, Batch number: 25200, Loss: 7.409677982330322\n",
      "Epoch: 1, Batch number: 25300, Loss: 6.971339702606201\n",
      "Epoch: 1, Batch number: 25400, Loss: 7.069660663604736\n",
      "Epoch: 1, Batch number: 25500, Loss: 7.043186187744141\n",
      "Epoch: 1, Batch number: 25600, Loss: 7.331573963165283\n",
      "Epoch: 1, Batch number: 25700, Loss: 7.5447797775268555\n",
      "Epoch: 1, Batch number: 25800, Loss: 7.173068523406982\n",
      "Epoch: 1, Batch number: 25900, Loss: 7.000094890594482\n",
      "Epoch: 1, Batch number: 26000, Loss: 7.063808917999268\n",
      "Epoch: 1, Batch number: 26100, Loss: 7.132248401641846\n",
      "Epoch: 1, Batch number: 26200, Loss: 7.111737251281738\n",
      "Epoch: 1, Batch number: 26300, Loss: 7.08195686340332\n",
      "Epoch: 1, Batch number: 26400, Loss: 7.2425923347473145\n",
      "Epoch: 1, Batch number: 26500, Loss: 7.5611371994018555\n",
      "Epoch: 1, Batch number: 26600, Loss: 6.983516216278076\n",
      "Epoch: 1, Batch number: 26700, Loss: 7.2602458000183105\n",
      "Epoch: 1, Batch number: 26800, Loss: 7.335642337799072\n",
      "Epoch: 1, Batch number: 26900, Loss: 7.297722339630127\n",
      "Epoch: 1, Batch number: 27000, Loss: 7.0911865234375\n",
      "Epoch: 1, Batch number: 27100, Loss: 7.194589138031006\n",
      "Epoch: 1, Batch number: 27200, Loss: 7.218977928161621\n",
      "Epoch: 1, Batch number: 27300, Loss: 7.2068705558776855\n",
      "Epoch: 1, Batch number: 27400, Loss: 7.276596546173096\n",
      "Epoch: 1, Batch number: 27500, Loss: 7.250896453857422\n",
      "Epoch: 1, Batch number: 27600, Loss: 7.227733612060547\n",
      "Epoch: 1, Batch number: 27700, Loss: 7.137001991271973\n",
      "Epoch: 1, Batch number: 27800, Loss: 7.079787731170654\n",
      "Epoch: 1, Batch number: 27900, Loss: 7.051351547241211\n",
      "Epoch: 1, Batch number: 28000, Loss: 7.273137092590332\n",
      "Epoch: 1, Batch number: 28100, Loss: 7.1055402755737305\n",
      "Epoch: 1, Batch number: 28200, Loss: 7.132929801940918\n",
      "Epoch: 1, Batch number: 28300, Loss: 7.212860584259033\n",
      "Epoch: 1, Batch number: 28400, Loss: 7.19074821472168\n",
      "Epoch: 1, Batch number: 28500, Loss: 7.356886863708496\n",
      "Epoch: 1, Batch number: 28600, Loss: 6.996440887451172\n",
      "Epoch: 1, Batch number: 28700, Loss: 7.37246036529541\n",
      "Epoch: 1, Batch number: 28800, Loss: 7.381697654724121\n",
      "Epoch: 1, Batch number: 28900, Loss: 7.1638875007629395\n",
      "Epoch: 1, Batch number: 29000, Loss: 7.400873184204102\n",
      "Epoch: 1, Batch number: 29100, Loss: 7.067983627319336\n",
      "Epoch: 1, Batch number: 29200, Loss: 7.48561429977417\n",
      "Epoch: 1, Batch number: 29300, Loss: 7.167916297912598\n",
      "Epoch: 1, Batch number: 29400, Loss: 7.09958553314209\n",
      "Epoch: 1, Batch number: 29500, Loss: 7.0807647705078125\n",
      "Epoch: 1, Batch number: 29600, Loss: 7.257809638977051\n",
      "Epoch: 1, Batch number: 29700, Loss: 7.297154903411865\n",
      "Epoch: 1, Batch number: 29800, Loss: 7.086347579956055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 29900, Loss: 7.252437591552734\n",
      "Epoch: 1, Batch number: 30000, Loss: 7.333477973937988\n",
      "Epoch: 1, Batch number: 30100, Loss: 7.338559150695801\n",
      "Epoch: 1, Batch number: 30200, Loss: 7.430111885070801\n",
      "Epoch: 1, Batch number: 30300, Loss: 7.2847981452941895\n",
      "Epoch: 1, Batch number: 30400, Loss: 7.303884506225586\n",
      "Epoch: 1, Batch number: 30500, Loss: 7.413614749908447\n",
      "Epoch: 1, Batch number: 30600, Loss: 7.190634727478027\n",
      "Epoch: 1, Batch number: 30700, Loss: 7.2126359939575195\n",
      "Epoch: 1, Batch number: 30800, Loss: 7.052307605743408\n",
      "Epoch: 1, Batch number: 30900, Loss: 7.393516540527344\n",
      "Epoch: 1, Batch number: 31000, Loss: 7.155821800231934\n",
      "Epoch: 1, Batch number: 31100, Loss: 7.241462707519531\n",
      "Epoch: 1, Batch number: 31200, Loss: 7.093506813049316\n",
      "Epoch: 1, Batch number: 31300, Loss: 7.174951553344727\n",
      "Epoch: 1, Batch number: 31400, Loss: 7.228707313537598\n",
      "Epoch: 1, Batch number: 31500, Loss: 7.311903953552246\n",
      "Epoch: 1, Batch number: 31600, Loss: 7.370737552642822\n",
      "Epoch: 1, Batch number: 31700, Loss: 7.23514461517334\n",
      "Epoch: 1, Batch number: 31800, Loss: 7.397835731506348\n",
      "Epoch: 1, Batch number: 31900, Loss: 7.211747646331787\n",
      "Epoch: 1, Batch number: 32000, Loss: 6.939796447753906\n",
      "Epoch: 1, Batch number: 32100, Loss: 7.2488861083984375\n",
      "Epoch: 1, Batch number: 32200, Loss: 7.219476222991943\n",
      "Epoch: 1, Batch number: 32300, Loss: 7.509970664978027\n",
      "Epoch: 1, Batch number: 32400, Loss: 7.0388312339782715\n",
      "Epoch: 1, Batch number: 32500, Loss: 7.013095378875732\n",
      "Epoch: 1, Batch number: 32600, Loss: 7.206876277923584\n",
      "Epoch: 1, Batch number: 32700, Loss: 7.147589683532715\n",
      "Epoch: 1, Batch number: 32800, Loss: 7.244184494018555\n",
      "Epoch: 1, Batch number: 32900, Loss: 7.05750036239624\n",
      "Epoch: 1, Batch number: 33000, Loss: 7.145401954650879\n",
      "Epoch: 1, Batch number: 33100, Loss: 7.262025356292725\n",
      "Epoch: 1, Batch number: 33200, Loss: 7.338080406188965\n",
      "Epoch: 1, Batch number: 33300, Loss: 7.435271739959717\n",
      "Epoch: 1, Batch number: 33400, Loss: 7.345762252807617\n",
      "Epoch: 1, Batch number: 33500, Loss: 7.233682632446289\n",
      "Epoch: 1, Batch number: 33600, Loss: 7.3339972496032715\n",
      "Epoch: 1, Batch number: 33700, Loss: 7.127270221710205\n",
      "Epoch: 1, Batch number: 33800, Loss: 7.3681230545043945\n",
      "Epoch: 1, Batch number: 33900, Loss: 7.267822742462158\n",
      "Epoch: 1, Batch number: 34000, Loss: 7.316035270690918\n",
      "Epoch: 1, Batch number: 34100, Loss: 7.112076282501221\n",
      "Epoch: 1, Batch number: 34200, Loss: 7.194454669952393\n",
      "Epoch: 1, Batch number: 34300, Loss: 7.378910541534424\n",
      "Epoch: 1, Batch number: 34400, Loss: 7.266529083251953\n",
      "Epoch: 1, Batch number: 34500, Loss: 7.2962260246276855\n",
      "Epoch: 1, Batch number: 34600, Loss: 7.048724174499512\n",
      "Epoch: 1, Batch number: 34700, Loss: 6.959686279296875\n",
      "Epoch: 1, Batch number: 34800, Loss: 7.087843894958496\n",
      "Epoch: 1, Batch number: 34900, Loss: 7.39293098449707\n",
      "Epoch: 1, Batch number: 35000, Loss: 7.048308372497559\n",
      "Epoch: 1, Batch number: 35100, Loss: 6.98717737197876\n",
      "Epoch: 1, Batch number: 35200, Loss: 7.08765172958374\n",
      "Epoch: 1, Batch number: 35300, Loss: 7.195115089416504\n",
      "Epoch: 1, Batch number: 35400, Loss: 7.403082847595215\n",
      "Epoch: 1, Batch number: 35500, Loss: 7.1383185386657715\n",
      "Epoch: 1, Batch number: 35600, Loss: 7.164729118347168\n",
      "Epoch: 1, Batch number: 35700, Loss: 7.009603023529053\n",
      "Epoch: 1, Batch number: 35800, Loss: 7.0765604972839355\n",
      "Epoch: 1, Batch number: 35900, Loss: 7.179656028747559\n",
      "Epoch: 1, Batch number: 36000, Loss: 7.236869812011719\n",
      "Epoch: 1, Batch number: 36100, Loss: 7.278536319732666\n",
      "Epoch: 1, Batch number: 36200, Loss: 7.22921085357666\n",
      "Epoch: 1, Batch number: 36300, Loss: 7.099071502685547\n",
      "Epoch: 1, Batch number: 36400, Loss: 7.216836929321289\n",
      "Epoch: 1, Batch number: 36500, Loss: 7.278407573699951\n",
      "Epoch: 1, Batch number: 36600, Loss: 7.135704040527344\n",
      "Epoch: 1, Batch number: 36700, Loss: 7.347580909729004\n",
      "Epoch: 1, Batch number: 36800, Loss: 7.1283111572265625\n",
      "Epoch: 1, Batch number: 36900, Loss: 7.075509548187256\n",
      "Epoch: 1, Batch number: 37000, Loss: 7.15349006652832\n",
      "Epoch: 1, Batch number: 37100, Loss: 7.327001094818115\n",
      "Epoch: 1, Batch number: 37200, Loss: 7.271958351135254\n",
      "Epoch: 1, Batch number: 37300, Loss: 7.0816826820373535\n",
      "Epoch: 1, Batch number: 37400, Loss: 7.17925500869751\n",
      "Epoch: 1, Batch number: 37500, Loss: 7.306485652923584\n",
      "Epoch: 1, Batch number: 37600, Loss: 7.321229934692383\n",
      "Epoch: 1, Batch number: 37700, Loss: 7.1588850021362305\n",
      "Epoch: 1, Batch number: 37800, Loss: 7.21964693069458\n",
      "Epoch: 1, Batch number: 37900, Loss: 7.415607929229736\n",
      "Epoch: 1, Batch number: 38000, Loss: 6.9818830490112305\n",
      "Epoch: 1, Batch number: 38100, Loss: 7.064580917358398\n",
      "Epoch: 1, Batch number: 38200, Loss: 7.176268577575684\n",
      "Epoch: 1, Batch number: 38300, Loss: 7.150089263916016\n",
      "Epoch: 1, Batch number: 38400, Loss: 7.213230609893799\n",
      "Epoch: 1, Batch number: 38500, Loss: 7.311598300933838\n",
      "Epoch: 1, Batch number: 38600, Loss: 7.201509952545166\n",
      "Epoch: 1, Batch number: 38700, Loss: 7.196880340576172\n",
      "Epoch: 1, Batch number: 38800, Loss: 7.339646816253662\n",
      "Epoch: 1, Batch number: 38900, Loss: 7.295825958251953\n",
      "Epoch: 1, Batch number: 39000, Loss: 7.1512675285339355\n",
      "Epoch: 1, Batch number: 39100, Loss: 7.268681049346924\n",
      "Epoch: 1, Batch number: 39200, Loss: 7.0149335861206055\n",
      "Epoch: 1, Batch number: 39300, Loss: 7.405322074890137\n",
      "Epoch: 1, Batch number: 39400, Loss: 7.078000068664551\n",
      "Epoch: 1, Batch number: 39500, Loss: 7.051585674285889\n",
      "Epoch: 1, Batch number: 39600, Loss: 7.269375801086426\n",
      "Epoch: 1, Batch number: 39700, Loss: 7.031001091003418\n",
      "Epoch: 1, Batch number: 39800, Loss: 7.17503547668457\n",
      "Epoch: 1, Batch number: 39900, Loss: 7.257565021514893\n",
      "Epoch: 1, Batch number: 40000, Loss: 7.141112804412842\n",
      "Epoch: 1, Batch number: 40100, Loss: 7.1446661949157715\n",
      "Epoch: 1, Batch number: 40200, Loss: 7.407073974609375\n",
      "Epoch: 1, Batch number: 40300, Loss: 7.039235591888428\n",
      "Epoch: 1, Batch number: 40400, Loss: 7.239971160888672\n",
      "Epoch: 1, Batch number: 40500, Loss: 7.555450439453125\n",
      "Epoch: 1, Batch number: 40600, Loss: 7.073521614074707\n",
      "Epoch: 1, Batch number: 40700, Loss: 7.329347610473633\n",
      "Epoch: 1, Batch number: 40800, Loss: 7.222484111785889\n",
      "Epoch: 1, Batch number: 40900, Loss: 7.041804313659668\n",
      "Epoch: 1, Batch number: 41000, Loss: 6.795139312744141\n",
      "Epoch: 1, Batch number: 41100, Loss: 7.1449408531188965\n",
      "Epoch: 1, Batch number: 41200, Loss: 6.984050750732422\n",
      "Epoch: 1, Batch number: 41300, Loss: 7.171480655670166\n",
      "Epoch: 1, Batch number: 41400, Loss: 7.347929000854492\n",
      "Epoch: 1, Batch number: 41500, Loss: 6.845534324645996\n",
      "Epoch: 1, Batch number: 41600, Loss: 7.160097599029541\n",
      "Epoch: 1, Batch number: 41700, Loss: 7.181308269500732\n",
      "Epoch: 1, Batch number: 41800, Loss: 6.910123825073242\n",
      "Epoch: 1, Batch number: 41900, Loss: 7.063328742980957\n",
      "Epoch: 1, Batch number: 42000, Loss: 7.246545314788818\n",
      "Epoch: 1, Batch number: 42100, Loss: 7.37387752532959\n",
      "Epoch: 1, Batch number: 42200, Loss: 6.929859161376953\n",
      "Epoch: 1, Batch number: 42300, Loss: 7.330446720123291\n",
      "Epoch: 1, Batch number: 42400, Loss: 7.383309841156006\n",
      "Epoch: 1, Batch number: 42500, Loss: 7.103139877319336\n",
      "Epoch: 1, Batch number: 42600, Loss: 6.968571662902832\n",
      "Epoch: 1, Batch number: 42700, Loss: 6.949620246887207\n",
      "Epoch: 1, Batch number: 42800, Loss: 7.200768947601318\n",
      "Epoch: 1, Batch number: 42900, Loss: 7.099593162536621\n",
      "Epoch: 1, Batch number: 43000, Loss: 7.245760440826416\n",
      "Epoch: 1, Batch number: 43100, Loss: 6.925349235534668\n",
      "Epoch: 1, Batch number: 43200, Loss: 7.004438400268555\n",
      "Epoch: 1, Batch number: 43300, Loss: 7.3755717277526855\n",
      "Epoch: 1, Batch number: 43400, Loss: 7.363836288452148\n",
      "Epoch: 1, Batch number: 43500, Loss: 7.026998996734619\n",
      "Epoch: 1, Batch number: 43600, Loss: 7.367210388183594\n",
      "Epoch: 1, Batch number: 43700, Loss: 6.874622344970703\n",
      "Epoch: 1, Batch number: 43800, Loss: 7.219841003417969\n",
      "Epoch: 1, Batch number: 43900, Loss: 7.0938239097595215\n",
      "Epoch: 1, Batch number: 44000, Loss: 7.108678817749023\n",
      "Epoch: 1, Batch number: 44100, Loss: 7.180109024047852\n",
      "Epoch: 1, Batch number: 44200, Loss: 7.210111141204834\n",
      "Epoch: 1, Batch number: 44300, Loss: 7.097651958465576\n",
      "Epoch: 1, Batch number: 44400, Loss: 7.03429651260376\n",
      "Epoch: 1, Batch number: 44500, Loss: 7.193406581878662\n",
      "Epoch: 1, Batch number: 44600, Loss: 7.099024295806885\n",
      "Epoch: 1, Batch number: 44700, Loss: 6.952149868011475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 44800, Loss: 7.001643657684326\n",
      "Epoch: 1, Batch number: 44900, Loss: 7.111486911773682\n",
      "Epoch: 1, Batch number: 45000, Loss: 7.131702899932861\n",
      "Epoch: 1, Batch number: 45100, Loss: 7.189658164978027\n",
      "Epoch: 1, Batch number: 45200, Loss: 7.446338653564453\n",
      "Epoch: 1, Batch number: 45300, Loss: 7.0010151863098145\n",
      "Epoch: 1, Batch number: 45400, Loss: 7.404354572296143\n",
      "Epoch: 1, Batch number: 45500, Loss: 7.082343101501465\n",
      "Epoch: 1, Batch number: 45600, Loss: 6.902629852294922\n",
      "Epoch: 1, Batch number: 45700, Loss: 7.258586406707764\n",
      "Epoch: 1, Batch number: 45800, Loss: 6.984985828399658\n",
      "Epoch: 1, Batch number: 45900, Loss: 6.865338325500488\n",
      "Epoch: 1, Batch number: 46000, Loss: 7.175999641418457\n",
      "Epoch: 1, Batch number: 46100, Loss: 7.055422782897949\n",
      "Epoch: 1, Batch number: 46200, Loss: 7.032507419586182\n",
      "Epoch: 1, Batch number: 46300, Loss: 7.138661861419678\n",
      "Epoch: 1, Batch number: 46400, Loss: 7.055293560028076\n",
      "Epoch: 1, Batch number: 46500, Loss: 6.857598304748535\n",
      "Epoch: 1, Batch number: 46600, Loss: 7.163023948669434\n",
      "Epoch: 1, Batch number: 46700, Loss: 7.215078830718994\n",
      "Epoch: 1, Batch number: 46800, Loss: 7.008074760437012\n",
      "Epoch: 1, Batch number: 46900, Loss: 7.059875965118408\n",
      "Epoch: 1, Batch number: 47000, Loss: 7.256932735443115\n",
      "Epoch: 1, Batch number: 47100, Loss: 7.078794002532959\n",
      "Epoch: 1, Batch number: 47200, Loss: 7.085020065307617\n",
      "Epoch: 1, Batch number: 47300, Loss: 6.934793949127197\n",
      "Epoch: 1, Batch number: 47400, Loss: 7.024869918823242\n",
      "Epoch: 1, Batch number: 47500, Loss: 7.023293495178223\n",
      "Epoch: 1, Batch number: 47600, Loss: 7.015596866607666\n",
      "Epoch: 1, Batch number: 47700, Loss: 6.99653959274292\n",
      "Epoch: 1, Batch number: 47800, Loss: 6.872615814208984\n",
      "Epoch: 1, Batch number: 47900, Loss: 7.114816665649414\n",
      "Epoch: 1, Batch number: 48000, Loss: 7.049917221069336\n",
      "Epoch: 1, Batch number: 48100, Loss: 7.508532524108887\n",
      "Epoch: 1, Batch number: 48200, Loss: 7.030678749084473\n",
      "Epoch: 1, Batch number: 48300, Loss: 7.255687236785889\n",
      "Epoch: 1, Batch number: 48400, Loss: 7.1656174659729\n",
      "Epoch: 1, Batch number: 48500, Loss: 6.949101448059082\n",
      "Epoch: 1, Batch number: 48600, Loss: 7.059788227081299\n",
      "Epoch: 1, Batch number: 48700, Loss: 7.053137302398682\n",
      "Epoch: 1, Batch number: 48800, Loss: 7.119614124298096\n",
      "Epoch: 1, Batch number: 48900, Loss: 7.267574787139893\n",
      "Epoch: 1, Batch number: 49000, Loss: 7.179476261138916\n",
      "Epoch: 1, Batch number: 49100, Loss: 7.1215128898620605\n",
      "Epoch: 1, Batch number: 49200, Loss: 6.967477321624756\n",
      "Epoch: 1, Batch number: 49300, Loss: 6.97731876373291\n",
      "Epoch: 1, Batch number: 49400, Loss: 6.988068580627441\n",
      "Epoch: 1, Batch number: 49500, Loss: 7.252023696899414\n",
      "Epoch: 1, Batch number: 49600, Loss: 7.155681610107422\n",
      "Epoch: 1, Batch number: 49700, Loss: 6.773776531219482\n",
      "Epoch: 1, Batch number: 49800, Loss: 7.02276086807251\n",
      "Epoch: 1, Batch number: 49900, Loss: 7.241931438446045\n",
      "Epoch: 1, Batch number: 50000, Loss: 7.158258438110352\n",
      "Epoch: 1, Batch number: 50100, Loss: 6.992403030395508\n",
      "Epoch: 1, Batch number: 50200, Loss: 7.206892967224121\n",
      "Epoch: 1, Batch number: 50300, Loss: 6.84039831161499\n",
      "Epoch: 1, Batch number: 50400, Loss: 7.48668098449707\n",
      "Epoch: 1, Batch number: 50500, Loss: 7.007105350494385\n",
      "Epoch: 1, Batch number: 50600, Loss: 7.460487365722656\n",
      "Epoch: 1, Batch number: 50700, Loss: 6.990616798400879\n",
      "Epoch: 1, Batch number: 50800, Loss: 7.38266134262085\n",
      "Epoch: 1, Batch number: 50900, Loss: 6.993188858032227\n",
      "Epoch: 1, Batch number: 51000, Loss: 7.055959701538086\n",
      "Epoch: 1, Batch number: 51100, Loss: 7.209726810455322\n",
      "Epoch: 1, Batch number: 51200, Loss: 7.229008674621582\n",
      "Epoch: 1, Batch number: 51300, Loss: 7.190975189208984\n",
      "Epoch: 1, Batch number: 51400, Loss: 7.183525085449219\n",
      "Epoch: 1, Batch number: 51500, Loss: 7.316315650939941\n",
      "Epoch: 1, Batch number: 51600, Loss: 7.379546165466309\n",
      "Epoch: 1, Batch number: 51700, Loss: 7.362144947052002\n",
      "Epoch: 1, Batch number: 51800, Loss: 7.0671586990356445\n",
      "Epoch: 1, Batch number: 51900, Loss: 6.976491451263428\n",
      "Epoch: 1, Batch number: 52000, Loss: 7.128292560577393\n",
      "Epoch: 1, Batch number: 52100, Loss: 6.951882839202881\n",
      "Epoch: 1, Batch number: 52200, Loss: 7.235385894775391\n",
      "Epoch: 1, Batch number: 52300, Loss: 6.7990899085998535\n",
      "Epoch: 1, Batch number: 52400, Loss: 7.1810526847839355\n",
      "Epoch: 1, Batch number: 52500, Loss: 7.336337089538574\n",
      "Epoch: 1, Batch number: 52600, Loss: 7.126680850982666\n",
      "Epoch: 1, Batch number: 52700, Loss: 6.923838138580322\n",
      "Epoch: 1, Batch number: 52800, Loss: 7.014987945556641\n",
      "Epoch: 1, Batch number: 52900, Loss: 7.435120105743408\n",
      "Epoch: 1, Batch number: 53000, Loss: 7.128683090209961\n",
      "Epoch: 1, Batch number: 53100, Loss: 7.0098557472229\n",
      "Epoch: 1, Batch number: 53200, Loss: 6.903744697570801\n",
      "Epoch: 1, Batch number: 53300, Loss: 7.148326873779297\n",
      "Epoch: 1, Batch number: 53400, Loss: 7.051478385925293\n",
      "Epoch: 1, Batch number: 53500, Loss: 7.148994445800781\n",
      "Epoch: 1, Batch number: 53600, Loss: 6.905425071716309\n",
      "Epoch: 1, Batch number: 53700, Loss: 7.094766139984131\n",
      "Epoch: 1, Batch number: 53800, Loss: 6.982261657714844\n",
      "Epoch: 1, Batch number: 53900, Loss: 7.05590295791626\n",
      "Epoch: 1, Batch number: 54000, Loss: 7.289844989776611\n",
      "Epoch: 1, Batch number: 54100, Loss: 7.043948650360107\n",
      "Epoch: 1, Batch number: 54200, Loss: 7.234330177307129\n",
      "Epoch: 1, Batch number: 54300, Loss: 6.902046203613281\n",
      "Epoch: 1, Batch number: 54400, Loss: 7.14677619934082\n",
      "Epoch: 1, Batch number: 54500, Loss: 7.081003189086914\n",
      "Epoch: 1, Batch number: 54600, Loss: 7.072353839874268\n",
      "Epoch: 1, Batch number: 54700, Loss: 7.098504543304443\n",
      "Epoch: 1, Batch number: 54800, Loss: 7.098865032196045\n",
      "Epoch: 1, Batch number: 54900, Loss: 6.813658714294434\n",
      "Epoch: 1, Batch number: 55000, Loss: 7.160151481628418\n",
      "Epoch: 1, Batch number: 55100, Loss: 7.325521469116211\n",
      "Epoch: 1, Batch number: 55200, Loss: 7.024322986602783\n",
      "Epoch: 1, Batch number: 55300, Loss: 6.766836643218994\n",
      "Epoch: 1, Batch number: 55400, Loss: 7.092068195343018\n",
      "Epoch: 1, Batch number: 55500, Loss: 7.282644271850586\n",
      "Epoch: 1, Batch number: 55600, Loss: 6.985207557678223\n",
      "Epoch: 1, Batch number: 55700, Loss: 7.152095794677734\n",
      "Epoch: 1, Batch number: 55800, Loss: 7.0906081199646\n",
      "Epoch: 1, Batch number: 55900, Loss: 7.172715663909912\n",
      "Epoch: 1, Batch number: 56000, Loss: 7.210358619689941\n",
      "Epoch: 1, Batch number: 56100, Loss: 7.173674583435059\n",
      "Epoch: 1, Batch number: 56200, Loss: 7.363542556762695\n",
      "Epoch: 1, Batch number: 56300, Loss: 7.363500595092773\n",
      "Epoch: 1, Batch number: 56400, Loss: 7.147037029266357\n",
      "Epoch: 1, Batch number: 56500, Loss: 7.219729423522949\n",
      "Epoch: 1, Batch number: 56600, Loss: 7.103557109832764\n",
      "Epoch: 1, Batch number: 56700, Loss: 6.956589698791504\n",
      "Epoch: 1, Batch number: 56800, Loss: 7.1223464012146\n",
      "Epoch: 1, Batch number: 56900, Loss: 7.062928676605225\n",
      "Epoch: 1, Batch number: 57000, Loss: 7.073510646820068\n",
      "Epoch: 1, Batch number: 57100, Loss: 7.12646484375\n",
      "Epoch: 1, Batch number: 57200, Loss: 7.226140022277832\n",
      "Epoch: 1, Batch number: 57300, Loss: 6.914012432098389\n",
      "Epoch: 1, Batch number: 57400, Loss: 6.881921768188477\n",
      "Epoch: 1, Batch number: 57500, Loss: 7.142090320587158\n",
      "Epoch: 1, Batch number: 57600, Loss: 7.071467399597168\n",
      "Epoch: 1, Batch number: 57700, Loss: 7.246582984924316\n",
      "Epoch: 1, Batch number: 57800, Loss: 6.903132438659668\n",
      "Epoch: 1, Batch number: 57900, Loss: 7.082770347595215\n",
      "Epoch: 1, Batch number: 58000, Loss: 7.25608491897583\n",
      "Epoch: 1, Batch number: 58100, Loss: 7.128724098205566\n",
      "Epoch: 1, Batch number: 58200, Loss: 7.194324016571045\n",
      "Epoch: 1, Batch number: 58300, Loss: 7.394082546234131\n",
      "Epoch: 1, Batch number: 58400, Loss: 7.165586471557617\n",
      "Epoch: 1, Batch number: 58500, Loss: 6.949378490447998\n",
      "Epoch: 1, Batch number: 58600, Loss: 7.333991527557373\n",
      "Epoch: 1, Batch number: 58700, Loss: 7.294528484344482\n",
      "Epoch: 1, Batch number: 58800, Loss: 7.297234535217285\n",
      "Epoch: 1, Batch number: 58900, Loss: 7.280625343322754\n",
      "Epoch: 1, Batch number: 59000, Loss: 7.322656154632568\n",
      "Epoch: 1, Batch number: 59100, Loss: 6.904734134674072\n",
      "Epoch: 1, Batch number: 59200, Loss: 7.149906635284424\n",
      "Epoch: 1, Batch number: 59300, Loss: 7.332048416137695\n",
      "Epoch: 1, Batch number: 59400, Loss: 7.248547077178955\n",
      "Epoch: 1, Batch number: 59500, Loss: 7.096641540527344\n",
      "Epoch: 1, Batch number: 59600, Loss: 7.190959453582764\n",
      "Epoch: 1, Batch number: 59700, Loss: 7.051332473754883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 59800, Loss: 7.276620864868164\n",
      "Epoch: 1, Batch number: 59900, Loss: 6.955380916595459\n",
      "Epoch: 1, Batch number: 60000, Loss: 7.105928421020508\n",
      "Epoch: 1, Batch number: 60100, Loss: 7.300835132598877\n",
      "Epoch: 1, Batch number: 60200, Loss: 7.185631275177002\n",
      "Epoch: 1, Batch number: 60300, Loss: 7.121718406677246\n",
      "Epoch: 1, Batch number: 60400, Loss: 6.963840007781982\n",
      "Epoch: 1, Batch number: 60500, Loss: 6.999975204467773\n",
      "Epoch: 1, Batch number: 60600, Loss: 7.086698532104492\n",
      "Epoch: 1, Batch number: 60700, Loss: 7.165543556213379\n",
      "Epoch: 1, Batch number: 60800, Loss: 7.114259243011475\n",
      "Epoch: 1, Batch number: 60900, Loss: 7.175834655761719\n",
      "Epoch: 1, Batch number: 61000, Loss: 7.487060546875\n",
      "Epoch: 1, Batch number: 61100, Loss: 7.056555271148682\n",
      "Epoch: 1, Batch number: 61200, Loss: 7.160287857055664\n",
      "Epoch: 1, Batch number: 61300, Loss: 7.251376152038574\n",
      "Epoch: 1, Batch number: 61400, Loss: 7.158819675445557\n",
      "Epoch: 1, Batch number: 61500, Loss: 7.211452960968018\n",
      "Epoch: 1, Batch number: 61600, Loss: 7.113083839416504\n",
      "Epoch: 1, Batch number: 61700, Loss: 6.864044666290283\n",
      "Epoch: 1, Batch number: 61800, Loss: 7.055421352386475\n",
      "Epoch: 1, Batch number: 61900, Loss: 7.169414043426514\n",
      "Epoch: 1, Batch number: 62000, Loss: 7.131819725036621\n",
      "Epoch: 1, Batch number: 62100, Loss: 7.17210054397583\n",
      "Epoch: 1, Batch number: 62200, Loss: 7.142075061798096\n",
      "Epoch: 1, Batch number: 62300, Loss: 7.128452777862549\n",
      "Epoch: 1, Batch number: 62400, Loss: 7.234911918640137\n",
      "Epoch: 1, Batch number: 62500, Loss: 7.073563098907471\n",
      "Epoch: 1, Batch number: 62600, Loss: 7.086137771606445\n",
      "Epoch: 1, Batch number: 62700, Loss: 7.05383825302124\n",
      "Epoch: 1, Batch number: 62800, Loss: 7.027867794036865\n",
      "Epoch: 1, Batch number: 62900, Loss: 7.084616661071777\n",
      "Epoch: 1, Batch number: 63000, Loss: 7.280215263366699\n",
      "Epoch: 1, Batch number: 63100, Loss: 6.967948913574219\n",
      "Epoch: 1, Batch number: 63200, Loss: 7.065713405609131\n",
      "Epoch: 1, Batch number: 63300, Loss: 6.9458394050598145\n",
      "Epoch: 1, Batch number: 63400, Loss: 7.115447998046875\n",
      "Epoch: 1, Batch number: 63500, Loss: 6.890925407409668\n",
      "Epoch: 1, Batch number: 63600, Loss: 7.023670196533203\n",
      "Epoch: 1, Batch number: 63700, Loss: 6.993378639221191\n",
      "Epoch: 1, Batch number: 63800, Loss: 6.88712739944458\n",
      "Epoch: 1, Batch number: 63900, Loss: 7.165705680847168\n",
      "Epoch: 1, Batch number: 64000, Loss: 6.911953926086426\n",
      "Epoch: 1, Batch number: 64100, Loss: 7.436545372009277\n",
      "Epoch: 1, Batch number: 64200, Loss: 7.460371017456055\n",
      "Epoch: 1, Batch number: 64300, Loss: 7.001951694488525\n",
      "Epoch: 1, Batch number: 64400, Loss: 7.238785266876221\n",
      "Epoch: 1, Batch number: 64500, Loss: 7.183448791503906\n",
      "Epoch: 1, Batch number: 64600, Loss: 7.150907516479492\n",
      "Epoch: 1, Batch number: 64700, Loss: 7.024845123291016\n",
      "Epoch: 1, Batch number: 64800, Loss: 7.118430137634277\n",
      "Epoch: 1, Batch number: 64900, Loss: 7.04005765914917\n",
      "Epoch: 1, Batch number: 65000, Loss: 6.9241461753845215\n",
      "Epoch: 1, Batch number: 65100, Loss: 7.036792278289795\n",
      "Epoch: 1, Batch number: 65200, Loss: 7.047205924987793\n",
      "Epoch: 1, Batch number: 65300, Loss: 7.243297100067139\n",
      "Epoch: 1, Batch number: 65400, Loss: 7.0297088623046875\n",
      "Epoch: 1, Batch number: 65500, Loss: 7.3119330406188965\n",
      "Epoch: 1, Batch number: 65600, Loss: 7.073217868804932\n",
      "Epoch: 1, Batch number: 65700, Loss: 6.983393669128418\n",
      "Epoch: 1, Batch number: 65800, Loss: 7.072402477264404\n",
      "Epoch: 1, Batch number: 65900, Loss: 7.094502925872803\n",
      "Epoch: 1, Batch number: 66000, Loss: 7.377522945404053\n",
      "Epoch: 1, Batch number: 66100, Loss: 7.373642444610596\n",
      "Epoch: 1, Batch number: 66200, Loss: 7.2576212882995605\n",
      "Epoch: 1, Batch number: 66300, Loss: 6.906497955322266\n",
      "Epoch: 1, Batch number: 66400, Loss: 7.0672407150268555\n",
      "Epoch: 1, Batch number: 66500, Loss: 7.304452896118164\n",
      "Epoch: 1, Batch number: 66600, Loss: 6.990301609039307\n",
      "Epoch: 1, Batch number: 66700, Loss: 7.1131134033203125\n",
      "Epoch: 1, Batch number: 66800, Loss: 6.6831278800964355\n",
      "Epoch: 1, Batch number: 66900, Loss: 7.1389689445495605\n",
      "Epoch: 1, Batch number: 67000, Loss: 6.913744926452637\n",
      "Epoch: 1, Batch number: 67100, Loss: 6.887885093688965\n",
      "Epoch: 1, Batch number: 67200, Loss: 7.0465497970581055\n",
      "Epoch: 1, Batch number: 67300, Loss: 7.0390448570251465\n",
      "Epoch: 1, Batch number: 67400, Loss: 7.394362449645996\n",
      "Epoch: 1, Batch number: 67500, Loss: 7.2139387130737305\n",
      "Epoch: 1, Batch number: 67600, Loss: 6.75385856628418\n",
      "Epoch: 1, Batch number: 67700, Loss: 7.091603755950928\n",
      "Epoch: 1, Batch number: 67800, Loss: 7.323501110076904\n",
      "Epoch: 1, Batch number: 67900, Loss: 7.206199645996094\n",
      "Epoch: 1, Batch number: 68000, Loss: 6.939748764038086\n",
      "Epoch: 1, Batch number: 68100, Loss: 7.16581392288208\n",
      "Epoch: 1, Batch number: 68200, Loss: 7.2331109046936035\n",
      "Epoch: 1, Batch number: 68300, Loss: 7.035248279571533\n",
      "Epoch: 1, Batch number: 68400, Loss: 7.163877487182617\n",
      "Epoch: 1, Batch number: 68500, Loss: 7.253547668457031\n",
      "Epoch: 1, Batch number: 68600, Loss: 7.029492378234863\n",
      "Epoch: 1, Batch number: 68700, Loss: 7.287922382354736\n",
      "Epoch: 1, Batch number: 68800, Loss: 6.651735305786133\n",
      "Epoch: 1, Batch number: 68900, Loss: 6.902715682983398\n",
      "Epoch: 1, Batch number: 69000, Loss: 7.117500305175781\n",
      "Epoch: 1, Batch number: 69100, Loss: 7.128733158111572\n",
      "Epoch: 1, Batch number: 69200, Loss: 7.025973796844482\n",
      "Epoch: 1, Batch number: 69300, Loss: 7.091062545776367\n",
      "Epoch: 1, Batch number: 69400, Loss: 6.98847770690918\n",
      "Epoch: 1, Batch number: 69500, Loss: 7.243806838989258\n",
      "Epoch: 1, Batch number: 69600, Loss: 7.006768226623535\n",
      "Epoch: 1, Batch number: 69700, Loss: 6.928731918334961\n",
      "Epoch: 1, Batch number: 69800, Loss: 7.033762454986572\n",
      "Epoch: 1, Batch number: 69900, Loss: 7.231385231018066\n",
      "Epoch: 1, Batch number: 70000, Loss: 7.257113933563232\n",
      "Epoch: 1, Batch number: 70100, Loss: 7.116485595703125\n",
      "Epoch: 1, Batch number: 70200, Loss: 7.31245231628418\n",
      "Epoch: 1, Batch number: 70300, Loss: 7.453176975250244\n",
      "Epoch: 1, Batch number: 70400, Loss: 6.975818157196045\n",
      "Epoch: 1, Batch number: 70500, Loss: 6.937752723693848\n",
      "Epoch: 1, Batch number: 70600, Loss: 7.326308727264404\n",
      "Epoch: 1, Batch number: 70700, Loss: 7.026490211486816\n",
      "Epoch: 1, Batch number: 70800, Loss: 7.13962459564209\n",
      "Epoch: 1, Batch number: 70900, Loss: 7.203378677368164\n",
      "Epoch: 1, Batch number: 71000, Loss: 6.906313419342041\n",
      "Epoch: 1, Batch number: 71100, Loss: 7.073370456695557\n",
      "Epoch: 1, Batch number: 71200, Loss: 6.850415229797363\n",
      "Epoch: 1, Batch number: 71300, Loss: 7.335192680358887\n",
      "Epoch: 1, Batch number: 71400, Loss: 7.202441692352295\n",
      "Epoch: 1, Batch number: 71500, Loss: 7.06960916519165\n",
      "Epoch: 1, Batch number: 71600, Loss: 6.919490337371826\n",
      "Epoch: 1, Batch number: 71700, Loss: 7.1534013748168945\n",
      "Epoch: 1, Batch number: 71800, Loss: 6.821390628814697\n",
      "Epoch: 1, Batch number: 71900, Loss: 6.852663040161133\n",
      "Epoch: 1, Batch number: 72000, Loss: 7.177630424499512\n",
      "Epoch: 1, Batch number: 72100, Loss: 7.021103382110596\n",
      "Epoch: 1, Batch number: 72200, Loss: 7.212038993835449\n",
      "Epoch: 1, Batch number: 72300, Loss: 6.9772772789001465\n",
      "Epoch: 1, Batch number: 72400, Loss: 7.4090352058410645\n",
      "Epoch: 1, Batch number: 72500, Loss: 7.23137092590332\n",
      "Epoch: 1, Batch number: 72600, Loss: 7.107415676116943\n",
      "Epoch: 1, Batch number: 72700, Loss: 7.176922798156738\n",
      "Epoch: 1, Batch number: 72800, Loss: 7.187734603881836\n",
      "Epoch: 1, Batch number: 72900, Loss: 7.2144012451171875\n",
      "Epoch: 1, Batch number: 73000, Loss: 6.92365837097168\n",
      "Epoch: 1, Batch number: 73100, Loss: 7.249378681182861\n",
      "Epoch: 1, Batch number: 73200, Loss: 7.152553558349609\n",
      "Epoch: 1, Batch number: 73300, Loss: 7.087649822235107\n",
      "Epoch: 1, Batch number: 73400, Loss: 6.914405822753906\n",
      "Epoch: 1, Batch number: 73500, Loss: 6.989354610443115\n",
      "Epoch: 1, Batch number: 73600, Loss: 6.963187217712402\n",
      "Epoch: 1, Batch number: 73700, Loss: 6.880207538604736\n",
      "Epoch: 1, Batch number: 73800, Loss: 7.314313888549805\n",
      "Epoch: 1, Batch number: 73900, Loss: 7.01533317565918\n",
      "Epoch: 1, Batch number: 74000, Loss: 7.077881813049316\n",
      "Epoch: 1, Batch number: 74100, Loss: 6.992106914520264\n",
      "Epoch: 1, Batch number: 74200, Loss: 7.165844917297363\n",
      "Epoch: 1, Batch number: 74300, Loss: 7.150091648101807\n",
      "Epoch: 1, Batch number: 74400, Loss: 6.993285655975342\n",
      "Epoch: 1, Batch number: 74500, Loss: 6.983470916748047\n",
      "Epoch: 1, Batch number: 74600, Loss: 7.128902435302734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 74700, Loss: 7.12608003616333\n",
      "Epoch: 1, Batch number: 74800, Loss: 6.702675819396973\n",
      "Epoch: 1, Batch number: 74900, Loss: 7.147655487060547\n",
      "Epoch: 1, Batch number: 75000, Loss: 6.980982780456543\n",
      "Epoch: 1, Batch number: 75100, Loss: 6.9404096603393555\n",
      "Epoch: 1, Batch number: 75200, Loss: 7.005832672119141\n",
      "Epoch: 1, Batch number: 75300, Loss: 7.106593608856201\n",
      "Epoch: 1, Batch number: 75400, Loss: 7.0760416984558105\n",
      "Epoch: 1, Batch number: 75500, Loss: 6.995962142944336\n",
      "Epoch: 1, Batch number: 75600, Loss: 7.023957252502441\n",
      "Epoch: 1, Batch number: 75700, Loss: 6.98784875869751\n",
      "Epoch: 1, Batch number: 75800, Loss: 6.847352504730225\n",
      "Epoch: 1, Batch number: 75900, Loss: 7.039768695831299\n",
      "Epoch: 1, Batch number: 76000, Loss: 7.25032901763916\n",
      "Epoch: 1, Batch number: 76100, Loss: 7.12064266204834\n",
      "Epoch: 1, Batch number: 76200, Loss: 6.961119651794434\n",
      "Epoch: 1, Batch number: 76300, Loss: 7.045912265777588\n",
      "Epoch: 1, Batch number: 76400, Loss: 7.11583137512207\n",
      "Epoch: 1, Batch number: 76500, Loss: 6.906013011932373\n",
      "Epoch: 1, Batch number: 76600, Loss: 6.910096168518066\n",
      "Epoch: 1, Batch number: 76700, Loss: 6.962996482849121\n",
      "Epoch: 1, Batch number: 76800, Loss: 6.945352077484131\n",
      "Epoch: 1, Batch number: 76900, Loss: 7.666943073272705\n",
      "Epoch: 1, Batch number: 77000, Loss: 7.479707717895508\n",
      "Epoch: 1, Batch number: 77100, Loss: 6.938692569732666\n",
      "Epoch: 1, Batch number: 77200, Loss: 7.054131031036377\n",
      "Epoch: 1, Batch number: 77300, Loss: 6.818301200866699\n",
      "Epoch: 1, Batch number: 77400, Loss: 7.0055742263793945\n",
      "Epoch: 1, Batch number: 77500, Loss: 7.088573455810547\n",
      "Epoch: 1, Batch number: 77600, Loss: 7.111619472503662\n",
      "Epoch: 1, Batch number: 77700, Loss: 6.978934288024902\n",
      "Epoch: 1, Batch number: 77800, Loss: 7.100347995758057\n",
      "Epoch: 1, Batch number: 77900, Loss: 7.037665843963623\n",
      "Epoch: 1, Batch number: 78000, Loss: 6.93503999710083\n",
      "Epoch: 1, Batch number: 78100, Loss: 6.875123977661133\n",
      "Epoch: 1, Batch number: 78200, Loss: 7.028456211090088\n",
      "Epoch: 1, Batch number: 78300, Loss: 7.06410026550293\n",
      "Epoch: 1, Batch number: 78400, Loss: 7.195882797241211\n",
      "Epoch: 1, Batch number: 78500, Loss: 7.323413848876953\n",
      "Epoch: 1, Batch number: 78600, Loss: 7.165934085845947\n",
      "Epoch: 1, Batch number: 78700, Loss: 7.274380683898926\n",
      "Epoch: 1, Batch number: 78800, Loss: 6.9841814041137695\n",
      "Epoch: 1, Batch number: 78900, Loss: 7.286197185516357\n",
      "Epoch: 1, Batch number: 79000, Loss: 7.162782192230225\n",
      "Epoch: 1, Batch number: 79100, Loss: 7.043834686279297\n",
      "Epoch: 1, Batch number: 79200, Loss: 7.289424896240234\n",
      "Epoch: 1, Batch number: 79300, Loss: 6.969176769256592\n",
      "Epoch: 1, Batch number: 79400, Loss: 6.9590840339660645\n",
      "Epoch: 1, Batch number: 79500, Loss: 6.938564300537109\n",
      "Epoch: 1, Batch number: 79600, Loss: 7.04938268661499\n",
      "Epoch: 1, Batch number: 79700, Loss: 7.053076267242432\n",
      "Epoch: 1, Batch number: 79800, Loss: 7.024104118347168\n",
      "Epoch: 1, Batch number: 79900, Loss: 7.384089946746826\n",
      "Epoch: 1, Batch number: 80000, Loss: 6.802353858947754\n",
      "Epoch: 1, Batch number: 80100, Loss: 6.96862268447876\n",
      "Epoch: 1, Batch number: 80200, Loss: 6.954489231109619\n",
      "Epoch: 1, Batch number: 80300, Loss: 7.054776191711426\n",
      "Epoch: 1, Batch number: 80400, Loss: 6.88882303237915\n",
      "Epoch: 1, Batch number: 80500, Loss: 7.015615940093994\n",
      "Epoch: 1, Batch number: 80600, Loss: 7.12544059753418\n",
      "Epoch: 1, Batch number: 80700, Loss: 7.041180610656738\n",
      "Epoch: 1, Batch number: 80800, Loss: 7.064718246459961\n",
      "Epoch: 1, Batch number: 80900, Loss: 7.026582717895508\n",
      "Epoch: 1, Batch number: 81000, Loss: 6.94440221786499\n",
      "Epoch: 1, Batch number: 81100, Loss: 7.153798580169678\n",
      "Epoch: 1, Batch number: 81200, Loss: 7.329723358154297\n",
      "Epoch: 1, Batch number: 81300, Loss: 7.099698543548584\n",
      "Epoch: 1, Batch number: 81400, Loss: 7.2786126136779785\n",
      "Epoch: 1, Batch number: 81500, Loss: 6.92864465713501\n",
      "Epoch: 1, Batch number: 81600, Loss: 7.162149906158447\n",
      "Epoch: 1, Batch number: 81700, Loss: 7.21809720993042\n",
      "Epoch: 1, Batch number: 81800, Loss: 7.064177513122559\n",
      "Epoch: 1, Batch number: 81900, Loss: 7.06726598739624\n",
      "Epoch: 1, Batch number: 82000, Loss: 6.987031936645508\n",
      "Epoch: 1, Batch number: 82100, Loss: 7.032375335693359\n",
      "Epoch: 1, Batch number: 82200, Loss: 6.6032915115356445\n",
      "Epoch: 1, Batch number: 82300, Loss: 7.073919296264648\n",
      "Epoch: 1, Batch number: 82400, Loss: 6.963796138763428\n",
      "Epoch: 1, Batch number: 82500, Loss: 7.222814083099365\n",
      "Epoch: 1, Batch number: 82600, Loss: 6.8882269859313965\n",
      "Epoch: 1, Batch number: 82700, Loss: 7.231307506561279\n",
      "Epoch: 1, Batch number: 82800, Loss: 7.192445755004883\n",
      "Epoch: 1, Batch number: 82900, Loss: 7.128672122955322\n",
      "Epoch: 1, Batch number: 83000, Loss: 6.943989276885986\n",
      "Epoch: 1, Batch number: 83100, Loss: 6.863033294677734\n",
      "Epoch: 1, Batch number: 83200, Loss: 7.145884037017822\n",
      "Epoch: 1, Batch number: 83300, Loss: 7.348935604095459\n",
      "Epoch: 1, Batch number: 83400, Loss: 7.28244161605835\n",
      "Epoch: 1, Batch number: 83500, Loss: 6.8631591796875\n",
      "Epoch: 1, Batch number: 83600, Loss: 7.012235641479492\n",
      "Epoch: 1, Batch number: 83700, Loss: 6.957296371459961\n",
      "Epoch: 1, Batch number: 83800, Loss: 7.112091064453125\n",
      "Epoch: 1, Batch number: 83900, Loss: 7.080552101135254\n",
      "Epoch: 1, Batch number: 84000, Loss: 7.126482963562012\n",
      "Epoch: 1, Batch number: 84100, Loss: 7.100831031799316\n",
      "Epoch: 1, Batch number: 84200, Loss: 7.115583419799805\n",
      "Epoch: 1, Batch number: 84300, Loss: 6.9725494384765625\n",
      "Epoch: 1, Batch number: 84400, Loss: 7.1943559646606445\n",
      "Epoch: 1, Batch number: 84500, Loss: 6.973268032073975\n",
      "Epoch: 1, Batch number: 84600, Loss: 7.195185661315918\n",
      "Epoch: 1, Batch number: 84700, Loss: 6.913405418395996\n",
      "Epoch: 1, Batch number: 84800, Loss: 7.09018611907959\n",
      "Epoch: 1, Batch number: 84900, Loss: 7.263192176818848\n",
      "Epoch: 1, Batch number: 85000, Loss: 7.170607089996338\n",
      "Epoch: 1, Batch number: 85100, Loss: 7.356929302215576\n",
      "Epoch: 1, Batch number: 85200, Loss: 6.990038871765137\n",
      "Epoch: 1, Batch number: 85300, Loss: 7.154617786407471\n",
      "Epoch: 1, Batch number: 85400, Loss: 7.130359649658203\n",
      "Epoch: 1, Batch number: 85500, Loss: 6.975094318389893\n",
      "Epoch: 1, Batch number: 85600, Loss: 6.922336101531982\n",
      "Epoch: 1, Batch number: 85700, Loss: 6.872617244720459\n",
      "Epoch: 1, Batch number: 85800, Loss: 6.961008548736572\n",
      "Epoch: 1, Batch number: 85900, Loss: 6.970523834228516\n",
      "Epoch: 1, Batch number: 86000, Loss: 6.953388690948486\n",
      "Epoch: 1, Batch number: 86100, Loss: 6.863999366760254\n",
      "Epoch: 1, Batch number: 86200, Loss: 7.181125164031982\n",
      "Epoch: 1, Batch number: 86300, Loss: 7.0811767578125\n",
      "Epoch: 1, Batch number: 86400, Loss: 7.079912185668945\n",
      "Epoch: 1, Batch number: 86500, Loss: 7.006940841674805\n",
      "Epoch: 1, Batch number: 86600, Loss: 7.11426305770874\n",
      "Epoch: 1, Batch number: 86700, Loss: 6.7908034324646\n",
      "Epoch: 1, Batch number: 86800, Loss: 7.330348968505859\n",
      "Epoch: 1, Batch number: 86900, Loss: 7.02520227432251\n",
      "Epoch: 1, Batch number: 87000, Loss: 7.091029644012451\n",
      "Epoch: 1, Batch number: 87100, Loss: 7.081985950469971\n",
      "Epoch: 1, Batch number: 87200, Loss: 6.94096040725708\n",
      "Epoch: 1, Batch number: 87300, Loss: 7.078518390655518\n",
      "Epoch: 1, Batch number: 87400, Loss: 7.01354455947876\n",
      "Epoch: 1, Batch number: 87500, Loss: 7.008280277252197\n",
      "Epoch: 1, Batch number: 87600, Loss: 6.9500732421875\n",
      "Epoch: 1, Batch number: 87700, Loss: 7.43402624130249\n",
      "Epoch: 1, Batch number: 87800, Loss: 7.0628767013549805\n",
      "Epoch: 1, Batch number: 87900, Loss: 7.040018558502197\n",
      "Epoch: 1, Batch number: 88000, Loss: 7.146955490112305\n",
      "Epoch: 1, Batch number: 88100, Loss: 6.972363471984863\n",
      "Epoch: 1, Batch number: 88200, Loss: 7.136495113372803\n",
      "Epoch: 1, Batch number: 88300, Loss: 7.207674503326416\n",
      "Epoch: 1, Batch number: 88400, Loss: 7.081799507141113\n",
      "Epoch: 1, Batch number: 88500, Loss: 6.975363731384277\n",
      "Epoch: 1, Batch number: 88600, Loss: 6.946702003479004\n",
      "Epoch: 1, Batch number: 88700, Loss: 7.099449634552002\n",
      "Epoch: 1, Batch number: 88800, Loss: 7.026515007019043\n",
      "Epoch: 1, Batch number: 88900, Loss: 7.09226131439209\n",
      "Epoch: 1, Batch number: 89000, Loss: 7.037489414215088\n",
      "Epoch: 1, Batch number: 89100, Loss: 6.832901954650879\n",
      "Epoch: 1, Batch number: 89200, Loss: 6.908379554748535\n",
      "Epoch: 1, Batch number: 89300, Loss: 6.99688196182251\n",
      "Epoch: 1, Batch number: 89400, Loss: 7.193160533905029\n",
      "Epoch: 1, Batch number: 89500, Loss: 6.839996337890625\n",
      "Epoch: 2, Batch number: 12, Loss: 6.965445518493652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 112, Loss: 6.641622543334961\n",
      "Epoch: 2, Batch number: 212, Loss: 6.9228739738464355\n",
      "Epoch: 2, Batch number: 312, Loss: 6.866583347320557\n",
      "Epoch: 2, Batch number: 412, Loss: 6.991401195526123\n",
      "Epoch: 2, Batch number: 512, Loss: 7.056544780731201\n",
      "Epoch: 2, Batch number: 612, Loss: 6.946160316467285\n",
      "Epoch: 2, Batch number: 712, Loss: 7.200469493865967\n",
      "Epoch: 2, Batch number: 812, Loss: 6.86555814743042\n",
      "Epoch: 2, Batch number: 912, Loss: 6.807487487792969\n",
      "Epoch: 2, Batch number: 1012, Loss: 7.028048992156982\n",
      "Epoch: 2, Batch number: 1112, Loss: 6.985781669616699\n",
      "Epoch: 2, Batch number: 1212, Loss: 6.820413112640381\n",
      "Epoch: 2, Batch number: 1312, Loss: 7.11613130569458\n",
      "Epoch: 2, Batch number: 1412, Loss: 6.6908159255981445\n",
      "Epoch: 2, Batch number: 1512, Loss: 6.912229061126709\n",
      "Epoch: 2, Batch number: 1612, Loss: 6.958860874176025\n",
      "Epoch: 2, Batch number: 1712, Loss: 7.093877792358398\n",
      "Epoch: 2, Batch number: 1812, Loss: 6.768916130065918\n",
      "Epoch: 2, Batch number: 1912, Loss: 6.909704208374023\n",
      "Epoch: 2, Batch number: 2012, Loss: 6.784393787384033\n",
      "Epoch: 2, Batch number: 2112, Loss: 6.80184268951416\n",
      "Epoch: 2, Batch number: 2212, Loss: 7.050657272338867\n",
      "Epoch: 2, Batch number: 2312, Loss: 7.003026962280273\n",
      "Epoch: 2, Batch number: 2412, Loss: 7.013625144958496\n",
      "Epoch: 2, Batch number: 2512, Loss: 7.159846782684326\n",
      "Epoch: 2, Batch number: 2612, Loss: 7.007901191711426\n",
      "Epoch: 2, Batch number: 2712, Loss: 7.143759727478027\n",
      "Epoch: 2, Batch number: 2812, Loss: 7.002681255340576\n",
      "Epoch: 2, Batch number: 2912, Loss: 7.149422645568848\n",
      "Epoch: 2, Batch number: 3012, Loss: 6.998186111450195\n",
      "Epoch: 2, Batch number: 3112, Loss: 6.8710036277771\n",
      "Epoch: 2, Batch number: 3212, Loss: 7.104200839996338\n",
      "Epoch: 2, Batch number: 3312, Loss: 6.987496852874756\n",
      "Epoch: 2, Batch number: 3412, Loss: 6.72005558013916\n",
      "Epoch: 2, Batch number: 3512, Loss: 6.9902663230896\n",
      "Epoch: 2, Batch number: 3612, Loss: 6.899440288543701\n",
      "Epoch: 2, Batch number: 3712, Loss: 6.990510940551758\n",
      "Epoch: 2, Batch number: 3812, Loss: 6.840026378631592\n",
      "Epoch: 2, Batch number: 3912, Loss: 6.824156284332275\n",
      "Epoch: 2, Batch number: 4012, Loss: 7.014390468597412\n",
      "Epoch: 2, Batch number: 4112, Loss: 6.964338779449463\n",
      "Epoch: 2, Batch number: 4212, Loss: 6.84127140045166\n",
      "Epoch: 2, Batch number: 4312, Loss: 6.846245765686035\n",
      "Epoch: 2, Batch number: 4412, Loss: 6.950661659240723\n",
      "Epoch: 2, Batch number: 4512, Loss: 7.134259223937988\n",
      "Epoch: 2, Batch number: 4612, Loss: 6.733527183532715\n",
      "Epoch: 2, Batch number: 4712, Loss: 6.871111869812012\n",
      "Epoch: 2, Batch number: 4812, Loss: 7.139188289642334\n",
      "Epoch: 2, Batch number: 4912, Loss: 6.9368577003479\n",
      "Epoch: 2, Batch number: 5012, Loss: 6.855099201202393\n",
      "Epoch: 2, Batch number: 5112, Loss: 6.926517009735107\n",
      "Epoch: 2, Batch number: 5212, Loss: 7.13657283782959\n",
      "Epoch: 2, Batch number: 5312, Loss: 7.063232421875\n",
      "Epoch: 2, Batch number: 5412, Loss: 6.853572368621826\n",
      "Epoch: 2, Batch number: 5512, Loss: 6.7752604484558105\n",
      "Epoch: 2, Batch number: 5612, Loss: 6.957636833190918\n",
      "Epoch: 2, Batch number: 5712, Loss: 7.2162346839904785\n",
      "Epoch: 2, Batch number: 5812, Loss: 6.888755798339844\n",
      "Epoch: 2, Batch number: 5912, Loss: 6.938836097717285\n",
      "Epoch: 2, Batch number: 6012, Loss: 6.960475444793701\n",
      "Epoch: 2, Batch number: 6112, Loss: 6.950538635253906\n",
      "Epoch: 2, Batch number: 6212, Loss: 6.896162986755371\n",
      "Epoch: 2, Batch number: 6312, Loss: 6.974722385406494\n",
      "Epoch: 2, Batch number: 6412, Loss: 7.093345642089844\n",
      "Epoch: 2, Batch number: 6512, Loss: 6.8163862228393555\n",
      "Epoch: 2, Batch number: 6612, Loss: 6.907050609588623\n",
      "Epoch: 2, Batch number: 6712, Loss: 6.961726665496826\n",
      "Epoch: 2, Batch number: 6812, Loss: 6.866186141967773\n",
      "Epoch: 2, Batch number: 6912, Loss: 7.066739082336426\n",
      "Epoch: 2, Batch number: 7012, Loss: 6.8680009841918945\n",
      "Epoch: 2, Batch number: 7112, Loss: 6.96442985534668\n",
      "Epoch: 2, Batch number: 7212, Loss: 6.74990701675415\n",
      "Epoch: 2, Batch number: 7312, Loss: 6.712506294250488\n",
      "Epoch: 2, Batch number: 7412, Loss: 6.941066741943359\n",
      "Epoch: 2, Batch number: 7512, Loss: 6.937388896942139\n",
      "Epoch: 2, Batch number: 7612, Loss: 7.019320011138916\n",
      "Epoch: 2, Batch number: 7712, Loss: 6.809733867645264\n",
      "Epoch: 2, Batch number: 7812, Loss: 6.971524238586426\n",
      "Epoch: 2, Batch number: 7912, Loss: 6.92179012298584\n",
      "Epoch: 2, Batch number: 8012, Loss: 6.936212062835693\n",
      "Epoch: 2, Batch number: 8112, Loss: 7.104280948638916\n",
      "Epoch: 2, Batch number: 8212, Loss: 7.109645843505859\n",
      "Epoch: 2, Batch number: 8312, Loss: 7.073123455047607\n",
      "Epoch: 2, Batch number: 8412, Loss: 6.854536056518555\n",
      "Epoch: 2, Batch number: 8512, Loss: 6.9499640464782715\n",
      "Epoch: 2, Batch number: 8612, Loss: 6.876250743865967\n",
      "Epoch: 2, Batch number: 8712, Loss: 7.022316932678223\n",
      "Epoch: 2, Batch number: 8812, Loss: 7.061944484710693\n",
      "Epoch: 2, Batch number: 8912, Loss: 7.109214782714844\n",
      "Epoch: 2, Batch number: 9012, Loss: 7.1870551109313965\n",
      "Epoch: 2, Batch number: 9112, Loss: 7.022102355957031\n",
      "Epoch: 2, Batch number: 9212, Loss: 7.009498596191406\n",
      "Epoch: 2, Batch number: 9312, Loss: 6.860986232757568\n",
      "Epoch: 2, Batch number: 9412, Loss: 7.101129531860352\n",
      "Epoch: 2, Batch number: 9512, Loss: 7.053769588470459\n",
      "Epoch: 2, Batch number: 9612, Loss: 6.8489274978637695\n",
      "Epoch: 2, Batch number: 9712, Loss: 6.736011981964111\n",
      "Epoch: 2, Batch number: 9812, Loss: 6.989985942840576\n",
      "Epoch: 2, Batch number: 9912, Loss: 6.998263359069824\n",
      "Epoch: 2, Batch number: 10012, Loss: 7.076509952545166\n",
      "Epoch: 2, Batch number: 10112, Loss: 6.959901332855225\n",
      "Epoch: 2, Batch number: 10212, Loss: 7.115084171295166\n",
      "Epoch: 2, Batch number: 10312, Loss: 7.012729167938232\n",
      "Epoch: 2, Batch number: 10412, Loss: 7.093687057495117\n",
      "Epoch: 2, Batch number: 10512, Loss: 6.914178371429443\n",
      "Epoch: 2, Batch number: 10612, Loss: 6.969598293304443\n",
      "Epoch: 2, Batch number: 10712, Loss: 6.981455326080322\n",
      "Epoch: 2, Batch number: 10812, Loss: 7.005700588226318\n",
      "Epoch: 2, Batch number: 10912, Loss: 7.202944755554199\n",
      "Epoch: 2, Batch number: 11012, Loss: 6.891900539398193\n",
      "Epoch: 2, Batch number: 11112, Loss: 7.0388102531433105\n",
      "Epoch: 2, Batch number: 11212, Loss: 7.173552513122559\n",
      "Epoch: 2, Batch number: 11312, Loss: 6.842854022979736\n",
      "Epoch: 2, Batch number: 11412, Loss: 6.861112594604492\n",
      "Epoch: 2, Batch number: 11512, Loss: 7.062573432922363\n",
      "Epoch: 2, Batch number: 11612, Loss: 6.947765827178955\n",
      "Epoch: 2, Batch number: 11712, Loss: 6.839822292327881\n",
      "Epoch: 2, Batch number: 11812, Loss: 7.133609294891357\n",
      "Epoch: 2, Batch number: 11912, Loss: 6.964913845062256\n",
      "Epoch: 2, Batch number: 12012, Loss: 6.87559175491333\n",
      "Epoch: 2, Batch number: 12112, Loss: 6.93966007232666\n",
      "Epoch: 2, Batch number: 12212, Loss: 6.975086212158203\n",
      "Epoch: 2, Batch number: 12312, Loss: 7.0707621574401855\n",
      "Epoch: 2, Batch number: 12412, Loss: 6.738068580627441\n",
      "Epoch: 2, Batch number: 12512, Loss: 7.037837505340576\n",
      "Epoch: 2, Batch number: 12612, Loss: 7.137578964233398\n",
      "Epoch: 2, Batch number: 12712, Loss: 7.118127346038818\n",
      "Epoch: 2, Batch number: 12812, Loss: 7.083779335021973\n",
      "Epoch: 2, Batch number: 12912, Loss: 7.022599697113037\n",
      "Epoch: 2, Batch number: 13012, Loss: 6.83659029006958\n",
      "Epoch: 2, Batch number: 13112, Loss: 6.857030391693115\n",
      "Epoch: 2, Batch number: 13212, Loss: 6.951439380645752\n",
      "Epoch: 2, Batch number: 13312, Loss: 7.009191036224365\n",
      "Epoch: 2, Batch number: 13412, Loss: 7.0341925621032715\n",
      "Epoch: 2, Batch number: 13512, Loss: 7.022426605224609\n",
      "Epoch: 2, Batch number: 13612, Loss: 7.184101581573486\n",
      "Epoch: 2, Batch number: 13712, Loss: 6.932888031005859\n",
      "Epoch: 2, Batch number: 13812, Loss: 7.06795072555542\n",
      "Epoch: 2, Batch number: 13912, Loss: 6.967852592468262\n",
      "Epoch: 2, Batch number: 14012, Loss: 6.892668724060059\n",
      "Epoch: 2, Batch number: 14112, Loss: 6.960993766784668\n",
      "Epoch: 2, Batch number: 14212, Loss: 7.04494571685791\n",
      "Epoch: 2, Batch number: 14312, Loss: 7.115860462188721\n",
      "Epoch: 2, Batch number: 14412, Loss: 6.83411169052124\n",
      "Epoch: 2, Batch number: 14512, Loss: 7.153059482574463\n",
      "Epoch: 2, Batch number: 14612, Loss: 6.956022262573242\n",
      "Epoch: 2, Batch number: 14712, Loss: 6.783409595489502\n",
      "Epoch: 2, Batch number: 14812, Loss: 6.993793487548828\n",
      "Epoch: 2, Batch number: 14912, Loss: 6.934208869934082\n",
      "Epoch: 2, Batch number: 15012, Loss: 6.5953216552734375\n",
      "Epoch: 2, Batch number: 15112, Loss: 6.800016403198242\n",
      "Epoch: 2, Batch number: 15212, Loss: 6.937079906463623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 15312, Loss: 7.030548095703125\n",
      "Epoch: 2, Batch number: 15412, Loss: 7.128864288330078\n",
      "Epoch: 2, Batch number: 15512, Loss: 7.1010823249816895\n",
      "Epoch: 2, Batch number: 15612, Loss: 6.933163642883301\n",
      "Epoch: 2, Batch number: 15712, Loss: 6.786186695098877\n",
      "Epoch: 2, Batch number: 15812, Loss: 7.155521869659424\n",
      "Epoch: 2, Batch number: 15912, Loss: 7.157838344573975\n",
      "Epoch: 2, Batch number: 16012, Loss: 6.631052494049072\n",
      "Epoch: 2, Batch number: 16112, Loss: 7.107619285583496\n",
      "Epoch: 2, Batch number: 16212, Loss: 6.931703567504883\n",
      "Epoch: 2, Batch number: 16312, Loss: 7.199376106262207\n",
      "Epoch: 2, Batch number: 16412, Loss: 6.7338151931762695\n",
      "Epoch: 2, Batch number: 16512, Loss: 6.99816370010376\n",
      "Epoch: 2, Batch number: 16612, Loss: 6.931698799133301\n",
      "Epoch: 2, Batch number: 16712, Loss: 6.965493679046631\n",
      "Epoch: 2, Batch number: 16812, Loss: 6.857831954956055\n",
      "Epoch: 2, Batch number: 16912, Loss: 7.022164821624756\n",
      "Epoch: 2, Batch number: 17012, Loss: 6.876627445220947\n",
      "Epoch: 2, Batch number: 17112, Loss: 6.908405780792236\n",
      "Epoch: 2, Batch number: 17212, Loss: 6.842835426330566\n",
      "Epoch: 2, Batch number: 17312, Loss: 6.935786724090576\n",
      "Epoch: 2, Batch number: 17412, Loss: 6.899108409881592\n",
      "Epoch: 2, Batch number: 17512, Loss: 6.6725335121154785\n",
      "Epoch: 2, Batch number: 17612, Loss: 7.261538505554199\n",
      "Epoch: 2, Batch number: 17712, Loss: 7.11212158203125\n",
      "Epoch: 2, Batch number: 17812, Loss: 7.009210586547852\n",
      "Epoch: 2, Batch number: 17912, Loss: 6.846170425415039\n",
      "Epoch: 2, Batch number: 18012, Loss: 6.8527703285217285\n",
      "Epoch: 2, Batch number: 18112, Loss: 7.008040428161621\n",
      "Epoch: 2, Batch number: 18212, Loss: 7.206770896911621\n",
      "Epoch: 2, Batch number: 18312, Loss: 6.990027904510498\n",
      "Epoch: 2, Batch number: 18412, Loss: 7.002801418304443\n",
      "Epoch: 2, Batch number: 18512, Loss: 7.19257926940918\n",
      "Epoch: 2, Batch number: 18612, Loss: 7.255380153656006\n",
      "Epoch: 2, Batch number: 18712, Loss: 7.034013748168945\n",
      "Epoch: 2, Batch number: 18812, Loss: 7.192692279815674\n",
      "Epoch: 2, Batch number: 18912, Loss: 7.032832622528076\n",
      "Epoch: 2, Batch number: 19012, Loss: 6.8904709815979\n",
      "Epoch: 2, Batch number: 19112, Loss: 7.068483352661133\n",
      "Epoch: 2, Batch number: 19212, Loss: 6.918910980224609\n",
      "Epoch: 2, Batch number: 19312, Loss: 6.977617263793945\n",
      "Epoch: 2, Batch number: 19412, Loss: 6.79500150680542\n",
      "Epoch: 2, Batch number: 19512, Loss: 6.908972263336182\n",
      "Epoch: 2, Batch number: 19612, Loss: 7.008665084838867\n",
      "Epoch: 2, Batch number: 19712, Loss: 7.150854110717773\n",
      "Epoch: 2, Batch number: 19812, Loss: 6.532496929168701\n",
      "Epoch: 2, Batch number: 19912, Loss: 6.8010759353637695\n",
      "Epoch: 2, Batch number: 20012, Loss: 6.962724685668945\n",
      "Epoch: 2, Batch number: 20112, Loss: 6.989495754241943\n",
      "Epoch: 2, Batch number: 20212, Loss: 7.007689952850342\n",
      "Epoch: 2, Batch number: 20312, Loss: 7.061130046844482\n",
      "Epoch: 2, Batch number: 20412, Loss: 7.025338649749756\n",
      "Epoch: 2, Batch number: 20512, Loss: 6.688898086547852\n",
      "Epoch: 2, Batch number: 20612, Loss: 6.842907905578613\n",
      "Epoch: 2, Batch number: 20712, Loss: 7.0909037590026855\n",
      "Epoch: 2, Batch number: 20812, Loss: 7.138586521148682\n",
      "Epoch: 2, Batch number: 20912, Loss: 7.164019584655762\n",
      "Epoch: 2, Batch number: 21012, Loss: 7.054268836975098\n",
      "Epoch: 2, Batch number: 21112, Loss: 7.166663646697998\n",
      "Epoch: 2, Batch number: 21212, Loss: 6.976805686950684\n",
      "Epoch: 2, Batch number: 21312, Loss: 6.929274082183838\n",
      "Epoch: 2, Batch number: 21412, Loss: 7.044781684875488\n",
      "Epoch: 2, Batch number: 21512, Loss: 7.099151134490967\n",
      "Epoch: 2, Batch number: 21612, Loss: 6.9666619300842285\n",
      "Epoch: 2, Batch number: 21712, Loss: 6.896414279937744\n",
      "Epoch: 2, Batch number: 21812, Loss: 7.046928405761719\n",
      "Epoch: 2, Batch number: 21912, Loss: 7.278941631317139\n",
      "Epoch: 2, Batch number: 22012, Loss: 7.011005878448486\n",
      "Epoch: 2, Batch number: 22112, Loss: 6.758550643920898\n",
      "Epoch: 2, Batch number: 22212, Loss: 6.951595783233643\n",
      "Epoch: 2, Batch number: 22312, Loss: 7.178723335266113\n",
      "Epoch: 2, Batch number: 22412, Loss: 7.219971656799316\n",
      "Epoch: 2, Batch number: 22512, Loss: 6.865464210510254\n",
      "Epoch: 2, Batch number: 22612, Loss: 6.948980331420898\n",
      "Epoch: 2, Batch number: 22712, Loss: 7.174087047576904\n",
      "Epoch: 2, Batch number: 22812, Loss: 6.871176719665527\n",
      "Epoch: 2, Batch number: 22912, Loss: 7.034471035003662\n",
      "Epoch: 2, Batch number: 23012, Loss: 7.080596923828125\n",
      "Epoch: 2, Batch number: 23112, Loss: 6.793185710906982\n",
      "Epoch: 2, Batch number: 23212, Loss: 6.941411972045898\n",
      "Epoch: 2, Batch number: 23312, Loss: 7.0558061599731445\n",
      "Epoch: 2, Batch number: 23412, Loss: 6.778726100921631\n",
      "Epoch: 2, Batch number: 23512, Loss: 7.123780727386475\n",
      "Epoch: 2, Batch number: 23612, Loss: 6.837654113769531\n",
      "Epoch: 2, Batch number: 23712, Loss: 7.127754211425781\n",
      "Epoch: 2, Batch number: 23812, Loss: 6.741343975067139\n",
      "Epoch: 2, Batch number: 23912, Loss: 7.003565311431885\n",
      "Epoch: 2, Batch number: 24012, Loss: 6.957408905029297\n",
      "Epoch: 2, Batch number: 24112, Loss: 7.271132946014404\n",
      "Epoch: 2, Batch number: 24212, Loss: 6.756119728088379\n",
      "Epoch: 2, Batch number: 24312, Loss: 7.09377384185791\n",
      "Epoch: 2, Batch number: 24412, Loss: 6.84188985824585\n",
      "Epoch: 2, Batch number: 24512, Loss: 7.062324523925781\n",
      "Epoch: 2, Batch number: 24612, Loss: 6.910458564758301\n",
      "Epoch: 2, Batch number: 24712, Loss: 6.972529888153076\n",
      "Epoch: 2, Batch number: 24812, Loss: 7.042257785797119\n",
      "Epoch: 2, Batch number: 24912, Loss: 7.025797367095947\n",
      "Epoch: 2, Batch number: 25012, Loss: 7.138181686401367\n",
      "Epoch: 2, Batch number: 25112, Loss: 6.828124046325684\n",
      "Epoch: 2, Batch number: 25212, Loss: 7.129770278930664\n",
      "Epoch: 2, Batch number: 25312, Loss: 6.94187593460083\n",
      "Epoch: 2, Batch number: 25412, Loss: 7.1173505783081055\n",
      "Epoch: 2, Batch number: 25512, Loss: 7.24810266494751\n",
      "Epoch: 2, Batch number: 25612, Loss: 6.8036909103393555\n",
      "Epoch: 2, Batch number: 25712, Loss: 6.932895660400391\n",
      "Epoch: 2, Batch number: 25812, Loss: 7.051009178161621\n",
      "Epoch: 2, Batch number: 25912, Loss: 6.961693286895752\n",
      "Epoch: 2, Batch number: 26012, Loss: 7.022848129272461\n",
      "Epoch: 2, Batch number: 26112, Loss: 6.859033584594727\n",
      "Epoch: 2, Batch number: 26212, Loss: 6.693282127380371\n",
      "Epoch: 2, Batch number: 26312, Loss: 7.021316051483154\n",
      "Epoch: 2, Batch number: 26412, Loss: 7.040897369384766\n",
      "Epoch: 2, Batch number: 26512, Loss: 6.927928924560547\n",
      "Epoch: 2, Batch number: 26612, Loss: 6.973961353302002\n",
      "Epoch: 2, Batch number: 26712, Loss: 7.054227352142334\n",
      "Epoch: 2, Batch number: 26812, Loss: 7.042485237121582\n",
      "Epoch: 2, Batch number: 26912, Loss: 6.830777168273926\n",
      "Epoch: 2, Batch number: 27012, Loss: 6.832038402557373\n",
      "Epoch: 2, Batch number: 27112, Loss: 6.982715129852295\n",
      "Epoch: 2, Batch number: 27212, Loss: 7.209202766418457\n",
      "Epoch: 2, Batch number: 27312, Loss: 7.005526542663574\n",
      "Epoch: 2, Batch number: 27412, Loss: 6.903587341308594\n",
      "Epoch: 2, Batch number: 27512, Loss: 6.726726531982422\n",
      "Epoch: 2, Batch number: 27612, Loss: 6.922286033630371\n",
      "Epoch: 2, Batch number: 27712, Loss: 7.134930610656738\n",
      "Epoch: 2, Batch number: 27812, Loss: 6.846663475036621\n",
      "Epoch: 2, Batch number: 27912, Loss: 7.039149284362793\n",
      "Epoch: 2, Batch number: 28012, Loss: 6.909449100494385\n",
      "Epoch: 2, Batch number: 28112, Loss: 6.889089107513428\n",
      "Epoch: 2, Batch number: 28212, Loss: 6.740736484527588\n",
      "Epoch: 2, Batch number: 28312, Loss: 6.800734519958496\n",
      "Epoch: 2, Batch number: 28412, Loss: 7.029341697692871\n",
      "Epoch: 2, Batch number: 28512, Loss: 6.911118507385254\n",
      "Epoch: 2, Batch number: 28612, Loss: 6.975917816162109\n",
      "Epoch: 2, Batch number: 28712, Loss: 6.795095443725586\n",
      "Epoch: 2, Batch number: 28812, Loss: 7.161944389343262\n",
      "Epoch: 2, Batch number: 28912, Loss: 6.912712097167969\n",
      "Epoch: 2, Batch number: 29012, Loss: 7.370216369628906\n",
      "Epoch: 2, Batch number: 29112, Loss: 6.998295783996582\n",
      "Epoch: 2, Batch number: 29212, Loss: 6.847658157348633\n",
      "Epoch: 2, Batch number: 29312, Loss: 6.937562942504883\n",
      "Epoch: 2, Batch number: 29412, Loss: 6.730135440826416\n",
      "Epoch: 2, Batch number: 29512, Loss: 6.980465888977051\n",
      "Epoch: 2, Batch number: 29612, Loss: 6.864555835723877\n",
      "Epoch: 2, Batch number: 29712, Loss: 6.839031219482422\n",
      "Epoch: 2, Batch number: 29812, Loss: 6.823525428771973\n",
      "Epoch: 2, Batch number: 29912, Loss: 7.085941314697266\n",
      "Epoch: 2, Batch number: 30012, Loss: 7.313201427459717\n",
      "Epoch: 2, Batch number: 30112, Loss: 6.968344688415527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 30212, Loss: 6.760458946228027\n",
      "Epoch: 2, Batch number: 30312, Loss: 7.140899658203125\n",
      "Epoch: 2, Batch number: 30412, Loss: 7.086085319519043\n",
      "Epoch: 2, Batch number: 30512, Loss: 7.189096450805664\n",
      "Epoch: 2, Batch number: 30612, Loss: 7.026693820953369\n",
      "Epoch: 2, Batch number: 30712, Loss: 7.025976181030273\n",
      "Epoch: 2, Batch number: 30812, Loss: 7.027937889099121\n",
      "Epoch: 2, Batch number: 30912, Loss: 6.976840496063232\n",
      "Epoch: 2, Batch number: 31012, Loss: 6.763932704925537\n",
      "Epoch: 2, Batch number: 31112, Loss: 7.1062397956848145\n",
      "Epoch: 2, Batch number: 31212, Loss: 6.962779521942139\n",
      "Epoch: 2, Batch number: 31312, Loss: 6.902525901794434\n",
      "Epoch: 2, Batch number: 31412, Loss: 6.751234531402588\n",
      "Epoch: 2, Batch number: 31512, Loss: 6.837856769561768\n",
      "Epoch: 2, Batch number: 31612, Loss: 6.988844394683838\n",
      "Epoch: 2, Batch number: 31712, Loss: 6.817753314971924\n",
      "Epoch: 2, Batch number: 31812, Loss: 6.921695709228516\n",
      "Epoch: 2, Batch number: 31912, Loss: 6.88108491897583\n",
      "Epoch: 2, Batch number: 32012, Loss: 6.937796592712402\n",
      "Epoch: 2, Batch number: 32112, Loss: 7.091331481933594\n",
      "Epoch: 2, Batch number: 32212, Loss: 7.05839729309082\n",
      "Epoch: 2, Batch number: 32312, Loss: 6.77376651763916\n",
      "Epoch: 2, Batch number: 32412, Loss: 7.102024555206299\n",
      "Epoch: 2, Batch number: 32512, Loss: 6.97432804107666\n",
      "Epoch: 2, Batch number: 32612, Loss: 7.068081855773926\n",
      "Epoch: 2, Batch number: 32712, Loss: 6.732314109802246\n",
      "Epoch: 2, Batch number: 32812, Loss: 7.307365894317627\n",
      "Epoch: 2, Batch number: 32912, Loss: 6.752718448638916\n",
      "Epoch: 2, Batch number: 33012, Loss: 6.848827362060547\n",
      "Epoch: 2, Batch number: 33112, Loss: 7.093231201171875\n",
      "Epoch: 2, Batch number: 33212, Loss: 7.054396152496338\n",
      "Epoch: 2, Batch number: 33312, Loss: 7.010805130004883\n",
      "Epoch: 2, Batch number: 33412, Loss: 6.848933219909668\n",
      "Epoch: 2, Batch number: 33512, Loss: 6.84438943862915\n",
      "Epoch: 2, Batch number: 33612, Loss: 6.983277797698975\n",
      "Epoch: 2, Batch number: 33712, Loss: 6.706124782562256\n",
      "Epoch: 2, Batch number: 33812, Loss: 7.057401657104492\n",
      "Epoch: 2, Batch number: 33912, Loss: 7.094925880432129\n",
      "Epoch: 2, Batch number: 34012, Loss: 7.288423538208008\n",
      "Epoch: 2, Batch number: 34112, Loss: 7.0040130615234375\n",
      "Epoch: 2, Batch number: 34212, Loss: 7.076559066772461\n",
      "Epoch: 2, Batch number: 34312, Loss: 6.9036664962768555\n",
      "Epoch: 2, Batch number: 34412, Loss: 6.907333850860596\n",
      "Epoch: 2, Batch number: 34512, Loss: 7.22507381439209\n",
      "Epoch: 2, Batch number: 34612, Loss: 7.015501022338867\n",
      "Epoch: 2, Batch number: 34712, Loss: 6.828907489776611\n",
      "Epoch: 2, Batch number: 34812, Loss: 7.09656286239624\n",
      "Epoch: 2, Batch number: 34912, Loss: 6.9873552322387695\n",
      "Epoch: 2, Batch number: 35012, Loss: 7.042044162750244\n",
      "Epoch: 2, Batch number: 35112, Loss: 6.934945106506348\n",
      "Epoch: 2, Batch number: 35212, Loss: 7.177737712860107\n",
      "Epoch: 2, Batch number: 35312, Loss: 6.677474498748779\n",
      "Epoch: 2, Batch number: 35412, Loss: 6.997252464294434\n",
      "Epoch: 2, Batch number: 35512, Loss: 7.154786586761475\n",
      "Epoch: 2, Batch number: 35612, Loss: 7.050666332244873\n",
      "Epoch: 2, Batch number: 35712, Loss: 7.115240573883057\n",
      "Epoch: 2, Batch number: 35812, Loss: 6.8176469802856445\n",
      "Epoch: 2, Batch number: 35912, Loss: 7.019749164581299\n",
      "Epoch: 2, Batch number: 36012, Loss: 7.1991472244262695\n",
      "Epoch: 2, Batch number: 36112, Loss: 7.002947807312012\n",
      "Epoch: 2, Batch number: 36212, Loss: 7.2047600746154785\n",
      "Epoch: 2, Batch number: 36312, Loss: 7.043029308319092\n",
      "Epoch: 2, Batch number: 36412, Loss: 7.415053367614746\n",
      "Epoch: 2, Batch number: 36512, Loss: 7.1131486892700195\n",
      "Epoch: 2, Batch number: 36612, Loss: 6.942471504211426\n",
      "Epoch: 2, Batch number: 36712, Loss: 7.012743949890137\n",
      "Epoch: 2, Batch number: 36812, Loss: 7.139837741851807\n",
      "Epoch: 2, Batch number: 36912, Loss: 6.838267803192139\n",
      "Epoch: 2, Batch number: 37012, Loss: 6.781877040863037\n",
      "Epoch: 2, Batch number: 37112, Loss: 6.951616287231445\n",
      "Epoch: 2, Batch number: 37212, Loss: 6.809535503387451\n",
      "Epoch: 2, Batch number: 37312, Loss: 6.838174343109131\n",
      "Epoch: 2, Batch number: 37412, Loss: 6.90620231628418\n",
      "Epoch: 2, Batch number: 37512, Loss: 6.872219085693359\n",
      "Epoch: 2, Batch number: 37612, Loss: 6.860644817352295\n",
      "Epoch: 2, Batch number: 37712, Loss: 6.9111247062683105\n",
      "Epoch: 2, Batch number: 37812, Loss: 7.002131462097168\n",
      "Epoch: 2, Batch number: 37912, Loss: 6.839210033416748\n",
      "Epoch: 2, Batch number: 38012, Loss: 7.076738357543945\n",
      "Epoch: 2, Batch number: 38112, Loss: 6.807312965393066\n",
      "Epoch: 2, Batch number: 38212, Loss: 6.977201461791992\n",
      "Epoch: 2, Batch number: 38312, Loss: 6.846456050872803\n",
      "Epoch: 2, Batch number: 38412, Loss: 6.865645408630371\n",
      "Epoch: 2, Batch number: 38512, Loss: 7.312200546264648\n",
      "Epoch: 2, Batch number: 38612, Loss: 7.2403717041015625\n",
      "Epoch: 2, Batch number: 38712, Loss: 6.92428731918335\n",
      "Epoch: 2, Batch number: 38812, Loss: 6.8966593742370605\n",
      "Epoch: 2, Batch number: 38912, Loss: 7.068397045135498\n",
      "Epoch: 2, Batch number: 39012, Loss: 6.916692733764648\n",
      "Epoch: 2, Batch number: 39112, Loss: 6.8807759284973145\n",
      "Epoch: 2, Batch number: 39212, Loss: 6.833186626434326\n",
      "Epoch: 2, Batch number: 39312, Loss: 6.918712615966797\n",
      "Epoch: 2, Batch number: 39412, Loss: 7.000817775726318\n",
      "Epoch: 2, Batch number: 39512, Loss: 6.9902424812316895\n",
      "Epoch: 2, Batch number: 39612, Loss: 7.20590353012085\n",
      "Epoch: 2, Batch number: 39712, Loss: 6.746245384216309\n",
      "Epoch: 2, Batch number: 39812, Loss: 6.880080223083496\n",
      "Epoch: 2, Batch number: 39912, Loss: 6.9717020988464355\n",
      "Epoch: 2, Batch number: 40012, Loss: 7.325223922729492\n",
      "Epoch: 2, Batch number: 40112, Loss: 6.956473350524902\n",
      "Epoch: 2, Batch number: 40212, Loss: 6.985814571380615\n",
      "Epoch: 2, Batch number: 40312, Loss: 6.910686492919922\n",
      "Epoch: 2, Batch number: 40412, Loss: 7.1504411697387695\n",
      "Epoch: 2, Batch number: 40512, Loss: 6.899522304534912\n",
      "Epoch: 2, Batch number: 40612, Loss: 6.6884331703186035\n",
      "Epoch: 2, Batch number: 40712, Loss: 7.211819171905518\n",
      "Epoch: 2, Batch number: 40812, Loss: 7.036163330078125\n",
      "Epoch: 2, Batch number: 40912, Loss: 6.988470554351807\n",
      "Epoch: 2, Batch number: 41012, Loss: 6.90385103225708\n",
      "Epoch: 2, Batch number: 41112, Loss: 6.9551920890808105\n",
      "Epoch: 2, Batch number: 41212, Loss: 6.769908428192139\n",
      "Epoch: 2, Batch number: 41312, Loss: 7.333018779754639\n",
      "Epoch: 2, Batch number: 41412, Loss: 7.0700883865356445\n",
      "Epoch: 2, Batch number: 41512, Loss: 6.962276458740234\n",
      "Epoch: 2, Batch number: 41612, Loss: 6.811520576477051\n",
      "Epoch: 2, Batch number: 41712, Loss: 6.921212673187256\n",
      "Epoch: 2, Batch number: 41812, Loss: 7.02511739730835\n",
      "Epoch: 2, Batch number: 41912, Loss: 6.747076511383057\n",
      "Epoch: 2, Batch number: 42012, Loss: 6.704456329345703\n",
      "Epoch: 2, Batch number: 42112, Loss: 7.116891860961914\n",
      "Epoch: 2, Batch number: 42212, Loss: 7.069598197937012\n",
      "Epoch: 2, Batch number: 42312, Loss: 6.787126541137695\n",
      "Epoch: 2, Batch number: 42412, Loss: 7.001101016998291\n",
      "Epoch: 2, Batch number: 42512, Loss: 7.140219688415527\n",
      "Epoch: 2, Batch number: 42612, Loss: 7.20290994644165\n",
      "Epoch: 2, Batch number: 42712, Loss: 7.088146686553955\n",
      "Epoch: 2, Batch number: 42812, Loss: 7.014445781707764\n",
      "Epoch: 2, Batch number: 42912, Loss: 6.9634552001953125\n",
      "Epoch: 2, Batch number: 43012, Loss: 6.978671073913574\n",
      "Epoch: 2, Batch number: 43112, Loss: 6.936299800872803\n",
      "Epoch: 2, Batch number: 43212, Loss: 6.945623874664307\n",
      "Epoch: 2, Batch number: 43312, Loss: 6.690364360809326\n",
      "Epoch: 2, Batch number: 43412, Loss: 6.932316303253174\n",
      "Epoch: 2, Batch number: 43512, Loss: 6.837736129760742\n",
      "Epoch: 2, Batch number: 43612, Loss: 6.9450459480285645\n",
      "Epoch: 2, Batch number: 43712, Loss: 6.824100971221924\n",
      "Epoch: 2, Batch number: 43812, Loss: 7.022886276245117\n",
      "Epoch: 2, Batch number: 43912, Loss: 6.837365627288818\n",
      "Epoch: 2, Batch number: 44012, Loss: 6.805418014526367\n",
      "Epoch: 2, Batch number: 44112, Loss: 6.95880126953125\n",
      "Epoch: 2, Batch number: 44212, Loss: 7.3072028160095215\n",
      "Epoch: 2, Batch number: 44312, Loss: 6.939464569091797\n",
      "Epoch: 2, Batch number: 44412, Loss: 6.9709906578063965\n",
      "Epoch: 2, Batch number: 44512, Loss: 7.086181163787842\n",
      "Epoch: 2, Batch number: 44612, Loss: 6.936214447021484\n",
      "Epoch: 2, Batch number: 44712, Loss: 7.221737861633301\n",
      "Epoch: 2, Batch number: 44812, Loss: 7.391468524932861\n",
      "Epoch: 2, Batch number: 44912, Loss: 7.010405540466309\n",
      "Epoch: 2, Batch number: 45012, Loss: 7.146858215332031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 45112, Loss: 6.874962329864502\n",
      "Epoch: 2, Batch number: 45212, Loss: 6.967273235321045\n",
      "Epoch: 2, Batch number: 45312, Loss: 7.008383750915527\n",
      "Epoch: 2, Batch number: 45412, Loss: 6.980703830718994\n",
      "Epoch: 2, Batch number: 45512, Loss: 6.982284069061279\n",
      "Epoch: 2, Batch number: 45612, Loss: 6.930966854095459\n",
      "Epoch: 2, Batch number: 45712, Loss: 6.974979877471924\n",
      "Epoch: 2, Batch number: 45812, Loss: 7.069748878479004\n",
      "Epoch: 2, Batch number: 45912, Loss: 7.046455383300781\n",
      "Epoch: 2, Batch number: 46012, Loss: 7.2272562980651855\n",
      "Epoch: 2, Batch number: 46112, Loss: 7.147893905639648\n",
      "Epoch: 2, Batch number: 46212, Loss: 6.88507604598999\n",
      "Epoch: 2, Batch number: 46312, Loss: 6.857820987701416\n",
      "Epoch: 2, Batch number: 46412, Loss: 7.000139236450195\n",
      "Epoch: 2, Batch number: 46512, Loss: 7.097516059875488\n",
      "Epoch: 2, Batch number: 46612, Loss: 6.9924821853637695\n",
      "Epoch: 2, Batch number: 46712, Loss: 6.798283576965332\n",
      "Epoch: 2, Batch number: 46812, Loss: 6.858398914337158\n",
      "Epoch: 2, Batch number: 46912, Loss: 7.101430892944336\n",
      "Epoch: 2, Batch number: 47012, Loss: 6.899663925170898\n",
      "Epoch: 2, Batch number: 47112, Loss: 6.874772071838379\n",
      "Epoch: 2, Batch number: 47212, Loss: 7.22226619720459\n",
      "Epoch: 2, Batch number: 47312, Loss: 6.827090740203857\n",
      "Epoch: 2, Batch number: 47412, Loss: 6.788715839385986\n",
      "Epoch: 2, Batch number: 47512, Loss: 6.847499370574951\n",
      "Epoch: 2, Batch number: 47612, Loss: 6.96590518951416\n",
      "Epoch: 2, Batch number: 47712, Loss: 7.099828243255615\n",
      "Epoch: 2, Batch number: 47812, Loss: 7.001672267913818\n",
      "Epoch: 2, Batch number: 47912, Loss: 6.904953479766846\n",
      "Epoch: 2, Batch number: 48012, Loss: 6.983088970184326\n",
      "Epoch: 2, Batch number: 48112, Loss: 6.963099002838135\n",
      "Epoch: 2, Batch number: 48212, Loss: 7.100914478302002\n",
      "Epoch: 2, Batch number: 48312, Loss: 6.7071146965026855\n",
      "Epoch: 2, Batch number: 48412, Loss: 6.7312750816345215\n",
      "Epoch: 2, Batch number: 48512, Loss: 7.243594646453857\n",
      "Epoch: 2, Batch number: 48612, Loss: 6.81365966796875\n",
      "Epoch: 2, Batch number: 48712, Loss: 7.0120368003845215\n",
      "Epoch: 2, Batch number: 48812, Loss: 7.112657070159912\n",
      "Epoch: 2, Batch number: 48912, Loss: 6.848608493804932\n",
      "Epoch: 2, Batch number: 49012, Loss: 6.792380332946777\n",
      "Epoch: 2, Batch number: 49112, Loss: 7.197096824645996\n",
      "Epoch: 2, Batch number: 49212, Loss: 6.893447399139404\n",
      "Epoch: 2, Batch number: 49312, Loss: 7.002635478973389\n",
      "Epoch: 2, Batch number: 49412, Loss: 7.072333335876465\n",
      "Epoch: 2, Batch number: 49512, Loss: 7.140625476837158\n",
      "Epoch: 2, Batch number: 49612, Loss: 6.699725151062012\n",
      "Epoch: 2, Batch number: 49712, Loss: 6.931858062744141\n",
      "Epoch: 2, Batch number: 49812, Loss: 6.920506477355957\n",
      "Epoch: 2, Batch number: 49912, Loss: 7.160682201385498\n",
      "Epoch: 2, Batch number: 50012, Loss: 6.943497657775879\n",
      "Epoch: 2, Batch number: 50112, Loss: 6.857386112213135\n",
      "Epoch: 2, Batch number: 50212, Loss: 6.946573257446289\n",
      "Epoch: 2, Batch number: 50312, Loss: 6.743860721588135\n",
      "Epoch: 2, Batch number: 50412, Loss: 7.0182061195373535\n",
      "Epoch: 2, Batch number: 50512, Loss: 7.019558429718018\n",
      "Epoch: 2, Batch number: 50612, Loss: 6.859552383422852\n",
      "Epoch: 2, Batch number: 50712, Loss: 7.0785231590271\n",
      "Epoch: 2, Batch number: 50812, Loss: 6.7794694900512695\n",
      "Epoch: 2, Batch number: 50912, Loss: 6.719263553619385\n",
      "Epoch: 2, Batch number: 51012, Loss: 6.898212432861328\n",
      "Epoch: 2, Batch number: 51112, Loss: 6.924619197845459\n",
      "Epoch: 2, Batch number: 51212, Loss: 6.973156929016113\n",
      "Epoch: 2, Batch number: 51312, Loss: 7.223111152648926\n",
      "Epoch: 2, Batch number: 51412, Loss: 6.9285969734191895\n",
      "Epoch: 2, Batch number: 51512, Loss: 6.886765956878662\n",
      "Epoch: 2, Batch number: 51612, Loss: 6.924347877502441\n",
      "Epoch: 2, Batch number: 51712, Loss: 6.760010719299316\n",
      "Epoch: 2, Batch number: 51812, Loss: 6.944067001342773\n",
      "Epoch: 2, Batch number: 51912, Loss: 6.997828960418701\n",
      "Epoch: 2, Batch number: 52012, Loss: 7.073227882385254\n",
      "Epoch: 2, Batch number: 52112, Loss: 6.938256740570068\n",
      "Epoch: 2, Batch number: 52212, Loss: 7.138102054595947\n",
      "Epoch: 2, Batch number: 52312, Loss: 6.783711910247803\n",
      "Epoch: 2, Batch number: 52412, Loss: 6.801199913024902\n",
      "Epoch: 2, Batch number: 52512, Loss: 6.964465141296387\n",
      "Epoch: 2, Batch number: 52612, Loss: 6.934152603149414\n",
      "Epoch: 2, Batch number: 52712, Loss: 6.722219467163086\n",
      "Epoch: 2, Batch number: 52812, Loss: 7.446488380432129\n",
      "Epoch: 2, Batch number: 52912, Loss: 6.786958694458008\n",
      "Epoch: 2, Batch number: 53012, Loss: 7.201857566833496\n",
      "Epoch: 2, Batch number: 53112, Loss: 7.129609107971191\n",
      "Epoch: 2, Batch number: 53212, Loss: 7.135067939758301\n",
      "Epoch: 2, Batch number: 53312, Loss: 7.035217761993408\n",
      "Epoch: 2, Batch number: 53412, Loss: 7.058371543884277\n",
      "Epoch: 2, Batch number: 53512, Loss: 6.873241424560547\n",
      "Epoch: 2, Batch number: 53612, Loss: 6.956259250640869\n",
      "Epoch: 2, Batch number: 53712, Loss: 6.8844428062438965\n",
      "Epoch: 2, Batch number: 53812, Loss: 7.075326919555664\n",
      "Epoch: 2, Batch number: 53912, Loss: 6.956745147705078\n",
      "Epoch: 2, Batch number: 54012, Loss: 7.215356826782227\n",
      "Epoch: 2, Batch number: 54112, Loss: 7.044958114624023\n",
      "Epoch: 2, Batch number: 54212, Loss: 6.894200801849365\n",
      "Epoch: 2, Batch number: 54312, Loss: 7.308874130249023\n",
      "Epoch: 2, Batch number: 54412, Loss: 7.215418815612793\n",
      "Epoch: 2, Batch number: 54512, Loss: 6.924576759338379\n",
      "Epoch: 2, Batch number: 54612, Loss: 6.981683731079102\n",
      "Epoch: 2, Batch number: 54712, Loss: 7.136982440948486\n",
      "Epoch: 2, Batch number: 54812, Loss: 6.8845062255859375\n",
      "Epoch: 2, Batch number: 54912, Loss: 6.987025260925293\n",
      "Epoch: 2, Batch number: 55012, Loss: 6.834031105041504\n",
      "Epoch: 2, Batch number: 55112, Loss: 7.182868957519531\n",
      "Epoch: 2, Batch number: 55212, Loss: 6.933039665222168\n",
      "Epoch: 2, Batch number: 55312, Loss: 6.840768814086914\n",
      "Epoch: 2, Batch number: 55412, Loss: 6.953100204467773\n",
      "Epoch: 2, Batch number: 55512, Loss: 7.192372798919678\n",
      "Epoch: 2, Batch number: 55612, Loss: 6.827459335327148\n",
      "Epoch: 2, Batch number: 55712, Loss: 6.786652565002441\n",
      "Epoch: 2, Batch number: 55812, Loss: 6.82936954498291\n",
      "Epoch: 2, Batch number: 55912, Loss: 7.167448997497559\n",
      "Epoch: 2, Batch number: 56012, Loss: 7.068206310272217\n",
      "Epoch: 2, Batch number: 56112, Loss: 6.848449230194092\n",
      "Epoch: 2, Batch number: 56212, Loss: 6.800419330596924\n",
      "Epoch: 2, Batch number: 56312, Loss: 6.983778953552246\n",
      "Epoch: 2, Batch number: 56412, Loss: 6.821368217468262\n",
      "Epoch: 2, Batch number: 56512, Loss: 6.874817371368408\n",
      "Epoch: 2, Batch number: 56612, Loss: 7.035015106201172\n",
      "Epoch: 2, Batch number: 56712, Loss: 7.211503028869629\n",
      "Epoch: 2, Batch number: 56812, Loss: 6.9303460121154785\n",
      "Epoch: 2, Batch number: 56912, Loss: 6.886355876922607\n",
      "Epoch: 2, Batch number: 57012, Loss: 7.032286167144775\n",
      "Epoch: 2, Batch number: 57112, Loss: 6.919734954833984\n",
      "Epoch: 2, Batch number: 57212, Loss: 6.858654975891113\n",
      "Epoch: 2, Batch number: 57312, Loss: 6.8491010665893555\n",
      "Epoch: 2, Batch number: 57412, Loss: 7.144645690917969\n",
      "Epoch: 2, Batch number: 57512, Loss: 6.846014976501465\n",
      "Epoch: 2, Batch number: 57612, Loss: 6.871735095977783\n",
      "Epoch: 2, Batch number: 57712, Loss: 6.983546733856201\n",
      "Epoch: 2, Batch number: 57812, Loss: 7.05067253112793\n",
      "Epoch: 2, Batch number: 57912, Loss: 7.099913597106934\n",
      "Epoch: 2, Batch number: 58012, Loss: 6.776535511016846\n",
      "Epoch: 2, Batch number: 58112, Loss: 6.926987648010254\n",
      "Epoch: 2, Batch number: 58212, Loss: 6.8942108154296875\n",
      "Epoch: 2, Batch number: 58312, Loss: 6.808879852294922\n",
      "Epoch: 2, Batch number: 58412, Loss: 6.989104747772217\n",
      "Epoch: 2, Batch number: 58512, Loss: 6.9608259201049805\n",
      "Epoch: 2, Batch number: 58612, Loss: 7.207371234893799\n",
      "Epoch: 2, Batch number: 58712, Loss: 7.091226577758789\n",
      "Epoch: 2, Batch number: 58812, Loss: 6.990542411804199\n",
      "Epoch: 2, Batch number: 58912, Loss: 7.087167263031006\n",
      "Epoch: 2, Batch number: 59012, Loss: 7.0669403076171875\n",
      "Epoch: 2, Batch number: 59112, Loss: 6.9726667404174805\n",
      "Epoch: 2, Batch number: 59212, Loss: 6.878159046173096\n",
      "Epoch: 2, Batch number: 59312, Loss: 7.206341743469238\n",
      "Epoch: 2, Batch number: 59412, Loss: 6.912522315979004\n",
      "Epoch: 2, Batch number: 59512, Loss: 7.063653945922852\n",
      "Epoch: 2, Batch number: 59612, Loss: 7.2840189933776855\n",
      "Epoch: 2, Batch number: 59712, Loss: 6.981173992156982\n",
      "Epoch: 2, Batch number: 59812, Loss: 7.282924652099609\n",
      "Epoch: 2, Batch number: 59912, Loss: 7.072005271911621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 60012, Loss: 6.979409217834473\n",
      "Epoch: 2, Batch number: 60112, Loss: 6.792092800140381\n",
      "Epoch: 2, Batch number: 60212, Loss: 6.880855083465576\n",
      "Epoch: 2, Batch number: 60312, Loss: 6.884953498840332\n",
      "Epoch: 2, Batch number: 60412, Loss: 6.865136623382568\n",
      "Epoch: 2, Batch number: 60512, Loss: 7.071976184844971\n",
      "Epoch: 2, Batch number: 60612, Loss: 6.866970539093018\n",
      "Epoch: 2, Batch number: 60712, Loss: 6.9731268882751465\n",
      "Epoch: 2, Batch number: 60812, Loss: 6.827010154724121\n",
      "Epoch: 2, Batch number: 60912, Loss: 6.8937907218933105\n",
      "Epoch: 2, Batch number: 61012, Loss: 7.070027828216553\n",
      "Epoch: 2, Batch number: 61112, Loss: 7.082510471343994\n",
      "Epoch: 2, Batch number: 61212, Loss: 6.826841354370117\n",
      "Epoch: 2, Batch number: 61312, Loss: 7.003704071044922\n",
      "Epoch: 2, Batch number: 61412, Loss: 6.949540615081787\n",
      "Epoch: 2, Batch number: 61512, Loss: 6.695104122161865\n",
      "Epoch: 2, Batch number: 61612, Loss: 6.877146244049072\n",
      "Epoch: 2, Batch number: 61712, Loss: 6.685549259185791\n",
      "Epoch: 2, Batch number: 61812, Loss: 7.01834774017334\n",
      "Epoch: 2, Batch number: 61912, Loss: 7.343098163604736\n",
      "Epoch: 2, Batch number: 62012, Loss: 6.9798712730407715\n",
      "Epoch: 2, Batch number: 62112, Loss: 6.819307327270508\n",
      "Epoch: 2, Batch number: 62212, Loss: 6.8628411293029785\n",
      "Epoch: 2, Batch number: 62312, Loss: 7.12216329574585\n",
      "Epoch: 2, Batch number: 62412, Loss: 6.9671711921691895\n",
      "Epoch: 2, Batch number: 62512, Loss: 7.179361820220947\n",
      "Epoch: 2, Batch number: 62612, Loss: 7.014345169067383\n",
      "Epoch: 2, Batch number: 62712, Loss: 6.931649208068848\n",
      "Epoch: 2, Batch number: 62812, Loss: 7.0670342445373535\n",
      "Epoch: 2, Batch number: 62912, Loss: 6.727155685424805\n",
      "Epoch: 2, Batch number: 63012, Loss: 6.858953475952148\n",
      "Epoch: 2, Batch number: 63112, Loss: 6.900495529174805\n",
      "Epoch: 2, Batch number: 63212, Loss: 6.89106559753418\n",
      "Epoch: 2, Batch number: 63312, Loss: 7.07598352432251\n",
      "Epoch: 2, Batch number: 63412, Loss: 6.833564281463623\n",
      "Epoch: 2, Batch number: 63512, Loss: 6.86920166015625\n",
      "Epoch: 2, Batch number: 63612, Loss: 7.104253768920898\n",
      "Epoch: 2, Batch number: 63712, Loss: 7.154548168182373\n",
      "Epoch: 2, Batch number: 63812, Loss: 6.941689491271973\n",
      "Epoch: 2, Batch number: 63912, Loss: 7.179506301879883\n",
      "Epoch: 2, Batch number: 64012, Loss: 7.019508361816406\n",
      "Epoch: 2, Batch number: 64112, Loss: 6.696559906005859\n",
      "Epoch: 2, Batch number: 64212, Loss: 7.1669511795043945\n",
      "Epoch: 2, Batch number: 64312, Loss: 7.08054780960083\n",
      "Epoch: 2, Batch number: 64412, Loss: 7.087745189666748\n",
      "Epoch: 2, Batch number: 64512, Loss: 6.807704925537109\n",
      "Epoch: 2, Batch number: 64612, Loss: 7.072896957397461\n",
      "Epoch: 2, Batch number: 64712, Loss: 7.346303462982178\n",
      "Epoch: 2, Batch number: 64812, Loss: 6.997376918792725\n",
      "Epoch: 2, Batch number: 64912, Loss: 7.1159467697143555\n",
      "Epoch: 2, Batch number: 65012, Loss: 7.042077541351318\n",
      "Epoch: 2, Batch number: 65112, Loss: 6.876357078552246\n",
      "Epoch: 2, Batch number: 65212, Loss: 6.971567153930664\n",
      "Epoch: 2, Batch number: 65312, Loss: 6.8292741775512695\n",
      "Epoch: 2, Batch number: 65412, Loss: 6.860103607177734\n",
      "Epoch: 2, Batch number: 65512, Loss: 6.993018627166748\n",
      "Epoch: 2, Batch number: 65612, Loss: 6.896477699279785\n",
      "Epoch: 2, Batch number: 65712, Loss: 6.6592488288879395\n",
      "Epoch: 2, Batch number: 65812, Loss: 6.976066589355469\n",
      "Epoch: 2, Batch number: 65912, Loss: 6.907127380371094\n",
      "Epoch: 2, Batch number: 66012, Loss: 7.258694648742676\n",
      "Epoch: 2, Batch number: 66112, Loss: 7.063484191894531\n",
      "Epoch: 2, Batch number: 66212, Loss: 6.943785667419434\n",
      "Epoch: 2, Batch number: 66312, Loss: 6.893304824829102\n",
      "Epoch: 2, Batch number: 66412, Loss: 6.863108158111572\n",
      "Epoch: 2, Batch number: 66512, Loss: 6.788844108581543\n",
      "Epoch: 2, Batch number: 66612, Loss: 7.021407127380371\n",
      "Epoch: 2, Batch number: 66712, Loss: 7.043917655944824\n",
      "Epoch: 2, Batch number: 66812, Loss: 7.010101795196533\n",
      "Epoch: 2, Batch number: 66912, Loss: 6.818417072296143\n",
      "Epoch: 2, Batch number: 67012, Loss: 7.330070495605469\n",
      "Epoch: 2, Batch number: 67112, Loss: 7.004576683044434\n",
      "Epoch: 2, Batch number: 67212, Loss: 7.026762962341309\n",
      "Epoch: 2, Batch number: 67312, Loss: 6.8552350997924805\n",
      "Epoch: 2, Batch number: 67412, Loss: 6.9049458503723145\n",
      "Epoch: 2, Batch number: 67512, Loss: 6.64356803894043\n",
      "Epoch: 2, Batch number: 67612, Loss: 6.998366832733154\n",
      "Epoch: 2, Batch number: 67712, Loss: 7.038999557495117\n",
      "Epoch: 2, Batch number: 67812, Loss: 7.071184158325195\n",
      "Epoch: 2, Batch number: 67912, Loss: 7.228397369384766\n",
      "Epoch: 2, Batch number: 68012, Loss: 6.98647928237915\n",
      "Epoch: 2, Batch number: 68112, Loss: 6.7675580978393555\n",
      "Epoch: 2, Batch number: 68212, Loss: 7.004485607147217\n",
      "Epoch: 2, Batch number: 68312, Loss: 6.989303112030029\n",
      "Epoch: 2, Batch number: 68412, Loss: 6.929075717926025\n",
      "Epoch: 2, Batch number: 68512, Loss: 7.136166572570801\n",
      "Epoch: 2, Batch number: 68612, Loss: 6.972360134124756\n",
      "Epoch: 2, Batch number: 68712, Loss: 6.673356056213379\n",
      "Epoch: 2, Batch number: 68812, Loss: 6.833881378173828\n",
      "Epoch: 2, Batch number: 68912, Loss: 6.987066268920898\n",
      "Epoch: 2, Batch number: 69012, Loss: 6.918737888336182\n",
      "Epoch: 2, Batch number: 69112, Loss: 6.8437275886535645\n",
      "Epoch: 2, Batch number: 69212, Loss: 7.178813457489014\n",
      "Epoch: 2, Batch number: 69312, Loss: 7.229944229125977\n",
      "Epoch: 2, Batch number: 69412, Loss: 6.975289821624756\n",
      "Epoch: 2, Batch number: 69512, Loss: 7.005054473876953\n",
      "Epoch: 2, Batch number: 69612, Loss: 6.930562973022461\n",
      "Epoch: 2, Batch number: 69712, Loss: 6.9378581047058105\n",
      "Epoch: 2, Batch number: 69812, Loss: 6.687872409820557\n",
      "Epoch: 2, Batch number: 69912, Loss: 6.9349236488342285\n",
      "Epoch: 2, Batch number: 70012, Loss: 6.980564594268799\n",
      "Epoch: 2, Batch number: 70112, Loss: 7.100540637969971\n",
      "Epoch: 2, Batch number: 70212, Loss: 6.790982246398926\n",
      "Epoch: 2, Batch number: 70312, Loss: 6.934776782989502\n",
      "Epoch: 2, Batch number: 70412, Loss: 7.063680648803711\n",
      "Epoch: 2, Batch number: 70512, Loss: 6.972866535186768\n",
      "Epoch: 2, Batch number: 70612, Loss: 6.8160881996154785\n",
      "Epoch: 2, Batch number: 70712, Loss: 7.063594818115234\n",
      "Epoch: 2, Batch number: 70812, Loss: 6.903501510620117\n",
      "Epoch: 2, Batch number: 70912, Loss: 7.037370204925537\n",
      "Epoch: 2, Batch number: 71012, Loss: 6.814798831939697\n",
      "Epoch: 2, Batch number: 71112, Loss: 6.817535877227783\n",
      "Epoch: 2, Batch number: 71212, Loss: 7.044483184814453\n",
      "Epoch: 2, Batch number: 71312, Loss: 7.213207244873047\n",
      "Epoch: 2, Batch number: 71412, Loss: 7.080085277557373\n",
      "Epoch: 2, Batch number: 71512, Loss: 6.939955711364746\n",
      "Epoch: 2, Batch number: 71612, Loss: 6.950998783111572\n",
      "Epoch: 2, Batch number: 71712, Loss: 7.420235633850098\n",
      "Epoch: 2, Batch number: 71812, Loss: 7.045038223266602\n",
      "Epoch: 2, Batch number: 71912, Loss: 7.119102478027344\n",
      "Epoch: 2, Batch number: 72012, Loss: 7.001377105712891\n",
      "Epoch: 2, Batch number: 72112, Loss: 7.107377052307129\n",
      "Epoch: 2, Batch number: 72212, Loss: 7.009578704833984\n",
      "Epoch: 2, Batch number: 72312, Loss: 7.187310218811035\n",
      "Epoch: 2, Batch number: 72412, Loss: 7.164608478546143\n",
      "Epoch: 2, Batch number: 72512, Loss: 6.967708110809326\n",
      "Epoch: 2, Batch number: 72612, Loss: 6.932633399963379\n",
      "Epoch: 2, Batch number: 72712, Loss: 7.015378475189209\n",
      "Epoch: 2, Batch number: 72812, Loss: 6.890308856964111\n",
      "Epoch: 2, Batch number: 72912, Loss: 6.846057415008545\n",
      "Epoch: 2, Batch number: 73012, Loss: 6.757948875427246\n",
      "Epoch: 2, Batch number: 73112, Loss: 6.588468074798584\n",
      "Epoch: 2, Batch number: 73212, Loss: 6.732497692108154\n",
      "Epoch: 2, Batch number: 73312, Loss: 7.003796577453613\n",
      "Epoch: 2, Batch number: 73412, Loss: 7.165467262268066\n",
      "Epoch: 2, Batch number: 73512, Loss: 6.782705307006836\n",
      "Epoch: 2, Batch number: 73612, Loss: 6.8711090087890625\n",
      "Epoch: 2, Batch number: 73712, Loss: 6.418078899383545\n",
      "Epoch: 2, Batch number: 73812, Loss: 6.937707424163818\n",
      "Epoch: 2, Batch number: 73912, Loss: 6.794098854064941\n",
      "Epoch: 2, Batch number: 74012, Loss: 7.023127555847168\n",
      "Epoch: 2, Batch number: 74112, Loss: 7.025626182556152\n",
      "Epoch: 2, Batch number: 74212, Loss: 7.035216331481934\n",
      "Epoch: 2, Batch number: 74312, Loss: 6.969430446624756\n",
      "Epoch: 2, Batch number: 74412, Loss: 6.968747138977051\n",
      "Epoch: 2, Batch number: 74512, Loss: 6.677190780639648\n",
      "Epoch: 2, Batch number: 74612, Loss: 7.157691955566406\n",
      "Epoch: 2, Batch number: 74712, Loss: 7.2425127029418945\n",
      "Epoch: 2, Batch number: 74812, Loss: 6.92479133605957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 74912, Loss: 6.795827388763428\n",
      "Epoch: 2, Batch number: 75012, Loss: 6.858728885650635\n",
      "Epoch: 2, Batch number: 75112, Loss: 7.09639835357666\n",
      "Epoch: 2, Batch number: 75212, Loss: 6.896742343902588\n",
      "Epoch: 2, Batch number: 75312, Loss: 6.763107776641846\n",
      "Epoch: 2, Batch number: 75412, Loss: 6.976282596588135\n",
      "Epoch: 2, Batch number: 75512, Loss: 7.0267863273620605\n",
      "Epoch: 2, Batch number: 75612, Loss: 6.898406982421875\n",
      "Epoch: 2, Batch number: 75712, Loss: 7.099132061004639\n",
      "Epoch: 2, Batch number: 75812, Loss: 7.0407185554504395\n",
      "Epoch: 2, Batch number: 75912, Loss: 6.859378337860107\n",
      "Epoch: 2, Batch number: 76012, Loss: 6.962005138397217\n",
      "Epoch: 2, Batch number: 76112, Loss: 6.818249702453613\n",
      "Epoch: 2, Batch number: 76212, Loss: 7.121413230895996\n",
      "Epoch: 2, Batch number: 76312, Loss: 6.787574768066406\n",
      "Epoch: 2, Batch number: 76412, Loss: 7.092962265014648\n",
      "Epoch: 2, Batch number: 76512, Loss: 6.977837562561035\n",
      "Epoch: 2, Batch number: 76612, Loss: 7.011443138122559\n",
      "Epoch: 2, Batch number: 76712, Loss: 7.090025424957275\n",
      "Epoch: 2, Batch number: 76812, Loss: 6.778975486755371\n",
      "Epoch: 2, Batch number: 76912, Loss: 6.95551872253418\n",
      "Epoch: 2, Batch number: 77012, Loss: 6.993510723114014\n",
      "Epoch: 2, Batch number: 77112, Loss: 7.162271499633789\n",
      "Epoch: 2, Batch number: 77212, Loss: 6.99413537979126\n",
      "Epoch: 2, Batch number: 77312, Loss: 6.96089506149292\n",
      "Epoch: 2, Batch number: 77412, Loss: 6.831432342529297\n",
      "Epoch: 2, Batch number: 77512, Loss: 7.210897922515869\n",
      "Epoch: 2, Batch number: 77612, Loss: 6.898946762084961\n",
      "Epoch: 2, Batch number: 77712, Loss: 6.991225719451904\n",
      "Epoch: 2, Batch number: 77812, Loss: 6.947288990020752\n",
      "Epoch: 2, Batch number: 77912, Loss: 6.864181041717529\n",
      "Epoch: 2, Batch number: 78012, Loss: 6.774397373199463\n",
      "Epoch: 2, Batch number: 78112, Loss: 6.941389560699463\n",
      "Epoch: 2, Batch number: 78212, Loss: 7.046117305755615\n",
      "Epoch: 2, Batch number: 78312, Loss: 7.026327133178711\n",
      "Epoch: 2, Batch number: 78412, Loss: 6.802000045776367\n",
      "Epoch: 2, Batch number: 78512, Loss: 6.956797122955322\n",
      "Epoch: 2, Batch number: 78612, Loss: 6.6789069175720215\n",
      "Epoch: 2, Batch number: 78712, Loss: 6.92578649520874\n",
      "Epoch: 2, Batch number: 78812, Loss: 6.973857402801514\n",
      "Epoch: 2, Batch number: 78912, Loss: 7.070861339569092\n",
      "Epoch: 2, Batch number: 79012, Loss: 6.596491813659668\n",
      "Epoch: 2, Batch number: 79112, Loss: 7.079596996307373\n",
      "Epoch: 2, Batch number: 79212, Loss: 7.207094669342041\n",
      "Epoch: 2, Batch number: 79312, Loss: 7.0315423011779785\n",
      "Epoch: 2, Batch number: 79412, Loss: 7.086493015289307\n",
      "Epoch: 2, Batch number: 79512, Loss: 7.098898887634277\n",
      "Epoch: 2, Batch number: 79612, Loss: 6.790151596069336\n",
      "Epoch: 2, Batch number: 79712, Loss: 7.052401065826416\n",
      "Epoch: 2, Batch number: 79812, Loss: 7.129281520843506\n",
      "Epoch: 2, Batch number: 79912, Loss: 6.838362693786621\n",
      "Epoch: 2, Batch number: 80012, Loss: 7.079288005828857\n",
      "Epoch: 2, Batch number: 80112, Loss: 7.034306526184082\n",
      "Epoch: 2, Batch number: 80212, Loss: 7.17629861831665\n",
      "Epoch: 2, Batch number: 80312, Loss: 7.031387805938721\n",
      "Epoch: 2, Batch number: 80412, Loss: 7.040163040161133\n",
      "Epoch: 2, Batch number: 80512, Loss: 6.890809535980225\n",
      "Epoch: 2, Batch number: 80612, Loss: 7.114957332611084\n",
      "Epoch: 2, Batch number: 80712, Loss: 6.953009128570557\n",
      "Epoch: 2, Batch number: 80812, Loss: 7.015963077545166\n",
      "Epoch: 2, Batch number: 80912, Loss: 6.972543239593506\n",
      "Epoch: 2, Batch number: 81012, Loss: 7.073338508605957\n",
      "Epoch: 2, Batch number: 81112, Loss: 7.014814376831055\n",
      "Epoch: 2, Batch number: 81212, Loss: 6.9924516677856445\n",
      "Epoch: 2, Batch number: 81312, Loss: 7.063190460205078\n",
      "Epoch: 2, Batch number: 81412, Loss: 6.883541584014893\n",
      "Epoch: 2, Batch number: 81512, Loss: 7.038806438446045\n",
      "Epoch: 2, Batch number: 81612, Loss: 7.02701997756958\n",
      "Epoch: 2, Batch number: 81712, Loss: 6.869072914123535\n",
      "Epoch: 2, Batch number: 81812, Loss: 7.105489730834961\n",
      "Epoch: 2, Batch number: 81912, Loss: 6.995009422302246\n",
      "Epoch: 2, Batch number: 82012, Loss: 7.050602912902832\n",
      "Epoch: 2, Batch number: 82112, Loss: 6.922006130218506\n",
      "Epoch: 2, Batch number: 82212, Loss: 7.046186923980713\n",
      "Epoch: 2, Batch number: 82312, Loss: 6.924584865570068\n",
      "Epoch: 2, Batch number: 82412, Loss: 7.1213459968566895\n",
      "Epoch: 2, Batch number: 82512, Loss: 7.032301425933838\n",
      "Epoch: 2, Batch number: 82612, Loss: 7.018726825714111\n",
      "Epoch: 2, Batch number: 82712, Loss: 6.988035678863525\n",
      "Epoch: 2, Batch number: 82812, Loss: 6.8395185470581055\n",
      "Epoch: 2, Batch number: 82912, Loss: 7.114505767822266\n",
      "Epoch: 2, Batch number: 83012, Loss: 7.126928329467773\n",
      "Epoch: 2, Batch number: 83112, Loss: 7.010128974914551\n",
      "Epoch: 2, Batch number: 83212, Loss: 7.325023174285889\n",
      "Epoch: 2, Batch number: 83312, Loss: 7.15019416809082\n",
      "Epoch: 2, Batch number: 83412, Loss: 7.081125259399414\n",
      "Epoch: 2, Batch number: 83512, Loss: 6.905187129974365\n",
      "Epoch: 2, Batch number: 83612, Loss: 6.948389053344727\n",
      "Epoch: 2, Batch number: 83712, Loss: 6.807322978973389\n",
      "Epoch: 2, Batch number: 83812, Loss: 7.029252529144287\n",
      "Epoch: 2, Batch number: 83912, Loss: 6.8765788078308105\n",
      "Epoch: 2, Batch number: 84012, Loss: 6.905307769775391\n",
      "Epoch: 2, Batch number: 84112, Loss: 6.844661712646484\n",
      "Epoch: 2, Batch number: 84212, Loss: 6.9287238121032715\n",
      "Epoch: 2, Batch number: 84312, Loss: 6.801761150360107\n",
      "Epoch: 2, Batch number: 84412, Loss: 7.0716552734375\n",
      "Epoch: 2, Batch number: 84512, Loss: 6.982892990112305\n",
      "Epoch: 2, Batch number: 84612, Loss: 6.9453630447387695\n",
      "Epoch: 2, Batch number: 84712, Loss: 7.0230488777160645\n",
      "Epoch: 2, Batch number: 84812, Loss: 7.0643744468688965\n",
      "Epoch: 2, Batch number: 84912, Loss: 7.198459625244141\n",
      "Epoch: 2, Batch number: 85012, Loss: 6.8440775871276855\n",
      "Epoch: 2, Batch number: 85112, Loss: 6.734214782714844\n",
      "Epoch: 2, Batch number: 85212, Loss: 6.996941089630127\n",
      "Epoch: 2, Batch number: 85312, Loss: 6.792714595794678\n",
      "Epoch: 2, Batch number: 85412, Loss: 7.003926753997803\n",
      "Epoch: 2, Batch number: 85512, Loss: 6.776115417480469\n",
      "Epoch: 2, Batch number: 85612, Loss: 6.9722113609313965\n",
      "Epoch: 2, Batch number: 85712, Loss: 6.94907808303833\n",
      "Epoch: 2, Batch number: 85812, Loss: 6.891396999359131\n",
      "Epoch: 2, Batch number: 85912, Loss: 6.94905424118042\n",
      "Epoch: 2, Batch number: 86012, Loss: 7.078135967254639\n",
      "Epoch: 2, Batch number: 86112, Loss: 6.913083076477051\n",
      "Epoch: 2, Batch number: 86212, Loss: 6.688209056854248\n",
      "Epoch: 2, Batch number: 86312, Loss: 7.060689449310303\n",
      "Epoch: 2, Batch number: 86412, Loss: 7.218827724456787\n",
      "Epoch: 2, Batch number: 86512, Loss: 6.947276592254639\n",
      "Epoch: 2, Batch number: 86612, Loss: 6.9118332862854\n",
      "Epoch: 2, Batch number: 86712, Loss: 6.944703102111816\n",
      "Epoch: 2, Batch number: 86812, Loss: 7.036904335021973\n",
      "Epoch: 2, Batch number: 86912, Loss: 7.062167167663574\n",
      "Epoch: 2, Batch number: 87012, Loss: 6.979105472564697\n",
      "Epoch: 2, Batch number: 87112, Loss: 7.095722675323486\n",
      "Epoch: 2, Batch number: 87212, Loss: 6.959786415100098\n",
      "Epoch: 2, Batch number: 87312, Loss: 6.998514175415039\n",
      "Epoch: 2, Batch number: 87412, Loss: 6.7223896980285645\n",
      "Epoch: 2, Batch number: 87512, Loss: 6.9708709716796875\n",
      "Epoch: 2, Batch number: 87612, Loss: 6.762778282165527\n",
      "Epoch: 2, Batch number: 87712, Loss: 7.018330097198486\n",
      "Epoch: 2, Batch number: 87812, Loss: 6.886509418487549\n",
      "Epoch: 2, Batch number: 87912, Loss: 6.916383266448975\n",
      "Epoch: 2, Batch number: 88012, Loss: 6.879815101623535\n",
      "Epoch: 2, Batch number: 88112, Loss: 6.969748497009277\n",
      "Epoch: 2, Batch number: 88212, Loss: 6.9691290855407715\n",
      "Epoch: 2, Batch number: 88312, Loss: 7.05353307723999\n",
      "Epoch: 2, Batch number: 88412, Loss: 6.975601673126221\n",
      "Epoch: 2, Batch number: 88512, Loss: 6.998035907745361\n",
      "Epoch: 2, Batch number: 88612, Loss: 6.736677169799805\n",
      "Epoch: 2, Batch number: 88712, Loss: 7.148097515106201\n",
      "Epoch: 2, Batch number: 88812, Loss: 6.920170307159424\n",
      "Epoch: 2, Batch number: 88912, Loss: 6.86204719543457\n",
      "Epoch: 2, Batch number: 89012, Loss: 7.00045919418335\n",
      "Epoch: 2, Batch number: 89112, Loss: 6.830085754394531\n",
      "Epoch: 2, Batch number: 89212, Loss: 6.849088668823242\n",
      "Epoch: 2, Batch number: 89312, Loss: 7.078422546386719\n",
      "Epoch: 2, Batch number: 89412, Loss: 6.967371463775635\n",
      "Epoch: 2, Batch number: 89512, Loss: 6.979010105133057\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 2\n",
      "Running on device (cuda:1)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 0, Loss: 11.304838180541992\n",
      "Epoch: 1, Batch number: 100, Loss: 10.616301536560059\n",
      "Epoch: 1, Batch number: 200, Loss: 9.969785690307617\n",
      "Epoch: 1, Batch number: 300, Loss: 9.781196594238281\n",
      "Epoch: 1, Batch number: 400, Loss: 9.646194458007812\n",
      "Epoch: 1, Batch number: 500, Loss: 9.394026756286621\n",
      "Epoch: 1, Batch number: 600, Loss: 9.189784049987793\n",
      "Epoch: 1, Batch number: 700, Loss: 9.212916374206543\n",
      "Epoch: 1, Batch number: 800, Loss: 8.76015853881836\n",
      "Epoch: 1, Batch number: 900, Loss: 8.688776969909668\n",
      "Epoch: 1, Batch number: 1000, Loss: 8.630600929260254\n",
      "Epoch: 1, Batch number: 1100, Loss: 8.4612455368042\n",
      "Epoch: 1, Batch number: 1200, Loss: 8.840152740478516\n",
      "Epoch: 1, Batch number: 1300, Loss: 8.638498306274414\n",
      "Epoch: 1, Batch number: 1400, Loss: 8.522233009338379\n",
      "Epoch: 1, Batch number: 1500, Loss: 8.268437385559082\n",
      "Epoch: 1, Batch number: 1600, Loss: 8.330235481262207\n",
      "Epoch: 1, Batch number: 1700, Loss: 8.361907005310059\n",
      "Epoch: 1, Batch number: 1800, Loss: 8.082632064819336\n",
      "Epoch: 1, Batch number: 1900, Loss: 8.243159294128418\n",
      "Epoch: 1, Batch number: 2000, Loss: 8.062566757202148\n",
      "Epoch: 1, Batch number: 2100, Loss: 8.164544105529785\n",
      "Epoch: 1, Batch number: 2200, Loss: 7.987461566925049\n",
      "Epoch: 1, Batch number: 2300, Loss: 8.06527328491211\n",
      "Epoch: 1, Batch number: 2400, Loss: 7.885382175445557\n",
      "Epoch: 1, Batch number: 2500, Loss: 8.076513290405273\n",
      "Epoch: 1, Batch number: 2600, Loss: 7.824198246002197\n",
      "Epoch: 1, Batch number: 2700, Loss: 7.900874614715576\n",
      "Epoch: 1, Batch number: 2800, Loss: 7.815942287445068\n",
      "Epoch: 1, Batch number: 2900, Loss: 8.090266227722168\n",
      "Epoch: 1, Batch number: 3000, Loss: 7.772951602935791\n",
      "Epoch: 1, Batch number: 3100, Loss: 7.822046756744385\n",
      "Epoch: 1, Batch number: 3200, Loss: 7.894588947296143\n",
      "Epoch: 1, Batch number: 3300, Loss: 7.65933084487915\n",
      "Epoch: 1, Batch number: 3400, Loss: 7.674371242523193\n",
      "Epoch: 1, Batch number: 3500, Loss: 7.6548752784729\n",
      "Epoch: 1, Batch number: 3600, Loss: 7.658123970031738\n",
      "Epoch: 1, Batch number: 3700, Loss: 7.644302845001221\n",
      "Epoch: 1, Batch number: 3800, Loss: 8.049394607543945\n",
      "Epoch: 1, Batch number: 3900, Loss: 7.639077186584473\n",
      "Epoch: 1, Batch number: 4000, Loss: 7.54888391494751\n",
      "Epoch: 1, Batch number: 4100, Loss: 7.675868034362793\n",
      "Epoch: 1, Batch number: 4200, Loss: 7.744195938110352\n",
      "Epoch: 1, Batch number: 4300, Loss: 7.838695049285889\n",
      "Epoch: 1, Batch number: 4400, Loss: 7.821629047393799\n",
      "Epoch: 1, Batch number: 4500, Loss: 7.712520599365234\n",
      "Epoch: 1, Batch number: 4600, Loss: 7.73619270324707\n",
      "Epoch: 1, Batch number: 4700, Loss: 7.45651912689209\n",
      "Epoch: 1, Batch number: 4800, Loss: 7.536476135253906\n",
      "Epoch: 1, Batch number: 4900, Loss: 7.540305137634277\n",
      "Epoch: 1, Batch number: 5000, Loss: 7.7957682609558105\n",
      "Epoch: 1, Batch number: 5100, Loss: 7.590357303619385\n",
      "Epoch: 1, Batch number: 5200, Loss: 7.334954261779785\n",
      "Epoch: 1, Batch number: 5300, Loss: 7.493712425231934\n",
      "Epoch: 1, Batch number: 5400, Loss: 7.721656799316406\n",
      "Epoch: 1, Batch number: 5500, Loss: 7.537755966186523\n",
      "Epoch: 1, Batch number: 5600, Loss: 7.72484827041626\n",
      "Epoch: 1, Batch number: 5700, Loss: 7.597460746765137\n",
      "Epoch: 1, Batch number: 5800, Loss: 7.441802978515625\n",
      "Epoch: 1, Batch number: 5900, Loss: 7.510041236877441\n",
      "Epoch: 1, Batch number: 6000, Loss: 7.516568660736084\n",
      "Epoch: 1, Batch number: 6100, Loss: 7.700508117675781\n",
      "Epoch: 1, Batch number: 6200, Loss: 7.422804355621338\n",
      "Epoch: 1, Batch number: 6300, Loss: 7.495899200439453\n",
      "Epoch: 1, Batch number: 6400, Loss: 7.430594444274902\n",
      "Epoch: 1, Batch number: 6500, Loss: 7.406966209411621\n",
      "Epoch: 1, Batch number: 6600, Loss: 7.45413875579834\n",
      "Epoch: 1, Batch number: 6700, Loss: 7.627445220947266\n",
      "Epoch: 1, Batch number: 6800, Loss: 7.559812545776367\n",
      "Epoch: 1, Batch number: 6900, Loss: 7.615529537200928\n",
      "Epoch: 1, Batch number: 7000, Loss: 7.512416362762451\n",
      "Epoch: 1, Batch number: 7100, Loss: 7.511221885681152\n",
      "Epoch: 1, Batch number: 7200, Loss: 7.369745254516602\n",
      "Epoch: 1, Batch number: 7300, Loss: 7.767394065856934\n",
      "Epoch: 1, Batch number: 7400, Loss: 7.309762001037598\n",
      "Epoch: 1, Batch number: 7500, Loss: 7.539827346801758\n",
      "Epoch: 1, Batch number: 7600, Loss: 7.593637466430664\n",
      "Epoch: 1, Batch number: 7700, Loss: 7.403454303741455\n",
      "Epoch: 1, Batch number: 7800, Loss: 7.36622428894043\n",
      "Epoch: 1, Batch number: 7900, Loss: 7.49418306350708\n",
      "Epoch: 1, Batch number: 8000, Loss: 7.743360996246338\n",
      "Epoch: 1, Batch number: 8100, Loss: 7.61008358001709\n",
      "Epoch: 1, Batch number: 8200, Loss: 7.587770462036133\n",
      "Epoch: 1, Batch number: 8300, Loss: 7.391729354858398\n",
      "Epoch: 1, Batch number: 8400, Loss: 7.467253684997559\n",
      "Epoch: 1, Batch number: 8500, Loss: 7.517784118652344\n",
      "Epoch: 1, Batch number: 8600, Loss: 7.572060585021973\n",
      "Epoch: 1, Batch number: 8700, Loss: 7.429760456085205\n",
      "Epoch: 1, Batch number: 8800, Loss: 7.626376628875732\n",
      "Epoch: 1, Batch number: 8900, Loss: 7.730282306671143\n",
      "Epoch: 1, Batch number: 9000, Loss: 7.358942985534668\n",
      "Epoch: 1, Batch number: 9100, Loss: 7.37952184677124\n",
      "Epoch: 1, Batch number: 9200, Loss: 7.557560920715332\n",
      "Epoch: 1, Batch number: 9300, Loss: 7.47441291809082\n",
      "Epoch: 1, Batch number: 9400, Loss: 7.411409378051758\n",
      "Epoch: 1, Batch number: 9500, Loss: 7.380937099456787\n",
      "Epoch: 1, Batch number: 9600, Loss: 7.487453937530518\n",
      "Epoch: 1, Batch number: 9700, Loss: 7.4774298667907715\n",
      "Epoch: 1, Batch number: 9800, Loss: 7.38637113571167\n",
      "Epoch: 1, Batch number: 9900, Loss: 7.456300258636475\n",
      "Epoch: 1, Batch number: 10000, Loss: 7.457585334777832\n",
      "Epoch: 1, Batch number: 10100, Loss: 7.498293399810791\n",
      "Epoch: 1, Batch number: 10200, Loss: 7.338970184326172\n",
      "Epoch: 1, Batch number: 10300, Loss: 7.511639595031738\n",
      "Epoch: 1, Batch number: 10400, Loss: 7.268652439117432\n",
      "Epoch: 1, Batch number: 10500, Loss: 7.555826187133789\n",
      "Epoch: 1, Batch number: 10600, Loss: 7.5326828956604\n",
      "Epoch: 1, Batch number: 10700, Loss: 7.249172210693359\n",
      "Epoch: 1, Batch number: 10800, Loss: 7.394710540771484\n",
      "Epoch: 1, Batch number: 10900, Loss: 7.459098815917969\n",
      "Epoch: 1, Batch number: 11000, Loss: 7.414186477661133\n",
      "Epoch: 1, Batch number: 11100, Loss: 7.736690044403076\n",
      "Epoch: 1, Batch number: 11200, Loss: 7.61141300201416\n",
      "Epoch: 1, Batch number: 11300, Loss: 7.190536022186279\n",
      "Epoch: 1, Batch number: 11400, Loss: 7.3797760009765625\n",
      "Epoch: 1, Batch number: 11500, Loss: 7.467006683349609\n",
      "Epoch: 1, Batch number: 11600, Loss: 7.337116241455078\n",
      "Epoch: 1, Batch number: 11700, Loss: 7.434757709503174\n",
      "Epoch: 1, Batch number: 11800, Loss: 7.12011194229126\n",
      "Epoch: 1, Batch number: 11900, Loss: 7.4952497482299805\n",
      "Epoch: 1, Batch number: 12000, Loss: 7.4592719078063965\n",
      "Epoch: 1, Batch number: 12100, Loss: 7.519571304321289\n",
      "Epoch: 1, Batch number: 12200, Loss: 7.23272180557251\n",
      "Epoch: 1, Batch number: 12300, Loss: 7.45326566696167\n",
      "Epoch: 1, Batch number: 12400, Loss: 7.433872222900391\n",
      "Epoch: 1, Batch number: 12500, Loss: 7.315193176269531\n",
      "Epoch: 1, Batch number: 12600, Loss: 7.642734527587891\n",
      "Epoch: 1, Batch number: 12700, Loss: 7.510460376739502\n",
      "Epoch: 1, Batch number: 12800, Loss: 7.395587921142578\n",
      "Epoch: 1, Batch number: 12900, Loss: 7.332082748413086\n",
      "Epoch: 1, Batch number: 13000, Loss: 7.391362190246582\n",
      "Epoch: 1, Batch number: 13100, Loss: 7.583961009979248\n",
      "Epoch: 1, Batch number: 13200, Loss: 7.686310768127441\n",
      "Epoch: 1, Batch number: 13300, Loss: 7.380800724029541\n",
      "Epoch: 1, Batch number: 13400, Loss: 7.580043792724609\n",
      "Epoch: 1, Batch number: 13500, Loss: 7.437276840209961\n",
      "Epoch: 1, Batch number: 13600, Loss: 7.409260272979736\n",
      "Epoch: 1, Batch number: 13700, Loss: 7.359190940856934\n",
      "Epoch: 1, Batch number: 13800, Loss: 7.2617340087890625\n",
      "Epoch: 1, Batch number: 13900, Loss: 7.190364837646484\n",
      "Epoch: 1, Batch number: 14000, Loss: 7.366945266723633\n",
      "Epoch: 1, Batch number: 14100, Loss: 7.663894176483154\n",
      "Epoch: 1, Batch number: 14200, Loss: 7.104912757873535\n",
      "Epoch: 1, Batch number: 14300, Loss: 7.162031650543213\n",
      "Epoch: 1, Batch number: 14400, Loss: 7.335237979888916\n",
      "Epoch: 1, Batch number: 14500, Loss: 7.377103805541992\n",
      "Epoch: 1, Batch number: 14600, Loss: 7.522451400756836\n",
      "Epoch: 1, Batch number: 14700, Loss: 7.216616153717041\n",
      "Epoch: 1, Batch number: 14800, Loss: 7.467712879180908\n",
      "Epoch: 1, Batch number: 14900, Loss: 7.418603420257568\n",
      "Epoch: 1, Batch number: 15000, Loss: 7.356875419616699\n",
      "Epoch: 1, Batch number: 15100, Loss: 7.4025559425354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 15200, Loss: 7.34837007522583\n",
      "Epoch: 1, Batch number: 15300, Loss: 7.115929126739502\n",
      "Epoch: 1, Batch number: 15400, Loss: 6.937678337097168\n",
      "Epoch: 1, Batch number: 15500, Loss: 7.400734901428223\n",
      "Epoch: 1, Batch number: 15600, Loss: 7.192984580993652\n",
      "Epoch: 1, Batch number: 15700, Loss: 7.390688419342041\n",
      "Epoch: 1, Batch number: 15800, Loss: 7.3856401443481445\n",
      "Epoch: 1, Batch number: 15900, Loss: 7.437159538269043\n",
      "Epoch: 1, Batch number: 16000, Loss: 7.30192756652832\n",
      "Epoch: 1, Batch number: 16100, Loss: 7.487643241882324\n",
      "Epoch: 1, Batch number: 16200, Loss: 7.4295477867126465\n",
      "Epoch: 1, Batch number: 16300, Loss: 7.290538787841797\n",
      "Epoch: 1, Batch number: 16400, Loss: 7.259387016296387\n",
      "Epoch: 1, Batch number: 16500, Loss: 7.307121753692627\n",
      "Epoch: 1, Batch number: 16600, Loss: 7.351812839508057\n",
      "Epoch: 1, Batch number: 16700, Loss: 7.108123302459717\n",
      "Epoch: 1, Batch number: 16800, Loss: 7.383680820465088\n",
      "Epoch: 1, Batch number: 16900, Loss: 7.627801418304443\n",
      "Epoch: 1, Batch number: 17000, Loss: 7.115103721618652\n",
      "Epoch: 1, Batch number: 17100, Loss: 7.409523963928223\n",
      "Epoch: 1, Batch number: 17200, Loss: 7.268779754638672\n",
      "Epoch: 1, Batch number: 17300, Loss: 7.239370346069336\n",
      "Epoch: 1, Batch number: 17400, Loss: 7.152146816253662\n",
      "Epoch: 1, Batch number: 17500, Loss: 7.298618793487549\n",
      "Epoch: 1, Batch number: 17600, Loss: 7.456414222717285\n",
      "Epoch: 1, Batch number: 17700, Loss: 7.562006950378418\n",
      "Epoch: 1, Batch number: 17800, Loss: 7.258718967437744\n",
      "Epoch: 1, Batch number: 17900, Loss: 7.252688407897949\n",
      "Epoch: 1, Batch number: 18000, Loss: 7.395449638366699\n",
      "Epoch: 1, Batch number: 18100, Loss: 7.296504020690918\n",
      "Epoch: 1, Batch number: 18200, Loss: 7.080489635467529\n",
      "Epoch: 1, Batch number: 18300, Loss: 7.53643798828125\n",
      "Epoch: 1, Batch number: 18400, Loss: 7.676827907562256\n",
      "Epoch: 1, Batch number: 18500, Loss: 7.132091522216797\n",
      "Epoch: 1, Batch number: 18600, Loss: 7.4065070152282715\n",
      "Epoch: 1, Batch number: 18700, Loss: 7.13617467880249\n",
      "Epoch: 1, Batch number: 18800, Loss: 7.231781959533691\n",
      "Epoch: 1, Batch number: 18900, Loss: 7.122771263122559\n",
      "Epoch: 1, Batch number: 19000, Loss: 7.479972839355469\n",
      "Epoch: 1, Batch number: 19100, Loss: 7.490574359893799\n",
      "Epoch: 1, Batch number: 19200, Loss: 7.126810550689697\n",
      "Epoch: 1, Batch number: 19300, Loss: 7.170473098754883\n",
      "Epoch: 1, Batch number: 19400, Loss: 7.34072732925415\n",
      "Epoch: 1, Batch number: 19500, Loss: 7.301799297332764\n",
      "Epoch: 1, Batch number: 19600, Loss: 7.326422691345215\n",
      "Epoch: 1, Batch number: 19700, Loss: 7.335721969604492\n",
      "Epoch: 1, Batch number: 19800, Loss: 7.123420238494873\n",
      "Epoch: 1, Batch number: 19900, Loss: 7.42500114440918\n",
      "Epoch: 1, Batch number: 20000, Loss: 7.30843448638916\n",
      "Epoch: 1, Batch number: 20100, Loss: 7.224116325378418\n",
      "Epoch: 1, Batch number: 20200, Loss: 7.059248924255371\n",
      "Epoch: 1, Batch number: 20300, Loss: 7.473748683929443\n",
      "Epoch: 1, Batch number: 20400, Loss: 7.26459264755249\n",
      "Epoch: 1, Batch number: 20500, Loss: 7.262370586395264\n",
      "Epoch: 1, Batch number: 20600, Loss: 7.417008399963379\n",
      "Epoch: 1, Batch number: 20700, Loss: 7.251466751098633\n",
      "Epoch: 1, Batch number: 20800, Loss: 7.408481597900391\n",
      "Epoch: 1, Batch number: 20900, Loss: 7.4044270515441895\n",
      "Epoch: 1, Batch number: 21000, Loss: 7.60080623626709\n",
      "Epoch: 1, Batch number: 21100, Loss: 7.222301006317139\n",
      "Epoch: 1, Batch number: 21200, Loss: 7.145256042480469\n",
      "Epoch: 1, Batch number: 21300, Loss: 7.212740421295166\n",
      "Epoch: 1, Batch number: 21400, Loss: 7.342118740081787\n",
      "Epoch: 1, Batch number: 21500, Loss: 7.235016345977783\n",
      "Epoch: 1, Batch number: 21600, Loss: 7.302641868591309\n",
      "Epoch: 1, Batch number: 21700, Loss: 7.052202224731445\n",
      "Epoch: 1, Batch number: 21800, Loss: 7.081902980804443\n",
      "Epoch: 1, Batch number: 21900, Loss: 7.574592113494873\n",
      "Epoch: 1, Batch number: 22000, Loss: 7.0133466720581055\n",
      "Epoch: 1, Batch number: 22100, Loss: 7.33195161819458\n",
      "Epoch: 1, Batch number: 22200, Loss: 7.230834484100342\n",
      "Epoch: 1, Batch number: 22300, Loss: 7.268599033355713\n",
      "Epoch: 1, Batch number: 22400, Loss: 7.120269298553467\n",
      "Epoch: 1, Batch number: 22500, Loss: 7.09096097946167\n",
      "Epoch: 1, Batch number: 22600, Loss: 7.264428615570068\n",
      "Epoch: 1, Batch number: 22700, Loss: 7.139867305755615\n",
      "Epoch: 1, Batch number: 22800, Loss: 7.413527965545654\n",
      "Epoch: 1, Batch number: 22900, Loss: 7.596573352813721\n",
      "Epoch: 1, Batch number: 23000, Loss: 7.000903606414795\n",
      "Epoch: 1, Batch number: 23100, Loss: 7.169137954711914\n",
      "Epoch: 1, Batch number: 23200, Loss: 7.153855800628662\n",
      "Epoch: 1, Batch number: 23300, Loss: 7.291864395141602\n",
      "Epoch: 1, Batch number: 23400, Loss: 7.399703025817871\n",
      "Epoch: 1, Batch number: 23500, Loss: 7.118936538696289\n",
      "Epoch: 1, Batch number: 23600, Loss: 7.176294326782227\n",
      "Epoch: 1, Batch number: 23700, Loss: 7.013532638549805\n",
      "Epoch: 1, Batch number: 23800, Loss: 7.441718578338623\n",
      "Epoch: 1, Batch number: 23900, Loss: 7.130692481994629\n",
      "Epoch: 1, Batch number: 24000, Loss: 7.149510860443115\n",
      "Epoch: 1, Batch number: 24100, Loss: 7.079614162445068\n",
      "Epoch: 1, Batch number: 24200, Loss: 7.606575965881348\n",
      "Epoch: 1, Batch number: 24300, Loss: 7.161519527435303\n",
      "Epoch: 1, Batch number: 24400, Loss: 7.196713447570801\n",
      "Epoch: 1, Batch number: 24500, Loss: 7.13236665725708\n",
      "Epoch: 1, Batch number: 24600, Loss: 7.25384521484375\n",
      "Epoch: 1, Batch number: 24700, Loss: 7.32199239730835\n",
      "Epoch: 1, Batch number: 24800, Loss: 7.548813343048096\n",
      "Epoch: 1, Batch number: 24900, Loss: 7.499483108520508\n",
      "Epoch: 1, Batch number: 25000, Loss: 7.1504998207092285\n",
      "Epoch: 1, Batch number: 25100, Loss: 7.123431205749512\n",
      "Epoch: 1, Batch number: 25200, Loss: 7.1957316398620605\n",
      "Epoch: 1, Batch number: 25300, Loss: 7.25625467300415\n",
      "Epoch: 1, Batch number: 25400, Loss: 7.279075622558594\n",
      "Epoch: 1, Batch number: 25500, Loss: 7.221141815185547\n",
      "Epoch: 1, Batch number: 25600, Loss: 7.325686931610107\n",
      "Epoch: 1, Batch number: 25700, Loss: 7.562646389007568\n",
      "Epoch: 1, Batch number: 25800, Loss: 7.331416130065918\n",
      "Epoch: 1, Batch number: 25900, Loss: 7.4814910888671875\n",
      "Epoch: 1, Batch number: 26000, Loss: 7.284430980682373\n",
      "Epoch: 1, Batch number: 26100, Loss: 7.279877662658691\n",
      "Epoch: 1, Batch number: 26200, Loss: 7.466701507568359\n",
      "Epoch: 1, Batch number: 26300, Loss: 7.253277778625488\n",
      "Epoch: 1, Batch number: 26400, Loss: 7.529141426086426\n",
      "Epoch: 1, Batch number: 26500, Loss: 7.158421993255615\n",
      "Epoch: 1, Batch number: 26600, Loss: 7.274774074554443\n",
      "Epoch: 1, Batch number: 26700, Loss: 7.209985733032227\n",
      "Epoch: 1, Batch number: 26800, Loss: 7.3577189445495605\n",
      "Epoch: 1, Batch number: 26900, Loss: 7.302714824676514\n",
      "Epoch: 1, Batch number: 27000, Loss: 7.378427982330322\n",
      "Epoch: 1, Batch number: 27100, Loss: 7.228120803833008\n",
      "Epoch: 1, Batch number: 27200, Loss: 7.227324485778809\n",
      "Epoch: 1, Batch number: 27300, Loss: 7.477470874786377\n",
      "Epoch: 1, Batch number: 27400, Loss: 7.393626689910889\n",
      "Epoch: 1, Batch number: 27500, Loss: 7.575565814971924\n",
      "Epoch: 1, Batch number: 27600, Loss: 7.451999187469482\n",
      "Epoch: 1, Batch number: 27700, Loss: 7.103814601898193\n",
      "Epoch: 1, Batch number: 27800, Loss: 7.4899725914001465\n",
      "Epoch: 1, Batch number: 27900, Loss: 7.58933162689209\n",
      "Epoch: 1, Batch number: 28000, Loss: 7.058582305908203\n",
      "Epoch: 1, Batch number: 28100, Loss: 7.258044242858887\n",
      "Epoch: 1, Batch number: 28200, Loss: 6.985803127288818\n",
      "Epoch: 1, Batch number: 28300, Loss: 7.3563456535339355\n",
      "Epoch: 1, Batch number: 28400, Loss: 7.312468528747559\n",
      "Epoch: 1, Batch number: 28500, Loss: 7.111955165863037\n",
      "Epoch: 1, Batch number: 28600, Loss: 7.42315673828125\n",
      "Epoch: 1, Batch number: 28700, Loss: 7.665743350982666\n",
      "Epoch: 1, Batch number: 28800, Loss: 7.155683994293213\n",
      "Epoch: 1, Batch number: 28900, Loss: 7.146997451782227\n",
      "Epoch: 1, Batch number: 29000, Loss: 7.384490966796875\n",
      "Epoch: 1, Batch number: 29100, Loss: 7.149567127227783\n",
      "Epoch: 1, Batch number: 29200, Loss: 7.26833963394165\n",
      "Epoch: 1, Batch number: 29300, Loss: 7.348687648773193\n",
      "Epoch: 1, Batch number: 29400, Loss: 7.309439182281494\n",
      "Epoch: 1, Batch number: 29500, Loss: 7.3866753578186035\n",
      "Epoch: 1, Batch number: 29600, Loss: 7.239877700805664\n",
      "Epoch: 1, Batch number: 29700, Loss: 7.302680969238281\n",
      "Epoch: 1, Batch number: 29800, Loss: 7.309124946594238\n",
      "Epoch: 1, Batch number: 29900, Loss: 7.220131874084473\n",
      "Epoch: 1, Batch number: 30000, Loss: 6.969812393188477\n",
      "Epoch: 1, Batch number: 30100, Loss: 7.188721656799316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch number: 30200, Loss: 7.290013790130615\n",
      "Epoch: 1, Batch number: 30300, Loss: 7.443323135375977\n",
      "Epoch: 1, Batch number: 30400, Loss: 7.109460830688477\n",
      "Epoch: 1, Batch number: 30500, Loss: 7.4952874183654785\n",
      "Epoch: 1, Batch number: 30600, Loss: 7.282031536102295\n",
      "Epoch: 1, Batch number: 30700, Loss: 7.054216384887695\n",
      "Epoch: 1, Batch number: 30800, Loss: 7.262642860412598\n",
      "Epoch: 1, Batch number: 30900, Loss: 7.1562700271606445\n",
      "Epoch: 1, Batch number: 31000, Loss: 6.952419281005859\n",
      "Epoch: 1, Batch number: 31100, Loss: 7.243354320526123\n",
      "Epoch: 1, Batch number: 31200, Loss: 6.947042942047119\n",
      "Epoch: 1, Batch number: 31300, Loss: 7.420711517333984\n",
      "Epoch: 1, Batch number: 31400, Loss: 7.384010314941406\n",
      "Epoch: 1, Batch number: 31500, Loss: 7.263108730316162\n",
      "Epoch: 1, Batch number: 31600, Loss: 7.573397159576416\n",
      "Epoch: 1, Batch number: 31700, Loss: 7.401759624481201\n",
      "Epoch: 1, Batch number: 31800, Loss: 7.686809539794922\n",
      "Epoch: 1, Batch number: 31900, Loss: 7.007547378540039\n",
      "Epoch: 1, Batch number: 32000, Loss: 7.271000385284424\n",
      "Epoch: 1, Batch number: 32100, Loss: 7.246733665466309\n",
      "Epoch: 1, Batch number: 32200, Loss: 7.238443851470947\n",
      "Epoch: 1, Batch number: 32300, Loss: 7.4870171546936035\n",
      "Epoch: 1, Batch number: 32400, Loss: 6.985034942626953\n",
      "Epoch: 1, Batch number: 32500, Loss: 7.18881893157959\n",
      "Epoch: 1, Batch number: 32600, Loss: 7.27244234085083\n",
      "Epoch: 1, Batch number: 32700, Loss: 6.993076801300049\n",
      "Epoch: 1, Batch number: 32800, Loss: 7.064874649047852\n",
      "Epoch: 1, Batch number: 32900, Loss: 7.001479148864746\n",
      "Epoch: 1, Batch number: 33000, Loss: 7.276855945587158\n",
      "Epoch: 1, Batch number: 33100, Loss: 7.117076873779297\n",
      "Epoch: 1, Batch number: 33200, Loss: 7.236272811889648\n",
      "Epoch: 1, Batch number: 33300, Loss: 7.257774829864502\n",
      "Epoch: 1, Batch number: 33400, Loss: 7.033239841461182\n",
      "Epoch: 1, Batch number: 33500, Loss: 7.096750736236572\n",
      "Epoch: 1, Batch number: 33600, Loss: 6.798524379730225\n",
      "Epoch: 1, Batch number: 33700, Loss: 7.258302688598633\n",
      "Epoch: 1, Batch number: 33800, Loss: 7.254340171813965\n",
      "Epoch: 1, Batch number: 33900, Loss: 7.155710220336914\n",
      "Epoch: 1, Batch number: 34000, Loss: 7.238705158233643\n",
      "Epoch: 1, Batch number: 34100, Loss: 7.402920722961426\n",
      "Epoch: 1, Batch number: 34200, Loss: 7.141441822052002\n",
      "Epoch: 1, Batch number: 34300, Loss: 7.241030216217041\n",
      "Epoch: 1, Batch number: 34400, Loss: 7.437496662139893\n",
      "Epoch: 1, Batch number: 34500, Loss: 7.000448226928711\n",
      "Epoch: 1, Batch number: 34600, Loss: 7.2028608322143555\n",
      "Epoch: 1, Batch number: 34700, Loss: 7.077978134155273\n",
      "Epoch: 1, Batch number: 34800, Loss: 7.258017539978027\n",
      "Epoch: 1, Batch number: 34900, Loss: 7.11128568649292\n",
      "Epoch: 1, Batch number: 35000, Loss: 7.223546981811523\n",
      "Epoch: 1, Batch number: 35100, Loss: 7.408764839172363\n",
      "Epoch: 1, Batch number: 35200, Loss: 7.211839199066162\n",
      "Epoch: 1, Batch number: 35300, Loss: 7.262613296508789\n",
      "Epoch: 1, Batch number: 35400, Loss: 7.1656813621521\n",
      "Epoch: 1, Batch number: 35500, Loss: 7.157310962677002\n",
      "Epoch: 1, Batch number: 35600, Loss: 7.137721538543701\n",
      "Epoch: 1, Batch number: 35700, Loss: 7.230770111083984\n",
      "Epoch: 1, Batch number: 35800, Loss: 7.148435592651367\n",
      "Epoch: 1, Batch number: 35900, Loss: 7.2144999504089355\n",
      "Epoch: 1, Batch number: 36000, Loss: 7.4586076736450195\n",
      "Epoch: 1, Batch number: 36100, Loss: 7.307251930236816\n",
      "Epoch: 1, Batch number: 36200, Loss: 7.316075325012207\n",
      "Epoch: 1, Batch number: 36300, Loss: 7.351802349090576\n",
      "Epoch: 1, Batch number: 36400, Loss: 7.212520599365234\n",
      "Epoch: 1, Batch number: 36500, Loss: 7.104452133178711\n",
      "Epoch: 1, Batch number: 36600, Loss: 7.153370380401611\n",
      "Epoch: 1, Batch number: 36700, Loss: 7.173290252685547\n",
      "Epoch: 1, Batch number: 36800, Loss: 7.578686714172363\n",
      "Epoch: 1, Batch number: 36900, Loss: 7.185672283172607\n",
      "Epoch: 1, Batch number: 37000, Loss: 7.100052833557129\n",
      "Epoch: 1, Batch number: 37100, Loss: 7.252654075622559\n",
      "Epoch: 1, Batch number: 37200, Loss: 7.097350120544434\n",
      "Epoch: 1, Batch number: 37300, Loss: 7.28399658203125\n",
      "Epoch: 1, Batch number: 37400, Loss: 7.376336097717285\n",
      "Epoch: 1, Batch number: 37500, Loss: 7.272848606109619\n",
      "Epoch: 1, Batch number: 37600, Loss: 7.149829387664795\n",
      "Epoch: 1, Batch number: 37700, Loss: 7.230213165283203\n",
      "Epoch: 1, Batch number: 37800, Loss: 6.958391189575195\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-181dcca754b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainers3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_loss_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/disco.lautaro/home/lestien/Documents/BecaNLP/Programs/18-Resumen-from-stratch/Utils/training.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, algorithm, epochs, sample_loss_every, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "algorithm = 'Adam'\n",
    "epochs = 2\n",
    "sample_loss_every = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "for trainer in trainers3:\n",
    "    trainer.Train(algorithm, epochs, sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for trainer in trainers3:\n",
    "    trainer.plot_loss_history(ax=ax,label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = Corpus.from_text_files(['./wiki-corpus/{}_cleaned.txt'.format(i) for i in range(1,4)] \\\n",
    "                                      + ['./promptsl40_train_cleaned.txt'], r'[ \\s]+', 3)\n",
    "# print(train_corpus.vocabulary)\n",
    "# print(train_corpus)\n",
    "# train_corpus.vocabulary\n",
    "\n",
    "model = 'SkipGram'\n",
    "window_size_list = [2,3,4,5]\n",
    "embedding_dim_list = [50,100,200,300]\n",
    "batch_size = 512\n",
    "device = 'cuda:1'\n",
    "\n",
    "trainers4 = []\n",
    "for window_size in window_size_list:\n",
    "    for embedding_dim in embedding_dim_list:\n",
    "        trainer =  Word2VecTrainer(model, train_corpus, window_size, embedding_dim, batch_size, device)\n",
    "        trainers4.append(trainer)\n",
    "\n",
    "algorithm = 'Adam'\n",
    "epochs = 2\n",
    "sample_loss_every = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "for trainer in trainers4:\n",
    "    trainer.Train(algorithm, epochs, sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for trainer in trainers4:\n",
    "    trainer.plot_loss_history(ax=ax,label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = read_binary_file('./promptsl40.train','iso-8859-1')\n",
    "# text = replace(text,r'[\\w\\d]+_[\\d]+[\\s]+','<s> ')\n",
    "# text = insert_left(text,r'\\n',' </s>')\n",
    "# text = remove(text,r'$\\n')\n",
    "# save_to_text_file(text,'promptsl40_train_cleaned.txt')\n",
    "# save_to_binary_file(text,'promptsl40_train_cleaned.bin','iso-8859-1')\n",
    "\n",
    "# text = read_binary_file('./promptsl40.test','iso-8859-1')\n",
    "# text = replace(text,r'[\\w\\d]+_[\\d]+[\\s]+','<s> ')\n",
    "# text = insert_left(text,r'\\n',' </s>')\n",
    "# text = remove(text,r'$\\n')\n",
    "# save_to_text_file(text,'promptsl40_test_cleaned.txt')\n",
    "# save_to_binary_file(text,'promptsl40_test_cleaned.bin','iso-8859-1')\n",
    "\n",
    "# for i in range(1,11):\n",
    "#     try:\n",
    "#         text = read_text_file('./wiki-corpus/{}'.format(i))\n",
    "#     except UnicodeDecodeError:\n",
    "#         text = read_binary_file('./wiki-corpus/{}'.format(i),decode='iso-8859-1')\n",
    "#     text = remove(text,r'[^a-zA-Z\\s]+')\n",
    "#     text = remove(text,r'!\\w+')\n",
    "#     text = remove(text,r'[aA]{2,10}')\n",
    "#     text = split(text.lower(), r'[\\s]+')\n",
    "#     new_text = []\n",
    "#     for k in range(len(text) // 10):\n",
    "#         new_text.append([text[k * 10 + j] for j in range(10)])\n",
    "#     new_text.append([tk for tk in text[(i*10):]])\n",
    "#     text = ''\n",
    "#     for line in new_text:\n",
    "#         text += ' '.join(line) + '\\n'\n",
    "#     save_to_text_file(text,'./wiki-corpus/{}_cleaned.txt'.format(i))\n",
    "#     save_to_binary_file(text,'./wiki-corpus/{}_cleaned.bin'.format(i),encode='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = './lm_new_trainer'\n",
    "# GetARPAFile(trainer, train_corpus, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El logaritmo de la perplejidad para el corpus de test es: -2.7604484998361127\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el modelo de lenguaje del mtodo frecuentista:\n",
    "with open('/home/lestien/final/lm/segunda-tanda/lm_freq', 'rb') as file:\n",
    "    lm_file = file.read().decode('iso-8859-1')\n",
    "    \n",
    "def get_log_prob(w1,w2):\n",
    "    match = re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({} {})'.format(w1,w2),lm_file)\n",
    "    if match is not None:\n",
    "        log_prob, _ = match.groups()\n",
    "        return float(log_prob)\n",
    "    match_w1 = re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({})\\t*(\\-?[\\d]*[\\.]?[\\d]*)'.format(w1),lm_file)\n",
    "    match_w2 = re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({})\\t*(\\-?[\\d]*[\\.]?[\\d]*)'.format(w2),lm_file)\n",
    "    str_w2 = match_w2.groups()[2]\n",
    "    float_w2 = 1. if str_w2 == '' else float(str_w2)\n",
    "    return float(match_w1.groups()[0]) + float_w2   \n",
    "        \n",
    "# Juntamos el corpus de test en una sola lista:\n",
    "with open('promptsl40.test','rb') as file:\n",
    "    test_lines = file.readlines()\n",
    "    test_lines = [' '.join(re.findall(r'\\w+',line.decode('iso-8859-1'))[1:]) for line in test_lines]\n",
    "    corpus_test = [['<s>'] + line.split(' ') + ['</s>'] for line in test_lines]\n",
    "    corpus_test = [word for line in corpus_test for word in line]\n",
    "    \n",
    "# Perplejidad para un modelo de bigrama:\n",
    "corpus_len = len(corpus_test)\n",
    "log_p = [get_log_prob(corpus_test[idx-1],corpus_test[idx]) for idx in range(1,corpus_len)]\n",
    "log_p.insert(0,float(re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({})\\t*(\\-?[\\d]*[\\.]?[\\d]*)'.format(corpus_test[0]),lm_file).groups()[0]))\n",
    "print('El logaritmo de la perplejidad para el corpus de test es: {}'.format(sum(log_p)/corpus_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El logaritmo de la perplejidad para el corpus de test es: -2.7604484998361127\n",
      "El logaritmo de la perplejidad para el corpus de test es: -2.5579754241548134\n",
      "El logaritmo de la perplejidad para el corpus de test es: -5.4267027838933055\n",
      "El logaritmo de la perplejidad para el corpus de test es: -6.64239031566159\n"
     ]
    }
   ],
   "source": [
    "def PerplexityFromARPA(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        lm_file = file.read().decode('iso-8859-1')\n",
    "\n",
    "    def get_log_prob(w1,w2):\n",
    "        match = re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({} {})'.format(w1,w2),lm_file)\n",
    "        if match is not None:\n",
    "            log_prob, _ = match.groups()\n",
    "            return float(log_prob)\n",
    "        match_w1 = re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({})\\t*(\\-?[\\d]*[\\.]?[\\d]*)'.format(w1),lm_file)\n",
    "        match_w2 = re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({})\\t*(\\-?[\\d]*[\\.]?[\\d]*)'.format(w2),lm_file)\n",
    "        str_w2 = match_w2.groups()[2]\n",
    "        float_w2 = 1. if str_w2 == '' else float(str_w2)\n",
    "        return float(match_w1.groups()[0]) + float_w2   \n",
    "\n",
    "    # Juntamos el corpus de test en una sola lista:\n",
    "    with open('promptsl40.test','rb') as file:\n",
    "        test_lines = file.readlines()\n",
    "        test_lines = [' '.join(re.findall(r'\\w+',line.decode('iso-8859-1'))[1:]) for line in test_lines]\n",
    "        corpus_test = [['<s>'] + line.split(' ') + ['</s>'] for line in test_lines]\n",
    "        corpus_test = [word for line in corpus_test for word in line]\n",
    "\n",
    "    # Perplejidad para un modelo de bigrama:\n",
    "    corpus_len = len(corpus_test)\n",
    "    log_p = [get_log_prob(corpus_test[idx-1],corpus_test[idx]) for idx in range(1,corpus_len)]\n",
    "    log_p.insert(0,float(re.search(r'([\\-]?[\\d]+[\\.]?[\\d]*)\\t({})\\t*(\\-?[\\d]*[\\.]?[\\d]*)'.format(corpus_test[0]),lm_file).groups()[0]))\n",
    "    print('El logaritmo de la perplejidad para el corpus de test es: {}'.format(sum(log_p)/corpus_len))\n",
    "    return sum(log_p)/corpus_len\n",
    "\n",
    "filename = '/home/lestien/final/lm/segunda-tanda/lm_freq'\n",
    "p1 = PerplexityFromARPA(filename)\n",
    "\n",
    "filename = '/home/lestien/final/lm/segunda-tanda/lm_freq2'\n",
    "p2 = PerplexityFromARPA(filename)\n",
    "\n",
    "filename = '/home/lestien/final/lm/segunda-tanda/lm_trainers1_ws_2_ed_300'\n",
    "p3 = PerplexityFromARPA(filename)\n",
    "\n",
    "filename = '/home/lestien/final/lm/segunda-tanda/lm_trainers2_ws_3_ed_300'\n",
    "p4 = PerplexityFromARPA(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.4396122966737543"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(np.exp(-7.92)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
