{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de lenguaje Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "SkipGram trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n"
     ]
    }
   ],
   "source": [
    "#corpus = [['w1', 'w2', 'w3', 'w4'], ['w1', 'w3', 'w3', 'w3'], ['w1'], ['w1', 'w2', 'w3', 'w4', 'w1', 'w2', 'w3', 'w4']]\n",
    "corpus = GetTrainCorpus('./promptsl40.train')\n",
    "cutoff_freq = 0\n",
    "window_size_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "batch_size = 512\n",
    "\n",
    "state_dict = None\n",
    "device = 'cuda:1'\n",
    "paralelize = False\n",
    "embedding_dim_list = [50, 100, 150, 200, 300, 400]\n",
    "\n",
    "sk_trainers = []\n",
    "for window_size in window_size_list:\n",
    "    embedding_dim_trainers = []\n",
    "    for embedding_dim in embedding_dim_list:\n",
    "        sk_trainer = SkipGramTrainer(corpus, cutoff_freq, window_size, batch_size)\n",
    "        sk_trainer.InitModel(state_dict=state_dict, device=device, paralelize=paralelize, embedding_dim=embedding_dim)\n",
    "        embedding_dim_trainers.append(sk_trainer)\n",
    "    sk_trainers.append(embedding_dim_trainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8030.67626953125\n",
      "Epoch: 2, Batch number: 24, Loss: 7778.5224609375\n",
      "Epoch: 3, Batch number: 48, Loss: 7660.98681640625\n",
      "Epoch: 4, Batch number: 72, Loss: 7413.61376953125\n",
      "Epoch: 6, Batch number: 20, Loss: 7072.8935546875\n",
      "Epoch: 7, Batch number: 44, Loss: 7066.8876953125\n",
      "Epoch: 8, Batch number: 68, Loss: 6857.48095703125\n",
      "Epoch: 10, Batch number: 16, Loss: 6450.0283203125\n",
      "Epoch: 11, Batch number: 40, Loss: 6592.77001953125\n",
      "Epoch: 12, Batch number: 64, Loss: 6526.9814453125\n",
      "Epoch: 14, Batch number: 12, Loss: 6293.771484375\n",
      "Epoch: 15, Batch number: 36, Loss: 6032.1875\n",
      "Epoch: 16, Batch number: 60, Loss: 6055.12646484375\n",
      "Epoch: 18, Batch number: 8, Loss: 5971.427734375\n",
      "Epoch: 19, Batch number: 32, Loss: 5938.4287109375\n",
      "Epoch: 20, Batch number: 56, Loss: 5773.2060546875\n",
      "Epoch: 22, Batch number: 4, Loss: 5810.70849609375\n",
      "Epoch: 23, Batch number: 28, Loss: 5572.33984375\n",
      "Epoch: 24, Batch number: 52, Loss: 5541.17822265625\n",
      "Epoch: 26, Batch number: 0, Loss: 5381.125\n",
      "Epoch: 27, Batch number: 24, Loss: 5354.6337890625\n",
      "Epoch: 28, Batch number: 48, Loss: 5342.388671875\n",
      "Epoch: 29, Batch number: 72, Loss: 5145.025390625\n",
      "Epoch: 31, Batch number: 20, Loss: 5106.45166015625\n",
      "Epoch: 32, Batch number: 44, Loss: 4910.5283203125\n",
      "Epoch: 33, Batch number: 68, Loss: 4941.44970703125\n",
      "Epoch: 35, Batch number: 16, Loss: 4954.43701171875\n",
      "Epoch: 36, Batch number: 40, Loss: 4888.822265625\n",
      "Epoch: 37, Batch number: 64, Loss: 4868.10595703125\n",
      "Epoch: 39, Batch number: 12, Loss: 4790.134765625\n",
      "Epoch: 40, Batch number: 36, Loss: 4671.8330078125\n",
      "Epoch: 41, Batch number: 60, Loss: 4691.77197265625\n",
      "Epoch: 43, Batch number: 8, Loss: 4681.60888671875\n",
      "Epoch: 44, Batch number: 32, Loss: 4756.85302734375\n",
      "Epoch: 45, Batch number: 56, Loss: 4816.7080078125\n",
      "Epoch: 47, Batch number: 4, Loss: 4490.31103515625\n",
      "Epoch: 48, Batch number: 28, Loss: 4553.6455078125\n",
      "Epoch: 49, Batch number: 52, Loss: 4503.18017578125\n",
      "Epoch: 51, Batch number: 0, Loss: 4292.8984375\n",
      "Epoch: 52, Batch number: 24, Loss: 4648.8232421875\n",
      "Epoch: 53, Batch number: 48, Loss: 4507.79638671875\n",
      "Epoch: 54, Batch number: 72, Loss: 4520.5693359375\n",
      "Epoch: 56, Batch number: 20, Loss: 4455.27783203125\n",
      "Epoch: 57, Batch number: 44, Loss: 4345.00732421875\n",
      "Epoch: 58, Batch number: 68, Loss: 4274.89599609375\n",
      "Epoch: 60, Batch number: 16, Loss: 4209.162109375\n",
      "Epoch: 61, Batch number: 40, Loss: 4319.732421875\n",
      "Epoch: 62, Batch number: 64, Loss: 4383.69921875\n",
      "Epoch: 64, Batch number: 12, Loss: 4256.9677734375\n",
      "Epoch: 65, Batch number: 36, Loss: 4258.31884765625\n",
      "Epoch: 66, Batch number: 60, Loss: 4181.224609375\n",
      "Epoch: 68, Batch number: 8, Loss: 4148.50439453125\n",
      "Epoch: 69, Batch number: 32, Loss: 4187.64892578125\n",
      "Epoch: 70, Batch number: 56, Loss: 4223.9716796875\n",
      "Epoch: 72, Batch number: 4, Loss: 4081.32275390625\n",
      "Epoch: 73, Batch number: 28, Loss: 4098.20556640625\n",
      "Epoch: 74, Batch number: 52, Loss: 4155.302734375\n",
      "Epoch: 76, Batch number: 0, Loss: 3962.1572265625\n",
      "Epoch: 77, Batch number: 24, Loss: 3958.1630859375\n",
      "Epoch: 78, Batch number: 48, Loss: 3930.902587890625\n",
      "Epoch: 79, Batch number: 72, Loss: 4108.2763671875\n",
      "Epoch: 81, Batch number: 20, Loss: 4023.053466796875\n",
      "Epoch: 82, Batch number: 44, Loss: 3958.932373046875\n",
      "Epoch: 83, Batch number: 68, Loss: 3945.128173828125\n",
      "Epoch: 85, Batch number: 16, Loss: 3874.9912109375\n",
      "Epoch: 86, Batch number: 40, Loss: 3888.8828125\n",
      "Epoch: 87, Batch number: 64, Loss: 3950.6396484375\n",
      "Epoch: 89, Batch number: 12, Loss: 3785.42236328125\n",
      "Epoch: 90, Batch number: 36, Loss: 3757.749267578125\n",
      "Epoch: 91, Batch number: 60, Loss: 3913.876708984375\n",
      "Epoch: 93, Batch number: 8, Loss: 3804.538330078125\n",
      "Epoch: 94, Batch number: 32, Loss: 3892.53173828125\n",
      "Epoch: 95, Batch number: 56, Loss: 3808.99609375\n",
      "Epoch: 97, Batch number: 4, Loss: 3837.760986328125\n",
      "Epoch: 98, Batch number: 28, Loss: 3760.7685546875\n",
      "Epoch: 99, Batch number: 52, Loss: 3802.89111328125\n",
      "Epoch: 101, Batch number: 0, Loss: 3791.451416015625\n",
      "Epoch: 102, Batch number: 24, Loss: 3750.664794921875\n",
      "Epoch: 103, Batch number: 48, Loss: 3780.292724609375\n",
      "Epoch: 104, Batch number: 72, Loss: 3732.308349609375\n",
      "Epoch: 106, Batch number: 20, Loss: 3780.322509765625\n",
      "Epoch: 107, Batch number: 44, Loss: 3824.185546875\n",
      "Epoch: 108, Batch number: 68, Loss: 3712.94384765625\n",
      "Epoch: 110, Batch number: 16, Loss: 3757.26171875\n",
      "Epoch: 111, Batch number: 40, Loss: 3699.35498046875\n",
      "Epoch: 112, Batch number: 64, Loss: 3718.945556640625\n",
      "Epoch: 114, Batch number: 12, Loss: 3643.82080078125\n",
      "Epoch: 115, Batch number: 36, Loss: 3640.858154296875\n",
      "Epoch: 116, Batch number: 60, Loss: 3718.76513671875\n",
      "Epoch: 118, Batch number: 8, Loss: 3682.51708984375\n",
      "Epoch: 119, Batch number: 32, Loss: 3618.052490234375\n",
      "Epoch: 120, Batch number: 56, Loss: 3682.720458984375\n",
      "Epoch: 122, Batch number: 4, Loss: 3730.364013671875\n",
      "Epoch: 123, Batch number: 28, Loss: 3514.564208984375\n",
      "Epoch: 124, Batch number: 52, Loss: 3570.629150390625\n",
      "Epoch: 126, Batch number: 0, Loss: 3424.301025390625\n",
      "Epoch: 127, Batch number: 24, Loss: 3622.466552734375\n",
      "Epoch: 128, Batch number: 48, Loss: 3528.28076171875\n",
      "Epoch: 129, Batch number: 72, Loss: 3552.92822265625\n",
      "Epoch: 131, Batch number: 20, Loss: 3637.2099609375\n",
      "Epoch: 132, Batch number: 44, Loss: 3682.784912109375\n",
      "Epoch: 133, Batch number: 68, Loss: 3802.80908203125\n",
      "Epoch: 135, Batch number: 16, Loss: 3552.494384765625\n",
      "Epoch: 136, Batch number: 40, Loss: 3656.853759765625\n",
      "Epoch: 137, Batch number: 64, Loss: 3525.908203125\n",
      "Epoch: 139, Batch number: 12, Loss: 3601.952880859375\n",
      "Epoch: 140, Batch number: 36, Loss: 3577.9970703125\n",
      "Epoch: 141, Batch number: 60, Loss: 3442.78857421875\n",
      "Epoch: 143, Batch number: 8, Loss: 3548.272705078125\n",
      "Epoch: 144, Batch number: 32, Loss: 3472.285400390625\n",
      "Epoch: 145, Batch number: 56, Loss: 3386.102294921875\n",
      "Epoch: 147, Batch number: 4, Loss: 3534.35595703125\n",
      "Epoch: 148, Batch number: 28, Loss: 3314.48828125\n",
      "Epoch: 149, Batch number: 52, Loss: 3501.5361328125\n",
      "Epoch: 151, Batch number: 0, Loss: 3541.681640625\n",
      "Epoch: 152, Batch number: 24, Loss: 3456.283935546875\n",
      "Epoch: 153, Batch number: 48, Loss: 3423.515869140625\n",
      "Epoch: 154, Batch number: 72, Loss: 3607.013671875\n",
      "Epoch: 156, Batch number: 20, Loss: 3439.2119140625\n",
      "Epoch: 157, Batch number: 44, Loss: 3423.197509765625\n",
      "Epoch: 158, Batch number: 68, Loss: 3480.110595703125\n",
      "Epoch: 160, Batch number: 16, Loss: 3360.38525390625\n",
      "Epoch: 161, Batch number: 40, Loss: 3464.736328125\n",
      "Epoch: 162, Batch number: 64, Loss: 3548.638671875\n",
      "Epoch: 164, Batch number: 12, Loss: 3407.931396484375\n",
      "Epoch: 165, Batch number: 36, Loss: 3474.078369140625\n",
      "Epoch: 166, Batch number: 60, Loss: 3453.477294921875\n",
      "Epoch: 168, Batch number: 8, Loss: 3437.499267578125\n",
      "Epoch: 169, Batch number: 32, Loss: 3417.557861328125\n",
      "Epoch: 170, Batch number: 56, Loss: 3403.14501953125\n",
      "Epoch: 172, Batch number: 4, Loss: 3355.6923828125\n",
      "Epoch: 173, Batch number: 28, Loss: 3349.841796875\n",
      "Epoch: 174, Batch number: 52, Loss: 3368.161865234375\n",
      "Epoch: 176, Batch number: 0, Loss: 3420.617919921875\n",
      "Epoch: 177, Batch number: 24, Loss: 3422.865966796875\n",
      "Epoch: 178, Batch number: 48, Loss: 3645.498779296875\n",
      "Epoch: 179, Batch number: 72, Loss: 3403.0009765625\n",
      "Epoch: 181, Batch number: 20, Loss: 3358.42529296875\n",
      "Epoch: 182, Batch number: 44, Loss: 3372.947265625\n",
      "Epoch: 183, Batch number: 68, Loss: 3469.818603515625\n",
      "Epoch: 185, Batch number: 16, Loss: 3512.7158203125\n",
      "Epoch: 186, Batch number: 40, Loss: 3547.75927734375\n",
      "Epoch: 187, Batch number: 64, Loss: 3345.5419921875\n",
      "Epoch: 189, Batch number: 12, Loss: 3441.7158203125\n",
      "Epoch: 190, Batch number: 36, Loss: 3274.949462890625\n",
      "Epoch: 191, Batch number: 60, Loss: 3438.067138671875\n",
      "Epoch: 193, Batch number: 8, Loss: 3279.47412109375\n",
      "Epoch: 194, Batch number: 32, Loss: 3507.408447265625\n",
      "Epoch: 195, Batch number: 56, Loss: 3376.878173828125\n",
      "Epoch: 197, Batch number: 4, Loss: 3271.62451171875\n",
      "Epoch: 198, Batch number: 28, Loss: 3355.768310546875\n",
      "Epoch: 199, Batch number: 52, Loss: 3497.07763671875\n",
      "Epoch: 201, Batch number: 0, Loss: 3253.65380859375\n",
      "Epoch: 202, Batch number: 24, Loss: 3284.871337890625\n",
      "Epoch: 203, Batch number: 48, Loss: 3322.598388671875\n",
      "Epoch: 204, Batch number: 72, Loss: 3209.5654296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 3356.16845703125\n",
      "Epoch: 207, Batch number: 44, Loss: 3363.999267578125\n",
      "Epoch: 208, Batch number: 68, Loss: 3426.956787109375\n",
      "Epoch: 210, Batch number: 16, Loss: 3460.0888671875\n",
      "Epoch: 211, Batch number: 40, Loss: 3441.960693359375\n",
      "Epoch: 212, Batch number: 64, Loss: 3343.122314453125\n",
      "Epoch: 214, Batch number: 12, Loss: 3322.14794921875\n",
      "Epoch: 215, Batch number: 36, Loss: 3223.489990234375\n",
      "Epoch: 216, Batch number: 60, Loss: 3274.672607421875\n",
      "Epoch: 218, Batch number: 8, Loss: 3516.762451171875\n",
      "Epoch: 219, Batch number: 32, Loss: 3451.792724609375\n",
      "Epoch: 220, Batch number: 56, Loss: 3235.129150390625\n",
      "Epoch: 222, Batch number: 4, Loss: 3147.301513671875\n",
      "Epoch: 223, Batch number: 28, Loss: 3229.815673828125\n",
      "Epoch: 224, Batch number: 52, Loss: 3402.410888671875\n",
      "Epoch: 226, Batch number: 0, Loss: 3356.888427734375\n",
      "Epoch: 227, Batch number: 24, Loss: 3182.70361328125\n",
      "Epoch: 228, Batch number: 48, Loss: 3385.10498046875\n",
      "Epoch: 229, Batch number: 72, Loss: 3416.743408203125\n",
      "Epoch: 231, Batch number: 20, Loss: 3298.094970703125\n",
      "Epoch: 232, Batch number: 44, Loss: 3319.271240234375\n",
      "Epoch: 233, Batch number: 68, Loss: 3260.841064453125\n",
      "Epoch: 235, Batch number: 16, Loss: 3300.4638671875\n",
      "Epoch: 236, Batch number: 40, Loss: 3337.07861328125\n",
      "Epoch: 237, Batch number: 64, Loss: 3435.837158203125\n",
      "Epoch: 239, Batch number: 12, Loss: 3252.559326171875\n",
      "Epoch: 240, Batch number: 36, Loss: 3363.005126953125\n",
      "Epoch: 241, Batch number: 60, Loss: 3280.227783203125\n",
      "Epoch: 243, Batch number: 8, Loss: 3287.0458984375\n",
      "Epoch: 244, Batch number: 32, Loss: 3405.844482421875\n",
      "Epoch: 245, Batch number: 56, Loss: 3358.458984375\n",
      "Epoch: 247, Batch number: 4, Loss: 3368.865966796875\n",
      "Epoch: 248, Batch number: 28, Loss: 3371.89501953125\n",
      "Epoch: 249, Batch number: 52, Loss: 3314.1298828125\n",
      "Epoch: 251, Batch number: 0, Loss: 3307.158935546875\n",
      "Epoch: 252, Batch number: 24, Loss: 3268.47998046875\n",
      "Epoch: 253, Batch number: 48, Loss: 3214.616943359375\n",
      "Epoch: 254, Batch number: 72, Loss: 3342.978515625\n",
      "Epoch: 256, Batch number: 20, Loss: 3377.984619140625\n",
      "Epoch: 257, Batch number: 44, Loss: 3196.9697265625\n",
      "Epoch: 258, Batch number: 68, Loss: 3207.750732421875\n",
      "Epoch: 260, Batch number: 16, Loss: 3207.325439453125\n",
      "Epoch: 261, Batch number: 40, Loss: 3266.526123046875\n",
      "Epoch: 262, Batch number: 64, Loss: 3286.60009765625\n",
      "Epoch: 264, Batch number: 12, Loss: 3223.1591796875\n",
      "Epoch: 265, Batch number: 36, Loss: 3291.171630859375\n",
      "Epoch: 266, Batch number: 60, Loss: 3325.60888671875\n",
      "Epoch: 268, Batch number: 8, Loss: 3142.953369140625\n",
      "Epoch: 269, Batch number: 32, Loss: 3291.135009765625\n",
      "Epoch: 270, Batch number: 56, Loss: 3260.869873046875\n",
      "Epoch: 272, Batch number: 4, Loss: 3301.208251953125\n",
      "Epoch: 273, Batch number: 28, Loss: 3301.130615234375\n",
      "Epoch: 274, Batch number: 52, Loss: 3297.0224609375\n",
      "Epoch: 276, Batch number: 0, Loss: 3330.247314453125\n",
      "Epoch: 277, Batch number: 24, Loss: 3260.109375\n",
      "Epoch: 278, Batch number: 48, Loss: 3262.712890625\n",
      "Epoch: 279, Batch number: 72, Loss: 3281.256103515625\n",
      "Epoch: 281, Batch number: 20, Loss: 3265.68896484375\n",
      "Epoch: 282, Batch number: 44, Loss: 3364.178955078125\n",
      "Epoch: 283, Batch number: 68, Loss: 3347.483154296875\n",
      "Epoch: 285, Batch number: 16, Loss: 3168.556640625\n",
      "Epoch: 286, Batch number: 40, Loss: 3349.20068359375\n",
      "Epoch: 287, Batch number: 64, Loss: 3144.81201171875\n",
      "Epoch: 289, Batch number: 12, Loss: 3171.553466796875\n",
      "Epoch: 290, Batch number: 36, Loss: 3143.82373046875\n",
      "Epoch: 291, Batch number: 60, Loss: 3434.93212890625\n",
      "Epoch: 293, Batch number: 8, Loss: 3265.727783203125\n",
      "Epoch: 294, Batch number: 32, Loss: 3245.06103515625\n",
      "Epoch: 295, Batch number: 56, Loss: 3112.270263671875\n",
      "Epoch: 297, Batch number: 4, Loss: 3173.082763671875\n",
      "Epoch: 298, Batch number: 28, Loss: 3066.451416015625\n",
      "Epoch: 299, Batch number: 52, Loss: 3163.414306640625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 7935.23486328125\n",
      "Epoch: 2, Batch number: 24, Loss: 7697.95166015625\n",
      "Epoch: 3, Batch number: 48, Loss: 7321.8505859375\n",
      "Epoch: 4, Batch number: 72, Loss: 7151.8583984375\n",
      "Epoch: 6, Batch number: 20, Loss: 6619.37255859375\n",
      "Epoch: 7, Batch number: 44, Loss: 6667.4794921875\n",
      "Epoch: 8, Batch number: 68, Loss: 6443.060546875\n",
      "Epoch: 10, Batch number: 16, Loss: 5937.98583984375\n",
      "Epoch: 11, Batch number: 40, Loss: 5960.5966796875\n",
      "Epoch: 12, Batch number: 64, Loss: 5876.451171875\n",
      "Epoch: 14, Batch number: 12, Loss: 5642.3974609375\n",
      "Epoch: 15, Batch number: 36, Loss: 5502.20361328125\n",
      "Epoch: 16, Batch number: 60, Loss: 5385.2861328125\n",
      "Epoch: 18, Batch number: 8, Loss: 5207.33154296875\n",
      "Epoch: 19, Batch number: 32, Loss: 5161.62744140625\n",
      "Epoch: 20, Batch number: 56, Loss: 4983.78662109375\n",
      "Epoch: 22, Batch number: 4, Loss: 4797.13720703125\n",
      "Epoch: 23, Batch number: 28, Loss: 4744.37353515625\n",
      "Epoch: 24, Batch number: 52, Loss: 4717.25048828125\n",
      "Epoch: 26, Batch number: 0, Loss: 4499.7734375\n",
      "Epoch: 27, Batch number: 24, Loss: 4507.20947265625\n",
      "Epoch: 28, Batch number: 48, Loss: 4418.39013671875\n",
      "Epoch: 29, Batch number: 72, Loss: 4534.66552734375\n",
      "Epoch: 31, Batch number: 20, Loss: 4359.2080078125\n",
      "Epoch: 32, Batch number: 44, Loss: 4455.51123046875\n",
      "Epoch: 33, Batch number: 68, Loss: 4434.66650390625\n",
      "Epoch: 35, Batch number: 16, Loss: 4133.451171875\n",
      "Epoch: 36, Batch number: 40, Loss: 4226.1884765625\n",
      "Epoch: 37, Batch number: 64, Loss: 4210.04638671875\n",
      "Epoch: 39, Batch number: 12, Loss: 4061.563720703125\n",
      "Epoch: 40, Batch number: 36, Loss: 4050.912109375\n",
      "Epoch: 41, Batch number: 60, Loss: 4123.18701171875\n",
      "Epoch: 43, Batch number: 8, Loss: 3952.077392578125\n",
      "Epoch: 44, Batch number: 32, Loss: 4015.69775390625\n",
      "Epoch: 45, Batch number: 56, Loss: 3926.638427734375\n",
      "Epoch: 47, Batch number: 4, Loss: 3907.48779296875\n",
      "Epoch: 48, Batch number: 28, Loss: 3853.18994140625\n",
      "Epoch: 49, Batch number: 52, Loss: 3880.416015625\n",
      "Epoch: 51, Batch number: 0, Loss: 3698.1201171875\n",
      "Epoch: 52, Batch number: 24, Loss: 3915.55908203125\n",
      "Epoch: 53, Batch number: 48, Loss: 3773.75927734375\n",
      "Epoch: 54, Batch number: 72, Loss: 3778.03125\n",
      "Epoch: 56, Batch number: 20, Loss: 3698.108642578125\n",
      "Epoch: 57, Batch number: 44, Loss: 3783.814453125\n",
      "Epoch: 58, Batch number: 68, Loss: 3875.132080078125\n",
      "Epoch: 60, Batch number: 16, Loss: 3703.733154296875\n",
      "Epoch: 61, Batch number: 40, Loss: 3732.533203125\n",
      "Epoch: 62, Batch number: 64, Loss: 3691.53076171875\n",
      "Epoch: 64, Batch number: 12, Loss: 3591.818115234375\n",
      "Epoch: 65, Batch number: 36, Loss: 3594.033203125\n",
      "Epoch: 66, Batch number: 60, Loss: 3653.203369140625\n",
      "Epoch: 68, Batch number: 8, Loss: 3656.205810546875\n",
      "Epoch: 69, Batch number: 32, Loss: 3577.058349609375\n",
      "Epoch: 70, Batch number: 56, Loss: 3473.149169921875\n",
      "Epoch: 72, Batch number: 4, Loss: 3546.714599609375\n",
      "Epoch: 73, Batch number: 28, Loss: 3517.95361328125\n",
      "Epoch: 74, Batch number: 52, Loss: 3648.306884765625\n",
      "Epoch: 76, Batch number: 0, Loss: 3482.711669921875\n",
      "Epoch: 77, Batch number: 24, Loss: 3597.820556640625\n",
      "Epoch: 78, Batch number: 48, Loss: 3436.959228515625\n",
      "Epoch: 79, Batch number: 72, Loss: 3434.65380859375\n",
      "Epoch: 81, Batch number: 20, Loss: 3412.979736328125\n",
      "Epoch: 82, Batch number: 44, Loss: 3463.900146484375\n",
      "Epoch: 83, Batch number: 68, Loss: 3534.26806640625\n",
      "Epoch: 85, Batch number: 16, Loss: 3361.90380859375\n",
      "Epoch: 86, Batch number: 40, Loss: 3515.7001953125\n",
      "Epoch: 87, Batch number: 64, Loss: 3373.3427734375\n",
      "Epoch: 89, Batch number: 12, Loss: 3438.21044921875\n",
      "Epoch: 90, Batch number: 36, Loss: 3374.89013671875\n",
      "Epoch: 91, Batch number: 60, Loss: 3533.138427734375\n",
      "Epoch: 93, Batch number: 8, Loss: 3475.31298828125\n",
      "Epoch: 94, Batch number: 32, Loss: 3308.574951171875\n",
      "Epoch: 95, Batch number: 56, Loss: 3487.03076171875\n",
      "Epoch: 97, Batch number: 4, Loss: 3395.895751953125\n",
      "Epoch: 98, Batch number: 28, Loss: 3335.202392578125\n",
      "Epoch: 99, Batch number: 52, Loss: 3320.335205078125\n",
      "Epoch: 101, Batch number: 0, Loss: 3314.47705078125\n",
      "Epoch: 102, Batch number: 24, Loss: 3362.72509765625\n",
      "Epoch: 103, Batch number: 48, Loss: 3300.2626953125\n",
      "Epoch: 104, Batch number: 72, Loss: 3335.4560546875\n",
      "Epoch: 106, Batch number: 20, Loss: 3344.428955078125\n",
      "Epoch: 107, Batch number: 44, Loss: 3448.7470703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Batch number: 68, Loss: 3299.842529296875\n",
      "Epoch: 110, Batch number: 16, Loss: 3214.678955078125\n",
      "Epoch: 111, Batch number: 40, Loss: 3318.345947265625\n",
      "Epoch: 112, Batch number: 64, Loss: 3271.87744140625\n",
      "Epoch: 114, Batch number: 12, Loss: 3385.904052734375\n",
      "Epoch: 115, Batch number: 36, Loss: 3273.841796875\n",
      "Epoch: 116, Batch number: 60, Loss: 3308.88427734375\n",
      "Epoch: 118, Batch number: 8, Loss: 3283.134033203125\n",
      "Epoch: 119, Batch number: 32, Loss: 3356.568359375\n",
      "Epoch: 120, Batch number: 56, Loss: 3252.722412109375\n",
      "Epoch: 122, Batch number: 4, Loss: 3248.814453125\n",
      "Epoch: 123, Batch number: 28, Loss: 3209.739990234375\n",
      "Epoch: 124, Batch number: 52, Loss: 3468.196533203125\n",
      "Epoch: 126, Batch number: 0, Loss: 3236.68896484375\n",
      "Epoch: 127, Batch number: 24, Loss: 3304.306884765625\n",
      "Epoch: 128, Batch number: 48, Loss: 3324.38037109375\n",
      "Epoch: 129, Batch number: 72, Loss: 3349.521240234375\n",
      "Epoch: 131, Batch number: 20, Loss: 3194.63232421875\n",
      "Epoch: 132, Batch number: 44, Loss: 3453.68701171875\n",
      "Epoch: 133, Batch number: 68, Loss: 3245.23779296875\n",
      "Epoch: 135, Batch number: 16, Loss: 3297.968505859375\n",
      "Epoch: 136, Batch number: 40, Loss: 3283.601318359375\n",
      "Epoch: 137, Batch number: 64, Loss: 3202.07470703125\n",
      "Epoch: 139, Batch number: 12, Loss: 3145.741943359375\n",
      "Epoch: 140, Batch number: 36, Loss: 3218.73291015625\n",
      "Epoch: 141, Batch number: 60, Loss: 3166.71728515625\n",
      "Epoch: 143, Batch number: 8, Loss: 3172.38232421875\n",
      "Epoch: 144, Batch number: 32, Loss: 3273.6396484375\n",
      "Epoch: 145, Batch number: 56, Loss: 3321.656494140625\n",
      "Epoch: 147, Batch number: 4, Loss: 3275.49267578125\n",
      "Epoch: 148, Batch number: 28, Loss: 3205.584716796875\n",
      "Epoch: 149, Batch number: 52, Loss: 3249.046630859375\n",
      "Epoch: 151, Batch number: 0, Loss: 3234.70556640625\n",
      "Epoch: 152, Batch number: 24, Loss: 3241.29833984375\n",
      "Epoch: 153, Batch number: 48, Loss: 3241.379150390625\n",
      "Epoch: 154, Batch number: 72, Loss: 3189.127685546875\n",
      "Epoch: 156, Batch number: 20, Loss: 3183.884521484375\n",
      "Epoch: 157, Batch number: 44, Loss: 3163.961181640625\n",
      "Epoch: 158, Batch number: 68, Loss: 3353.072265625\n",
      "Epoch: 160, Batch number: 16, Loss: 3044.965576171875\n",
      "Epoch: 161, Batch number: 40, Loss: 3321.828125\n",
      "Epoch: 162, Batch number: 64, Loss: 3336.01904296875\n",
      "Epoch: 164, Batch number: 12, Loss: 3193.049560546875\n",
      "Epoch: 165, Batch number: 36, Loss: 3180.0087890625\n",
      "Epoch: 166, Batch number: 60, Loss: 3270.87939453125\n",
      "Epoch: 168, Batch number: 8, Loss: 3062.96484375\n",
      "Epoch: 169, Batch number: 32, Loss: 3050.614501953125\n",
      "Epoch: 170, Batch number: 56, Loss: 3185.401123046875\n",
      "Epoch: 172, Batch number: 4, Loss: 3359.51123046875\n",
      "Epoch: 173, Batch number: 28, Loss: 3271.334716796875\n",
      "Epoch: 174, Batch number: 52, Loss: 3155.44580078125\n",
      "Epoch: 176, Batch number: 0, Loss: 3132.4345703125\n",
      "Epoch: 177, Batch number: 24, Loss: 3256.1669921875\n",
      "Epoch: 178, Batch number: 48, Loss: 3212.94189453125\n",
      "Epoch: 179, Batch number: 72, Loss: 3220.47265625\n",
      "Epoch: 181, Batch number: 20, Loss: 3238.485107421875\n",
      "Epoch: 182, Batch number: 44, Loss: 3242.86865234375\n",
      "Epoch: 183, Batch number: 68, Loss: 3215.311279296875\n",
      "Epoch: 185, Batch number: 16, Loss: 3224.151123046875\n",
      "Epoch: 186, Batch number: 40, Loss: 3250.982421875\n",
      "Epoch: 187, Batch number: 64, Loss: 3119.877685546875\n",
      "Epoch: 189, Batch number: 12, Loss: 3299.41943359375\n",
      "Epoch: 190, Batch number: 36, Loss: 3164.181640625\n",
      "Epoch: 191, Batch number: 60, Loss: 3274.779541015625\n",
      "Epoch: 193, Batch number: 8, Loss: 3253.973388671875\n",
      "Epoch: 194, Batch number: 32, Loss: 3328.615234375\n",
      "Epoch: 195, Batch number: 56, Loss: 3344.14404296875\n",
      "Epoch: 197, Batch number: 4, Loss: 3250.8271484375\n",
      "Epoch: 198, Batch number: 28, Loss: 3324.87841796875\n",
      "Epoch: 199, Batch number: 52, Loss: 3290.03955078125\n",
      "Epoch: 201, Batch number: 0, Loss: 3178.654052734375\n",
      "Epoch: 202, Batch number: 24, Loss: 3159.56103515625\n",
      "Epoch: 203, Batch number: 48, Loss: 3264.384521484375\n",
      "Epoch: 204, Batch number: 72, Loss: 3255.5244140625\n",
      "Epoch: 206, Batch number: 20, Loss: 3183.483154296875\n",
      "Epoch: 207, Batch number: 44, Loss: 3214.7080078125\n",
      "Epoch: 208, Batch number: 68, Loss: 3336.19580078125\n",
      "Epoch: 210, Batch number: 16, Loss: 3214.754638671875\n",
      "Epoch: 211, Batch number: 40, Loss: 3287.30224609375\n",
      "Epoch: 212, Batch number: 64, Loss: 3288.2001953125\n",
      "Epoch: 214, Batch number: 12, Loss: 2997.85498046875\n",
      "Epoch: 215, Batch number: 36, Loss: 3308.14453125\n",
      "Epoch: 216, Batch number: 60, Loss: 3335.237060546875\n",
      "Epoch: 218, Batch number: 8, Loss: 3294.048583984375\n",
      "Epoch: 219, Batch number: 32, Loss: 3194.82177734375\n",
      "Epoch: 220, Batch number: 56, Loss: 3224.90673828125\n",
      "Epoch: 222, Batch number: 4, Loss: 3078.86181640625\n",
      "Epoch: 223, Batch number: 28, Loss: 3332.44384765625\n",
      "Epoch: 224, Batch number: 52, Loss: 3176.65087890625\n",
      "Epoch: 226, Batch number: 0, Loss: 3183.744873046875\n",
      "Epoch: 227, Batch number: 24, Loss: 3306.9990234375\n",
      "Epoch: 228, Batch number: 48, Loss: 3221.14990234375\n",
      "Epoch: 229, Batch number: 72, Loss: 3168.737548828125\n",
      "Epoch: 231, Batch number: 20, Loss: 3125.146484375\n",
      "Epoch: 232, Batch number: 44, Loss: 3180.807861328125\n",
      "Epoch: 233, Batch number: 68, Loss: 3078.601318359375\n",
      "Epoch: 235, Batch number: 16, Loss: 3090.782958984375\n",
      "Epoch: 236, Batch number: 40, Loss: 3250.04736328125\n",
      "Epoch: 237, Batch number: 64, Loss: 3286.241943359375\n",
      "Epoch: 239, Batch number: 12, Loss: 3122.927001953125\n",
      "Epoch: 240, Batch number: 36, Loss: 3243.1513671875\n",
      "Epoch: 241, Batch number: 60, Loss: 3274.360107421875\n",
      "Epoch: 243, Batch number: 8, Loss: 3114.280517578125\n",
      "Epoch: 244, Batch number: 32, Loss: 3252.046875\n",
      "Epoch: 245, Batch number: 56, Loss: 3249.104248046875\n",
      "Epoch: 247, Batch number: 4, Loss: 3175.718994140625\n",
      "Epoch: 248, Batch number: 28, Loss: 3146.74169921875\n",
      "Epoch: 249, Batch number: 52, Loss: 3255.111083984375\n",
      "Epoch: 251, Batch number: 0, Loss: 3085.466796875\n",
      "Epoch: 252, Batch number: 24, Loss: 3071.841796875\n",
      "Epoch: 253, Batch number: 48, Loss: 3139.41845703125\n",
      "Epoch: 254, Batch number: 72, Loss: 3283.610595703125\n",
      "Epoch: 256, Batch number: 20, Loss: 3103.71484375\n",
      "Epoch: 257, Batch number: 44, Loss: 3217.677490234375\n",
      "Epoch: 258, Batch number: 68, Loss: 3230.93994140625\n",
      "Epoch: 260, Batch number: 16, Loss: 3199.598876953125\n",
      "Epoch: 261, Batch number: 40, Loss: 3224.9638671875\n",
      "Epoch: 262, Batch number: 64, Loss: 3302.4072265625\n",
      "Epoch: 264, Batch number: 12, Loss: 3084.232421875\n",
      "Epoch: 265, Batch number: 36, Loss: 3100.908203125\n",
      "Epoch: 266, Batch number: 60, Loss: 3301.439697265625\n",
      "Epoch: 268, Batch number: 8, Loss: 3229.798095703125\n",
      "Epoch: 269, Batch number: 32, Loss: 3115.089111328125\n",
      "Epoch: 270, Batch number: 56, Loss: 3248.874755859375\n",
      "Epoch: 272, Batch number: 4, Loss: 3270.3447265625\n",
      "Epoch: 273, Batch number: 28, Loss: 3274.8916015625\n",
      "Epoch: 274, Batch number: 52, Loss: 3242.09716796875\n",
      "Epoch: 276, Batch number: 0, Loss: 3264.756103515625\n",
      "Epoch: 277, Batch number: 24, Loss: 3116.13720703125\n",
      "Epoch: 278, Batch number: 48, Loss: 3178.209716796875\n",
      "Epoch: 279, Batch number: 72, Loss: 3373.06494140625\n",
      "Epoch: 281, Batch number: 20, Loss: 3207.11376953125\n",
      "Epoch: 282, Batch number: 44, Loss: 3224.13134765625\n",
      "Epoch: 283, Batch number: 68, Loss: 3133.311279296875\n",
      "Epoch: 285, Batch number: 16, Loss: 3302.12890625\n",
      "Epoch: 286, Batch number: 40, Loss: 3262.77587890625\n",
      "Epoch: 287, Batch number: 64, Loss: 3139.38671875\n",
      "Epoch: 289, Batch number: 12, Loss: 3200.34765625\n",
      "Epoch: 290, Batch number: 36, Loss: 3024.2880859375\n",
      "Epoch: 291, Batch number: 60, Loss: 3278.79736328125\n",
      "Epoch: 293, Batch number: 8, Loss: 3001.056640625\n",
      "Epoch: 294, Batch number: 32, Loss: 3272.087890625\n",
      "Epoch: 295, Batch number: 56, Loss: 3082.103759765625\n",
      "Epoch: 297, Batch number: 4, Loss: 3140.33984375\n",
      "Epoch: 298, Batch number: 28, Loss: 3075.93701171875\n",
      "Epoch: 299, Batch number: 52, Loss: 3187.220947265625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8128.650390625\n",
      "Epoch: 2, Batch number: 24, Loss: 7527.32861328125\n",
      "Epoch: 3, Batch number: 48, Loss: 7087.21240234375\n",
      "Epoch: 4, Batch number: 72, Loss: 6864.61865234375\n",
      "Epoch: 6, Batch number: 20, Loss: 6492.37158203125\n",
      "Epoch: 7, Batch number: 44, Loss: 6251.666015625\n",
      "Epoch: 8, Batch number: 68, Loss: 6017.5078125\n",
      "Epoch: 10, Batch number: 16, Loss: 5677.7783203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Batch number: 40, Loss: 5643.5380859375\n",
      "Epoch: 12, Batch number: 64, Loss: 5431.52490234375\n",
      "Epoch: 14, Batch number: 12, Loss: 5230.212890625\n",
      "Epoch: 15, Batch number: 36, Loss: 5156.35546875\n",
      "Epoch: 16, Batch number: 60, Loss: 4864.15625\n",
      "Epoch: 18, Batch number: 8, Loss: 4855.09033203125\n",
      "Epoch: 19, Batch number: 32, Loss: 4614.7841796875\n",
      "Epoch: 20, Batch number: 56, Loss: 4489.01708984375\n",
      "Epoch: 22, Batch number: 4, Loss: 4454.41259765625\n",
      "Epoch: 23, Batch number: 28, Loss: 4446.154296875\n",
      "Epoch: 24, Batch number: 52, Loss: 4428.8046875\n",
      "Epoch: 26, Batch number: 0, Loss: 4182.6767578125\n",
      "Epoch: 27, Batch number: 24, Loss: 4151.59521484375\n",
      "Epoch: 28, Batch number: 48, Loss: 4122.302734375\n",
      "Epoch: 29, Batch number: 72, Loss: 4224.4453125\n",
      "Epoch: 31, Batch number: 20, Loss: 4007.268310546875\n",
      "Epoch: 32, Batch number: 44, Loss: 4108.00927734375\n",
      "Epoch: 33, Batch number: 68, Loss: 4031.45849609375\n",
      "Epoch: 35, Batch number: 16, Loss: 3892.5458984375\n",
      "Epoch: 36, Batch number: 40, Loss: 3823.143310546875\n",
      "Epoch: 37, Batch number: 64, Loss: 3932.555908203125\n",
      "Epoch: 39, Batch number: 12, Loss: 3826.19384765625\n",
      "Epoch: 40, Batch number: 36, Loss: 3730.246337890625\n",
      "Epoch: 41, Batch number: 60, Loss: 3699.539794921875\n",
      "Epoch: 43, Batch number: 8, Loss: 3559.479736328125\n",
      "Epoch: 44, Batch number: 32, Loss: 3552.59912109375\n",
      "Epoch: 45, Batch number: 56, Loss: 3541.068115234375\n",
      "Epoch: 47, Batch number: 4, Loss: 3624.177001953125\n",
      "Epoch: 48, Batch number: 28, Loss: 3691.827880859375\n",
      "Epoch: 49, Batch number: 52, Loss: 3604.542724609375\n",
      "Epoch: 51, Batch number: 0, Loss: 3479.241455078125\n",
      "Epoch: 52, Batch number: 24, Loss: 3492.29345703125\n",
      "Epoch: 53, Batch number: 48, Loss: 3473.322998046875\n",
      "Epoch: 54, Batch number: 72, Loss: 3510.06884765625\n",
      "Epoch: 56, Batch number: 20, Loss: 3442.993896484375\n",
      "Epoch: 57, Batch number: 44, Loss: 3540.03515625\n",
      "Epoch: 58, Batch number: 68, Loss: 3432.8408203125\n",
      "Epoch: 60, Batch number: 16, Loss: 3395.376708984375\n",
      "Epoch: 61, Batch number: 40, Loss: 3550.451904296875\n",
      "Epoch: 62, Batch number: 64, Loss: 3477.5390625\n",
      "Epoch: 64, Batch number: 12, Loss: 3318.9765625\n",
      "Epoch: 65, Batch number: 36, Loss: 3483.790283203125\n",
      "Epoch: 66, Batch number: 60, Loss: 3500.65625\n",
      "Epoch: 68, Batch number: 8, Loss: 3543.078857421875\n",
      "Epoch: 69, Batch number: 32, Loss: 3298.642822265625\n",
      "Epoch: 70, Batch number: 56, Loss: 3502.4580078125\n",
      "Epoch: 72, Batch number: 4, Loss: 3180.859130859375\n",
      "Epoch: 73, Batch number: 28, Loss: 3358.87451171875\n",
      "Epoch: 74, Batch number: 52, Loss: 3358.73779296875\n",
      "Epoch: 76, Batch number: 0, Loss: 3342.373779296875\n",
      "Epoch: 77, Batch number: 24, Loss: 3271.322998046875\n",
      "Epoch: 78, Batch number: 48, Loss: 3463.556396484375\n",
      "Epoch: 79, Batch number: 72, Loss: 3479.9482421875\n",
      "Epoch: 81, Batch number: 20, Loss: 3352.795654296875\n",
      "Epoch: 82, Batch number: 44, Loss: 3501.22265625\n",
      "Epoch: 83, Batch number: 68, Loss: 3330.40234375\n",
      "Epoch: 85, Batch number: 16, Loss: 3277.349853515625\n",
      "Epoch: 86, Batch number: 40, Loss: 3369.637451171875\n",
      "Epoch: 87, Batch number: 64, Loss: 3368.0712890625\n",
      "Epoch: 89, Batch number: 12, Loss: 3411.08447265625\n",
      "Epoch: 90, Batch number: 36, Loss: 3337.43896484375\n",
      "Epoch: 91, Batch number: 60, Loss: 3339.6103515625\n",
      "Epoch: 93, Batch number: 8, Loss: 3270.48291015625\n",
      "Epoch: 94, Batch number: 32, Loss: 3254.390869140625\n",
      "Epoch: 95, Batch number: 56, Loss: 3308.303466796875\n",
      "Epoch: 97, Batch number: 4, Loss: 3209.66845703125\n",
      "Epoch: 98, Batch number: 28, Loss: 3160.4658203125\n",
      "Epoch: 99, Batch number: 52, Loss: 3368.452392578125\n",
      "Epoch: 101, Batch number: 0, Loss: 3182.33154296875\n",
      "Epoch: 102, Batch number: 24, Loss: 3181.058837890625\n",
      "Epoch: 103, Batch number: 48, Loss: 3211.83837890625\n",
      "Epoch: 104, Batch number: 72, Loss: 3382.93994140625\n",
      "Epoch: 106, Batch number: 20, Loss: 3221.523193359375\n",
      "Epoch: 107, Batch number: 44, Loss: 3260.2548828125\n",
      "Epoch: 108, Batch number: 68, Loss: 3226.326171875\n",
      "Epoch: 110, Batch number: 16, Loss: 3306.7177734375\n",
      "Epoch: 111, Batch number: 40, Loss: 3165.490966796875\n",
      "Epoch: 112, Batch number: 64, Loss: 3318.970703125\n",
      "Epoch: 114, Batch number: 12, Loss: 3258.417724609375\n",
      "Epoch: 115, Batch number: 36, Loss: 3308.641357421875\n",
      "Epoch: 116, Batch number: 60, Loss: 3360.05810546875\n",
      "Epoch: 118, Batch number: 8, Loss: 3312.8505859375\n",
      "Epoch: 119, Batch number: 32, Loss: 3173.7919921875\n",
      "Epoch: 120, Batch number: 56, Loss: 3231.1357421875\n",
      "Epoch: 122, Batch number: 4, Loss: 3156.34326171875\n",
      "Epoch: 123, Batch number: 28, Loss: 3330.4013671875\n",
      "Epoch: 124, Batch number: 52, Loss: 3337.232177734375\n",
      "Epoch: 126, Batch number: 0, Loss: 3161.18701171875\n",
      "Epoch: 127, Batch number: 24, Loss: 3146.745849609375\n",
      "Epoch: 128, Batch number: 48, Loss: 3158.18310546875\n",
      "Epoch: 129, Batch number: 72, Loss: 3247.725830078125\n",
      "Epoch: 131, Batch number: 20, Loss: 3175.9169921875\n",
      "Epoch: 132, Batch number: 44, Loss: 3328.122802734375\n",
      "Epoch: 133, Batch number: 68, Loss: 3241.843017578125\n",
      "Epoch: 135, Batch number: 16, Loss: 3263.5517578125\n",
      "Epoch: 136, Batch number: 40, Loss: 3096.59375\n",
      "Epoch: 137, Batch number: 64, Loss: 3295.308837890625\n",
      "Epoch: 139, Batch number: 12, Loss: 3200.826416015625\n",
      "Epoch: 140, Batch number: 36, Loss: 3107.20166015625\n",
      "Epoch: 141, Batch number: 60, Loss: 3271.40380859375\n",
      "Epoch: 143, Batch number: 8, Loss: 3307.099365234375\n",
      "Epoch: 144, Batch number: 32, Loss: 3261.61865234375\n",
      "Epoch: 145, Batch number: 56, Loss: 3280.685546875\n",
      "Epoch: 147, Batch number: 4, Loss: 3184.39697265625\n",
      "Epoch: 148, Batch number: 28, Loss: 3191.55615234375\n",
      "Epoch: 149, Batch number: 52, Loss: 3296.080322265625\n",
      "Epoch: 151, Batch number: 0, Loss: 3214.261474609375\n",
      "Epoch: 152, Batch number: 24, Loss: 3071.274658203125\n",
      "Epoch: 153, Batch number: 48, Loss: 3229.575927734375\n",
      "Epoch: 154, Batch number: 72, Loss: 3264.89599609375\n",
      "Epoch: 156, Batch number: 20, Loss: 3192.15185546875\n",
      "Epoch: 157, Batch number: 44, Loss: 3016.1748046875\n",
      "Epoch: 158, Batch number: 68, Loss: 3252.72216796875\n",
      "Epoch: 160, Batch number: 16, Loss: 3113.684326171875\n",
      "Epoch: 161, Batch number: 40, Loss: 3330.51708984375\n",
      "Epoch: 162, Batch number: 64, Loss: 3280.4296875\n",
      "Epoch: 164, Batch number: 12, Loss: 3147.234130859375\n",
      "Epoch: 165, Batch number: 36, Loss: 3186.769775390625\n",
      "Epoch: 166, Batch number: 60, Loss: 3216.98681640625\n",
      "Epoch: 168, Batch number: 8, Loss: 3032.85107421875\n",
      "Epoch: 169, Batch number: 32, Loss: 3129.930908203125\n",
      "Epoch: 170, Batch number: 56, Loss: 3170.19921875\n",
      "Epoch: 172, Batch number: 4, Loss: 3128.82080078125\n",
      "Epoch: 173, Batch number: 28, Loss: 3151.349853515625\n",
      "Epoch: 174, Batch number: 52, Loss: 3094.08447265625\n",
      "Epoch: 176, Batch number: 0, Loss: 3127.517333984375\n",
      "Epoch: 177, Batch number: 24, Loss: 3249.38232421875\n",
      "Epoch: 178, Batch number: 48, Loss: 3200.06494140625\n",
      "Epoch: 179, Batch number: 72, Loss: 3159.7001953125\n",
      "Epoch: 181, Batch number: 20, Loss: 3033.068603515625\n",
      "Epoch: 182, Batch number: 44, Loss: 3119.00634765625\n",
      "Epoch: 183, Batch number: 68, Loss: 3176.53173828125\n",
      "Epoch: 185, Batch number: 16, Loss: 3204.0859375\n",
      "Epoch: 186, Batch number: 40, Loss: 3186.389892578125\n",
      "Epoch: 187, Batch number: 64, Loss: 3126.284423828125\n",
      "Epoch: 189, Batch number: 12, Loss: 3186.199462890625\n",
      "Epoch: 190, Batch number: 36, Loss: 3275.082275390625\n",
      "Epoch: 191, Batch number: 60, Loss: 3240.191162109375\n",
      "Epoch: 193, Batch number: 8, Loss: 3194.2119140625\n",
      "Epoch: 194, Batch number: 32, Loss: 3240.397216796875\n",
      "Epoch: 195, Batch number: 56, Loss: 3226.973876953125\n",
      "Epoch: 197, Batch number: 4, Loss: 3086.091796875\n",
      "Epoch: 198, Batch number: 28, Loss: 3091.69091796875\n",
      "Epoch: 199, Batch number: 52, Loss: 3214.09130859375\n",
      "Epoch: 201, Batch number: 0, Loss: 3253.736328125\n",
      "Epoch: 202, Batch number: 24, Loss: 3226.572021484375\n",
      "Epoch: 203, Batch number: 48, Loss: 3110.3544921875\n",
      "Epoch: 204, Batch number: 72, Loss: 3198.907958984375\n",
      "Epoch: 206, Batch number: 20, Loss: 3296.163330078125\n",
      "Epoch: 207, Batch number: 44, Loss: 3112.189453125\n",
      "Epoch: 208, Batch number: 68, Loss: 3015.277587890625\n",
      "Epoch: 210, Batch number: 16, Loss: 3126.23046875\n",
      "Epoch: 211, Batch number: 40, Loss: 3130.283447265625\n",
      "Epoch: 212, Batch number: 64, Loss: 3260.189208984375\n",
      "Epoch: 214, Batch number: 12, Loss: 3086.8251953125\n",
      "Epoch: 215, Batch number: 36, Loss: 3174.958740234375\n",
      "Epoch: 216, Batch number: 60, Loss: 3340.0703125\n",
      "Epoch: 218, Batch number: 8, Loss: 3124.25634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219, Batch number: 32, Loss: 3161.0810546875\n",
      "Epoch: 220, Batch number: 56, Loss: 3411.954345703125\n",
      "Epoch: 222, Batch number: 4, Loss: 3107.835205078125\n",
      "Epoch: 223, Batch number: 28, Loss: 3265.247314453125\n",
      "Epoch: 224, Batch number: 52, Loss: 3241.4501953125\n",
      "Epoch: 226, Batch number: 0, Loss: 3277.532470703125\n",
      "Epoch: 227, Batch number: 24, Loss: 3176.315185546875\n",
      "Epoch: 228, Batch number: 48, Loss: 3333.126708984375\n",
      "Epoch: 229, Batch number: 72, Loss: 3196.651123046875\n",
      "Epoch: 231, Batch number: 20, Loss: 3211.433349609375\n",
      "Epoch: 232, Batch number: 44, Loss: 3115.51171875\n",
      "Epoch: 233, Batch number: 68, Loss: 3181.314453125\n",
      "Epoch: 235, Batch number: 16, Loss: 3196.893310546875\n",
      "Epoch: 236, Batch number: 40, Loss: 3214.510986328125\n",
      "Epoch: 237, Batch number: 64, Loss: 3157.139404296875\n",
      "Epoch: 239, Batch number: 12, Loss: 3143.700927734375\n",
      "Epoch: 240, Batch number: 36, Loss: 3224.060791015625\n",
      "Epoch: 241, Batch number: 60, Loss: 3342.64306640625\n",
      "Epoch: 243, Batch number: 8, Loss: 3007.709228515625\n",
      "Epoch: 244, Batch number: 32, Loss: 3294.98583984375\n",
      "Epoch: 245, Batch number: 56, Loss: 3229.82373046875\n",
      "Epoch: 247, Batch number: 4, Loss: 3156.37744140625\n",
      "Epoch: 248, Batch number: 28, Loss: 3184.765380859375\n",
      "Epoch: 249, Batch number: 52, Loss: 3112.42919921875\n",
      "Epoch: 251, Batch number: 0, Loss: 3159.677001953125\n",
      "Epoch: 252, Batch number: 24, Loss: 3227.73095703125\n",
      "Epoch: 253, Batch number: 48, Loss: 3042.134033203125\n",
      "Epoch: 254, Batch number: 72, Loss: 3187.7509765625\n",
      "Epoch: 256, Batch number: 20, Loss: 3147.205078125\n",
      "Epoch: 257, Batch number: 44, Loss: 3303.095947265625\n",
      "Epoch: 258, Batch number: 68, Loss: 3263.30078125\n",
      "Epoch: 260, Batch number: 16, Loss: 3256.25146484375\n",
      "Epoch: 261, Batch number: 40, Loss: 3283.569580078125\n",
      "Epoch: 262, Batch number: 64, Loss: 3171.332275390625\n",
      "Epoch: 264, Batch number: 12, Loss: 3204.42138671875\n",
      "Epoch: 265, Batch number: 36, Loss: 3163.388427734375\n",
      "Epoch: 266, Batch number: 60, Loss: 3135.08837890625\n",
      "Epoch: 268, Batch number: 8, Loss: 3124.0927734375\n",
      "Epoch: 269, Batch number: 32, Loss: 3259.76953125\n",
      "Epoch: 270, Batch number: 56, Loss: 3026.720458984375\n",
      "Epoch: 272, Batch number: 4, Loss: 3035.9970703125\n",
      "Epoch: 273, Batch number: 28, Loss: 3265.205322265625\n",
      "Epoch: 274, Batch number: 52, Loss: 3229.828369140625\n",
      "Epoch: 276, Batch number: 0, Loss: 3097.9150390625\n",
      "Epoch: 277, Batch number: 24, Loss: 3155.228271484375\n",
      "Epoch: 278, Batch number: 48, Loss: 3174.03564453125\n",
      "Epoch: 279, Batch number: 72, Loss: 3133.757080078125\n",
      "Epoch: 281, Batch number: 20, Loss: 3183.848876953125\n",
      "Epoch: 282, Batch number: 44, Loss: 3167.875732421875\n",
      "Epoch: 283, Batch number: 68, Loss: 3337.11865234375\n",
      "Epoch: 285, Batch number: 16, Loss: 3259.124755859375\n",
      "Epoch: 286, Batch number: 40, Loss: 3090.3642578125\n",
      "Epoch: 287, Batch number: 64, Loss: 3310.41455078125\n",
      "Epoch: 289, Batch number: 12, Loss: 3189.6640625\n",
      "Epoch: 290, Batch number: 36, Loss: 3282.05859375\n",
      "Epoch: 291, Batch number: 60, Loss: 3165.685546875\n",
      "Epoch: 293, Batch number: 8, Loss: 3068.131591796875\n",
      "Epoch: 294, Batch number: 32, Loss: 3347.759765625\n",
      "Epoch: 295, Batch number: 56, Loss: 3127.73583984375\n",
      "Epoch: 297, Batch number: 4, Loss: 3173.169677734375\n",
      "Epoch: 298, Batch number: 28, Loss: 3242.314697265625\n",
      "Epoch: 299, Batch number: 52, Loss: 3106.0068359375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8079.47607421875\n",
      "Epoch: 2, Batch number: 24, Loss: 7293.2900390625\n",
      "Epoch: 3, Batch number: 48, Loss: 6821.86376953125\n",
      "Epoch: 4, Batch number: 72, Loss: 6674.41455078125\n",
      "Epoch: 6, Batch number: 20, Loss: 6077.27978515625\n",
      "Epoch: 7, Batch number: 44, Loss: 6041.53271484375\n",
      "Epoch: 8, Batch number: 68, Loss: 5729.47216796875\n",
      "Epoch: 10, Batch number: 16, Loss: 5501.76611328125\n",
      "Epoch: 11, Batch number: 40, Loss: 5277.08984375\n",
      "Epoch: 12, Batch number: 64, Loss: 4970.85986328125\n",
      "Epoch: 14, Batch number: 12, Loss: 4899.2294921875\n",
      "Epoch: 15, Batch number: 36, Loss: 4778.4453125\n",
      "Epoch: 16, Batch number: 60, Loss: 4418.68798828125\n",
      "Epoch: 18, Batch number: 8, Loss: 4300.1279296875\n",
      "Epoch: 19, Batch number: 32, Loss: 4248.552734375\n",
      "Epoch: 20, Batch number: 56, Loss: 4282.0703125\n",
      "Epoch: 22, Batch number: 4, Loss: 4208.0810546875\n",
      "Epoch: 23, Batch number: 28, Loss: 4225.7001953125\n",
      "Epoch: 24, Batch number: 52, Loss: 3984.70703125\n",
      "Epoch: 26, Batch number: 0, Loss: 3718.696533203125\n",
      "Epoch: 27, Batch number: 24, Loss: 3866.7578125\n",
      "Epoch: 28, Batch number: 48, Loss: 3809.509521484375\n",
      "Epoch: 29, Batch number: 72, Loss: 3866.544677734375\n",
      "Epoch: 31, Batch number: 20, Loss: 3743.528564453125\n",
      "Epoch: 32, Batch number: 44, Loss: 3747.916015625\n",
      "Epoch: 33, Batch number: 68, Loss: 3698.611083984375\n",
      "Epoch: 35, Batch number: 16, Loss: 3817.525390625\n",
      "Epoch: 36, Batch number: 40, Loss: 3565.08251953125\n",
      "Epoch: 37, Batch number: 64, Loss: 3735.38330078125\n",
      "Epoch: 39, Batch number: 12, Loss: 3518.749755859375\n",
      "Epoch: 40, Batch number: 36, Loss: 3500.171630859375\n",
      "Epoch: 41, Batch number: 60, Loss: 3810.457275390625\n",
      "Epoch: 43, Batch number: 8, Loss: 3523.8095703125\n",
      "Epoch: 44, Batch number: 32, Loss: 3608.58154296875\n",
      "Epoch: 45, Batch number: 56, Loss: 3544.763916015625\n",
      "Epoch: 47, Batch number: 4, Loss: 3652.326171875\n",
      "Epoch: 48, Batch number: 28, Loss: 3447.568359375\n",
      "Epoch: 49, Batch number: 52, Loss: 3621.3134765625\n",
      "Epoch: 51, Batch number: 0, Loss: 3377.603759765625\n",
      "Epoch: 52, Batch number: 24, Loss: 3348.27587890625\n",
      "Epoch: 53, Batch number: 48, Loss: 3364.287109375\n",
      "Epoch: 54, Batch number: 72, Loss: 3520.916748046875\n",
      "Epoch: 56, Batch number: 20, Loss: 3394.830078125\n",
      "Epoch: 57, Batch number: 44, Loss: 3384.789794921875\n",
      "Epoch: 58, Batch number: 68, Loss: 3312.347412109375\n",
      "Epoch: 60, Batch number: 16, Loss: 3253.27734375\n",
      "Epoch: 61, Batch number: 40, Loss: 3541.429443359375\n",
      "Epoch: 62, Batch number: 64, Loss: 3400.103271484375\n",
      "Epoch: 64, Batch number: 12, Loss: 3356.4091796875\n",
      "Epoch: 65, Batch number: 36, Loss: 3247.37255859375\n",
      "Epoch: 66, Batch number: 60, Loss: 3296.46044921875\n",
      "Epoch: 68, Batch number: 8, Loss: 3231.119384765625\n",
      "Epoch: 69, Batch number: 32, Loss: 3396.270751953125\n",
      "Epoch: 70, Batch number: 56, Loss: 3361.391357421875\n",
      "Epoch: 72, Batch number: 4, Loss: 3321.180419921875\n",
      "Epoch: 73, Batch number: 28, Loss: 3156.0517578125\n",
      "Epoch: 74, Batch number: 52, Loss: 3327.78125\n",
      "Epoch: 76, Batch number: 0, Loss: 3179.82861328125\n",
      "Epoch: 77, Batch number: 24, Loss: 3328.593017578125\n",
      "Epoch: 78, Batch number: 48, Loss: 3357.62158203125\n",
      "Epoch: 79, Batch number: 72, Loss: 3144.471435546875\n",
      "Epoch: 81, Batch number: 20, Loss: 3066.63720703125\n",
      "Epoch: 82, Batch number: 44, Loss: 3257.818603515625\n",
      "Epoch: 83, Batch number: 68, Loss: 3487.3994140625\n",
      "Epoch: 85, Batch number: 16, Loss: 3081.32373046875\n",
      "Epoch: 86, Batch number: 40, Loss: 3390.355224609375\n",
      "Epoch: 87, Batch number: 64, Loss: 3320.853515625\n",
      "Epoch: 89, Batch number: 12, Loss: 3232.50830078125\n",
      "Epoch: 90, Batch number: 36, Loss: 3277.765625\n",
      "Epoch: 91, Batch number: 60, Loss: 3258.289306640625\n",
      "Epoch: 93, Batch number: 8, Loss: 3228.033935546875\n",
      "Epoch: 94, Batch number: 32, Loss: 3296.134033203125\n",
      "Epoch: 95, Batch number: 56, Loss: 3305.197265625\n",
      "Epoch: 97, Batch number: 4, Loss: 3189.775390625\n",
      "Epoch: 98, Batch number: 28, Loss: 3180.261962890625\n",
      "Epoch: 99, Batch number: 52, Loss: 3232.591552734375\n",
      "Epoch: 101, Batch number: 0, Loss: 3255.162841796875\n",
      "Epoch: 102, Batch number: 24, Loss: 3222.678466796875\n",
      "Epoch: 103, Batch number: 48, Loss: 3234.738037109375\n",
      "Epoch: 104, Batch number: 72, Loss: 3304.804443359375\n",
      "Epoch: 106, Batch number: 20, Loss: 3131.21923828125\n",
      "Epoch: 107, Batch number: 44, Loss: 3197.342529296875\n",
      "Epoch: 108, Batch number: 68, Loss: 3289.9990234375\n",
      "Epoch: 110, Batch number: 16, Loss: 3035.100341796875\n",
      "Epoch: 111, Batch number: 40, Loss: 3258.271728515625\n",
      "Epoch: 112, Batch number: 64, Loss: 3291.62939453125\n",
      "Epoch: 114, Batch number: 12, Loss: 3290.1708984375\n",
      "Epoch: 115, Batch number: 36, Loss: 3155.060791015625\n",
      "Epoch: 116, Batch number: 60, Loss: 3244.26611328125\n",
      "Epoch: 118, Batch number: 8, Loss: 3175.04931640625\n",
      "Epoch: 119, Batch number: 32, Loss: 3242.9599609375\n",
      "Epoch: 120, Batch number: 56, Loss: 3193.78076171875\n",
      "Epoch: 122, Batch number: 4, Loss: 3109.991455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123, Batch number: 28, Loss: 3143.684814453125\n",
      "Epoch: 124, Batch number: 52, Loss: 3242.466064453125\n",
      "Epoch: 126, Batch number: 0, Loss: 3144.481201171875\n",
      "Epoch: 127, Batch number: 24, Loss: 3113.004150390625\n",
      "Epoch: 128, Batch number: 48, Loss: 3226.072265625\n",
      "Epoch: 129, Batch number: 72, Loss: 3191.55615234375\n",
      "Epoch: 131, Batch number: 20, Loss: 3134.431884765625\n",
      "Epoch: 132, Batch number: 44, Loss: 3241.7861328125\n",
      "Epoch: 133, Batch number: 68, Loss: 3306.25\n",
      "Epoch: 135, Batch number: 16, Loss: 3122.4892578125\n",
      "Epoch: 136, Batch number: 40, Loss: 3262.59375\n",
      "Epoch: 137, Batch number: 64, Loss: 3340.421875\n",
      "Epoch: 139, Batch number: 12, Loss: 3175.990234375\n",
      "Epoch: 140, Batch number: 36, Loss: 3207.231689453125\n",
      "Epoch: 141, Batch number: 60, Loss: 3318.614501953125\n",
      "Epoch: 143, Batch number: 8, Loss: 3277.122314453125\n",
      "Epoch: 144, Batch number: 32, Loss: 3329.23046875\n",
      "Epoch: 145, Batch number: 56, Loss: 3266.40234375\n",
      "Epoch: 147, Batch number: 4, Loss: 3115.437255859375\n",
      "Epoch: 148, Batch number: 28, Loss: 3305.111328125\n",
      "Epoch: 149, Batch number: 52, Loss: 3406.9150390625\n",
      "Epoch: 151, Batch number: 0, Loss: 3157.234130859375\n",
      "Epoch: 152, Batch number: 24, Loss: 3162.2529296875\n",
      "Epoch: 153, Batch number: 48, Loss: 3288.369140625\n",
      "Epoch: 154, Batch number: 72, Loss: 3313.357177734375\n",
      "Epoch: 156, Batch number: 20, Loss: 3171.0556640625\n",
      "Epoch: 157, Batch number: 44, Loss: 3210.92919921875\n",
      "Epoch: 158, Batch number: 68, Loss: 3345.44091796875\n",
      "Epoch: 160, Batch number: 16, Loss: 3170.120361328125\n",
      "Epoch: 161, Batch number: 40, Loss: 3267.134765625\n",
      "Epoch: 162, Batch number: 64, Loss: 3207.571533203125\n",
      "Epoch: 164, Batch number: 12, Loss: 3091.4912109375\n",
      "Epoch: 165, Batch number: 36, Loss: 3143.79150390625\n",
      "Epoch: 166, Batch number: 60, Loss: 3270.575439453125\n",
      "Epoch: 168, Batch number: 8, Loss: 3266.905517578125\n",
      "Epoch: 169, Batch number: 32, Loss: 3207.40966796875\n",
      "Epoch: 170, Batch number: 56, Loss: 3186.370361328125\n",
      "Epoch: 172, Batch number: 4, Loss: 3189.141357421875\n",
      "Epoch: 173, Batch number: 28, Loss: 3261.574951171875\n",
      "Epoch: 174, Batch number: 52, Loss: 3076.64697265625\n",
      "Epoch: 176, Batch number: 0, Loss: 3161.37255859375\n",
      "Epoch: 177, Batch number: 24, Loss: 3250.4697265625\n",
      "Epoch: 178, Batch number: 48, Loss: 3213.660888671875\n",
      "Epoch: 179, Batch number: 72, Loss: 3267.9208984375\n",
      "Epoch: 181, Batch number: 20, Loss: 3291.20947265625\n",
      "Epoch: 182, Batch number: 44, Loss: 3259.92333984375\n",
      "Epoch: 183, Batch number: 68, Loss: 3195.5302734375\n",
      "Epoch: 185, Batch number: 16, Loss: 3068.3916015625\n",
      "Epoch: 186, Batch number: 40, Loss: 3204.03564453125\n",
      "Epoch: 187, Batch number: 64, Loss: 3241.497802734375\n",
      "Epoch: 189, Batch number: 12, Loss: 3168.06005859375\n",
      "Epoch: 190, Batch number: 36, Loss: 3140.371826171875\n",
      "Epoch: 191, Batch number: 60, Loss: 3306.28662109375\n",
      "Epoch: 193, Batch number: 8, Loss: 3148.241943359375\n",
      "Epoch: 194, Batch number: 32, Loss: 3218.5205078125\n",
      "Epoch: 195, Batch number: 56, Loss: 3272.90625\n",
      "Epoch: 197, Batch number: 4, Loss: 3111.2998046875\n",
      "Epoch: 198, Batch number: 28, Loss: 3208.218994140625\n",
      "Epoch: 199, Batch number: 52, Loss: 3284.135498046875\n",
      "Epoch: 201, Batch number: 0, Loss: 3264.00830078125\n",
      "Epoch: 202, Batch number: 24, Loss: 3234.991455078125\n",
      "Epoch: 203, Batch number: 48, Loss: 3221.91748046875\n",
      "Epoch: 204, Batch number: 72, Loss: 3288.3935546875\n",
      "Epoch: 206, Batch number: 20, Loss: 3247.17431640625\n",
      "Epoch: 207, Batch number: 44, Loss: 3242.9287109375\n",
      "Epoch: 208, Batch number: 68, Loss: 3281.41015625\n",
      "Epoch: 210, Batch number: 16, Loss: 3258.903564453125\n",
      "Epoch: 211, Batch number: 40, Loss: 3205.483642578125\n",
      "Epoch: 212, Batch number: 64, Loss: 3298.62109375\n",
      "Epoch: 214, Batch number: 12, Loss: 3140.147705078125\n",
      "Epoch: 215, Batch number: 36, Loss: 3226.38720703125\n",
      "Epoch: 216, Batch number: 60, Loss: 3223.821533203125\n",
      "Epoch: 218, Batch number: 8, Loss: 3125.61279296875\n",
      "Epoch: 219, Batch number: 32, Loss: 3264.2783203125\n",
      "Epoch: 220, Batch number: 56, Loss: 3194.08154296875\n",
      "Epoch: 222, Batch number: 4, Loss: 3102.859375\n",
      "Epoch: 223, Batch number: 28, Loss: 3106.823974609375\n",
      "Epoch: 224, Batch number: 52, Loss: 3294.7392578125\n",
      "Epoch: 226, Batch number: 0, Loss: 3239.013427734375\n",
      "Epoch: 227, Batch number: 24, Loss: 3225.548583984375\n",
      "Epoch: 228, Batch number: 48, Loss: 3237.93994140625\n",
      "Epoch: 229, Batch number: 72, Loss: 3208.590087890625\n",
      "Epoch: 231, Batch number: 20, Loss: 3350.888916015625\n",
      "Epoch: 232, Batch number: 44, Loss: 3127.43505859375\n",
      "Epoch: 233, Batch number: 68, Loss: 3002.163330078125\n",
      "Epoch: 235, Batch number: 16, Loss: 3256.582763671875\n",
      "Epoch: 236, Batch number: 40, Loss: 3195.52001953125\n",
      "Epoch: 237, Batch number: 64, Loss: 3256.207763671875\n",
      "Epoch: 239, Batch number: 12, Loss: 3151.941650390625\n",
      "Epoch: 240, Batch number: 36, Loss: 3218.5966796875\n",
      "Epoch: 241, Batch number: 60, Loss: 3375.3115234375\n",
      "Epoch: 243, Batch number: 8, Loss: 3121.578857421875\n",
      "Epoch: 244, Batch number: 32, Loss: 3137.021728515625\n",
      "Epoch: 245, Batch number: 56, Loss: 3188.7744140625\n",
      "Epoch: 247, Batch number: 4, Loss: 3111.82958984375\n",
      "Epoch: 248, Batch number: 28, Loss: 3151.126953125\n",
      "Epoch: 249, Batch number: 52, Loss: 3363.94091796875\n",
      "Epoch: 251, Batch number: 0, Loss: 3230.049560546875\n",
      "Epoch: 252, Batch number: 24, Loss: 3043.709716796875\n",
      "Epoch: 253, Batch number: 48, Loss: 3186.083251953125\n",
      "Epoch: 254, Batch number: 72, Loss: 3235.571044921875\n",
      "Epoch: 256, Batch number: 20, Loss: 3262.986083984375\n",
      "Epoch: 257, Batch number: 44, Loss: 3232.322265625\n",
      "Epoch: 258, Batch number: 68, Loss: 3395.041259765625\n",
      "Epoch: 260, Batch number: 16, Loss: 3107.511474609375\n",
      "Epoch: 261, Batch number: 40, Loss: 3284.45556640625\n",
      "Epoch: 262, Batch number: 64, Loss: 3271.912109375\n",
      "Epoch: 264, Batch number: 12, Loss: 2967.059814453125\n",
      "Epoch: 265, Batch number: 36, Loss: 3327.69287109375\n",
      "Epoch: 266, Batch number: 60, Loss: 3342.76806640625\n",
      "Epoch: 268, Batch number: 8, Loss: 3151.038818359375\n",
      "Epoch: 269, Batch number: 32, Loss: 3340.76318359375\n",
      "Epoch: 270, Batch number: 56, Loss: 3225.71630859375\n",
      "Epoch: 272, Batch number: 4, Loss: 3065.00439453125\n",
      "Epoch: 273, Batch number: 28, Loss: 3310.92724609375\n",
      "Epoch: 274, Batch number: 52, Loss: 3351.45263671875\n",
      "Epoch: 276, Batch number: 0, Loss: 3125.291015625\n",
      "Epoch: 277, Batch number: 24, Loss: 3189.96630859375\n",
      "Epoch: 278, Batch number: 48, Loss: 3318.037109375\n",
      "Epoch: 279, Batch number: 72, Loss: 3298.318359375\n",
      "Epoch: 281, Batch number: 20, Loss: 3338.927001953125\n",
      "Epoch: 282, Batch number: 44, Loss: 3345.089111328125\n",
      "Epoch: 283, Batch number: 68, Loss: 3347.03125\n",
      "Epoch: 285, Batch number: 16, Loss: 3044.37646484375\n",
      "Epoch: 286, Batch number: 40, Loss: 3156.171875\n",
      "Epoch: 287, Batch number: 64, Loss: 3201.007080078125\n",
      "Epoch: 289, Batch number: 12, Loss: 3176.15380859375\n",
      "Epoch: 290, Batch number: 36, Loss: 3185.810546875\n",
      "Epoch: 291, Batch number: 60, Loss: 3313.756591796875\n",
      "Epoch: 293, Batch number: 8, Loss: 3066.50048828125\n",
      "Epoch: 294, Batch number: 32, Loss: 3283.603759765625\n",
      "Epoch: 295, Batch number: 56, Loss: 3323.64404296875\n",
      "Epoch: 297, Batch number: 4, Loss: 3257.7900390625\n",
      "Epoch: 298, Batch number: 28, Loss: 3083.593994140625\n",
      "Epoch: 299, Batch number: 52, Loss: 3230.6337890625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8174.78564453125\n",
      "Epoch: 2, Batch number: 24, Loss: 7324.8974609375\n",
      "Epoch: 3, Batch number: 48, Loss: 6648.30859375\n",
      "Epoch: 4, Batch number: 72, Loss: 6320.22265625\n",
      "Epoch: 6, Batch number: 20, Loss: 5872.005859375\n",
      "Epoch: 7, Batch number: 44, Loss: 5625.7958984375\n",
      "Epoch: 8, Batch number: 68, Loss: 5404.63818359375\n",
      "Epoch: 10, Batch number: 16, Loss: 4995.0869140625\n",
      "Epoch: 11, Batch number: 40, Loss: 4775.279296875\n",
      "Epoch: 12, Batch number: 64, Loss: 4801.029296875\n",
      "Epoch: 14, Batch number: 12, Loss: 4352.00146484375\n",
      "Epoch: 15, Batch number: 36, Loss: 4287.4541015625\n",
      "Epoch: 16, Batch number: 60, Loss: 4432.95556640625\n",
      "Epoch: 18, Batch number: 8, Loss: 4105.8330078125\n",
      "Epoch: 19, Batch number: 32, Loss: 4107.009765625\n",
      "Epoch: 20, Batch number: 56, Loss: 3983.679931640625\n",
      "Epoch: 22, Batch number: 4, Loss: 3845.5263671875\n",
      "Epoch: 23, Batch number: 28, Loss: 3812.69482421875\n",
      "Epoch: 24, Batch number: 52, Loss: 3780.5537109375\n",
      "Epoch: 26, Batch number: 0, Loss: 3569.552001953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Batch number: 24, Loss: 3652.281982421875\n",
      "Epoch: 28, Batch number: 48, Loss: 3608.4140625\n",
      "Epoch: 29, Batch number: 72, Loss: 3796.44921875\n",
      "Epoch: 31, Batch number: 20, Loss: 3445.804931640625\n",
      "Epoch: 32, Batch number: 44, Loss: 3445.406982421875\n",
      "Epoch: 33, Batch number: 68, Loss: 3570.217041015625\n",
      "Epoch: 35, Batch number: 16, Loss: 3487.60107421875\n",
      "Epoch: 36, Batch number: 40, Loss: 3443.462646484375\n",
      "Epoch: 37, Batch number: 64, Loss: 3486.103515625\n",
      "Epoch: 39, Batch number: 12, Loss: 3360.364990234375\n",
      "Epoch: 40, Batch number: 36, Loss: 3443.603271484375\n",
      "Epoch: 41, Batch number: 60, Loss: 3572.364501953125\n",
      "Epoch: 43, Batch number: 8, Loss: 3299.8330078125\n",
      "Epoch: 44, Batch number: 32, Loss: 3376.684814453125\n",
      "Epoch: 45, Batch number: 56, Loss: 3358.038818359375\n",
      "Epoch: 47, Batch number: 4, Loss: 3258.233642578125\n",
      "Epoch: 48, Batch number: 28, Loss: 3376.373291015625\n",
      "Epoch: 49, Batch number: 52, Loss: 3240.24169921875\n",
      "Epoch: 51, Batch number: 0, Loss: 3270.810546875\n",
      "Epoch: 52, Batch number: 24, Loss: 3217.797119140625\n",
      "Epoch: 53, Batch number: 48, Loss: 3312.1435546875\n",
      "Epoch: 54, Batch number: 72, Loss: 3369.02099609375\n",
      "Epoch: 56, Batch number: 20, Loss: 3228.855712890625\n",
      "Epoch: 57, Batch number: 44, Loss: 3224.0302734375\n",
      "Epoch: 58, Batch number: 68, Loss: 3251.679931640625\n",
      "Epoch: 60, Batch number: 16, Loss: 3222.708251953125\n",
      "Epoch: 61, Batch number: 40, Loss: 3331.829345703125\n",
      "Epoch: 62, Batch number: 64, Loss: 3342.136474609375\n",
      "Epoch: 64, Batch number: 12, Loss: 3136.332763671875\n",
      "Epoch: 65, Batch number: 36, Loss: 3335.092529296875\n",
      "Epoch: 66, Batch number: 60, Loss: 3301.76171875\n",
      "Epoch: 68, Batch number: 8, Loss: 3151.42431640625\n",
      "Epoch: 69, Batch number: 32, Loss: 3149.314208984375\n",
      "Epoch: 70, Batch number: 56, Loss: 3160.619873046875\n",
      "Epoch: 72, Batch number: 4, Loss: 3158.00927734375\n",
      "Epoch: 73, Batch number: 28, Loss: 3181.219482421875\n",
      "Epoch: 74, Batch number: 52, Loss: 3385.476806640625\n",
      "Epoch: 76, Batch number: 0, Loss: 3157.06591796875\n",
      "Epoch: 77, Batch number: 24, Loss: 3174.403564453125\n",
      "Epoch: 78, Batch number: 48, Loss: 3341.77978515625\n",
      "Epoch: 79, Batch number: 72, Loss: 3413.6669921875\n",
      "Epoch: 81, Batch number: 20, Loss: 3195.4677734375\n",
      "Epoch: 82, Batch number: 44, Loss: 3293.27099609375\n",
      "Epoch: 83, Batch number: 68, Loss: 3345.851318359375\n",
      "Epoch: 85, Batch number: 16, Loss: 3286.18310546875\n",
      "Epoch: 86, Batch number: 40, Loss: 3388.968505859375\n",
      "Epoch: 87, Batch number: 64, Loss: 3144.8466796875\n",
      "Epoch: 89, Batch number: 12, Loss: 3132.63037109375\n",
      "Epoch: 90, Batch number: 36, Loss: 3303.39501953125\n",
      "Epoch: 91, Batch number: 60, Loss: 3297.337646484375\n",
      "Epoch: 93, Batch number: 8, Loss: 3198.168701171875\n",
      "Epoch: 94, Batch number: 32, Loss: 3234.54248046875\n",
      "Epoch: 95, Batch number: 56, Loss: 3174.13671875\n",
      "Epoch: 97, Batch number: 4, Loss: 3094.60693359375\n",
      "Epoch: 98, Batch number: 28, Loss: 3076.522216796875\n",
      "Epoch: 99, Batch number: 52, Loss: 3302.925537109375\n",
      "Epoch: 101, Batch number: 0, Loss: 3078.10791015625\n",
      "Epoch: 102, Batch number: 24, Loss: 3386.142822265625\n",
      "Epoch: 103, Batch number: 48, Loss: 3305.928955078125\n",
      "Epoch: 104, Batch number: 72, Loss: 3252.269775390625\n",
      "Epoch: 106, Batch number: 20, Loss: 3102.21728515625\n",
      "Epoch: 107, Batch number: 44, Loss: 3315.221435546875\n",
      "Epoch: 108, Batch number: 68, Loss: 3197.03125\n",
      "Epoch: 110, Batch number: 16, Loss: 3230.175537109375\n",
      "Epoch: 111, Batch number: 40, Loss: 3196.543701171875\n",
      "Epoch: 112, Batch number: 64, Loss: 3299.101318359375\n",
      "Epoch: 114, Batch number: 12, Loss: 3176.608154296875\n",
      "Epoch: 115, Batch number: 36, Loss: 3337.112060546875\n",
      "Epoch: 116, Batch number: 60, Loss: 3213.55712890625\n",
      "Epoch: 118, Batch number: 8, Loss: 3089.735595703125\n",
      "Epoch: 119, Batch number: 32, Loss: 3212.4306640625\n",
      "Epoch: 120, Batch number: 56, Loss: 3265.13232421875\n",
      "Epoch: 122, Batch number: 4, Loss: 3224.87841796875\n",
      "Epoch: 123, Batch number: 28, Loss: 3300.727783203125\n",
      "Epoch: 124, Batch number: 52, Loss: 3270.26513671875\n",
      "Epoch: 126, Batch number: 0, Loss: 3225.98779296875\n",
      "Epoch: 127, Batch number: 24, Loss: 3360.15771484375\n",
      "Epoch: 128, Batch number: 48, Loss: 3192.9775390625\n",
      "Epoch: 129, Batch number: 72, Loss: 3287.282958984375\n",
      "Epoch: 131, Batch number: 20, Loss: 3208.025390625\n",
      "Epoch: 132, Batch number: 44, Loss: 3302.4091796875\n",
      "Epoch: 133, Batch number: 68, Loss: 3413.385986328125\n",
      "Epoch: 135, Batch number: 16, Loss: 3099.58447265625\n",
      "Epoch: 136, Batch number: 40, Loss: 3165.645263671875\n",
      "Epoch: 137, Batch number: 64, Loss: 3200.6708984375\n",
      "Epoch: 139, Batch number: 12, Loss: 2998.247802734375\n",
      "Epoch: 140, Batch number: 36, Loss: 3158.7138671875\n",
      "Epoch: 141, Batch number: 60, Loss: 3315.515869140625\n",
      "Epoch: 143, Batch number: 8, Loss: 3080.911865234375\n",
      "Epoch: 144, Batch number: 32, Loss: 3272.53759765625\n",
      "Epoch: 145, Batch number: 56, Loss: 3200.06494140625\n",
      "Epoch: 147, Batch number: 4, Loss: 3233.468017578125\n",
      "Epoch: 148, Batch number: 28, Loss: 3184.544189453125\n",
      "Epoch: 149, Batch number: 52, Loss: 3345.025146484375\n",
      "Epoch: 151, Batch number: 0, Loss: 3221.482177734375\n",
      "Epoch: 152, Batch number: 24, Loss: 3241.336669921875\n",
      "Epoch: 153, Batch number: 48, Loss: 3231.27294921875\n",
      "Epoch: 154, Batch number: 72, Loss: 3283.978515625\n",
      "Epoch: 156, Batch number: 20, Loss: 3308.286865234375\n",
      "Epoch: 157, Batch number: 44, Loss: 3210.821044921875\n",
      "Epoch: 158, Batch number: 68, Loss: 3406.607421875\n",
      "Epoch: 160, Batch number: 16, Loss: 3156.352294921875\n",
      "Epoch: 161, Batch number: 40, Loss: 3175.55224609375\n",
      "Epoch: 162, Batch number: 64, Loss: 3270.203857421875\n",
      "Epoch: 164, Batch number: 12, Loss: 3317.565673828125\n",
      "Epoch: 165, Batch number: 36, Loss: 3113.137939453125\n",
      "Epoch: 166, Batch number: 60, Loss: 3306.39111328125\n",
      "Epoch: 168, Batch number: 8, Loss: 3118.837890625\n",
      "Epoch: 169, Batch number: 32, Loss: 3172.160400390625\n",
      "Epoch: 170, Batch number: 56, Loss: 3435.050048828125\n",
      "Epoch: 172, Batch number: 4, Loss: 3070.507080078125\n",
      "Epoch: 173, Batch number: 28, Loss: 3232.395263671875\n",
      "Epoch: 174, Batch number: 52, Loss: 3306.7763671875\n",
      "Epoch: 176, Batch number: 0, Loss: 3121.91259765625\n",
      "Epoch: 177, Batch number: 24, Loss: 3297.424560546875\n",
      "Epoch: 178, Batch number: 48, Loss: 3223.1865234375\n",
      "Epoch: 179, Batch number: 72, Loss: 3190.7060546875\n",
      "Epoch: 181, Batch number: 20, Loss: 3238.123779296875\n",
      "Epoch: 182, Batch number: 44, Loss: 3143.16455078125\n",
      "Epoch: 183, Batch number: 68, Loss: 3261.041748046875\n",
      "Epoch: 185, Batch number: 16, Loss: 3111.504150390625\n",
      "Epoch: 186, Batch number: 40, Loss: 3252.282958984375\n",
      "Epoch: 187, Batch number: 64, Loss: 3250.689208984375\n",
      "Epoch: 189, Batch number: 12, Loss: 3225.619384765625\n",
      "Epoch: 190, Batch number: 36, Loss: 3134.69482421875\n",
      "Epoch: 191, Batch number: 60, Loss: 3068.45654296875\n",
      "Epoch: 193, Batch number: 8, Loss: 3198.53466796875\n",
      "Epoch: 194, Batch number: 32, Loss: 3345.333984375\n",
      "Epoch: 195, Batch number: 56, Loss: 3221.26171875\n",
      "Epoch: 197, Batch number: 4, Loss: 3213.802001953125\n",
      "Epoch: 198, Batch number: 28, Loss: 3171.697021484375\n",
      "Epoch: 199, Batch number: 52, Loss: 3267.10888671875\n",
      "Epoch: 201, Batch number: 0, Loss: 3125.972900390625\n",
      "Epoch: 202, Batch number: 24, Loss: 3146.70458984375\n",
      "Epoch: 203, Batch number: 48, Loss: 3280.25244140625\n",
      "Epoch: 204, Batch number: 72, Loss: 3280.427001953125\n",
      "Epoch: 206, Batch number: 20, Loss: 3185.2880859375\n",
      "Epoch: 207, Batch number: 44, Loss: 3279.7265625\n",
      "Epoch: 208, Batch number: 68, Loss: 3198.501708984375\n",
      "Epoch: 210, Batch number: 16, Loss: 3048.72216796875\n",
      "Epoch: 211, Batch number: 40, Loss: 3175.25537109375\n",
      "Epoch: 212, Batch number: 64, Loss: 3192.171875\n",
      "Epoch: 214, Batch number: 12, Loss: 3188.298095703125\n",
      "Epoch: 215, Batch number: 36, Loss: 3191.647216796875\n",
      "Epoch: 216, Batch number: 60, Loss: 3172.81591796875\n",
      "Epoch: 218, Batch number: 8, Loss: 3023.651123046875\n",
      "Epoch: 219, Batch number: 32, Loss: 3240.572509765625\n",
      "Epoch: 220, Batch number: 56, Loss: 3201.843505859375\n",
      "Epoch: 222, Batch number: 4, Loss: 3181.6708984375\n",
      "Epoch: 223, Batch number: 28, Loss: 3126.25390625\n",
      "Epoch: 224, Batch number: 52, Loss: 3005.505126953125\n",
      "Epoch: 226, Batch number: 0, Loss: 3087.36376953125\n",
      "Epoch: 227, Batch number: 24, Loss: 3326.9287109375\n",
      "Epoch: 228, Batch number: 48, Loss: 3128.9482421875\n",
      "Epoch: 229, Batch number: 72, Loss: 3344.961181640625\n",
      "Epoch: 231, Batch number: 20, Loss: 3220.503173828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 232, Batch number: 44, Loss: 3238.28955078125\n",
      "Epoch: 233, Batch number: 68, Loss: 3207.71728515625\n",
      "Epoch: 235, Batch number: 16, Loss: 3133.994873046875\n",
      "Epoch: 236, Batch number: 40, Loss: 3215.276123046875\n",
      "Epoch: 237, Batch number: 64, Loss: 3363.839111328125\n",
      "Epoch: 239, Batch number: 12, Loss: 3158.80224609375\n",
      "Epoch: 240, Batch number: 36, Loss: 3205.058349609375\n",
      "Epoch: 241, Batch number: 60, Loss: 3321.3828125\n",
      "Epoch: 243, Batch number: 8, Loss: 2993.469970703125\n",
      "Epoch: 244, Batch number: 32, Loss: 3267.669189453125\n",
      "Epoch: 245, Batch number: 56, Loss: 3237.753173828125\n",
      "Epoch: 247, Batch number: 4, Loss: 3154.94482421875\n",
      "Epoch: 248, Batch number: 28, Loss: 3248.494873046875\n",
      "Epoch: 249, Batch number: 52, Loss: 3178.606689453125\n",
      "Epoch: 251, Batch number: 0, Loss: 3178.366943359375\n",
      "Epoch: 252, Batch number: 24, Loss: 3240.0927734375\n",
      "Epoch: 253, Batch number: 48, Loss: 3249.34814453125\n",
      "Epoch: 254, Batch number: 72, Loss: 3187.884033203125\n",
      "Epoch: 256, Batch number: 20, Loss: 3158.229736328125\n",
      "Epoch: 257, Batch number: 44, Loss: 3175.50048828125\n",
      "Epoch: 258, Batch number: 68, Loss: 3374.90185546875\n",
      "Epoch: 260, Batch number: 16, Loss: 3166.540283203125\n",
      "Epoch: 261, Batch number: 40, Loss: 3045.752197265625\n",
      "Epoch: 262, Batch number: 64, Loss: 3237.9931640625\n",
      "Epoch: 264, Batch number: 12, Loss: 3319.262451171875\n",
      "Epoch: 265, Batch number: 36, Loss: 3301.47265625\n",
      "Epoch: 266, Batch number: 60, Loss: 3350.478759765625\n",
      "Epoch: 268, Batch number: 8, Loss: 3100.221923828125\n",
      "Epoch: 269, Batch number: 32, Loss: 3190.564453125\n",
      "Epoch: 270, Batch number: 56, Loss: 3308.36083984375\n",
      "Epoch: 272, Batch number: 4, Loss: 3248.23193359375\n",
      "Epoch: 273, Batch number: 28, Loss: 3147.514404296875\n",
      "Epoch: 274, Batch number: 52, Loss: 3169.32275390625\n",
      "Epoch: 276, Batch number: 0, Loss: 3138.8544921875\n",
      "Epoch: 277, Batch number: 24, Loss: 3165.85205078125\n",
      "Epoch: 278, Batch number: 48, Loss: 3156.988525390625\n",
      "Epoch: 279, Batch number: 72, Loss: 3261.47705078125\n",
      "Epoch: 281, Batch number: 20, Loss: 3441.585693359375\n",
      "Epoch: 282, Batch number: 44, Loss: 3236.77783203125\n",
      "Epoch: 283, Batch number: 68, Loss: 3477.765869140625\n",
      "Epoch: 285, Batch number: 16, Loss: 3137.071533203125\n",
      "Epoch: 286, Batch number: 40, Loss: 3186.312744140625\n",
      "Epoch: 287, Batch number: 64, Loss: 3191.51318359375\n",
      "Epoch: 289, Batch number: 12, Loss: 3230.37890625\n",
      "Epoch: 290, Batch number: 36, Loss: 3195.881103515625\n",
      "Epoch: 291, Batch number: 60, Loss: 3382.72314453125\n",
      "Epoch: 293, Batch number: 8, Loss: 2957.813232421875\n",
      "Epoch: 294, Batch number: 32, Loss: 3090.07373046875\n",
      "Epoch: 295, Batch number: 56, Loss: 3246.536865234375\n",
      "Epoch: 297, Batch number: 4, Loss: 3136.210205078125\n",
      "Epoch: 298, Batch number: 28, Loss: 3265.353515625\n",
      "Epoch: 299, Batch number: 52, Loss: 3182.66845703125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 8041.49951171875\n",
      "Epoch: 2, Batch number: 24, Loss: 7034.95166015625\n",
      "Epoch: 3, Batch number: 48, Loss: 6569.00830078125\n",
      "Epoch: 4, Batch number: 72, Loss: 5999.16650390625\n",
      "Epoch: 6, Batch number: 20, Loss: 5572.048828125\n",
      "Epoch: 7, Batch number: 44, Loss: 5212.9453125\n",
      "Epoch: 8, Batch number: 68, Loss: 5019.1708984375\n",
      "Epoch: 10, Batch number: 16, Loss: 4749.90869140625\n",
      "Epoch: 11, Batch number: 40, Loss: 4743.0908203125\n",
      "Epoch: 12, Batch number: 64, Loss: 4292.06787109375\n",
      "Epoch: 14, Batch number: 12, Loss: 4158.3984375\n",
      "Epoch: 15, Batch number: 36, Loss: 4235.89501953125\n",
      "Epoch: 16, Batch number: 60, Loss: 4000.36328125\n",
      "Epoch: 18, Batch number: 8, Loss: 3847.059814453125\n",
      "Epoch: 19, Batch number: 32, Loss: 3847.01318359375\n",
      "Epoch: 20, Batch number: 56, Loss: 3822.660400390625\n",
      "Epoch: 22, Batch number: 4, Loss: 3570.1103515625\n",
      "Epoch: 23, Batch number: 28, Loss: 3514.341796875\n",
      "Epoch: 24, Batch number: 52, Loss: 3653.136962890625\n",
      "Epoch: 26, Batch number: 0, Loss: 3594.429443359375\n",
      "Epoch: 27, Batch number: 24, Loss: 3308.660400390625\n",
      "Epoch: 28, Batch number: 48, Loss: 3472.130615234375\n",
      "Epoch: 29, Batch number: 72, Loss: 3484.02099609375\n",
      "Epoch: 31, Batch number: 20, Loss: 3345.483154296875\n",
      "Epoch: 32, Batch number: 44, Loss: 3504.5234375\n",
      "Epoch: 33, Batch number: 68, Loss: 3377.780517578125\n",
      "Epoch: 35, Batch number: 16, Loss: 3372.750244140625\n",
      "Epoch: 36, Batch number: 40, Loss: 3362.181396484375\n",
      "Epoch: 37, Batch number: 64, Loss: 3407.166015625\n",
      "Epoch: 39, Batch number: 12, Loss: 3310.094482421875\n",
      "Epoch: 40, Batch number: 36, Loss: 3322.636474609375\n",
      "Epoch: 41, Batch number: 60, Loss: 3441.916748046875\n",
      "Epoch: 43, Batch number: 8, Loss: 3331.4248046875\n",
      "Epoch: 44, Batch number: 32, Loss: 3411.093505859375\n",
      "Epoch: 45, Batch number: 56, Loss: 3424.03076171875\n",
      "Epoch: 47, Batch number: 4, Loss: 3299.056884765625\n",
      "Epoch: 48, Batch number: 28, Loss: 3100.77880859375\n",
      "Epoch: 49, Batch number: 52, Loss: 3382.640625\n",
      "Epoch: 51, Batch number: 0, Loss: 3202.8154296875\n",
      "Epoch: 52, Batch number: 24, Loss: 3336.327392578125\n",
      "Epoch: 53, Batch number: 48, Loss: 3397.78955078125\n",
      "Epoch: 54, Batch number: 72, Loss: 3445.66943359375\n",
      "Epoch: 56, Batch number: 20, Loss: 3278.989990234375\n",
      "Epoch: 57, Batch number: 44, Loss: 3402.329833984375\n",
      "Epoch: 58, Batch number: 68, Loss: 3309.887451171875\n",
      "Epoch: 60, Batch number: 16, Loss: 3197.49072265625\n",
      "Epoch: 61, Batch number: 40, Loss: 3257.564208984375\n",
      "Epoch: 62, Batch number: 64, Loss: 3497.664306640625\n",
      "Epoch: 64, Batch number: 12, Loss: 3326.1484375\n",
      "Epoch: 65, Batch number: 36, Loss: 3250.0283203125\n",
      "Epoch: 66, Batch number: 60, Loss: 3284.391357421875\n",
      "Epoch: 68, Batch number: 8, Loss: 3043.779052734375\n",
      "Epoch: 69, Batch number: 32, Loss: 3184.358154296875\n",
      "Epoch: 70, Batch number: 56, Loss: 3182.732177734375\n",
      "Epoch: 72, Batch number: 4, Loss: 3096.437255859375\n",
      "Epoch: 73, Batch number: 28, Loss: 3180.348876953125\n",
      "Epoch: 74, Batch number: 52, Loss: 3262.507080078125\n",
      "Epoch: 76, Batch number: 0, Loss: 3222.946044921875\n",
      "Epoch: 77, Batch number: 24, Loss: 3287.380126953125\n",
      "Epoch: 78, Batch number: 48, Loss: 3239.176513671875\n",
      "Epoch: 79, Batch number: 72, Loss: 3252.53466796875\n",
      "Epoch: 81, Batch number: 20, Loss: 3324.507568359375\n",
      "Epoch: 82, Batch number: 44, Loss: 3221.65087890625\n",
      "Epoch: 83, Batch number: 68, Loss: 3252.757080078125\n",
      "Epoch: 85, Batch number: 16, Loss: 3100.511474609375\n",
      "Epoch: 86, Batch number: 40, Loss: 3146.498291015625\n",
      "Epoch: 87, Batch number: 64, Loss: 3329.327880859375\n",
      "Epoch: 89, Batch number: 12, Loss: 3083.2939453125\n",
      "Epoch: 90, Batch number: 36, Loss: 3322.828857421875\n",
      "Epoch: 91, Batch number: 60, Loss: 3397.055419921875\n",
      "Epoch: 93, Batch number: 8, Loss: 3233.36328125\n",
      "Epoch: 94, Batch number: 32, Loss: 3217.322021484375\n",
      "Epoch: 95, Batch number: 56, Loss: 3222.2275390625\n",
      "Epoch: 97, Batch number: 4, Loss: 3171.18896484375\n",
      "Epoch: 98, Batch number: 28, Loss: 3039.24755859375\n",
      "Epoch: 99, Batch number: 52, Loss: 3276.562744140625\n",
      "Epoch: 101, Batch number: 0, Loss: 3140.39794921875\n",
      "Epoch: 102, Batch number: 24, Loss: 3139.364013671875\n",
      "Epoch: 103, Batch number: 48, Loss: 3158.352783203125\n",
      "Epoch: 104, Batch number: 72, Loss: 3344.20703125\n",
      "Epoch: 106, Batch number: 20, Loss: 3273.6298828125\n",
      "Epoch: 107, Batch number: 44, Loss: 3333.307373046875\n",
      "Epoch: 108, Batch number: 68, Loss: 3373.9404296875\n",
      "Epoch: 110, Batch number: 16, Loss: 3127.793701171875\n",
      "Epoch: 111, Batch number: 40, Loss: 3352.440673828125\n",
      "Epoch: 112, Batch number: 64, Loss: 3324.876953125\n",
      "Epoch: 114, Batch number: 12, Loss: 3152.473876953125\n",
      "Epoch: 115, Batch number: 36, Loss: 3379.959716796875\n",
      "Epoch: 116, Batch number: 60, Loss: 3111.8759765625\n",
      "Epoch: 118, Batch number: 8, Loss: 3189.049072265625\n",
      "Epoch: 119, Batch number: 32, Loss: 3256.93896484375\n",
      "Epoch: 120, Batch number: 56, Loss: 3326.918701171875\n",
      "Epoch: 122, Batch number: 4, Loss: 3180.21142578125\n",
      "Epoch: 123, Batch number: 28, Loss: 3058.328857421875\n",
      "Epoch: 124, Batch number: 52, Loss: 3342.812744140625\n",
      "Epoch: 126, Batch number: 0, Loss: 3172.57421875\n",
      "Epoch: 127, Batch number: 24, Loss: 3174.682861328125\n",
      "Epoch: 128, Batch number: 48, Loss: 3206.63330078125\n",
      "Epoch: 129, Batch number: 72, Loss: 3301.72265625\n",
      "Epoch: 131, Batch number: 20, Loss: 3264.4482421875\n",
      "Epoch: 132, Batch number: 44, Loss: 3310.6689453125\n",
      "Epoch: 133, Batch number: 68, Loss: 3291.834716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135, Batch number: 16, Loss: 3124.93310546875\n",
      "Epoch: 136, Batch number: 40, Loss: 3237.58984375\n",
      "Epoch: 137, Batch number: 64, Loss: 3339.762939453125\n",
      "Epoch: 139, Batch number: 12, Loss: 3202.705810546875\n",
      "Epoch: 140, Batch number: 36, Loss: 3198.29931640625\n",
      "Epoch: 141, Batch number: 60, Loss: 3182.290771484375\n",
      "Epoch: 143, Batch number: 8, Loss: 3047.377197265625\n",
      "Epoch: 144, Batch number: 32, Loss: 3148.760009765625\n",
      "Epoch: 145, Batch number: 56, Loss: 3467.434814453125\n",
      "Epoch: 147, Batch number: 4, Loss: 3173.24853515625\n",
      "Epoch: 148, Batch number: 28, Loss: 3391.103759765625\n",
      "Epoch: 149, Batch number: 52, Loss: 3420.861572265625\n",
      "Epoch: 151, Batch number: 0, Loss: 3155.928955078125\n",
      "Epoch: 152, Batch number: 24, Loss: 3201.55517578125\n",
      "Epoch: 153, Batch number: 48, Loss: 3229.9248046875\n",
      "Epoch: 154, Batch number: 72, Loss: 3463.863037109375\n",
      "Epoch: 156, Batch number: 20, Loss: 3263.87548828125\n",
      "Epoch: 157, Batch number: 44, Loss: 3245.53759765625\n",
      "Epoch: 158, Batch number: 68, Loss: 3280.0\n",
      "Epoch: 160, Batch number: 16, Loss: 3291.312744140625\n",
      "Epoch: 161, Batch number: 40, Loss: 3310.742431640625\n",
      "Epoch: 162, Batch number: 64, Loss: 3337.697998046875\n",
      "Epoch: 164, Batch number: 12, Loss: 3178.259765625\n",
      "Epoch: 165, Batch number: 36, Loss: 3276.8701171875\n",
      "Epoch: 166, Batch number: 60, Loss: 3350.2080078125\n",
      "Epoch: 168, Batch number: 8, Loss: 3120.01318359375\n",
      "Epoch: 169, Batch number: 32, Loss: 3134.255126953125\n",
      "Epoch: 170, Batch number: 56, Loss: 3400.463134765625\n",
      "Epoch: 172, Batch number: 4, Loss: 3214.107421875\n",
      "Epoch: 173, Batch number: 28, Loss: 3179.705078125\n",
      "Epoch: 174, Batch number: 52, Loss: 3331.503662109375\n",
      "Epoch: 176, Batch number: 0, Loss: 3228.8486328125\n",
      "Epoch: 177, Batch number: 24, Loss: 3209.691162109375\n",
      "Epoch: 178, Batch number: 48, Loss: 3382.158447265625\n",
      "Epoch: 179, Batch number: 72, Loss: 3305.450439453125\n",
      "Epoch: 181, Batch number: 20, Loss: 3149.876220703125\n",
      "Epoch: 182, Batch number: 44, Loss: 3143.055419921875\n",
      "Epoch: 183, Batch number: 68, Loss: 3398.4150390625\n",
      "Epoch: 185, Batch number: 16, Loss: 3241.055908203125\n",
      "Epoch: 186, Batch number: 40, Loss: 3178.662841796875\n",
      "Epoch: 187, Batch number: 64, Loss: 3406.123046875\n",
      "Epoch: 189, Batch number: 12, Loss: 3011.2216796875\n",
      "Epoch: 190, Batch number: 36, Loss: 3164.489501953125\n",
      "Epoch: 191, Batch number: 60, Loss: 3363.2548828125\n",
      "Epoch: 193, Batch number: 8, Loss: 3191.65771484375\n",
      "Epoch: 194, Batch number: 32, Loss: 3264.2265625\n",
      "Epoch: 195, Batch number: 56, Loss: 3312.480712890625\n",
      "Epoch: 197, Batch number: 4, Loss: 3143.41455078125\n",
      "Epoch: 198, Batch number: 28, Loss: 3294.989990234375\n",
      "Epoch: 199, Batch number: 52, Loss: 3200.576904296875\n",
      "Epoch: 201, Batch number: 0, Loss: 3276.043701171875\n",
      "Epoch: 202, Batch number: 24, Loss: 3159.46484375\n",
      "Epoch: 203, Batch number: 48, Loss: 3318.79736328125\n",
      "Epoch: 204, Batch number: 72, Loss: 3335.203369140625\n",
      "Epoch: 206, Batch number: 20, Loss: 3133.63037109375\n",
      "Epoch: 207, Batch number: 44, Loss: 3264.195068359375\n",
      "Epoch: 208, Batch number: 68, Loss: 3321.395751953125\n",
      "Epoch: 210, Batch number: 16, Loss: 3225.5390625\n",
      "Epoch: 211, Batch number: 40, Loss: 3342.110107421875\n",
      "Epoch: 212, Batch number: 64, Loss: 3417.11181640625\n",
      "Epoch: 214, Batch number: 12, Loss: 3074.412109375\n",
      "Epoch: 215, Batch number: 36, Loss: 3442.914794921875\n",
      "Epoch: 216, Batch number: 60, Loss: 3460.400146484375\n",
      "Epoch: 218, Batch number: 8, Loss: 3194.311767578125\n",
      "Epoch: 219, Batch number: 32, Loss: 3104.816162109375\n",
      "Epoch: 220, Batch number: 56, Loss: 3312.619384765625\n",
      "Epoch: 222, Batch number: 4, Loss: 3179.57421875\n",
      "Epoch: 223, Batch number: 28, Loss: 3172.8671875\n",
      "Epoch: 224, Batch number: 52, Loss: 3313.66650390625\n",
      "Epoch: 226, Batch number: 0, Loss: 3161.5341796875\n",
      "Epoch: 227, Batch number: 24, Loss: 3251.2939453125\n",
      "Epoch: 228, Batch number: 48, Loss: 3308.192138671875\n",
      "Epoch: 229, Batch number: 72, Loss: 3232.06591796875\n",
      "Epoch: 231, Batch number: 20, Loss: 3063.14013671875\n",
      "Epoch: 232, Batch number: 44, Loss: 3381.33935546875\n",
      "Epoch: 233, Batch number: 68, Loss: 3243.04345703125\n",
      "Epoch: 235, Batch number: 16, Loss: 3094.515625\n",
      "Epoch: 236, Batch number: 40, Loss: 3300.34375\n",
      "Epoch: 237, Batch number: 64, Loss: 3254.844482421875\n",
      "Epoch: 239, Batch number: 12, Loss: 3214.15380859375\n",
      "Epoch: 240, Batch number: 36, Loss: 3393.46923828125\n",
      "Epoch: 241, Batch number: 60, Loss: 3307.72314453125\n",
      "Epoch: 243, Batch number: 8, Loss: 3080.381103515625\n",
      "Epoch: 244, Batch number: 32, Loss: 3353.120361328125\n",
      "Epoch: 245, Batch number: 56, Loss: 3204.087890625\n",
      "Epoch: 247, Batch number: 4, Loss: 3196.8828125\n",
      "Epoch: 248, Batch number: 28, Loss: 3181.95556640625\n",
      "Epoch: 249, Batch number: 52, Loss: 3491.53173828125\n",
      "Epoch: 251, Batch number: 0, Loss: 3214.7080078125\n",
      "Epoch: 252, Batch number: 24, Loss: 3059.124267578125\n",
      "Epoch: 253, Batch number: 48, Loss: 3180.45654296875\n",
      "Epoch: 254, Batch number: 72, Loss: 3149.68017578125\n",
      "Epoch: 256, Batch number: 20, Loss: 3179.989990234375\n",
      "Epoch: 257, Batch number: 44, Loss: 3232.177001953125\n",
      "Epoch: 258, Batch number: 68, Loss: 3369.74072265625\n",
      "Epoch: 260, Batch number: 16, Loss: 3066.838134765625\n",
      "Epoch: 261, Batch number: 40, Loss: 3310.6298828125\n",
      "Epoch: 262, Batch number: 64, Loss: 3154.379638671875\n",
      "Epoch: 264, Batch number: 12, Loss: 3033.27978515625\n",
      "Epoch: 265, Batch number: 36, Loss: 3184.300537109375\n",
      "Epoch: 266, Batch number: 60, Loss: 3256.5380859375\n",
      "Epoch: 268, Batch number: 8, Loss: 3235.080810546875\n",
      "Epoch: 269, Batch number: 32, Loss: 3099.213134765625\n",
      "Epoch: 270, Batch number: 56, Loss: 3209.0595703125\n",
      "Epoch: 272, Batch number: 4, Loss: 3100.5458984375\n",
      "Epoch: 273, Batch number: 28, Loss: 3235.958740234375\n",
      "Epoch: 274, Batch number: 52, Loss: 3338.15185546875\n",
      "Epoch: 276, Batch number: 0, Loss: 3111.594970703125\n",
      "Epoch: 277, Batch number: 24, Loss: 3476.105712890625\n",
      "Epoch: 278, Batch number: 48, Loss: 3221.00048828125\n",
      "Epoch: 279, Batch number: 72, Loss: 3318.1318359375\n",
      "Epoch: 281, Batch number: 20, Loss: 3271.489013671875\n",
      "Epoch: 282, Batch number: 44, Loss: 3229.880126953125\n",
      "Epoch: 283, Batch number: 68, Loss: 3358.0673828125\n",
      "Epoch: 285, Batch number: 16, Loss: 3208.08544921875\n",
      "Epoch: 286, Batch number: 40, Loss: 3109.450439453125\n",
      "Epoch: 287, Batch number: 64, Loss: 3326.61767578125\n",
      "Epoch: 289, Batch number: 12, Loss: 3258.887939453125\n",
      "Epoch: 290, Batch number: 36, Loss: 3285.286376953125\n",
      "Epoch: 291, Batch number: 60, Loss: 3310.115478515625\n",
      "Epoch: 293, Batch number: 8, Loss: 3238.716796875\n",
      "Epoch: 294, Batch number: 32, Loss: 3184.926025390625\n",
      "Epoch: 295, Batch number: 56, Loss: 3379.8330078125\n",
      "Epoch: 297, Batch number: 4, Loss: 3188.593505859375\n",
      "Epoch: 298, Batch number: 28, Loss: 3140.13037109375\n",
      "Epoch: 299, Batch number: 52, Loss: 3310.767333984375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15144.94921875\n",
      "Epoch: 2, Batch number: 24, Loss: 14699.0859375\n",
      "Epoch: 3, Batch number: 48, Loss: 14769.03125\n",
      "Epoch: 4, Batch number: 72, Loss: 13855.490234375\n",
      "Epoch: 6, Batch number: 20, Loss: 13644.9892578125\n",
      "Epoch: 7, Batch number: 44, Loss: 13241.255859375\n",
      "Epoch: 8, Batch number: 68, Loss: 12901.18359375\n",
      "Epoch: 10, Batch number: 16, Loss: 12645.69140625\n",
      "Epoch: 11, Batch number: 40, Loss: 12270.5849609375\n",
      "Epoch: 12, Batch number: 64, Loss: 12242.5\n",
      "Epoch: 14, Batch number: 12, Loss: 11833.8076171875\n",
      "Epoch: 15, Batch number: 36, Loss: 11793.4765625\n",
      "Epoch: 16, Batch number: 60, Loss: 11743.828125\n",
      "Epoch: 18, Batch number: 8, Loss: 11371.947265625\n",
      "Epoch: 19, Batch number: 32, Loss: 11282.1298828125\n",
      "Epoch: 20, Batch number: 56, Loss: 11034.958984375\n",
      "Epoch: 22, Batch number: 4, Loss: 10979.388671875\n",
      "Epoch: 23, Batch number: 28, Loss: 10931.9228515625\n",
      "Epoch: 24, Batch number: 52, Loss: 10646.90625\n",
      "Epoch: 26, Batch number: 0, Loss: 10669.1064453125\n",
      "Epoch: 27, Batch number: 24, Loss: 10538.1474609375\n",
      "Epoch: 28, Batch number: 48, Loss: 10557.87890625\n",
      "Epoch: 29, Batch number: 72, Loss: 10770.9609375\n",
      "Epoch: 31, Batch number: 20, Loss: 10162.7685546875\n",
      "Epoch: 32, Batch number: 44, Loss: 10159.92578125\n",
      "Epoch: 33, Batch number: 68, Loss: 10113.4384765625\n",
      "Epoch: 35, Batch number: 16, Loss: 9966.5498046875\n",
      "Epoch: 36, Batch number: 40, Loss: 10204.650390625\n",
      "Epoch: 37, Batch number: 64, Loss: 10231.1953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Batch number: 12, Loss: 9672.78125\n",
      "Epoch: 40, Batch number: 36, Loss: 9806.703125\n",
      "Epoch: 41, Batch number: 60, Loss: 9967.07421875\n",
      "Epoch: 43, Batch number: 8, Loss: 9735.8447265625\n",
      "Epoch: 44, Batch number: 32, Loss: 9873.1845703125\n",
      "Epoch: 45, Batch number: 56, Loss: 9593.8974609375\n",
      "Epoch: 47, Batch number: 4, Loss: 9590.404296875\n",
      "Epoch: 48, Batch number: 28, Loss: 9518.486328125\n",
      "Epoch: 49, Batch number: 52, Loss: 9552.1318359375\n",
      "Epoch: 51, Batch number: 0, Loss: 9626.1787109375\n",
      "Epoch: 52, Batch number: 24, Loss: 9564.9580078125\n",
      "Epoch: 53, Batch number: 48, Loss: 9436.1474609375\n",
      "Epoch: 54, Batch number: 72, Loss: 9489.7333984375\n",
      "Epoch: 56, Batch number: 20, Loss: 9174.2373046875\n",
      "Epoch: 57, Batch number: 44, Loss: 9075.7021484375\n",
      "Epoch: 58, Batch number: 68, Loss: 9274.322265625\n",
      "Epoch: 60, Batch number: 16, Loss: 9212.1533203125\n",
      "Epoch: 61, Batch number: 40, Loss: 9349.97265625\n",
      "Epoch: 62, Batch number: 64, Loss: 9362.6181640625\n",
      "Epoch: 64, Batch number: 12, Loss: 9253.3701171875\n",
      "Epoch: 65, Batch number: 36, Loss: 9322.203125\n",
      "Epoch: 66, Batch number: 60, Loss: 9124.69921875\n",
      "Epoch: 68, Batch number: 8, Loss: 8989.9296875\n",
      "Epoch: 69, Batch number: 32, Loss: 9075.0966796875\n",
      "Epoch: 70, Batch number: 56, Loss: 9277.193359375\n",
      "Epoch: 72, Batch number: 4, Loss: 8928.1982421875\n",
      "Epoch: 73, Batch number: 28, Loss: 9160.419921875\n",
      "Epoch: 74, Batch number: 52, Loss: 9010.7880859375\n",
      "Epoch: 76, Batch number: 0, Loss: 8998.029296875\n",
      "Epoch: 77, Batch number: 24, Loss: 8958.7578125\n",
      "Epoch: 78, Batch number: 48, Loss: 8763.185546875\n",
      "Epoch: 79, Batch number: 72, Loss: 8786.435546875\n",
      "Epoch: 81, Batch number: 20, Loss: 8928.73046875\n",
      "Epoch: 82, Batch number: 44, Loss: 8806.0341796875\n",
      "Epoch: 83, Batch number: 68, Loss: 9095.453125\n",
      "Epoch: 85, Batch number: 16, Loss: 8683.9345703125\n",
      "Epoch: 86, Batch number: 40, Loss: 8742.2021484375\n",
      "Epoch: 87, Batch number: 64, Loss: 8766.6826171875\n",
      "Epoch: 89, Batch number: 12, Loss: 8802.80859375\n",
      "Epoch: 90, Batch number: 36, Loss: 8859.357421875\n",
      "Epoch: 91, Batch number: 60, Loss: 8695.08203125\n",
      "Epoch: 93, Batch number: 8, Loss: 8641.7470703125\n",
      "Epoch: 94, Batch number: 32, Loss: 8812.0126953125\n",
      "Epoch: 95, Batch number: 56, Loss: 8636.6552734375\n",
      "Epoch: 97, Batch number: 4, Loss: 8769.6279296875\n",
      "Epoch: 98, Batch number: 28, Loss: 8604.697265625\n",
      "Epoch: 99, Batch number: 52, Loss: 8540.4326171875\n",
      "Epoch: 101, Batch number: 0, Loss: 8522.5810546875\n",
      "Epoch: 102, Batch number: 24, Loss: 8579.2890625\n",
      "Epoch: 103, Batch number: 48, Loss: 8555.451171875\n",
      "Epoch: 104, Batch number: 72, Loss: 8721.1357421875\n",
      "Epoch: 106, Batch number: 20, Loss: 8576.75390625\n",
      "Epoch: 107, Batch number: 44, Loss: 8515.7841796875\n",
      "Epoch: 108, Batch number: 68, Loss: 8747.6484375\n",
      "Epoch: 110, Batch number: 16, Loss: 8379.5224609375\n",
      "Epoch: 111, Batch number: 40, Loss: 8401.2744140625\n",
      "Epoch: 112, Batch number: 64, Loss: 8516.3984375\n",
      "Epoch: 114, Batch number: 12, Loss: 8215.69921875\n",
      "Epoch: 115, Batch number: 36, Loss: 8406.599609375\n",
      "Epoch: 116, Batch number: 60, Loss: 8501.31640625\n",
      "Epoch: 118, Batch number: 8, Loss: 8255.892578125\n",
      "Epoch: 119, Batch number: 32, Loss: 8200.869140625\n",
      "Epoch: 120, Batch number: 56, Loss: 8267.2421875\n",
      "Epoch: 122, Batch number: 4, Loss: 8302.029296875\n",
      "Epoch: 123, Batch number: 28, Loss: 8400.64453125\n",
      "Epoch: 124, Batch number: 52, Loss: 8390.0390625\n",
      "Epoch: 126, Batch number: 0, Loss: 8243.400390625\n",
      "Epoch: 127, Batch number: 24, Loss: 8038.38818359375\n",
      "Epoch: 128, Batch number: 48, Loss: 8035.43017578125\n",
      "Epoch: 129, Batch number: 72, Loss: 8235.5771484375\n",
      "Epoch: 131, Batch number: 20, Loss: 8320.3056640625\n",
      "Epoch: 132, Batch number: 44, Loss: 8261.6572265625\n",
      "Epoch: 133, Batch number: 68, Loss: 8096.36669921875\n",
      "Epoch: 135, Batch number: 16, Loss: 8395.201171875\n",
      "Epoch: 136, Batch number: 40, Loss: 8081.97314453125\n",
      "Epoch: 137, Batch number: 64, Loss: 8412.802734375\n",
      "Epoch: 139, Batch number: 12, Loss: 8140.9599609375\n",
      "Epoch: 140, Batch number: 36, Loss: 8029.16650390625\n",
      "Epoch: 141, Batch number: 60, Loss: 8098.947265625\n",
      "Epoch: 143, Batch number: 8, Loss: 8113.8779296875\n",
      "Epoch: 144, Batch number: 32, Loss: 7924.74072265625\n",
      "Epoch: 145, Batch number: 56, Loss: 8151.017578125\n",
      "Epoch: 147, Batch number: 4, Loss: 8334.66015625\n",
      "Epoch: 148, Batch number: 28, Loss: 8219.966796875\n",
      "Epoch: 149, Batch number: 52, Loss: 8135.33447265625\n",
      "Epoch: 151, Batch number: 0, Loss: 7890.703125\n",
      "Epoch: 152, Batch number: 24, Loss: 8381.1650390625\n",
      "Epoch: 153, Batch number: 48, Loss: 7625.06396484375\n",
      "Epoch: 154, Batch number: 72, Loss: 8047.47900390625\n",
      "Epoch: 156, Batch number: 20, Loss: 8041.658203125\n",
      "Epoch: 157, Batch number: 44, Loss: 7894.72021484375\n",
      "Epoch: 158, Batch number: 68, Loss: 8167.6123046875\n",
      "Epoch: 160, Batch number: 16, Loss: 8159.15673828125\n",
      "Epoch: 161, Batch number: 40, Loss: 8127.35009765625\n",
      "Epoch: 162, Batch number: 64, Loss: 8057.611328125\n",
      "Epoch: 164, Batch number: 12, Loss: 8082.2080078125\n",
      "Epoch: 165, Batch number: 36, Loss: 8241.6767578125\n",
      "Epoch: 166, Batch number: 60, Loss: 8036.72900390625\n",
      "Epoch: 168, Batch number: 8, Loss: 7973.09130859375\n",
      "Epoch: 169, Batch number: 32, Loss: 7753.91748046875\n",
      "Epoch: 170, Batch number: 56, Loss: 7942.39404296875\n",
      "Epoch: 172, Batch number: 4, Loss: 8075.1796875\n",
      "Epoch: 173, Batch number: 28, Loss: 7867.9453125\n",
      "Epoch: 174, Batch number: 52, Loss: 7778.55126953125\n",
      "Epoch: 176, Batch number: 0, Loss: 7981.46533203125\n",
      "Epoch: 177, Batch number: 24, Loss: 8048.62744140625\n",
      "Epoch: 178, Batch number: 48, Loss: 7744.24609375\n",
      "Epoch: 179, Batch number: 72, Loss: 7807.30859375\n",
      "Epoch: 181, Batch number: 20, Loss: 7979.1982421875\n",
      "Epoch: 182, Batch number: 44, Loss: 7680.787109375\n",
      "Epoch: 183, Batch number: 68, Loss: 7883.58642578125\n",
      "Epoch: 185, Batch number: 16, Loss: 7748.8515625\n",
      "Epoch: 186, Batch number: 40, Loss: 7761.44970703125\n",
      "Epoch: 187, Batch number: 64, Loss: 8011.35009765625\n",
      "Epoch: 189, Batch number: 12, Loss: 7840.8115234375\n",
      "Epoch: 190, Batch number: 36, Loss: 7928.70751953125\n",
      "Epoch: 191, Batch number: 60, Loss: 7805.79443359375\n",
      "Epoch: 193, Batch number: 8, Loss: 7637.541015625\n",
      "Epoch: 194, Batch number: 32, Loss: 7896.44287109375\n",
      "Epoch: 195, Batch number: 56, Loss: 7857.36181640625\n",
      "Epoch: 197, Batch number: 4, Loss: 7740.0234375\n",
      "Epoch: 198, Batch number: 28, Loss: 7925.7001953125\n",
      "Epoch: 199, Batch number: 52, Loss: 7687.83349609375\n",
      "Epoch: 201, Batch number: 0, Loss: 7673.08447265625\n",
      "Epoch: 202, Batch number: 24, Loss: 7667.6923828125\n",
      "Epoch: 203, Batch number: 48, Loss: 7636.71044921875\n",
      "Epoch: 204, Batch number: 72, Loss: 7800.3837890625\n",
      "Epoch: 206, Batch number: 20, Loss: 7576.70703125\n",
      "Epoch: 207, Batch number: 44, Loss: 7783.3056640625\n",
      "Epoch: 208, Batch number: 68, Loss: 7954.45751953125\n",
      "Epoch: 210, Batch number: 16, Loss: 7839.57275390625\n",
      "Epoch: 211, Batch number: 40, Loss: 7698.525390625\n",
      "Epoch: 212, Batch number: 64, Loss: 7602.08544921875\n",
      "Epoch: 214, Batch number: 12, Loss: 7770.5341796875\n",
      "Epoch: 215, Batch number: 36, Loss: 7659.72265625\n",
      "Epoch: 216, Batch number: 60, Loss: 7985.5205078125\n",
      "Epoch: 218, Batch number: 8, Loss: 7518.40380859375\n",
      "Epoch: 219, Batch number: 32, Loss: 7544.337890625\n",
      "Epoch: 220, Batch number: 56, Loss: 7683.83251953125\n",
      "Epoch: 222, Batch number: 4, Loss: 7858.41552734375\n",
      "Epoch: 223, Batch number: 28, Loss: 7634.6767578125\n",
      "Epoch: 224, Batch number: 52, Loss: 7395.380859375\n",
      "Epoch: 226, Batch number: 0, Loss: 7544.689453125\n",
      "Epoch: 227, Batch number: 24, Loss: 7783.8173828125\n",
      "Epoch: 228, Batch number: 48, Loss: 7817.9638671875\n",
      "Epoch: 229, Batch number: 72, Loss: 7534.1923828125\n",
      "Epoch: 231, Batch number: 20, Loss: 7802.94677734375\n",
      "Epoch: 232, Batch number: 44, Loss: 7739.13232421875\n",
      "Epoch: 233, Batch number: 68, Loss: 7760.00830078125\n",
      "Epoch: 235, Batch number: 16, Loss: 7450.1875\n",
      "Epoch: 236, Batch number: 40, Loss: 7790.2939453125\n",
      "Epoch: 237, Batch number: 64, Loss: 7644.88818359375\n",
      "Epoch: 239, Batch number: 12, Loss: 7656.09765625\n",
      "Epoch: 240, Batch number: 36, Loss: 7891.47265625\n",
      "Epoch: 241, Batch number: 60, Loss: 7590.205078125\n",
      "Epoch: 243, Batch number: 8, Loss: 7297.8291015625\n",
      "Epoch: 244, Batch number: 32, Loss: 7729.54296875\n",
      "Epoch: 245, Batch number: 56, Loss: 7501.748046875\n",
      "Epoch: 247, Batch number: 4, Loss: 7494.60595703125\n",
      "Epoch: 248, Batch number: 28, Loss: 7518.1181640625\n",
      "Epoch: 249, Batch number: 52, Loss: 7438.06640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251, Batch number: 0, Loss: 7667.75390625\n",
      "Epoch: 252, Batch number: 24, Loss: 7475.31689453125\n",
      "Epoch: 253, Batch number: 48, Loss: 7643.39306640625\n",
      "Epoch: 254, Batch number: 72, Loss: 7316.578125\n",
      "Epoch: 256, Batch number: 20, Loss: 7373.359375\n",
      "Epoch: 257, Batch number: 44, Loss: 7400.08837890625\n",
      "Epoch: 258, Batch number: 68, Loss: 7447.3408203125\n",
      "Epoch: 260, Batch number: 16, Loss: 7266.2568359375\n",
      "Epoch: 261, Batch number: 40, Loss: 7576.00634765625\n",
      "Epoch: 262, Batch number: 64, Loss: 7575.17236328125\n",
      "Epoch: 264, Batch number: 12, Loss: 7555.60791015625\n",
      "Epoch: 265, Batch number: 36, Loss: 7527.015625\n",
      "Epoch: 266, Batch number: 60, Loss: 7690.62451171875\n",
      "Epoch: 268, Batch number: 8, Loss: 7654.890625\n",
      "Epoch: 269, Batch number: 32, Loss: 7517.98779296875\n",
      "Epoch: 270, Batch number: 56, Loss: 7711.6630859375\n",
      "Epoch: 272, Batch number: 4, Loss: 7332.67822265625\n",
      "Epoch: 273, Batch number: 28, Loss: 7586.30712890625\n",
      "Epoch: 274, Batch number: 52, Loss: 7560.482421875\n",
      "Epoch: 276, Batch number: 0, Loss: 7468.6044921875\n",
      "Epoch: 277, Batch number: 24, Loss: 7534.38525390625\n",
      "Epoch: 278, Batch number: 48, Loss: 7686.41015625\n",
      "Epoch: 279, Batch number: 72, Loss: 7480.83056640625\n",
      "Epoch: 281, Batch number: 20, Loss: 7474.51953125\n",
      "Epoch: 282, Batch number: 44, Loss: 7385.9287109375\n",
      "Epoch: 283, Batch number: 68, Loss: 7681.2998046875\n",
      "Epoch: 285, Batch number: 16, Loss: 7590.59375\n",
      "Epoch: 286, Batch number: 40, Loss: 7616.49560546875\n",
      "Epoch: 287, Batch number: 64, Loss: 7544.666015625\n",
      "Epoch: 289, Batch number: 12, Loss: 7574.76123046875\n",
      "Epoch: 290, Batch number: 36, Loss: 7501.24853515625\n",
      "Epoch: 291, Batch number: 60, Loss: 7483.44873046875\n",
      "Epoch: 293, Batch number: 8, Loss: 7593.740234375\n",
      "Epoch: 294, Batch number: 32, Loss: 7420.37060546875\n",
      "Epoch: 295, Batch number: 56, Loss: 7408.3525390625\n",
      "Epoch: 297, Batch number: 4, Loss: 7181.626953125\n",
      "Epoch: 298, Batch number: 28, Loss: 7229.3447265625\n",
      "Epoch: 299, Batch number: 52, Loss: 7410.8720703125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15150.455078125\n",
      "Epoch: 2, Batch number: 24, Loss: 14790.7353515625\n",
      "Epoch: 3, Batch number: 48, Loss: 14150.857421875\n",
      "Epoch: 4, Batch number: 72, Loss: 13473.8828125\n",
      "Epoch: 6, Batch number: 20, Loss: 12710.6171875\n",
      "Epoch: 7, Batch number: 44, Loss: 12573.4208984375\n",
      "Epoch: 8, Batch number: 68, Loss: 12216.845703125\n",
      "Epoch: 10, Batch number: 16, Loss: 11987.365234375\n",
      "Epoch: 11, Batch number: 40, Loss: 11296.0986328125\n",
      "Epoch: 12, Batch number: 64, Loss: 11381.2578125\n",
      "Epoch: 14, Batch number: 12, Loss: 11082.3662109375\n",
      "Epoch: 15, Batch number: 36, Loss: 10571.3837890625\n",
      "Epoch: 16, Batch number: 60, Loss: 10722.810546875\n",
      "Epoch: 18, Batch number: 8, Loss: 10150.0078125\n",
      "Epoch: 19, Batch number: 32, Loss: 10026.5966796875\n",
      "Epoch: 20, Batch number: 56, Loss: 10069.6171875\n",
      "Epoch: 22, Batch number: 4, Loss: 10035.853515625\n",
      "Epoch: 23, Batch number: 28, Loss: 9875.5888671875\n",
      "Epoch: 24, Batch number: 52, Loss: 9826.8828125\n",
      "Epoch: 26, Batch number: 0, Loss: 9582.3818359375\n",
      "Epoch: 27, Batch number: 24, Loss: 9453.49609375\n",
      "Epoch: 28, Batch number: 48, Loss: 9426.59375\n",
      "Epoch: 29, Batch number: 72, Loss: 9250.158203125\n",
      "Epoch: 31, Batch number: 20, Loss: 9389.2978515625\n",
      "Epoch: 32, Batch number: 44, Loss: 8887.841796875\n",
      "Epoch: 33, Batch number: 68, Loss: 8960.92578125\n",
      "Epoch: 35, Batch number: 16, Loss: 8884.0625\n",
      "Epoch: 36, Batch number: 40, Loss: 9056.38671875\n",
      "Epoch: 37, Batch number: 64, Loss: 9062.1650390625\n",
      "Epoch: 39, Batch number: 12, Loss: 8974.662109375\n",
      "Epoch: 40, Batch number: 36, Loss: 8719.5693359375\n",
      "Epoch: 41, Batch number: 60, Loss: 8791.6474609375\n",
      "Epoch: 43, Batch number: 8, Loss: 8583.697265625\n",
      "Epoch: 44, Batch number: 32, Loss: 8650.66796875\n",
      "Epoch: 45, Batch number: 56, Loss: 8623.8095703125\n",
      "Epoch: 47, Batch number: 4, Loss: 8521.396484375\n",
      "Epoch: 48, Batch number: 28, Loss: 8515.6181640625\n",
      "Epoch: 49, Batch number: 52, Loss: 8674.4189453125\n",
      "Epoch: 51, Batch number: 0, Loss: 8514.6484375\n",
      "Epoch: 52, Batch number: 24, Loss: 8447.41796875\n",
      "Epoch: 53, Batch number: 48, Loss: 8445.626953125\n",
      "Epoch: 54, Batch number: 72, Loss: 8510.4365234375\n",
      "Epoch: 56, Batch number: 20, Loss: 8461.6064453125\n",
      "Epoch: 57, Batch number: 44, Loss: 8335.5986328125\n",
      "Epoch: 58, Batch number: 68, Loss: 8264.4853515625\n",
      "Epoch: 60, Batch number: 16, Loss: 8045.466796875\n",
      "Epoch: 61, Batch number: 40, Loss: 8216.537109375\n",
      "Epoch: 62, Batch number: 64, Loss: 8118.0498046875\n",
      "Epoch: 64, Batch number: 12, Loss: 8339.8251953125\n",
      "Epoch: 65, Batch number: 36, Loss: 8140.08154296875\n",
      "Epoch: 66, Batch number: 60, Loss: 8259.65234375\n",
      "Epoch: 68, Batch number: 8, Loss: 8030.92138671875\n",
      "Epoch: 69, Batch number: 32, Loss: 8074.4677734375\n",
      "Epoch: 70, Batch number: 56, Loss: 8012.6064453125\n",
      "Epoch: 72, Batch number: 4, Loss: 8226.7158203125\n",
      "Epoch: 73, Batch number: 28, Loss: 8102.109375\n",
      "Epoch: 74, Batch number: 52, Loss: 8015.51318359375\n",
      "Epoch: 76, Batch number: 0, Loss: 7854.0673828125\n",
      "Epoch: 77, Batch number: 24, Loss: 8072.65087890625\n",
      "Epoch: 78, Batch number: 48, Loss: 8145.19287109375\n",
      "Epoch: 79, Batch number: 72, Loss: 8064.5546875\n",
      "Epoch: 81, Batch number: 20, Loss: 7712.9775390625\n",
      "Epoch: 82, Batch number: 44, Loss: 7737.232421875\n",
      "Epoch: 83, Batch number: 68, Loss: 8038.65380859375\n",
      "Epoch: 85, Batch number: 16, Loss: 7640.72265625\n",
      "Epoch: 86, Batch number: 40, Loss: 7850.99267578125\n",
      "Epoch: 87, Batch number: 64, Loss: 7876.13720703125\n",
      "Epoch: 89, Batch number: 12, Loss: 7762.1572265625\n",
      "Epoch: 90, Batch number: 36, Loss: 7792.5810546875\n",
      "Epoch: 91, Batch number: 60, Loss: 8004.90625\n",
      "Epoch: 93, Batch number: 8, Loss: 7849.4697265625\n",
      "Epoch: 94, Batch number: 32, Loss: 7772.23779296875\n",
      "Epoch: 95, Batch number: 56, Loss: 7731.1162109375\n",
      "Epoch: 97, Batch number: 4, Loss: 7568.13134765625\n",
      "Epoch: 98, Batch number: 28, Loss: 7814.37939453125\n",
      "Epoch: 99, Batch number: 52, Loss: 7864.4140625\n",
      "Epoch: 101, Batch number: 0, Loss: 7877.15478515625\n",
      "Epoch: 102, Batch number: 24, Loss: 7528.76025390625\n",
      "Epoch: 103, Batch number: 48, Loss: 7883.71044921875\n",
      "Epoch: 104, Batch number: 72, Loss: 7681.4033203125\n",
      "Epoch: 106, Batch number: 20, Loss: 7822.10888671875\n",
      "Epoch: 107, Batch number: 44, Loss: 7681.96533203125\n",
      "Epoch: 108, Batch number: 68, Loss: 7519.01416015625\n",
      "Epoch: 110, Batch number: 16, Loss: 7529.505859375\n",
      "Epoch: 111, Batch number: 40, Loss: 7705.732421875\n",
      "Epoch: 112, Batch number: 64, Loss: 7459.0234375\n",
      "Epoch: 114, Batch number: 12, Loss: 7694.52392578125\n",
      "Epoch: 115, Batch number: 36, Loss: 7592.79345703125\n",
      "Epoch: 116, Batch number: 60, Loss: 7624.6640625\n",
      "Epoch: 118, Batch number: 8, Loss: 7224.04638671875\n",
      "Epoch: 119, Batch number: 32, Loss: 7202.72509765625\n",
      "Epoch: 120, Batch number: 56, Loss: 7523.1650390625\n",
      "Epoch: 122, Batch number: 4, Loss: 7591.0703125\n",
      "Epoch: 123, Batch number: 28, Loss: 7440.47705078125\n",
      "Epoch: 124, Batch number: 52, Loss: 7512.64599609375\n",
      "Epoch: 126, Batch number: 0, Loss: 7520.4912109375\n",
      "Epoch: 127, Batch number: 24, Loss: 7607.85595703125\n",
      "Epoch: 128, Batch number: 48, Loss: 7675.3564453125\n",
      "Epoch: 129, Batch number: 72, Loss: 7594.380859375\n",
      "Epoch: 131, Batch number: 20, Loss: 7265.22607421875\n",
      "Epoch: 132, Batch number: 44, Loss: 7578.78515625\n",
      "Epoch: 133, Batch number: 68, Loss: 7286.833984375\n",
      "Epoch: 135, Batch number: 16, Loss: 7348.31982421875\n",
      "Epoch: 136, Batch number: 40, Loss: 7597.07373046875\n",
      "Epoch: 137, Batch number: 64, Loss: 7281.16455078125\n",
      "Epoch: 139, Batch number: 12, Loss: 7350.607421875\n",
      "Epoch: 140, Batch number: 36, Loss: 7230.81298828125\n",
      "Epoch: 141, Batch number: 60, Loss: 7288.47705078125\n",
      "Epoch: 143, Batch number: 8, Loss: 7303.216796875\n",
      "Epoch: 144, Batch number: 32, Loss: 7374.69287109375\n",
      "Epoch: 145, Batch number: 56, Loss: 7298.81201171875\n",
      "Epoch: 147, Batch number: 4, Loss: 7202.27099609375\n",
      "Epoch: 148, Batch number: 28, Loss: 7357.5625\n",
      "Epoch: 149, Batch number: 52, Loss: 7271.25146484375\n",
      "Epoch: 151, Batch number: 0, Loss: 7375.078125\n",
      "Epoch: 152, Batch number: 24, Loss: 7449.765625\n",
      "Epoch: 153, Batch number: 48, Loss: 7136.65185546875\n",
      "Epoch: 154, Batch number: 72, Loss: 7356.7255859375\n",
      "Epoch: 156, Batch number: 20, Loss: 7395.6435546875\n",
      "Epoch: 157, Batch number: 44, Loss: 7303.072265625\n",
      "Epoch: 158, Batch number: 68, Loss: 7406.509765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Batch number: 16, Loss: 7234.552734375\n",
      "Epoch: 161, Batch number: 40, Loss: 7137.5341796875\n",
      "Epoch: 162, Batch number: 64, Loss: 7187.59765625\n",
      "Epoch: 164, Batch number: 12, Loss: 7301.94921875\n",
      "Epoch: 165, Batch number: 36, Loss: 7045.6708984375\n",
      "Epoch: 166, Batch number: 60, Loss: 7203.33544921875\n",
      "Epoch: 168, Batch number: 8, Loss: 7141.78173828125\n",
      "Epoch: 169, Batch number: 32, Loss: 7021.232421875\n",
      "Epoch: 170, Batch number: 56, Loss: 7038.04833984375\n",
      "Epoch: 172, Batch number: 4, Loss: 7080.3095703125\n",
      "Epoch: 173, Batch number: 28, Loss: 7116.34716796875\n",
      "Epoch: 174, Batch number: 52, Loss: 7178.11474609375\n",
      "Epoch: 176, Batch number: 0, Loss: 7043.26171875\n",
      "Epoch: 177, Batch number: 24, Loss: 7387.05859375\n",
      "Epoch: 178, Batch number: 48, Loss: 7417.2021484375\n",
      "Epoch: 179, Batch number: 72, Loss: 7106.48486328125\n",
      "Epoch: 181, Batch number: 20, Loss: 7039.306640625\n",
      "Epoch: 182, Batch number: 44, Loss: 7051.4287109375\n",
      "Epoch: 183, Batch number: 68, Loss: 7147.07470703125\n",
      "Epoch: 185, Batch number: 16, Loss: 7088.892578125\n",
      "Epoch: 186, Batch number: 40, Loss: 7338.7041015625\n",
      "Epoch: 187, Batch number: 64, Loss: 7456.1865234375\n",
      "Epoch: 189, Batch number: 12, Loss: 7031.23486328125\n",
      "Epoch: 190, Batch number: 36, Loss: 7284.697265625\n",
      "Epoch: 191, Batch number: 60, Loss: 7288.01806640625\n",
      "Epoch: 193, Batch number: 8, Loss: 7079.02783203125\n",
      "Epoch: 194, Batch number: 32, Loss: 7160.126953125\n",
      "Epoch: 195, Batch number: 56, Loss: 7286.2666015625\n",
      "Epoch: 197, Batch number: 4, Loss: 7294.056640625\n",
      "Epoch: 198, Batch number: 28, Loss: 7272.28759765625\n",
      "Epoch: 199, Batch number: 52, Loss: 7223.87353515625\n",
      "Epoch: 201, Batch number: 0, Loss: 7087.00927734375\n",
      "Epoch: 202, Batch number: 24, Loss: 6981.9208984375\n",
      "Epoch: 203, Batch number: 48, Loss: 7091.09912109375\n",
      "Epoch: 204, Batch number: 72, Loss: 6825.568359375\n",
      "Epoch: 206, Batch number: 20, Loss: 7460.28076171875\n",
      "Epoch: 207, Batch number: 44, Loss: 7228.59912109375\n",
      "Epoch: 208, Batch number: 68, Loss: 7199.73095703125\n",
      "Epoch: 210, Batch number: 16, Loss: 7176.3701171875\n",
      "Epoch: 211, Batch number: 40, Loss: 7252.37060546875\n",
      "Epoch: 212, Batch number: 64, Loss: 7230.537109375\n",
      "Epoch: 214, Batch number: 12, Loss: 7216.17626953125\n",
      "Epoch: 215, Batch number: 36, Loss: 7065.43017578125\n",
      "Epoch: 216, Batch number: 60, Loss: 7317.6845703125\n",
      "Epoch: 218, Batch number: 8, Loss: 6989.17724609375\n",
      "Epoch: 219, Batch number: 32, Loss: 6978.5009765625\n",
      "Epoch: 220, Batch number: 56, Loss: 7202.8203125\n",
      "Epoch: 222, Batch number: 4, Loss: 6861.3115234375\n",
      "Epoch: 223, Batch number: 28, Loss: 7182.19287109375\n",
      "Epoch: 224, Batch number: 52, Loss: 7267.2568359375\n",
      "Epoch: 226, Batch number: 0, Loss: 7050.884765625\n",
      "Epoch: 227, Batch number: 24, Loss: 6825.01513671875\n",
      "Epoch: 228, Batch number: 48, Loss: 7141.63427734375\n",
      "Epoch: 229, Batch number: 72, Loss: 7324.85693359375\n",
      "Epoch: 231, Batch number: 20, Loss: 7108.98388671875\n",
      "Epoch: 232, Batch number: 44, Loss: 7188.435546875\n",
      "Epoch: 233, Batch number: 68, Loss: 7053.66650390625\n",
      "Epoch: 235, Batch number: 16, Loss: 6770.86865234375\n",
      "Epoch: 236, Batch number: 40, Loss: 7142.7080078125\n",
      "Epoch: 237, Batch number: 64, Loss: 7034.87890625\n",
      "Epoch: 239, Batch number: 12, Loss: 7002.2109375\n",
      "Epoch: 240, Batch number: 36, Loss: 7292.28955078125\n",
      "Epoch: 241, Batch number: 60, Loss: 7431.4501953125\n",
      "Epoch: 243, Batch number: 8, Loss: 6974.0751953125\n",
      "Epoch: 244, Batch number: 32, Loss: 7085.83251953125\n",
      "Epoch: 245, Batch number: 56, Loss: 7082.59912109375\n",
      "Epoch: 247, Batch number: 4, Loss: 7252.6904296875\n",
      "Epoch: 248, Batch number: 28, Loss: 6892.1630859375\n",
      "Epoch: 249, Batch number: 52, Loss: 6891.23828125\n",
      "Epoch: 251, Batch number: 0, Loss: 6953.4375\n",
      "Epoch: 252, Batch number: 24, Loss: 6976.92138671875\n",
      "Epoch: 253, Batch number: 48, Loss: 7094.46044921875\n",
      "Epoch: 254, Batch number: 72, Loss: 7216.97509765625\n",
      "Epoch: 256, Batch number: 20, Loss: 6952.44091796875\n",
      "Epoch: 257, Batch number: 44, Loss: 6918.39794921875\n",
      "Epoch: 258, Batch number: 68, Loss: 6931.26611328125\n",
      "Epoch: 260, Batch number: 16, Loss: 6873.580078125\n",
      "Epoch: 261, Batch number: 40, Loss: 7119.30615234375\n",
      "Epoch: 262, Batch number: 64, Loss: 6903.6435546875\n",
      "Epoch: 264, Batch number: 12, Loss: 7022.8916015625\n",
      "Epoch: 265, Batch number: 36, Loss: 6956.865234375\n",
      "Epoch: 266, Batch number: 60, Loss: 7179.4013671875\n",
      "Epoch: 268, Batch number: 8, Loss: 6964.79345703125\n",
      "Epoch: 269, Batch number: 32, Loss: 6815.13818359375\n",
      "Epoch: 270, Batch number: 56, Loss: 7405.26513671875\n",
      "Epoch: 272, Batch number: 4, Loss: 6977.7900390625\n",
      "Epoch: 273, Batch number: 28, Loss: 7080.27392578125\n",
      "Epoch: 274, Batch number: 52, Loss: 7214.0625\n",
      "Epoch: 276, Batch number: 0, Loss: 6761.28369140625\n",
      "Epoch: 277, Batch number: 24, Loss: 7177.99609375\n",
      "Epoch: 278, Batch number: 48, Loss: 7102.5439453125\n",
      "Epoch: 279, Batch number: 72, Loss: 7073.810546875\n",
      "Epoch: 281, Batch number: 20, Loss: 6990.56884765625\n",
      "Epoch: 282, Batch number: 44, Loss: 6941.05908203125\n",
      "Epoch: 283, Batch number: 68, Loss: 7002.0302734375\n",
      "Epoch: 285, Batch number: 16, Loss: 7163.37939453125\n",
      "Epoch: 286, Batch number: 40, Loss: 7262.74609375\n",
      "Epoch: 287, Batch number: 64, Loss: 6793.88671875\n",
      "Epoch: 289, Batch number: 12, Loss: 6856.046875\n",
      "Epoch: 290, Batch number: 36, Loss: 7169.23095703125\n",
      "Epoch: 291, Batch number: 60, Loss: 7255.67431640625\n",
      "Epoch: 293, Batch number: 8, Loss: 7277.56494140625\n",
      "Epoch: 294, Batch number: 32, Loss: 7035.71826171875\n",
      "Epoch: 295, Batch number: 56, Loss: 6710.28125\n",
      "Epoch: 297, Batch number: 4, Loss: 7050.32763671875\n",
      "Epoch: 298, Batch number: 28, Loss: 6924.43115234375\n",
      "Epoch: 299, Batch number: 52, Loss: 6849.49560546875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15584.326171875\n",
      "Epoch: 2, Batch number: 24, Loss: 14276.2841796875\n",
      "Epoch: 3, Batch number: 48, Loss: 13654.390625\n",
      "Epoch: 4, Batch number: 72, Loss: 13362.9873046875\n",
      "Epoch: 6, Batch number: 20, Loss: 12443.0\n",
      "Epoch: 7, Batch number: 44, Loss: 12078.25\n",
      "Epoch: 8, Batch number: 68, Loss: 11613.5859375\n",
      "Epoch: 10, Batch number: 16, Loss: 11249.6318359375\n",
      "Epoch: 11, Batch number: 40, Loss: 11156.7685546875\n",
      "Epoch: 12, Batch number: 64, Loss: 10530.1787109375\n",
      "Epoch: 14, Batch number: 12, Loss: 10236.439453125\n",
      "Epoch: 15, Batch number: 36, Loss: 10218.2744140625\n",
      "Epoch: 16, Batch number: 60, Loss: 10166.9404296875\n",
      "Epoch: 18, Batch number: 8, Loss: 9729.3564453125\n",
      "Epoch: 19, Batch number: 32, Loss: 9481.767578125\n",
      "Epoch: 20, Batch number: 56, Loss: 9544.5654296875\n",
      "Epoch: 22, Batch number: 4, Loss: 9276.25390625\n",
      "Epoch: 23, Batch number: 28, Loss: 9010.9013671875\n",
      "Epoch: 24, Batch number: 52, Loss: 9186.6416015625\n",
      "Epoch: 26, Batch number: 0, Loss: 8767.0087890625\n",
      "Epoch: 27, Batch number: 24, Loss: 8779.22265625\n",
      "Epoch: 28, Batch number: 48, Loss: 8634.818359375\n",
      "Epoch: 29, Batch number: 72, Loss: 8858.4111328125\n",
      "Epoch: 31, Batch number: 20, Loss: 8619.0361328125\n",
      "Epoch: 32, Batch number: 44, Loss: 8589.283203125\n",
      "Epoch: 33, Batch number: 68, Loss: 8628.6865234375\n",
      "Epoch: 35, Batch number: 16, Loss: 8643.001953125\n",
      "Epoch: 36, Batch number: 40, Loss: 8277.0244140625\n",
      "Epoch: 37, Batch number: 64, Loss: 8302.4111328125\n",
      "Epoch: 39, Batch number: 12, Loss: 8191.98095703125\n",
      "Epoch: 40, Batch number: 36, Loss: 8378.5126953125\n",
      "Epoch: 41, Batch number: 60, Loss: 8217.0478515625\n",
      "Epoch: 43, Batch number: 8, Loss: 8068.88525390625\n",
      "Epoch: 44, Batch number: 32, Loss: 7835.61474609375\n",
      "Epoch: 45, Batch number: 56, Loss: 8223.05078125\n",
      "Epoch: 47, Batch number: 4, Loss: 8008.6826171875\n",
      "Epoch: 48, Batch number: 28, Loss: 8134.98974609375\n",
      "Epoch: 49, Batch number: 52, Loss: 8064.125\n",
      "Epoch: 51, Batch number: 0, Loss: 7948.94775390625\n",
      "Epoch: 52, Batch number: 24, Loss: 7796.30126953125\n",
      "Epoch: 53, Batch number: 48, Loss: 7762.40185546875\n",
      "Epoch: 54, Batch number: 72, Loss: 7872.77978515625\n",
      "Epoch: 56, Batch number: 20, Loss: 7953.283203125\n",
      "Epoch: 57, Batch number: 44, Loss: 7850.68798828125\n",
      "Epoch: 58, Batch number: 68, Loss: 7932.376953125\n",
      "Epoch: 60, Batch number: 16, Loss: 7442.15283203125\n",
      "Epoch: 61, Batch number: 40, Loss: 7814.47705078125\n",
      "Epoch: 62, Batch number: 64, Loss: 7604.16162109375\n",
      "Epoch: 64, Batch number: 12, Loss: 7669.47705078125\n",
      "Epoch: 65, Batch number: 36, Loss: 7679.65771484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Batch number: 60, Loss: 7700.294921875\n",
      "Epoch: 68, Batch number: 8, Loss: 7569.92333984375\n",
      "Epoch: 69, Batch number: 32, Loss: 7584.60205078125\n",
      "Epoch: 70, Batch number: 56, Loss: 7579.87548828125\n",
      "Epoch: 72, Batch number: 4, Loss: 7596.10986328125\n",
      "Epoch: 73, Batch number: 28, Loss: 7509.80078125\n",
      "Epoch: 74, Batch number: 52, Loss: 7691.623046875\n",
      "Epoch: 76, Batch number: 0, Loss: 7496.4560546875\n",
      "Epoch: 77, Batch number: 24, Loss: 7507.11865234375\n",
      "Epoch: 78, Batch number: 48, Loss: 7533.1455078125\n",
      "Epoch: 79, Batch number: 72, Loss: 7751.4697265625\n",
      "Epoch: 81, Batch number: 20, Loss: 7339.3798828125\n",
      "Epoch: 82, Batch number: 44, Loss: 7493.5029296875\n",
      "Epoch: 83, Batch number: 68, Loss: 7622.107421875\n",
      "Epoch: 85, Batch number: 16, Loss: 7327.44775390625\n",
      "Epoch: 86, Batch number: 40, Loss: 7442.8115234375\n",
      "Epoch: 87, Batch number: 64, Loss: 7323.52197265625\n",
      "Epoch: 89, Batch number: 12, Loss: 7304.50634765625\n",
      "Epoch: 90, Batch number: 36, Loss: 7329.35595703125\n",
      "Epoch: 91, Batch number: 60, Loss: 7409.60400390625\n",
      "Epoch: 93, Batch number: 8, Loss: 7512.6875\n",
      "Epoch: 94, Batch number: 32, Loss: 7432.89990234375\n",
      "Epoch: 95, Batch number: 56, Loss: 7394.0224609375\n",
      "Epoch: 97, Batch number: 4, Loss: 7151.78173828125\n",
      "Epoch: 98, Batch number: 28, Loss: 7458.4970703125\n",
      "Epoch: 99, Batch number: 52, Loss: 7589.99169921875\n",
      "Epoch: 101, Batch number: 0, Loss: 7220.8046875\n",
      "Epoch: 102, Batch number: 24, Loss: 7355.064453125\n",
      "Epoch: 103, Batch number: 48, Loss: 7443.14306640625\n",
      "Epoch: 104, Batch number: 72, Loss: 7355.91455078125\n",
      "Epoch: 106, Batch number: 20, Loss: 7136.833984375\n",
      "Epoch: 107, Batch number: 44, Loss: 7182.9091796875\n",
      "Epoch: 108, Batch number: 68, Loss: 7615.4794921875\n",
      "Epoch: 110, Batch number: 16, Loss: 7213.6611328125\n",
      "Epoch: 111, Batch number: 40, Loss: 7082.56787109375\n",
      "Epoch: 112, Batch number: 64, Loss: 7473.8759765625\n",
      "Epoch: 114, Batch number: 12, Loss: 7310.93505859375\n",
      "Epoch: 115, Batch number: 36, Loss: 7263.72607421875\n",
      "Epoch: 116, Batch number: 60, Loss: 7479.14013671875\n",
      "Epoch: 118, Batch number: 8, Loss: 6916.30078125\n",
      "Epoch: 119, Batch number: 32, Loss: 7428.521484375\n",
      "Epoch: 120, Batch number: 56, Loss: 7056.97216796875\n",
      "Epoch: 122, Batch number: 4, Loss: 7176.12939453125\n",
      "Epoch: 123, Batch number: 28, Loss: 7111.31982421875\n",
      "Epoch: 124, Batch number: 52, Loss: 7249.14013671875\n",
      "Epoch: 126, Batch number: 0, Loss: 6903.65771484375\n",
      "Epoch: 127, Batch number: 24, Loss: 7005.75439453125\n",
      "Epoch: 128, Batch number: 48, Loss: 7215.1962890625\n",
      "Epoch: 129, Batch number: 72, Loss: 7206.32421875\n",
      "Epoch: 131, Batch number: 20, Loss: 7120.0361328125\n",
      "Epoch: 132, Batch number: 44, Loss: 7029.11376953125\n",
      "Epoch: 133, Batch number: 68, Loss: 7184.5830078125\n",
      "Epoch: 135, Batch number: 16, Loss: 7468.16455078125\n",
      "Epoch: 136, Batch number: 40, Loss: 7184.81982421875\n",
      "Epoch: 137, Batch number: 64, Loss: 7041.626953125\n",
      "Epoch: 139, Batch number: 12, Loss: 7109.431640625\n",
      "Epoch: 140, Batch number: 36, Loss: 7058.15478515625\n",
      "Epoch: 141, Batch number: 60, Loss: 7012.53515625\n",
      "Epoch: 143, Batch number: 8, Loss: 6940.259765625\n",
      "Epoch: 144, Batch number: 32, Loss: 6804.33544921875\n",
      "Epoch: 145, Batch number: 56, Loss: 7021.05419921875\n",
      "Epoch: 147, Batch number: 4, Loss: 7030.77978515625\n",
      "Epoch: 148, Batch number: 28, Loss: 6857.798828125\n",
      "Epoch: 149, Batch number: 52, Loss: 7296.33447265625\n",
      "Epoch: 151, Batch number: 0, Loss: 6988.41748046875\n",
      "Epoch: 152, Batch number: 24, Loss: 6682.20556640625\n",
      "Epoch: 153, Batch number: 48, Loss: 6865.8388671875\n",
      "Epoch: 154, Batch number: 72, Loss: 7058.91064453125\n",
      "Epoch: 156, Batch number: 20, Loss: 7449.4130859375\n",
      "Epoch: 157, Batch number: 44, Loss: 6983.2373046875\n",
      "Epoch: 158, Batch number: 68, Loss: 6960.41650390625\n",
      "Epoch: 160, Batch number: 16, Loss: 7039.36376953125\n",
      "Epoch: 161, Batch number: 40, Loss: 7121.37548828125\n",
      "Epoch: 162, Batch number: 64, Loss: 7197.22900390625\n",
      "Epoch: 164, Batch number: 12, Loss: 6877.7548828125\n",
      "Epoch: 165, Batch number: 36, Loss: 7239.91357421875\n",
      "Epoch: 166, Batch number: 60, Loss: 7240.11767578125\n",
      "Epoch: 168, Batch number: 8, Loss: 6843.0400390625\n",
      "Epoch: 169, Batch number: 32, Loss: 7002.890625\n",
      "Epoch: 170, Batch number: 56, Loss: 7131.80810546875\n",
      "Epoch: 172, Batch number: 4, Loss: 7032.1142578125\n",
      "Epoch: 173, Batch number: 28, Loss: 6981.21240234375\n",
      "Epoch: 174, Batch number: 52, Loss: 7080.88671875\n",
      "Epoch: 176, Batch number: 0, Loss: 6955.388671875\n",
      "Epoch: 177, Batch number: 24, Loss: 6897.0732421875\n",
      "Epoch: 178, Batch number: 48, Loss: 6846.1806640625\n",
      "Epoch: 179, Batch number: 72, Loss: 6906.2255859375\n",
      "Epoch: 181, Batch number: 20, Loss: 7183.2158203125\n",
      "Epoch: 182, Batch number: 44, Loss: 6974.22607421875\n",
      "Epoch: 183, Batch number: 68, Loss: 7178.13037109375\n",
      "Epoch: 185, Batch number: 16, Loss: 6819.23046875\n",
      "Epoch: 186, Batch number: 40, Loss: 7188.220703125\n",
      "Epoch: 187, Batch number: 64, Loss: 7083.05322265625\n",
      "Epoch: 189, Batch number: 12, Loss: 6909.71630859375\n",
      "Epoch: 190, Batch number: 36, Loss: 7034.4375\n",
      "Epoch: 191, Batch number: 60, Loss: 6970.3046875\n",
      "Epoch: 193, Batch number: 8, Loss: 6881.2412109375\n",
      "Epoch: 194, Batch number: 32, Loss: 6927.916015625\n",
      "Epoch: 195, Batch number: 56, Loss: 7308.12060546875\n",
      "Epoch: 197, Batch number: 4, Loss: 7070.97705078125\n",
      "Epoch: 198, Batch number: 28, Loss: 6980.6005859375\n",
      "Epoch: 199, Batch number: 52, Loss: 7149.56005859375\n",
      "Epoch: 201, Batch number: 0, Loss: 6865.7109375\n",
      "Epoch: 202, Batch number: 24, Loss: 6931.23876953125\n",
      "Epoch: 203, Batch number: 48, Loss: 6728.84619140625\n",
      "Epoch: 204, Batch number: 72, Loss: 7115.99267578125\n",
      "Epoch: 206, Batch number: 20, Loss: 6861.6201171875\n",
      "Epoch: 207, Batch number: 44, Loss: 6791.17822265625\n",
      "Epoch: 208, Batch number: 68, Loss: 6962.16064453125\n",
      "Epoch: 210, Batch number: 16, Loss: 6735.478515625\n",
      "Epoch: 211, Batch number: 40, Loss: 6979.9091796875\n",
      "Epoch: 212, Batch number: 64, Loss: 7116.13134765625\n",
      "Epoch: 214, Batch number: 12, Loss: 6790.021484375\n",
      "Epoch: 215, Batch number: 36, Loss: 7180.099609375\n",
      "Epoch: 216, Batch number: 60, Loss: 6998.87744140625\n",
      "Epoch: 218, Batch number: 8, Loss: 6784.84619140625\n",
      "Epoch: 219, Batch number: 32, Loss: 7186.91259765625\n",
      "Epoch: 220, Batch number: 56, Loss: 7140.7919921875\n",
      "Epoch: 222, Batch number: 4, Loss: 7188.138671875\n",
      "Epoch: 223, Batch number: 28, Loss: 6952.408203125\n",
      "Epoch: 224, Batch number: 52, Loss: 6859.2412109375\n",
      "Epoch: 226, Batch number: 0, Loss: 6879.52734375\n",
      "Epoch: 227, Batch number: 24, Loss: 6967.4091796875\n",
      "Epoch: 228, Batch number: 48, Loss: 7108.1005859375\n",
      "Epoch: 229, Batch number: 72, Loss: 7091.6259765625\n",
      "Epoch: 231, Batch number: 20, Loss: 6986.376953125\n",
      "Epoch: 232, Batch number: 44, Loss: 6955.779296875\n",
      "Epoch: 233, Batch number: 68, Loss: 7102.5673828125\n",
      "Epoch: 235, Batch number: 16, Loss: 6966.01708984375\n",
      "Epoch: 236, Batch number: 40, Loss: 6916.62353515625\n",
      "Epoch: 237, Batch number: 64, Loss: 7262.48681640625\n",
      "Epoch: 239, Batch number: 12, Loss: 7195.046875\n",
      "Epoch: 240, Batch number: 36, Loss: 7097.29052734375\n",
      "Epoch: 241, Batch number: 60, Loss: 7221.19189453125\n",
      "Epoch: 243, Batch number: 8, Loss: 7255.34619140625\n",
      "Epoch: 244, Batch number: 32, Loss: 7056.72119140625\n",
      "Epoch: 245, Batch number: 56, Loss: 7121.51025390625\n",
      "Epoch: 247, Batch number: 4, Loss: 6785.20263671875\n",
      "Epoch: 248, Batch number: 28, Loss: 6601.3388671875\n",
      "Epoch: 249, Batch number: 52, Loss: 6967.72119140625\n",
      "Epoch: 251, Batch number: 0, Loss: 6849.37060546875\n",
      "Epoch: 252, Batch number: 24, Loss: 6904.27783203125\n",
      "Epoch: 253, Batch number: 48, Loss: 7082.5830078125\n",
      "Epoch: 254, Batch number: 72, Loss: 6727.80908203125\n",
      "Epoch: 256, Batch number: 20, Loss: 7187.7705078125\n",
      "Epoch: 257, Batch number: 44, Loss: 6819.56640625\n",
      "Epoch: 258, Batch number: 68, Loss: 7094.923828125\n",
      "Epoch: 260, Batch number: 16, Loss: 7274.57080078125\n",
      "Epoch: 261, Batch number: 40, Loss: 7050.81494140625\n",
      "Epoch: 262, Batch number: 64, Loss: 7047.224609375\n",
      "Epoch: 264, Batch number: 12, Loss: 6682.7822265625\n",
      "Epoch: 265, Batch number: 36, Loss: 7063.88427734375\n",
      "Epoch: 266, Batch number: 60, Loss: 6941.2900390625\n",
      "Epoch: 268, Batch number: 8, Loss: 6897.1171875\n",
      "Epoch: 269, Batch number: 32, Loss: 7004.96875\n",
      "Epoch: 270, Batch number: 56, Loss: 7167.39892578125\n",
      "Epoch: 272, Batch number: 4, Loss: 6956.60498046875\n",
      "Epoch: 273, Batch number: 28, Loss: 6812.7275390625\n",
      "Epoch: 274, Batch number: 52, Loss: 7001.61376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 276, Batch number: 0, Loss: 6843.5341796875\n",
      "Epoch: 277, Batch number: 24, Loss: 6801.7060546875\n",
      "Epoch: 278, Batch number: 48, Loss: 7001.89306640625\n",
      "Epoch: 279, Batch number: 72, Loss: 7091.8828125\n",
      "Epoch: 281, Batch number: 20, Loss: 6917.146484375\n",
      "Epoch: 282, Batch number: 44, Loss: 7173.71728515625\n",
      "Epoch: 283, Batch number: 68, Loss: 7088.16259765625\n",
      "Epoch: 285, Batch number: 16, Loss: 6858.61181640625\n",
      "Epoch: 286, Batch number: 40, Loss: 7223.5244140625\n",
      "Epoch: 287, Batch number: 64, Loss: 7222.2998046875\n",
      "Epoch: 289, Batch number: 12, Loss: 6936.51416015625\n",
      "Epoch: 290, Batch number: 36, Loss: 7045.87255859375\n",
      "Epoch: 291, Batch number: 60, Loss: 6911.296875\n",
      "Epoch: 293, Batch number: 8, Loss: 6986.26708984375\n",
      "Epoch: 294, Batch number: 32, Loss: 7214.3828125\n",
      "Epoch: 295, Batch number: 56, Loss: 7081.7099609375\n",
      "Epoch: 297, Batch number: 4, Loss: 6805.55126953125\n",
      "Epoch: 298, Batch number: 28, Loss: 6870.29150390625\n",
      "Epoch: 299, Batch number: 52, Loss: 6661.97607421875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15344.548828125\n",
      "Epoch: 2, Batch number: 24, Loss: 13992.619140625\n",
      "Epoch: 3, Batch number: 48, Loss: 13403.416015625\n",
      "Epoch: 4, Batch number: 72, Loss: 12480.70703125\n",
      "Epoch: 6, Batch number: 20, Loss: 12078.6181640625\n",
      "Epoch: 7, Batch number: 44, Loss: 11631.734375\n",
      "Epoch: 8, Batch number: 68, Loss: 11143.7666015625\n",
      "Epoch: 10, Batch number: 16, Loss: 10778.3310546875\n",
      "Epoch: 11, Batch number: 40, Loss: 10559.048828125\n",
      "Epoch: 12, Batch number: 64, Loss: 10066.865234375\n",
      "Epoch: 14, Batch number: 12, Loss: 9903.9169921875\n",
      "Epoch: 15, Batch number: 36, Loss: 9804.064453125\n",
      "Epoch: 16, Batch number: 60, Loss: 9612.6259765625\n",
      "Epoch: 18, Batch number: 8, Loss: 9120.8515625\n",
      "Epoch: 19, Batch number: 32, Loss: 9201.6572265625\n",
      "Epoch: 20, Batch number: 56, Loss: 9089.900390625\n",
      "Epoch: 22, Batch number: 4, Loss: 8748.43359375\n",
      "Epoch: 23, Batch number: 28, Loss: 8763.8046875\n",
      "Epoch: 24, Batch number: 52, Loss: 8763.431640625\n",
      "Epoch: 26, Batch number: 0, Loss: 8396.6357421875\n",
      "Epoch: 27, Batch number: 24, Loss: 8449.5205078125\n",
      "Epoch: 28, Batch number: 48, Loss: 8332.0205078125\n",
      "Epoch: 29, Batch number: 72, Loss: 8173.99267578125\n",
      "Epoch: 31, Batch number: 20, Loss: 8172.7265625\n",
      "Epoch: 32, Batch number: 44, Loss: 8081.14111328125\n",
      "Epoch: 33, Batch number: 68, Loss: 8158.2568359375\n",
      "Epoch: 35, Batch number: 16, Loss: 8237.7275390625\n",
      "Epoch: 36, Batch number: 40, Loss: 7752.74755859375\n",
      "Epoch: 37, Batch number: 64, Loss: 8117.697265625\n",
      "Epoch: 39, Batch number: 12, Loss: 7960.884765625\n",
      "Epoch: 40, Batch number: 36, Loss: 7992.74267578125\n",
      "Epoch: 41, Batch number: 60, Loss: 7984.26513671875\n",
      "Epoch: 43, Batch number: 8, Loss: 7747.333984375\n",
      "Epoch: 44, Batch number: 32, Loss: 7820.87841796875\n",
      "Epoch: 45, Batch number: 56, Loss: 8003.443359375\n",
      "Epoch: 47, Batch number: 4, Loss: 7855.228515625\n",
      "Epoch: 48, Batch number: 28, Loss: 7845.119140625\n",
      "Epoch: 49, Batch number: 52, Loss: 7605.2236328125\n",
      "Epoch: 51, Batch number: 0, Loss: 7998.18505859375\n",
      "Epoch: 52, Batch number: 24, Loss: 7642.29248046875\n",
      "Epoch: 53, Batch number: 48, Loss: 7475.4462890625\n",
      "Epoch: 54, Batch number: 72, Loss: 7671.86376953125\n",
      "Epoch: 56, Batch number: 20, Loss: 7510.49755859375\n",
      "Epoch: 57, Batch number: 44, Loss: 7564.37158203125\n",
      "Epoch: 58, Batch number: 68, Loss: 7654.83740234375\n",
      "Epoch: 60, Batch number: 16, Loss: 7714.162109375\n",
      "Epoch: 61, Batch number: 40, Loss: 7572.3212890625\n",
      "Epoch: 62, Batch number: 64, Loss: 7440.08642578125\n",
      "Epoch: 64, Batch number: 12, Loss: 7363.23974609375\n",
      "Epoch: 65, Batch number: 36, Loss: 7743.0732421875\n",
      "Epoch: 66, Batch number: 60, Loss: 7602.24267578125\n",
      "Epoch: 68, Batch number: 8, Loss: 7405.73828125\n",
      "Epoch: 69, Batch number: 32, Loss: 7295.169921875\n",
      "Epoch: 70, Batch number: 56, Loss: 7340.2333984375\n",
      "Epoch: 72, Batch number: 4, Loss: 7233.5751953125\n",
      "Epoch: 73, Batch number: 28, Loss: 7389.4951171875\n",
      "Epoch: 74, Batch number: 52, Loss: 7323.02001953125\n",
      "Epoch: 76, Batch number: 0, Loss: 7105.65283203125\n",
      "Epoch: 77, Batch number: 24, Loss: 7217.328125\n",
      "Epoch: 78, Batch number: 48, Loss: 7247.9150390625\n",
      "Epoch: 79, Batch number: 72, Loss: 7389.6982421875\n",
      "Epoch: 81, Batch number: 20, Loss: 7158.03857421875\n",
      "Epoch: 82, Batch number: 44, Loss: 7214.79443359375\n",
      "Epoch: 83, Batch number: 68, Loss: 7562.92041015625\n",
      "Epoch: 85, Batch number: 16, Loss: 7176.9541015625\n",
      "Epoch: 86, Batch number: 40, Loss: 7294.48193359375\n",
      "Epoch: 87, Batch number: 64, Loss: 7471.6533203125\n",
      "Epoch: 89, Batch number: 12, Loss: 7163.8916015625\n",
      "Epoch: 90, Batch number: 36, Loss: 7340.45751953125\n",
      "Epoch: 91, Batch number: 60, Loss: 7505.72607421875\n",
      "Epoch: 93, Batch number: 8, Loss: 7313.7216796875\n",
      "Epoch: 94, Batch number: 32, Loss: 7187.9609375\n",
      "Epoch: 95, Batch number: 56, Loss: 7232.3115234375\n",
      "Epoch: 97, Batch number: 4, Loss: 7235.60595703125\n",
      "Epoch: 98, Batch number: 28, Loss: 6936.22265625\n",
      "Epoch: 99, Batch number: 52, Loss: 7156.3818359375\n",
      "Epoch: 101, Batch number: 0, Loss: 6898.5390625\n",
      "Epoch: 102, Batch number: 24, Loss: 7302.83642578125\n",
      "Epoch: 103, Batch number: 48, Loss: 7405.177734375\n",
      "Epoch: 104, Batch number: 72, Loss: 7035.9765625\n",
      "Epoch: 106, Batch number: 20, Loss: 7147.25244140625\n",
      "Epoch: 107, Batch number: 44, Loss: 7476.27392578125\n",
      "Epoch: 108, Batch number: 68, Loss: 6920.1181640625\n",
      "Epoch: 110, Batch number: 16, Loss: 7245.341796875\n",
      "Epoch: 111, Batch number: 40, Loss: 7194.552734375\n",
      "Epoch: 112, Batch number: 64, Loss: 7166.15966796875\n",
      "Epoch: 114, Batch number: 12, Loss: 7100.7275390625\n",
      "Epoch: 115, Batch number: 36, Loss: 7307.43212890625\n",
      "Epoch: 116, Batch number: 60, Loss: 7143.1494140625\n",
      "Epoch: 118, Batch number: 8, Loss: 6934.38818359375\n",
      "Epoch: 119, Batch number: 32, Loss: 6830.25048828125\n",
      "Epoch: 120, Batch number: 56, Loss: 7254.998046875\n",
      "Epoch: 122, Batch number: 4, Loss: 7196.76904296875\n",
      "Epoch: 123, Batch number: 28, Loss: 7006.9384765625\n",
      "Epoch: 124, Batch number: 52, Loss: 7104.04833984375\n",
      "Epoch: 126, Batch number: 0, Loss: 6951.48974609375\n",
      "Epoch: 127, Batch number: 24, Loss: 7131.11767578125\n",
      "Epoch: 128, Batch number: 48, Loss: 7204.37939453125\n",
      "Epoch: 129, Batch number: 72, Loss: 7002.92041015625\n",
      "Epoch: 131, Batch number: 20, Loss: 7002.04052734375\n",
      "Epoch: 132, Batch number: 44, Loss: 7184.42333984375\n",
      "Epoch: 133, Batch number: 68, Loss: 6997.8671875\n",
      "Epoch: 135, Batch number: 16, Loss: 7156.4033203125\n",
      "Epoch: 136, Batch number: 40, Loss: 7152.59912109375\n",
      "Epoch: 137, Batch number: 64, Loss: 7078.2822265625\n",
      "Epoch: 139, Batch number: 12, Loss: 6982.03271484375\n",
      "Epoch: 140, Batch number: 36, Loss: 7112.18701171875\n",
      "Epoch: 141, Batch number: 60, Loss: 7219.34423828125\n",
      "Epoch: 143, Batch number: 8, Loss: 6832.0234375\n",
      "Epoch: 144, Batch number: 32, Loss: 6870.0283203125\n",
      "Epoch: 145, Batch number: 56, Loss: 7223.01953125\n",
      "Epoch: 147, Batch number: 4, Loss: 6801.58154296875\n",
      "Epoch: 148, Batch number: 28, Loss: 7089.4775390625\n",
      "Epoch: 149, Batch number: 52, Loss: 6844.78515625\n",
      "Epoch: 151, Batch number: 0, Loss: 6818.2138671875\n",
      "Epoch: 152, Batch number: 24, Loss: 7085.0263671875\n",
      "Epoch: 153, Batch number: 48, Loss: 7294.9345703125\n",
      "Epoch: 154, Batch number: 72, Loss: 7172.25927734375\n",
      "Epoch: 156, Batch number: 20, Loss: 7021.6513671875\n",
      "Epoch: 157, Batch number: 44, Loss: 7072.990234375\n",
      "Epoch: 158, Batch number: 68, Loss: 6982.8154296875\n",
      "Epoch: 160, Batch number: 16, Loss: 7105.57177734375\n",
      "Epoch: 161, Batch number: 40, Loss: 6994.927734375\n",
      "Epoch: 162, Batch number: 64, Loss: 7179.60986328125\n",
      "Epoch: 164, Batch number: 12, Loss: 7115.46240234375\n",
      "Epoch: 165, Batch number: 36, Loss: 7125.029296875\n",
      "Epoch: 166, Batch number: 60, Loss: 7032.0888671875\n",
      "Epoch: 168, Batch number: 8, Loss: 6982.15771484375\n",
      "Epoch: 169, Batch number: 32, Loss: 7102.490234375\n",
      "Epoch: 170, Batch number: 56, Loss: 7111.6337890625\n",
      "Epoch: 172, Batch number: 4, Loss: 7004.95166015625\n",
      "Epoch: 173, Batch number: 28, Loss: 7150.0146484375\n",
      "Epoch: 174, Batch number: 52, Loss: 6991.49853515625\n",
      "Epoch: 176, Batch number: 0, Loss: 6735.7841796875\n",
      "Epoch: 177, Batch number: 24, Loss: 6894.89111328125\n",
      "Epoch: 178, Batch number: 48, Loss: 7006.5068359375\n",
      "Epoch: 179, Batch number: 72, Loss: 7022.76025390625\n",
      "Epoch: 181, Batch number: 20, Loss: 7121.8701171875\n",
      "Epoch: 182, Batch number: 44, Loss: 7202.0439453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 183, Batch number: 68, Loss: 7142.2861328125\n",
      "Epoch: 185, Batch number: 16, Loss: 7011.26318359375\n",
      "Epoch: 186, Batch number: 40, Loss: 6785.9326171875\n",
      "Epoch: 187, Batch number: 64, Loss: 7020.30712890625\n",
      "Epoch: 189, Batch number: 12, Loss: 6884.27490234375\n",
      "Epoch: 190, Batch number: 36, Loss: 7115.30615234375\n",
      "Epoch: 191, Batch number: 60, Loss: 7137.5166015625\n",
      "Epoch: 193, Batch number: 8, Loss: 7072.4970703125\n",
      "Epoch: 194, Batch number: 32, Loss: 6832.15673828125\n",
      "Epoch: 195, Batch number: 56, Loss: 7135.1123046875\n",
      "Epoch: 197, Batch number: 4, Loss: 6816.06884765625\n",
      "Epoch: 198, Batch number: 28, Loss: 7113.265625\n",
      "Epoch: 199, Batch number: 52, Loss: 7098.56787109375\n",
      "Epoch: 201, Batch number: 0, Loss: 6886.84130859375\n",
      "Epoch: 202, Batch number: 24, Loss: 6669.67041015625\n",
      "Epoch: 203, Batch number: 48, Loss: 7064.98095703125\n",
      "Epoch: 204, Batch number: 72, Loss: 6915.13330078125\n",
      "Epoch: 206, Batch number: 20, Loss: 6973.14794921875\n",
      "Epoch: 207, Batch number: 44, Loss: 7116.51708984375\n",
      "Epoch: 208, Batch number: 68, Loss: 7105.90380859375\n",
      "Epoch: 210, Batch number: 16, Loss: 7001.49853515625\n",
      "Epoch: 211, Batch number: 40, Loss: 6893.37109375\n",
      "Epoch: 212, Batch number: 64, Loss: 7185.22802734375\n",
      "Epoch: 214, Batch number: 12, Loss: 6981.7978515625\n",
      "Epoch: 215, Batch number: 36, Loss: 7184.99169921875\n",
      "Epoch: 216, Batch number: 60, Loss: 7014.96337890625\n",
      "Epoch: 218, Batch number: 8, Loss: 7070.70068359375\n",
      "Epoch: 219, Batch number: 32, Loss: 6836.91943359375\n",
      "Epoch: 220, Batch number: 56, Loss: 6875.830078125\n",
      "Epoch: 222, Batch number: 4, Loss: 6813.22900390625\n",
      "Epoch: 223, Batch number: 28, Loss: 7196.63818359375\n",
      "Epoch: 224, Batch number: 52, Loss: 7144.5576171875\n",
      "Epoch: 226, Batch number: 0, Loss: 6752.99658203125\n",
      "Epoch: 227, Batch number: 24, Loss: 7032.91552734375\n",
      "Epoch: 228, Batch number: 48, Loss: 6990.39013671875\n",
      "Epoch: 229, Batch number: 72, Loss: 7107.12548828125\n",
      "Epoch: 231, Batch number: 20, Loss: 7247.50390625\n",
      "Epoch: 232, Batch number: 44, Loss: 6775.353515625\n",
      "Epoch: 233, Batch number: 68, Loss: 7017.94677734375\n",
      "Epoch: 235, Batch number: 16, Loss: 7087.5283203125\n",
      "Epoch: 236, Batch number: 40, Loss: 7001.3251953125\n",
      "Epoch: 237, Batch number: 64, Loss: 7116.33251953125\n",
      "Epoch: 239, Batch number: 12, Loss: 6788.66650390625\n",
      "Epoch: 240, Batch number: 36, Loss: 6791.80224609375\n",
      "Epoch: 241, Batch number: 60, Loss: 7177.98779296875\n",
      "Epoch: 243, Batch number: 8, Loss: 7172.77490234375\n",
      "Epoch: 244, Batch number: 32, Loss: 6757.4033203125\n",
      "Epoch: 245, Batch number: 56, Loss: 6781.28564453125\n",
      "Epoch: 247, Batch number: 4, Loss: 7241.9462890625\n",
      "Epoch: 248, Batch number: 28, Loss: 7112.47265625\n",
      "Epoch: 249, Batch number: 52, Loss: 7402.78564453125\n",
      "Epoch: 251, Batch number: 0, Loss: 6995.466796875\n",
      "Epoch: 252, Batch number: 24, Loss: 6875.70849609375\n",
      "Epoch: 253, Batch number: 48, Loss: 7108.12158203125\n",
      "Epoch: 254, Batch number: 72, Loss: 6972.04443359375\n",
      "Epoch: 256, Batch number: 20, Loss: 6855.046875\n",
      "Epoch: 257, Batch number: 44, Loss: 7087.44873046875\n",
      "Epoch: 258, Batch number: 68, Loss: 6857.169921875\n",
      "Epoch: 260, Batch number: 16, Loss: 6924.60791015625\n",
      "Epoch: 261, Batch number: 40, Loss: 6971.15380859375\n",
      "Epoch: 262, Batch number: 64, Loss: 7154.9228515625\n",
      "Epoch: 264, Batch number: 12, Loss: 6905.5126953125\n",
      "Epoch: 265, Batch number: 36, Loss: 7264.40087890625\n",
      "Epoch: 266, Batch number: 60, Loss: 7298.03466796875\n",
      "Epoch: 268, Batch number: 8, Loss: 6899.79150390625\n",
      "Epoch: 269, Batch number: 32, Loss: 7236.3408203125\n",
      "Epoch: 270, Batch number: 56, Loss: 7274.8798828125\n",
      "Epoch: 272, Batch number: 4, Loss: 7016.19775390625\n",
      "Epoch: 273, Batch number: 28, Loss: 6712.466796875\n",
      "Epoch: 274, Batch number: 52, Loss: 6886.91796875\n",
      "Epoch: 276, Batch number: 0, Loss: 6833.49072265625\n",
      "Epoch: 277, Batch number: 24, Loss: 7137.20263671875\n",
      "Epoch: 278, Batch number: 48, Loss: 6906.474609375\n",
      "Epoch: 279, Batch number: 72, Loss: 7003.02099609375\n",
      "Epoch: 281, Batch number: 20, Loss: 7029.0966796875\n",
      "Epoch: 282, Batch number: 44, Loss: 6978.27734375\n",
      "Epoch: 283, Batch number: 68, Loss: 6778.89404296875\n",
      "Epoch: 285, Batch number: 16, Loss: 6956.23779296875\n",
      "Epoch: 286, Batch number: 40, Loss: 6993.1220703125\n",
      "Epoch: 287, Batch number: 64, Loss: 7219.45849609375\n",
      "Epoch: 289, Batch number: 12, Loss: 7129.212890625\n",
      "Epoch: 290, Batch number: 36, Loss: 6948.13916015625\n",
      "Epoch: 291, Batch number: 60, Loss: 6660.2216796875\n",
      "Epoch: 293, Batch number: 8, Loss: 7030.3798828125\n",
      "Epoch: 294, Batch number: 32, Loss: 6988.65869140625\n",
      "Epoch: 295, Batch number: 56, Loss: 7131.49609375\n",
      "Epoch: 297, Batch number: 4, Loss: 6985.36669921875\n",
      "Epoch: 298, Batch number: 28, Loss: 6966.9453125\n",
      "Epoch: 299, Batch number: 52, Loss: 6942.48486328125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15262.2412109375\n",
      "Epoch: 2, Batch number: 24, Loss: 13576.564453125\n",
      "Epoch: 3, Batch number: 48, Loss: 12797.5693359375\n",
      "Epoch: 4, Batch number: 72, Loss: 12342.791015625\n",
      "Epoch: 6, Batch number: 20, Loss: 11330.2666015625\n",
      "Epoch: 7, Batch number: 44, Loss: 10801.7333984375\n",
      "Epoch: 8, Batch number: 68, Loss: 10542.4814453125\n",
      "Epoch: 10, Batch number: 16, Loss: 10107.923828125\n",
      "Epoch: 11, Batch number: 40, Loss: 9655.5693359375\n",
      "Epoch: 12, Batch number: 64, Loss: 9676.39453125\n",
      "Epoch: 14, Batch number: 12, Loss: 9039.0087890625\n",
      "Epoch: 15, Batch number: 36, Loss: 8898.693359375\n",
      "Epoch: 16, Batch number: 60, Loss: 8811.146484375\n",
      "Epoch: 18, Batch number: 8, Loss: 8535.2421875\n",
      "Epoch: 19, Batch number: 32, Loss: 8363.3583984375\n",
      "Epoch: 20, Batch number: 56, Loss: 8317.552734375\n",
      "Epoch: 22, Batch number: 4, Loss: 8018.880859375\n",
      "Epoch: 23, Batch number: 28, Loss: 8110.0859375\n",
      "Epoch: 24, Batch number: 52, Loss: 8184.85546875\n",
      "Epoch: 26, Batch number: 0, Loss: 8036.37744140625\n",
      "Epoch: 27, Batch number: 24, Loss: 7814.07275390625\n",
      "Epoch: 28, Batch number: 48, Loss: 7966.76708984375\n",
      "Epoch: 29, Batch number: 72, Loss: 7867.95654296875\n",
      "Epoch: 31, Batch number: 20, Loss: 7620.2919921875\n",
      "Epoch: 32, Batch number: 44, Loss: 7956.91357421875\n",
      "Epoch: 33, Batch number: 68, Loss: 7825.95068359375\n",
      "Epoch: 35, Batch number: 16, Loss: 7616.04443359375\n",
      "Epoch: 36, Batch number: 40, Loss: 7972.2900390625\n",
      "Epoch: 37, Batch number: 64, Loss: 7569.89599609375\n",
      "Epoch: 39, Batch number: 12, Loss: 7714.0185546875\n",
      "Epoch: 40, Batch number: 36, Loss: 7434.49365234375\n",
      "Epoch: 41, Batch number: 60, Loss: 7535.9697265625\n",
      "Epoch: 43, Batch number: 8, Loss: 7598.38916015625\n",
      "Epoch: 44, Batch number: 32, Loss: 7368.36572265625\n",
      "Epoch: 45, Batch number: 56, Loss: 7650.82861328125\n",
      "Epoch: 47, Batch number: 4, Loss: 7227.01904296875\n",
      "Epoch: 48, Batch number: 28, Loss: 7546.59765625\n",
      "Epoch: 49, Batch number: 52, Loss: 7475.69580078125\n",
      "Epoch: 51, Batch number: 0, Loss: 7350.96142578125\n",
      "Epoch: 52, Batch number: 24, Loss: 7216.966796875\n",
      "Epoch: 53, Batch number: 48, Loss: 7178.98095703125\n",
      "Epoch: 54, Batch number: 72, Loss: 7424.666015625\n",
      "Epoch: 56, Batch number: 20, Loss: 7386.58642578125\n",
      "Epoch: 57, Batch number: 44, Loss: 7273.431640625\n",
      "Epoch: 58, Batch number: 68, Loss: 7431.65625\n",
      "Epoch: 60, Batch number: 16, Loss: 7480.9775390625\n",
      "Epoch: 61, Batch number: 40, Loss: 7217.67041015625\n",
      "Epoch: 62, Batch number: 64, Loss: 7224.484375\n",
      "Epoch: 64, Batch number: 12, Loss: 7182.62060546875\n",
      "Epoch: 65, Batch number: 36, Loss: 7281.1943359375\n",
      "Epoch: 66, Batch number: 60, Loss: 7672.59619140625\n",
      "Epoch: 68, Batch number: 8, Loss: 7204.8994140625\n",
      "Epoch: 69, Batch number: 32, Loss: 7220.076171875\n",
      "Epoch: 70, Batch number: 56, Loss: 7272.3583984375\n",
      "Epoch: 72, Batch number: 4, Loss: 7331.7138671875\n",
      "Epoch: 73, Batch number: 28, Loss: 7085.20947265625\n",
      "Epoch: 74, Batch number: 52, Loss: 7353.64404296875\n",
      "Epoch: 76, Batch number: 0, Loss: 7056.45947265625\n",
      "Epoch: 77, Batch number: 24, Loss: 7106.3837890625\n",
      "Epoch: 78, Batch number: 48, Loss: 7303.11181640625\n",
      "Epoch: 79, Batch number: 72, Loss: 7124.3994140625\n",
      "Epoch: 81, Batch number: 20, Loss: 6898.814453125\n",
      "Epoch: 82, Batch number: 44, Loss: 7236.326171875\n",
      "Epoch: 83, Batch number: 68, Loss: 6993.3154296875\n",
      "Epoch: 85, Batch number: 16, Loss: 7067.3935546875\n",
      "Epoch: 86, Batch number: 40, Loss: 7141.46826171875\n",
      "Epoch: 87, Batch number: 64, Loss: 7231.177734375\n",
      "Epoch: 89, Batch number: 12, Loss: 7090.25048828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Batch number: 36, Loss: 7016.4599609375\n",
      "Epoch: 91, Batch number: 60, Loss: 7320.8369140625\n",
      "Epoch: 93, Batch number: 8, Loss: 7249.98876953125\n",
      "Epoch: 94, Batch number: 32, Loss: 7048.48779296875\n",
      "Epoch: 95, Batch number: 56, Loss: 7055.91015625\n",
      "Epoch: 97, Batch number: 4, Loss: 7195.0341796875\n",
      "Epoch: 98, Batch number: 28, Loss: 7190.025390625\n",
      "Epoch: 99, Batch number: 52, Loss: 6984.09130859375\n",
      "Epoch: 101, Batch number: 0, Loss: 6914.20947265625\n",
      "Epoch: 102, Batch number: 24, Loss: 6915.57958984375\n",
      "Epoch: 103, Batch number: 48, Loss: 7036.16455078125\n",
      "Epoch: 104, Batch number: 72, Loss: 7215.63330078125\n",
      "Epoch: 106, Batch number: 20, Loss: 7191.662109375\n",
      "Epoch: 107, Batch number: 44, Loss: 7342.54736328125\n",
      "Epoch: 108, Batch number: 68, Loss: 7316.33837890625\n",
      "Epoch: 110, Batch number: 16, Loss: 6922.43115234375\n",
      "Epoch: 111, Batch number: 40, Loss: 7077.66748046875\n",
      "Epoch: 112, Batch number: 64, Loss: 7088.05810546875\n",
      "Epoch: 114, Batch number: 12, Loss: 7066.47265625\n",
      "Epoch: 115, Batch number: 36, Loss: 6900.97509765625\n",
      "Epoch: 116, Batch number: 60, Loss: 7112.43994140625\n",
      "Epoch: 118, Batch number: 8, Loss: 7049.13818359375\n",
      "Epoch: 119, Batch number: 32, Loss: 7021.7265625\n",
      "Epoch: 120, Batch number: 56, Loss: 7204.70458984375\n",
      "Epoch: 122, Batch number: 4, Loss: 7065.02587890625\n",
      "Epoch: 123, Batch number: 28, Loss: 7027.611328125\n",
      "Epoch: 124, Batch number: 52, Loss: 6954.57568359375\n",
      "Epoch: 126, Batch number: 0, Loss: 6824.71435546875\n",
      "Epoch: 127, Batch number: 24, Loss: 7163.404296875\n",
      "Epoch: 128, Batch number: 48, Loss: 7373.388671875\n",
      "Epoch: 129, Batch number: 72, Loss: 6945.9931640625\n",
      "Epoch: 131, Batch number: 20, Loss: 7014.568359375\n",
      "Epoch: 132, Batch number: 44, Loss: 6834.8720703125\n",
      "Epoch: 133, Batch number: 68, Loss: 6820.81298828125\n",
      "Epoch: 135, Batch number: 16, Loss: 7002.6083984375\n",
      "Epoch: 136, Batch number: 40, Loss: 7071.6611328125\n",
      "Epoch: 137, Batch number: 64, Loss: 7138.771484375\n",
      "Epoch: 139, Batch number: 12, Loss: 6754.1640625\n",
      "Epoch: 140, Batch number: 36, Loss: 7190.15966796875\n",
      "Epoch: 141, Batch number: 60, Loss: 7249.25439453125\n",
      "Epoch: 143, Batch number: 8, Loss: 6981.34814453125\n",
      "Epoch: 144, Batch number: 32, Loss: 7182.77734375\n",
      "Epoch: 145, Batch number: 56, Loss: 7078.9609375\n",
      "Epoch: 147, Batch number: 4, Loss: 7142.30126953125\n",
      "Epoch: 148, Batch number: 28, Loss: 7197.03076171875\n",
      "Epoch: 149, Batch number: 52, Loss: 6994.76318359375\n",
      "Epoch: 151, Batch number: 0, Loss: 6780.30615234375\n",
      "Epoch: 152, Batch number: 24, Loss: 7254.61572265625\n",
      "Epoch: 153, Batch number: 48, Loss: 6932.5908203125\n",
      "Epoch: 154, Batch number: 72, Loss: 7190.4677734375\n",
      "Epoch: 156, Batch number: 20, Loss: 6974.4111328125\n",
      "Epoch: 157, Batch number: 44, Loss: 7149.0361328125\n",
      "Epoch: 158, Batch number: 68, Loss: 7287.4208984375\n",
      "Epoch: 160, Batch number: 16, Loss: 7028.453125\n",
      "Epoch: 161, Batch number: 40, Loss: 7237.07568359375\n",
      "Epoch: 162, Batch number: 64, Loss: 7047.31396484375\n",
      "Epoch: 164, Batch number: 12, Loss: 7049.28369140625\n",
      "Epoch: 165, Batch number: 36, Loss: 7097.76806640625\n",
      "Epoch: 166, Batch number: 60, Loss: 7060.16845703125\n",
      "Epoch: 168, Batch number: 8, Loss: 6853.37939453125\n",
      "Epoch: 169, Batch number: 32, Loss: 7213.2939453125\n",
      "Epoch: 170, Batch number: 56, Loss: 6889.84765625\n",
      "Epoch: 172, Batch number: 4, Loss: 6790.93017578125\n",
      "Epoch: 173, Batch number: 28, Loss: 6962.44140625\n",
      "Epoch: 174, Batch number: 52, Loss: 7105.02587890625\n",
      "Epoch: 176, Batch number: 0, Loss: 7001.83740234375\n",
      "Epoch: 177, Batch number: 24, Loss: 6934.17578125\n",
      "Epoch: 178, Batch number: 48, Loss: 7099.96240234375\n",
      "Epoch: 179, Batch number: 72, Loss: 7093.0322265625\n",
      "Epoch: 181, Batch number: 20, Loss: 6780.19091796875\n",
      "Epoch: 182, Batch number: 44, Loss: 6985.6474609375\n",
      "Epoch: 183, Batch number: 68, Loss: 7117.18359375\n",
      "Epoch: 185, Batch number: 16, Loss: 7072.29833984375\n",
      "Epoch: 186, Batch number: 40, Loss: 7001.60595703125\n",
      "Epoch: 187, Batch number: 64, Loss: 6951.52734375\n",
      "Epoch: 189, Batch number: 12, Loss: 7180.505859375\n",
      "Epoch: 190, Batch number: 36, Loss: 7075.3291015625\n",
      "Epoch: 191, Batch number: 60, Loss: 7071.365234375\n",
      "Epoch: 193, Batch number: 8, Loss: 6795.30029296875\n",
      "Epoch: 194, Batch number: 32, Loss: 6937.01513671875\n",
      "Epoch: 195, Batch number: 56, Loss: 7056.80908203125\n",
      "Epoch: 197, Batch number: 4, Loss: 7021.4189453125\n",
      "Epoch: 198, Batch number: 28, Loss: 6946.0029296875\n",
      "Epoch: 199, Batch number: 52, Loss: 6977.93798828125\n",
      "Epoch: 201, Batch number: 0, Loss: 7200.11083984375\n",
      "Epoch: 202, Batch number: 24, Loss: 6830.49951171875\n",
      "Epoch: 203, Batch number: 48, Loss: 7039.0009765625\n",
      "Epoch: 204, Batch number: 72, Loss: 7165.169921875\n",
      "Epoch: 206, Batch number: 20, Loss: 6918.30419921875\n",
      "Epoch: 207, Batch number: 44, Loss: 7140.9248046875\n",
      "Epoch: 208, Batch number: 68, Loss: 7210.3994140625\n",
      "Epoch: 210, Batch number: 16, Loss: 6677.79150390625\n",
      "Epoch: 211, Batch number: 40, Loss: 6964.32666015625\n",
      "Epoch: 212, Batch number: 64, Loss: 7362.13427734375\n",
      "Epoch: 214, Batch number: 12, Loss: 6835.82080078125\n",
      "Epoch: 215, Batch number: 36, Loss: 7093.2890625\n",
      "Epoch: 216, Batch number: 60, Loss: 7012.3955078125\n",
      "Epoch: 218, Batch number: 8, Loss: 6988.0\n",
      "Epoch: 219, Batch number: 32, Loss: 6977.01171875\n",
      "Epoch: 220, Batch number: 56, Loss: 7355.1982421875\n",
      "Epoch: 222, Batch number: 4, Loss: 6778.39501953125\n",
      "Epoch: 223, Batch number: 28, Loss: 7082.33740234375\n",
      "Epoch: 224, Batch number: 52, Loss: 7112.8671875\n",
      "Epoch: 226, Batch number: 0, Loss: 7226.77685546875\n",
      "Epoch: 227, Batch number: 24, Loss: 6907.93505859375\n",
      "Epoch: 228, Batch number: 48, Loss: 7067.8369140625\n",
      "Epoch: 229, Batch number: 72, Loss: 7050.13232421875\n",
      "Epoch: 231, Batch number: 20, Loss: 7261.10595703125\n",
      "Epoch: 232, Batch number: 44, Loss: 6876.77783203125\n",
      "Epoch: 233, Batch number: 68, Loss: 7314.54345703125\n",
      "Epoch: 235, Batch number: 16, Loss: 6937.41259765625\n",
      "Epoch: 236, Batch number: 40, Loss: 6932.3115234375\n",
      "Epoch: 237, Batch number: 64, Loss: 7167.10693359375\n",
      "Epoch: 239, Batch number: 12, Loss: 7100.25634765625\n",
      "Epoch: 240, Batch number: 36, Loss: 6940.4443359375\n",
      "Epoch: 241, Batch number: 60, Loss: 7022.86669921875\n",
      "Epoch: 243, Batch number: 8, Loss: 7086.87939453125\n",
      "Epoch: 244, Batch number: 32, Loss: 6830.07861328125\n",
      "Epoch: 245, Batch number: 56, Loss: 7015.73828125\n",
      "Epoch: 247, Batch number: 4, Loss: 6846.37841796875\n",
      "Epoch: 248, Batch number: 28, Loss: 7002.146484375\n",
      "Epoch: 249, Batch number: 52, Loss: 7288.470703125\n",
      "Epoch: 251, Batch number: 0, Loss: 7105.38818359375\n",
      "Epoch: 252, Batch number: 24, Loss: 6843.22216796875\n",
      "Epoch: 253, Batch number: 48, Loss: 7384.333984375\n",
      "Epoch: 254, Batch number: 72, Loss: 7090.96826171875\n",
      "Epoch: 256, Batch number: 20, Loss: 6839.3701171875\n",
      "Epoch: 257, Batch number: 44, Loss: 7416.20556640625\n",
      "Epoch: 258, Batch number: 68, Loss: 6940.56640625\n",
      "Epoch: 260, Batch number: 16, Loss: 6754.37890625\n",
      "Epoch: 261, Batch number: 40, Loss: 7025.66552734375\n",
      "Epoch: 262, Batch number: 64, Loss: 6976.87158203125\n",
      "Epoch: 264, Batch number: 12, Loss: 6822.923828125\n",
      "Epoch: 265, Batch number: 36, Loss: 7218.3935546875\n",
      "Epoch: 266, Batch number: 60, Loss: 7052.89990234375\n",
      "Epoch: 268, Batch number: 8, Loss: 6902.08154296875\n",
      "Epoch: 269, Batch number: 32, Loss: 6832.87548828125\n",
      "Epoch: 270, Batch number: 56, Loss: 7076.13916015625\n",
      "Epoch: 272, Batch number: 4, Loss: 6767.50732421875\n",
      "Epoch: 273, Batch number: 28, Loss: 7088.3466796875\n",
      "Epoch: 274, Batch number: 52, Loss: 7018.5\n",
      "Epoch: 276, Batch number: 0, Loss: 6983.10791015625\n",
      "Epoch: 277, Batch number: 24, Loss: 7085.9208984375\n",
      "Epoch: 278, Batch number: 48, Loss: 7070.017578125\n",
      "Epoch: 279, Batch number: 72, Loss: 7333.3330078125\n",
      "Epoch: 281, Batch number: 20, Loss: 7084.24560546875\n",
      "Epoch: 282, Batch number: 44, Loss: 7160.154296875\n",
      "Epoch: 283, Batch number: 68, Loss: 7130.85693359375\n",
      "Epoch: 285, Batch number: 16, Loss: 6911.03125\n",
      "Epoch: 286, Batch number: 40, Loss: 7274.4755859375\n",
      "Epoch: 287, Batch number: 64, Loss: 6988.71044921875\n",
      "Epoch: 289, Batch number: 12, Loss: 7069.39111328125\n",
      "Epoch: 290, Batch number: 36, Loss: 7253.150390625\n",
      "Epoch: 291, Batch number: 60, Loss: 6818.22021484375\n",
      "Epoch: 293, Batch number: 8, Loss: 7066.55126953125\n",
      "Epoch: 294, Batch number: 32, Loss: 7099.84716796875\n",
      "Epoch: 295, Batch number: 56, Loss: 6733.76611328125\n",
      "Epoch: 297, Batch number: 4, Loss: 6873.60888671875\n",
      "Epoch: 298, Batch number: 28, Loss: 7183.50537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299, Batch number: 52, Loss: 7260.18798828125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 15432.474609375\n",
      "Epoch: 2, Batch number: 24, Loss: 13443.7060546875\n",
      "Epoch: 3, Batch number: 48, Loss: 12907.533203125\n",
      "Epoch: 4, Batch number: 72, Loss: 11872.9599609375\n",
      "Epoch: 6, Batch number: 20, Loss: 11257.751953125\n",
      "Epoch: 7, Batch number: 44, Loss: 10547.10546875\n",
      "Epoch: 8, Batch number: 68, Loss: 10411.87890625\n",
      "Epoch: 10, Batch number: 16, Loss: 9567.6826171875\n",
      "Epoch: 11, Batch number: 40, Loss: 9308.9345703125\n",
      "Epoch: 12, Batch number: 64, Loss: 9207.2705078125\n",
      "Epoch: 14, Batch number: 12, Loss: 8457.4833984375\n",
      "Epoch: 15, Batch number: 36, Loss: 8430.0458984375\n",
      "Epoch: 16, Batch number: 60, Loss: 8502.6767578125\n",
      "Epoch: 18, Batch number: 8, Loss: 8168.78857421875\n",
      "Epoch: 19, Batch number: 32, Loss: 8006.03857421875\n",
      "Epoch: 20, Batch number: 56, Loss: 8383.7138671875\n",
      "Epoch: 22, Batch number: 4, Loss: 7852.10009765625\n",
      "Epoch: 23, Batch number: 28, Loss: 7947.8017578125\n",
      "Epoch: 24, Batch number: 52, Loss: 7958.07373046875\n",
      "Epoch: 26, Batch number: 0, Loss: 7864.4150390625\n",
      "Epoch: 27, Batch number: 24, Loss: 7710.25732421875\n",
      "Epoch: 28, Batch number: 48, Loss: 7665.55126953125\n",
      "Epoch: 29, Batch number: 72, Loss: 7621.529296875\n",
      "Epoch: 31, Batch number: 20, Loss: 7477.0322265625\n",
      "Epoch: 32, Batch number: 44, Loss: 7470.736328125\n",
      "Epoch: 33, Batch number: 68, Loss: 7621.310546875\n",
      "Epoch: 35, Batch number: 16, Loss: 7457.64501953125\n",
      "Epoch: 36, Batch number: 40, Loss: 7360.60498046875\n",
      "Epoch: 37, Batch number: 64, Loss: 7238.37060546875\n",
      "Epoch: 39, Batch number: 12, Loss: 7246.34423828125\n",
      "Epoch: 40, Batch number: 36, Loss: 7378.30322265625\n",
      "Epoch: 41, Batch number: 60, Loss: 7201.412109375\n",
      "Epoch: 43, Batch number: 8, Loss: 7183.5908203125\n",
      "Epoch: 44, Batch number: 32, Loss: 7192.00634765625\n",
      "Epoch: 45, Batch number: 56, Loss: 7475.4833984375\n",
      "Epoch: 47, Batch number: 4, Loss: 7240.6494140625\n",
      "Epoch: 48, Batch number: 28, Loss: 7131.59130859375\n",
      "Epoch: 49, Batch number: 52, Loss: 7046.93408203125\n",
      "Epoch: 51, Batch number: 0, Loss: 7042.6337890625\n",
      "Epoch: 52, Batch number: 24, Loss: 7372.9697265625\n",
      "Epoch: 53, Batch number: 48, Loss: 7342.24267578125\n",
      "Epoch: 54, Batch number: 72, Loss: 7232.1845703125\n",
      "Epoch: 56, Batch number: 20, Loss: 7201.2236328125\n",
      "Epoch: 57, Batch number: 44, Loss: 7365.697265625\n",
      "Epoch: 58, Batch number: 68, Loss: 6833.4697265625\n",
      "Epoch: 60, Batch number: 16, Loss: 7093.46875\n",
      "Epoch: 61, Batch number: 40, Loss: 7171.548828125\n",
      "Epoch: 62, Batch number: 64, Loss: 7299.87451171875\n",
      "Epoch: 64, Batch number: 12, Loss: 7049.02587890625\n",
      "Epoch: 65, Batch number: 36, Loss: 7114.4248046875\n",
      "Epoch: 66, Batch number: 60, Loss: 7248.88037109375\n",
      "Epoch: 68, Batch number: 8, Loss: 7060.3291015625\n",
      "Epoch: 69, Batch number: 32, Loss: 7058.85498046875\n",
      "Epoch: 70, Batch number: 56, Loss: 7218.6796875\n",
      "Epoch: 72, Batch number: 4, Loss: 6829.07373046875\n",
      "Epoch: 73, Batch number: 28, Loss: 7021.3017578125\n",
      "Epoch: 74, Batch number: 52, Loss: 7185.75830078125\n",
      "Epoch: 76, Batch number: 0, Loss: 6900.06640625\n",
      "Epoch: 77, Batch number: 24, Loss: 7041.5419921875\n",
      "Epoch: 78, Batch number: 48, Loss: 7227.87158203125\n",
      "Epoch: 79, Batch number: 72, Loss: 6972.6611328125\n",
      "Epoch: 81, Batch number: 20, Loss: 7186.767578125\n",
      "Epoch: 82, Batch number: 44, Loss: 6761.9892578125\n",
      "Epoch: 83, Batch number: 68, Loss: 7159.8359375\n",
      "Epoch: 85, Batch number: 16, Loss: 6711.4033203125\n",
      "Epoch: 86, Batch number: 40, Loss: 7092.8447265625\n",
      "Epoch: 87, Batch number: 64, Loss: 7199.77197265625\n",
      "Epoch: 89, Batch number: 12, Loss: 7258.376953125\n",
      "Epoch: 90, Batch number: 36, Loss: 7137.20947265625\n",
      "Epoch: 91, Batch number: 60, Loss: 7257.54345703125\n",
      "Epoch: 93, Batch number: 8, Loss: 6922.4208984375\n",
      "Epoch: 94, Batch number: 32, Loss: 7138.626953125\n",
      "Epoch: 95, Batch number: 56, Loss: 7121.73779296875\n",
      "Epoch: 97, Batch number: 4, Loss: 6957.87744140625\n",
      "Epoch: 98, Batch number: 28, Loss: 7031.59716796875\n",
      "Epoch: 99, Batch number: 52, Loss: 6964.57275390625\n",
      "Epoch: 101, Batch number: 0, Loss: 6832.5732421875\n",
      "Epoch: 102, Batch number: 24, Loss: 7019.66552734375\n",
      "Epoch: 103, Batch number: 48, Loss: 7183.64404296875\n",
      "Epoch: 104, Batch number: 72, Loss: 7246.31298828125\n",
      "Epoch: 106, Batch number: 20, Loss: 6901.0732421875\n",
      "Epoch: 107, Batch number: 44, Loss: 7107.03173828125\n",
      "Epoch: 108, Batch number: 68, Loss: 7097.11376953125\n",
      "Epoch: 110, Batch number: 16, Loss: 7106.97314453125\n",
      "Epoch: 111, Batch number: 40, Loss: 6992.79052734375\n",
      "Epoch: 112, Batch number: 64, Loss: 6822.22021484375\n",
      "Epoch: 114, Batch number: 12, Loss: 7023.44287109375\n",
      "Epoch: 115, Batch number: 36, Loss: 6957.0400390625\n",
      "Epoch: 116, Batch number: 60, Loss: 6925.32177734375\n",
      "Epoch: 118, Batch number: 8, Loss: 6874.11474609375\n",
      "Epoch: 119, Batch number: 32, Loss: 6879.89794921875\n",
      "Epoch: 120, Batch number: 56, Loss: 7212.27880859375\n",
      "Epoch: 122, Batch number: 4, Loss: 7081.6123046875\n",
      "Epoch: 123, Batch number: 28, Loss: 7208.80615234375\n",
      "Epoch: 124, Batch number: 52, Loss: 7026.75537109375\n",
      "Epoch: 126, Batch number: 0, Loss: 6924.37939453125\n",
      "Epoch: 127, Batch number: 24, Loss: 7102.4345703125\n",
      "Epoch: 128, Batch number: 48, Loss: 6912.9501953125\n",
      "Epoch: 129, Batch number: 72, Loss: 7062.64501953125\n",
      "Epoch: 131, Batch number: 20, Loss: 7463.26171875\n",
      "Epoch: 132, Batch number: 44, Loss: 7086.93017578125\n",
      "Epoch: 133, Batch number: 68, Loss: 6926.06982421875\n",
      "Epoch: 135, Batch number: 16, Loss: 6999.87548828125\n",
      "Epoch: 136, Batch number: 40, Loss: 7072.4453125\n",
      "Epoch: 137, Batch number: 64, Loss: 6979.2138671875\n",
      "Epoch: 139, Batch number: 12, Loss: 7021.0341796875\n",
      "Epoch: 140, Batch number: 36, Loss: 7495.94384765625\n",
      "Epoch: 141, Batch number: 60, Loss: 6968.3740234375\n",
      "Epoch: 143, Batch number: 8, Loss: 6702.4228515625\n",
      "Epoch: 144, Batch number: 32, Loss: 6970.8876953125\n",
      "Epoch: 145, Batch number: 56, Loss: 7127.2216796875\n",
      "Epoch: 147, Batch number: 4, Loss: 6807.888671875\n",
      "Epoch: 148, Batch number: 28, Loss: 6993.126953125\n",
      "Epoch: 149, Batch number: 52, Loss: 6973.95458984375\n",
      "Epoch: 151, Batch number: 0, Loss: 6989.14794921875\n",
      "Epoch: 152, Batch number: 24, Loss: 6943.6162109375\n",
      "Epoch: 153, Batch number: 48, Loss: 6899.70263671875\n",
      "Epoch: 154, Batch number: 72, Loss: 7498.07666015625\n",
      "Epoch: 156, Batch number: 20, Loss: 6895.05859375\n",
      "Epoch: 157, Batch number: 44, Loss: 7001.740234375\n",
      "Epoch: 158, Batch number: 68, Loss: 7254.5830078125\n",
      "Epoch: 160, Batch number: 16, Loss: 7057.53857421875\n",
      "Epoch: 161, Batch number: 40, Loss: 6937.2138671875\n",
      "Epoch: 162, Batch number: 64, Loss: 7245.2373046875\n",
      "Epoch: 164, Batch number: 12, Loss: 7161.033203125\n",
      "Epoch: 165, Batch number: 36, Loss: 6679.40283203125\n",
      "Epoch: 166, Batch number: 60, Loss: 7375.72314453125\n",
      "Epoch: 168, Batch number: 8, Loss: 6679.57421875\n",
      "Epoch: 169, Batch number: 32, Loss: 7111.38134765625\n",
      "Epoch: 170, Batch number: 56, Loss: 7100.439453125\n",
      "Epoch: 172, Batch number: 4, Loss: 7066.267578125\n",
      "Epoch: 173, Batch number: 28, Loss: 6840.70263671875\n",
      "Epoch: 174, Batch number: 52, Loss: 7053.30126953125\n",
      "Epoch: 176, Batch number: 0, Loss: 7114.3857421875\n",
      "Epoch: 177, Batch number: 24, Loss: 7104.29833984375\n",
      "Epoch: 178, Batch number: 48, Loss: 7206.18505859375\n",
      "Epoch: 179, Batch number: 72, Loss: 7146.25537109375\n",
      "Epoch: 181, Batch number: 20, Loss: 6898.431640625\n",
      "Epoch: 182, Batch number: 44, Loss: 7136.64794921875\n",
      "Epoch: 183, Batch number: 68, Loss: 7142.81787109375\n",
      "Epoch: 185, Batch number: 16, Loss: 6746.18994140625\n",
      "Epoch: 186, Batch number: 40, Loss: 6653.2490234375\n",
      "Epoch: 187, Batch number: 64, Loss: 6973.29248046875\n",
      "Epoch: 189, Batch number: 12, Loss: 7073.2509765625\n",
      "Epoch: 190, Batch number: 36, Loss: 7159.736328125\n",
      "Epoch: 191, Batch number: 60, Loss: 7259.02685546875\n",
      "Epoch: 193, Batch number: 8, Loss: 7084.53955078125\n",
      "Epoch: 194, Batch number: 32, Loss: 7002.92333984375\n",
      "Epoch: 195, Batch number: 56, Loss: 7172.423828125\n",
      "Epoch: 197, Batch number: 4, Loss: 6879.53369140625\n",
      "Epoch: 198, Batch number: 28, Loss: 7173.6298828125\n",
      "Epoch: 199, Batch number: 52, Loss: 6913.091796875\n",
      "Epoch: 201, Batch number: 0, Loss: 6807.75146484375\n",
      "Epoch: 202, Batch number: 24, Loss: 7154.802734375\n",
      "Epoch: 203, Batch number: 48, Loss: 7056.7958984375\n",
      "Epoch: 204, Batch number: 72, Loss: 7167.751953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 7079.3193359375\n",
      "Epoch: 207, Batch number: 44, Loss: 7175.67333984375\n",
      "Epoch: 208, Batch number: 68, Loss: 6957.24609375\n",
      "Epoch: 210, Batch number: 16, Loss: 6716.90673828125\n",
      "Epoch: 211, Batch number: 40, Loss: 6947.52001953125\n",
      "Epoch: 212, Batch number: 64, Loss: 7065.7138671875\n",
      "Epoch: 214, Batch number: 12, Loss: 6777.7490234375\n",
      "Epoch: 215, Batch number: 36, Loss: 6738.94921875\n",
      "Epoch: 216, Batch number: 60, Loss: 6893.47265625\n",
      "Epoch: 218, Batch number: 8, Loss: 6920.6923828125\n",
      "Epoch: 219, Batch number: 32, Loss: 6933.88623046875\n",
      "Epoch: 220, Batch number: 56, Loss: 7150.83154296875\n",
      "Epoch: 222, Batch number: 4, Loss: 6609.7255859375\n",
      "Epoch: 223, Batch number: 28, Loss: 7144.12841796875\n",
      "Epoch: 224, Batch number: 52, Loss: 7060.8798828125\n",
      "Epoch: 226, Batch number: 0, Loss: 6762.61767578125\n",
      "Epoch: 227, Batch number: 24, Loss: 6826.2705078125\n",
      "Epoch: 228, Batch number: 48, Loss: 7068.05517578125\n",
      "Epoch: 229, Batch number: 72, Loss: 6904.880859375\n",
      "Epoch: 231, Batch number: 20, Loss: 7036.68359375\n",
      "Epoch: 232, Batch number: 44, Loss: 6812.193359375\n",
      "Epoch: 233, Batch number: 68, Loss: 7137.068359375\n",
      "Epoch: 235, Batch number: 16, Loss: 6999.8828125\n",
      "Epoch: 236, Batch number: 40, Loss: 7042.50634765625\n",
      "Epoch: 237, Batch number: 64, Loss: 7231.150390625\n",
      "Epoch: 239, Batch number: 12, Loss: 7018.04736328125\n",
      "Epoch: 240, Batch number: 36, Loss: 7019.4072265625\n",
      "Epoch: 241, Batch number: 60, Loss: 7192.65185546875\n",
      "Epoch: 243, Batch number: 8, Loss: 7173.40576171875\n",
      "Epoch: 244, Batch number: 32, Loss: 6765.57861328125\n",
      "Epoch: 245, Batch number: 56, Loss: 7177.29150390625\n",
      "Epoch: 247, Batch number: 4, Loss: 6870.59912109375\n",
      "Epoch: 248, Batch number: 28, Loss: 6622.046875\n",
      "Epoch: 249, Batch number: 52, Loss: 7333.53857421875\n",
      "Epoch: 251, Batch number: 0, Loss: 6773.59619140625\n",
      "Epoch: 252, Batch number: 24, Loss: 7017.98486328125\n",
      "Epoch: 253, Batch number: 48, Loss: 6924.708984375\n",
      "Epoch: 254, Batch number: 72, Loss: 7003.31103515625\n",
      "Epoch: 256, Batch number: 20, Loss: 6959.6357421875\n",
      "Epoch: 257, Batch number: 44, Loss: 6804.314453125\n",
      "Epoch: 258, Batch number: 68, Loss: 7112.36669921875\n",
      "Epoch: 260, Batch number: 16, Loss: 7181.7294921875\n",
      "Epoch: 261, Batch number: 40, Loss: 6936.1826171875\n",
      "Epoch: 262, Batch number: 64, Loss: 7333.96240234375\n",
      "Epoch: 264, Batch number: 12, Loss: 7129.13037109375\n",
      "Epoch: 265, Batch number: 36, Loss: 7201.5625\n",
      "Epoch: 266, Batch number: 60, Loss: 7165.70703125\n",
      "Epoch: 268, Batch number: 8, Loss: 6846.05615234375\n",
      "Epoch: 269, Batch number: 32, Loss: 7134.18798828125\n",
      "Epoch: 270, Batch number: 56, Loss: 7179.92236328125\n",
      "Epoch: 272, Batch number: 4, Loss: 7023.4140625\n",
      "Epoch: 273, Batch number: 28, Loss: 6828.35546875\n",
      "Epoch: 274, Batch number: 52, Loss: 7234.15234375\n",
      "Epoch: 276, Batch number: 0, Loss: 6994.64794921875\n",
      "Epoch: 277, Batch number: 24, Loss: 7207.57421875\n",
      "Epoch: 278, Batch number: 48, Loss: 7139.6455078125\n",
      "Epoch: 279, Batch number: 72, Loss: 7406.24658203125\n",
      "Epoch: 281, Batch number: 20, Loss: 7105.86474609375\n",
      "Epoch: 282, Batch number: 44, Loss: 7193.69189453125\n",
      "Epoch: 283, Batch number: 68, Loss: 7195.07373046875\n",
      "Epoch: 285, Batch number: 16, Loss: 6937.3779296875\n",
      "Epoch: 286, Batch number: 40, Loss: 6979.41162109375\n",
      "Epoch: 287, Batch number: 64, Loss: 7008.30126953125\n",
      "Epoch: 289, Batch number: 12, Loss: 6835.75048828125\n",
      "Epoch: 290, Batch number: 36, Loss: 7051.1279296875\n",
      "Epoch: 291, Batch number: 60, Loss: 6951.333984375\n",
      "Epoch: 293, Batch number: 8, Loss: 6994.29833984375\n",
      "Epoch: 294, Batch number: 32, Loss: 7098.3466796875\n",
      "Epoch: 295, Batch number: 56, Loss: 7316.16259765625\n",
      "Epoch: 297, Batch number: 4, Loss: 6891.74755859375\n",
      "Epoch: 298, Batch number: 28, Loss: 7009.25390625\n",
      "Epoch: 299, Batch number: 52, Loss: 7085.8037109375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21347.255859375\n",
      "Epoch: 2, Batch number: 24, Loss: 21285.88671875\n",
      "Epoch: 3, Batch number: 48, Loss: 20884.75390625\n",
      "Epoch: 4, Batch number: 72, Loss: 19624.15234375\n",
      "Epoch: 6, Batch number: 20, Loss: 19107.05859375\n",
      "Epoch: 7, Batch number: 44, Loss: 18898.400390625\n",
      "Epoch: 8, Batch number: 68, Loss: 17951.189453125\n",
      "Epoch: 10, Batch number: 16, Loss: 17757.953125\n",
      "Epoch: 11, Batch number: 40, Loss: 17298.05859375\n",
      "Epoch: 12, Batch number: 64, Loss: 17154.888671875\n",
      "Epoch: 14, Batch number: 12, Loss: 16653.5703125\n",
      "Epoch: 15, Batch number: 36, Loss: 16598.90625\n",
      "Epoch: 16, Batch number: 60, Loss: 16551.78515625\n",
      "Epoch: 18, Batch number: 8, Loss: 16008.0546875\n",
      "Epoch: 19, Batch number: 32, Loss: 16117.451171875\n",
      "Epoch: 20, Batch number: 56, Loss: 15799.9267578125\n",
      "Epoch: 22, Batch number: 4, Loss: 15462.3330078125\n",
      "Epoch: 23, Batch number: 28, Loss: 15480.255859375\n",
      "Epoch: 24, Batch number: 52, Loss: 15618.078125\n",
      "Epoch: 26, Batch number: 0, Loss: 15603.044921875\n",
      "Epoch: 27, Batch number: 24, Loss: 15527.95703125\n",
      "Epoch: 28, Batch number: 48, Loss: 15266.5771484375\n",
      "Epoch: 29, Batch number: 72, Loss: 15177.21484375\n",
      "Epoch: 31, Batch number: 20, Loss: 14482.6962890625\n",
      "Epoch: 32, Batch number: 44, Loss: 14776.1953125\n",
      "Epoch: 33, Batch number: 68, Loss: 14616.814453125\n",
      "Epoch: 35, Batch number: 16, Loss: 14608.994140625\n",
      "Epoch: 36, Batch number: 40, Loss: 14904.7724609375\n",
      "Epoch: 37, Batch number: 64, Loss: 14602.384765625\n",
      "Epoch: 39, Batch number: 12, Loss: 14533.6240234375\n",
      "Epoch: 40, Batch number: 36, Loss: 14015.9208984375\n",
      "Epoch: 41, Batch number: 60, Loss: 14357.3310546875\n",
      "Epoch: 43, Batch number: 8, Loss: 14171.580078125\n",
      "Epoch: 44, Batch number: 32, Loss: 13933.2734375\n",
      "Epoch: 45, Batch number: 56, Loss: 14098.5439453125\n",
      "Epoch: 47, Batch number: 4, Loss: 14092.6171875\n",
      "Epoch: 48, Batch number: 28, Loss: 14113.8408203125\n",
      "Epoch: 49, Batch number: 52, Loss: 14113.8837890625\n",
      "Epoch: 51, Batch number: 0, Loss: 13929.9384765625\n",
      "Epoch: 52, Batch number: 24, Loss: 14260.5302734375\n",
      "Epoch: 53, Batch number: 48, Loss: 14050.705078125\n",
      "Epoch: 54, Batch number: 72, Loss: 14249.0234375\n",
      "Epoch: 56, Batch number: 20, Loss: 13690.5712890625\n",
      "Epoch: 57, Batch number: 44, Loss: 13782.44921875\n",
      "Epoch: 58, Batch number: 68, Loss: 14000.5732421875\n",
      "Epoch: 60, Batch number: 16, Loss: 13599.6826171875\n",
      "Epoch: 61, Batch number: 40, Loss: 14034.3212890625\n",
      "Epoch: 62, Batch number: 64, Loss: 13714.5498046875\n",
      "Epoch: 64, Batch number: 12, Loss: 13689.537109375\n",
      "Epoch: 65, Batch number: 36, Loss: 13656.607421875\n",
      "Epoch: 66, Batch number: 60, Loss: 13616.255859375\n",
      "Epoch: 68, Batch number: 8, Loss: 13512.724609375\n",
      "Epoch: 69, Batch number: 32, Loss: 13564.6669921875\n",
      "Epoch: 70, Batch number: 56, Loss: 13371.759765625\n",
      "Epoch: 72, Batch number: 4, Loss: 13280.1123046875\n",
      "Epoch: 73, Batch number: 28, Loss: 13359.4140625\n",
      "Epoch: 74, Batch number: 52, Loss: 13542.8310546875\n",
      "Epoch: 76, Batch number: 0, Loss: 13352.326171875\n",
      "Epoch: 77, Batch number: 24, Loss: 13270.4365234375\n",
      "Epoch: 78, Batch number: 48, Loss: 13106.462890625\n",
      "Epoch: 79, Batch number: 72, Loss: 13071.7529296875\n",
      "Epoch: 81, Batch number: 20, Loss: 13248.6044921875\n",
      "Epoch: 82, Batch number: 44, Loss: 13288.9541015625\n",
      "Epoch: 83, Batch number: 68, Loss: 13470.169921875\n",
      "Epoch: 85, Batch number: 16, Loss: 13320.2998046875\n",
      "Epoch: 86, Batch number: 40, Loss: 13147.23828125\n",
      "Epoch: 87, Batch number: 64, Loss: 13157.9755859375\n",
      "Epoch: 89, Batch number: 12, Loss: 13142.19140625\n",
      "Epoch: 90, Batch number: 36, Loss: 12825.6181640625\n",
      "Epoch: 91, Batch number: 60, Loss: 13243.328125\n",
      "Epoch: 93, Batch number: 8, Loss: 12923.4453125\n",
      "Epoch: 94, Batch number: 32, Loss: 13314.6337890625\n",
      "Epoch: 95, Batch number: 56, Loss: 12939.6435546875\n",
      "Epoch: 97, Batch number: 4, Loss: 12793.701171875\n",
      "Epoch: 98, Batch number: 28, Loss: 12865.3642578125\n",
      "Epoch: 99, Batch number: 52, Loss: 12973.275390625\n",
      "Epoch: 101, Batch number: 0, Loss: 12997.94921875\n",
      "Epoch: 102, Batch number: 24, Loss: 12890.3759765625\n",
      "Epoch: 103, Batch number: 48, Loss: 13038.5595703125\n",
      "Epoch: 104, Batch number: 72, Loss: 13001.07421875\n",
      "Epoch: 106, Batch number: 20, Loss: 13023.6025390625\n",
      "Epoch: 107, Batch number: 44, Loss: 12612.1826171875\n",
      "Epoch: 108, Batch number: 68, Loss: 12752.9921875\n",
      "Epoch: 110, Batch number: 16, Loss: 12733.3232421875\n",
      "Epoch: 111, Batch number: 40, Loss: 12662.349609375\n",
      "Epoch: 112, Batch number: 64, Loss: 12764.1455078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114, Batch number: 12, Loss: 12582.25\n",
      "Epoch: 115, Batch number: 36, Loss: 12762.6767578125\n",
      "Epoch: 116, Batch number: 60, Loss: 12692.861328125\n",
      "Epoch: 118, Batch number: 8, Loss: 12646.0224609375\n",
      "Epoch: 119, Batch number: 32, Loss: 12429.189453125\n",
      "Epoch: 120, Batch number: 56, Loss: 12869.2578125\n",
      "Epoch: 122, Batch number: 4, Loss: 12260.2451171875\n",
      "Epoch: 123, Batch number: 28, Loss: 12787.6005859375\n",
      "Epoch: 124, Batch number: 52, Loss: 12611.2626953125\n",
      "Epoch: 126, Batch number: 0, Loss: 12505.82421875\n",
      "Epoch: 127, Batch number: 24, Loss: 12644.7705078125\n",
      "Epoch: 128, Batch number: 48, Loss: 12555.1728515625\n",
      "Epoch: 129, Batch number: 72, Loss: 12600.5703125\n",
      "Epoch: 131, Batch number: 20, Loss: 12286.701171875\n",
      "Epoch: 132, Batch number: 44, Loss: 12341.0712890625\n",
      "Epoch: 133, Batch number: 68, Loss: 12309.2236328125\n",
      "Epoch: 135, Batch number: 16, Loss: 12393.833984375\n",
      "Epoch: 136, Batch number: 40, Loss: 12275.1962890625\n",
      "Epoch: 137, Batch number: 64, Loss: 12452.91796875\n",
      "Epoch: 139, Batch number: 12, Loss: 12403.015625\n",
      "Epoch: 140, Batch number: 36, Loss: 12416.931640625\n",
      "Epoch: 141, Batch number: 60, Loss: 11910.8037109375\n",
      "Epoch: 143, Batch number: 8, Loss: 12296.5576171875\n",
      "Epoch: 144, Batch number: 32, Loss: 12411.71484375\n",
      "Epoch: 145, Batch number: 56, Loss: 12132.263671875\n",
      "Epoch: 147, Batch number: 4, Loss: 12199.5908203125\n",
      "Epoch: 148, Batch number: 28, Loss: 12321.68359375\n",
      "Epoch: 149, Batch number: 52, Loss: 12234.58203125\n",
      "Epoch: 151, Batch number: 0, Loss: 12185.1083984375\n",
      "Epoch: 152, Batch number: 24, Loss: 12275.8779296875\n",
      "Epoch: 153, Batch number: 48, Loss: 12149.9970703125\n",
      "Epoch: 154, Batch number: 72, Loss: 12353.5869140625\n",
      "Epoch: 156, Batch number: 20, Loss: 11806.5361328125\n",
      "Epoch: 157, Batch number: 44, Loss: 12246.84375\n",
      "Epoch: 158, Batch number: 68, Loss: 12220.7646484375\n",
      "Epoch: 160, Batch number: 16, Loss: 12211.353515625\n",
      "Epoch: 161, Batch number: 40, Loss: 11998.78515625\n",
      "Epoch: 162, Batch number: 64, Loss: 12303.1650390625\n",
      "Epoch: 164, Batch number: 12, Loss: 12152.232421875\n",
      "Epoch: 165, Batch number: 36, Loss: 12295.296875\n",
      "Epoch: 166, Batch number: 60, Loss: 12262.142578125\n",
      "Epoch: 168, Batch number: 8, Loss: 11838.4873046875\n",
      "Epoch: 169, Batch number: 32, Loss: 11982.626953125\n",
      "Epoch: 170, Batch number: 56, Loss: 12267.1484375\n",
      "Epoch: 172, Batch number: 4, Loss: 11664.654296875\n",
      "Epoch: 173, Batch number: 28, Loss: 11829.9072265625\n",
      "Epoch: 174, Batch number: 52, Loss: 12325.92578125\n",
      "Epoch: 176, Batch number: 0, Loss: 12041.7705078125\n",
      "Epoch: 177, Batch number: 24, Loss: 12018.9033203125\n",
      "Epoch: 178, Batch number: 48, Loss: 12061.40625\n",
      "Epoch: 179, Batch number: 72, Loss: 11827.8037109375\n",
      "Epoch: 181, Batch number: 20, Loss: 11559.8134765625\n",
      "Epoch: 182, Batch number: 44, Loss: 11821.98828125\n",
      "Epoch: 183, Batch number: 68, Loss: 11825.1416015625\n",
      "Epoch: 185, Batch number: 16, Loss: 12005.6748046875\n",
      "Epoch: 186, Batch number: 40, Loss: 11831.119140625\n",
      "Epoch: 187, Batch number: 64, Loss: 12057.49609375\n",
      "Epoch: 189, Batch number: 12, Loss: 11653.0224609375\n",
      "Epoch: 190, Batch number: 36, Loss: 11867.2275390625\n",
      "Epoch: 191, Batch number: 60, Loss: 12069.53515625\n",
      "Epoch: 193, Batch number: 8, Loss: 11982.4833984375\n",
      "Epoch: 194, Batch number: 32, Loss: 11674.384765625\n",
      "Epoch: 195, Batch number: 56, Loss: 11752.654296875\n",
      "Epoch: 197, Batch number: 4, Loss: 11893.4765625\n",
      "Epoch: 198, Batch number: 28, Loss: 12001.650390625\n",
      "Epoch: 199, Batch number: 52, Loss: 11671.8994140625\n",
      "Epoch: 201, Batch number: 0, Loss: 12117.841796875\n",
      "Epoch: 202, Batch number: 24, Loss: 11664.55859375\n",
      "Epoch: 203, Batch number: 48, Loss: 11510.6484375\n",
      "Epoch: 204, Batch number: 72, Loss: 11727.4853515625\n",
      "Epoch: 206, Batch number: 20, Loss: 11659.40234375\n",
      "Epoch: 207, Batch number: 44, Loss: 11791.8388671875\n",
      "Epoch: 208, Batch number: 68, Loss: 11422.978515625\n",
      "Epoch: 210, Batch number: 16, Loss: 11331.4794921875\n",
      "Epoch: 211, Batch number: 40, Loss: 11644.9306640625\n",
      "Epoch: 212, Batch number: 64, Loss: 11706.845703125\n",
      "Epoch: 214, Batch number: 12, Loss: 11689.423828125\n",
      "Epoch: 215, Batch number: 36, Loss: 11862.1572265625\n",
      "Epoch: 216, Batch number: 60, Loss: 11739.1572265625\n",
      "Epoch: 218, Batch number: 8, Loss: 11633.8955078125\n",
      "Epoch: 219, Batch number: 32, Loss: 11675.1357421875\n",
      "Epoch: 220, Batch number: 56, Loss: 11572.6337890625\n",
      "Epoch: 222, Batch number: 4, Loss: 12065.5986328125\n",
      "Epoch: 223, Batch number: 28, Loss: 11407.712890625\n",
      "Epoch: 224, Batch number: 52, Loss: 11487.962890625\n",
      "Epoch: 226, Batch number: 0, Loss: 11740.7568359375\n",
      "Epoch: 227, Batch number: 24, Loss: 11565.7958984375\n",
      "Epoch: 228, Batch number: 48, Loss: 11676.5107421875\n",
      "Epoch: 229, Batch number: 72, Loss: 11741.578125\n",
      "Epoch: 231, Batch number: 20, Loss: 11094.4814453125\n",
      "Epoch: 232, Batch number: 44, Loss: 11711.060546875\n",
      "Epoch: 233, Batch number: 68, Loss: 11857.9501953125\n",
      "Epoch: 235, Batch number: 16, Loss: 11495.009765625\n",
      "Epoch: 236, Batch number: 40, Loss: 11569.501953125\n",
      "Epoch: 237, Batch number: 64, Loss: 11372.205078125\n",
      "Epoch: 239, Batch number: 12, Loss: 11777.697265625\n",
      "Epoch: 240, Batch number: 36, Loss: 11727.65625\n",
      "Epoch: 241, Batch number: 60, Loss: 11479.560546875\n",
      "Epoch: 243, Batch number: 8, Loss: 11860.5634765625\n",
      "Epoch: 244, Batch number: 32, Loss: 11738.91796875\n",
      "Epoch: 245, Batch number: 56, Loss: 11874.8818359375\n",
      "Epoch: 247, Batch number: 4, Loss: 11266.181640625\n",
      "Epoch: 248, Batch number: 28, Loss: 11664.3623046875\n",
      "Epoch: 249, Batch number: 52, Loss: 11875.806640625\n",
      "Epoch: 251, Batch number: 0, Loss: 11797.8486328125\n",
      "Epoch: 252, Batch number: 24, Loss: 11336.9443359375\n",
      "Epoch: 253, Batch number: 48, Loss: 11610.154296875\n",
      "Epoch: 254, Batch number: 72, Loss: 11544.9208984375\n",
      "Epoch: 256, Batch number: 20, Loss: 11790.3955078125\n",
      "Epoch: 257, Batch number: 44, Loss: 11442.72265625\n",
      "Epoch: 258, Batch number: 68, Loss: 11369.9501953125\n",
      "Epoch: 260, Batch number: 16, Loss: 11690.806640625\n",
      "Epoch: 261, Batch number: 40, Loss: 11547.0712890625\n",
      "Epoch: 262, Batch number: 64, Loss: 11771.3896484375\n",
      "Epoch: 264, Batch number: 12, Loss: 11370.6953125\n",
      "Epoch: 265, Batch number: 36, Loss: 11396.8818359375\n",
      "Epoch: 266, Batch number: 60, Loss: 11383.1953125\n",
      "Epoch: 268, Batch number: 8, Loss: 11464.7939453125\n",
      "Epoch: 269, Batch number: 32, Loss: 11602.1640625\n",
      "Epoch: 270, Batch number: 56, Loss: 11309.326171875\n",
      "Epoch: 272, Batch number: 4, Loss: 11306.9384765625\n",
      "Epoch: 273, Batch number: 28, Loss: 11661.6923828125\n",
      "Epoch: 274, Batch number: 52, Loss: 11196.4140625\n",
      "Epoch: 276, Batch number: 0, Loss: 11383.513671875\n",
      "Epoch: 277, Batch number: 24, Loss: 11366.2578125\n",
      "Epoch: 278, Batch number: 48, Loss: 11257.0361328125\n",
      "Epoch: 279, Batch number: 72, Loss: 11266.728515625\n",
      "Epoch: 281, Batch number: 20, Loss: 11261.029296875\n",
      "Epoch: 282, Batch number: 44, Loss: 11402.333984375\n",
      "Epoch: 283, Batch number: 68, Loss: 11047.62890625\n",
      "Epoch: 285, Batch number: 16, Loss: 11356.3740234375\n",
      "Epoch: 286, Batch number: 40, Loss: 11719.787109375\n",
      "Epoch: 287, Batch number: 64, Loss: 11534.498046875\n",
      "Epoch: 289, Batch number: 12, Loss: 11435.462890625\n",
      "Epoch: 290, Batch number: 36, Loss: 11292.1416015625\n",
      "Epoch: 291, Batch number: 60, Loss: 11035.474609375\n",
      "Epoch: 293, Batch number: 8, Loss: 11182.9677734375\n",
      "Epoch: 294, Batch number: 32, Loss: 11331.6171875\n",
      "Epoch: 295, Batch number: 56, Loss: 10993.5908203125\n",
      "Epoch: 297, Batch number: 4, Loss: 11327.0478515625\n",
      "Epoch: 298, Batch number: 28, Loss: 10931.2080078125\n",
      "Epoch: 299, Batch number: 52, Loss: 11432.681640625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 20841.26953125\n",
      "Epoch: 2, Batch number: 24, Loss: 20697.3671875\n",
      "Epoch: 3, Batch number: 48, Loss: 20122.638671875\n",
      "Epoch: 4, Batch number: 72, Loss: 19287.728515625\n",
      "Epoch: 6, Batch number: 20, Loss: 18124.923828125\n",
      "Epoch: 7, Batch number: 44, Loss: 18184.611328125\n",
      "Epoch: 8, Batch number: 68, Loss: 16742.109375\n",
      "Epoch: 10, Batch number: 16, Loss: 16326.4765625\n",
      "Epoch: 11, Batch number: 40, Loss: 16381.1474609375\n",
      "Epoch: 12, Batch number: 64, Loss: 16178.4306640625\n",
      "Epoch: 14, Batch number: 12, Loss: 15728.1484375\n",
      "Epoch: 15, Batch number: 36, Loss: 15473.970703125\n",
      "Epoch: 16, Batch number: 60, Loss: 15315.107421875\n",
      "Epoch: 18, Batch number: 8, Loss: 14794.1572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Batch number: 32, Loss: 14750.654296875\n",
      "Epoch: 20, Batch number: 56, Loss: 14792.708984375\n",
      "Epoch: 22, Batch number: 4, Loss: 14511.626953125\n",
      "Epoch: 23, Batch number: 28, Loss: 14392.876953125\n",
      "Epoch: 24, Batch number: 52, Loss: 14137.0498046875\n",
      "Epoch: 26, Batch number: 0, Loss: 14087.060546875\n",
      "Epoch: 27, Batch number: 24, Loss: 13837.533203125\n",
      "Epoch: 28, Batch number: 48, Loss: 13759.900390625\n",
      "Epoch: 29, Batch number: 72, Loss: 14142.1552734375\n",
      "Epoch: 31, Batch number: 20, Loss: 13421.8681640625\n",
      "Epoch: 32, Batch number: 44, Loss: 13394.4306640625\n",
      "Epoch: 33, Batch number: 68, Loss: 13385.1826171875\n",
      "Epoch: 35, Batch number: 16, Loss: 13283.384765625\n",
      "Epoch: 36, Batch number: 40, Loss: 13173.3115234375\n",
      "Epoch: 37, Batch number: 64, Loss: 13194.1318359375\n",
      "Epoch: 39, Batch number: 12, Loss: 12878.8779296875\n",
      "Epoch: 40, Batch number: 36, Loss: 13140.0263671875\n",
      "Epoch: 41, Batch number: 60, Loss: 12959.33203125\n",
      "Epoch: 43, Batch number: 8, Loss: 12996.9873046875\n",
      "Epoch: 44, Batch number: 32, Loss: 12601.4560546875\n",
      "Epoch: 45, Batch number: 56, Loss: 12884.7421875\n",
      "Epoch: 47, Batch number: 4, Loss: 12703.556640625\n",
      "Epoch: 48, Batch number: 28, Loss: 12334.0576171875\n",
      "Epoch: 49, Batch number: 52, Loss: 12647.73046875\n",
      "Epoch: 51, Batch number: 0, Loss: 12604.3125\n",
      "Epoch: 52, Batch number: 24, Loss: 12733.021484375\n",
      "Epoch: 53, Batch number: 48, Loss: 12526.849609375\n",
      "Epoch: 54, Batch number: 72, Loss: 12626.677734375\n",
      "Epoch: 56, Batch number: 20, Loss: 12506.0771484375\n",
      "Epoch: 57, Batch number: 44, Loss: 12595.728515625\n",
      "Epoch: 58, Batch number: 68, Loss: 12529.615234375\n",
      "Epoch: 60, Batch number: 16, Loss: 12220.662109375\n",
      "Epoch: 61, Batch number: 40, Loss: 12114.5068359375\n",
      "Epoch: 62, Batch number: 64, Loss: 12613.67578125\n",
      "Epoch: 64, Batch number: 12, Loss: 12248.31640625\n",
      "Epoch: 65, Batch number: 36, Loss: 12232.13671875\n",
      "Epoch: 66, Batch number: 60, Loss: 12093.9521484375\n",
      "Epoch: 68, Batch number: 8, Loss: 12309.7197265625\n",
      "Epoch: 69, Batch number: 32, Loss: 12121.509765625\n",
      "Epoch: 70, Batch number: 56, Loss: 12187.119140625\n",
      "Epoch: 72, Batch number: 4, Loss: 12227.9091796875\n",
      "Epoch: 73, Batch number: 28, Loss: 12214.0859375\n",
      "Epoch: 74, Batch number: 52, Loss: 11908.2900390625\n",
      "Epoch: 76, Batch number: 0, Loss: 12236.4365234375\n",
      "Epoch: 77, Batch number: 24, Loss: 12225.794921875\n",
      "Epoch: 78, Batch number: 48, Loss: 11746.947265625\n",
      "Epoch: 79, Batch number: 72, Loss: 12221.12890625\n",
      "Epoch: 81, Batch number: 20, Loss: 12186.9599609375\n",
      "Epoch: 82, Batch number: 44, Loss: 12024.884765625\n",
      "Epoch: 83, Batch number: 68, Loss: 11978.4462890625\n",
      "Epoch: 85, Batch number: 16, Loss: 11719.6796875\n",
      "Epoch: 86, Batch number: 40, Loss: 11996.861328125\n",
      "Epoch: 87, Batch number: 64, Loss: 12005.640625\n",
      "Epoch: 89, Batch number: 12, Loss: 12056.9267578125\n",
      "Epoch: 90, Batch number: 36, Loss: 11649.84765625\n",
      "Epoch: 91, Batch number: 60, Loss: 12411.796875\n",
      "Epoch: 93, Batch number: 8, Loss: 11994.25\n",
      "Epoch: 94, Batch number: 32, Loss: 11562.28125\n",
      "Epoch: 95, Batch number: 56, Loss: 11538.9306640625\n",
      "Epoch: 97, Batch number: 4, Loss: 11383.74609375\n",
      "Epoch: 98, Batch number: 28, Loss: 11378.5224609375\n",
      "Epoch: 99, Batch number: 52, Loss: 11751.740234375\n",
      "Epoch: 101, Batch number: 0, Loss: 11832.623046875\n",
      "Epoch: 102, Batch number: 24, Loss: 11709.2978515625\n",
      "Epoch: 103, Batch number: 48, Loss: 11457.732421875\n",
      "Epoch: 104, Batch number: 72, Loss: 11503.607421875\n",
      "Epoch: 106, Batch number: 20, Loss: 11473.814453125\n",
      "Epoch: 107, Batch number: 44, Loss: 11496.697265625\n",
      "Epoch: 108, Batch number: 68, Loss: 11804.689453125\n",
      "Epoch: 110, Batch number: 16, Loss: 11667.943359375\n",
      "Epoch: 111, Batch number: 40, Loss: 11343.5791015625\n",
      "Epoch: 112, Batch number: 64, Loss: 11475.1259765625\n",
      "Epoch: 114, Batch number: 12, Loss: 11789.41796875\n",
      "Epoch: 115, Batch number: 36, Loss: 11161.380859375\n",
      "Epoch: 116, Batch number: 60, Loss: 11580.21875\n",
      "Epoch: 118, Batch number: 8, Loss: 11311.1943359375\n",
      "Epoch: 119, Batch number: 32, Loss: 11236.1396484375\n",
      "Epoch: 120, Batch number: 56, Loss: 11703.6826171875\n",
      "Epoch: 122, Batch number: 4, Loss: 11503.984375\n",
      "Epoch: 123, Batch number: 28, Loss: 11194.369140625\n",
      "Epoch: 124, Batch number: 52, Loss: 11120.650390625\n",
      "Epoch: 126, Batch number: 0, Loss: 11176.6826171875\n",
      "Epoch: 127, Batch number: 24, Loss: 11413.1298828125\n",
      "Epoch: 128, Batch number: 48, Loss: 11514.11328125\n",
      "Epoch: 129, Batch number: 72, Loss: 11236.2763671875\n",
      "Epoch: 131, Batch number: 20, Loss: 11264.7197265625\n",
      "Epoch: 132, Batch number: 44, Loss: 11518.7900390625\n",
      "Epoch: 133, Batch number: 68, Loss: 11461.2216796875\n",
      "Epoch: 135, Batch number: 16, Loss: 11246.0947265625\n",
      "Epoch: 136, Batch number: 40, Loss: 10940.7001953125\n",
      "Epoch: 137, Batch number: 64, Loss: 11088.3837890625\n",
      "Epoch: 139, Batch number: 12, Loss: 11777.4638671875\n",
      "Epoch: 140, Batch number: 36, Loss: 10963.0986328125\n",
      "Epoch: 141, Batch number: 60, Loss: 11263.0947265625\n",
      "Epoch: 143, Batch number: 8, Loss: 11323.193359375\n",
      "Epoch: 144, Batch number: 32, Loss: 11274.6083984375\n",
      "Epoch: 145, Batch number: 56, Loss: 11247.1845703125\n",
      "Epoch: 147, Batch number: 4, Loss: 11207.728515625\n",
      "Epoch: 148, Batch number: 28, Loss: 11037.4931640625\n",
      "Epoch: 149, Batch number: 52, Loss: 10871.9716796875\n",
      "Epoch: 151, Batch number: 0, Loss: 11081.28125\n",
      "Epoch: 152, Batch number: 24, Loss: 11071.328125\n",
      "Epoch: 153, Batch number: 48, Loss: 11157.94140625\n",
      "Epoch: 154, Batch number: 72, Loss: 11206.443359375\n",
      "Epoch: 156, Batch number: 20, Loss: 11054.8203125\n",
      "Epoch: 157, Batch number: 44, Loss: 11398.0537109375\n",
      "Epoch: 158, Batch number: 68, Loss: 11053.7431640625\n",
      "Epoch: 160, Batch number: 16, Loss: 11111.765625\n",
      "Epoch: 161, Batch number: 40, Loss: 11066.0693359375\n",
      "Epoch: 162, Batch number: 64, Loss: 10757.5634765625\n",
      "Epoch: 164, Batch number: 12, Loss: 11122.0302734375\n",
      "Epoch: 165, Batch number: 36, Loss: 10967.49609375\n",
      "Epoch: 166, Batch number: 60, Loss: 10962.09765625\n",
      "Epoch: 168, Batch number: 8, Loss: 11075.0322265625\n",
      "Epoch: 169, Batch number: 32, Loss: 11215.4404296875\n",
      "Epoch: 170, Batch number: 56, Loss: 10746.7822265625\n",
      "Epoch: 172, Batch number: 4, Loss: 10950.60546875\n",
      "Epoch: 173, Batch number: 28, Loss: 11031.9931640625\n",
      "Epoch: 174, Batch number: 52, Loss: 10620.0458984375\n",
      "Epoch: 176, Batch number: 0, Loss: 10757.59375\n",
      "Epoch: 177, Batch number: 24, Loss: 11265.19921875\n",
      "Epoch: 178, Batch number: 48, Loss: 10906.46875\n",
      "Epoch: 179, Batch number: 72, Loss: 11267.8671875\n",
      "Epoch: 181, Batch number: 20, Loss: 10989.037109375\n",
      "Epoch: 182, Batch number: 44, Loss: 11264.5185546875\n",
      "Epoch: 183, Batch number: 68, Loss: 10794.4921875\n",
      "Epoch: 185, Batch number: 16, Loss: 11094.521484375\n",
      "Epoch: 186, Batch number: 40, Loss: 10945.271484375\n",
      "Epoch: 187, Batch number: 64, Loss: 10971.37109375\n",
      "Epoch: 189, Batch number: 12, Loss: 11083.1904296875\n",
      "Epoch: 190, Batch number: 36, Loss: 10872.7734375\n",
      "Epoch: 191, Batch number: 60, Loss: 11373.837890625\n",
      "Epoch: 193, Batch number: 8, Loss: 10964.0224609375\n",
      "Epoch: 194, Batch number: 32, Loss: 10763.2822265625\n",
      "Epoch: 195, Batch number: 56, Loss: 10851.890625\n",
      "Epoch: 197, Batch number: 4, Loss: 10668.4482421875\n",
      "Epoch: 198, Batch number: 28, Loss: 10712.203125\n",
      "Epoch: 199, Batch number: 52, Loss: 11172.630859375\n",
      "Epoch: 201, Batch number: 0, Loss: 10778.671875\n",
      "Epoch: 202, Batch number: 24, Loss: 10967.7890625\n",
      "Epoch: 203, Batch number: 48, Loss: 10961.5146484375\n",
      "Epoch: 204, Batch number: 72, Loss: 10611.6337890625\n",
      "Epoch: 206, Batch number: 20, Loss: 10793.923828125\n",
      "Epoch: 207, Batch number: 44, Loss: 10940.1083984375\n",
      "Epoch: 208, Batch number: 68, Loss: 10802.9482421875\n",
      "Epoch: 210, Batch number: 16, Loss: 10813.83984375\n",
      "Epoch: 211, Batch number: 40, Loss: 10536.748046875\n",
      "Epoch: 212, Batch number: 64, Loss: 10846.611328125\n",
      "Epoch: 214, Batch number: 12, Loss: 10903.4853515625\n",
      "Epoch: 215, Batch number: 36, Loss: 10873.7763671875\n",
      "Epoch: 216, Batch number: 60, Loss: 10643.1748046875\n",
      "Epoch: 218, Batch number: 8, Loss: 10888.5966796875\n",
      "Epoch: 219, Batch number: 32, Loss: 10745.849609375\n",
      "Epoch: 220, Batch number: 56, Loss: 10711.3251953125\n",
      "Epoch: 222, Batch number: 4, Loss: 10751.2548828125\n",
      "Epoch: 223, Batch number: 28, Loss: 10790.890625\n",
      "Epoch: 224, Batch number: 52, Loss: 10637.6533203125\n",
      "Epoch: 226, Batch number: 0, Loss: 10621.4677734375\n",
      "Epoch: 227, Batch number: 24, Loss: 10777.67578125\n",
      "Epoch: 228, Batch number: 48, Loss: 10925.7373046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 229, Batch number: 72, Loss: 10742.4189453125\n",
      "Epoch: 231, Batch number: 20, Loss: 10672.2119140625\n",
      "Epoch: 232, Batch number: 44, Loss: 10804.955078125\n",
      "Epoch: 233, Batch number: 68, Loss: 10713.4716796875\n",
      "Epoch: 235, Batch number: 16, Loss: 10622.3447265625\n",
      "Epoch: 236, Batch number: 40, Loss: 10773.947265625\n",
      "Epoch: 237, Batch number: 64, Loss: 11022.5751953125\n",
      "Epoch: 239, Batch number: 12, Loss: 10386.7236328125\n",
      "Epoch: 240, Batch number: 36, Loss: 10563.5947265625\n",
      "Epoch: 241, Batch number: 60, Loss: 10978.1015625\n",
      "Epoch: 243, Batch number: 8, Loss: 10642.7138671875\n",
      "Epoch: 244, Batch number: 32, Loss: 10817.9814453125\n",
      "Epoch: 245, Batch number: 56, Loss: 10489.6083984375\n",
      "Epoch: 247, Batch number: 4, Loss: 10807.1875\n",
      "Epoch: 248, Batch number: 28, Loss: 10436.7685546875\n",
      "Epoch: 249, Batch number: 52, Loss: 10851.2421875\n",
      "Epoch: 251, Batch number: 0, Loss: 10482.29296875\n",
      "Epoch: 252, Batch number: 24, Loss: 10342.8876953125\n",
      "Epoch: 253, Batch number: 48, Loss: 10825.421875\n",
      "Epoch: 254, Batch number: 72, Loss: 10573.9091796875\n",
      "Epoch: 256, Batch number: 20, Loss: 10676.5751953125\n",
      "Epoch: 257, Batch number: 44, Loss: 10788.96484375\n",
      "Epoch: 258, Batch number: 68, Loss: 11045.33203125\n",
      "Epoch: 260, Batch number: 16, Loss: 10695.9609375\n",
      "Epoch: 261, Batch number: 40, Loss: 10794.099609375\n",
      "Epoch: 262, Batch number: 64, Loss: 10630.9150390625\n",
      "Epoch: 264, Batch number: 12, Loss: 10908.8037109375\n",
      "Epoch: 265, Batch number: 36, Loss: 10910.046875\n",
      "Epoch: 266, Batch number: 60, Loss: 10365.4765625\n",
      "Epoch: 268, Batch number: 8, Loss: 10535.716796875\n",
      "Epoch: 269, Batch number: 32, Loss: 10457.1259765625\n",
      "Epoch: 270, Batch number: 56, Loss: 11185.7802734375\n",
      "Epoch: 272, Batch number: 4, Loss: 10343.60546875\n",
      "Epoch: 273, Batch number: 28, Loss: 10701.1279296875\n",
      "Epoch: 274, Batch number: 52, Loss: 10552.0869140625\n",
      "Epoch: 276, Batch number: 0, Loss: 10430.0625\n",
      "Epoch: 277, Batch number: 24, Loss: 10780.2353515625\n",
      "Epoch: 278, Batch number: 48, Loss: 10749.21875\n",
      "Epoch: 279, Batch number: 72, Loss: 10878.65234375\n",
      "Epoch: 281, Batch number: 20, Loss: 10690.9228515625\n",
      "Epoch: 282, Batch number: 44, Loss: 10806.578125\n",
      "Epoch: 283, Batch number: 68, Loss: 10548.70703125\n",
      "Epoch: 285, Batch number: 16, Loss: 10712.287109375\n",
      "Epoch: 286, Batch number: 40, Loss: 10547.6953125\n",
      "Epoch: 287, Batch number: 64, Loss: 10446.732421875\n",
      "Epoch: 289, Batch number: 12, Loss: 10395.4521484375\n",
      "Epoch: 290, Batch number: 36, Loss: 10502.7392578125\n",
      "Epoch: 291, Batch number: 60, Loss: 11112.6796875\n",
      "Epoch: 293, Batch number: 8, Loss: 10676.896484375\n",
      "Epoch: 294, Batch number: 32, Loss: 10973.6865234375\n",
      "Epoch: 295, Batch number: 56, Loss: 10681.09765625\n",
      "Epoch: 297, Batch number: 4, Loss: 10386.0703125\n",
      "Epoch: 298, Batch number: 28, Loss: 10785.224609375\n",
      "Epoch: 299, Batch number: 52, Loss: 10743.083984375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21886.248046875\n",
      "Epoch: 2, Batch number: 24, Loss: 20454.783203125\n",
      "Epoch: 3, Batch number: 48, Loss: 19163.138671875\n",
      "Epoch: 4, Batch number: 72, Loss: 18493.41796875\n",
      "Epoch: 6, Batch number: 20, Loss: 17431.171875\n",
      "Epoch: 7, Batch number: 44, Loss: 17097.61328125\n",
      "Epoch: 8, Batch number: 68, Loss: 16817.814453125\n",
      "Epoch: 10, Batch number: 16, Loss: 15998.2626953125\n",
      "Epoch: 11, Batch number: 40, Loss: 15647.677734375\n",
      "Epoch: 12, Batch number: 64, Loss: 15498.03125\n",
      "Epoch: 14, Batch number: 12, Loss: 14865.2646484375\n",
      "Epoch: 15, Batch number: 36, Loss: 14634.3876953125\n",
      "Epoch: 16, Batch number: 60, Loss: 14173.138671875\n",
      "Epoch: 18, Batch number: 8, Loss: 14129.283203125\n",
      "Epoch: 19, Batch number: 32, Loss: 13942.6953125\n",
      "Epoch: 20, Batch number: 56, Loss: 13631.2578125\n",
      "Epoch: 22, Batch number: 4, Loss: 13567.96484375\n",
      "Epoch: 23, Batch number: 28, Loss: 13536.0517578125\n",
      "Epoch: 24, Batch number: 52, Loss: 13349.9560546875\n",
      "Epoch: 26, Batch number: 0, Loss: 13229.9365234375\n",
      "Epoch: 27, Batch number: 24, Loss: 12750.1181640625\n",
      "Epoch: 28, Batch number: 48, Loss: 13241.7099609375\n",
      "Epoch: 29, Batch number: 72, Loss: 12982.298828125\n",
      "Epoch: 31, Batch number: 20, Loss: 12902.4990234375\n",
      "Epoch: 32, Batch number: 44, Loss: 12580.6298828125\n",
      "Epoch: 33, Batch number: 68, Loss: 12723.48046875\n",
      "Epoch: 35, Batch number: 16, Loss: 12694.9443359375\n",
      "Epoch: 36, Batch number: 40, Loss: 12927.1298828125\n",
      "Epoch: 37, Batch number: 64, Loss: 12393.828125\n",
      "Epoch: 39, Batch number: 12, Loss: 12301.515625\n",
      "Epoch: 40, Batch number: 36, Loss: 12345.029296875\n",
      "Epoch: 41, Batch number: 60, Loss: 12399.306640625\n",
      "Epoch: 43, Batch number: 8, Loss: 12216.1025390625\n",
      "Epoch: 44, Batch number: 32, Loss: 12374.2109375\n",
      "Epoch: 45, Batch number: 56, Loss: 12213.4189453125\n",
      "Epoch: 47, Batch number: 4, Loss: 12116.841796875\n",
      "Epoch: 48, Batch number: 28, Loss: 11818.25390625\n",
      "Epoch: 49, Batch number: 52, Loss: 11956.580078125\n",
      "Epoch: 51, Batch number: 0, Loss: 11853.734375\n",
      "Epoch: 52, Batch number: 24, Loss: 11936.984375\n",
      "Epoch: 53, Batch number: 48, Loss: 11873.2470703125\n",
      "Epoch: 54, Batch number: 72, Loss: 12198.6591796875\n",
      "Epoch: 56, Batch number: 20, Loss: 11940.7314453125\n",
      "Epoch: 57, Batch number: 44, Loss: 12181.1796875\n",
      "Epoch: 58, Batch number: 68, Loss: 12104.98828125\n",
      "Epoch: 60, Batch number: 16, Loss: 11824.40234375\n",
      "Epoch: 61, Batch number: 40, Loss: 11803.6826171875\n",
      "Epoch: 62, Batch number: 64, Loss: 11948.0615234375\n",
      "Epoch: 64, Batch number: 12, Loss: 11471.533203125\n",
      "Epoch: 65, Batch number: 36, Loss: 11660.9794921875\n",
      "Epoch: 66, Batch number: 60, Loss: 11395.35546875\n",
      "Epoch: 68, Batch number: 8, Loss: 11286.2353515625\n",
      "Epoch: 69, Batch number: 32, Loss: 11446.814453125\n",
      "Epoch: 70, Batch number: 56, Loss: 11298.3427734375\n",
      "Epoch: 72, Batch number: 4, Loss: 11505.05859375\n",
      "Epoch: 73, Batch number: 28, Loss: 11697.830078125\n",
      "Epoch: 74, Batch number: 52, Loss: 11755.90625\n",
      "Epoch: 76, Batch number: 0, Loss: 11472.3662109375\n",
      "Epoch: 77, Batch number: 24, Loss: 11456.7333984375\n",
      "Epoch: 78, Batch number: 48, Loss: 11502.884765625\n",
      "Epoch: 79, Batch number: 72, Loss: 11520.634765625\n",
      "Epoch: 81, Batch number: 20, Loss: 11155.0556640625\n",
      "Epoch: 82, Batch number: 44, Loss: 11325.88671875\n",
      "Epoch: 83, Batch number: 68, Loss: 11226.1474609375\n",
      "Epoch: 85, Batch number: 16, Loss: 11269.58984375\n",
      "Epoch: 86, Batch number: 40, Loss: 11434.568359375\n",
      "Epoch: 87, Batch number: 64, Loss: 11058.0927734375\n",
      "Epoch: 89, Batch number: 12, Loss: 11479.87109375\n",
      "Epoch: 90, Batch number: 36, Loss: 11513.720703125\n",
      "Epoch: 91, Batch number: 60, Loss: 11447.279296875\n",
      "Epoch: 93, Batch number: 8, Loss: 11056.1220703125\n",
      "Epoch: 94, Batch number: 32, Loss: 11631.3330078125\n",
      "Epoch: 95, Batch number: 56, Loss: 11118.177734375\n",
      "Epoch: 97, Batch number: 4, Loss: 11143.5146484375\n",
      "Epoch: 98, Batch number: 28, Loss: 11152.81640625\n",
      "Epoch: 99, Batch number: 52, Loss: 11316.4482421875\n",
      "Epoch: 101, Batch number: 0, Loss: 10802.2919921875\n",
      "Epoch: 102, Batch number: 24, Loss: 11027.75390625\n",
      "Epoch: 103, Batch number: 48, Loss: 11205.86328125\n",
      "Epoch: 104, Batch number: 72, Loss: 11173.21875\n",
      "Epoch: 106, Batch number: 20, Loss: 10911.923828125\n",
      "Epoch: 107, Batch number: 44, Loss: 10883.255859375\n",
      "Epoch: 108, Batch number: 68, Loss: 11430.75\n",
      "Epoch: 110, Batch number: 16, Loss: 11047.4990234375\n",
      "Epoch: 111, Batch number: 40, Loss: 11249.1259765625\n",
      "Epoch: 112, Batch number: 64, Loss: 11360.5244140625\n",
      "Epoch: 114, Batch number: 12, Loss: 10876.1201171875\n",
      "Epoch: 115, Batch number: 36, Loss: 10913.861328125\n",
      "Epoch: 116, Batch number: 60, Loss: 10987.046875\n",
      "Epoch: 118, Batch number: 8, Loss: 11222.033203125\n",
      "Epoch: 119, Batch number: 32, Loss: 10418.033203125\n",
      "Epoch: 120, Batch number: 56, Loss: 10586.2607421875\n",
      "Epoch: 122, Batch number: 4, Loss: 10918.90234375\n",
      "Epoch: 123, Batch number: 28, Loss: 10870.912109375\n",
      "Epoch: 124, Batch number: 52, Loss: 11112.5390625\n",
      "Epoch: 126, Batch number: 0, Loss: 11175.5634765625\n",
      "Epoch: 127, Batch number: 24, Loss: 10746.076171875\n",
      "Epoch: 128, Batch number: 48, Loss: 10636.3203125\n",
      "Epoch: 129, Batch number: 72, Loss: 10877.16796875\n",
      "Epoch: 131, Batch number: 20, Loss: 11228.564453125\n",
      "Epoch: 132, Batch number: 44, Loss: 10998.2578125\n",
      "Epoch: 133, Batch number: 68, Loss: 10732.333984375\n",
      "Epoch: 135, Batch number: 16, Loss: 10542.9130859375\n",
      "Epoch: 136, Batch number: 40, Loss: 10942.341796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137, Batch number: 64, Loss: 11250.8662109375\n",
      "Epoch: 139, Batch number: 12, Loss: 10387.9736328125\n",
      "Epoch: 140, Batch number: 36, Loss: 10750.3994140625\n",
      "Epoch: 141, Batch number: 60, Loss: 10828.140625\n",
      "Epoch: 143, Batch number: 8, Loss: 10730.53125\n",
      "Epoch: 144, Batch number: 32, Loss: 10647.5390625\n",
      "Epoch: 145, Batch number: 56, Loss: 10928.205078125\n",
      "Epoch: 147, Batch number: 4, Loss: 11062.0556640625\n",
      "Epoch: 148, Batch number: 28, Loss: 10664.5126953125\n",
      "Epoch: 149, Batch number: 52, Loss: 10920.767578125\n",
      "Epoch: 151, Batch number: 0, Loss: 10916.05859375\n",
      "Epoch: 152, Batch number: 24, Loss: 10647.703125\n",
      "Epoch: 153, Batch number: 48, Loss: 10627.1318359375\n",
      "Epoch: 154, Batch number: 72, Loss: 10430.84765625\n",
      "Epoch: 156, Batch number: 20, Loss: 11144.205078125\n",
      "Epoch: 157, Batch number: 44, Loss: 10748.083984375\n",
      "Epoch: 158, Batch number: 68, Loss: 10809.8447265625\n",
      "Epoch: 160, Batch number: 16, Loss: 10650.2509765625\n",
      "Epoch: 161, Batch number: 40, Loss: 10798.4375\n",
      "Epoch: 162, Batch number: 64, Loss: 10791.4375\n",
      "Epoch: 164, Batch number: 12, Loss: 10619.896484375\n",
      "Epoch: 165, Batch number: 36, Loss: 10547.6787109375\n",
      "Epoch: 166, Batch number: 60, Loss: 10474.86328125\n",
      "Epoch: 168, Batch number: 8, Loss: 10238.5166015625\n",
      "Epoch: 169, Batch number: 32, Loss: 10614.4609375\n",
      "Epoch: 170, Batch number: 56, Loss: 10871.451171875\n",
      "Epoch: 172, Batch number: 4, Loss: 10533.15625\n",
      "Epoch: 173, Batch number: 28, Loss: 10592.31640625\n",
      "Epoch: 174, Batch number: 52, Loss: 10686.8134765625\n",
      "Epoch: 176, Batch number: 0, Loss: 10459.06640625\n",
      "Epoch: 177, Batch number: 24, Loss: 11232.6669921875\n",
      "Epoch: 178, Batch number: 48, Loss: 10482.953125\n",
      "Epoch: 179, Batch number: 72, Loss: 10576.6015625\n",
      "Epoch: 181, Batch number: 20, Loss: 10530.6640625\n",
      "Epoch: 182, Batch number: 44, Loss: 10602.4462890625\n",
      "Epoch: 183, Batch number: 68, Loss: 10928.7265625\n",
      "Epoch: 185, Batch number: 16, Loss: 10470.1943359375\n",
      "Epoch: 186, Batch number: 40, Loss: 10658.841796875\n",
      "Epoch: 187, Batch number: 64, Loss: 10612.001953125\n",
      "Epoch: 189, Batch number: 12, Loss: 10245.1328125\n",
      "Epoch: 190, Batch number: 36, Loss: 10453.3134765625\n",
      "Epoch: 191, Batch number: 60, Loss: 10643.8271484375\n",
      "Epoch: 193, Batch number: 8, Loss: 10583.1884765625\n",
      "Epoch: 194, Batch number: 32, Loss: 10898.3310546875\n",
      "Epoch: 195, Batch number: 56, Loss: 10401.337890625\n",
      "Epoch: 197, Batch number: 4, Loss: 10129.2236328125\n",
      "Epoch: 198, Batch number: 28, Loss: 10513.5419921875\n",
      "Epoch: 199, Batch number: 52, Loss: 10689.580078125\n",
      "Epoch: 201, Batch number: 0, Loss: 10284.658203125\n",
      "Epoch: 202, Batch number: 24, Loss: 10362.8779296875\n",
      "Epoch: 203, Batch number: 48, Loss: 10807.3173828125\n",
      "Epoch: 204, Batch number: 72, Loss: 10845.4189453125\n",
      "Epoch: 206, Batch number: 20, Loss: 10401.3515625\n",
      "Epoch: 207, Batch number: 44, Loss: 10495.9443359375\n",
      "Epoch: 208, Batch number: 68, Loss: 10638.1083984375\n",
      "Epoch: 210, Batch number: 16, Loss: 10352.7021484375\n",
      "Epoch: 211, Batch number: 40, Loss: 10401.4287109375\n",
      "Epoch: 212, Batch number: 64, Loss: 10520.955078125\n",
      "Epoch: 214, Batch number: 12, Loss: 10601.71484375\n",
      "Epoch: 215, Batch number: 36, Loss: 10290.19140625\n",
      "Epoch: 216, Batch number: 60, Loss: 10639.6171875\n",
      "Epoch: 218, Batch number: 8, Loss: 10595.8984375\n",
      "Epoch: 219, Batch number: 32, Loss: 10321.3232421875\n",
      "Epoch: 220, Batch number: 56, Loss: 10232.03515625\n",
      "Epoch: 222, Batch number: 4, Loss: 10769.0849609375\n",
      "Epoch: 223, Batch number: 28, Loss: 10425.5673828125\n",
      "Epoch: 224, Batch number: 52, Loss: 10908.49609375\n",
      "Epoch: 226, Batch number: 0, Loss: 10025.4365234375\n",
      "Epoch: 227, Batch number: 24, Loss: 10625.546875\n",
      "Epoch: 228, Batch number: 48, Loss: 10460.3447265625\n",
      "Epoch: 229, Batch number: 72, Loss: 10447.0654296875\n",
      "Epoch: 231, Batch number: 20, Loss: 10731.861328125\n",
      "Epoch: 232, Batch number: 44, Loss: 10615.9775390625\n",
      "Epoch: 233, Batch number: 68, Loss: 10926.255859375\n",
      "Epoch: 235, Batch number: 16, Loss: 10707.80078125\n",
      "Epoch: 236, Batch number: 40, Loss: 10879.953125\n",
      "Epoch: 237, Batch number: 64, Loss: 10779.228515625\n",
      "Epoch: 239, Batch number: 12, Loss: 10672.1376953125\n",
      "Epoch: 240, Batch number: 36, Loss: 10816.0751953125\n",
      "Epoch: 241, Batch number: 60, Loss: 10683.6025390625\n",
      "Epoch: 243, Batch number: 8, Loss: 10403.2685546875\n",
      "Epoch: 244, Batch number: 32, Loss: 10774.486328125\n",
      "Epoch: 245, Batch number: 56, Loss: 10451.9697265625\n",
      "Epoch: 247, Batch number: 4, Loss: 10335.7255859375\n",
      "Epoch: 248, Batch number: 28, Loss: 10436.2607421875\n",
      "Epoch: 249, Batch number: 52, Loss: 10709.060546875\n",
      "Epoch: 251, Batch number: 0, Loss: 10362.8779296875\n",
      "Epoch: 252, Batch number: 24, Loss: 10504.5673828125\n",
      "Epoch: 253, Batch number: 48, Loss: 10215.994140625\n",
      "Epoch: 254, Batch number: 72, Loss: 10665.5029296875\n",
      "Epoch: 256, Batch number: 20, Loss: 10356.2314453125\n",
      "Epoch: 257, Batch number: 44, Loss: 10093.4970703125\n",
      "Epoch: 258, Batch number: 68, Loss: 10613.009765625\n",
      "Epoch: 260, Batch number: 16, Loss: 10639.4169921875\n",
      "Epoch: 261, Batch number: 40, Loss: 10143.9296875\n",
      "Epoch: 262, Batch number: 64, Loss: 10479.2783203125\n",
      "Epoch: 264, Batch number: 12, Loss: 10202.0654296875\n",
      "Epoch: 265, Batch number: 36, Loss: 10451.8818359375\n",
      "Epoch: 266, Batch number: 60, Loss: 10760.828125\n",
      "Epoch: 268, Batch number: 8, Loss: 10177.2666015625\n",
      "Epoch: 269, Batch number: 32, Loss: 10317.970703125\n",
      "Epoch: 270, Batch number: 56, Loss: 10626.998046875\n",
      "Epoch: 272, Batch number: 4, Loss: 10388.7431640625\n",
      "Epoch: 273, Batch number: 28, Loss: 10470.607421875\n",
      "Epoch: 274, Batch number: 52, Loss: 10339.361328125\n",
      "Epoch: 276, Batch number: 0, Loss: 10299.0595703125\n",
      "Epoch: 277, Batch number: 24, Loss: 10641.8916015625\n",
      "Epoch: 278, Batch number: 48, Loss: 10529.51171875\n",
      "Epoch: 279, Batch number: 72, Loss: 10598.3271484375\n",
      "Epoch: 281, Batch number: 20, Loss: 10518.955078125\n",
      "Epoch: 282, Batch number: 44, Loss: 10236.1220703125\n",
      "Epoch: 283, Batch number: 68, Loss: 10461.8916015625\n",
      "Epoch: 285, Batch number: 16, Loss: 10455.9736328125\n",
      "Epoch: 286, Batch number: 40, Loss: 10822.0087890625\n",
      "Epoch: 287, Batch number: 64, Loss: 10432.5361328125\n",
      "Epoch: 289, Batch number: 12, Loss: 10569.62890625\n",
      "Epoch: 290, Batch number: 36, Loss: 10821.0625\n",
      "Epoch: 291, Batch number: 60, Loss: 10654.3603515625\n",
      "Epoch: 293, Batch number: 8, Loss: 10565.0625\n",
      "Epoch: 294, Batch number: 32, Loss: 10523.548828125\n",
      "Epoch: 295, Batch number: 56, Loss: 10132.1923828125\n",
      "Epoch: 297, Batch number: 4, Loss: 10183.5927734375\n",
      "Epoch: 298, Batch number: 28, Loss: 10443.087890625\n",
      "Epoch: 299, Batch number: 52, Loss: 10441.5751953125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21790.189453125\n",
      "Epoch: 2, Batch number: 24, Loss: 20001.333984375\n",
      "Epoch: 3, Batch number: 48, Loss: 18810.037109375\n",
      "Epoch: 4, Batch number: 72, Loss: 17874.291015625\n",
      "Epoch: 6, Batch number: 20, Loss: 17171.7421875\n",
      "Epoch: 7, Batch number: 44, Loss: 16707.57421875\n",
      "Epoch: 8, Batch number: 68, Loss: 15962.025390625\n",
      "Epoch: 10, Batch number: 16, Loss: 15340.1943359375\n",
      "Epoch: 11, Batch number: 40, Loss: 15180.16796875\n",
      "Epoch: 12, Batch number: 64, Loss: 14534.0537109375\n",
      "Epoch: 14, Batch number: 12, Loss: 14307.724609375\n",
      "Epoch: 15, Batch number: 36, Loss: 14177.18359375\n",
      "Epoch: 16, Batch number: 60, Loss: 13618.669921875\n",
      "Epoch: 18, Batch number: 8, Loss: 13348.9873046875\n",
      "Epoch: 19, Batch number: 32, Loss: 13459.0712890625\n",
      "Epoch: 20, Batch number: 56, Loss: 13393.123046875\n",
      "Epoch: 22, Batch number: 4, Loss: 13133.3056640625\n",
      "Epoch: 23, Batch number: 28, Loss: 12585.3359375\n",
      "Epoch: 24, Batch number: 52, Loss: 12767.9228515625\n",
      "Epoch: 26, Batch number: 0, Loss: 12726.939453125\n",
      "Epoch: 27, Batch number: 24, Loss: 12245.1044921875\n",
      "Epoch: 28, Batch number: 48, Loss: 12404.1669921875\n",
      "Epoch: 29, Batch number: 72, Loss: 12469.9453125\n",
      "Epoch: 31, Batch number: 20, Loss: 12423.1884765625\n",
      "Epoch: 32, Batch number: 44, Loss: 12335.326171875\n",
      "Epoch: 33, Batch number: 68, Loss: 12077.796875\n",
      "Epoch: 35, Batch number: 16, Loss: 12142.95703125\n",
      "Epoch: 36, Batch number: 40, Loss: 11734.6533203125\n",
      "Epoch: 37, Batch number: 64, Loss: 11961.5302734375\n",
      "Epoch: 39, Batch number: 12, Loss: 11859.8671875\n",
      "Epoch: 40, Batch number: 36, Loss: 11977.4091796875\n",
      "Epoch: 41, Batch number: 60, Loss: 12089.509765625\n",
      "Epoch: 43, Batch number: 8, Loss: 11902.7119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Batch number: 32, Loss: 11609.5947265625\n",
      "Epoch: 45, Batch number: 56, Loss: 11778.9228515625\n",
      "Epoch: 47, Batch number: 4, Loss: 11508.7890625\n",
      "Epoch: 48, Batch number: 28, Loss: 11614.8837890625\n",
      "Epoch: 49, Batch number: 52, Loss: 11431.408203125\n",
      "Epoch: 51, Batch number: 0, Loss: 11601.1904296875\n",
      "Epoch: 52, Batch number: 24, Loss: 11506.4736328125\n",
      "Epoch: 53, Batch number: 48, Loss: 11355.53515625\n",
      "Epoch: 54, Batch number: 72, Loss: 11891.5625\n",
      "Epoch: 56, Batch number: 20, Loss: 11635.84375\n",
      "Epoch: 57, Batch number: 44, Loss: 11608.421875\n",
      "Epoch: 58, Batch number: 68, Loss: 11184.7802734375\n",
      "Epoch: 60, Batch number: 16, Loss: 11282.4541015625\n",
      "Epoch: 61, Batch number: 40, Loss: 11322.5283203125\n",
      "Epoch: 62, Batch number: 64, Loss: 11238.7314453125\n",
      "Epoch: 64, Batch number: 12, Loss: 11473.349609375\n",
      "Epoch: 65, Batch number: 36, Loss: 11357.7626953125\n",
      "Epoch: 66, Batch number: 60, Loss: 11481.400390625\n",
      "Epoch: 68, Batch number: 8, Loss: 11039.1259765625\n",
      "Epoch: 69, Batch number: 32, Loss: 11009.34765625\n",
      "Epoch: 70, Batch number: 56, Loss: 11438.537109375\n",
      "Epoch: 72, Batch number: 4, Loss: 11012.634765625\n",
      "Epoch: 73, Batch number: 28, Loss: 10938.205078125\n",
      "Epoch: 74, Batch number: 52, Loss: 11024.3994140625\n",
      "Epoch: 76, Batch number: 0, Loss: 10842.2705078125\n",
      "Epoch: 77, Batch number: 24, Loss: 10884.265625\n",
      "Epoch: 78, Batch number: 48, Loss: 11258.6181640625\n",
      "Epoch: 79, Batch number: 72, Loss: 11303.1982421875\n",
      "Epoch: 81, Batch number: 20, Loss: 11101.7080078125\n",
      "Epoch: 82, Batch number: 44, Loss: 11608.4072265625\n",
      "Epoch: 83, Batch number: 68, Loss: 10656.611328125\n",
      "Epoch: 85, Batch number: 16, Loss: 10981.171875\n",
      "Epoch: 86, Batch number: 40, Loss: 11026.2099609375\n",
      "Epoch: 87, Batch number: 64, Loss: 11217.0107421875\n",
      "Epoch: 89, Batch number: 12, Loss: 11176.6103515625\n",
      "Epoch: 90, Batch number: 36, Loss: 10914.0693359375\n",
      "Epoch: 91, Batch number: 60, Loss: 10936.69921875\n",
      "Epoch: 93, Batch number: 8, Loss: 10663.87109375\n",
      "Epoch: 94, Batch number: 32, Loss: 10742.634765625\n",
      "Epoch: 95, Batch number: 56, Loss: 10915.0927734375\n",
      "Epoch: 97, Batch number: 4, Loss: 10702.59765625\n",
      "Epoch: 98, Batch number: 28, Loss: 10987.27734375\n",
      "Epoch: 99, Batch number: 52, Loss: 10730.1533203125\n",
      "Epoch: 101, Batch number: 0, Loss: 10642.1533203125\n",
      "Epoch: 102, Batch number: 24, Loss: 10809.3486328125\n",
      "Epoch: 103, Batch number: 48, Loss: 10741.5712890625\n",
      "Epoch: 104, Batch number: 72, Loss: 11282.6279296875\n",
      "Epoch: 106, Batch number: 20, Loss: 10441.23828125\n",
      "Epoch: 107, Batch number: 44, Loss: 10934.072265625\n",
      "Epoch: 108, Batch number: 68, Loss: 10489.8935546875\n",
      "Epoch: 110, Batch number: 16, Loss: 10743.73046875\n",
      "Epoch: 111, Batch number: 40, Loss: 10809.244140625\n",
      "Epoch: 112, Batch number: 64, Loss: 10687.3359375\n",
      "Epoch: 114, Batch number: 12, Loss: 10561.833984375\n",
      "Epoch: 115, Batch number: 36, Loss: 10770.2109375\n",
      "Epoch: 116, Batch number: 60, Loss: 10868.966796875\n",
      "Epoch: 118, Batch number: 8, Loss: 10468.2705078125\n",
      "Epoch: 119, Batch number: 32, Loss: 10555.2900390625\n",
      "Epoch: 120, Batch number: 56, Loss: 10650.2255859375\n",
      "Epoch: 122, Batch number: 4, Loss: 10481.2666015625\n",
      "Epoch: 123, Batch number: 28, Loss: 10916.2060546875\n",
      "Epoch: 124, Batch number: 52, Loss: 10751.251953125\n",
      "Epoch: 126, Batch number: 0, Loss: 10650.3935546875\n",
      "Epoch: 127, Batch number: 24, Loss: 10610.7333984375\n",
      "Epoch: 128, Batch number: 48, Loss: 10467.171875\n",
      "Epoch: 129, Batch number: 72, Loss: 10603.0888671875\n",
      "Epoch: 131, Batch number: 20, Loss: 10071.150390625\n",
      "Epoch: 132, Batch number: 44, Loss: 10937.6591796875\n",
      "Epoch: 133, Batch number: 68, Loss: 10814.900390625\n",
      "Epoch: 135, Batch number: 16, Loss: 10696.8837890625\n",
      "Epoch: 136, Batch number: 40, Loss: 10704.376953125\n",
      "Epoch: 137, Batch number: 64, Loss: 10610.728515625\n",
      "Epoch: 139, Batch number: 12, Loss: 10222.3720703125\n",
      "Epoch: 140, Batch number: 36, Loss: 10621.1943359375\n",
      "Epoch: 141, Batch number: 60, Loss: 10454.037109375\n",
      "Epoch: 143, Batch number: 8, Loss: 11034.380859375\n",
      "Epoch: 144, Batch number: 32, Loss: 10815.962890625\n",
      "Epoch: 145, Batch number: 56, Loss: 10635.0400390625\n",
      "Epoch: 147, Batch number: 4, Loss: 10251.65625\n",
      "Epoch: 148, Batch number: 28, Loss: 10468.6015625\n",
      "Epoch: 149, Batch number: 52, Loss: 10532.67578125\n",
      "Epoch: 151, Batch number: 0, Loss: 10571.8291015625\n",
      "Epoch: 152, Batch number: 24, Loss: 10544.1728515625\n",
      "Epoch: 153, Batch number: 48, Loss: 10368.056640625\n",
      "Epoch: 154, Batch number: 72, Loss: 10705.962890625\n",
      "Epoch: 156, Batch number: 20, Loss: 10337.4677734375\n",
      "Epoch: 157, Batch number: 44, Loss: 10425.7578125\n",
      "Epoch: 158, Batch number: 68, Loss: 10733.091796875\n",
      "Epoch: 160, Batch number: 16, Loss: 10823.279296875\n",
      "Epoch: 161, Batch number: 40, Loss: 10214.9814453125\n",
      "Epoch: 162, Batch number: 64, Loss: 10803.4150390625\n",
      "Epoch: 164, Batch number: 12, Loss: 10796.5830078125\n",
      "Epoch: 165, Batch number: 36, Loss: 10621.78515625\n",
      "Epoch: 166, Batch number: 60, Loss: 10753.3916015625\n",
      "Epoch: 168, Batch number: 8, Loss: 10460.0048828125\n",
      "Epoch: 169, Batch number: 32, Loss: 10433.94921875\n",
      "Epoch: 170, Batch number: 56, Loss: 10818.66796875\n",
      "Epoch: 172, Batch number: 4, Loss: 10413.5068359375\n",
      "Epoch: 173, Batch number: 28, Loss: 10611.2666015625\n",
      "Epoch: 174, Batch number: 52, Loss: 10736.76953125\n",
      "Epoch: 176, Batch number: 0, Loss: 10468.92578125\n",
      "Epoch: 177, Batch number: 24, Loss: 10458.201171875\n",
      "Epoch: 178, Batch number: 48, Loss: 10753.642578125\n",
      "Epoch: 179, Batch number: 72, Loss: 10477.369140625\n",
      "Epoch: 181, Batch number: 20, Loss: 10403.1796875\n",
      "Epoch: 182, Batch number: 44, Loss: 10832.9794921875\n",
      "Epoch: 183, Batch number: 68, Loss: 10561.4248046875\n",
      "Epoch: 185, Batch number: 16, Loss: 10574.3056640625\n",
      "Epoch: 186, Batch number: 40, Loss: 10863.9931640625\n",
      "Epoch: 187, Batch number: 64, Loss: 10340.474609375\n",
      "Epoch: 189, Batch number: 12, Loss: 10271.255859375\n",
      "Epoch: 190, Batch number: 36, Loss: 10665.533203125\n",
      "Epoch: 191, Batch number: 60, Loss: 10295.095703125\n",
      "Epoch: 193, Batch number: 8, Loss: 10568.4130859375\n",
      "Epoch: 194, Batch number: 32, Loss: 10531.9072265625\n",
      "Epoch: 195, Batch number: 56, Loss: 10526.259765625\n",
      "Epoch: 197, Batch number: 4, Loss: 10353.7802734375\n",
      "Epoch: 198, Batch number: 28, Loss: 10556.8193359375\n",
      "Epoch: 199, Batch number: 52, Loss: 11005.2138671875\n",
      "Epoch: 201, Batch number: 0, Loss: 10178.0712890625\n",
      "Epoch: 202, Batch number: 24, Loss: 10143.4560546875\n",
      "Epoch: 203, Batch number: 48, Loss: 10665.1220703125\n",
      "Epoch: 204, Batch number: 72, Loss: 10347.7587890625\n",
      "Epoch: 206, Batch number: 20, Loss: 10318.638671875\n",
      "Epoch: 207, Batch number: 44, Loss: 10344.158203125\n",
      "Epoch: 208, Batch number: 68, Loss: 10297.3779296875\n",
      "Epoch: 210, Batch number: 16, Loss: 10644.2958984375\n",
      "Epoch: 211, Batch number: 40, Loss: 10917.646484375\n",
      "Epoch: 212, Batch number: 64, Loss: 10340.6357421875\n",
      "Epoch: 214, Batch number: 12, Loss: 10262.849609375\n",
      "Epoch: 215, Batch number: 36, Loss: 10350.1181640625\n",
      "Epoch: 216, Batch number: 60, Loss: 10102.701171875\n",
      "Epoch: 218, Batch number: 8, Loss: 10489.671875\n",
      "Epoch: 219, Batch number: 32, Loss: 10407.5087890625\n",
      "Epoch: 220, Batch number: 56, Loss: 10274.0771484375\n",
      "Epoch: 222, Batch number: 4, Loss: 10606.0361328125\n",
      "Epoch: 223, Batch number: 28, Loss: 10332.7978515625\n",
      "Epoch: 224, Batch number: 52, Loss: 10432.0166015625\n",
      "Epoch: 226, Batch number: 0, Loss: 10314.4638671875\n",
      "Epoch: 227, Batch number: 24, Loss: 10488.3154296875\n",
      "Epoch: 228, Batch number: 48, Loss: 10627.9130859375\n",
      "Epoch: 229, Batch number: 72, Loss: 10815.7158203125\n",
      "Epoch: 231, Batch number: 20, Loss: 10640.8642578125\n",
      "Epoch: 232, Batch number: 44, Loss: 10533.017578125\n",
      "Epoch: 233, Batch number: 68, Loss: 10280.3271484375\n",
      "Epoch: 235, Batch number: 16, Loss: 10465.234375\n",
      "Epoch: 236, Batch number: 40, Loss: 10834.21875\n",
      "Epoch: 237, Batch number: 64, Loss: 10413.59765625\n",
      "Epoch: 239, Batch number: 12, Loss: 10556.0908203125\n",
      "Epoch: 240, Batch number: 36, Loss: 10422.73828125\n",
      "Epoch: 241, Batch number: 60, Loss: 10474.5146484375\n",
      "Epoch: 243, Batch number: 8, Loss: 10460.6865234375\n",
      "Epoch: 244, Batch number: 32, Loss: 10695.3740234375\n",
      "Epoch: 245, Batch number: 56, Loss: 10563.09765625\n",
      "Epoch: 247, Batch number: 4, Loss: 10738.4794921875\n",
      "Epoch: 248, Batch number: 28, Loss: 10285.6162109375\n",
      "Epoch: 249, Batch number: 52, Loss: 10601.310546875\n",
      "Epoch: 251, Batch number: 0, Loss: 10211.201171875\n",
      "Epoch: 252, Batch number: 24, Loss: 10275.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 253, Batch number: 48, Loss: 10612.76171875\n",
      "Epoch: 254, Batch number: 72, Loss: 10762.8798828125\n",
      "Epoch: 256, Batch number: 20, Loss: 10708.3583984375\n",
      "Epoch: 257, Batch number: 44, Loss: 10855.720703125\n",
      "Epoch: 258, Batch number: 68, Loss: 10625.4775390625\n",
      "Epoch: 260, Batch number: 16, Loss: 10249.2783203125\n",
      "Epoch: 261, Batch number: 40, Loss: 10295.3486328125\n",
      "Epoch: 262, Batch number: 64, Loss: 10496.6396484375\n",
      "Epoch: 264, Batch number: 12, Loss: 10317.2236328125\n",
      "Epoch: 265, Batch number: 36, Loss: 10470.765625\n",
      "Epoch: 266, Batch number: 60, Loss: 10321.064453125\n",
      "Epoch: 268, Batch number: 8, Loss: 10239.1181640625\n",
      "Epoch: 269, Batch number: 32, Loss: 10507.0625\n",
      "Epoch: 270, Batch number: 56, Loss: 10424.455078125\n",
      "Epoch: 272, Batch number: 4, Loss: 10508.064453125\n",
      "Epoch: 273, Batch number: 28, Loss: 10501.9375\n",
      "Epoch: 274, Batch number: 52, Loss: 10704.9755859375\n",
      "Epoch: 276, Batch number: 0, Loss: 10268.794921875\n",
      "Epoch: 277, Batch number: 24, Loss: 10616.419921875\n",
      "Epoch: 278, Batch number: 48, Loss: 10896.146484375\n",
      "Epoch: 279, Batch number: 72, Loss: 10759.1953125\n",
      "Epoch: 281, Batch number: 20, Loss: 10452.689453125\n",
      "Epoch: 282, Batch number: 44, Loss: 10692.3583984375\n",
      "Epoch: 283, Batch number: 68, Loss: 10540.4013671875\n",
      "Epoch: 285, Batch number: 16, Loss: 10199.533203125\n",
      "Epoch: 286, Batch number: 40, Loss: 10379.2294921875\n",
      "Epoch: 287, Batch number: 64, Loss: 10603.419921875\n",
      "Epoch: 289, Batch number: 12, Loss: 10486.6826171875\n",
      "Epoch: 290, Batch number: 36, Loss: 10534.36328125\n",
      "Epoch: 291, Batch number: 60, Loss: 10375.5654296875\n",
      "Epoch: 293, Batch number: 8, Loss: 10135.0693359375\n",
      "Epoch: 294, Batch number: 32, Loss: 10365.3291015625\n",
      "Epoch: 295, Batch number: 56, Loss: 10789.2041015625\n",
      "Epoch: 297, Batch number: 4, Loss: 10219.9326171875\n",
      "Epoch: 298, Batch number: 28, Loss: 10442.029296875\n",
      "Epoch: 299, Batch number: 52, Loss: 10600.908203125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21436.822265625\n",
      "Epoch: 2, Batch number: 24, Loss: 19637.314453125\n",
      "Epoch: 3, Batch number: 48, Loss: 17518.87890625\n",
      "Epoch: 4, Batch number: 72, Loss: 17594.908203125\n",
      "Epoch: 6, Batch number: 20, Loss: 16545.01171875\n",
      "Epoch: 7, Batch number: 44, Loss: 15639.978515625\n",
      "Epoch: 8, Batch number: 68, Loss: 15464.9208984375\n",
      "Epoch: 10, Batch number: 16, Loss: 14484.2861328125\n",
      "Epoch: 11, Batch number: 40, Loss: 14003.087890625\n",
      "Epoch: 12, Batch number: 64, Loss: 14024.4033203125\n",
      "Epoch: 14, Batch number: 12, Loss: 13396.337890625\n",
      "Epoch: 15, Batch number: 36, Loss: 13127.2041015625\n",
      "Epoch: 16, Batch number: 60, Loss: 13284.5654296875\n",
      "Epoch: 18, Batch number: 8, Loss: 12516.791015625\n",
      "Epoch: 19, Batch number: 32, Loss: 12529.9736328125\n",
      "Epoch: 20, Batch number: 56, Loss: 12413.65234375\n",
      "Epoch: 22, Batch number: 4, Loss: 12021.8310546875\n",
      "Epoch: 23, Batch number: 28, Loss: 12281.5830078125\n",
      "Epoch: 24, Batch number: 52, Loss: 12104.4404296875\n",
      "Epoch: 26, Batch number: 0, Loss: 12262.791015625\n",
      "Epoch: 27, Batch number: 24, Loss: 12241.1767578125\n",
      "Epoch: 28, Batch number: 48, Loss: 12111.8984375\n",
      "Epoch: 29, Batch number: 72, Loss: 11773.3837890625\n",
      "Epoch: 31, Batch number: 20, Loss: 11575.2431640625\n",
      "Epoch: 32, Batch number: 44, Loss: 11671.486328125\n",
      "Epoch: 33, Batch number: 68, Loss: 11702.9384765625\n",
      "Epoch: 35, Batch number: 16, Loss: 11371.2529296875\n",
      "Epoch: 36, Batch number: 40, Loss: 11366.5810546875\n",
      "Epoch: 37, Batch number: 64, Loss: 11665.24609375\n",
      "Epoch: 39, Batch number: 12, Loss: 11261.865234375\n",
      "Epoch: 40, Batch number: 36, Loss: 11398.1318359375\n",
      "Epoch: 41, Batch number: 60, Loss: 11512.2490234375\n",
      "Epoch: 43, Batch number: 8, Loss: 11170.0244140625\n",
      "Epoch: 44, Batch number: 32, Loss: 11082.111328125\n",
      "Epoch: 45, Batch number: 56, Loss: 11089.25\n",
      "Epoch: 47, Batch number: 4, Loss: 11046.119140625\n",
      "Epoch: 48, Batch number: 28, Loss: 11090.6455078125\n",
      "Epoch: 49, Batch number: 52, Loss: 11516.3623046875\n",
      "Epoch: 51, Batch number: 0, Loss: 11307.685546875\n",
      "Epoch: 52, Batch number: 24, Loss: 11315.48046875\n",
      "Epoch: 53, Batch number: 48, Loss: 11140.134765625\n",
      "Epoch: 54, Batch number: 72, Loss: 11219.7529296875\n",
      "Epoch: 56, Batch number: 20, Loss: 11006.4541015625\n",
      "Epoch: 57, Batch number: 44, Loss: 11167.2333984375\n",
      "Epoch: 58, Batch number: 68, Loss: 10924.619140625\n",
      "Epoch: 60, Batch number: 16, Loss: 10886.7763671875\n",
      "Epoch: 61, Batch number: 40, Loss: 10918.478515625\n",
      "Epoch: 62, Batch number: 64, Loss: 11053.580078125\n",
      "Epoch: 64, Batch number: 12, Loss: 10740.5224609375\n",
      "Epoch: 65, Batch number: 36, Loss: 10798.9873046875\n",
      "Epoch: 66, Batch number: 60, Loss: 11077.6787109375\n",
      "Epoch: 68, Batch number: 8, Loss: 10928.3408203125\n",
      "Epoch: 69, Batch number: 32, Loss: 10393.2373046875\n",
      "Epoch: 70, Batch number: 56, Loss: 11008.560546875\n",
      "Epoch: 72, Batch number: 4, Loss: 10859.15625\n",
      "Epoch: 73, Batch number: 28, Loss: 10843.865234375\n",
      "Epoch: 74, Batch number: 52, Loss: 11046.859375\n",
      "Epoch: 76, Batch number: 0, Loss: 10562.32421875\n",
      "Epoch: 77, Batch number: 24, Loss: 10852.1767578125\n",
      "Epoch: 78, Batch number: 48, Loss: 11172.8955078125\n",
      "Epoch: 79, Batch number: 72, Loss: 11024.978515625\n",
      "Epoch: 81, Batch number: 20, Loss: 10538.4755859375\n",
      "Epoch: 82, Batch number: 44, Loss: 10908.9423828125\n",
      "Epoch: 83, Batch number: 68, Loss: 11258.6005859375\n",
      "Epoch: 85, Batch number: 16, Loss: 10833.697265625\n",
      "Epoch: 86, Batch number: 40, Loss: 10605.0009765625\n",
      "Epoch: 87, Batch number: 64, Loss: 10545.0029296875\n",
      "Epoch: 89, Batch number: 12, Loss: 10900.7763671875\n",
      "Epoch: 90, Batch number: 36, Loss: 10840.615234375\n",
      "Epoch: 91, Batch number: 60, Loss: 10993.1201171875\n",
      "Epoch: 93, Batch number: 8, Loss: 10564.3037109375\n",
      "Epoch: 94, Batch number: 32, Loss: 10588.73046875\n",
      "Epoch: 95, Batch number: 56, Loss: 10804.076171875\n",
      "Epoch: 97, Batch number: 4, Loss: 10816.125\n",
      "Epoch: 98, Batch number: 28, Loss: 10765.654296875\n",
      "Epoch: 99, Batch number: 52, Loss: 10701.5888671875\n",
      "Epoch: 101, Batch number: 0, Loss: 10517.5615234375\n",
      "Epoch: 102, Batch number: 24, Loss: 10623.9150390625\n",
      "Epoch: 103, Batch number: 48, Loss: 10577.533203125\n",
      "Epoch: 104, Batch number: 72, Loss: 10715.0390625\n",
      "Epoch: 106, Batch number: 20, Loss: 10717.578125\n",
      "Epoch: 107, Batch number: 44, Loss: 10737.591796875\n",
      "Epoch: 108, Batch number: 68, Loss: 10862.2939453125\n",
      "Epoch: 110, Batch number: 16, Loss: 10500.375\n",
      "Epoch: 111, Batch number: 40, Loss: 10233.6318359375\n",
      "Epoch: 112, Batch number: 64, Loss: 10404.40625\n",
      "Epoch: 114, Batch number: 12, Loss: 10401.80859375\n",
      "Epoch: 115, Batch number: 36, Loss: 10727.7900390625\n",
      "Epoch: 116, Batch number: 60, Loss: 10475.1025390625\n",
      "Epoch: 118, Batch number: 8, Loss: 10796.5517578125\n",
      "Epoch: 119, Batch number: 32, Loss: 10945.19140625\n",
      "Epoch: 120, Batch number: 56, Loss: 10534.6142578125\n",
      "Epoch: 122, Batch number: 4, Loss: 10743.37109375\n",
      "Epoch: 123, Batch number: 28, Loss: 10475.8154296875\n",
      "Epoch: 124, Batch number: 52, Loss: 10782.49609375\n",
      "Epoch: 126, Batch number: 0, Loss: 10714.4697265625\n",
      "Epoch: 127, Batch number: 24, Loss: 10552.0302734375\n",
      "Epoch: 128, Batch number: 48, Loss: 10796.63671875\n",
      "Epoch: 129, Batch number: 72, Loss: 10832.8779296875\n",
      "Epoch: 131, Batch number: 20, Loss: 10429.666015625\n",
      "Epoch: 132, Batch number: 44, Loss: 10719.6767578125\n",
      "Epoch: 133, Batch number: 68, Loss: 10809.365234375\n",
      "Epoch: 135, Batch number: 16, Loss: 10354.8330078125\n",
      "Epoch: 136, Batch number: 40, Loss: 10703.833984375\n",
      "Epoch: 137, Batch number: 64, Loss: 10683.9052734375\n",
      "Epoch: 139, Batch number: 12, Loss: 10353.4013671875\n",
      "Epoch: 140, Batch number: 36, Loss: 10436.197265625\n",
      "Epoch: 141, Batch number: 60, Loss: 10556.6484375\n",
      "Epoch: 143, Batch number: 8, Loss: 10610.791015625\n",
      "Epoch: 144, Batch number: 32, Loss: 10624.095703125\n",
      "Epoch: 145, Batch number: 56, Loss: 11097.4599609375\n",
      "Epoch: 147, Batch number: 4, Loss: 10406.87890625\n",
      "Epoch: 148, Batch number: 28, Loss: 10605.2890625\n",
      "Epoch: 149, Batch number: 52, Loss: 10571.177734375\n",
      "Epoch: 151, Batch number: 0, Loss: 10235.373046875\n",
      "Epoch: 152, Batch number: 24, Loss: 10342.353515625\n",
      "Epoch: 153, Batch number: 48, Loss: 10268.9892578125\n",
      "Epoch: 154, Batch number: 72, Loss: 10831.720703125\n",
      "Epoch: 156, Batch number: 20, Loss: 10556.021484375\n",
      "Epoch: 157, Batch number: 44, Loss: 10521.7373046875\n",
      "Epoch: 158, Batch number: 68, Loss: 10480.2705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Batch number: 16, Loss: 10382.34375\n",
      "Epoch: 161, Batch number: 40, Loss: 10821.2314453125\n",
      "Epoch: 162, Batch number: 64, Loss: 10276.1318359375\n",
      "Epoch: 164, Batch number: 12, Loss: 10609.1572265625\n",
      "Epoch: 165, Batch number: 36, Loss: 10598.97265625\n",
      "Epoch: 166, Batch number: 60, Loss: 10664.578125\n",
      "Epoch: 168, Batch number: 8, Loss: 10454.0751953125\n",
      "Epoch: 169, Batch number: 32, Loss: 10586.8017578125\n",
      "Epoch: 170, Batch number: 56, Loss: 10736.8916015625\n",
      "Epoch: 172, Batch number: 4, Loss: 10018.2109375\n",
      "Epoch: 173, Batch number: 28, Loss: 10556.7373046875\n",
      "Epoch: 174, Batch number: 52, Loss: 10582.1357421875\n",
      "Epoch: 176, Batch number: 0, Loss: 10218.6123046875\n",
      "Epoch: 177, Batch number: 24, Loss: 10334.2412109375\n",
      "Epoch: 178, Batch number: 48, Loss: 10320.6962890625\n",
      "Epoch: 179, Batch number: 72, Loss: 10302.521484375\n",
      "Epoch: 181, Batch number: 20, Loss: 10662.283203125\n",
      "Epoch: 182, Batch number: 44, Loss: 10508.140625\n",
      "Epoch: 183, Batch number: 68, Loss: 10527.8232421875\n",
      "Epoch: 185, Batch number: 16, Loss: 10476.5\n",
      "Epoch: 186, Batch number: 40, Loss: 10508.4150390625\n",
      "Epoch: 187, Batch number: 64, Loss: 10425.5751953125\n",
      "Epoch: 189, Batch number: 12, Loss: 10245.669921875\n",
      "Epoch: 190, Batch number: 36, Loss: 10180.15234375\n",
      "Epoch: 191, Batch number: 60, Loss: 10864.5419921875\n",
      "Epoch: 193, Batch number: 8, Loss: 10484.7919921875\n",
      "Epoch: 194, Batch number: 32, Loss: 10492.01953125\n",
      "Epoch: 195, Batch number: 56, Loss: 10867.00390625\n",
      "Epoch: 197, Batch number: 4, Loss: 10426.8671875\n",
      "Epoch: 198, Batch number: 28, Loss: 10459.892578125\n",
      "Epoch: 199, Batch number: 52, Loss: 10233.9423828125\n",
      "Epoch: 201, Batch number: 0, Loss: 10512.029296875\n",
      "Epoch: 202, Batch number: 24, Loss: 10402.6357421875\n",
      "Epoch: 203, Batch number: 48, Loss: 10396.3271484375\n",
      "Epoch: 204, Batch number: 72, Loss: 10441.9248046875\n",
      "Epoch: 206, Batch number: 20, Loss: 10589.7353515625\n",
      "Epoch: 207, Batch number: 44, Loss: 10492.3720703125\n",
      "Epoch: 208, Batch number: 68, Loss: 10582.1279296875\n",
      "Epoch: 210, Batch number: 16, Loss: 10433.3662109375\n",
      "Epoch: 211, Batch number: 40, Loss: 10200.46875\n",
      "Epoch: 212, Batch number: 64, Loss: 10520.0458984375\n",
      "Epoch: 214, Batch number: 12, Loss: 10347.953125\n",
      "Epoch: 215, Batch number: 36, Loss: 10238.6962890625\n",
      "Epoch: 216, Batch number: 60, Loss: 10474.240234375\n",
      "Epoch: 218, Batch number: 8, Loss: 10080.48828125\n",
      "Epoch: 219, Batch number: 32, Loss: 10855.744140625\n",
      "Epoch: 220, Batch number: 56, Loss: 10626.61328125\n",
      "Epoch: 222, Batch number: 4, Loss: 10146.4921875\n",
      "Epoch: 223, Batch number: 28, Loss: 10604.337890625\n",
      "Epoch: 224, Batch number: 52, Loss: 10296.693359375\n",
      "Epoch: 226, Batch number: 0, Loss: 10213.927734375\n",
      "Epoch: 227, Batch number: 24, Loss: 10614.2568359375\n",
      "Epoch: 228, Batch number: 48, Loss: 10742.76171875\n",
      "Epoch: 229, Batch number: 72, Loss: 10845.2421875\n",
      "Epoch: 231, Batch number: 20, Loss: 10321.6806640625\n",
      "Epoch: 232, Batch number: 44, Loss: 10521.5380859375\n",
      "Epoch: 233, Batch number: 68, Loss: 10701.4638671875\n",
      "Epoch: 235, Batch number: 16, Loss: 10306.8408203125\n",
      "Epoch: 236, Batch number: 40, Loss: 10722.923828125\n",
      "Epoch: 237, Batch number: 64, Loss: 10752.7763671875\n",
      "Epoch: 239, Batch number: 12, Loss: 10536.4384765625\n",
      "Epoch: 240, Batch number: 36, Loss: 10291.44921875\n",
      "Epoch: 241, Batch number: 60, Loss: 10233.5576171875\n",
      "Epoch: 243, Batch number: 8, Loss: 10579.193359375\n",
      "Epoch: 244, Batch number: 32, Loss: 10613.0869140625\n",
      "Epoch: 245, Batch number: 56, Loss: 10617.7021484375\n",
      "Epoch: 247, Batch number: 4, Loss: 9977.1171875\n",
      "Epoch: 248, Batch number: 28, Loss: 10295.3359375\n",
      "Epoch: 249, Batch number: 52, Loss: 11001.15625\n",
      "Epoch: 251, Batch number: 0, Loss: 10154.142578125\n",
      "Epoch: 252, Batch number: 24, Loss: 10195.4208984375\n",
      "Epoch: 253, Batch number: 48, Loss: 10722.8583984375\n",
      "Epoch: 254, Batch number: 72, Loss: 10576.80859375\n",
      "Epoch: 256, Batch number: 20, Loss: 10332.70703125\n",
      "Epoch: 257, Batch number: 44, Loss: 10539.4052734375\n",
      "Epoch: 258, Batch number: 68, Loss: 10614.5244140625\n",
      "Epoch: 260, Batch number: 16, Loss: 10494.2080078125\n",
      "Epoch: 261, Batch number: 40, Loss: 10520.841796875\n",
      "Epoch: 262, Batch number: 64, Loss: 10888.908203125\n",
      "Epoch: 264, Batch number: 12, Loss: 10289.078125\n",
      "Epoch: 265, Batch number: 36, Loss: 10524.98046875\n",
      "Epoch: 266, Batch number: 60, Loss: 10701.0087890625\n",
      "Epoch: 268, Batch number: 8, Loss: 10088.4208984375\n",
      "Epoch: 269, Batch number: 32, Loss: 10260.4794921875\n",
      "Epoch: 270, Batch number: 56, Loss: 10254.2734375\n",
      "Epoch: 272, Batch number: 4, Loss: 10629.798828125\n",
      "Epoch: 273, Batch number: 28, Loss: 10601.3818359375\n",
      "Epoch: 274, Batch number: 52, Loss: 10590.9892578125\n",
      "Epoch: 276, Batch number: 0, Loss: 10326.6171875\n",
      "Epoch: 277, Batch number: 24, Loss: 10516.2216796875\n",
      "Epoch: 278, Batch number: 48, Loss: 10443.97265625\n",
      "Epoch: 279, Batch number: 72, Loss: 10339.6494140625\n",
      "Epoch: 281, Batch number: 20, Loss: 10619.4296875\n",
      "Epoch: 282, Batch number: 44, Loss: 10458.0830078125\n",
      "Epoch: 283, Batch number: 68, Loss: 10997.8330078125\n",
      "Epoch: 285, Batch number: 16, Loss: 10254.521484375\n",
      "Epoch: 286, Batch number: 40, Loss: 10684.3916015625\n",
      "Epoch: 287, Batch number: 64, Loss: 10249.9560546875\n",
      "Epoch: 289, Batch number: 12, Loss: 10273.328125\n",
      "Epoch: 290, Batch number: 36, Loss: 10572.9951171875\n",
      "Epoch: 291, Batch number: 60, Loss: 10314.4921875\n",
      "Epoch: 293, Batch number: 8, Loss: 10323.349609375\n",
      "Epoch: 294, Batch number: 32, Loss: 10309.6064453125\n",
      "Epoch: 295, Batch number: 56, Loss: 10429.306640625\n",
      "Epoch: 297, Batch number: 4, Loss: 10041.29296875\n",
      "Epoch: 298, Batch number: 28, Loss: 10391.9580078125\n",
      "Epoch: 299, Batch number: 52, Loss: 10744.6826171875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 21584.052734375\n",
      "Epoch: 2, Batch number: 24, Loss: 19035.28125\n",
      "Epoch: 3, Batch number: 48, Loss: 17603.705078125\n",
      "Epoch: 4, Batch number: 72, Loss: 16751.173828125\n",
      "Epoch: 6, Batch number: 20, Loss: 15888.7548828125\n",
      "Epoch: 7, Batch number: 44, Loss: 14966.6328125\n",
      "Epoch: 8, Batch number: 68, Loss: 14584.2294921875\n",
      "Epoch: 10, Batch number: 16, Loss: 13535.67578125\n",
      "Epoch: 11, Batch number: 40, Loss: 13587.328125\n",
      "Epoch: 12, Batch number: 64, Loss: 13277.162109375\n",
      "Epoch: 14, Batch number: 12, Loss: 12381.6748046875\n",
      "Epoch: 15, Batch number: 36, Loss: 12775.6865234375\n",
      "Epoch: 16, Batch number: 60, Loss: 12326.060546875\n",
      "Epoch: 18, Batch number: 8, Loss: 11890.2578125\n",
      "Epoch: 19, Batch number: 32, Loss: 12249.0048828125\n",
      "Epoch: 20, Batch number: 56, Loss: 11909.470703125\n",
      "Epoch: 22, Batch number: 4, Loss: 11778.091796875\n",
      "Epoch: 23, Batch number: 28, Loss: 11892.4501953125\n",
      "Epoch: 24, Batch number: 52, Loss: 11794.1630859375\n",
      "Epoch: 26, Batch number: 0, Loss: 11346.431640625\n",
      "Epoch: 27, Batch number: 24, Loss: 11834.505859375\n",
      "Epoch: 28, Batch number: 48, Loss: 11618.8701171875\n",
      "Epoch: 29, Batch number: 72, Loss: 11624.947265625\n",
      "Epoch: 31, Batch number: 20, Loss: 11105.1259765625\n",
      "Epoch: 32, Batch number: 44, Loss: 11287.234375\n",
      "Epoch: 33, Batch number: 68, Loss: 11517.1689453125\n",
      "Epoch: 35, Batch number: 16, Loss: 11021.76171875\n",
      "Epoch: 36, Batch number: 40, Loss: 11557.994140625\n",
      "Epoch: 37, Batch number: 64, Loss: 11370.8330078125\n",
      "Epoch: 39, Batch number: 12, Loss: 11184.966796875\n",
      "Epoch: 40, Batch number: 36, Loss: 10960.744140625\n",
      "Epoch: 41, Batch number: 60, Loss: 10711.943359375\n",
      "Epoch: 43, Batch number: 8, Loss: 11330.984375\n",
      "Epoch: 44, Batch number: 32, Loss: 11205.40234375\n",
      "Epoch: 45, Batch number: 56, Loss: 10837.9169921875\n",
      "Epoch: 47, Batch number: 4, Loss: 10549.7861328125\n",
      "Epoch: 48, Batch number: 28, Loss: 10951.126953125\n",
      "Epoch: 49, Batch number: 52, Loss: 11090.015625\n",
      "Epoch: 51, Batch number: 0, Loss: 10912.54296875\n",
      "Epoch: 52, Batch number: 24, Loss: 11258.015625\n",
      "Epoch: 53, Batch number: 48, Loss: 10883.857421875\n",
      "Epoch: 54, Batch number: 72, Loss: 10909.4755859375\n",
      "Epoch: 56, Batch number: 20, Loss: 10925.2763671875\n",
      "Epoch: 57, Batch number: 44, Loss: 10903.251953125\n",
      "Epoch: 58, Batch number: 68, Loss: 11306.052734375\n",
      "Epoch: 60, Batch number: 16, Loss: 10973.1640625\n",
      "Epoch: 61, Batch number: 40, Loss: 10781.2724609375\n",
      "Epoch: 62, Batch number: 64, Loss: 11104.9873046875\n",
      "Epoch: 64, Batch number: 12, Loss: 10628.99609375\n",
      "Epoch: 65, Batch number: 36, Loss: 11185.89453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Batch number: 60, Loss: 10890.7919921875\n",
      "Epoch: 68, Batch number: 8, Loss: 10402.3271484375\n",
      "Epoch: 69, Batch number: 32, Loss: 10561.6650390625\n",
      "Epoch: 70, Batch number: 56, Loss: 10653.2158203125\n",
      "Epoch: 72, Batch number: 4, Loss: 10394.9287109375\n",
      "Epoch: 73, Batch number: 28, Loss: 10761.4375\n",
      "Epoch: 74, Batch number: 52, Loss: 10902.21875\n",
      "Epoch: 76, Batch number: 0, Loss: 10589.751953125\n",
      "Epoch: 77, Batch number: 24, Loss: 10310.82421875\n",
      "Epoch: 78, Batch number: 48, Loss: 10637.6923828125\n",
      "Epoch: 79, Batch number: 72, Loss: 11062.0927734375\n",
      "Epoch: 81, Batch number: 20, Loss: 10678.5703125\n",
      "Epoch: 82, Batch number: 44, Loss: 10621.7451171875\n",
      "Epoch: 83, Batch number: 68, Loss: 11310.8447265625\n",
      "Epoch: 85, Batch number: 16, Loss: 10409.6513671875\n",
      "Epoch: 86, Batch number: 40, Loss: 10403.0400390625\n",
      "Epoch: 87, Batch number: 64, Loss: 10611.21484375\n",
      "Epoch: 89, Batch number: 12, Loss: 10127.8017578125\n",
      "Epoch: 90, Batch number: 36, Loss: 10566.6865234375\n",
      "Epoch: 91, Batch number: 60, Loss: 10719.93359375\n",
      "Epoch: 93, Batch number: 8, Loss: 10420.6748046875\n",
      "Epoch: 94, Batch number: 32, Loss: 10543.5791015625\n",
      "Epoch: 95, Batch number: 56, Loss: 10994.0517578125\n",
      "Epoch: 97, Batch number: 4, Loss: 10402.310546875\n",
      "Epoch: 98, Batch number: 28, Loss: 10667.8466796875\n",
      "Epoch: 99, Batch number: 52, Loss: 10957.7783203125\n",
      "Epoch: 101, Batch number: 0, Loss: 10732.1728515625\n",
      "Epoch: 102, Batch number: 24, Loss: 10505.978515625\n",
      "Epoch: 103, Batch number: 48, Loss: 10847.435546875\n",
      "Epoch: 104, Batch number: 72, Loss: 10842.9970703125\n",
      "Epoch: 106, Batch number: 20, Loss: 10465.31640625\n",
      "Epoch: 107, Batch number: 44, Loss: 10587.1064453125\n",
      "Epoch: 108, Batch number: 68, Loss: 10616.2890625\n",
      "Epoch: 110, Batch number: 16, Loss: 10639.595703125\n",
      "Epoch: 111, Batch number: 40, Loss: 10413.83984375\n",
      "Epoch: 112, Batch number: 64, Loss: 10376.544921875\n",
      "Epoch: 114, Batch number: 12, Loss: 10417.0791015625\n",
      "Epoch: 115, Batch number: 36, Loss: 10688.5263671875\n",
      "Epoch: 116, Batch number: 60, Loss: 10540.3583984375\n",
      "Epoch: 118, Batch number: 8, Loss: 10572.2783203125\n",
      "Epoch: 119, Batch number: 32, Loss: 10611.99609375\n",
      "Epoch: 120, Batch number: 56, Loss: 11181.9345703125\n",
      "Epoch: 122, Batch number: 4, Loss: 10549.1171875\n",
      "Epoch: 123, Batch number: 28, Loss: 10317.599609375\n",
      "Epoch: 124, Batch number: 52, Loss: 10947.2470703125\n",
      "Epoch: 126, Batch number: 0, Loss: 10716.5498046875\n",
      "Epoch: 127, Batch number: 24, Loss: 10658.794921875\n",
      "Epoch: 128, Batch number: 48, Loss: 10373.3369140625\n",
      "Epoch: 129, Batch number: 72, Loss: 10590.7978515625\n",
      "Epoch: 131, Batch number: 20, Loss: 10440.9150390625\n",
      "Epoch: 132, Batch number: 44, Loss: 10059.3876953125\n",
      "Epoch: 133, Batch number: 68, Loss: 10740.240234375\n",
      "Epoch: 135, Batch number: 16, Loss: 10595.3798828125\n",
      "Epoch: 136, Batch number: 40, Loss: 10496.4697265625\n",
      "Epoch: 137, Batch number: 64, Loss: 10746.3134765625\n",
      "Epoch: 139, Batch number: 12, Loss: 10400.369140625\n",
      "Epoch: 140, Batch number: 36, Loss: 10983.376953125\n",
      "Epoch: 141, Batch number: 60, Loss: 10452.25\n",
      "Epoch: 143, Batch number: 8, Loss: 10248.2998046875\n",
      "Epoch: 144, Batch number: 32, Loss: 10430.3046875\n",
      "Epoch: 145, Batch number: 56, Loss: 10750.41796875\n",
      "Epoch: 147, Batch number: 4, Loss: 10280.2734375\n",
      "Epoch: 148, Batch number: 28, Loss: 10477.9765625\n",
      "Epoch: 149, Batch number: 52, Loss: 10625.6201171875\n",
      "Epoch: 151, Batch number: 0, Loss: 10069.5693359375\n",
      "Epoch: 152, Batch number: 24, Loss: 10433.1904296875\n",
      "Epoch: 153, Batch number: 48, Loss: 10298.373046875\n",
      "Epoch: 154, Batch number: 72, Loss: 10471.8466796875\n",
      "Epoch: 156, Batch number: 20, Loss: 10387.7080078125\n",
      "Epoch: 157, Batch number: 44, Loss: 10556.8173828125\n",
      "Epoch: 158, Batch number: 68, Loss: 10771.6123046875\n",
      "Epoch: 160, Batch number: 16, Loss: 10343.74609375\n",
      "Epoch: 161, Batch number: 40, Loss: 10646.3203125\n",
      "Epoch: 162, Batch number: 64, Loss: 10610.4541015625\n",
      "Epoch: 164, Batch number: 12, Loss: 10138.546875\n",
      "Epoch: 165, Batch number: 36, Loss: 10399.708984375\n",
      "Epoch: 166, Batch number: 60, Loss: 10444.07421875\n",
      "Epoch: 168, Batch number: 8, Loss: 10687.466796875\n",
      "Epoch: 169, Batch number: 32, Loss: 10629.3662109375\n",
      "Epoch: 170, Batch number: 56, Loss: 10719.908203125\n",
      "Epoch: 172, Batch number: 4, Loss: 10509.69140625\n",
      "Epoch: 173, Batch number: 28, Loss: 10273.3046875\n",
      "Epoch: 174, Batch number: 52, Loss: 10650.5498046875\n",
      "Epoch: 176, Batch number: 0, Loss: 10628.619140625\n",
      "Epoch: 177, Batch number: 24, Loss: 10308.875\n",
      "Epoch: 178, Batch number: 48, Loss: 10338.9013671875\n",
      "Epoch: 179, Batch number: 72, Loss: 10851.189453125\n",
      "Epoch: 181, Batch number: 20, Loss: 10462.255859375\n",
      "Epoch: 182, Batch number: 44, Loss: 10565.02734375\n",
      "Epoch: 183, Batch number: 68, Loss: 10694.0126953125\n",
      "Epoch: 185, Batch number: 16, Loss: 10360.4111328125\n",
      "Epoch: 186, Batch number: 40, Loss: 10537.9052734375\n",
      "Epoch: 187, Batch number: 64, Loss: 10772.06640625\n",
      "Epoch: 189, Batch number: 12, Loss: 10104.14453125\n",
      "Epoch: 190, Batch number: 36, Loss: 10532.2041015625\n",
      "Epoch: 191, Batch number: 60, Loss: 10576.4150390625\n",
      "Epoch: 193, Batch number: 8, Loss: 10519.1240234375\n",
      "Epoch: 194, Batch number: 32, Loss: 10480.3251953125\n",
      "Epoch: 195, Batch number: 56, Loss: 10481.2392578125\n",
      "Epoch: 197, Batch number: 4, Loss: 10216.1591796875\n",
      "Epoch: 198, Batch number: 28, Loss: 10677.498046875\n",
      "Epoch: 199, Batch number: 52, Loss: 11106.8173828125\n",
      "Epoch: 201, Batch number: 0, Loss: 10775.4375\n",
      "Epoch: 202, Batch number: 24, Loss: 10709.392578125\n",
      "Epoch: 203, Batch number: 48, Loss: 10775.064453125\n",
      "Epoch: 204, Batch number: 72, Loss: 10732.4365234375\n",
      "Epoch: 206, Batch number: 20, Loss: 10573.72265625\n",
      "Epoch: 207, Batch number: 44, Loss: 10494.552734375\n",
      "Epoch: 208, Batch number: 68, Loss: 11084.9013671875\n",
      "Epoch: 210, Batch number: 16, Loss: 10292.732421875\n",
      "Epoch: 211, Batch number: 40, Loss: 10479.6982421875\n",
      "Epoch: 212, Batch number: 64, Loss: 10467.7841796875\n",
      "Epoch: 214, Batch number: 12, Loss: 10583.1103515625\n",
      "Epoch: 215, Batch number: 36, Loss: 10660.759765625\n",
      "Epoch: 216, Batch number: 60, Loss: 10428.3681640625\n",
      "Epoch: 218, Batch number: 8, Loss: 10459.7783203125\n",
      "Epoch: 219, Batch number: 32, Loss: 10332.8056640625\n",
      "Epoch: 220, Batch number: 56, Loss: 10319.29296875\n",
      "Epoch: 222, Batch number: 4, Loss: 10642.66796875\n",
      "Epoch: 223, Batch number: 28, Loss: 10489.78515625\n",
      "Epoch: 224, Batch number: 52, Loss: 10609.98046875\n",
      "Epoch: 226, Batch number: 0, Loss: 10202.7255859375\n",
      "Epoch: 227, Batch number: 24, Loss: 10486.3330078125\n",
      "Epoch: 228, Batch number: 48, Loss: 10123.31640625\n",
      "Epoch: 229, Batch number: 72, Loss: 10504.06640625\n",
      "Epoch: 231, Batch number: 20, Loss: 10229.14453125\n",
      "Epoch: 232, Batch number: 44, Loss: 10358.8466796875\n",
      "Epoch: 233, Batch number: 68, Loss: 10393.4404296875\n",
      "Epoch: 235, Batch number: 16, Loss: 10241.6220703125\n",
      "Epoch: 236, Batch number: 40, Loss: 11113.86328125\n",
      "Epoch: 237, Batch number: 64, Loss: 10590.2041015625\n",
      "Epoch: 239, Batch number: 12, Loss: 10713.8291015625\n",
      "Epoch: 240, Batch number: 36, Loss: 10724.9248046875\n",
      "Epoch: 241, Batch number: 60, Loss: 10330.8935546875\n",
      "Epoch: 243, Batch number: 8, Loss: 10647.1787109375\n",
      "Epoch: 244, Batch number: 32, Loss: 10163.9404296875\n",
      "Epoch: 245, Batch number: 56, Loss: 10869.912109375\n",
      "Epoch: 247, Batch number: 4, Loss: 10956.6484375\n",
      "Epoch: 248, Batch number: 28, Loss: 10517.0419921875\n",
      "Epoch: 249, Batch number: 52, Loss: 10844.103515625\n",
      "Epoch: 251, Batch number: 0, Loss: 10534.736328125\n",
      "Epoch: 252, Batch number: 24, Loss: 10228.6865234375\n",
      "Epoch: 253, Batch number: 48, Loss: 10218.6806640625\n",
      "Epoch: 254, Batch number: 72, Loss: 10722.0107421875\n",
      "Epoch: 256, Batch number: 20, Loss: 10598.384765625\n",
      "Epoch: 257, Batch number: 44, Loss: 10655.1689453125\n",
      "Epoch: 258, Batch number: 68, Loss: 10686.880859375\n",
      "Epoch: 260, Batch number: 16, Loss: 10601.890625\n",
      "Epoch: 261, Batch number: 40, Loss: 10365.4599609375\n",
      "Epoch: 262, Batch number: 64, Loss: 10622.3671875\n",
      "Epoch: 264, Batch number: 12, Loss: 9937.5859375\n",
      "Epoch: 265, Batch number: 36, Loss: 10785.7890625\n",
      "Epoch: 266, Batch number: 60, Loss: 10887.3857421875\n",
      "Epoch: 268, Batch number: 8, Loss: 10317.5107421875\n",
      "Epoch: 269, Batch number: 32, Loss: 10517.556640625\n",
      "Epoch: 270, Batch number: 56, Loss: 10456.4462890625\n",
      "Epoch: 272, Batch number: 4, Loss: 10440.759765625\n",
      "Epoch: 273, Batch number: 28, Loss: 10518.4208984375\n",
      "Epoch: 274, Batch number: 52, Loss: 10712.8623046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 276, Batch number: 0, Loss: 10649.076171875\n",
      "Epoch: 277, Batch number: 24, Loss: 10537.8994140625\n",
      "Epoch: 278, Batch number: 48, Loss: 10498.4365234375\n",
      "Epoch: 279, Batch number: 72, Loss: 10249.0400390625\n",
      "Epoch: 281, Batch number: 20, Loss: 10538.8447265625\n",
      "Epoch: 282, Batch number: 44, Loss: 10841.5556640625\n",
      "Epoch: 283, Batch number: 68, Loss: 10788.2919921875\n",
      "Epoch: 285, Batch number: 16, Loss: 10343.982421875\n",
      "Epoch: 286, Batch number: 40, Loss: 10969.4169921875\n",
      "Epoch: 287, Batch number: 64, Loss: 10391.2236328125\n",
      "Epoch: 289, Batch number: 12, Loss: 10200.966796875\n",
      "Epoch: 290, Batch number: 36, Loss: 10595.6201171875\n",
      "Epoch: 291, Batch number: 60, Loss: 10836.64453125\n",
      "Epoch: 293, Batch number: 8, Loss: 10571.10546875\n",
      "Epoch: 294, Batch number: 32, Loss: 10804.58203125\n",
      "Epoch: 295, Batch number: 56, Loss: 10434.880859375\n",
      "Epoch: 297, Batch number: 4, Loss: 10290.1240234375\n",
      "Epoch: 298, Batch number: 28, Loss: 10682.587890625\n",
      "Epoch: 299, Batch number: 52, Loss: 10516.5595703125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 27365.255859375\n",
      "Epoch: 2, Batch number: 24, Loss: 26302.125\n",
      "Epoch: 3, Batch number: 48, Loss: 25870.802734375\n",
      "Epoch: 4, Batch number: 72, Loss: 24767.5546875\n",
      "Epoch: 6, Batch number: 20, Loss: 23483.611328125\n",
      "Epoch: 7, Batch number: 44, Loss: 23267.1875\n",
      "Epoch: 8, Batch number: 68, Loss: 22133.5390625\n",
      "Epoch: 10, Batch number: 16, Loss: 21979.7265625\n",
      "Epoch: 11, Batch number: 40, Loss: 21753.79296875\n",
      "Epoch: 12, Batch number: 64, Loss: 21543.0390625\n",
      "Epoch: 14, Batch number: 12, Loss: 20624.1484375\n",
      "Epoch: 15, Batch number: 36, Loss: 20603.509765625\n",
      "Epoch: 16, Batch number: 60, Loss: 20039.640625\n",
      "Epoch: 18, Batch number: 8, Loss: 20675.333984375\n",
      "Epoch: 19, Batch number: 32, Loss: 19975.9609375\n",
      "Epoch: 20, Batch number: 56, Loss: 19627.40625\n",
      "Epoch: 22, Batch number: 4, Loss: 19168.224609375\n",
      "Epoch: 23, Batch number: 28, Loss: 19722.171875\n",
      "Epoch: 24, Batch number: 52, Loss: 19411.818359375\n",
      "Epoch: 26, Batch number: 0, Loss: 19237.30859375\n",
      "Epoch: 27, Batch number: 24, Loss: 19146.71875\n",
      "Epoch: 28, Batch number: 48, Loss: 18544.15625\n",
      "Epoch: 29, Batch number: 72, Loss: 18763.8359375\n",
      "Epoch: 31, Batch number: 20, Loss: 18943.5859375\n",
      "Epoch: 32, Batch number: 44, Loss: 18527.70703125\n",
      "Epoch: 33, Batch number: 68, Loss: 18517.490234375\n",
      "Epoch: 35, Batch number: 16, Loss: 18928.11328125\n",
      "Epoch: 36, Batch number: 40, Loss: 18295.154296875\n",
      "Epoch: 37, Batch number: 64, Loss: 18207.591796875\n",
      "Epoch: 39, Batch number: 12, Loss: 18280.095703125\n",
      "Epoch: 40, Batch number: 36, Loss: 18531.078125\n",
      "Epoch: 41, Batch number: 60, Loss: 18682.62109375\n",
      "Epoch: 43, Batch number: 8, Loss: 18249.587890625\n",
      "Epoch: 44, Batch number: 32, Loss: 17810.24609375\n",
      "Epoch: 45, Batch number: 56, Loss: 18236.81640625\n",
      "Epoch: 47, Batch number: 4, Loss: 17815.55078125\n",
      "Epoch: 48, Batch number: 28, Loss: 17703.259765625\n",
      "Epoch: 49, Batch number: 52, Loss: 17756.396484375\n",
      "Epoch: 51, Batch number: 0, Loss: 17591.388671875\n",
      "Epoch: 52, Batch number: 24, Loss: 17661.990234375\n",
      "Epoch: 53, Batch number: 48, Loss: 17435.4140625\n",
      "Epoch: 54, Batch number: 72, Loss: 17702.81640625\n",
      "Epoch: 56, Batch number: 20, Loss: 17543.6875\n",
      "Epoch: 57, Batch number: 44, Loss: 18144.19921875\n",
      "Epoch: 58, Batch number: 68, Loss: 17480.0859375\n",
      "Epoch: 60, Batch number: 16, Loss: 17934.28125\n",
      "Epoch: 61, Batch number: 40, Loss: 17282.177734375\n",
      "Epoch: 62, Batch number: 64, Loss: 17292.0234375\n",
      "Epoch: 64, Batch number: 12, Loss: 17250.66796875\n",
      "Epoch: 65, Batch number: 36, Loss: 17198.6953125\n",
      "Epoch: 66, Batch number: 60, Loss: 16977.9296875\n",
      "Epoch: 68, Batch number: 8, Loss: 16933.75\n",
      "Epoch: 69, Batch number: 32, Loss: 17271.771484375\n",
      "Epoch: 70, Batch number: 56, Loss: 16905.9453125\n",
      "Epoch: 72, Batch number: 4, Loss: 17028.296875\n",
      "Epoch: 73, Batch number: 28, Loss: 17199.2265625\n",
      "Epoch: 74, Batch number: 52, Loss: 17284.853515625\n",
      "Epoch: 76, Batch number: 0, Loss: 17348.455078125\n",
      "Epoch: 77, Batch number: 24, Loss: 16943.474609375\n",
      "Epoch: 78, Batch number: 48, Loss: 16993.955078125\n",
      "Epoch: 79, Batch number: 72, Loss: 16914.474609375\n",
      "Epoch: 81, Batch number: 20, Loss: 17074.513671875\n",
      "Epoch: 82, Batch number: 44, Loss: 17067.87109375\n",
      "Epoch: 83, Batch number: 68, Loss: 16627.458984375\n",
      "Epoch: 85, Batch number: 16, Loss: 17063.87109375\n",
      "Epoch: 86, Batch number: 40, Loss: 16632.310546875\n",
      "Epoch: 87, Batch number: 64, Loss: 16891.193359375\n",
      "Epoch: 89, Batch number: 12, Loss: 16826.00390625\n",
      "Epoch: 90, Batch number: 36, Loss: 16541.19140625\n",
      "Epoch: 91, Batch number: 60, Loss: 16847.12890625\n",
      "Epoch: 93, Batch number: 8, Loss: 16479.3828125\n",
      "Epoch: 94, Batch number: 32, Loss: 16753.859375\n",
      "Epoch: 95, Batch number: 56, Loss: 17258.32421875\n",
      "Epoch: 97, Batch number: 4, Loss: 16216.3681640625\n",
      "Epoch: 98, Batch number: 28, Loss: 16792.34375\n",
      "Epoch: 99, Batch number: 52, Loss: 16425.564453125\n",
      "Epoch: 101, Batch number: 0, Loss: 16762.99609375\n",
      "Epoch: 102, Batch number: 24, Loss: 16701.044921875\n",
      "Epoch: 103, Batch number: 48, Loss: 16789.765625\n",
      "Epoch: 104, Batch number: 72, Loss: 16564.1171875\n",
      "Epoch: 106, Batch number: 20, Loss: 16612.921875\n",
      "Epoch: 107, Batch number: 44, Loss: 16222.119140625\n",
      "Epoch: 108, Batch number: 68, Loss: 16559.759765625\n",
      "Epoch: 110, Batch number: 16, Loss: 16344.4970703125\n",
      "Epoch: 111, Batch number: 40, Loss: 16339.0869140625\n",
      "Epoch: 112, Batch number: 64, Loss: 16410.365234375\n",
      "Epoch: 114, Batch number: 12, Loss: 16359.130859375\n",
      "Epoch: 115, Batch number: 36, Loss: 16312.5390625\n",
      "Epoch: 116, Batch number: 60, Loss: 16246.0771484375\n",
      "Epoch: 118, Batch number: 8, Loss: 16543.75\n",
      "Epoch: 119, Batch number: 32, Loss: 16583.521484375\n",
      "Epoch: 120, Batch number: 56, Loss: 15935.6083984375\n",
      "Epoch: 122, Batch number: 4, Loss: 15980.7275390625\n",
      "Epoch: 123, Batch number: 28, Loss: 16317.6630859375\n",
      "Epoch: 124, Batch number: 52, Loss: 16122.634765625\n",
      "Epoch: 126, Batch number: 0, Loss: 15797.533203125\n",
      "Epoch: 127, Batch number: 24, Loss: 16250.1513671875\n",
      "Epoch: 128, Batch number: 48, Loss: 16245.4208984375\n",
      "Epoch: 129, Batch number: 72, Loss: 15988.873046875\n",
      "Epoch: 131, Batch number: 20, Loss: 15945.0703125\n",
      "Epoch: 132, Batch number: 44, Loss: 16074.974609375\n",
      "Epoch: 133, Batch number: 68, Loss: 16269.4609375\n",
      "Epoch: 135, Batch number: 16, Loss: 16080.4638671875\n",
      "Epoch: 136, Batch number: 40, Loss: 16107.9482421875\n",
      "Epoch: 137, Batch number: 64, Loss: 15757.7900390625\n",
      "Epoch: 139, Batch number: 12, Loss: 15773.7529296875\n",
      "Epoch: 140, Batch number: 36, Loss: 16061.5166015625\n",
      "Epoch: 141, Batch number: 60, Loss: 15791.8681640625\n",
      "Epoch: 143, Batch number: 8, Loss: 16006.9912109375\n",
      "Epoch: 144, Batch number: 32, Loss: 15769.4619140625\n",
      "Epoch: 145, Batch number: 56, Loss: 15714.2236328125\n",
      "Epoch: 147, Batch number: 4, Loss: 15797.955078125\n",
      "Epoch: 148, Batch number: 28, Loss: 15841.4052734375\n",
      "Epoch: 149, Batch number: 52, Loss: 15608.8447265625\n",
      "Epoch: 151, Batch number: 0, Loss: 16021.767578125\n",
      "Epoch: 152, Batch number: 24, Loss: 15582.6767578125\n",
      "Epoch: 153, Batch number: 48, Loss: 15771.5537109375\n",
      "Epoch: 154, Batch number: 72, Loss: 15700.6953125\n",
      "Epoch: 156, Batch number: 20, Loss: 16003.2646484375\n",
      "Epoch: 157, Batch number: 44, Loss: 15780.9853515625\n",
      "Epoch: 158, Batch number: 68, Loss: 15476.3984375\n",
      "Epoch: 160, Batch number: 16, Loss: 15525.4609375\n",
      "Epoch: 161, Batch number: 40, Loss: 15940.9892578125\n",
      "Epoch: 162, Batch number: 64, Loss: 15641.1337890625\n",
      "Epoch: 164, Batch number: 12, Loss: 15609.794921875\n",
      "Epoch: 165, Batch number: 36, Loss: 15416.5478515625\n",
      "Epoch: 166, Batch number: 60, Loss: 15471.94140625\n",
      "Epoch: 168, Batch number: 8, Loss: 15800.0693359375\n",
      "Epoch: 169, Batch number: 32, Loss: 15831.69921875\n",
      "Epoch: 170, Batch number: 56, Loss: 15575.740234375\n",
      "Epoch: 172, Batch number: 4, Loss: 15641.453125\n",
      "Epoch: 173, Batch number: 28, Loss: 15435.345703125\n",
      "Epoch: 174, Batch number: 52, Loss: 15462.9072265625\n",
      "Epoch: 176, Batch number: 0, Loss: 15719.02734375\n",
      "Epoch: 177, Batch number: 24, Loss: 15515.173828125\n",
      "Epoch: 178, Batch number: 48, Loss: 15504.2138671875\n",
      "Epoch: 179, Batch number: 72, Loss: 15980.9609375\n",
      "Epoch: 181, Batch number: 20, Loss: 15193.6142578125\n",
      "Epoch: 182, Batch number: 44, Loss: 15647.3701171875\n",
      "Epoch: 183, Batch number: 68, Loss: 15299.4296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, Batch number: 16, Loss: 15203.798828125\n",
      "Epoch: 186, Batch number: 40, Loss: 15117.064453125\n",
      "Epoch: 187, Batch number: 64, Loss: 15472.126953125\n",
      "Epoch: 189, Batch number: 12, Loss: 15399.2939453125\n",
      "Epoch: 190, Batch number: 36, Loss: 15469.0390625\n",
      "Epoch: 191, Batch number: 60, Loss: 15437.849609375\n",
      "Epoch: 193, Batch number: 8, Loss: 15420.275390625\n",
      "Epoch: 194, Batch number: 32, Loss: 15113.7197265625\n",
      "Epoch: 195, Batch number: 56, Loss: 15493.033203125\n",
      "Epoch: 197, Batch number: 4, Loss: 15402.9384765625\n",
      "Epoch: 198, Batch number: 28, Loss: 14979.6005859375\n",
      "Epoch: 199, Batch number: 52, Loss: 15468.3232421875\n",
      "Epoch: 201, Batch number: 0, Loss: 15169.2607421875\n",
      "Epoch: 202, Batch number: 24, Loss: 15195.0546875\n",
      "Epoch: 203, Batch number: 48, Loss: 15247.849609375\n",
      "Epoch: 204, Batch number: 72, Loss: 15606.4033203125\n",
      "Epoch: 206, Batch number: 20, Loss: 15382.947265625\n",
      "Epoch: 207, Batch number: 44, Loss: 15397.4501953125\n",
      "Epoch: 208, Batch number: 68, Loss: 15108.462890625\n",
      "Epoch: 210, Batch number: 16, Loss: 14820.857421875\n",
      "Epoch: 211, Batch number: 40, Loss: 15348.1416015625\n",
      "Epoch: 212, Batch number: 64, Loss: 14903.140625\n",
      "Epoch: 214, Batch number: 12, Loss: 15339.1357421875\n",
      "Epoch: 215, Batch number: 36, Loss: 14665.1474609375\n",
      "Epoch: 216, Batch number: 60, Loss: 15640.9375\n",
      "Epoch: 218, Batch number: 8, Loss: 14444.7392578125\n",
      "Epoch: 219, Batch number: 32, Loss: 15077.1455078125\n",
      "Epoch: 220, Batch number: 56, Loss: 15095.2548828125\n",
      "Epoch: 222, Batch number: 4, Loss: 15007.9541015625\n",
      "Epoch: 223, Batch number: 28, Loss: 14927.54296875\n",
      "Epoch: 224, Batch number: 52, Loss: 15014.505859375\n",
      "Epoch: 226, Batch number: 0, Loss: 15052.6220703125\n",
      "Epoch: 227, Batch number: 24, Loss: 14795.9482421875\n",
      "Epoch: 228, Batch number: 48, Loss: 14840.228515625\n",
      "Epoch: 229, Batch number: 72, Loss: 14655.185546875\n",
      "Epoch: 231, Batch number: 20, Loss: 14902.4443359375\n",
      "Epoch: 232, Batch number: 44, Loss: 14913.7412109375\n",
      "Epoch: 233, Batch number: 68, Loss: 15127.5810546875\n",
      "Epoch: 235, Batch number: 16, Loss: 14962.251953125\n",
      "Epoch: 236, Batch number: 40, Loss: 14803.8173828125\n",
      "Epoch: 237, Batch number: 64, Loss: 15001.490234375\n",
      "Epoch: 239, Batch number: 12, Loss: 15260.2119140625\n",
      "Epoch: 240, Batch number: 36, Loss: 15033.9794921875\n",
      "Epoch: 241, Batch number: 60, Loss: 15121.654296875\n",
      "Epoch: 243, Batch number: 8, Loss: 14838.4501953125\n",
      "Epoch: 244, Batch number: 32, Loss: 15094.5869140625\n",
      "Epoch: 245, Batch number: 56, Loss: 14804.513671875\n",
      "Epoch: 247, Batch number: 4, Loss: 14505.0322265625\n",
      "Epoch: 248, Batch number: 28, Loss: 15335.9580078125\n",
      "Epoch: 249, Batch number: 52, Loss: 14835.8583984375\n",
      "Epoch: 251, Batch number: 0, Loss: 14592.4814453125\n",
      "Epoch: 252, Batch number: 24, Loss: 14855.1787109375\n",
      "Epoch: 253, Batch number: 48, Loss: 15148.705078125\n",
      "Epoch: 254, Batch number: 72, Loss: 14817.0478515625\n",
      "Epoch: 256, Batch number: 20, Loss: 15339.4345703125\n",
      "Epoch: 257, Batch number: 44, Loss: 14627.4775390625\n",
      "Epoch: 258, Batch number: 68, Loss: 15178.298828125\n",
      "Epoch: 260, Batch number: 16, Loss: 14963.5400390625\n",
      "Epoch: 261, Batch number: 40, Loss: 14750.5830078125\n",
      "Epoch: 262, Batch number: 64, Loss: 14941.8896484375\n",
      "Epoch: 264, Batch number: 12, Loss: 15039.392578125\n",
      "Epoch: 265, Batch number: 36, Loss: 15105.12890625\n",
      "Epoch: 266, Batch number: 60, Loss: 15158.59375\n",
      "Epoch: 268, Batch number: 8, Loss: 14845.2998046875\n",
      "Epoch: 269, Batch number: 32, Loss: 15001.50390625\n",
      "Epoch: 270, Batch number: 56, Loss: 14879.2080078125\n",
      "Epoch: 272, Batch number: 4, Loss: 14339.3623046875\n",
      "Epoch: 273, Batch number: 28, Loss: 15179.8447265625\n",
      "Epoch: 274, Batch number: 52, Loss: 14650.3349609375\n",
      "Epoch: 276, Batch number: 0, Loss: 14736.9990234375\n",
      "Epoch: 277, Batch number: 24, Loss: 14704.4208984375\n",
      "Epoch: 278, Batch number: 48, Loss: 14830.7529296875\n",
      "Epoch: 279, Batch number: 72, Loss: 14865.9775390625\n",
      "Epoch: 281, Batch number: 20, Loss: 14869.751953125\n",
      "Epoch: 282, Batch number: 44, Loss: 14718.998046875\n",
      "Epoch: 283, Batch number: 68, Loss: 14853.7060546875\n",
      "Epoch: 285, Batch number: 16, Loss: 14846.5751953125\n",
      "Epoch: 286, Batch number: 40, Loss: 14783.18359375\n",
      "Epoch: 287, Batch number: 64, Loss: 15112.9287109375\n",
      "Epoch: 289, Batch number: 12, Loss: 14699.5595703125\n",
      "Epoch: 290, Batch number: 36, Loss: 14710.5732421875\n",
      "Epoch: 291, Batch number: 60, Loss: 14482.568359375\n",
      "Epoch: 293, Batch number: 8, Loss: 14665.0107421875\n",
      "Epoch: 294, Batch number: 32, Loss: 14413.5888671875\n",
      "Epoch: 295, Batch number: 56, Loss: 14613.099609375\n",
      "Epoch: 297, Batch number: 4, Loss: 14505.44140625\n",
      "Epoch: 298, Batch number: 28, Loss: 14779.1845703125\n",
      "Epoch: 299, Batch number: 52, Loss: 14658.7060546875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 26976.064453125\n",
      "Epoch: 2, Batch number: 24, Loss: 25879.744140625\n",
      "Epoch: 3, Batch number: 48, Loss: 24361.400390625\n",
      "Epoch: 4, Batch number: 72, Loss: 23823.697265625\n",
      "Epoch: 6, Batch number: 20, Loss: 22350.744140625\n",
      "Epoch: 7, Batch number: 44, Loss: 21496.39453125\n",
      "Epoch: 8, Batch number: 68, Loss: 21025.361328125\n",
      "Epoch: 10, Batch number: 16, Loss: 21199.193359375\n",
      "Epoch: 11, Batch number: 40, Loss: 20416.861328125\n",
      "Epoch: 12, Batch number: 64, Loss: 20087.16796875\n",
      "Epoch: 14, Batch number: 12, Loss: 19503.10546875\n",
      "Epoch: 15, Batch number: 36, Loss: 19329.177734375\n",
      "Epoch: 16, Batch number: 60, Loss: 19358.392578125\n",
      "Epoch: 18, Batch number: 8, Loss: 18777.248046875\n",
      "Epoch: 19, Batch number: 32, Loss: 18992.25390625\n",
      "Epoch: 20, Batch number: 56, Loss: 18474.658203125\n",
      "Epoch: 22, Batch number: 4, Loss: 18572.283203125\n",
      "Epoch: 23, Batch number: 28, Loss: 17858.796875\n",
      "Epoch: 24, Batch number: 52, Loss: 17783.08984375\n",
      "Epoch: 26, Batch number: 0, Loss: 17510.62890625\n",
      "Epoch: 27, Batch number: 24, Loss: 17528.9140625\n",
      "Epoch: 28, Batch number: 48, Loss: 17684.208984375\n",
      "Epoch: 29, Batch number: 72, Loss: 17318.974609375\n",
      "Epoch: 31, Batch number: 20, Loss: 16999.482421875\n",
      "Epoch: 32, Batch number: 44, Loss: 17559.271484375\n",
      "Epoch: 33, Batch number: 68, Loss: 16902.5625\n",
      "Epoch: 35, Batch number: 16, Loss: 16893.650390625\n",
      "Epoch: 36, Batch number: 40, Loss: 16881.306640625\n",
      "Epoch: 37, Batch number: 64, Loss: 16802.083984375\n",
      "Epoch: 39, Batch number: 12, Loss: 16998.958984375\n",
      "Epoch: 40, Batch number: 36, Loss: 16728.75\n",
      "Epoch: 41, Batch number: 60, Loss: 16752.14453125\n",
      "Epoch: 43, Batch number: 8, Loss: 16474.181640625\n",
      "Epoch: 44, Batch number: 32, Loss: 16412.20703125\n",
      "Epoch: 45, Batch number: 56, Loss: 16594.25390625\n",
      "Epoch: 47, Batch number: 4, Loss: 16457.56640625\n",
      "Epoch: 48, Batch number: 28, Loss: 16433.697265625\n",
      "Epoch: 49, Batch number: 52, Loss: 16544.875\n",
      "Epoch: 51, Batch number: 0, Loss: 16552.5234375\n",
      "Epoch: 52, Batch number: 24, Loss: 16022.81640625\n",
      "Epoch: 53, Batch number: 48, Loss: 16104.0595703125\n",
      "Epoch: 54, Batch number: 72, Loss: 15859.3369140625\n",
      "Epoch: 56, Batch number: 20, Loss: 16369.82421875\n",
      "Epoch: 57, Batch number: 44, Loss: 16233.689453125\n",
      "Epoch: 58, Batch number: 68, Loss: 16000.646484375\n",
      "Epoch: 60, Batch number: 16, Loss: 16236.6328125\n",
      "Epoch: 61, Batch number: 40, Loss: 15662.638671875\n",
      "Epoch: 62, Batch number: 64, Loss: 16014.173828125\n",
      "Epoch: 64, Batch number: 12, Loss: 15796.7568359375\n",
      "Epoch: 65, Batch number: 36, Loss: 15871.603515625\n",
      "Epoch: 66, Batch number: 60, Loss: 16069.7587890625\n",
      "Epoch: 68, Batch number: 8, Loss: 15504.5166015625\n",
      "Epoch: 69, Batch number: 32, Loss: 15664.990234375\n",
      "Epoch: 70, Batch number: 56, Loss: 15783.7939453125\n",
      "Epoch: 72, Batch number: 4, Loss: 15579.900390625\n",
      "Epoch: 73, Batch number: 28, Loss: 15554.2978515625\n",
      "Epoch: 74, Batch number: 52, Loss: 15666.5439453125\n",
      "Epoch: 76, Batch number: 0, Loss: 15523.8291015625\n",
      "Epoch: 77, Batch number: 24, Loss: 15512.5478515625\n",
      "Epoch: 78, Batch number: 48, Loss: 15488.080078125\n",
      "Epoch: 79, Batch number: 72, Loss: 15717.16015625\n",
      "Epoch: 81, Batch number: 20, Loss: 15452.4697265625\n",
      "Epoch: 82, Batch number: 44, Loss: 15011.615234375\n",
      "Epoch: 83, Batch number: 68, Loss: 15505.435546875\n",
      "Epoch: 85, Batch number: 16, Loss: 15079.7421875\n",
      "Epoch: 86, Batch number: 40, Loss: 15056.6806640625\n",
      "Epoch: 87, Batch number: 64, Loss: 15294.2236328125\n",
      "Epoch: 89, Batch number: 12, Loss: 14999.83984375\n",
      "Epoch: 90, Batch number: 36, Loss: 15454.9462890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91, Batch number: 60, Loss: 15190.3916015625\n",
      "Epoch: 93, Batch number: 8, Loss: 15177.2255859375\n",
      "Epoch: 94, Batch number: 32, Loss: 15148.2744140625\n",
      "Epoch: 95, Batch number: 56, Loss: 15050.77734375\n",
      "Epoch: 97, Batch number: 4, Loss: 15040.7841796875\n",
      "Epoch: 98, Batch number: 28, Loss: 15273.2578125\n",
      "Epoch: 99, Batch number: 52, Loss: 14996.3916015625\n",
      "Epoch: 101, Batch number: 0, Loss: 15108.5166015625\n",
      "Epoch: 102, Batch number: 24, Loss: 15266.017578125\n",
      "Epoch: 103, Batch number: 48, Loss: 14966.439453125\n",
      "Epoch: 104, Batch number: 72, Loss: 14675.4169921875\n",
      "Epoch: 106, Batch number: 20, Loss: 15060.2724609375\n",
      "Epoch: 107, Batch number: 44, Loss: 15023.240234375\n",
      "Epoch: 108, Batch number: 68, Loss: 15073.2109375\n",
      "Epoch: 110, Batch number: 16, Loss: 15081.869140625\n",
      "Epoch: 111, Batch number: 40, Loss: 15155.4853515625\n",
      "Epoch: 112, Batch number: 64, Loss: 15338.939453125\n",
      "Epoch: 114, Batch number: 12, Loss: 14906.2822265625\n",
      "Epoch: 115, Batch number: 36, Loss: 14915.0703125\n",
      "Epoch: 116, Batch number: 60, Loss: 15094.9765625\n",
      "Epoch: 118, Batch number: 8, Loss: 14870.111328125\n",
      "Epoch: 119, Batch number: 32, Loss: 14655.6484375\n",
      "Epoch: 120, Batch number: 56, Loss: 14542.3515625\n",
      "Epoch: 122, Batch number: 4, Loss: 14752.6376953125\n",
      "Epoch: 123, Batch number: 28, Loss: 14628.65234375\n",
      "Epoch: 124, Batch number: 52, Loss: 14979.1494140625\n",
      "Epoch: 126, Batch number: 0, Loss: 14408.365234375\n",
      "Epoch: 127, Batch number: 24, Loss: 14453.533203125\n",
      "Epoch: 128, Batch number: 48, Loss: 14994.9931640625\n",
      "Epoch: 129, Batch number: 72, Loss: 14780.876953125\n",
      "Epoch: 131, Batch number: 20, Loss: 14596.64453125\n",
      "Epoch: 132, Batch number: 44, Loss: 14509.107421875\n",
      "Epoch: 133, Batch number: 68, Loss: 14860.5439453125\n",
      "Epoch: 135, Batch number: 16, Loss: 14729.5087890625\n",
      "Epoch: 136, Batch number: 40, Loss: 14607.1796875\n",
      "Epoch: 137, Batch number: 64, Loss: 14622.4697265625\n",
      "Epoch: 139, Batch number: 12, Loss: 14198.529296875\n",
      "Epoch: 140, Batch number: 36, Loss: 14490.3466796875\n",
      "Epoch: 141, Batch number: 60, Loss: 14892.365234375\n",
      "Epoch: 143, Batch number: 8, Loss: 14521.47265625\n",
      "Epoch: 144, Batch number: 32, Loss: 14346.55859375\n",
      "Epoch: 145, Batch number: 56, Loss: 14935.580078125\n",
      "Epoch: 147, Batch number: 4, Loss: 14468.529296875\n",
      "Epoch: 148, Batch number: 28, Loss: 14583.185546875\n",
      "Epoch: 149, Batch number: 52, Loss: 14119.2216796875\n",
      "Epoch: 151, Batch number: 0, Loss: 14374.0244140625\n",
      "Epoch: 152, Batch number: 24, Loss: 13922.185546875\n",
      "Epoch: 153, Batch number: 48, Loss: 14148.91015625\n",
      "Epoch: 154, Batch number: 72, Loss: 14649.5888671875\n",
      "Epoch: 156, Batch number: 20, Loss: 14164.70703125\n",
      "Epoch: 157, Batch number: 44, Loss: 14094.7275390625\n",
      "Epoch: 158, Batch number: 68, Loss: 14493.443359375\n",
      "Epoch: 160, Batch number: 16, Loss: 14462.935546875\n",
      "Epoch: 161, Batch number: 40, Loss: 14243.8388671875\n",
      "Epoch: 162, Batch number: 64, Loss: 14776.404296875\n",
      "Epoch: 164, Batch number: 12, Loss: 14068.0185546875\n",
      "Epoch: 165, Batch number: 36, Loss: 13802.560546875\n",
      "Epoch: 166, Batch number: 60, Loss: 14644.255859375\n",
      "Epoch: 168, Batch number: 8, Loss: 14255.8740234375\n",
      "Epoch: 169, Batch number: 32, Loss: 14440.1181640625\n",
      "Epoch: 170, Batch number: 56, Loss: 14042.1494140625\n",
      "Epoch: 172, Batch number: 4, Loss: 14499.763671875\n",
      "Epoch: 173, Batch number: 28, Loss: 14157.27734375\n",
      "Epoch: 174, Batch number: 52, Loss: 14267.708984375\n",
      "Epoch: 176, Batch number: 0, Loss: 14415.3203125\n",
      "Epoch: 177, Batch number: 24, Loss: 14328.3115234375\n",
      "Epoch: 178, Batch number: 48, Loss: 14391.2333984375\n",
      "Epoch: 179, Batch number: 72, Loss: 14967.2080078125\n",
      "Epoch: 181, Batch number: 20, Loss: 14656.671875\n",
      "Epoch: 182, Batch number: 44, Loss: 13950.8671875\n",
      "Epoch: 183, Batch number: 68, Loss: 14254.798828125\n",
      "Epoch: 185, Batch number: 16, Loss: 14049.40234375\n",
      "Epoch: 186, Batch number: 40, Loss: 14115.29296875\n",
      "Epoch: 187, Batch number: 64, Loss: 14183.7060546875\n",
      "Epoch: 189, Batch number: 12, Loss: 14149.4677734375\n",
      "Epoch: 190, Batch number: 36, Loss: 14505.681640625\n",
      "Epoch: 191, Batch number: 60, Loss: 14074.0849609375\n",
      "Epoch: 193, Batch number: 8, Loss: 14120.4208984375\n",
      "Epoch: 194, Batch number: 32, Loss: 13934.3203125\n",
      "Epoch: 195, Batch number: 56, Loss: 14082.70703125\n",
      "Epoch: 197, Batch number: 4, Loss: 14075.572265625\n",
      "Epoch: 198, Batch number: 28, Loss: 13750.1689453125\n",
      "Epoch: 199, Batch number: 52, Loss: 14129.18359375\n",
      "Epoch: 201, Batch number: 0, Loss: 14218.60546875\n",
      "Epoch: 202, Batch number: 24, Loss: 14188.7880859375\n",
      "Epoch: 203, Batch number: 48, Loss: 13935.234375\n",
      "Epoch: 204, Batch number: 72, Loss: 14296.7998046875\n",
      "Epoch: 206, Batch number: 20, Loss: 14021.7568359375\n",
      "Epoch: 207, Batch number: 44, Loss: 14239.1748046875\n",
      "Epoch: 208, Batch number: 68, Loss: 14469.6767578125\n",
      "Epoch: 210, Batch number: 16, Loss: 13919.208984375\n",
      "Epoch: 211, Batch number: 40, Loss: 13917.0517578125\n",
      "Epoch: 212, Batch number: 64, Loss: 14100.525390625\n",
      "Epoch: 214, Batch number: 12, Loss: 13986.681640625\n",
      "Epoch: 215, Batch number: 36, Loss: 14411.017578125\n",
      "Epoch: 216, Batch number: 60, Loss: 14223.8486328125\n",
      "Epoch: 218, Batch number: 8, Loss: 14236.8134765625\n",
      "Epoch: 219, Batch number: 32, Loss: 14210.0849609375\n",
      "Epoch: 220, Batch number: 56, Loss: 14448.4677734375\n",
      "Epoch: 222, Batch number: 4, Loss: 13702.392578125\n",
      "Epoch: 223, Batch number: 28, Loss: 14235.9345703125\n",
      "Epoch: 224, Batch number: 52, Loss: 14061.953125\n",
      "Epoch: 226, Batch number: 0, Loss: 14146.8369140625\n",
      "Epoch: 227, Batch number: 24, Loss: 13852.421875\n",
      "Epoch: 228, Batch number: 48, Loss: 14131.4228515625\n",
      "Epoch: 229, Batch number: 72, Loss: 13732.154296875\n",
      "Epoch: 231, Batch number: 20, Loss: 13889.2646484375\n",
      "Epoch: 232, Batch number: 44, Loss: 14401.1552734375\n",
      "Epoch: 233, Batch number: 68, Loss: 13888.8173828125\n",
      "Epoch: 235, Batch number: 16, Loss: 13476.9462890625\n",
      "Epoch: 236, Batch number: 40, Loss: 13859.7099609375\n",
      "Epoch: 237, Batch number: 64, Loss: 13704.8583984375\n",
      "Epoch: 239, Batch number: 12, Loss: 14027.5703125\n",
      "Epoch: 240, Batch number: 36, Loss: 14351.1787109375\n",
      "Epoch: 241, Batch number: 60, Loss: 13917.576171875\n",
      "Epoch: 243, Batch number: 8, Loss: 13760.310546875\n",
      "Epoch: 244, Batch number: 32, Loss: 14077.0791015625\n",
      "Epoch: 245, Batch number: 56, Loss: 14034.294921875\n",
      "Epoch: 247, Batch number: 4, Loss: 13725.90625\n",
      "Epoch: 248, Batch number: 28, Loss: 14054.7314453125\n",
      "Epoch: 249, Batch number: 52, Loss: 13920.630859375\n",
      "Epoch: 251, Batch number: 0, Loss: 13899.5498046875\n",
      "Epoch: 252, Batch number: 24, Loss: 14151.275390625\n",
      "Epoch: 253, Batch number: 48, Loss: 13901.330078125\n",
      "Epoch: 254, Batch number: 72, Loss: 13639.662109375\n",
      "Epoch: 256, Batch number: 20, Loss: 13609.1728515625\n",
      "Epoch: 257, Batch number: 44, Loss: 13771.064453125\n",
      "Epoch: 258, Batch number: 68, Loss: 14061.2265625\n",
      "Epoch: 260, Batch number: 16, Loss: 14194.02734375\n",
      "Epoch: 261, Batch number: 40, Loss: 13536.865234375\n",
      "Epoch: 262, Batch number: 64, Loss: 13719.1083984375\n",
      "Epoch: 264, Batch number: 12, Loss: 13800.1279296875\n",
      "Epoch: 265, Batch number: 36, Loss: 14182.162109375\n",
      "Epoch: 266, Batch number: 60, Loss: 13661.22265625\n",
      "Epoch: 268, Batch number: 8, Loss: 13548.71875\n",
      "Epoch: 269, Batch number: 32, Loss: 13992.5859375\n",
      "Epoch: 270, Batch number: 56, Loss: 14067.2763671875\n",
      "Epoch: 272, Batch number: 4, Loss: 13617.7880859375\n",
      "Epoch: 273, Batch number: 28, Loss: 14213.650390625\n",
      "Epoch: 274, Batch number: 52, Loss: 14172.298828125\n",
      "Epoch: 276, Batch number: 0, Loss: 13447.5439453125\n",
      "Epoch: 277, Batch number: 24, Loss: 13431.4951171875\n",
      "Epoch: 278, Batch number: 48, Loss: 13887.251953125\n",
      "Epoch: 279, Batch number: 72, Loss: 13296.7275390625\n",
      "Epoch: 281, Batch number: 20, Loss: 13662.2265625\n",
      "Epoch: 282, Batch number: 44, Loss: 13867.1962890625\n",
      "Epoch: 283, Batch number: 68, Loss: 13793.001953125\n",
      "Epoch: 285, Batch number: 16, Loss: 13489.4716796875\n",
      "Epoch: 286, Batch number: 40, Loss: 13649.2744140625\n",
      "Epoch: 287, Batch number: 64, Loss: 13696.9912109375\n",
      "Epoch: 289, Batch number: 12, Loss: 13612.857421875\n",
      "Epoch: 290, Batch number: 36, Loss: 13725.6953125\n",
      "Epoch: 291, Batch number: 60, Loss: 13950.013671875\n",
      "Epoch: 293, Batch number: 8, Loss: 13773.4150390625\n",
      "Epoch: 294, Batch number: 32, Loss: 13955.0498046875\n",
      "Epoch: 295, Batch number: 56, Loss: 13817.990234375\n",
      "Epoch: 297, Batch number: 4, Loss: 13530.353515625\n",
      "Epoch: 298, Batch number: 28, Loss: 13682.1455078125\n",
      "Epoch: 299, Batch number: 52, Loss: 14017.4091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 26608.291015625\n",
      "Epoch: 2, Batch number: 24, Loss: 25146.662109375\n",
      "Epoch: 3, Batch number: 48, Loss: 24218.951171875\n",
      "Epoch: 4, Batch number: 72, Loss: 22696.9921875\n",
      "Epoch: 6, Batch number: 20, Loss: 22228.76953125\n",
      "Epoch: 7, Batch number: 44, Loss: 21413.708984375\n",
      "Epoch: 8, Batch number: 68, Loss: 20603.623046875\n",
      "Epoch: 10, Batch number: 16, Loss: 19871.669921875\n",
      "Epoch: 11, Batch number: 40, Loss: 19689.046875\n",
      "Epoch: 12, Batch number: 64, Loss: 19304.666015625\n",
      "Epoch: 14, Batch number: 12, Loss: 18902.501953125\n",
      "Epoch: 15, Batch number: 36, Loss: 18402.875\n",
      "Epoch: 16, Batch number: 60, Loss: 18431.529296875\n",
      "Epoch: 18, Batch number: 8, Loss: 18167.341796875\n",
      "Epoch: 19, Batch number: 32, Loss: 17898.5234375\n",
      "Epoch: 20, Batch number: 56, Loss: 17497.6484375\n",
      "Epoch: 22, Batch number: 4, Loss: 17493.865234375\n",
      "Epoch: 23, Batch number: 28, Loss: 17024.259765625\n",
      "Epoch: 24, Batch number: 52, Loss: 17352.341796875\n",
      "Epoch: 26, Batch number: 0, Loss: 17081.498046875\n",
      "Epoch: 27, Batch number: 24, Loss: 16733.962890625\n",
      "Epoch: 28, Batch number: 48, Loss: 16396.119140625\n",
      "Epoch: 29, Batch number: 72, Loss: 16632.171875\n",
      "Epoch: 31, Batch number: 20, Loss: 16369.3486328125\n",
      "Epoch: 32, Batch number: 44, Loss: 16043.3046875\n",
      "Epoch: 33, Batch number: 68, Loss: 16417.595703125\n",
      "Epoch: 35, Batch number: 16, Loss: 16645.828125\n",
      "Epoch: 36, Batch number: 40, Loss: 15958.0751953125\n",
      "Epoch: 37, Batch number: 64, Loss: 16198.70703125\n",
      "Epoch: 39, Batch number: 12, Loss: 15684.0712890625\n",
      "Epoch: 40, Batch number: 36, Loss: 16090.4755859375\n",
      "Epoch: 41, Batch number: 60, Loss: 16023.2294921875\n",
      "Epoch: 43, Batch number: 8, Loss: 15408.515625\n",
      "Epoch: 44, Batch number: 32, Loss: 15595.8369140625\n",
      "Epoch: 45, Batch number: 56, Loss: 15443.1572265625\n",
      "Epoch: 47, Batch number: 4, Loss: 15214.919921875\n",
      "Epoch: 48, Batch number: 28, Loss: 15463.3994140625\n",
      "Epoch: 49, Batch number: 52, Loss: 15654.0859375\n",
      "Epoch: 51, Batch number: 0, Loss: 15079.3642578125\n",
      "Epoch: 52, Batch number: 24, Loss: 15403.7216796875\n",
      "Epoch: 53, Batch number: 48, Loss: 15729.63671875\n",
      "Epoch: 54, Batch number: 72, Loss: 15506.2822265625\n",
      "Epoch: 56, Batch number: 20, Loss: 15362.712890625\n",
      "Epoch: 57, Batch number: 44, Loss: 15353.4453125\n",
      "Epoch: 58, Batch number: 68, Loss: 15846.494140625\n",
      "Epoch: 60, Batch number: 16, Loss: 15041.0712890625\n",
      "Epoch: 61, Batch number: 40, Loss: 15014.46484375\n",
      "Epoch: 62, Batch number: 64, Loss: 14925.9814453125\n",
      "Epoch: 64, Batch number: 12, Loss: 15175.7021484375\n",
      "Epoch: 65, Batch number: 36, Loss: 14985.8935546875\n",
      "Epoch: 66, Batch number: 60, Loss: 15631.763671875\n",
      "Epoch: 68, Batch number: 8, Loss: 14790.599609375\n",
      "Epoch: 69, Batch number: 32, Loss: 14863.3701171875\n",
      "Epoch: 70, Batch number: 56, Loss: 15172.93359375\n",
      "Epoch: 72, Batch number: 4, Loss: 14738.337890625\n",
      "Epoch: 73, Batch number: 28, Loss: 14731.947265625\n",
      "Epoch: 74, Batch number: 52, Loss: 15230.109375\n",
      "Epoch: 76, Batch number: 0, Loss: 14578.1728515625\n",
      "Epoch: 77, Batch number: 24, Loss: 14746.2119140625\n",
      "Epoch: 78, Batch number: 48, Loss: 15094.0078125\n",
      "Epoch: 79, Batch number: 72, Loss: 14660.9130859375\n",
      "Epoch: 81, Batch number: 20, Loss: 14706.58984375\n",
      "Epoch: 82, Batch number: 44, Loss: 14781.22265625\n",
      "Epoch: 83, Batch number: 68, Loss: 14611.7578125\n",
      "Epoch: 85, Batch number: 16, Loss: 14752.9609375\n",
      "Epoch: 86, Batch number: 40, Loss: 14914.5810546875\n",
      "Epoch: 87, Batch number: 64, Loss: 14865.6171875\n",
      "Epoch: 89, Batch number: 12, Loss: 15013.5302734375\n",
      "Epoch: 90, Batch number: 36, Loss: 14364.853515625\n",
      "Epoch: 91, Batch number: 60, Loss: 14603.6494140625\n",
      "Epoch: 93, Batch number: 8, Loss: 14357.185546875\n",
      "Epoch: 94, Batch number: 32, Loss: 14715.779296875\n",
      "Epoch: 95, Batch number: 56, Loss: 14472.3115234375\n",
      "Epoch: 97, Batch number: 4, Loss: 14982.0712890625\n",
      "Epoch: 98, Batch number: 28, Loss: 14420.1875\n",
      "Epoch: 99, Batch number: 52, Loss: 14106.5029296875\n",
      "Epoch: 101, Batch number: 0, Loss: 14286.634765625\n",
      "Epoch: 102, Batch number: 24, Loss: 14612.2626953125\n",
      "Epoch: 103, Batch number: 48, Loss: 14649.2099609375\n",
      "Epoch: 104, Batch number: 72, Loss: 14463.9228515625\n",
      "Epoch: 106, Batch number: 20, Loss: 14317.3291015625\n",
      "Epoch: 107, Batch number: 44, Loss: 14484.490234375\n",
      "Epoch: 108, Batch number: 68, Loss: 14170.7060546875\n",
      "Epoch: 110, Batch number: 16, Loss: 14253.7578125\n",
      "Epoch: 111, Batch number: 40, Loss: 14525.0439453125\n",
      "Epoch: 112, Batch number: 64, Loss: 14503.50390625\n",
      "Epoch: 114, Batch number: 12, Loss: 14467.4208984375\n",
      "Epoch: 115, Batch number: 36, Loss: 13918.1806640625\n",
      "Epoch: 116, Batch number: 60, Loss: 14213.0390625\n",
      "Epoch: 118, Batch number: 8, Loss: 14218.322265625\n",
      "Epoch: 119, Batch number: 32, Loss: 14153.2578125\n",
      "Epoch: 120, Batch number: 56, Loss: 14404.818359375\n",
      "Epoch: 122, Batch number: 4, Loss: 14278.607421875\n",
      "Epoch: 123, Batch number: 28, Loss: 13781.2890625\n",
      "Epoch: 124, Batch number: 52, Loss: 13822.2548828125\n",
      "Epoch: 126, Batch number: 0, Loss: 14020.5595703125\n",
      "Epoch: 127, Batch number: 24, Loss: 14498.005859375\n",
      "Epoch: 128, Batch number: 48, Loss: 14295.33203125\n",
      "Epoch: 129, Batch number: 72, Loss: 14188.0791015625\n",
      "Epoch: 131, Batch number: 20, Loss: 13907.5517578125\n",
      "Epoch: 132, Batch number: 44, Loss: 14230.1591796875\n",
      "Epoch: 133, Batch number: 68, Loss: 14437.8427734375\n",
      "Epoch: 135, Batch number: 16, Loss: 13764.2470703125\n",
      "Epoch: 136, Batch number: 40, Loss: 14291.259765625\n",
      "Epoch: 137, Batch number: 64, Loss: 14104.35546875\n",
      "Epoch: 139, Batch number: 12, Loss: 13865.0556640625\n",
      "Epoch: 140, Batch number: 36, Loss: 14259.767578125\n",
      "Epoch: 141, Batch number: 60, Loss: 13706.7958984375\n",
      "Epoch: 143, Batch number: 8, Loss: 13980.578125\n",
      "Epoch: 144, Batch number: 32, Loss: 13871.4462890625\n",
      "Epoch: 145, Batch number: 56, Loss: 13753.17578125\n",
      "Epoch: 147, Batch number: 4, Loss: 14085.345703125\n",
      "Epoch: 148, Batch number: 28, Loss: 14179.9423828125\n",
      "Epoch: 149, Batch number: 52, Loss: 14360.009765625\n",
      "Epoch: 151, Batch number: 0, Loss: 14036.4541015625\n",
      "Epoch: 152, Batch number: 24, Loss: 13745.625\n",
      "Epoch: 153, Batch number: 48, Loss: 14158.9951171875\n",
      "Epoch: 154, Batch number: 72, Loss: 13939.60546875\n",
      "Epoch: 156, Batch number: 20, Loss: 13696.6611328125\n",
      "Epoch: 157, Batch number: 44, Loss: 14035.4443359375\n",
      "Epoch: 158, Batch number: 68, Loss: 13918.375\n",
      "Epoch: 160, Batch number: 16, Loss: 13239.5517578125\n",
      "Epoch: 161, Batch number: 40, Loss: 14297.431640625\n",
      "Epoch: 162, Batch number: 64, Loss: 13930.71875\n",
      "Epoch: 164, Batch number: 12, Loss: 14025.068359375\n",
      "Epoch: 165, Batch number: 36, Loss: 13773.68359375\n",
      "Epoch: 166, Batch number: 60, Loss: 14144.470703125\n",
      "Epoch: 168, Batch number: 8, Loss: 13920.173828125\n",
      "Epoch: 169, Batch number: 32, Loss: 13704.20703125\n",
      "Epoch: 170, Batch number: 56, Loss: 13550.0322265625\n",
      "Epoch: 172, Batch number: 4, Loss: 13436.9541015625\n",
      "Epoch: 173, Batch number: 28, Loss: 13457.25\n",
      "Epoch: 174, Batch number: 52, Loss: 14300.3681640625\n",
      "Epoch: 176, Batch number: 0, Loss: 14029.1396484375\n",
      "Epoch: 177, Batch number: 24, Loss: 14023.1181640625\n",
      "Epoch: 178, Batch number: 48, Loss: 13279.2509765625\n",
      "Epoch: 179, Batch number: 72, Loss: 13811.849609375\n",
      "Epoch: 181, Batch number: 20, Loss: 13997.416015625\n",
      "Epoch: 182, Batch number: 44, Loss: 13929.8466796875\n",
      "Epoch: 183, Batch number: 68, Loss: 13559.841796875\n",
      "Epoch: 185, Batch number: 16, Loss: 13578.9140625\n",
      "Epoch: 186, Batch number: 40, Loss: 13720.412109375\n",
      "Epoch: 187, Batch number: 64, Loss: 13150.93359375\n",
      "Epoch: 189, Batch number: 12, Loss: 13990.9599609375\n",
      "Epoch: 190, Batch number: 36, Loss: 13978.8408203125\n",
      "Epoch: 191, Batch number: 60, Loss: 13615.3125\n",
      "Epoch: 193, Batch number: 8, Loss: 13866.3056640625\n",
      "Epoch: 194, Batch number: 32, Loss: 13597.2958984375\n",
      "Epoch: 195, Batch number: 56, Loss: 13982.57421875\n",
      "Epoch: 197, Batch number: 4, Loss: 13905.0849609375\n",
      "Epoch: 198, Batch number: 28, Loss: 13784.681640625\n",
      "Epoch: 199, Batch number: 52, Loss: 13496.666015625\n",
      "Epoch: 201, Batch number: 0, Loss: 13895.4599609375\n",
      "Epoch: 202, Batch number: 24, Loss: 13759.2685546875\n",
      "Epoch: 203, Batch number: 48, Loss: 13851.90625\n",
      "Epoch: 204, Batch number: 72, Loss: 14237.15625\n",
      "Epoch: 206, Batch number: 20, Loss: 13830.3671875\n",
      "Epoch: 207, Batch number: 44, Loss: 13601.646484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 13759.900390625\n",
      "Epoch: 210, Batch number: 16, Loss: 13690.28515625\n",
      "Epoch: 211, Batch number: 40, Loss: 13808.392578125\n",
      "Epoch: 212, Batch number: 64, Loss: 14263.8876953125\n",
      "Epoch: 214, Batch number: 12, Loss: 13462.2802734375\n",
      "Epoch: 215, Batch number: 36, Loss: 13822.19140625\n",
      "Epoch: 216, Batch number: 60, Loss: 13707.8125\n",
      "Epoch: 218, Batch number: 8, Loss: 13416.1630859375\n",
      "Epoch: 219, Batch number: 32, Loss: 13557.248046875\n",
      "Epoch: 220, Batch number: 56, Loss: 13705.4853515625\n",
      "Epoch: 222, Batch number: 4, Loss: 13349.1328125\n",
      "Epoch: 223, Batch number: 28, Loss: 14098.853515625\n",
      "Epoch: 224, Batch number: 52, Loss: 13896.466796875\n",
      "Epoch: 226, Batch number: 0, Loss: 13904.12890625\n",
      "Epoch: 227, Batch number: 24, Loss: 13920.4140625\n",
      "Epoch: 228, Batch number: 48, Loss: 13748.265625\n",
      "Epoch: 229, Batch number: 72, Loss: 13457.3505859375\n",
      "Epoch: 231, Batch number: 20, Loss: 13951.29296875\n",
      "Epoch: 232, Batch number: 44, Loss: 13805.93359375\n",
      "Epoch: 233, Batch number: 68, Loss: 14117.4326171875\n",
      "Epoch: 235, Batch number: 16, Loss: 13462.775390625\n",
      "Epoch: 236, Batch number: 40, Loss: 13638.03515625\n",
      "Epoch: 237, Batch number: 64, Loss: 13854.4326171875\n",
      "Epoch: 239, Batch number: 12, Loss: 13695.7353515625\n",
      "Epoch: 240, Batch number: 36, Loss: 13405.09375\n",
      "Epoch: 241, Batch number: 60, Loss: 13376.7109375\n",
      "Epoch: 243, Batch number: 8, Loss: 13556.708984375\n",
      "Epoch: 244, Batch number: 32, Loss: 13754.6669921875\n",
      "Epoch: 245, Batch number: 56, Loss: 13983.583984375\n",
      "Epoch: 247, Batch number: 4, Loss: 13316.1259765625\n",
      "Epoch: 248, Batch number: 28, Loss: 13544.7958984375\n",
      "Epoch: 249, Batch number: 52, Loss: 13755.36328125\n",
      "Epoch: 251, Batch number: 0, Loss: 13622.396484375\n",
      "Epoch: 252, Batch number: 24, Loss: 13886.5234375\n",
      "Epoch: 253, Batch number: 48, Loss: 13609.6796875\n",
      "Epoch: 254, Batch number: 72, Loss: 13611.5087890625\n",
      "Epoch: 256, Batch number: 20, Loss: 13792.9052734375\n",
      "Epoch: 257, Batch number: 44, Loss: 13658.3916015625\n",
      "Epoch: 258, Batch number: 68, Loss: 13884.2783203125\n",
      "Epoch: 260, Batch number: 16, Loss: 13856.7431640625\n",
      "Epoch: 261, Batch number: 40, Loss: 13295.888671875\n",
      "Epoch: 262, Batch number: 64, Loss: 13910.3603515625\n",
      "Epoch: 264, Batch number: 12, Loss: 13600.2861328125\n",
      "Epoch: 265, Batch number: 36, Loss: 13448.6982421875\n",
      "Epoch: 266, Batch number: 60, Loss: 13739.396484375\n",
      "Epoch: 268, Batch number: 8, Loss: 13474.5703125\n",
      "Epoch: 269, Batch number: 32, Loss: 13456.892578125\n",
      "Epoch: 270, Batch number: 56, Loss: 13524.8310546875\n",
      "Epoch: 272, Batch number: 4, Loss: 13684.27734375\n",
      "Epoch: 273, Batch number: 28, Loss: 13847.560546875\n",
      "Epoch: 274, Batch number: 52, Loss: 13829.78515625\n",
      "Epoch: 276, Batch number: 0, Loss: 13303.5966796875\n",
      "Epoch: 277, Batch number: 24, Loss: 13464.923828125\n",
      "Epoch: 278, Batch number: 48, Loss: 13219.693359375\n",
      "Epoch: 279, Batch number: 72, Loss: 14089.06640625\n",
      "Epoch: 281, Batch number: 20, Loss: 13540.4599609375\n",
      "Epoch: 282, Batch number: 44, Loss: 13567.8740234375\n",
      "Epoch: 283, Batch number: 68, Loss: 13611.609375\n",
      "Epoch: 285, Batch number: 16, Loss: 13454.03515625\n",
      "Epoch: 286, Batch number: 40, Loss: 13504.54296875\n",
      "Epoch: 287, Batch number: 64, Loss: 14001.6103515625\n",
      "Epoch: 289, Batch number: 12, Loss: 13170.822265625\n",
      "Epoch: 290, Batch number: 36, Loss: 13776.50390625\n",
      "Epoch: 291, Batch number: 60, Loss: 13661.1826171875\n",
      "Epoch: 293, Batch number: 8, Loss: 13481.78125\n",
      "Epoch: 294, Batch number: 32, Loss: 14010.2783203125\n",
      "Epoch: 295, Batch number: 56, Loss: 14104.71875\n",
      "Epoch: 297, Batch number: 4, Loss: 13502.041015625\n",
      "Epoch: 298, Batch number: 28, Loss: 13671.7041015625\n",
      "Epoch: 299, Batch number: 52, Loss: 13404.435546875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 27259.697265625\n",
      "Epoch: 2, Batch number: 24, Loss: 25032.541015625\n",
      "Epoch: 3, Batch number: 48, Loss: 23604.318359375\n",
      "Epoch: 4, Batch number: 72, Loss: 22370.19140625\n",
      "Epoch: 6, Batch number: 20, Loss: 21146.353515625\n",
      "Epoch: 7, Batch number: 44, Loss: 21050.40234375\n",
      "Epoch: 8, Batch number: 68, Loss: 20520.625\n",
      "Epoch: 10, Batch number: 16, Loss: 19236.458984375\n",
      "Epoch: 11, Batch number: 40, Loss: 18957.662109375\n",
      "Epoch: 12, Batch number: 64, Loss: 18513.6484375\n",
      "Epoch: 14, Batch number: 12, Loss: 18427.3125\n",
      "Epoch: 15, Batch number: 36, Loss: 17691.642578125\n",
      "Epoch: 16, Batch number: 60, Loss: 17683.13671875\n",
      "Epoch: 18, Batch number: 8, Loss: 17255.2265625\n",
      "Epoch: 19, Batch number: 32, Loss: 16973.4140625\n",
      "Epoch: 20, Batch number: 56, Loss: 16842.359375\n",
      "Epoch: 22, Batch number: 4, Loss: 16911.1875\n",
      "Epoch: 23, Batch number: 28, Loss: 16567.33203125\n",
      "Epoch: 24, Batch number: 52, Loss: 16461.966796875\n",
      "Epoch: 26, Batch number: 0, Loss: 15977.9775390625\n",
      "Epoch: 27, Batch number: 24, Loss: 16278.1455078125\n",
      "Epoch: 28, Batch number: 48, Loss: 16152.8984375\n",
      "Epoch: 29, Batch number: 72, Loss: 16037.203125\n",
      "Epoch: 31, Batch number: 20, Loss: 15867.2744140625\n",
      "Epoch: 32, Batch number: 44, Loss: 15853.3623046875\n",
      "Epoch: 33, Batch number: 68, Loss: 15589.4814453125\n",
      "Epoch: 35, Batch number: 16, Loss: 15704.1474609375\n",
      "Epoch: 36, Batch number: 40, Loss: 15447.8447265625\n",
      "Epoch: 37, Batch number: 64, Loss: 15695.54296875\n",
      "Epoch: 39, Batch number: 12, Loss: 15217.443359375\n",
      "Epoch: 40, Batch number: 36, Loss: 15018.1923828125\n",
      "Epoch: 41, Batch number: 60, Loss: 15082.751953125\n",
      "Epoch: 43, Batch number: 8, Loss: 15023.9814453125\n",
      "Epoch: 44, Batch number: 32, Loss: 15059.650390625\n",
      "Epoch: 45, Batch number: 56, Loss: 15020.6591796875\n",
      "Epoch: 47, Batch number: 4, Loss: 15029.369140625\n",
      "Epoch: 48, Batch number: 28, Loss: 14991.7421875\n",
      "Epoch: 49, Batch number: 52, Loss: 15088.4443359375\n",
      "Epoch: 51, Batch number: 0, Loss: 14639.7880859375\n",
      "Epoch: 52, Batch number: 24, Loss: 15006.3349609375\n",
      "Epoch: 53, Batch number: 48, Loss: 14884.177734375\n",
      "Epoch: 54, Batch number: 72, Loss: 15388.2861328125\n",
      "Epoch: 56, Batch number: 20, Loss: 14824.900390625\n",
      "Epoch: 57, Batch number: 44, Loss: 14748.8515625\n",
      "Epoch: 58, Batch number: 68, Loss: 14889.259765625\n",
      "Epoch: 60, Batch number: 16, Loss: 14695.2646484375\n",
      "Epoch: 61, Batch number: 40, Loss: 14550.8837890625\n",
      "Epoch: 62, Batch number: 64, Loss: 15365.69921875\n",
      "Epoch: 64, Batch number: 12, Loss: 14447.0400390625\n",
      "Epoch: 65, Batch number: 36, Loss: 14418.3974609375\n",
      "Epoch: 66, Batch number: 60, Loss: 14610.37109375\n",
      "Epoch: 68, Batch number: 8, Loss: 14215.708984375\n",
      "Epoch: 69, Batch number: 32, Loss: 14337.408203125\n",
      "Epoch: 70, Batch number: 56, Loss: 14440.5107421875\n",
      "Epoch: 72, Batch number: 4, Loss: 14614.396484375\n",
      "Epoch: 73, Batch number: 28, Loss: 14342.9228515625\n",
      "Epoch: 74, Batch number: 52, Loss: 14772.666015625\n",
      "Epoch: 76, Batch number: 0, Loss: 14157.046875\n",
      "Epoch: 77, Batch number: 24, Loss: 14226.9306640625\n",
      "Epoch: 78, Batch number: 48, Loss: 14595.291015625\n",
      "Epoch: 79, Batch number: 72, Loss: 14180.0703125\n",
      "Epoch: 81, Batch number: 20, Loss: 14014.7275390625\n",
      "Epoch: 82, Batch number: 44, Loss: 14658.42578125\n",
      "Epoch: 83, Batch number: 68, Loss: 14506.345703125\n",
      "Epoch: 85, Batch number: 16, Loss: 14465.3603515625\n",
      "Epoch: 86, Batch number: 40, Loss: 14547.7548828125\n",
      "Epoch: 87, Batch number: 64, Loss: 14306.462890625\n",
      "Epoch: 89, Batch number: 12, Loss: 14127.279296875\n",
      "Epoch: 90, Batch number: 36, Loss: 14120.0087890625\n",
      "Epoch: 91, Batch number: 60, Loss: 14053.6103515625\n",
      "Epoch: 93, Batch number: 8, Loss: 14170.7431640625\n",
      "Epoch: 94, Batch number: 32, Loss: 13751.9716796875\n",
      "Epoch: 95, Batch number: 56, Loss: 13984.1708984375\n",
      "Epoch: 97, Batch number: 4, Loss: 14031.5927734375\n",
      "Epoch: 98, Batch number: 28, Loss: 13877.796875\n",
      "Epoch: 99, Batch number: 52, Loss: 14101.82421875\n",
      "Epoch: 101, Batch number: 0, Loss: 14166.6767578125\n",
      "Epoch: 102, Batch number: 24, Loss: 14209.578125\n",
      "Epoch: 103, Batch number: 48, Loss: 14286.58984375\n",
      "Epoch: 104, Batch number: 72, Loss: 14401.3671875\n",
      "Epoch: 106, Batch number: 20, Loss: 13863.55078125\n",
      "Epoch: 107, Batch number: 44, Loss: 14207.1474609375\n",
      "Epoch: 108, Batch number: 68, Loss: 14035.6015625\n",
      "Epoch: 110, Batch number: 16, Loss: 13745.5341796875\n",
      "Epoch: 111, Batch number: 40, Loss: 13664.4501953125\n",
      "Epoch: 112, Batch number: 64, Loss: 14267.6357421875\n",
      "Epoch: 114, Batch number: 12, Loss: 13678.86328125\n",
      "Epoch: 115, Batch number: 36, Loss: 14080.0615234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116, Batch number: 60, Loss: 13986.1533203125\n",
      "Epoch: 118, Batch number: 8, Loss: 14093.9365234375\n",
      "Epoch: 119, Batch number: 32, Loss: 13874.2470703125\n",
      "Epoch: 120, Batch number: 56, Loss: 14105.8427734375\n",
      "Epoch: 122, Batch number: 4, Loss: 13747.775390625\n",
      "Epoch: 123, Batch number: 28, Loss: 14035.0458984375\n",
      "Epoch: 124, Batch number: 52, Loss: 13491.0048828125\n",
      "Epoch: 126, Batch number: 0, Loss: 13697.974609375\n",
      "Epoch: 127, Batch number: 24, Loss: 14305.349609375\n",
      "Epoch: 128, Batch number: 48, Loss: 13749.0927734375\n",
      "Epoch: 129, Batch number: 72, Loss: 13714.6162109375\n",
      "Epoch: 131, Batch number: 20, Loss: 13856.96484375\n",
      "Epoch: 132, Batch number: 44, Loss: 14128.2998046875\n",
      "Epoch: 133, Batch number: 68, Loss: 13912.5244140625\n",
      "Epoch: 135, Batch number: 16, Loss: 13731.01171875\n",
      "Epoch: 136, Batch number: 40, Loss: 13410.1953125\n",
      "Epoch: 137, Batch number: 64, Loss: 13508.7470703125\n",
      "Epoch: 139, Batch number: 12, Loss: 13828.42578125\n",
      "Epoch: 140, Batch number: 36, Loss: 13949.0068359375\n",
      "Epoch: 141, Batch number: 60, Loss: 13579.3671875\n",
      "Epoch: 143, Batch number: 8, Loss: 13360.8798828125\n",
      "Epoch: 144, Batch number: 32, Loss: 14082.59765625\n",
      "Epoch: 145, Batch number: 56, Loss: 13515.990234375\n",
      "Epoch: 147, Batch number: 4, Loss: 13419.3310546875\n",
      "Epoch: 148, Batch number: 28, Loss: 13862.8203125\n",
      "Epoch: 149, Batch number: 52, Loss: 13651.5712890625\n",
      "Epoch: 151, Batch number: 0, Loss: 13786.7998046875\n",
      "Epoch: 152, Batch number: 24, Loss: 13577.0830078125\n",
      "Epoch: 153, Batch number: 48, Loss: 13641.037109375\n",
      "Epoch: 154, Batch number: 72, Loss: 13855.1513671875\n",
      "Epoch: 156, Batch number: 20, Loss: 13917.07421875\n",
      "Epoch: 157, Batch number: 44, Loss: 13782.7001953125\n",
      "Epoch: 158, Batch number: 68, Loss: 13909.267578125\n",
      "Epoch: 160, Batch number: 16, Loss: 13497.73828125\n",
      "Epoch: 161, Batch number: 40, Loss: 13719.578125\n",
      "Epoch: 162, Batch number: 64, Loss: 14129.1826171875\n",
      "Epoch: 164, Batch number: 12, Loss: 13410.3740234375\n",
      "Epoch: 165, Batch number: 36, Loss: 13997.6865234375\n",
      "Epoch: 166, Batch number: 60, Loss: 13894.6650390625\n",
      "Epoch: 168, Batch number: 8, Loss: 13969.8232421875\n",
      "Epoch: 169, Batch number: 32, Loss: 13593.7841796875\n",
      "Epoch: 170, Batch number: 56, Loss: 14359.2646484375\n",
      "Epoch: 172, Batch number: 4, Loss: 13473.9443359375\n",
      "Epoch: 173, Batch number: 28, Loss: 13279.3095703125\n",
      "Epoch: 174, Batch number: 52, Loss: 13863.5693359375\n",
      "Epoch: 176, Batch number: 0, Loss: 13081.0595703125\n",
      "Epoch: 177, Batch number: 24, Loss: 13715.0673828125\n",
      "Epoch: 178, Batch number: 48, Loss: 13963.78125\n",
      "Epoch: 179, Batch number: 72, Loss: 13876.5673828125\n",
      "Epoch: 181, Batch number: 20, Loss: 14054.439453125\n",
      "Epoch: 182, Batch number: 44, Loss: 13631.7490234375\n",
      "Epoch: 183, Batch number: 68, Loss: 13355.408203125\n",
      "Epoch: 185, Batch number: 16, Loss: 13648.8095703125\n",
      "Epoch: 186, Batch number: 40, Loss: 13816.7099609375\n",
      "Epoch: 187, Batch number: 64, Loss: 14114.8798828125\n",
      "Epoch: 189, Batch number: 12, Loss: 13326.2060546875\n",
      "Epoch: 190, Batch number: 36, Loss: 13705.66015625\n",
      "Epoch: 191, Batch number: 60, Loss: 14130.2001953125\n",
      "Epoch: 193, Batch number: 8, Loss: 13345.47265625\n",
      "Epoch: 194, Batch number: 32, Loss: 13434.197265625\n",
      "Epoch: 195, Batch number: 56, Loss: 13524.1123046875\n",
      "Epoch: 197, Batch number: 4, Loss: 13921.001953125\n",
      "Epoch: 198, Batch number: 28, Loss: 13264.681640625\n",
      "Epoch: 199, Batch number: 52, Loss: 13460.060546875\n",
      "Epoch: 201, Batch number: 0, Loss: 13651.5390625\n",
      "Epoch: 202, Batch number: 24, Loss: 13829.142578125\n",
      "Epoch: 203, Batch number: 48, Loss: 13311.6953125\n",
      "Epoch: 204, Batch number: 72, Loss: 13170.306640625\n",
      "Epoch: 206, Batch number: 20, Loss: 13610.93359375\n",
      "Epoch: 207, Batch number: 44, Loss: 13910.1904296875\n",
      "Epoch: 208, Batch number: 68, Loss: 13692.6240234375\n",
      "Epoch: 210, Batch number: 16, Loss: 13148.73828125\n",
      "Epoch: 211, Batch number: 40, Loss: 13894.16796875\n",
      "Epoch: 212, Batch number: 64, Loss: 13280.0\n",
      "Epoch: 214, Batch number: 12, Loss: 13436.2900390625\n",
      "Epoch: 215, Batch number: 36, Loss: 13264.365234375\n",
      "Epoch: 216, Batch number: 60, Loss: 13638.0859375\n",
      "Epoch: 218, Batch number: 8, Loss: 13625.4755859375\n",
      "Epoch: 219, Batch number: 32, Loss: 13673.376953125\n",
      "Epoch: 220, Batch number: 56, Loss: 13492.1767578125\n",
      "Epoch: 222, Batch number: 4, Loss: 13280.4453125\n",
      "Epoch: 223, Batch number: 28, Loss: 13517.1240234375\n",
      "Epoch: 224, Batch number: 52, Loss: 13926.3603515625\n",
      "Epoch: 226, Batch number: 0, Loss: 13250.166015625\n",
      "Epoch: 227, Batch number: 24, Loss: 13383.21875\n",
      "Epoch: 228, Batch number: 48, Loss: 13722.6650390625\n",
      "Epoch: 229, Batch number: 72, Loss: 13851.583984375\n",
      "Epoch: 231, Batch number: 20, Loss: 13340.8251953125\n",
      "Epoch: 232, Batch number: 44, Loss: 13439.5\n",
      "Epoch: 233, Batch number: 68, Loss: 13898.4072265625\n",
      "Epoch: 235, Batch number: 16, Loss: 13456.5634765625\n",
      "Epoch: 236, Batch number: 40, Loss: 13531.5283203125\n",
      "Epoch: 237, Batch number: 64, Loss: 13692.056640625\n",
      "Epoch: 239, Batch number: 12, Loss: 13661.375\n",
      "Epoch: 240, Batch number: 36, Loss: 13541.7880859375\n",
      "Epoch: 241, Batch number: 60, Loss: 13739.1318359375\n",
      "Epoch: 243, Batch number: 8, Loss: 13426.8916015625\n",
      "Epoch: 244, Batch number: 32, Loss: 13290.5166015625\n",
      "Epoch: 245, Batch number: 56, Loss: 13711.0166015625\n",
      "Epoch: 247, Batch number: 4, Loss: 13945.69921875\n",
      "Epoch: 248, Batch number: 28, Loss: 13227.037109375\n",
      "Epoch: 249, Batch number: 52, Loss: 13340.7294921875\n",
      "Epoch: 251, Batch number: 0, Loss: 13574.0869140625\n",
      "Epoch: 252, Batch number: 24, Loss: 13938.3974609375\n",
      "Epoch: 253, Batch number: 48, Loss: 14126.083984375\n",
      "Epoch: 254, Batch number: 72, Loss: 13506.0478515625\n",
      "Epoch: 256, Batch number: 20, Loss: 13150.81640625\n",
      "Epoch: 257, Batch number: 44, Loss: 13803.82421875\n",
      "Epoch: 258, Batch number: 68, Loss: 13628.6708984375\n",
      "Epoch: 260, Batch number: 16, Loss: 13639.7607421875\n",
      "Epoch: 261, Batch number: 40, Loss: 13453.36328125\n",
      "Epoch: 262, Batch number: 64, Loss: 13373.6513671875\n",
      "Epoch: 264, Batch number: 12, Loss: 13602.8857421875\n",
      "Epoch: 265, Batch number: 36, Loss: 13200.970703125\n",
      "Epoch: 266, Batch number: 60, Loss: 13574.7080078125\n",
      "Epoch: 268, Batch number: 8, Loss: 13372.5712890625\n",
      "Epoch: 269, Batch number: 32, Loss: 13791.791015625\n",
      "Epoch: 270, Batch number: 56, Loss: 13601.7021484375\n",
      "Epoch: 272, Batch number: 4, Loss: 13657.583984375\n",
      "Epoch: 273, Batch number: 28, Loss: 13793.3125\n",
      "Epoch: 274, Batch number: 52, Loss: 13842.9052734375\n",
      "Epoch: 276, Batch number: 0, Loss: 13326.6396484375\n",
      "Epoch: 277, Batch number: 24, Loss: 13098.236328125\n",
      "Epoch: 278, Batch number: 48, Loss: 13435.373046875\n",
      "Epoch: 279, Batch number: 72, Loss: 13353.388671875\n",
      "Epoch: 281, Batch number: 20, Loss: 13613.16796875\n",
      "Epoch: 282, Batch number: 44, Loss: 13219.9794921875\n",
      "Epoch: 283, Batch number: 68, Loss: 13566.947265625\n",
      "Epoch: 285, Batch number: 16, Loss: 13658.8681640625\n",
      "Epoch: 286, Batch number: 40, Loss: 13525.20703125\n",
      "Epoch: 287, Batch number: 64, Loss: 13893.166015625\n",
      "Epoch: 289, Batch number: 12, Loss: 13661.03515625\n",
      "Epoch: 290, Batch number: 36, Loss: 12873.4638671875\n",
      "Epoch: 291, Batch number: 60, Loss: 13767.2568359375\n",
      "Epoch: 293, Batch number: 8, Loss: 13392.0283203125\n",
      "Epoch: 294, Batch number: 32, Loss: 13417.2890625\n",
      "Epoch: 295, Batch number: 56, Loss: 13954.8740234375\n",
      "Epoch: 297, Batch number: 4, Loss: 13128.2236328125\n",
      "Epoch: 298, Batch number: 28, Loss: 13767.6962890625\n",
      "Epoch: 299, Batch number: 52, Loss: 13792.4873046875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 26964.8515625\n",
      "Epoch: 2, Batch number: 24, Loss: 24349.87109375\n",
      "Epoch: 3, Batch number: 48, Loss: 22843.26171875\n",
      "Epoch: 4, Batch number: 72, Loss: 21870.65625\n",
      "Epoch: 6, Batch number: 20, Loss: 20361.875\n",
      "Epoch: 7, Batch number: 44, Loss: 19884.900390625\n",
      "Epoch: 8, Batch number: 68, Loss: 19499.068359375\n",
      "Epoch: 10, Batch number: 16, Loss: 17781.658203125\n",
      "Epoch: 11, Batch number: 40, Loss: 17697.7265625\n",
      "Epoch: 12, Batch number: 64, Loss: 17400.599609375\n",
      "Epoch: 14, Batch number: 12, Loss: 16583.44921875\n",
      "Epoch: 15, Batch number: 36, Loss: 16825.767578125\n",
      "Epoch: 16, Batch number: 60, Loss: 16738.478515625\n",
      "Epoch: 18, Batch number: 8, Loss: 16499.345703125\n",
      "Epoch: 19, Batch number: 32, Loss: 16058.798828125\n",
      "Epoch: 20, Batch number: 56, Loss: 16012.3203125\n",
      "Epoch: 22, Batch number: 4, Loss: 15518.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Batch number: 28, Loss: 15423.177734375\n",
      "Epoch: 24, Batch number: 52, Loss: 15577.7978515625\n",
      "Epoch: 26, Batch number: 0, Loss: 15248.087890625\n",
      "Epoch: 27, Batch number: 24, Loss: 15080.1474609375\n",
      "Epoch: 28, Batch number: 48, Loss: 15128.162109375\n",
      "Epoch: 29, Batch number: 72, Loss: 15399.85546875\n",
      "Epoch: 31, Batch number: 20, Loss: 14881.3017578125\n",
      "Epoch: 32, Batch number: 44, Loss: 15112.5302734375\n",
      "Epoch: 33, Batch number: 68, Loss: 14794.3408203125\n",
      "Epoch: 35, Batch number: 16, Loss: 15195.9267578125\n",
      "Epoch: 36, Batch number: 40, Loss: 14920.0419921875\n",
      "Epoch: 37, Batch number: 64, Loss: 15060.4833984375\n",
      "Epoch: 39, Batch number: 12, Loss: 14538.0712890625\n",
      "Epoch: 40, Batch number: 36, Loss: 14823.2626953125\n",
      "Epoch: 41, Batch number: 60, Loss: 14857.0322265625\n",
      "Epoch: 43, Batch number: 8, Loss: 14619.412109375\n",
      "Epoch: 44, Batch number: 32, Loss: 14642.869140625\n",
      "Epoch: 45, Batch number: 56, Loss: 14484.060546875\n",
      "Epoch: 47, Batch number: 4, Loss: 14670.509765625\n",
      "Epoch: 48, Batch number: 28, Loss: 14447.390625\n",
      "Epoch: 49, Batch number: 52, Loss: 14928.5439453125\n",
      "Epoch: 51, Batch number: 0, Loss: 14209.7080078125\n",
      "Epoch: 52, Batch number: 24, Loss: 14746.998046875\n",
      "Epoch: 53, Batch number: 48, Loss: 14283.783203125\n",
      "Epoch: 54, Batch number: 72, Loss: 14671.59375\n",
      "Epoch: 56, Batch number: 20, Loss: 14521.5517578125\n",
      "Epoch: 57, Batch number: 44, Loss: 14290.3037109375\n",
      "Epoch: 58, Batch number: 68, Loss: 14678.560546875\n",
      "Epoch: 60, Batch number: 16, Loss: 14124.3115234375\n",
      "Epoch: 61, Batch number: 40, Loss: 14049.8798828125\n",
      "Epoch: 62, Batch number: 64, Loss: 14266.3203125\n",
      "Epoch: 64, Batch number: 12, Loss: 13965.3115234375\n",
      "Epoch: 65, Batch number: 36, Loss: 13953.9375\n",
      "Epoch: 66, Batch number: 60, Loss: 14130.087890625\n",
      "Epoch: 68, Batch number: 8, Loss: 13824.2138671875\n",
      "Epoch: 69, Batch number: 32, Loss: 13675.8017578125\n",
      "Epoch: 70, Batch number: 56, Loss: 13650.3955078125\n",
      "Epoch: 72, Batch number: 4, Loss: 13635.2265625\n",
      "Epoch: 73, Batch number: 28, Loss: 14128.7822265625\n",
      "Epoch: 74, Batch number: 52, Loss: 14033.7041015625\n",
      "Epoch: 76, Batch number: 0, Loss: 13888.6884765625\n",
      "Epoch: 77, Batch number: 24, Loss: 13836.703125\n",
      "Epoch: 78, Batch number: 48, Loss: 13795.400390625\n",
      "Epoch: 79, Batch number: 72, Loss: 14104.060546875\n",
      "Epoch: 81, Batch number: 20, Loss: 13645.3583984375\n",
      "Epoch: 82, Batch number: 44, Loss: 13851.7734375\n",
      "Epoch: 83, Batch number: 68, Loss: 14026.1552734375\n",
      "Epoch: 85, Batch number: 16, Loss: 14129.16015625\n",
      "Epoch: 86, Batch number: 40, Loss: 14117.2861328125\n",
      "Epoch: 87, Batch number: 64, Loss: 13897.0224609375\n",
      "Epoch: 89, Batch number: 12, Loss: 13988.73046875\n",
      "Epoch: 90, Batch number: 36, Loss: 13498.365234375\n",
      "Epoch: 91, Batch number: 60, Loss: 14234.4306640625\n",
      "Epoch: 93, Batch number: 8, Loss: 14105.154296875\n",
      "Epoch: 94, Batch number: 32, Loss: 13940.677734375\n",
      "Epoch: 95, Batch number: 56, Loss: 13509.9814453125\n",
      "Epoch: 97, Batch number: 4, Loss: 13541.7744140625\n",
      "Epoch: 98, Batch number: 28, Loss: 13712.697265625\n",
      "Epoch: 99, Batch number: 52, Loss: 13810.0078125\n",
      "Epoch: 101, Batch number: 0, Loss: 14000.986328125\n",
      "Epoch: 102, Batch number: 24, Loss: 13583.78125\n",
      "Epoch: 103, Batch number: 48, Loss: 13544.4375\n",
      "Epoch: 104, Batch number: 72, Loss: 13928.05078125\n",
      "Epoch: 106, Batch number: 20, Loss: 13629.3251953125\n",
      "Epoch: 107, Batch number: 44, Loss: 14027.0078125\n",
      "Epoch: 108, Batch number: 68, Loss: 13816.78125\n",
      "Epoch: 110, Batch number: 16, Loss: 13607.9873046875\n",
      "Epoch: 111, Batch number: 40, Loss: 13929.287109375\n",
      "Epoch: 112, Batch number: 64, Loss: 13775.44140625\n",
      "Epoch: 114, Batch number: 12, Loss: 13750.7109375\n",
      "Epoch: 115, Batch number: 36, Loss: 13980.560546875\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'Adam'\n",
    "epochs = 300\n",
    "sample_loss_every = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "for trainer_list in sk_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (5., 4.)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for trainer_list in sk_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        ax.plot(trainer.loss_history['iter'],trainer.loss_history['loss'],\n",
    "                label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 1\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "CBOW trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "CBOW trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 3\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "CBOW trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 4\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "CBOW trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 5\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "CBOW trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 6\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "CBOW trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 7\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n",
      "CBOW trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 50\n",
      "CBOW trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 100\n",
      "CBOW trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 150\n",
      "CBOW trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 200\n",
      "CBOW trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 300\n",
      "CBOW trainer created:\n",
      "Window size: 8\n",
      "Number of samples: 38728\n",
      "Vocabulary Size: 5365\n",
      "Number of batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:0\n",
      "Dimensión del espacio de los embeddings: 400\n"
     ]
    }
   ],
   "source": [
    "#corpus = [['w1', 'w2', 'w3', 'w4'], ['w1', 'w3', 'w3', 'w3'], ['w1'], ['w1', 'w2', 'w3', 'w4', 'w1', 'w2', 'w3', 'w4']]\n",
    "corpus = GetTrainCorpus('./promptsl40.train')\n",
    "cutoff_freq = 0\n",
    "window_size_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "batch_size = 512\n",
    "\n",
    "state_dict = None\n",
    "device = 'cuda:0'\n",
    "paralelize = False\n",
    "embedding_dim_list = [50, 100, 150, 200, 300, 400]\n",
    "\n",
    "cbow_trainers = []\n",
    "for window_size in window_size_list:\n",
    "    embedding_dim_trainers = []\n",
    "    for embedding_dim in embedding_dim_list:\n",
    "        cbow_trainer = CBOWTrainer(corpus, cutoff_freq, window_size, batch_size)\n",
    "        cbow_trainer.InitModel(state_dict=state_dict, device=device, paralelize=paralelize, embedding_dim=embedding_dim)\n",
    "        embedding_dim_trainers.append(cbow_trainer)\n",
    "    cbow_trainers.append(embedding_dim_trainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4430.8564453125\n",
      "Epoch: 2, Batch number: 24, Loss: 4329.7421875\n",
      "Epoch: 3, Batch number: 48, Loss: 4212.1220703125\n",
      "Epoch: 4, Batch number: 72, Loss: 4056.63720703125\n",
      "Epoch: 6, Batch number: 20, Loss: 3842.26806640625\n",
      "Epoch: 7, Batch number: 44, Loss: 3627.57763671875\n",
      "Epoch: 8, Batch number: 68, Loss: 3407.746337890625\n",
      "Epoch: 10, Batch number: 16, Loss: 3068.506103515625\n",
      "Epoch: 11, Batch number: 40, Loss: 3028.6435546875\n",
      "Epoch: 12, Batch number: 64, Loss: 3001.88720703125\n",
      "Epoch: 14, Batch number: 12, Loss: 2816.53125\n",
      "Epoch: 15, Batch number: 36, Loss: 2594.18896484375\n",
      "Epoch: 16, Batch number: 60, Loss: 2639.33984375\n",
      "Epoch: 18, Batch number: 8, Loss: 2548.654296875\n",
      "Epoch: 19, Batch number: 32, Loss: 2558.513427734375\n",
      "Epoch: 20, Batch number: 56, Loss: 2389.912841796875\n",
      "Epoch: 22, Batch number: 4, Loss: 2347.719970703125\n",
      "Epoch: 23, Batch number: 28, Loss: 2235.996337890625\n",
      "Epoch: 24, Batch number: 52, Loss: 2163.594970703125\n",
      "Epoch: 26, Batch number: 0, Loss: 2242.1298828125\n",
      "Epoch: 27, Batch number: 24, Loss: 2153.350830078125\n",
      "Epoch: 28, Batch number: 48, Loss: 2100.736572265625\n",
      "Epoch: 29, Batch number: 72, Loss: 1980.3748779296875\n",
      "Epoch: 31, Batch number: 20, Loss: 2012.6744384765625\n",
      "Epoch: 32, Batch number: 44, Loss: 2045.1976318359375\n",
      "Epoch: 33, Batch number: 68, Loss: 1973.8653564453125\n",
      "Epoch: 35, Batch number: 16, Loss: 1945.7928466796875\n",
      "Epoch: 36, Batch number: 40, Loss: 1927.683349609375\n",
      "Epoch: 37, Batch number: 64, Loss: 1793.17138671875\n",
      "Epoch: 39, Batch number: 12, Loss: 1830.75048828125\n",
      "Epoch: 40, Batch number: 36, Loss: 1789.7298583984375\n",
      "Epoch: 41, Batch number: 60, Loss: 1753.8408203125\n",
      "Epoch: 43, Batch number: 8, Loss: 1762.36474609375\n",
      "Epoch: 44, Batch number: 32, Loss: 1586.6871337890625\n",
      "Epoch: 45, Batch number: 56, Loss: 1596.96923828125\n",
      "Epoch: 47, Batch number: 4, Loss: 1584.6182861328125\n",
      "Epoch: 48, Batch number: 28, Loss: 1567.241943359375\n",
      "Epoch: 49, Batch number: 52, Loss: 1459.0133056640625\n",
      "Epoch: 51, Batch number: 0, Loss: 1438.949951171875\n",
      "Epoch: 52, Batch number: 24, Loss: 1464.7547607421875\n",
      "Epoch: 53, Batch number: 48, Loss: 1460.8350830078125\n",
      "Epoch: 54, Batch number: 72, Loss: 1467.4688720703125\n",
      "Epoch: 56, Batch number: 20, Loss: 1425.4210205078125\n",
      "Epoch: 57, Batch number: 44, Loss: 1427.4927978515625\n",
      "Epoch: 58, Batch number: 68, Loss: 1357.2701416015625\n",
      "Epoch: 60, Batch number: 16, Loss: 1383.8450927734375\n",
      "Epoch: 61, Batch number: 40, Loss: 1342.337158203125\n",
      "Epoch: 62, Batch number: 64, Loss: 1356.817626953125\n",
      "Epoch: 64, Batch number: 12, Loss: 1210.451171875\n",
      "Epoch: 65, Batch number: 36, Loss: 1280.4713134765625\n",
      "Epoch: 66, Batch number: 60, Loss: 1320.0545654296875\n",
      "Epoch: 68, Batch number: 8, Loss: 1313.2379150390625\n",
      "Epoch: 69, Batch number: 32, Loss: 1202.750732421875\n",
      "Epoch: 70, Batch number: 56, Loss: 1229.2252197265625\n",
      "Epoch: 72, Batch number: 4, Loss: 1287.110595703125\n",
      "Epoch: 73, Batch number: 28, Loss: 1171.3912353515625\n",
      "Epoch: 74, Batch number: 52, Loss: 1215.2667236328125\n",
      "Epoch: 76, Batch number: 0, Loss: 1204.840087890625\n",
      "Epoch: 77, Batch number: 24, Loss: 1153.0467529296875\n",
      "Epoch: 78, Batch number: 48, Loss: 1216.3594970703125\n",
      "Epoch: 79, Batch number: 72, Loss: 1168.7034912109375\n",
      "Epoch: 81, Batch number: 20, Loss: 1116.3016357421875\n",
      "Epoch: 82, Batch number: 44, Loss: 1107.3472900390625\n",
      "Epoch: 83, Batch number: 68, Loss: 1025.1365966796875\n",
      "Epoch: 85, Batch number: 16, Loss: 1096.025634765625\n",
      "Epoch: 86, Batch number: 40, Loss: 1069.14306640625\n",
      "Epoch: 87, Batch number: 64, Loss: 1059.731201171875\n",
      "Epoch: 89, Batch number: 12, Loss: 1104.4249267578125\n",
      "Epoch: 90, Batch number: 36, Loss: 985.0037841796875\n",
      "Epoch: 91, Batch number: 60, Loss: 1037.19775390625\n",
      "Epoch: 93, Batch number: 8, Loss: 904.8789672851562\n",
      "Epoch: 94, Batch number: 32, Loss: 1061.7349853515625\n",
      "Epoch: 95, Batch number: 56, Loss: 983.3056640625\n",
      "Epoch: 97, Batch number: 4, Loss: 984.339599609375\n",
      "Epoch: 98, Batch number: 28, Loss: 939.434326171875\n",
      "Epoch: 99, Batch number: 52, Loss: 940.5684204101562\n",
      "Epoch: 101, Batch number: 0, Loss: 879.0020751953125\n",
      "Epoch: 102, Batch number: 24, Loss: 964.6378173828125\n",
      "Epoch: 103, Batch number: 48, Loss: 837.8728637695312\n",
      "Epoch: 104, Batch number: 72, Loss: 1006.2574462890625\n",
      "Epoch: 106, Batch number: 20, Loss: 850.9827880859375\n",
      "Epoch: 107, Batch number: 44, Loss: 894.353759765625\n",
      "Epoch: 108, Batch number: 68, Loss: 935.9161987304688\n",
      "Epoch: 110, Batch number: 16, Loss: 825.16845703125\n",
      "Epoch: 111, Batch number: 40, Loss: 901.77880859375\n",
      "Epoch: 112, Batch number: 64, Loss: 919.6204833984375\n",
      "Epoch: 114, Batch number: 12, Loss: 875.4749755859375\n",
      "Epoch: 115, Batch number: 36, Loss: 814.3798828125\n",
      "Epoch: 116, Batch number: 60, Loss: 796.3709716796875\n",
      "Epoch: 118, Batch number: 8, Loss: 889.5577392578125\n",
      "Epoch: 119, Batch number: 32, Loss: 841.4775390625\n",
      "Epoch: 120, Batch number: 56, Loss: 851.0756225585938\n",
      "Epoch: 122, Batch number: 4, Loss: 768.8853149414062\n",
      "Epoch: 123, Batch number: 28, Loss: 804.8013916015625\n",
      "Epoch: 124, Batch number: 52, Loss: 795.9503173828125\n",
      "Epoch: 126, Batch number: 0, Loss: 797.7215576171875\n",
      "Epoch: 127, Batch number: 24, Loss: 774.8203735351562\n",
      "Epoch: 128, Batch number: 48, Loss: 757.690673828125\n",
      "Epoch: 129, Batch number: 72, Loss: 723.5654907226562\n",
      "Epoch: 131, Batch number: 20, Loss: 708.4859619140625\n",
      "Epoch: 132, Batch number: 44, Loss: 732.9812622070312\n",
      "Epoch: 133, Batch number: 68, Loss: 753.7574462890625\n",
      "Epoch: 135, Batch number: 16, Loss: 744.3997192382812\n",
      "Epoch: 136, Batch number: 40, Loss: 710.20361328125\n",
      "Epoch: 137, Batch number: 64, Loss: 804.88427734375\n",
      "Epoch: 139, Batch number: 12, Loss: 746.863037109375\n",
      "Epoch: 140, Batch number: 36, Loss: 718.9891967773438\n",
      "Epoch: 141, Batch number: 60, Loss: 717.523681640625\n",
      "Epoch: 143, Batch number: 8, Loss: 730.6411743164062\n",
      "Epoch: 144, Batch number: 32, Loss: 634.6747436523438\n",
      "Epoch: 145, Batch number: 56, Loss: 731.6798095703125\n",
      "Epoch: 147, Batch number: 4, Loss: 714.611572265625\n",
      "Epoch: 148, Batch number: 28, Loss: 653.0748291015625\n",
      "Epoch: 149, Batch number: 52, Loss: 712.29296875\n",
      "Epoch: 151, Batch number: 0, Loss: 683.3143920898438\n",
      "Epoch: 152, Batch number: 24, Loss: 575.3716430664062\n",
      "Epoch: 153, Batch number: 48, Loss: 670.2200927734375\n",
      "Epoch: 154, Batch number: 72, Loss: 680.6591796875\n",
      "Epoch: 156, Batch number: 20, Loss: 669.2647094726562\n",
      "Epoch: 157, Batch number: 44, Loss: 742.9160766601562\n",
      "Epoch: 158, Batch number: 68, Loss: 757.1419677734375\n",
      "Epoch: 160, Batch number: 16, Loss: 625.629638671875\n",
      "Epoch: 161, Batch number: 40, Loss: 590.131591796875\n",
      "Epoch: 162, Batch number: 64, Loss: 691.8448486328125\n",
      "Epoch: 164, Batch number: 12, Loss: 658.0091552734375\n",
      "Epoch: 165, Batch number: 36, Loss: 676.586181640625\n",
      "Epoch: 166, Batch number: 60, Loss: 684.0070190429688\n",
      "Epoch: 168, Batch number: 8, Loss: 584.4603271484375\n",
      "Epoch: 169, Batch number: 32, Loss: 634.707275390625\n",
      "Epoch: 170, Batch number: 56, Loss: 587.55126953125\n",
      "Epoch: 172, Batch number: 4, Loss: 710.55029296875\n",
      "Epoch: 173, Batch number: 28, Loss: 636.0354614257812\n",
      "Epoch: 174, Batch number: 52, Loss: 598.6432495117188\n",
      "Epoch: 176, Batch number: 0, Loss: 705.098388671875\n",
      "Epoch: 177, Batch number: 24, Loss: 653.8350830078125\n",
      "Epoch: 178, Batch number: 48, Loss: 624.22412109375\n",
      "Epoch: 179, Batch number: 72, Loss: 623.7754516601562\n",
      "Epoch: 181, Batch number: 20, Loss: 571.8873901367188\n",
      "Epoch: 182, Batch number: 44, Loss: 582.4325561523438\n",
      "Epoch: 183, Batch number: 68, Loss: 591.9141235351562\n",
      "Epoch: 185, Batch number: 16, Loss: 617.1417846679688\n",
      "Epoch: 186, Batch number: 40, Loss: 593.549560546875\n",
      "Epoch: 187, Batch number: 64, Loss: 566.0902709960938\n",
      "Epoch: 189, Batch number: 12, Loss: 584.9329223632812\n",
      "Epoch: 190, Batch number: 36, Loss: 586.6611938476562\n",
      "Epoch: 191, Batch number: 60, Loss: 552.0286865234375\n",
      "Epoch: 193, Batch number: 8, Loss: 591.888671875\n",
      "Epoch: 194, Batch number: 32, Loss: 611.040771484375\n",
      "Epoch: 195, Batch number: 56, Loss: 570.7216796875\n",
      "Epoch: 197, Batch number: 4, Loss: 603.3228149414062\n",
      "Epoch: 198, Batch number: 28, Loss: 633.0795288085938\n",
      "Epoch: 199, Batch number: 52, Loss: 578.0796508789062\n",
      "Epoch: 201, Batch number: 0, Loss: 585.6912231445312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202, Batch number: 24, Loss: 596.6123657226562\n",
      "Epoch: 203, Batch number: 48, Loss: 526.9928588867188\n",
      "Epoch: 204, Batch number: 72, Loss: 592.4153442382812\n",
      "Epoch: 206, Batch number: 20, Loss: 546.248046875\n",
      "Epoch: 207, Batch number: 44, Loss: 576.3812255859375\n",
      "Epoch: 208, Batch number: 68, Loss: 641.4169311523438\n",
      "Epoch: 210, Batch number: 16, Loss: 585.3668212890625\n",
      "Epoch: 211, Batch number: 40, Loss: 567.5971069335938\n",
      "Epoch: 212, Batch number: 64, Loss: 615.4054565429688\n",
      "Epoch: 214, Batch number: 12, Loss: 539.1146240234375\n",
      "Epoch: 215, Batch number: 36, Loss: 547.1031494140625\n",
      "Epoch: 216, Batch number: 60, Loss: 592.9738159179688\n",
      "Epoch: 218, Batch number: 8, Loss: 506.8787841796875\n",
      "Epoch: 219, Batch number: 32, Loss: 518.972412109375\n",
      "Epoch: 220, Batch number: 56, Loss: 533.5850219726562\n",
      "Epoch: 222, Batch number: 4, Loss: 524.1573486328125\n",
      "Epoch: 223, Batch number: 28, Loss: 509.1853942871094\n",
      "Epoch: 224, Batch number: 52, Loss: 567.3779296875\n",
      "Epoch: 226, Batch number: 0, Loss: 557.822998046875\n",
      "Epoch: 227, Batch number: 24, Loss: 592.6803588867188\n",
      "Epoch: 228, Batch number: 48, Loss: 475.5628356933594\n",
      "Epoch: 229, Batch number: 72, Loss: 551.115234375\n",
      "Epoch: 231, Batch number: 20, Loss: 499.58685302734375\n",
      "Epoch: 232, Batch number: 44, Loss: 503.4032287597656\n",
      "Epoch: 233, Batch number: 68, Loss: 529.48046875\n",
      "Epoch: 235, Batch number: 16, Loss: 573.7207641601562\n",
      "Epoch: 236, Batch number: 40, Loss: 519.1380615234375\n",
      "Epoch: 237, Batch number: 64, Loss: 569.6708984375\n",
      "Epoch: 239, Batch number: 12, Loss: 571.266357421875\n",
      "Epoch: 240, Batch number: 36, Loss: 535.8417358398438\n",
      "Epoch: 241, Batch number: 60, Loss: 528.2364501953125\n",
      "Epoch: 243, Batch number: 8, Loss: 520.1941528320312\n",
      "Epoch: 244, Batch number: 32, Loss: 488.6038818359375\n",
      "Epoch: 245, Batch number: 56, Loss: 502.14599609375\n",
      "Epoch: 247, Batch number: 4, Loss: 515.4060668945312\n",
      "Epoch: 248, Batch number: 28, Loss: 553.1480712890625\n",
      "Epoch: 249, Batch number: 52, Loss: 499.37152099609375\n",
      "Epoch: 251, Batch number: 0, Loss: 553.686767578125\n",
      "Epoch: 252, Batch number: 24, Loss: 482.1966247558594\n",
      "Epoch: 253, Batch number: 48, Loss: 434.59466552734375\n",
      "Epoch: 254, Batch number: 72, Loss: 469.0348815917969\n",
      "Epoch: 256, Batch number: 20, Loss: 483.8118591308594\n",
      "Epoch: 257, Batch number: 44, Loss: 446.1160583496094\n",
      "Epoch: 258, Batch number: 68, Loss: 488.947265625\n",
      "Epoch: 260, Batch number: 16, Loss: 469.599609375\n",
      "Epoch: 261, Batch number: 40, Loss: 469.439453125\n",
      "Epoch: 262, Batch number: 64, Loss: 487.6988220214844\n",
      "Epoch: 264, Batch number: 12, Loss: 490.3595275878906\n",
      "Epoch: 265, Batch number: 36, Loss: 470.0549011230469\n",
      "Epoch: 266, Batch number: 60, Loss: 492.99951171875\n",
      "Epoch: 268, Batch number: 8, Loss: 535.5175170898438\n",
      "Epoch: 269, Batch number: 32, Loss: 515.5584106445312\n",
      "Epoch: 270, Batch number: 56, Loss: 532.475830078125\n",
      "Epoch: 272, Batch number: 4, Loss: 448.5904541015625\n",
      "Epoch: 273, Batch number: 28, Loss: 435.94036865234375\n",
      "Epoch: 274, Batch number: 52, Loss: 536.21435546875\n",
      "Epoch: 276, Batch number: 0, Loss: 476.0323791503906\n",
      "Epoch: 277, Batch number: 24, Loss: 514.451416015625\n",
      "Epoch: 278, Batch number: 48, Loss: 492.6129455566406\n",
      "Epoch: 279, Batch number: 72, Loss: 535.306396484375\n",
      "Epoch: 281, Batch number: 20, Loss: 460.8424987792969\n",
      "Epoch: 282, Batch number: 44, Loss: 488.2908935546875\n",
      "Epoch: 283, Batch number: 68, Loss: 527.733154296875\n",
      "Epoch: 285, Batch number: 16, Loss: 499.4319763183594\n",
      "Epoch: 286, Batch number: 40, Loss: 488.3245849609375\n",
      "Epoch: 287, Batch number: 64, Loss: 492.1897888183594\n",
      "Epoch: 289, Batch number: 12, Loss: 510.4396057128906\n",
      "Epoch: 290, Batch number: 36, Loss: 507.2864074707031\n",
      "Epoch: 291, Batch number: 60, Loss: 517.7525024414062\n",
      "Epoch: 293, Batch number: 8, Loss: 469.5762023925781\n",
      "Epoch: 294, Batch number: 32, Loss: 529.4655151367188\n",
      "Epoch: 295, Batch number: 56, Loss: 527.9716186523438\n",
      "Epoch: 297, Batch number: 4, Loss: 430.1188659667969\n",
      "Epoch: 298, Batch number: 28, Loss: 482.5830993652344\n",
      "Epoch: 299, Batch number: 52, Loss: 461.16534423828125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4446.18359375\n",
      "Epoch: 2, Batch number: 24, Loss: 4258.216796875\n",
      "Epoch: 3, Batch number: 48, Loss: 3983.428955078125\n",
      "Epoch: 4, Batch number: 72, Loss: 3709.52001953125\n",
      "Epoch: 6, Batch number: 20, Loss: 3352.544921875\n",
      "Epoch: 7, Batch number: 44, Loss: 3079.771728515625\n",
      "Epoch: 8, Batch number: 68, Loss: 2683.099365234375\n",
      "Epoch: 10, Batch number: 16, Loss: 2578.928955078125\n",
      "Epoch: 11, Batch number: 40, Loss: 2420.59912109375\n",
      "Epoch: 12, Batch number: 64, Loss: 2401.606201171875\n",
      "Epoch: 14, Batch number: 12, Loss: 2315.42236328125\n",
      "Epoch: 15, Batch number: 36, Loss: 2205.730224609375\n",
      "Epoch: 16, Batch number: 60, Loss: 2184.973388671875\n",
      "Epoch: 18, Batch number: 8, Loss: 2098.553466796875\n",
      "Epoch: 19, Batch number: 32, Loss: 2098.544921875\n",
      "Epoch: 20, Batch number: 56, Loss: 1947.0146484375\n",
      "Epoch: 22, Batch number: 4, Loss: 1802.6907958984375\n",
      "Epoch: 23, Batch number: 28, Loss: 1776.3675537109375\n",
      "Epoch: 24, Batch number: 52, Loss: 1763.752685546875\n",
      "Epoch: 26, Batch number: 0, Loss: 1613.4498291015625\n",
      "Epoch: 27, Batch number: 24, Loss: 1614.385009765625\n",
      "Epoch: 28, Batch number: 48, Loss: 1625.560302734375\n",
      "Epoch: 29, Batch number: 72, Loss: 1548.0999755859375\n",
      "Epoch: 31, Batch number: 20, Loss: 1488.079345703125\n",
      "Epoch: 32, Batch number: 44, Loss: 1433.78369140625\n",
      "Epoch: 33, Batch number: 68, Loss: 1427.214111328125\n",
      "Epoch: 35, Batch number: 16, Loss: 1401.366943359375\n",
      "Epoch: 36, Batch number: 40, Loss: 1325.383544921875\n",
      "Epoch: 37, Batch number: 64, Loss: 1270.1607666015625\n",
      "Epoch: 39, Batch number: 12, Loss: 1238.191650390625\n",
      "Epoch: 40, Batch number: 36, Loss: 1184.4130859375\n",
      "Epoch: 41, Batch number: 60, Loss: 1231.36474609375\n",
      "Epoch: 43, Batch number: 8, Loss: 1119.832763671875\n",
      "Epoch: 44, Batch number: 32, Loss: 1068.9403076171875\n",
      "Epoch: 45, Batch number: 56, Loss: 1135.910400390625\n",
      "Epoch: 47, Batch number: 4, Loss: 1083.157958984375\n",
      "Epoch: 48, Batch number: 28, Loss: 1081.0008544921875\n",
      "Epoch: 49, Batch number: 52, Loss: 1020.1779174804688\n",
      "Epoch: 51, Batch number: 0, Loss: 960.2530517578125\n",
      "Epoch: 52, Batch number: 24, Loss: 970.2157592773438\n",
      "Epoch: 53, Batch number: 48, Loss: 1016.9705810546875\n",
      "Epoch: 54, Batch number: 72, Loss: 934.7958984375\n",
      "Epoch: 56, Batch number: 20, Loss: 932.6875610351562\n",
      "Epoch: 57, Batch number: 44, Loss: 989.8128662109375\n",
      "Epoch: 58, Batch number: 68, Loss: 845.8715209960938\n",
      "Epoch: 60, Batch number: 16, Loss: 914.7257690429688\n",
      "Epoch: 61, Batch number: 40, Loss: 904.9185791015625\n",
      "Epoch: 62, Batch number: 64, Loss: 884.0316162109375\n",
      "Epoch: 64, Batch number: 12, Loss: 789.0965576171875\n",
      "Epoch: 65, Batch number: 36, Loss: 779.5721435546875\n",
      "Epoch: 66, Batch number: 60, Loss: 897.6605834960938\n",
      "Epoch: 68, Batch number: 8, Loss: 913.0784301757812\n",
      "Epoch: 69, Batch number: 32, Loss: 800.97998046875\n",
      "Epoch: 70, Batch number: 56, Loss: 766.41845703125\n",
      "Epoch: 72, Batch number: 4, Loss: 710.9991455078125\n",
      "Epoch: 73, Batch number: 28, Loss: 762.7184448242188\n",
      "Epoch: 74, Batch number: 52, Loss: 747.7166748046875\n",
      "Epoch: 76, Batch number: 0, Loss: 739.8248291015625\n",
      "Epoch: 77, Batch number: 24, Loss: 689.1011962890625\n",
      "Epoch: 78, Batch number: 48, Loss: 721.0616455078125\n",
      "Epoch: 79, Batch number: 72, Loss: 685.6275634765625\n",
      "Epoch: 81, Batch number: 20, Loss: 691.3765258789062\n",
      "Epoch: 82, Batch number: 44, Loss: 677.4728393554688\n",
      "Epoch: 83, Batch number: 68, Loss: 738.0115966796875\n",
      "Epoch: 85, Batch number: 16, Loss: 603.425048828125\n",
      "Epoch: 86, Batch number: 40, Loss: 685.4066772460938\n",
      "Epoch: 87, Batch number: 64, Loss: 693.3883666992188\n",
      "Epoch: 89, Batch number: 12, Loss: 667.7329711914062\n",
      "Epoch: 90, Batch number: 36, Loss: 625.7137451171875\n",
      "Epoch: 91, Batch number: 60, Loss: 660.7714233398438\n",
      "Epoch: 93, Batch number: 8, Loss: 628.4421997070312\n",
      "Epoch: 94, Batch number: 32, Loss: 658.6557006835938\n",
      "Epoch: 95, Batch number: 56, Loss: 675.2769775390625\n",
      "Epoch: 97, Batch number: 4, Loss: 638.077880859375\n",
      "Epoch: 98, Batch number: 28, Loss: 676.9635009765625\n",
      "Epoch: 99, Batch number: 52, Loss: 597.8820190429688\n",
      "Epoch: 101, Batch number: 0, Loss: 616.751708984375\n",
      "Epoch: 102, Batch number: 24, Loss: 623.340576171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103, Batch number: 48, Loss: 601.3485717773438\n",
      "Epoch: 104, Batch number: 72, Loss: 572.333984375\n",
      "Epoch: 106, Batch number: 20, Loss: 514.5880737304688\n",
      "Epoch: 107, Batch number: 44, Loss: 616.9256591796875\n",
      "Epoch: 108, Batch number: 68, Loss: 614.718505859375\n",
      "Epoch: 110, Batch number: 16, Loss: 584.7534790039062\n",
      "Epoch: 111, Batch number: 40, Loss: 579.0636596679688\n",
      "Epoch: 112, Batch number: 64, Loss: 557.687255859375\n",
      "Epoch: 114, Batch number: 12, Loss: 539.9090576171875\n",
      "Epoch: 115, Batch number: 36, Loss: 518.7421264648438\n",
      "Epoch: 116, Batch number: 60, Loss: 578.48095703125\n",
      "Epoch: 118, Batch number: 8, Loss: 526.7406616210938\n",
      "Epoch: 119, Batch number: 32, Loss: 588.8125\n",
      "Epoch: 120, Batch number: 56, Loss: 610.4322509765625\n",
      "Epoch: 122, Batch number: 4, Loss: 488.2532653808594\n",
      "Epoch: 123, Batch number: 28, Loss: 519.7977294921875\n",
      "Epoch: 124, Batch number: 52, Loss: 527.8368530273438\n",
      "Epoch: 126, Batch number: 0, Loss: 510.25775146484375\n",
      "Epoch: 127, Batch number: 24, Loss: 581.2000732421875\n",
      "Epoch: 128, Batch number: 48, Loss: 609.44921875\n",
      "Epoch: 129, Batch number: 72, Loss: 490.2554931640625\n",
      "Epoch: 131, Batch number: 20, Loss: 502.0901794433594\n",
      "Epoch: 132, Batch number: 44, Loss: 476.4352111816406\n",
      "Epoch: 133, Batch number: 68, Loss: 521.8651123046875\n",
      "Epoch: 135, Batch number: 16, Loss: 498.3936767578125\n",
      "Epoch: 136, Batch number: 40, Loss: 501.0558166503906\n",
      "Epoch: 137, Batch number: 64, Loss: 514.13525390625\n",
      "Epoch: 139, Batch number: 12, Loss: 509.58953857421875\n",
      "Epoch: 140, Batch number: 36, Loss: 496.84912109375\n",
      "Epoch: 141, Batch number: 60, Loss: 500.6528015136719\n",
      "Epoch: 143, Batch number: 8, Loss: 544.6867065429688\n",
      "Epoch: 144, Batch number: 32, Loss: 494.08551025390625\n",
      "Epoch: 145, Batch number: 56, Loss: 501.14727783203125\n",
      "Epoch: 147, Batch number: 4, Loss: 444.7645568847656\n",
      "Epoch: 148, Batch number: 28, Loss: 468.32379150390625\n",
      "Epoch: 149, Batch number: 52, Loss: 516.9078369140625\n",
      "Epoch: 151, Batch number: 0, Loss: 441.6435241699219\n",
      "Epoch: 152, Batch number: 24, Loss: 506.49456787109375\n",
      "Epoch: 153, Batch number: 48, Loss: 458.36114501953125\n",
      "Epoch: 154, Batch number: 72, Loss: 559.6586303710938\n",
      "Epoch: 156, Batch number: 20, Loss: 417.58135986328125\n",
      "Epoch: 157, Batch number: 44, Loss: 473.83892822265625\n",
      "Epoch: 158, Batch number: 68, Loss: 531.1576538085938\n",
      "Epoch: 160, Batch number: 16, Loss: 463.7409973144531\n",
      "Epoch: 161, Batch number: 40, Loss: 519.1788940429688\n",
      "Epoch: 162, Batch number: 64, Loss: 491.9665832519531\n",
      "Epoch: 164, Batch number: 12, Loss: 500.0379638671875\n",
      "Epoch: 165, Batch number: 36, Loss: 474.83270263671875\n",
      "Epoch: 166, Batch number: 60, Loss: 495.9667053222656\n",
      "Epoch: 168, Batch number: 8, Loss: 445.5859375\n",
      "Epoch: 169, Batch number: 32, Loss: 466.7552795410156\n",
      "Epoch: 170, Batch number: 56, Loss: 507.4927062988281\n",
      "Epoch: 172, Batch number: 4, Loss: 485.8116149902344\n",
      "Epoch: 173, Batch number: 28, Loss: 454.174560546875\n",
      "Epoch: 174, Batch number: 52, Loss: 510.1905212402344\n",
      "Epoch: 176, Batch number: 0, Loss: 472.51202392578125\n",
      "Epoch: 177, Batch number: 24, Loss: 457.97821044921875\n",
      "Epoch: 178, Batch number: 48, Loss: 496.10308837890625\n",
      "Epoch: 179, Batch number: 72, Loss: 464.9812316894531\n",
      "Epoch: 181, Batch number: 20, Loss: 426.2051696777344\n",
      "Epoch: 182, Batch number: 44, Loss: 466.3422546386719\n",
      "Epoch: 183, Batch number: 68, Loss: 469.9462585449219\n",
      "Epoch: 185, Batch number: 16, Loss: 425.1202697753906\n",
      "Epoch: 186, Batch number: 40, Loss: 481.14752197265625\n",
      "Epoch: 187, Batch number: 64, Loss: 408.41802978515625\n",
      "Epoch: 189, Batch number: 12, Loss: 414.72393798828125\n",
      "Epoch: 190, Batch number: 36, Loss: 479.9449462890625\n",
      "Epoch: 191, Batch number: 60, Loss: 452.6312561035156\n",
      "Epoch: 193, Batch number: 8, Loss: 471.1080627441406\n",
      "Epoch: 194, Batch number: 32, Loss: 453.06353759765625\n",
      "Epoch: 195, Batch number: 56, Loss: 444.16558837890625\n",
      "Epoch: 197, Batch number: 4, Loss: 476.000732421875\n",
      "Epoch: 198, Batch number: 28, Loss: 391.3194580078125\n",
      "Epoch: 199, Batch number: 52, Loss: 410.6092834472656\n",
      "Epoch: 201, Batch number: 0, Loss: 417.08184814453125\n",
      "Epoch: 202, Batch number: 24, Loss: 457.7058410644531\n",
      "Epoch: 203, Batch number: 48, Loss: 452.8554382324219\n",
      "Epoch: 204, Batch number: 72, Loss: 506.0709533691406\n",
      "Epoch: 206, Batch number: 20, Loss: 493.04071044921875\n",
      "Epoch: 207, Batch number: 44, Loss: 442.2047424316406\n",
      "Epoch: 208, Batch number: 68, Loss: 453.1783752441406\n",
      "Epoch: 210, Batch number: 16, Loss: 386.8644714355469\n",
      "Epoch: 211, Batch number: 40, Loss: 408.8529968261719\n",
      "Epoch: 212, Batch number: 64, Loss: 416.3694763183594\n",
      "Epoch: 214, Batch number: 12, Loss: 416.73486328125\n",
      "Epoch: 215, Batch number: 36, Loss: 444.05889892578125\n",
      "Epoch: 216, Batch number: 60, Loss: 468.1110534667969\n",
      "Epoch: 218, Batch number: 8, Loss: 390.73773193359375\n",
      "Epoch: 219, Batch number: 32, Loss: 444.9045104980469\n",
      "Epoch: 220, Batch number: 56, Loss: 436.0953369140625\n",
      "Epoch: 222, Batch number: 4, Loss: 396.1396789550781\n",
      "Epoch: 223, Batch number: 28, Loss: 477.3393249511719\n",
      "Epoch: 224, Batch number: 52, Loss: 462.1215515136719\n",
      "Epoch: 226, Batch number: 0, Loss: 395.6026916503906\n",
      "Epoch: 227, Batch number: 24, Loss: 436.9859313964844\n",
      "Epoch: 228, Batch number: 48, Loss: 476.71380615234375\n",
      "Epoch: 229, Batch number: 72, Loss: 442.2958679199219\n",
      "Epoch: 231, Batch number: 20, Loss: 433.97491455078125\n",
      "Epoch: 232, Batch number: 44, Loss: 400.22552490234375\n",
      "Epoch: 233, Batch number: 68, Loss: 468.9315185546875\n",
      "Epoch: 235, Batch number: 16, Loss: 427.42706298828125\n",
      "Epoch: 236, Batch number: 40, Loss: 447.9285888671875\n",
      "Epoch: 237, Batch number: 64, Loss: 420.3470153808594\n",
      "Epoch: 239, Batch number: 12, Loss: 457.9196472167969\n",
      "Epoch: 240, Batch number: 36, Loss: 435.44024658203125\n",
      "Epoch: 241, Batch number: 60, Loss: 389.85626220703125\n",
      "Epoch: 243, Batch number: 8, Loss: 445.9940185546875\n",
      "Epoch: 244, Batch number: 32, Loss: 422.6515197753906\n",
      "Epoch: 245, Batch number: 56, Loss: 430.918701171875\n",
      "Epoch: 247, Batch number: 4, Loss: 381.4164123535156\n",
      "Epoch: 248, Batch number: 28, Loss: 454.8603515625\n",
      "Epoch: 249, Batch number: 52, Loss: 420.02545166015625\n",
      "Epoch: 251, Batch number: 0, Loss: 459.71685791015625\n",
      "Epoch: 252, Batch number: 24, Loss: 422.6414794921875\n",
      "Epoch: 253, Batch number: 48, Loss: 456.9333190917969\n",
      "Epoch: 254, Batch number: 72, Loss: 406.1894836425781\n",
      "Epoch: 256, Batch number: 20, Loss: 446.57373046875\n",
      "Epoch: 257, Batch number: 44, Loss: 416.74530029296875\n",
      "Epoch: 258, Batch number: 68, Loss: 436.3446960449219\n",
      "Epoch: 260, Batch number: 16, Loss: 363.2132873535156\n",
      "Epoch: 261, Batch number: 40, Loss: 429.5168151855469\n",
      "Epoch: 262, Batch number: 64, Loss: 429.83978271484375\n",
      "Epoch: 264, Batch number: 12, Loss: 410.4364929199219\n",
      "Epoch: 265, Batch number: 36, Loss: 408.9946594238281\n",
      "Epoch: 266, Batch number: 60, Loss: 504.2856140136719\n",
      "Epoch: 268, Batch number: 8, Loss: 398.8868408203125\n",
      "Epoch: 269, Batch number: 32, Loss: 468.4044494628906\n",
      "Epoch: 270, Batch number: 56, Loss: 400.9162902832031\n",
      "Epoch: 272, Batch number: 4, Loss: 420.88775634765625\n",
      "Epoch: 273, Batch number: 28, Loss: 422.49615478515625\n",
      "Epoch: 274, Batch number: 52, Loss: 442.8186340332031\n",
      "Epoch: 276, Batch number: 0, Loss: 471.5790100097656\n",
      "Epoch: 277, Batch number: 24, Loss: 400.5804748535156\n",
      "Epoch: 278, Batch number: 48, Loss: 452.8486328125\n",
      "Epoch: 279, Batch number: 72, Loss: 403.4887390136719\n",
      "Epoch: 281, Batch number: 20, Loss: 388.2334899902344\n",
      "Epoch: 282, Batch number: 44, Loss: 445.18011474609375\n",
      "Epoch: 283, Batch number: 68, Loss: 415.31085205078125\n",
      "Epoch: 285, Batch number: 16, Loss: 415.1159973144531\n",
      "Epoch: 286, Batch number: 40, Loss: 405.8844909667969\n",
      "Epoch: 287, Batch number: 64, Loss: 412.2840576171875\n",
      "Epoch: 289, Batch number: 12, Loss: 460.4501037597656\n",
      "Epoch: 290, Batch number: 36, Loss: 465.9298400878906\n",
      "Epoch: 291, Batch number: 60, Loss: 424.9678649902344\n",
      "Epoch: 293, Batch number: 8, Loss: 385.0408935546875\n",
      "Epoch: 294, Batch number: 32, Loss: 418.7528991699219\n",
      "Epoch: 295, Batch number: 56, Loss: 415.4926452636719\n",
      "Epoch: 297, Batch number: 4, Loss: 418.44384765625\n",
      "Epoch: 298, Batch number: 28, Loss: 409.3675231933594\n",
      "Epoch: 299, Batch number: 52, Loss: 382.23822021484375\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4435.265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 24, Loss: 4116.6201171875\n",
      "Epoch: 3, Batch number: 48, Loss: 3765.100341796875\n",
      "Epoch: 4, Batch number: 72, Loss: 3500.685302734375\n",
      "Epoch: 6, Batch number: 20, Loss: 3063.77392578125\n",
      "Epoch: 7, Batch number: 44, Loss: 2669.214599609375\n",
      "Epoch: 8, Batch number: 68, Loss: 2513.103515625\n",
      "Epoch: 10, Batch number: 16, Loss: 2346.822021484375\n",
      "Epoch: 11, Batch number: 40, Loss: 2349.6767578125\n",
      "Epoch: 12, Batch number: 64, Loss: 2163.383544921875\n",
      "Epoch: 14, Batch number: 12, Loss: 1944.7513427734375\n",
      "Epoch: 15, Batch number: 36, Loss: 1905.276611328125\n",
      "Epoch: 16, Batch number: 60, Loss: 1963.816162109375\n",
      "Epoch: 18, Batch number: 8, Loss: 1711.9150390625\n",
      "Epoch: 19, Batch number: 32, Loss: 1687.35009765625\n",
      "Epoch: 20, Batch number: 56, Loss: 1544.6090087890625\n",
      "Epoch: 22, Batch number: 4, Loss: 1467.8402099609375\n",
      "Epoch: 23, Batch number: 28, Loss: 1427.528076171875\n",
      "Epoch: 24, Batch number: 52, Loss: 1368.3922119140625\n",
      "Epoch: 26, Batch number: 0, Loss: 1355.7540283203125\n",
      "Epoch: 27, Batch number: 24, Loss: 1247.126708984375\n",
      "Epoch: 28, Batch number: 48, Loss: 1295.1326904296875\n",
      "Epoch: 29, Batch number: 72, Loss: 1199.0093994140625\n",
      "Epoch: 31, Batch number: 20, Loss: 1095.7305908203125\n",
      "Epoch: 32, Batch number: 44, Loss: 1021.3411254882812\n",
      "Epoch: 33, Batch number: 68, Loss: 1094.196044921875\n",
      "Epoch: 35, Batch number: 16, Loss: 1105.8441162109375\n",
      "Epoch: 36, Batch number: 40, Loss: 1073.525634765625\n",
      "Epoch: 37, Batch number: 64, Loss: 1075.2744140625\n",
      "Epoch: 39, Batch number: 12, Loss: 1006.45556640625\n",
      "Epoch: 40, Batch number: 36, Loss: 950.6659545898438\n",
      "Epoch: 41, Batch number: 60, Loss: 938.2257690429688\n",
      "Epoch: 43, Batch number: 8, Loss: 873.1753540039062\n",
      "Epoch: 44, Batch number: 32, Loss: 884.8098754882812\n",
      "Epoch: 45, Batch number: 56, Loss: 869.4096069335938\n",
      "Epoch: 47, Batch number: 4, Loss: 887.7412719726562\n",
      "Epoch: 48, Batch number: 28, Loss: 842.8909912109375\n",
      "Epoch: 49, Batch number: 52, Loss: 787.4236450195312\n",
      "Epoch: 51, Batch number: 0, Loss: 799.5374145507812\n",
      "Epoch: 52, Batch number: 24, Loss: 697.9566650390625\n",
      "Epoch: 53, Batch number: 48, Loss: 781.81494140625\n",
      "Epoch: 54, Batch number: 72, Loss: 758.9097290039062\n",
      "Epoch: 56, Batch number: 20, Loss: 775.5950317382812\n",
      "Epoch: 57, Batch number: 44, Loss: 757.3455200195312\n",
      "Epoch: 58, Batch number: 68, Loss: 763.8038330078125\n",
      "Epoch: 60, Batch number: 16, Loss: 663.83056640625\n",
      "Epoch: 61, Batch number: 40, Loss: 692.7781982421875\n",
      "Epoch: 62, Batch number: 64, Loss: 643.7180786132812\n",
      "Epoch: 64, Batch number: 12, Loss: 665.6964721679688\n",
      "Epoch: 65, Batch number: 36, Loss: 662.8624267578125\n",
      "Epoch: 66, Batch number: 60, Loss: 691.9703979492188\n",
      "Epoch: 68, Batch number: 8, Loss: 670.50927734375\n",
      "Epoch: 69, Batch number: 32, Loss: 640.0346069335938\n",
      "Epoch: 70, Batch number: 56, Loss: 579.6644287109375\n",
      "Epoch: 72, Batch number: 4, Loss: 554.8192138671875\n",
      "Epoch: 73, Batch number: 28, Loss: 530.0633544921875\n",
      "Epoch: 74, Batch number: 52, Loss: 569.3234252929688\n",
      "Epoch: 76, Batch number: 0, Loss: 580.493896484375\n",
      "Epoch: 77, Batch number: 24, Loss: 612.6026000976562\n",
      "Epoch: 78, Batch number: 48, Loss: 571.7120361328125\n",
      "Epoch: 79, Batch number: 72, Loss: 548.9190063476562\n",
      "Epoch: 81, Batch number: 20, Loss: 614.5352783203125\n",
      "Epoch: 82, Batch number: 44, Loss: 575.2377319335938\n",
      "Epoch: 83, Batch number: 68, Loss: 541.58447265625\n",
      "Epoch: 85, Batch number: 16, Loss: 505.9454650878906\n",
      "Epoch: 86, Batch number: 40, Loss: 526.8116455078125\n",
      "Epoch: 87, Batch number: 64, Loss: 580.2453002929688\n",
      "Epoch: 89, Batch number: 12, Loss: 481.2895202636719\n",
      "Epoch: 90, Batch number: 36, Loss: 499.9101867675781\n",
      "Epoch: 91, Batch number: 60, Loss: 581.1268310546875\n",
      "Epoch: 93, Batch number: 8, Loss: 591.21240234375\n",
      "Epoch: 94, Batch number: 32, Loss: 518.9957885742188\n",
      "Epoch: 95, Batch number: 56, Loss: 545.7952270507812\n",
      "Epoch: 97, Batch number: 4, Loss: 521.4036865234375\n",
      "Epoch: 98, Batch number: 28, Loss: 493.4438171386719\n",
      "Epoch: 99, Batch number: 52, Loss: 455.51190185546875\n",
      "Epoch: 101, Batch number: 0, Loss: 522.7568359375\n",
      "Epoch: 102, Batch number: 24, Loss: 482.223876953125\n",
      "Epoch: 103, Batch number: 48, Loss: 450.5729064941406\n",
      "Epoch: 104, Batch number: 72, Loss: 557.247802734375\n",
      "Epoch: 106, Batch number: 20, Loss: 472.4896240234375\n",
      "Epoch: 107, Batch number: 44, Loss: 471.2460021972656\n",
      "Epoch: 108, Batch number: 68, Loss: 475.22296142578125\n",
      "Epoch: 110, Batch number: 16, Loss: 460.0723571777344\n",
      "Epoch: 111, Batch number: 40, Loss: 542.4688110351562\n",
      "Epoch: 112, Batch number: 64, Loss: 512.0819091796875\n",
      "Epoch: 114, Batch number: 12, Loss: 523.1539916992188\n",
      "Epoch: 115, Batch number: 36, Loss: 461.9277648925781\n",
      "Epoch: 116, Batch number: 60, Loss: 530.3012084960938\n",
      "Epoch: 118, Batch number: 8, Loss: 473.86767578125\n",
      "Epoch: 119, Batch number: 32, Loss: 445.18731689453125\n",
      "Epoch: 120, Batch number: 56, Loss: 389.0715026855469\n",
      "Epoch: 122, Batch number: 4, Loss: 419.48876953125\n",
      "Epoch: 123, Batch number: 28, Loss: 445.2301940917969\n",
      "Epoch: 124, Batch number: 52, Loss: 521.2918701171875\n",
      "Epoch: 126, Batch number: 0, Loss: 453.4671936035156\n",
      "Epoch: 127, Batch number: 24, Loss: 423.2142333984375\n",
      "Epoch: 128, Batch number: 48, Loss: 487.69873046875\n",
      "Epoch: 129, Batch number: 72, Loss: 470.0952453613281\n",
      "Epoch: 131, Batch number: 20, Loss: 445.0858459472656\n",
      "Epoch: 132, Batch number: 44, Loss: 509.426513671875\n",
      "Epoch: 133, Batch number: 68, Loss: 523.9732055664062\n",
      "Epoch: 135, Batch number: 16, Loss: 453.5390319824219\n",
      "Epoch: 136, Batch number: 40, Loss: 480.5323486328125\n",
      "Epoch: 137, Batch number: 64, Loss: 457.964111328125\n",
      "Epoch: 139, Batch number: 12, Loss: 394.0419921875\n",
      "Epoch: 140, Batch number: 36, Loss: 449.231689453125\n",
      "Epoch: 141, Batch number: 60, Loss: 396.7838134765625\n",
      "Epoch: 143, Batch number: 8, Loss: 397.38134765625\n",
      "Epoch: 144, Batch number: 32, Loss: 424.3572998046875\n",
      "Epoch: 145, Batch number: 56, Loss: 473.21173095703125\n",
      "Epoch: 147, Batch number: 4, Loss: 436.5347900390625\n",
      "Epoch: 148, Batch number: 28, Loss: 499.1410217285156\n",
      "Epoch: 149, Batch number: 52, Loss: 421.05523681640625\n",
      "Epoch: 151, Batch number: 0, Loss: 429.1761779785156\n",
      "Epoch: 152, Batch number: 24, Loss: 461.19964599609375\n",
      "Epoch: 153, Batch number: 48, Loss: 449.5340270996094\n",
      "Epoch: 154, Batch number: 72, Loss: 510.81072998046875\n",
      "Epoch: 156, Batch number: 20, Loss: 441.8849792480469\n",
      "Epoch: 157, Batch number: 44, Loss: 468.93414306640625\n",
      "Epoch: 158, Batch number: 68, Loss: 450.8288269042969\n",
      "Epoch: 160, Batch number: 16, Loss: 412.5220642089844\n",
      "Epoch: 161, Batch number: 40, Loss: 514.625244140625\n",
      "Epoch: 162, Batch number: 64, Loss: 403.38946533203125\n",
      "Epoch: 164, Batch number: 12, Loss: 402.83367919921875\n",
      "Epoch: 165, Batch number: 36, Loss: 459.78814697265625\n",
      "Epoch: 166, Batch number: 60, Loss: 460.04632568359375\n",
      "Epoch: 168, Batch number: 8, Loss: 383.9217529296875\n",
      "Epoch: 169, Batch number: 32, Loss: 440.0308532714844\n",
      "Epoch: 170, Batch number: 56, Loss: 467.34136962890625\n",
      "Epoch: 172, Batch number: 4, Loss: 351.9881591796875\n",
      "Epoch: 173, Batch number: 28, Loss: 418.4671630859375\n",
      "Epoch: 174, Batch number: 52, Loss: 446.24334716796875\n",
      "Epoch: 176, Batch number: 0, Loss: 447.6772155761719\n",
      "Epoch: 177, Batch number: 24, Loss: 389.9131774902344\n",
      "Epoch: 178, Batch number: 48, Loss: 464.2528381347656\n",
      "Epoch: 179, Batch number: 72, Loss: 407.33734130859375\n",
      "Epoch: 181, Batch number: 20, Loss: 416.1451110839844\n",
      "Epoch: 182, Batch number: 44, Loss: 413.2164001464844\n",
      "Epoch: 183, Batch number: 68, Loss: 472.0713195800781\n",
      "Epoch: 185, Batch number: 16, Loss: 363.8839111328125\n",
      "Epoch: 186, Batch number: 40, Loss: 495.7295227050781\n",
      "Epoch: 187, Batch number: 64, Loss: 394.8109436035156\n",
      "Epoch: 189, Batch number: 12, Loss: 430.9112548828125\n",
      "Epoch: 190, Batch number: 36, Loss: 380.53912353515625\n",
      "Epoch: 191, Batch number: 60, Loss: 418.9537658691406\n",
      "Epoch: 193, Batch number: 8, Loss: 361.15753173828125\n",
      "Epoch: 194, Batch number: 32, Loss: 363.400634765625\n",
      "Epoch: 195, Batch number: 56, Loss: 405.8489990234375\n",
      "Epoch: 197, Batch number: 4, Loss: 419.11505126953125\n",
      "Epoch: 198, Batch number: 28, Loss: 425.1739196777344\n",
      "Epoch: 199, Batch number: 52, Loss: 403.29791259765625\n",
      "Epoch: 201, Batch number: 0, Loss: 435.2212829589844\n",
      "Epoch: 202, Batch number: 24, Loss: 446.01220703125\n",
      "Epoch: 203, Batch number: 48, Loss: 397.9041748046875\n",
      "Epoch: 204, Batch number: 72, Loss: 416.5887145996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 429.0628356933594\n",
      "Epoch: 207, Batch number: 44, Loss: 390.1788024902344\n",
      "Epoch: 208, Batch number: 68, Loss: 404.1308898925781\n",
      "Epoch: 210, Batch number: 16, Loss: 428.5010681152344\n",
      "Epoch: 211, Batch number: 40, Loss: 451.6729736328125\n",
      "Epoch: 212, Batch number: 64, Loss: 508.10675048828125\n",
      "Epoch: 214, Batch number: 12, Loss: 470.7125549316406\n",
      "Epoch: 215, Batch number: 36, Loss: 450.4432678222656\n",
      "Epoch: 216, Batch number: 60, Loss: 437.4830627441406\n",
      "Epoch: 218, Batch number: 8, Loss: 385.2030334472656\n",
      "Epoch: 219, Batch number: 32, Loss: 460.33917236328125\n",
      "Epoch: 220, Batch number: 56, Loss: 393.32061767578125\n",
      "Epoch: 222, Batch number: 4, Loss: 424.6883544921875\n",
      "Epoch: 223, Batch number: 28, Loss: 370.01092529296875\n",
      "Epoch: 224, Batch number: 52, Loss: 472.5671081542969\n",
      "Epoch: 226, Batch number: 0, Loss: 403.3660888671875\n",
      "Epoch: 227, Batch number: 24, Loss: 449.4847412109375\n",
      "Epoch: 228, Batch number: 48, Loss: 427.7404479980469\n",
      "Epoch: 229, Batch number: 72, Loss: 428.751708984375\n",
      "Epoch: 231, Batch number: 20, Loss: 506.3017883300781\n",
      "Epoch: 232, Batch number: 44, Loss: 434.74371337890625\n",
      "Epoch: 233, Batch number: 68, Loss: 454.3616638183594\n",
      "Epoch: 235, Batch number: 16, Loss: 398.2472839355469\n",
      "Epoch: 236, Batch number: 40, Loss: 427.4266662597656\n",
      "Epoch: 237, Batch number: 64, Loss: 488.9759826660156\n",
      "Epoch: 239, Batch number: 12, Loss: 390.1581726074219\n",
      "Epoch: 240, Batch number: 36, Loss: 370.75933837890625\n",
      "Epoch: 241, Batch number: 60, Loss: 441.6197814941406\n",
      "Epoch: 243, Batch number: 8, Loss: 396.12176513671875\n",
      "Epoch: 244, Batch number: 32, Loss: 409.6962585449219\n",
      "Epoch: 245, Batch number: 56, Loss: 414.9317626953125\n",
      "Epoch: 247, Batch number: 4, Loss: 386.27069091796875\n",
      "Epoch: 248, Batch number: 28, Loss: 404.3704833984375\n",
      "Epoch: 249, Batch number: 52, Loss: 473.1789855957031\n",
      "Epoch: 251, Batch number: 0, Loss: 388.34222412109375\n",
      "Epoch: 252, Batch number: 24, Loss: 402.2607421875\n",
      "Epoch: 253, Batch number: 48, Loss: 477.8497619628906\n",
      "Epoch: 254, Batch number: 72, Loss: 397.4540100097656\n",
      "Epoch: 256, Batch number: 20, Loss: 363.015380859375\n",
      "Epoch: 257, Batch number: 44, Loss: 402.2417297363281\n",
      "Epoch: 258, Batch number: 68, Loss: 472.04248046875\n",
      "Epoch: 260, Batch number: 16, Loss: 384.0791931152344\n",
      "Epoch: 261, Batch number: 40, Loss: 425.7099914550781\n",
      "Epoch: 262, Batch number: 64, Loss: 366.4345703125\n",
      "Epoch: 264, Batch number: 12, Loss: 397.21978759765625\n",
      "Epoch: 265, Batch number: 36, Loss: 393.59503173828125\n",
      "Epoch: 266, Batch number: 60, Loss: 409.0605163574219\n",
      "Epoch: 268, Batch number: 8, Loss: 376.083251953125\n",
      "Epoch: 269, Batch number: 32, Loss: 410.25628662109375\n",
      "Epoch: 270, Batch number: 56, Loss: 397.18890380859375\n",
      "Epoch: 272, Batch number: 4, Loss: 393.02923583984375\n",
      "Epoch: 273, Batch number: 28, Loss: 399.7693786621094\n",
      "Epoch: 274, Batch number: 52, Loss: 467.08819580078125\n",
      "Epoch: 276, Batch number: 0, Loss: 377.2524719238281\n",
      "Epoch: 277, Batch number: 24, Loss: 415.8780517578125\n",
      "Epoch: 278, Batch number: 48, Loss: 418.38043212890625\n",
      "Epoch: 279, Batch number: 72, Loss: 465.2032470703125\n",
      "Epoch: 281, Batch number: 20, Loss: 391.7243957519531\n",
      "Epoch: 282, Batch number: 44, Loss: 445.4241027832031\n",
      "Epoch: 283, Batch number: 68, Loss: 368.772705078125\n",
      "Epoch: 285, Batch number: 16, Loss: 419.211181640625\n",
      "Epoch: 286, Batch number: 40, Loss: 451.1027526855469\n",
      "Epoch: 287, Batch number: 64, Loss: 451.0369873046875\n",
      "Epoch: 289, Batch number: 12, Loss: 398.7836608886719\n",
      "Epoch: 290, Batch number: 36, Loss: 437.44268798828125\n",
      "Epoch: 291, Batch number: 60, Loss: 369.8619384765625\n",
      "Epoch: 293, Batch number: 8, Loss: 454.5793762207031\n",
      "Epoch: 294, Batch number: 32, Loss: 451.2417297363281\n",
      "Epoch: 295, Batch number: 56, Loss: 503.6770324707031\n",
      "Epoch: 297, Batch number: 4, Loss: 431.7983093261719\n",
      "Epoch: 298, Batch number: 28, Loss: 455.46502685546875\n",
      "Epoch: 299, Batch number: 52, Loss: 415.96697998046875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4426.3515625\n",
      "Epoch: 2, Batch number: 24, Loss: 4048.20263671875\n",
      "Epoch: 3, Batch number: 48, Loss: 3658.531494140625\n",
      "Epoch: 4, Batch number: 72, Loss: 3263.0107421875\n",
      "Epoch: 6, Batch number: 20, Loss: 2837.245849609375\n",
      "Epoch: 7, Batch number: 44, Loss: 2519.317626953125\n",
      "Epoch: 8, Batch number: 68, Loss: 2297.1689453125\n",
      "Epoch: 10, Batch number: 16, Loss: 2176.2822265625\n",
      "Epoch: 11, Batch number: 40, Loss: 2096.85498046875\n",
      "Epoch: 12, Batch number: 64, Loss: 2061.728271484375\n",
      "Epoch: 14, Batch number: 12, Loss: 1744.8905029296875\n",
      "Epoch: 15, Batch number: 36, Loss: 1688.73876953125\n",
      "Epoch: 16, Batch number: 60, Loss: 1554.9105224609375\n",
      "Epoch: 18, Batch number: 8, Loss: 1487.7828369140625\n",
      "Epoch: 19, Batch number: 32, Loss: 1414.7802734375\n",
      "Epoch: 20, Batch number: 56, Loss: 1339.0311279296875\n",
      "Epoch: 22, Batch number: 4, Loss: 1285.687255859375\n",
      "Epoch: 23, Batch number: 28, Loss: 1222.543212890625\n",
      "Epoch: 24, Batch number: 52, Loss: 1184.7633056640625\n",
      "Epoch: 26, Batch number: 0, Loss: 1127.98388671875\n",
      "Epoch: 27, Batch number: 24, Loss: 1078.581787109375\n",
      "Epoch: 28, Batch number: 48, Loss: 1022.8067626953125\n",
      "Epoch: 29, Batch number: 72, Loss: 1107.964599609375\n",
      "Epoch: 31, Batch number: 20, Loss: 962.3391723632812\n",
      "Epoch: 32, Batch number: 44, Loss: 1013.7932739257812\n",
      "Epoch: 33, Batch number: 68, Loss: 947.3576049804688\n",
      "Epoch: 35, Batch number: 16, Loss: 844.510986328125\n",
      "Epoch: 36, Batch number: 40, Loss: 889.469970703125\n",
      "Epoch: 37, Batch number: 64, Loss: 882.68798828125\n",
      "Epoch: 39, Batch number: 12, Loss: 823.7863159179688\n",
      "Epoch: 40, Batch number: 36, Loss: 751.6944580078125\n",
      "Epoch: 41, Batch number: 60, Loss: 808.647705078125\n",
      "Epoch: 43, Batch number: 8, Loss: 778.910400390625\n",
      "Epoch: 44, Batch number: 32, Loss: 720.6265869140625\n",
      "Epoch: 45, Batch number: 56, Loss: 772.0657958984375\n",
      "Epoch: 47, Batch number: 4, Loss: 683.2094116210938\n",
      "Epoch: 48, Batch number: 28, Loss: 653.2925415039062\n",
      "Epoch: 49, Batch number: 52, Loss: 698.5748901367188\n",
      "Epoch: 51, Batch number: 0, Loss: 697.494873046875\n",
      "Epoch: 52, Batch number: 24, Loss: 625.1751708984375\n",
      "Epoch: 53, Batch number: 48, Loss: 612.4583740234375\n",
      "Epoch: 54, Batch number: 72, Loss: 623.1861572265625\n",
      "Epoch: 56, Batch number: 20, Loss: 596.5354614257812\n",
      "Epoch: 57, Batch number: 44, Loss: 647.8729248046875\n",
      "Epoch: 58, Batch number: 68, Loss: 670.0512084960938\n",
      "Epoch: 60, Batch number: 16, Loss: 565.3971557617188\n",
      "Epoch: 61, Batch number: 40, Loss: 554.9326171875\n",
      "Epoch: 62, Batch number: 64, Loss: 573.6998291015625\n",
      "Epoch: 64, Batch number: 12, Loss: 526.23193359375\n",
      "Epoch: 65, Batch number: 36, Loss: 546.847412109375\n",
      "Epoch: 66, Batch number: 60, Loss: 590.6856079101562\n",
      "Epoch: 68, Batch number: 8, Loss: 559.0742797851562\n",
      "Epoch: 69, Batch number: 32, Loss: 553.7295532226562\n",
      "Epoch: 70, Batch number: 56, Loss: 540.7159423828125\n",
      "Epoch: 72, Batch number: 4, Loss: 520.4866943359375\n",
      "Epoch: 73, Batch number: 28, Loss: 477.42572021484375\n",
      "Epoch: 74, Batch number: 52, Loss: 515.1697387695312\n",
      "Epoch: 76, Batch number: 0, Loss: 479.40252685546875\n",
      "Epoch: 77, Batch number: 24, Loss: 540.7877197265625\n",
      "Epoch: 78, Batch number: 48, Loss: 523.4625244140625\n",
      "Epoch: 79, Batch number: 72, Loss: 561.28857421875\n",
      "Epoch: 81, Batch number: 20, Loss: 527.6741943359375\n",
      "Epoch: 82, Batch number: 44, Loss: 490.0050964355469\n",
      "Epoch: 83, Batch number: 68, Loss: 561.1011962890625\n",
      "Epoch: 85, Batch number: 16, Loss: 481.8247985839844\n",
      "Epoch: 86, Batch number: 40, Loss: 479.3991394042969\n",
      "Epoch: 87, Batch number: 64, Loss: 497.7690734863281\n",
      "Epoch: 89, Batch number: 12, Loss: 482.34649658203125\n",
      "Epoch: 90, Batch number: 36, Loss: 471.1494140625\n",
      "Epoch: 91, Batch number: 60, Loss: 545.6006469726562\n",
      "Epoch: 93, Batch number: 8, Loss: 502.9146423339844\n",
      "Epoch: 94, Batch number: 32, Loss: 430.982421875\n",
      "Epoch: 95, Batch number: 56, Loss: 473.7198791503906\n",
      "Epoch: 97, Batch number: 4, Loss: 486.995849609375\n",
      "Epoch: 98, Batch number: 28, Loss: 474.3724365234375\n",
      "Epoch: 99, Batch number: 52, Loss: 498.1225280761719\n",
      "Epoch: 101, Batch number: 0, Loss: 462.3365783691406\n",
      "Epoch: 102, Batch number: 24, Loss: 467.3963623046875\n",
      "Epoch: 103, Batch number: 48, Loss: 466.2898864746094\n",
      "Epoch: 104, Batch number: 72, Loss: 477.84283447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106, Batch number: 20, Loss: 470.1535949707031\n",
      "Epoch: 107, Batch number: 44, Loss: 370.1351318359375\n",
      "Epoch: 108, Batch number: 68, Loss: 504.7479248046875\n",
      "Epoch: 110, Batch number: 16, Loss: 431.2978515625\n",
      "Epoch: 111, Batch number: 40, Loss: 465.4183349609375\n",
      "Epoch: 112, Batch number: 64, Loss: 433.4081726074219\n",
      "Epoch: 114, Batch number: 12, Loss: 464.93035888671875\n",
      "Epoch: 115, Batch number: 36, Loss: 510.1170349121094\n",
      "Epoch: 116, Batch number: 60, Loss: 470.579345703125\n",
      "Epoch: 118, Batch number: 8, Loss: 458.80340576171875\n",
      "Epoch: 119, Batch number: 32, Loss: 432.8737487792969\n",
      "Epoch: 120, Batch number: 56, Loss: 464.6601257324219\n",
      "Epoch: 122, Batch number: 4, Loss: 408.89874267578125\n",
      "Epoch: 123, Batch number: 28, Loss: 389.9397888183594\n",
      "Epoch: 124, Batch number: 52, Loss: 439.4310302734375\n",
      "Epoch: 126, Batch number: 0, Loss: 381.1477966308594\n",
      "Epoch: 127, Batch number: 24, Loss: 388.8951416015625\n",
      "Epoch: 128, Batch number: 48, Loss: 391.4857482910156\n",
      "Epoch: 129, Batch number: 72, Loss: 509.9774169921875\n",
      "Epoch: 131, Batch number: 20, Loss: 479.5697937011719\n",
      "Epoch: 132, Batch number: 44, Loss: 445.0771484375\n",
      "Epoch: 133, Batch number: 68, Loss: 480.6729431152344\n",
      "Epoch: 135, Batch number: 16, Loss: 458.9581604003906\n",
      "Epoch: 136, Batch number: 40, Loss: 432.7463073730469\n",
      "Epoch: 137, Batch number: 64, Loss: 466.6146240234375\n",
      "Epoch: 139, Batch number: 12, Loss: 426.55999755859375\n",
      "Epoch: 140, Batch number: 36, Loss: 457.3783874511719\n",
      "Epoch: 141, Batch number: 60, Loss: 486.3376770019531\n",
      "Epoch: 143, Batch number: 8, Loss: 465.92584228515625\n",
      "Epoch: 144, Batch number: 32, Loss: 462.976806640625\n",
      "Epoch: 145, Batch number: 56, Loss: 498.5317687988281\n",
      "Epoch: 147, Batch number: 4, Loss: 411.8358154296875\n",
      "Epoch: 148, Batch number: 28, Loss: 369.10986328125\n",
      "Epoch: 149, Batch number: 52, Loss: 415.6684265136719\n",
      "Epoch: 151, Batch number: 0, Loss: 374.1990661621094\n",
      "Epoch: 152, Batch number: 24, Loss: 458.1266784667969\n",
      "Epoch: 153, Batch number: 48, Loss: 487.6152648925781\n",
      "Epoch: 154, Batch number: 72, Loss: 474.35125732421875\n",
      "Epoch: 156, Batch number: 20, Loss: 427.35345458984375\n",
      "Epoch: 157, Batch number: 44, Loss: 449.5780334472656\n",
      "Epoch: 158, Batch number: 68, Loss: 485.43646240234375\n",
      "Epoch: 160, Batch number: 16, Loss: 435.2398376464844\n",
      "Epoch: 161, Batch number: 40, Loss: 424.6601867675781\n",
      "Epoch: 162, Batch number: 64, Loss: 460.3794860839844\n",
      "Epoch: 164, Batch number: 12, Loss: 426.38818359375\n",
      "Epoch: 165, Batch number: 36, Loss: 510.1969299316406\n",
      "Epoch: 166, Batch number: 60, Loss: 441.90887451171875\n",
      "Epoch: 168, Batch number: 8, Loss: 459.93243408203125\n",
      "Epoch: 169, Batch number: 32, Loss: 417.30169677734375\n",
      "Epoch: 170, Batch number: 56, Loss: 442.8028869628906\n",
      "Epoch: 172, Batch number: 4, Loss: 425.9767150878906\n",
      "Epoch: 173, Batch number: 28, Loss: 358.562744140625\n",
      "Epoch: 174, Batch number: 52, Loss: 399.85455322265625\n",
      "Epoch: 176, Batch number: 0, Loss: 399.76654052734375\n",
      "Epoch: 177, Batch number: 24, Loss: 448.68035888671875\n",
      "Epoch: 178, Batch number: 48, Loss: 463.28131103515625\n",
      "Epoch: 179, Batch number: 72, Loss: 494.23516845703125\n",
      "Epoch: 181, Batch number: 20, Loss: 441.3088073730469\n",
      "Epoch: 182, Batch number: 44, Loss: 426.9332580566406\n",
      "Epoch: 183, Batch number: 68, Loss: 460.00616455078125\n",
      "Epoch: 185, Batch number: 16, Loss: 414.413818359375\n",
      "Epoch: 186, Batch number: 40, Loss: 432.3796691894531\n",
      "Epoch: 187, Batch number: 64, Loss: 436.32257080078125\n",
      "Epoch: 189, Batch number: 12, Loss: 442.6822509765625\n",
      "Epoch: 190, Batch number: 36, Loss: 417.7981872558594\n",
      "Epoch: 191, Batch number: 60, Loss: 429.44720458984375\n",
      "Epoch: 193, Batch number: 8, Loss: 436.1527404785156\n",
      "Epoch: 194, Batch number: 32, Loss: 373.8743591308594\n",
      "Epoch: 195, Batch number: 56, Loss: 425.0951843261719\n",
      "Epoch: 197, Batch number: 4, Loss: 397.01641845703125\n",
      "Epoch: 198, Batch number: 28, Loss: 439.0308532714844\n",
      "Epoch: 199, Batch number: 52, Loss: 423.4684753417969\n",
      "Epoch: 201, Batch number: 0, Loss: 459.2557678222656\n",
      "Epoch: 202, Batch number: 24, Loss: 392.2860107421875\n",
      "Epoch: 203, Batch number: 48, Loss: 500.9648742675781\n",
      "Epoch: 204, Batch number: 72, Loss: 457.3645935058594\n",
      "Epoch: 206, Batch number: 20, Loss: 394.07086181640625\n",
      "Epoch: 207, Batch number: 44, Loss: 414.3852844238281\n",
      "Epoch: 208, Batch number: 68, Loss: 465.6056823730469\n",
      "Epoch: 210, Batch number: 16, Loss: 422.4974670410156\n",
      "Epoch: 211, Batch number: 40, Loss: 481.5460510253906\n",
      "Epoch: 212, Batch number: 64, Loss: 490.0402526855469\n",
      "Epoch: 214, Batch number: 12, Loss: 406.07305908203125\n",
      "Epoch: 215, Batch number: 36, Loss: 434.07257080078125\n",
      "Epoch: 216, Batch number: 60, Loss: 448.4392395019531\n",
      "Epoch: 218, Batch number: 8, Loss: 412.54766845703125\n",
      "Epoch: 219, Batch number: 32, Loss: 379.8150329589844\n",
      "Epoch: 220, Batch number: 56, Loss: 464.254638671875\n",
      "Epoch: 222, Batch number: 4, Loss: 420.5755920410156\n",
      "Epoch: 223, Batch number: 28, Loss: 404.3446044921875\n",
      "Epoch: 224, Batch number: 52, Loss: 454.11474609375\n",
      "Epoch: 226, Batch number: 0, Loss: 412.736083984375\n",
      "Epoch: 227, Batch number: 24, Loss: 423.4361572265625\n",
      "Epoch: 228, Batch number: 48, Loss: 421.3443603515625\n",
      "Epoch: 229, Batch number: 72, Loss: 468.00347900390625\n",
      "Epoch: 231, Batch number: 20, Loss: 425.2254943847656\n",
      "Epoch: 232, Batch number: 44, Loss: 399.9940185546875\n",
      "Epoch: 233, Batch number: 68, Loss: 437.0511169433594\n",
      "Epoch: 235, Batch number: 16, Loss: 394.8123474121094\n",
      "Epoch: 236, Batch number: 40, Loss: 400.6240234375\n",
      "Epoch: 237, Batch number: 64, Loss: 401.68524169921875\n",
      "Epoch: 239, Batch number: 12, Loss: 422.0030517578125\n",
      "Epoch: 240, Batch number: 36, Loss: 384.7577209472656\n",
      "Epoch: 241, Batch number: 60, Loss: 416.6058654785156\n",
      "Epoch: 243, Batch number: 8, Loss: 385.8646545410156\n",
      "Epoch: 244, Batch number: 32, Loss: 378.43377685546875\n",
      "Epoch: 245, Batch number: 56, Loss: 461.97210693359375\n",
      "Epoch: 247, Batch number: 4, Loss: 404.9884033203125\n",
      "Epoch: 248, Batch number: 28, Loss: 448.570068359375\n",
      "Epoch: 249, Batch number: 52, Loss: 456.3987121582031\n",
      "Epoch: 251, Batch number: 0, Loss: 470.0815124511719\n",
      "Epoch: 252, Batch number: 24, Loss: 448.14874267578125\n",
      "Epoch: 253, Batch number: 48, Loss: 449.5406799316406\n",
      "Epoch: 254, Batch number: 72, Loss: 429.2001037597656\n",
      "Epoch: 256, Batch number: 20, Loss: 386.3005065917969\n",
      "Epoch: 257, Batch number: 44, Loss: 403.5488586425781\n",
      "Epoch: 258, Batch number: 68, Loss: 451.4681701660156\n",
      "Epoch: 260, Batch number: 16, Loss: 433.21533203125\n",
      "Epoch: 261, Batch number: 40, Loss: 418.5047912597656\n",
      "Epoch: 262, Batch number: 64, Loss: 453.1263122558594\n",
      "Epoch: 264, Batch number: 12, Loss: 470.32952880859375\n",
      "Epoch: 265, Batch number: 36, Loss: 417.882568359375\n",
      "Epoch: 266, Batch number: 60, Loss: 418.6441345214844\n",
      "Epoch: 268, Batch number: 8, Loss: 407.3484802246094\n",
      "Epoch: 269, Batch number: 32, Loss: 406.4399108886719\n",
      "Epoch: 270, Batch number: 56, Loss: 370.69134521484375\n",
      "Epoch: 272, Batch number: 4, Loss: 363.5746765136719\n",
      "Epoch: 273, Batch number: 28, Loss: 411.57379150390625\n",
      "Epoch: 274, Batch number: 52, Loss: 380.3753356933594\n",
      "Epoch: 276, Batch number: 0, Loss: 369.60223388671875\n",
      "Epoch: 277, Batch number: 24, Loss: 405.0591735839844\n",
      "Epoch: 278, Batch number: 48, Loss: 419.1293640136719\n",
      "Epoch: 279, Batch number: 72, Loss: 433.9566345214844\n",
      "Epoch: 281, Batch number: 20, Loss: 403.29339599609375\n",
      "Epoch: 282, Batch number: 44, Loss: 424.9101257324219\n",
      "Epoch: 283, Batch number: 68, Loss: 429.64947509765625\n",
      "Epoch: 285, Batch number: 16, Loss: 382.3070068359375\n",
      "Epoch: 286, Batch number: 40, Loss: 413.9792175292969\n",
      "Epoch: 287, Batch number: 64, Loss: 441.8433532714844\n",
      "Epoch: 289, Batch number: 12, Loss: 472.841552734375\n",
      "Epoch: 290, Batch number: 36, Loss: 379.2558898925781\n",
      "Epoch: 291, Batch number: 60, Loss: 378.107177734375\n",
      "Epoch: 293, Batch number: 8, Loss: 452.4830017089844\n",
      "Epoch: 294, Batch number: 32, Loss: 463.8459777832031\n",
      "Epoch: 295, Batch number: 56, Loss: 413.1964416503906\n",
      "Epoch: 297, Batch number: 4, Loss: 417.456787109375\n",
      "Epoch: 298, Batch number: 28, Loss: 370.5302734375\n",
      "Epoch: 299, Batch number: 52, Loss: 369.1748962402344\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4431.1318359375\n",
      "Epoch: 2, Batch number: 24, Loss: 3890.757568359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch number: 48, Loss: 3466.23046875\n",
      "Epoch: 4, Batch number: 72, Loss: 3002.90625\n",
      "Epoch: 6, Batch number: 20, Loss: 2551.0751953125\n",
      "Epoch: 7, Batch number: 44, Loss: 2153.306884765625\n",
      "Epoch: 8, Batch number: 68, Loss: 2156.85302734375\n",
      "Epoch: 10, Batch number: 16, Loss: 1812.2293701171875\n",
      "Epoch: 11, Batch number: 40, Loss: 1713.4892578125\n",
      "Epoch: 12, Batch number: 64, Loss: 1624.6807861328125\n",
      "Epoch: 14, Batch number: 12, Loss: 1403.239501953125\n",
      "Epoch: 15, Batch number: 36, Loss: 1403.138916015625\n",
      "Epoch: 16, Batch number: 60, Loss: 1228.462646484375\n",
      "Epoch: 18, Batch number: 8, Loss: 1155.826904296875\n",
      "Epoch: 19, Batch number: 32, Loss: 1133.14208984375\n",
      "Epoch: 20, Batch number: 56, Loss: 1076.52734375\n",
      "Epoch: 22, Batch number: 4, Loss: 1027.7423095703125\n",
      "Epoch: 23, Batch number: 28, Loss: 964.7817993164062\n",
      "Epoch: 24, Batch number: 52, Loss: 993.2339477539062\n",
      "Epoch: 26, Batch number: 0, Loss: 814.2146606445312\n",
      "Epoch: 27, Batch number: 24, Loss: 831.291748046875\n",
      "Epoch: 28, Batch number: 48, Loss: 897.3695678710938\n",
      "Epoch: 29, Batch number: 72, Loss: 818.8421020507812\n",
      "Epoch: 31, Batch number: 20, Loss: 792.0162963867188\n",
      "Epoch: 32, Batch number: 44, Loss: 817.8325805664062\n",
      "Epoch: 33, Batch number: 68, Loss: 737.4873657226562\n",
      "Epoch: 35, Batch number: 16, Loss: 650.6768798828125\n",
      "Epoch: 36, Batch number: 40, Loss: 732.3184814453125\n",
      "Epoch: 37, Batch number: 64, Loss: 719.385986328125\n",
      "Epoch: 39, Batch number: 12, Loss: 661.3311767578125\n",
      "Epoch: 40, Batch number: 36, Loss: 579.7051391601562\n",
      "Epoch: 41, Batch number: 60, Loss: 700.6921997070312\n",
      "Epoch: 43, Batch number: 8, Loss: 568.156494140625\n",
      "Epoch: 44, Batch number: 32, Loss: 616.6658935546875\n",
      "Epoch: 45, Batch number: 56, Loss: 629.9044189453125\n",
      "Epoch: 47, Batch number: 4, Loss: 503.0680236816406\n",
      "Epoch: 48, Batch number: 28, Loss: 607.3220825195312\n",
      "Epoch: 49, Batch number: 52, Loss: 592.329833984375\n",
      "Epoch: 51, Batch number: 0, Loss: 527.0450439453125\n",
      "Epoch: 52, Batch number: 24, Loss: 584.09130859375\n",
      "Epoch: 53, Batch number: 48, Loss: 566.8102416992188\n",
      "Epoch: 54, Batch number: 72, Loss: 589.0158081054688\n",
      "Epoch: 56, Batch number: 20, Loss: 536.0934448242188\n",
      "Epoch: 57, Batch number: 44, Loss: 502.9136657714844\n",
      "Epoch: 58, Batch number: 68, Loss: 544.4735107421875\n",
      "Epoch: 60, Batch number: 16, Loss: 518.7664794921875\n",
      "Epoch: 61, Batch number: 40, Loss: 555.42529296875\n",
      "Epoch: 62, Batch number: 64, Loss: 548.195068359375\n",
      "Epoch: 64, Batch number: 12, Loss: 543.7698974609375\n",
      "Epoch: 65, Batch number: 36, Loss: 412.8475646972656\n",
      "Epoch: 66, Batch number: 60, Loss: 499.4776611328125\n",
      "Epoch: 68, Batch number: 8, Loss: 457.7193908691406\n",
      "Epoch: 69, Batch number: 32, Loss: 404.4337158203125\n",
      "Epoch: 70, Batch number: 56, Loss: 467.92193603515625\n",
      "Epoch: 72, Batch number: 4, Loss: 449.76556396484375\n",
      "Epoch: 73, Batch number: 28, Loss: 459.4378662109375\n",
      "Epoch: 74, Batch number: 52, Loss: 532.6060180664062\n",
      "Epoch: 76, Batch number: 0, Loss: 409.6355285644531\n",
      "Epoch: 77, Batch number: 24, Loss: 431.83612060546875\n",
      "Epoch: 78, Batch number: 48, Loss: 472.9577331542969\n",
      "Epoch: 79, Batch number: 72, Loss: 507.89227294921875\n",
      "Epoch: 81, Batch number: 20, Loss: 473.88812255859375\n",
      "Epoch: 82, Batch number: 44, Loss: 471.9056701660156\n",
      "Epoch: 83, Batch number: 68, Loss: 486.8635559082031\n",
      "Epoch: 85, Batch number: 16, Loss: 537.509033203125\n",
      "Epoch: 86, Batch number: 40, Loss: 445.47467041015625\n",
      "Epoch: 87, Batch number: 64, Loss: 410.7149963378906\n",
      "Epoch: 89, Batch number: 12, Loss: 446.0741882324219\n",
      "Epoch: 90, Batch number: 36, Loss: 412.3866882324219\n",
      "Epoch: 91, Batch number: 60, Loss: 441.97943115234375\n",
      "Epoch: 93, Batch number: 8, Loss: 413.0039978027344\n",
      "Epoch: 94, Batch number: 32, Loss: 462.241455078125\n",
      "Epoch: 95, Batch number: 56, Loss: 469.86187744140625\n",
      "Epoch: 97, Batch number: 4, Loss: 433.26837158203125\n",
      "Epoch: 98, Batch number: 28, Loss: 395.7723693847656\n",
      "Epoch: 99, Batch number: 52, Loss: 476.8316955566406\n",
      "Epoch: 101, Batch number: 0, Loss: 433.5479736328125\n",
      "Epoch: 102, Batch number: 24, Loss: 385.4969177246094\n",
      "Epoch: 103, Batch number: 48, Loss: 435.056396484375\n",
      "Epoch: 104, Batch number: 72, Loss: 490.4928894042969\n",
      "Epoch: 106, Batch number: 20, Loss: 454.3005676269531\n",
      "Epoch: 107, Batch number: 44, Loss: 442.3999938964844\n",
      "Epoch: 108, Batch number: 68, Loss: 407.09075927734375\n",
      "Epoch: 110, Batch number: 16, Loss: 462.11248779296875\n",
      "Epoch: 111, Batch number: 40, Loss: 418.67303466796875\n",
      "Epoch: 112, Batch number: 64, Loss: 512.79736328125\n",
      "Epoch: 114, Batch number: 12, Loss: 387.6249694824219\n",
      "Epoch: 115, Batch number: 36, Loss: 455.2062072753906\n",
      "Epoch: 116, Batch number: 60, Loss: 452.71600341796875\n",
      "Epoch: 118, Batch number: 8, Loss: 385.6172180175781\n",
      "Epoch: 119, Batch number: 32, Loss: 450.4642639160156\n",
      "Epoch: 120, Batch number: 56, Loss: 483.2234191894531\n",
      "Epoch: 122, Batch number: 4, Loss: 420.59002685546875\n",
      "Epoch: 123, Batch number: 28, Loss: 445.6834716796875\n",
      "Epoch: 124, Batch number: 52, Loss: 441.79620361328125\n",
      "Epoch: 126, Batch number: 0, Loss: 367.1951599121094\n",
      "Epoch: 127, Batch number: 24, Loss: 393.25244140625\n",
      "Epoch: 128, Batch number: 48, Loss: 428.4000244140625\n",
      "Epoch: 129, Batch number: 72, Loss: 426.5193786621094\n",
      "Epoch: 131, Batch number: 20, Loss: 445.8251953125\n",
      "Epoch: 132, Batch number: 44, Loss: 448.6416015625\n",
      "Epoch: 133, Batch number: 68, Loss: 412.90325927734375\n",
      "Epoch: 135, Batch number: 16, Loss: 411.26922607421875\n",
      "Epoch: 136, Batch number: 40, Loss: 429.7068176269531\n",
      "Epoch: 137, Batch number: 64, Loss: 469.22271728515625\n",
      "Epoch: 139, Batch number: 12, Loss: 381.6582336425781\n",
      "Epoch: 140, Batch number: 36, Loss: 457.22052001953125\n",
      "Epoch: 141, Batch number: 60, Loss: 504.7606201171875\n",
      "Epoch: 143, Batch number: 8, Loss: 468.0749206542969\n",
      "Epoch: 144, Batch number: 32, Loss: 399.0938415527344\n",
      "Epoch: 145, Batch number: 56, Loss: 382.11236572265625\n",
      "Epoch: 147, Batch number: 4, Loss: 470.1883239746094\n",
      "Epoch: 148, Batch number: 28, Loss: 398.0863952636719\n",
      "Epoch: 149, Batch number: 52, Loss: 446.0920715332031\n",
      "Epoch: 151, Batch number: 0, Loss: 405.3414306640625\n",
      "Epoch: 152, Batch number: 24, Loss: 455.2107238769531\n",
      "Epoch: 153, Batch number: 48, Loss: 431.58636474609375\n",
      "Epoch: 154, Batch number: 72, Loss: 454.1247863769531\n",
      "Epoch: 156, Batch number: 20, Loss: 315.9237976074219\n",
      "Epoch: 157, Batch number: 44, Loss: 456.3166198730469\n",
      "Epoch: 158, Batch number: 68, Loss: 434.4761047363281\n",
      "Epoch: 160, Batch number: 16, Loss: 425.1133117675781\n",
      "Epoch: 161, Batch number: 40, Loss: 474.82061767578125\n",
      "Epoch: 162, Batch number: 64, Loss: 457.40057373046875\n",
      "Epoch: 164, Batch number: 12, Loss: 364.21905517578125\n",
      "Epoch: 165, Batch number: 36, Loss: 381.712890625\n",
      "Epoch: 166, Batch number: 60, Loss: 473.7408447265625\n",
      "Epoch: 168, Batch number: 8, Loss: 428.01263427734375\n",
      "Epoch: 169, Batch number: 32, Loss: 470.4815979003906\n",
      "Epoch: 170, Batch number: 56, Loss: 450.7435302734375\n",
      "Epoch: 172, Batch number: 4, Loss: 405.14044189453125\n",
      "Epoch: 173, Batch number: 28, Loss: 414.9002380371094\n",
      "Epoch: 174, Batch number: 52, Loss: 495.67730712890625\n",
      "Epoch: 176, Batch number: 0, Loss: 439.6597900390625\n",
      "Epoch: 177, Batch number: 24, Loss: 414.541259765625\n",
      "Epoch: 178, Batch number: 48, Loss: 451.6626281738281\n",
      "Epoch: 179, Batch number: 72, Loss: 475.9474182128906\n",
      "Epoch: 181, Batch number: 20, Loss: 375.7388000488281\n",
      "Epoch: 182, Batch number: 44, Loss: 389.32061767578125\n",
      "Epoch: 183, Batch number: 68, Loss: 445.281982421875\n",
      "Epoch: 185, Batch number: 16, Loss: 417.5721435546875\n",
      "Epoch: 186, Batch number: 40, Loss: 402.2300720214844\n",
      "Epoch: 187, Batch number: 64, Loss: 471.6900634765625\n",
      "Epoch: 189, Batch number: 12, Loss: 414.5546875\n",
      "Epoch: 190, Batch number: 36, Loss: 471.3892517089844\n",
      "Epoch: 191, Batch number: 60, Loss: 430.78997802734375\n",
      "Epoch: 193, Batch number: 8, Loss: 405.32806396484375\n",
      "Epoch: 194, Batch number: 32, Loss: 446.2604064941406\n",
      "Epoch: 195, Batch number: 56, Loss: 481.0436096191406\n",
      "Epoch: 197, Batch number: 4, Loss: 389.97723388671875\n",
      "Epoch: 198, Batch number: 28, Loss: 400.9490966796875\n",
      "Epoch: 199, Batch number: 52, Loss: 373.8187255859375\n",
      "Epoch: 201, Batch number: 0, Loss: 442.9504089355469\n",
      "Epoch: 202, Batch number: 24, Loss: 427.5466003417969\n",
      "Epoch: 203, Batch number: 48, Loss: 464.8670349121094\n",
      "Epoch: 204, Batch number: 72, Loss: 417.0086364746094\n",
      "Epoch: 206, Batch number: 20, Loss: 400.5895690917969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207, Batch number: 44, Loss: 412.5506591796875\n",
      "Epoch: 208, Batch number: 68, Loss: 449.01812744140625\n",
      "Epoch: 210, Batch number: 16, Loss: 386.98492431640625\n",
      "Epoch: 211, Batch number: 40, Loss: 314.8743591308594\n",
      "Epoch: 212, Batch number: 64, Loss: 448.2713928222656\n",
      "Epoch: 214, Batch number: 12, Loss: 415.9203796386719\n",
      "Epoch: 215, Batch number: 36, Loss: 378.72259521484375\n",
      "Epoch: 216, Batch number: 60, Loss: 451.90045166015625\n",
      "Epoch: 218, Batch number: 8, Loss: 450.6505432128906\n",
      "Epoch: 219, Batch number: 32, Loss: 422.66162109375\n",
      "Epoch: 220, Batch number: 56, Loss: 504.1678771972656\n",
      "Epoch: 222, Batch number: 4, Loss: 494.7538146972656\n",
      "Epoch: 223, Batch number: 28, Loss: 399.38226318359375\n",
      "Epoch: 224, Batch number: 52, Loss: 401.3694152832031\n",
      "Epoch: 226, Batch number: 0, Loss: 418.37054443359375\n",
      "Epoch: 227, Batch number: 24, Loss: 410.3663635253906\n",
      "Epoch: 228, Batch number: 48, Loss: 396.9898376464844\n",
      "Epoch: 229, Batch number: 72, Loss: 427.8692321777344\n",
      "Epoch: 231, Batch number: 20, Loss: 402.66094970703125\n",
      "Epoch: 232, Batch number: 44, Loss: 477.4450988769531\n",
      "Epoch: 233, Batch number: 68, Loss: 464.90673828125\n",
      "Epoch: 235, Batch number: 16, Loss: 385.0475158691406\n",
      "Epoch: 236, Batch number: 40, Loss: 386.861083984375\n",
      "Epoch: 237, Batch number: 64, Loss: 436.9172058105469\n",
      "Epoch: 239, Batch number: 12, Loss: 402.2221984863281\n",
      "Epoch: 240, Batch number: 36, Loss: 369.4705810546875\n",
      "Epoch: 241, Batch number: 60, Loss: 463.5452880859375\n",
      "Epoch: 243, Batch number: 8, Loss: 413.1507568359375\n",
      "Epoch: 244, Batch number: 32, Loss: 436.8988952636719\n",
      "Epoch: 245, Batch number: 56, Loss: 498.11309814453125\n",
      "Epoch: 247, Batch number: 4, Loss: 348.3229064941406\n",
      "Epoch: 248, Batch number: 28, Loss: 409.8213806152344\n",
      "Epoch: 249, Batch number: 52, Loss: 358.15460205078125\n",
      "Epoch: 251, Batch number: 0, Loss: 372.25543212890625\n",
      "Epoch: 252, Batch number: 24, Loss: 386.7325134277344\n",
      "Epoch: 253, Batch number: 48, Loss: 453.0003356933594\n",
      "Epoch: 254, Batch number: 72, Loss: 463.4591979980469\n",
      "Epoch: 256, Batch number: 20, Loss: 455.666748046875\n",
      "Epoch: 257, Batch number: 44, Loss: 448.1914367675781\n",
      "Epoch: 258, Batch number: 68, Loss: 497.9567565917969\n",
      "Epoch: 260, Batch number: 16, Loss: 393.6313781738281\n",
      "Epoch: 261, Batch number: 40, Loss: 421.0740051269531\n",
      "Epoch: 262, Batch number: 64, Loss: 404.63128662109375\n",
      "Epoch: 264, Batch number: 12, Loss: 427.15338134765625\n",
      "Epoch: 265, Batch number: 36, Loss: 428.72802734375\n",
      "Epoch: 266, Batch number: 60, Loss: 391.7613220214844\n",
      "Epoch: 268, Batch number: 8, Loss: 441.19549560546875\n",
      "Epoch: 269, Batch number: 32, Loss: 395.99041748046875\n",
      "Epoch: 270, Batch number: 56, Loss: 386.8231506347656\n",
      "Epoch: 272, Batch number: 4, Loss: 417.2769775390625\n",
      "Epoch: 273, Batch number: 28, Loss: 429.7802734375\n",
      "Epoch: 274, Batch number: 52, Loss: 476.57232666015625\n",
      "Epoch: 276, Batch number: 0, Loss: 358.06707763671875\n",
      "Epoch: 277, Batch number: 24, Loss: 389.27197265625\n",
      "Epoch: 278, Batch number: 48, Loss: 404.8841552734375\n",
      "Epoch: 279, Batch number: 72, Loss: 528.4103393554688\n",
      "Epoch: 281, Batch number: 20, Loss: 421.1363525390625\n",
      "Epoch: 282, Batch number: 44, Loss: 380.2004699707031\n",
      "Epoch: 283, Batch number: 68, Loss: 451.5973205566406\n",
      "Epoch: 285, Batch number: 16, Loss: 387.6800231933594\n",
      "Epoch: 286, Batch number: 40, Loss: 371.5179748535156\n",
      "Epoch: 287, Batch number: 64, Loss: 505.6612243652344\n",
      "Epoch: 289, Batch number: 12, Loss: 352.7379455566406\n",
      "Epoch: 290, Batch number: 36, Loss: 395.9455261230469\n",
      "Epoch: 291, Batch number: 60, Loss: 427.1573791503906\n",
      "Epoch: 293, Batch number: 8, Loss: 400.2460632324219\n",
      "Epoch: 294, Batch number: 32, Loss: 447.8795471191406\n",
      "Epoch: 295, Batch number: 56, Loss: 433.4513244628906\n",
      "Epoch: 297, Batch number: 4, Loss: 362.0651550292969\n",
      "Epoch: 298, Batch number: 28, Loss: 398.0435485839844\n",
      "Epoch: 299, Batch number: 52, Loss: 365.2900085449219\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4439.7021484375\n",
      "Epoch: 2, Batch number: 24, Loss: 3707.55078125\n",
      "Epoch: 3, Batch number: 48, Loss: 3209.288330078125\n",
      "Epoch: 4, Batch number: 72, Loss: 2741.437744140625\n",
      "Epoch: 6, Batch number: 20, Loss: 2320.77197265625\n",
      "Epoch: 7, Batch number: 44, Loss: 2020.05126953125\n",
      "Epoch: 8, Batch number: 68, Loss: 1891.8359375\n",
      "Epoch: 10, Batch number: 16, Loss: 1599.8826904296875\n",
      "Epoch: 11, Batch number: 40, Loss: 1413.921630859375\n",
      "Epoch: 12, Batch number: 64, Loss: 1412.820556640625\n",
      "Epoch: 14, Batch number: 12, Loss: 1197.0867919921875\n",
      "Epoch: 15, Batch number: 36, Loss: 1171.0948486328125\n",
      "Epoch: 16, Batch number: 60, Loss: 1107.4114990234375\n",
      "Epoch: 18, Batch number: 8, Loss: 953.9595947265625\n",
      "Epoch: 19, Batch number: 32, Loss: 964.5250854492188\n",
      "Epoch: 20, Batch number: 56, Loss: 866.0433349609375\n",
      "Epoch: 22, Batch number: 4, Loss: 893.8780517578125\n",
      "Epoch: 23, Batch number: 28, Loss: 783.59716796875\n",
      "Epoch: 24, Batch number: 52, Loss: 850.40283203125\n",
      "Epoch: 26, Batch number: 0, Loss: 796.7830200195312\n",
      "Epoch: 27, Batch number: 24, Loss: 757.5247802734375\n",
      "Epoch: 28, Batch number: 48, Loss: 663.0823364257812\n",
      "Epoch: 29, Batch number: 72, Loss: 760.5905151367188\n",
      "Epoch: 31, Batch number: 20, Loss: 640.2351684570312\n",
      "Epoch: 32, Batch number: 44, Loss: 684.910888671875\n",
      "Epoch: 33, Batch number: 68, Loss: 681.1409912109375\n",
      "Epoch: 35, Batch number: 16, Loss: 581.032958984375\n",
      "Epoch: 36, Batch number: 40, Loss: 656.2151489257812\n",
      "Epoch: 37, Batch number: 64, Loss: 626.8427734375\n",
      "Epoch: 39, Batch number: 12, Loss: 586.4322509765625\n",
      "Epoch: 40, Batch number: 36, Loss: 579.9383544921875\n",
      "Epoch: 41, Batch number: 60, Loss: 600.079833984375\n",
      "Epoch: 43, Batch number: 8, Loss: 442.5436706542969\n",
      "Epoch: 44, Batch number: 32, Loss: 576.1630249023438\n",
      "Epoch: 45, Batch number: 56, Loss: 518.3344116210938\n",
      "Epoch: 47, Batch number: 4, Loss: 535.1776733398438\n",
      "Epoch: 48, Batch number: 28, Loss: 542.79736328125\n",
      "Epoch: 49, Batch number: 52, Loss: 524.6043701171875\n",
      "Epoch: 51, Batch number: 0, Loss: 508.80352783203125\n",
      "Epoch: 52, Batch number: 24, Loss: 464.958984375\n",
      "Epoch: 53, Batch number: 48, Loss: 512.9481201171875\n",
      "Epoch: 54, Batch number: 72, Loss: 530.0520629882812\n",
      "Epoch: 56, Batch number: 20, Loss: 498.4848327636719\n",
      "Epoch: 57, Batch number: 44, Loss: 474.34051513671875\n",
      "Epoch: 58, Batch number: 68, Loss: 511.0834655761719\n",
      "Epoch: 60, Batch number: 16, Loss: 446.20367431640625\n",
      "Epoch: 61, Batch number: 40, Loss: 457.93731689453125\n",
      "Epoch: 62, Batch number: 64, Loss: 456.9059143066406\n",
      "Epoch: 64, Batch number: 12, Loss: 508.4841613769531\n",
      "Epoch: 65, Batch number: 36, Loss: 468.810791015625\n",
      "Epoch: 66, Batch number: 60, Loss: 463.8224792480469\n",
      "Epoch: 68, Batch number: 8, Loss: 417.4798583984375\n",
      "Epoch: 69, Batch number: 32, Loss: 522.2686157226562\n",
      "Epoch: 70, Batch number: 56, Loss: 457.0624084472656\n",
      "Epoch: 72, Batch number: 4, Loss: 401.5391540527344\n",
      "Epoch: 73, Batch number: 28, Loss: 494.0599060058594\n",
      "Epoch: 74, Batch number: 52, Loss: 469.4444885253906\n",
      "Epoch: 76, Batch number: 0, Loss: 422.86614990234375\n",
      "Epoch: 77, Batch number: 24, Loss: 398.53314208984375\n",
      "Epoch: 78, Batch number: 48, Loss: 423.751953125\n",
      "Epoch: 79, Batch number: 72, Loss: 498.731689453125\n",
      "Epoch: 81, Batch number: 20, Loss: 476.4039306640625\n",
      "Epoch: 82, Batch number: 44, Loss: 438.7082214355469\n",
      "Epoch: 83, Batch number: 68, Loss: 467.9879150390625\n",
      "Epoch: 85, Batch number: 16, Loss: 447.19647216796875\n",
      "Epoch: 86, Batch number: 40, Loss: 446.3506774902344\n",
      "Epoch: 87, Batch number: 64, Loss: 453.77984619140625\n",
      "Epoch: 89, Batch number: 12, Loss: 419.6450500488281\n",
      "Epoch: 90, Batch number: 36, Loss: 475.9523620605469\n",
      "Epoch: 91, Batch number: 60, Loss: 508.94146728515625\n",
      "Epoch: 93, Batch number: 8, Loss: 468.0528259277344\n",
      "Epoch: 94, Batch number: 32, Loss: 496.00555419921875\n",
      "Epoch: 95, Batch number: 56, Loss: 437.4663391113281\n",
      "Epoch: 97, Batch number: 4, Loss: 427.6818542480469\n",
      "Epoch: 98, Batch number: 28, Loss: 430.5979919433594\n",
      "Epoch: 99, Batch number: 52, Loss: 437.177490234375\n",
      "Epoch: 101, Batch number: 0, Loss: 411.5428771972656\n",
      "Epoch: 102, Batch number: 24, Loss: 452.7021179199219\n",
      "Epoch: 103, Batch number: 48, Loss: 478.4259338378906\n",
      "Epoch: 104, Batch number: 72, Loss: 465.23370361328125\n",
      "Epoch: 106, Batch number: 20, Loss: 468.84759521484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 473.0251159667969\n",
      "Epoch: 108, Batch number: 68, Loss: 459.0220642089844\n",
      "Epoch: 110, Batch number: 16, Loss: 437.66302490234375\n",
      "Epoch: 111, Batch number: 40, Loss: 420.4629211425781\n",
      "Epoch: 112, Batch number: 64, Loss: 452.9340515136719\n",
      "Epoch: 114, Batch number: 12, Loss: 372.56549072265625\n",
      "Epoch: 115, Batch number: 36, Loss: 428.82904052734375\n",
      "Epoch: 116, Batch number: 60, Loss: 430.60321044921875\n",
      "Epoch: 118, Batch number: 8, Loss: 417.5836486816406\n",
      "Epoch: 119, Batch number: 32, Loss: 365.0910339355469\n",
      "Epoch: 120, Batch number: 56, Loss: 512.2116088867188\n",
      "Epoch: 122, Batch number: 4, Loss: 440.6715087890625\n",
      "Epoch: 123, Batch number: 28, Loss: 423.3623046875\n",
      "Epoch: 124, Batch number: 52, Loss: 441.6435241699219\n",
      "Epoch: 126, Batch number: 0, Loss: 400.3707275390625\n",
      "Epoch: 127, Batch number: 24, Loss: 409.27459716796875\n",
      "Epoch: 128, Batch number: 48, Loss: 437.5090637207031\n",
      "Epoch: 129, Batch number: 72, Loss: 462.7281188964844\n",
      "Epoch: 131, Batch number: 20, Loss: 426.9145812988281\n",
      "Epoch: 132, Batch number: 44, Loss: 399.46807861328125\n",
      "Epoch: 133, Batch number: 68, Loss: 473.22308349609375\n",
      "Epoch: 135, Batch number: 16, Loss: 402.666748046875\n",
      "Epoch: 136, Batch number: 40, Loss: 383.7388916015625\n",
      "Epoch: 137, Batch number: 64, Loss: 426.7996520996094\n",
      "Epoch: 139, Batch number: 12, Loss: 386.3749694824219\n",
      "Epoch: 140, Batch number: 36, Loss: 405.2117919921875\n",
      "Epoch: 141, Batch number: 60, Loss: 470.6435546875\n",
      "Epoch: 143, Batch number: 8, Loss: 389.2135009765625\n",
      "Epoch: 144, Batch number: 32, Loss: 415.77545166015625\n",
      "Epoch: 145, Batch number: 56, Loss: 471.82122802734375\n",
      "Epoch: 147, Batch number: 4, Loss: 370.58135986328125\n",
      "Epoch: 148, Batch number: 28, Loss: 361.77178955078125\n",
      "Epoch: 149, Batch number: 52, Loss: 398.6524353027344\n",
      "Epoch: 151, Batch number: 0, Loss: 394.8184814453125\n",
      "Epoch: 152, Batch number: 24, Loss: 458.5971374511719\n",
      "Epoch: 153, Batch number: 48, Loss: 423.76947021484375\n",
      "Epoch: 154, Batch number: 72, Loss: 453.79840087890625\n",
      "Epoch: 156, Batch number: 20, Loss: 386.9790344238281\n",
      "Epoch: 157, Batch number: 44, Loss: 458.3592834472656\n",
      "Epoch: 158, Batch number: 68, Loss: 425.90875244140625\n",
      "Epoch: 160, Batch number: 16, Loss: 352.4534606933594\n",
      "Epoch: 161, Batch number: 40, Loss: 425.5906982421875\n",
      "Epoch: 162, Batch number: 64, Loss: 410.5811767578125\n",
      "Epoch: 164, Batch number: 12, Loss: 379.4728088378906\n",
      "Epoch: 165, Batch number: 36, Loss: 463.0829162597656\n",
      "Epoch: 166, Batch number: 60, Loss: 445.4588317871094\n",
      "Epoch: 168, Batch number: 8, Loss: 405.6270751953125\n",
      "Epoch: 169, Batch number: 32, Loss: 444.60552978515625\n",
      "Epoch: 170, Batch number: 56, Loss: 452.4131164550781\n",
      "Epoch: 172, Batch number: 4, Loss: 359.9687805175781\n",
      "Epoch: 173, Batch number: 28, Loss: 481.4886474609375\n",
      "Epoch: 174, Batch number: 52, Loss: 481.03399658203125\n",
      "Epoch: 176, Batch number: 0, Loss: 349.738525390625\n",
      "Epoch: 177, Batch number: 24, Loss: 431.16168212890625\n",
      "Epoch: 178, Batch number: 48, Loss: 427.9385986328125\n",
      "Epoch: 179, Batch number: 72, Loss: 466.2849426269531\n",
      "Epoch: 181, Batch number: 20, Loss: 394.4783630371094\n",
      "Epoch: 182, Batch number: 44, Loss: 393.59173583984375\n",
      "Epoch: 183, Batch number: 68, Loss: 439.1272277832031\n",
      "Epoch: 185, Batch number: 16, Loss: 475.86376953125\n",
      "Epoch: 186, Batch number: 40, Loss: 405.8258972167969\n",
      "Epoch: 187, Batch number: 64, Loss: 408.30914306640625\n",
      "Epoch: 189, Batch number: 12, Loss: 467.164306640625\n",
      "Epoch: 190, Batch number: 36, Loss: 512.921142578125\n",
      "Epoch: 191, Batch number: 60, Loss: 465.9087219238281\n",
      "Epoch: 193, Batch number: 8, Loss: 381.7923583984375\n",
      "Epoch: 194, Batch number: 32, Loss: 404.7196350097656\n",
      "Epoch: 195, Batch number: 56, Loss: 435.0923767089844\n",
      "Epoch: 197, Batch number: 4, Loss: 397.145263671875\n",
      "Epoch: 198, Batch number: 28, Loss: 408.8667297363281\n",
      "Epoch: 199, Batch number: 52, Loss: 403.27618408203125\n",
      "Epoch: 201, Batch number: 0, Loss: 419.33819580078125\n",
      "Epoch: 202, Batch number: 24, Loss: 424.3323669433594\n",
      "Epoch: 203, Batch number: 48, Loss: 443.12713623046875\n",
      "Epoch: 204, Batch number: 72, Loss: 442.56011962890625\n",
      "Epoch: 206, Batch number: 20, Loss: 398.403076171875\n",
      "Epoch: 207, Batch number: 44, Loss: 429.79119873046875\n",
      "Epoch: 208, Batch number: 68, Loss: 418.9678039550781\n",
      "Epoch: 210, Batch number: 16, Loss: 439.2656555175781\n",
      "Epoch: 211, Batch number: 40, Loss: 418.998779296875\n",
      "Epoch: 212, Batch number: 64, Loss: 453.6417541503906\n",
      "Epoch: 214, Batch number: 12, Loss: 391.2073974609375\n",
      "Epoch: 215, Batch number: 36, Loss: 442.4317626953125\n",
      "Epoch: 216, Batch number: 60, Loss: 470.3829345703125\n",
      "Epoch: 218, Batch number: 8, Loss: 445.1730651855469\n",
      "Epoch: 219, Batch number: 32, Loss: 423.8491516113281\n",
      "Epoch: 220, Batch number: 56, Loss: 494.6978454589844\n",
      "Epoch: 222, Batch number: 4, Loss: 419.5728454589844\n",
      "Epoch: 223, Batch number: 28, Loss: 412.3446350097656\n",
      "Epoch: 224, Batch number: 52, Loss: 455.5888366699219\n",
      "Epoch: 226, Batch number: 0, Loss: 401.4100646972656\n",
      "Epoch: 227, Batch number: 24, Loss: 381.7700500488281\n",
      "Epoch: 228, Batch number: 48, Loss: 461.0258483886719\n",
      "Epoch: 229, Batch number: 72, Loss: 481.98565673828125\n",
      "Epoch: 231, Batch number: 20, Loss: 422.7239074707031\n",
      "Epoch: 232, Batch number: 44, Loss: 405.7533874511719\n",
      "Epoch: 233, Batch number: 68, Loss: 493.4930419921875\n",
      "Epoch: 235, Batch number: 16, Loss: 391.6238098144531\n",
      "Epoch: 236, Batch number: 40, Loss: 412.3134765625\n",
      "Epoch: 237, Batch number: 64, Loss: 405.77008056640625\n",
      "Epoch: 239, Batch number: 12, Loss: 387.66510009765625\n",
      "Epoch: 240, Batch number: 36, Loss: 395.0567932128906\n",
      "Epoch: 241, Batch number: 60, Loss: 453.6041259765625\n",
      "Epoch: 243, Batch number: 8, Loss: 369.72900390625\n",
      "Epoch: 244, Batch number: 32, Loss: 417.1482238769531\n",
      "Epoch: 245, Batch number: 56, Loss: 415.4493713378906\n",
      "Epoch: 247, Batch number: 4, Loss: 417.42449951171875\n",
      "Epoch: 248, Batch number: 28, Loss: 481.91314697265625\n",
      "Epoch: 249, Batch number: 52, Loss: 421.5346984863281\n",
      "Epoch: 251, Batch number: 0, Loss: 409.9163513183594\n",
      "Epoch: 252, Batch number: 24, Loss: 408.1187438964844\n",
      "Epoch: 253, Batch number: 48, Loss: 427.827392578125\n",
      "Epoch: 254, Batch number: 72, Loss: 443.86083984375\n",
      "Epoch: 256, Batch number: 20, Loss: 404.93035888671875\n",
      "Epoch: 257, Batch number: 44, Loss: 407.5132751464844\n",
      "Epoch: 258, Batch number: 68, Loss: 426.0444641113281\n",
      "Epoch: 260, Batch number: 16, Loss: 448.1869812011719\n",
      "Epoch: 261, Batch number: 40, Loss: 502.54364013671875\n",
      "Epoch: 262, Batch number: 64, Loss: 439.5916748046875\n",
      "Epoch: 264, Batch number: 12, Loss: 412.095703125\n",
      "Epoch: 265, Batch number: 36, Loss: 478.3470458984375\n",
      "Epoch: 266, Batch number: 60, Loss: 493.7645263671875\n",
      "Epoch: 268, Batch number: 8, Loss: 390.3274230957031\n",
      "Epoch: 269, Batch number: 32, Loss: 408.60809326171875\n",
      "Epoch: 270, Batch number: 56, Loss: 447.5239562988281\n",
      "Epoch: 272, Batch number: 4, Loss: 367.8205871582031\n",
      "Epoch: 273, Batch number: 28, Loss: 405.47552490234375\n",
      "Epoch: 274, Batch number: 52, Loss: 444.4847717285156\n",
      "Epoch: 276, Batch number: 0, Loss: 350.8037109375\n",
      "Epoch: 277, Batch number: 24, Loss: 358.0150451660156\n",
      "Epoch: 278, Batch number: 48, Loss: 437.0732421875\n",
      "Epoch: 279, Batch number: 72, Loss: 463.3518371582031\n",
      "Epoch: 281, Batch number: 20, Loss: 343.2718811035156\n",
      "Epoch: 282, Batch number: 44, Loss: 395.4452209472656\n",
      "Epoch: 283, Batch number: 68, Loss: 430.6603088378906\n",
      "Epoch: 285, Batch number: 16, Loss: 366.9226989746094\n",
      "Epoch: 286, Batch number: 40, Loss: 395.8901672363281\n",
      "Epoch: 287, Batch number: 64, Loss: 436.7611389160156\n",
      "Epoch: 289, Batch number: 12, Loss: 428.92279052734375\n",
      "Epoch: 290, Batch number: 36, Loss: 431.63226318359375\n",
      "Epoch: 291, Batch number: 60, Loss: 384.1507568359375\n",
      "Epoch: 293, Batch number: 8, Loss: 386.03485107421875\n",
      "Epoch: 294, Batch number: 32, Loss: 416.78350830078125\n",
      "Epoch: 295, Batch number: 56, Loss: 447.8531494140625\n",
      "Epoch: 297, Batch number: 4, Loss: 365.1756896972656\n",
      "Epoch: 298, Batch number: 28, Loss: 455.79974365234375\n",
      "Epoch: 299, Batch number: 52, Loss: 429.2992248535156\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4406.20166015625\n",
      "Epoch: 2, Batch number: 24, Loss: 4316.25830078125\n",
      "Epoch: 3, Batch number: 48, Loss: 4173.13134765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch number: 72, Loss: 3982.33837890625\n",
      "Epoch: 6, Batch number: 20, Loss: 3647.142822265625\n",
      "Epoch: 7, Batch number: 44, Loss: 3415.320556640625\n",
      "Epoch: 8, Batch number: 68, Loss: 3198.513916015625\n",
      "Epoch: 10, Batch number: 16, Loss: 3034.84765625\n",
      "Epoch: 11, Batch number: 40, Loss: 2943.367919921875\n",
      "Epoch: 12, Batch number: 64, Loss: 2908.5986328125\n",
      "Epoch: 14, Batch number: 12, Loss: 2802.34326171875\n",
      "Epoch: 15, Batch number: 36, Loss: 2694.1416015625\n",
      "Epoch: 16, Batch number: 60, Loss: 2622.9111328125\n",
      "Epoch: 18, Batch number: 8, Loss: 2758.39013671875\n",
      "Epoch: 19, Batch number: 32, Loss: 2606.26513671875\n",
      "Epoch: 20, Batch number: 56, Loss: 2626.91357421875\n",
      "Epoch: 22, Batch number: 4, Loss: 2526.4462890625\n",
      "Epoch: 23, Batch number: 28, Loss: 2450.639404296875\n",
      "Epoch: 24, Batch number: 52, Loss: 2340.974365234375\n",
      "Epoch: 26, Batch number: 0, Loss: 2400.224609375\n",
      "Epoch: 27, Batch number: 24, Loss: 2276.7158203125\n",
      "Epoch: 28, Batch number: 48, Loss: 2240.0927734375\n",
      "Epoch: 29, Batch number: 72, Loss: 2245.176025390625\n",
      "Epoch: 31, Batch number: 20, Loss: 2128.867919921875\n",
      "Epoch: 32, Batch number: 44, Loss: 2190.950439453125\n",
      "Epoch: 33, Batch number: 68, Loss: 2150.884521484375\n",
      "Epoch: 35, Batch number: 16, Loss: 2162.107421875\n",
      "Epoch: 36, Batch number: 40, Loss: 2090.126220703125\n",
      "Epoch: 37, Batch number: 64, Loss: 2075.238037109375\n",
      "Epoch: 39, Batch number: 12, Loss: 1955.265625\n",
      "Epoch: 40, Batch number: 36, Loss: 1968.6573486328125\n",
      "Epoch: 41, Batch number: 60, Loss: 1987.02783203125\n",
      "Epoch: 43, Batch number: 8, Loss: 1954.7861328125\n",
      "Epoch: 44, Batch number: 32, Loss: 1882.4244384765625\n",
      "Epoch: 45, Batch number: 56, Loss: 1875.4365234375\n",
      "Epoch: 47, Batch number: 4, Loss: 1740.6038818359375\n",
      "Epoch: 48, Batch number: 28, Loss: 1749.5009765625\n",
      "Epoch: 49, Batch number: 52, Loss: 1789.28466796875\n",
      "Epoch: 51, Batch number: 0, Loss: 1724.5704345703125\n",
      "Epoch: 52, Batch number: 24, Loss: 1668.39794921875\n",
      "Epoch: 53, Batch number: 48, Loss: 1663.364013671875\n",
      "Epoch: 54, Batch number: 72, Loss: 1680.737060546875\n",
      "Epoch: 56, Batch number: 20, Loss: 1575.4466552734375\n",
      "Epoch: 57, Batch number: 44, Loss: 1679.0545654296875\n",
      "Epoch: 58, Batch number: 68, Loss: 1586.017333984375\n",
      "Epoch: 60, Batch number: 16, Loss: 1574.9984130859375\n",
      "Epoch: 61, Batch number: 40, Loss: 1542.10595703125\n",
      "Epoch: 62, Batch number: 64, Loss: 1469.9678955078125\n",
      "Epoch: 64, Batch number: 12, Loss: 1450.0240478515625\n",
      "Epoch: 65, Batch number: 36, Loss: 1495.16943359375\n",
      "Epoch: 66, Batch number: 60, Loss: 1546.8712158203125\n",
      "Epoch: 68, Batch number: 8, Loss: 1401.4783935546875\n",
      "Epoch: 69, Batch number: 32, Loss: 1472.96923828125\n",
      "Epoch: 70, Batch number: 56, Loss: 1431.0933837890625\n",
      "Epoch: 72, Batch number: 4, Loss: 1299.1175537109375\n",
      "Epoch: 73, Batch number: 28, Loss: 1314.1025390625\n",
      "Epoch: 74, Batch number: 52, Loss: 1368.85302734375\n",
      "Epoch: 76, Batch number: 0, Loss: 1301.4453125\n",
      "Epoch: 77, Batch number: 24, Loss: 1322.5709228515625\n",
      "Epoch: 78, Batch number: 48, Loss: 1276.041015625\n",
      "Epoch: 79, Batch number: 72, Loss: 1315.7252197265625\n",
      "Epoch: 81, Batch number: 20, Loss: 1182.38427734375\n",
      "Epoch: 82, Batch number: 44, Loss: 1183.0693359375\n",
      "Epoch: 83, Batch number: 68, Loss: 1277.29443359375\n",
      "Epoch: 85, Batch number: 16, Loss: 1130.13623046875\n",
      "Epoch: 86, Batch number: 40, Loss: 1201.86865234375\n",
      "Epoch: 87, Batch number: 64, Loss: 1078.5440673828125\n",
      "Epoch: 89, Batch number: 12, Loss: 1161.66748046875\n",
      "Epoch: 90, Batch number: 36, Loss: 1194.99462890625\n",
      "Epoch: 91, Batch number: 60, Loss: 1178.9945068359375\n",
      "Epoch: 93, Batch number: 8, Loss: 1171.9481201171875\n",
      "Epoch: 94, Batch number: 32, Loss: 1199.9798583984375\n",
      "Epoch: 95, Batch number: 56, Loss: 1025.675048828125\n",
      "Epoch: 97, Batch number: 4, Loss: 1029.0718994140625\n",
      "Epoch: 98, Batch number: 28, Loss: 1094.2220458984375\n",
      "Epoch: 99, Batch number: 52, Loss: 1049.1834716796875\n",
      "Epoch: 101, Batch number: 0, Loss: 1090.8482666015625\n",
      "Epoch: 102, Batch number: 24, Loss: 1035.858154296875\n",
      "Epoch: 103, Batch number: 48, Loss: 1012.7493896484375\n",
      "Epoch: 104, Batch number: 72, Loss: 1038.88134765625\n",
      "Epoch: 106, Batch number: 20, Loss: 970.119140625\n",
      "Epoch: 107, Batch number: 44, Loss: 877.6738891601562\n",
      "Epoch: 108, Batch number: 68, Loss: 975.72265625\n",
      "Epoch: 110, Batch number: 16, Loss: 934.89306640625\n",
      "Epoch: 111, Batch number: 40, Loss: 929.94384765625\n",
      "Epoch: 112, Batch number: 64, Loss: 920.312744140625\n",
      "Epoch: 114, Batch number: 12, Loss: 840.0391845703125\n",
      "Epoch: 115, Batch number: 36, Loss: 854.2361450195312\n",
      "Epoch: 116, Batch number: 60, Loss: 887.0855712890625\n",
      "Epoch: 118, Batch number: 8, Loss: 877.8261108398438\n",
      "Epoch: 119, Batch number: 32, Loss: 800.3943481445312\n",
      "Epoch: 120, Batch number: 56, Loss: 875.5856323242188\n",
      "Epoch: 122, Batch number: 4, Loss: 827.8674926757812\n",
      "Epoch: 123, Batch number: 28, Loss: 842.3869018554688\n",
      "Epoch: 124, Batch number: 52, Loss: 847.8672485351562\n",
      "Epoch: 126, Batch number: 0, Loss: 760.8125\n",
      "Epoch: 127, Batch number: 24, Loss: 803.5619506835938\n",
      "Epoch: 128, Batch number: 48, Loss: 805.63818359375\n",
      "Epoch: 129, Batch number: 72, Loss: 794.6890869140625\n",
      "Epoch: 131, Batch number: 20, Loss: 777.0106201171875\n",
      "Epoch: 132, Batch number: 44, Loss: 751.0884399414062\n",
      "Epoch: 133, Batch number: 68, Loss: 738.8154296875\n",
      "Epoch: 135, Batch number: 16, Loss: 784.3462524414062\n",
      "Epoch: 136, Batch number: 40, Loss: 708.1810913085938\n",
      "Epoch: 137, Batch number: 64, Loss: 724.8275146484375\n",
      "Epoch: 139, Batch number: 12, Loss: 767.6392822265625\n",
      "Epoch: 140, Batch number: 36, Loss: 675.408935546875\n",
      "Epoch: 141, Batch number: 60, Loss: 723.6605224609375\n",
      "Epoch: 143, Batch number: 8, Loss: 691.8985595703125\n",
      "Epoch: 144, Batch number: 32, Loss: 729.325439453125\n",
      "Epoch: 145, Batch number: 56, Loss: 667.545654296875\n",
      "Epoch: 147, Batch number: 4, Loss: 685.9222412109375\n",
      "Epoch: 148, Batch number: 28, Loss: 683.1932983398438\n",
      "Epoch: 149, Batch number: 52, Loss: 624.51025390625\n",
      "Epoch: 151, Batch number: 0, Loss: 611.6082153320312\n",
      "Epoch: 152, Batch number: 24, Loss: 643.396240234375\n",
      "Epoch: 153, Batch number: 48, Loss: 599.1859741210938\n",
      "Epoch: 154, Batch number: 72, Loss: 715.4705200195312\n",
      "Epoch: 156, Batch number: 20, Loss: 606.2080688476562\n",
      "Epoch: 157, Batch number: 44, Loss: 642.8099365234375\n",
      "Epoch: 158, Batch number: 68, Loss: 592.4810180664062\n",
      "Epoch: 160, Batch number: 16, Loss: 605.802490234375\n",
      "Epoch: 161, Batch number: 40, Loss: 652.7582397460938\n",
      "Epoch: 162, Batch number: 64, Loss: 626.2239379882812\n",
      "Epoch: 164, Batch number: 12, Loss: 615.9974975585938\n",
      "Epoch: 165, Batch number: 36, Loss: 619.3232421875\n",
      "Epoch: 166, Batch number: 60, Loss: 580.3817138671875\n",
      "Epoch: 168, Batch number: 8, Loss: 618.8160400390625\n",
      "Epoch: 169, Batch number: 32, Loss: 485.133056640625\n",
      "Epoch: 170, Batch number: 56, Loss: 578.7562255859375\n",
      "Epoch: 172, Batch number: 4, Loss: 467.0618896484375\n",
      "Epoch: 173, Batch number: 28, Loss: 558.7185668945312\n",
      "Epoch: 174, Batch number: 52, Loss: 556.0101318359375\n",
      "Epoch: 176, Batch number: 0, Loss: 504.8351135253906\n",
      "Epoch: 177, Batch number: 24, Loss: 578.27099609375\n",
      "Epoch: 178, Batch number: 48, Loss: 547.0521850585938\n",
      "Epoch: 179, Batch number: 72, Loss: 520.4868774414062\n",
      "Epoch: 181, Batch number: 20, Loss: 462.07452392578125\n",
      "Epoch: 182, Batch number: 44, Loss: 530.804931640625\n",
      "Epoch: 183, Batch number: 68, Loss: 472.7781982421875\n",
      "Epoch: 185, Batch number: 16, Loss: 458.9826965332031\n",
      "Epoch: 186, Batch number: 40, Loss: 502.760009765625\n",
      "Epoch: 187, Batch number: 64, Loss: 516.4615478515625\n",
      "Epoch: 189, Batch number: 12, Loss: 489.1019592285156\n",
      "Epoch: 190, Batch number: 36, Loss: 488.5274963378906\n",
      "Epoch: 191, Batch number: 60, Loss: 484.5523681640625\n",
      "Epoch: 193, Batch number: 8, Loss: 483.7294921875\n",
      "Epoch: 194, Batch number: 32, Loss: 432.78558349609375\n",
      "Epoch: 195, Batch number: 56, Loss: 421.6115417480469\n",
      "Epoch: 197, Batch number: 4, Loss: 463.9724426269531\n",
      "Epoch: 198, Batch number: 28, Loss: 444.0213317871094\n",
      "Epoch: 199, Batch number: 52, Loss: 418.6278381347656\n",
      "Epoch: 201, Batch number: 0, Loss: 427.30596923828125\n",
      "Epoch: 202, Batch number: 24, Loss: 445.1358337402344\n",
      "Epoch: 203, Batch number: 48, Loss: 385.9658203125\n",
      "Epoch: 204, Batch number: 72, Loss: 437.4359130859375\n",
      "Epoch: 206, Batch number: 20, Loss: 442.030029296875\n",
      "Epoch: 207, Batch number: 44, Loss: 424.4969177246094\n",
      "Epoch: 208, Batch number: 68, Loss: 380.8648681640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Batch number: 16, Loss: 408.1578369140625\n",
      "Epoch: 211, Batch number: 40, Loss: 441.5118408203125\n",
      "Epoch: 212, Batch number: 64, Loss: 461.0477600097656\n",
      "Epoch: 214, Batch number: 12, Loss: 384.8839111328125\n",
      "Epoch: 215, Batch number: 36, Loss: 331.7644958496094\n",
      "Epoch: 216, Batch number: 60, Loss: 356.37139892578125\n",
      "Epoch: 218, Batch number: 8, Loss: 407.042724609375\n",
      "Epoch: 219, Batch number: 32, Loss: 326.30975341796875\n",
      "Epoch: 220, Batch number: 56, Loss: 317.4443054199219\n",
      "Epoch: 222, Batch number: 4, Loss: 339.0945129394531\n",
      "Epoch: 223, Batch number: 28, Loss: 402.6903381347656\n",
      "Epoch: 224, Batch number: 52, Loss: 371.1662292480469\n",
      "Epoch: 226, Batch number: 0, Loss: 381.6698303222656\n",
      "Epoch: 227, Batch number: 24, Loss: 346.178466796875\n",
      "Epoch: 228, Batch number: 48, Loss: 309.1287841796875\n",
      "Epoch: 229, Batch number: 72, Loss: 371.5747985839844\n",
      "Epoch: 231, Batch number: 20, Loss: 339.0248107910156\n",
      "Epoch: 232, Batch number: 44, Loss: 291.3477783203125\n",
      "Epoch: 233, Batch number: 68, Loss: 373.4382629394531\n",
      "Epoch: 235, Batch number: 16, Loss: 328.2790222167969\n",
      "Epoch: 236, Batch number: 40, Loss: 332.1722412109375\n",
      "Epoch: 237, Batch number: 64, Loss: 336.392578125\n",
      "Epoch: 239, Batch number: 12, Loss: 311.7647705078125\n",
      "Epoch: 240, Batch number: 36, Loss: 307.6599426269531\n",
      "Epoch: 241, Batch number: 60, Loss: 311.500244140625\n",
      "Epoch: 243, Batch number: 8, Loss: 299.1459655761719\n",
      "Epoch: 244, Batch number: 32, Loss: 341.3494873046875\n",
      "Epoch: 245, Batch number: 56, Loss: 287.2759094238281\n",
      "Epoch: 247, Batch number: 4, Loss: 274.093994140625\n",
      "Epoch: 248, Batch number: 28, Loss: 281.13970947265625\n",
      "Epoch: 249, Batch number: 52, Loss: 313.95635986328125\n",
      "Epoch: 251, Batch number: 0, Loss: 279.08721923828125\n",
      "Epoch: 252, Batch number: 24, Loss: 299.3246154785156\n",
      "Epoch: 253, Batch number: 48, Loss: 294.0318603515625\n",
      "Epoch: 254, Batch number: 72, Loss: 312.9540710449219\n",
      "Epoch: 256, Batch number: 20, Loss: 256.3765869140625\n",
      "Epoch: 257, Batch number: 44, Loss: 295.9903259277344\n",
      "Epoch: 258, Batch number: 68, Loss: 309.0503845214844\n",
      "Epoch: 260, Batch number: 16, Loss: 260.2968444824219\n",
      "Epoch: 261, Batch number: 40, Loss: 233.37832641601562\n",
      "Epoch: 262, Batch number: 64, Loss: 302.93377685546875\n",
      "Epoch: 264, Batch number: 12, Loss: 289.33056640625\n",
      "Epoch: 265, Batch number: 36, Loss: 281.0600891113281\n",
      "Epoch: 266, Batch number: 60, Loss: 245.94815063476562\n",
      "Epoch: 268, Batch number: 8, Loss: 306.9819641113281\n",
      "Epoch: 269, Batch number: 32, Loss: 244.7288360595703\n",
      "Epoch: 270, Batch number: 56, Loss: 249.24134826660156\n",
      "Epoch: 272, Batch number: 4, Loss: 203.9687042236328\n",
      "Epoch: 273, Batch number: 28, Loss: 260.63458251953125\n",
      "Epoch: 274, Batch number: 52, Loss: 260.45831298828125\n",
      "Epoch: 276, Batch number: 0, Loss: 255.38861083984375\n",
      "Epoch: 277, Batch number: 24, Loss: 245.11245727539062\n",
      "Epoch: 278, Batch number: 48, Loss: 229.9656219482422\n",
      "Epoch: 279, Batch number: 72, Loss: 260.9909973144531\n",
      "Epoch: 281, Batch number: 20, Loss: 199.8850555419922\n",
      "Epoch: 282, Batch number: 44, Loss: 226.0570526123047\n",
      "Epoch: 283, Batch number: 68, Loss: 240.27102661132812\n",
      "Epoch: 285, Batch number: 16, Loss: 214.43194580078125\n",
      "Epoch: 286, Batch number: 40, Loss: 238.0460205078125\n",
      "Epoch: 287, Batch number: 64, Loss: 207.1129608154297\n",
      "Epoch: 289, Batch number: 12, Loss: 187.75869750976562\n",
      "Epoch: 290, Batch number: 36, Loss: 196.50697326660156\n",
      "Epoch: 291, Batch number: 60, Loss: 240.38941955566406\n",
      "Epoch: 293, Batch number: 8, Loss: 223.2310028076172\n",
      "Epoch: 294, Batch number: 32, Loss: 206.130126953125\n",
      "Epoch: 295, Batch number: 56, Loss: 196.77288818359375\n",
      "Epoch: 297, Batch number: 4, Loss: 181.18890380859375\n",
      "Epoch: 298, Batch number: 28, Loss: 227.59249877929688\n",
      "Epoch: 299, Batch number: 52, Loss: 214.60862731933594\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4401.5458984375\n",
      "Epoch: 2, Batch number: 24, Loss: 4232.92626953125\n",
      "Epoch: 3, Batch number: 48, Loss: 3964.473876953125\n",
      "Epoch: 4, Batch number: 72, Loss: 3632.093017578125\n",
      "Epoch: 6, Batch number: 20, Loss: 3210.86279296875\n",
      "Epoch: 7, Batch number: 44, Loss: 2887.298828125\n",
      "Epoch: 8, Batch number: 68, Loss: 2754.564208984375\n",
      "Epoch: 10, Batch number: 16, Loss: 2714.2080078125\n",
      "Epoch: 11, Batch number: 40, Loss: 2510.76171875\n",
      "Epoch: 12, Batch number: 64, Loss: 2479.5966796875\n",
      "Epoch: 14, Batch number: 12, Loss: 2473.5986328125\n",
      "Epoch: 15, Batch number: 36, Loss: 2430.669921875\n",
      "Epoch: 16, Batch number: 60, Loss: 2311.651611328125\n",
      "Epoch: 18, Batch number: 8, Loss: 2214.490966796875\n",
      "Epoch: 19, Batch number: 32, Loss: 2163.748779296875\n",
      "Epoch: 20, Batch number: 56, Loss: 2099.252197265625\n",
      "Epoch: 22, Batch number: 4, Loss: 1965.4774169921875\n",
      "Epoch: 23, Batch number: 28, Loss: 2004.0750732421875\n",
      "Epoch: 24, Batch number: 52, Loss: 1909.9495849609375\n",
      "Epoch: 26, Batch number: 0, Loss: 1849.638671875\n",
      "Epoch: 27, Batch number: 24, Loss: 1819.2542724609375\n",
      "Epoch: 28, Batch number: 48, Loss: 1796.79443359375\n",
      "Epoch: 29, Batch number: 72, Loss: 1716.922119140625\n",
      "Epoch: 31, Batch number: 20, Loss: 1618.585205078125\n",
      "Epoch: 32, Batch number: 44, Loss: 1618.628662109375\n",
      "Epoch: 33, Batch number: 68, Loss: 1577.835693359375\n",
      "Epoch: 35, Batch number: 16, Loss: 1509.2171630859375\n",
      "Epoch: 36, Batch number: 40, Loss: 1530.472412109375\n",
      "Epoch: 37, Batch number: 64, Loss: 1465.8568115234375\n",
      "Epoch: 39, Batch number: 12, Loss: 1420.9349365234375\n",
      "Epoch: 40, Batch number: 36, Loss: 1288.8909912109375\n",
      "Epoch: 41, Batch number: 60, Loss: 1386.53125\n",
      "Epoch: 43, Batch number: 8, Loss: 1264.6468505859375\n",
      "Epoch: 44, Batch number: 32, Loss: 1305.865234375\n",
      "Epoch: 45, Batch number: 56, Loss: 1238.9296875\n",
      "Epoch: 47, Batch number: 4, Loss: 1177.808349609375\n",
      "Epoch: 48, Batch number: 28, Loss: 1099.5830078125\n",
      "Epoch: 49, Batch number: 52, Loss: 1215.9527587890625\n",
      "Epoch: 51, Batch number: 0, Loss: 1064.74560546875\n",
      "Epoch: 52, Batch number: 24, Loss: 1066.01904296875\n",
      "Epoch: 53, Batch number: 48, Loss: 990.3848876953125\n",
      "Epoch: 54, Batch number: 72, Loss: 1082.099853515625\n",
      "Epoch: 56, Batch number: 20, Loss: 941.7576904296875\n",
      "Epoch: 57, Batch number: 44, Loss: 940.3629150390625\n",
      "Epoch: 58, Batch number: 68, Loss: 945.3648681640625\n",
      "Epoch: 60, Batch number: 16, Loss: 892.3709716796875\n",
      "Epoch: 61, Batch number: 40, Loss: 885.0487060546875\n",
      "Epoch: 62, Batch number: 64, Loss: 954.0733032226562\n",
      "Epoch: 64, Batch number: 12, Loss: 815.0032958984375\n",
      "Epoch: 65, Batch number: 36, Loss: 763.7353515625\n",
      "Epoch: 66, Batch number: 60, Loss: 785.7548217773438\n",
      "Epoch: 68, Batch number: 8, Loss: 794.4256591796875\n",
      "Epoch: 69, Batch number: 32, Loss: 743.2738647460938\n",
      "Epoch: 70, Batch number: 56, Loss: 812.181396484375\n",
      "Epoch: 72, Batch number: 4, Loss: 703.6066284179688\n",
      "Epoch: 73, Batch number: 28, Loss: 761.42724609375\n",
      "Epoch: 74, Batch number: 52, Loss: 722.6882934570312\n",
      "Epoch: 76, Batch number: 0, Loss: 691.9295043945312\n",
      "Epoch: 77, Batch number: 24, Loss: 664.9847412109375\n",
      "Epoch: 78, Batch number: 48, Loss: 664.9703369140625\n",
      "Epoch: 79, Batch number: 72, Loss: 628.8505859375\n",
      "Epoch: 81, Batch number: 20, Loss: 687.8172607421875\n",
      "Epoch: 82, Batch number: 44, Loss: 649.6561889648438\n",
      "Epoch: 83, Batch number: 68, Loss: 657.9168701171875\n",
      "Epoch: 85, Batch number: 16, Loss: 549.283935546875\n",
      "Epoch: 86, Batch number: 40, Loss: 635.4298706054688\n",
      "Epoch: 87, Batch number: 64, Loss: 574.3101196289062\n",
      "Epoch: 89, Batch number: 12, Loss: 546.8907470703125\n",
      "Epoch: 90, Batch number: 36, Loss: 600.7374267578125\n",
      "Epoch: 91, Batch number: 60, Loss: 560.1488647460938\n",
      "Epoch: 93, Batch number: 8, Loss: 560.1243896484375\n",
      "Epoch: 94, Batch number: 32, Loss: 510.83673095703125\n",
      "Epoch: 95, Batch number: 56, Loss: 512.6654663085938\n",
      "Epoch: 97, Batch number: 4, Loss: 500.1518859863281\n",
      "Epoch: 98, Batch number: 28, Loss: 470.9195556640625\n",
      "Epoch: 99, Batch number: 52, Loss: 477.9765319824219\n",
      "Epoch: 101, Batch number: 0, Loss: 454.3789367675781\n",
      "Epoch: 102, Batch number: 24, Loss: 451.7809143066406\n",
      "Epoch: 103, Batch number: 48, Loss: 419.7759704589844\n",
      "Epoch: 104, Batch number: 72, Loss: 416.5255432128906\n",
      "Epoch: 106, Batch number: 20, Loss: 413.19573974609375\n",
      "Epoch: 107, Batch number: 44, Loss: 400.5347595214844\n",
      "Epoch: 108, Batch number: 68, Loss: 405.0574645996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 16, Loss: 373.6551818847656\n",
      "Epoch: 111, Batch number: 40, Loss: 440.40087890625\n",
      "Epoch: 112, Batch number: 64, Loss: 415.49365234375\n",
      "Epoch: 114, Batch number: 12, Loss: 368.81329345703125\n",
      "Epoch: 115, Batch number: 36, Loss: 392.0521545410156\n",
      "Epoch: 116, Batch number: 60, Loss: 365.14105224609375\n",
      "Epoch: 118, Batch number: 8, Loss: 341.829833984375\n",
      "Epoch: 119, Batch number: 32, Loss: 379.6281433105469\n",
      "Epoch: 120, Batch number: 56, Loss: 324.1636657714844\n",
      "Epoch: 122, Batch number: 4, Loss: 337.3331604003906\n",
      "Epoch: 123, Batch number: 28, Loss: 365.1316223144531\n",
      "Epoch: 124, Batch number: 52, Loss: 345.435791015625\n",
      "Epoch: 126, Batch number: 0, Loss: 314.5960693359375\n",
      "Epoch: 127, Batch number: 24, Loss: 316.3324279785156\n",
      "Epoch: 128, Batch number: 48, Loss: 294.7251892089844\n",
      "Epoch: 129, Batch number: 72, Loss: 308.685302734375\n",
      "Epoch: 131, Batch number: 20, Loss: 319.7208251953125\n",
      "Epoch: 132, Batch number: 44, Loss: 354.96923828125\n",
      "Epoch: 133, Batch number: 68, Loss: 275.2996520996094\n",
      "Epoch: 135, Batch number: 16, Loss: 268.69561767578125\n",
      "Epoch: 136, Batch number: 40, Loss: 328.22265625\n",
      "Epoch: 137, Batch number: 64, Loss: 257.2591857910156\n",
      "Epoch: 139, Batch number: 12, Loss: 244.8837432861328\n",
      "Epoch: 140, Batch number: 36, Loss: 272.70733642578125\n",
      "Epoch: 141, Batch number: 60, Loss: 276.96673583984375\n",
      "Epoch: 143, Batch number: 8, Loss: 248.9666290283203\n",
      "Epoch: 144, Batch number: 32, Loss: 266.86663818359375\n",
      "Epoch: 145, Batch number: 56, Loss: 236.16200256347656\n",
      "Epoch: 147, Batch number: 4, Loss: 291.7767333984375\n",
      "Epoch: 148, Batch number: 28, Loss: 235.34837341308594\n",
      "Epoch: 149, Batch number: 52, Loss: 243.30416870117188\n",
      "Epoch: 151, Batch number: 0, Loss: 235.0616912841797\n",
      "Epoch: 152, Batch number: 24, Loss: 216.82476806640625\n",
      "Epoch: 153, Batch number: 48, Loss: 227.8953094482422\n",
      "Epoch: 154, Batch number: 72, Loss: 224.01206970214844\n",
      "Epoch: 156, Batch number: 20, Loss: 219.53817749023438\n",
      "Epoch: 157, Batch number: 44, Loss: 214.5459747314453\n",
      "Epoch: 158, Batch number: 68, Loss: 207.73178100585938\n",
      "Epoch: 160, Batch number: 16, Loss: 196.2117156982422\n",
      "Epoch: 161, Batch number: 40, Loss: 211.7542724609375\n",
      "Epoch: 162, Batch number: 64, Loss: 206.02108764648438\n",
      "Epoch: 164, Batch number: 12, Loss: 220.71157836914062\n",
      "Epoch: 165, Batch number: 36, Loss: 215.444580078125\n",
      "Epoch: 166, Batch number: 60, Loss: 192.5298614501953\n",
      "Epoch: 168, Batch number: 8, Loss: 172.87322998046875\n",
      "Epoch: 169, Batch number: 32, Loss: 168.5271453857422\n",
      "Epoch: 170, Batch number: 56, Loss: 157.2476806640625\n",
      "Epoch: 172, Batch number: 4, Loss: 160.693359375\n",
      "Epoch: 173, Batch number: 28, Loss: 150.16310119628906\n",
      "Epoch: 174, Batch number: 52, Loss: 158.79872131347656\n",
      "Epoch: 176, Batch number: 0, Loss: 172.95616149902344\n",
      "Epoch: 177, Batch number: 24, Loss: 146.86209106445312\n",
      "Epoch: 178, Batch number: 48, Loss: 145.56292724609375\n",
      "Epoch: 179, Batch number: 72, Loss: 177.1703338623047\n",
      "Epoch: 181, Batch number: 20, Loss: 132.6002655029297\n",
      "Epoch: 182, Batch number: 44, Loss: 154.40321350097656\n",
      "Epoch: 183, Batch number: 68, Loss: 145.68295288085938\n",
      "Epoch: 185, Batch number: 16, Loss: 140.50914001464844\n",
      "Epoch: 186, Batch number: 40, Loss: 147.8460693359375\n",
      "Epoch: 187, Batch number: 64, Loss: 133.1720428466797\n",
      "Epoch: 189, Batch number: 12, Loss: 169.8296356201172\n",
      "Epoch: 190, Batch number: 36, Loss: 137.54776000976562\n",
      "Epoch: 191, Batch number: 60, Loss: 162.16940307617188\n",
      "Epoch: 193, Batch number: 8, Loss: 121.27655792236328\n",
      "Epoch: 194, Batch number: 32, Loss: 136.0955352783203\n",
      "Epoch: 195, Batch number: 56, Loss: 128.94732666015625\n",
      "Epoch: 197, Batch number: 4, Loss: 140.5309295654297\n",
      "Epoch: 198, Batch number: 28, Loss: 101.11739349365234\n",
      "Epoch: 199, Batch number: 52, Loss: 119.52336120605469\n",
      "Epoch: 201, Batch number: 0, Loss: 114.64146423339844\n",
      "Epoch: 202, Batch number: 24, Loss: 120.23074340820312\n",
      "Epoch: 203, Batch number: 48, Loss: 133.19972229003906\n",
      "Epoch: 204, Batch number: 72, Loss: 118.0440673828125\n",
      "Epoch: 206, Batch number: 20, Loss: 111.5676040649414\n",
      "Epoch: 207, Batch number: 44, Loss: 114.77135467529297\n",
      "Epoch: 208, Batch number: 68, Loss: 116.9885482788086\n",
      "Epoch: 210, Batch number: 16, Loss: 107.7667465209961\n",
      "Epoch: 211, Batch number: 40, Loss: 94.8618392944336\n",
      "Epoch: 212, Batch number: 64, Loss: 136.5656280517578\n",
      "Epoch: 214, Batch number: 12, Loss: 113.07440185546875\n",
      "Epoch: 215, Batch number: 36, Loss: 108.24114990234375\n",
      "Epoch: 216, Batch number: 60, Loss: 106.85442352294922\n",
      "Epoch: 218, Batch number: 8, Loss: 94.38131713867188\n",
      "Epoch: 219, Batch number: 32, Loss: 131.39498901367188\n",
      "Epoch: 220, Batch number: 56, Loss: 96.0408706665039\n",
      "Epoch: 222, Batch number: 4, Loss: 87.52417755126953\n",
      "Epoch: 223, Batch number: 28, Loss: 93.781005859375\n",
      "Epoch: 224, Batch number: 52, Loss: 98.96345520019531\n",
      "Epoch: 226, Batch number: 0, Loss: 79.23410034179688\n",
      "Epoch: 227, Batch number: 24, Loss: 88.76522064208984\n",
      "Epoch: 228, Batch number: 48, Loss: 87.93990325927734\n",
      "Epoch: 229, Batch number: 72, Loss: 107.84544372558594\n",
      "Epoch: 231, Batch number: 20, Loss: 82.37255859375\n",
      "Epoch: 232, Batch number: 44, Loss: 101.47718048095703\n",
      "Epoch: 233, Batch number: 68, Loss: 116.39002227783203\n",
      "Epoch: 235, Batch number: 16, Loss: 73.34245300292969\n",
      "Epoch: 236, Batch number: 40, Loss: 97.09693145751953\n",
      "Epoch: 237, Batch number: 64, Loss: 86.94071197509766\n",
      "Epoch: 239, Batch number: 12, Loss: 106.03855895996094\n",
      "Epoch: 240, Batch number: 36, Loss: 87.92045593261719\n",
      "Epoch: 241, Batch number: 60, Loss: 92.00465393066406\n",
      "Epoch: 243, Batch number: 8, Loss: 84.4556884765625\n",
      "Epoch: 244, Batch number: 32, Loss: 86.63519287109375\n",
      "Epoch: 245, Batch number: 56, Loss: 73.29093170166016\n",
      "Epoch: 247, Batch number: 4, Loss: 95.6710205078125\n",
      "Epoch: 248, Batch number: 28, Loss: 74.17483520507812\n",
      "Epoch: 249, Batch number: 52, Loss: 79.84089660644531\n",
      "Epoch: 251, Batch number: 0, Loss: 75.68046569824219\n",
      "Epoch: 252, Batch number: 24, Loss: 89.8689193725586\n",
      "Epoch: 253, Batch number: 48, Loss: 85.62136840820312\n",
      "Epoch: 254, Batch number: 72, Loss: 76.41931915283203\n",
      "Epoch: 256, Batch number: 20, Loss: 78.15734100341797\n",
      "Epoch: 257, Batch number: 44, Loss: 84.0467529296875\n",
      "Epoch: 258, Batch number: 68, Loss: 88.57646179199219\n",
      "Epoch: 260, Batch number: 16, Loss: 68.11167907714844\n",
      "Epoch: 261, Batch number: 40, Loss: 76.55130767822266\n",
      "Epoch: 262, Batch number: 64, Loss: 71.44662475585938\n",
      "Epoch: 264, Batch number: 12, Loss: 60.537139892578125\n",
      "Epoch: 265, Batch number: 36, Loss: 74.1712417602539\n",
      "Epoch: 266, Batch number: 60, Loss: 67.16283416748047\n",
      "Epoch: 268, Batch number: 8, Loss: 56.78896713256836\n",
      "Epoch: 269, Batch number: 32, Loss: 87.29471588134766\n",
      "Epoch: 270, Batch number: 56, Loss: 88.3434066772461\n",
      "Epoch: 272, Batch number: 4, Loss: 66.61266326904297\n",
      "Epoch: 273, Batch number: 28, Loss: 70.39518737792969\n",
      "Epoch: 274, Batch number: 52, Loss: 75.41573333740234\n",
      "Epoch: 276, Batch number: 0, Loss: 62.20244216918945\n",
      "Epoch: 277, Batch number: 24, Loss: 51.890525817871094\n",
      "Epoch: 278, Batch number: 48, Loss: 63.683555603027344\n",
      "Epoch: 279, Batch number: 72, Loss: 77.74981689453125\n",
      "Epoch: 281, Batch number: 20, Loss: 65.70879364013672\n",
      "Epoch: 282, Batch number: 44, Loss: 51.4415283203125\n",
      "Epoch: 283, Batch number: 68, Loss: 71.77182006835938\n",
      "Epoch: 285, Batch number: 16, Loss: 68.23800659179688\n",
      "Epoch: 286, Batch number: 40, Loss: 74.23878479003906\n",
      "Epoch: 287, Batch number: 64, Loss: 46.746734619140625\n",
      "Epoch: 289, Batch number: 12, Loss: 68.57665252685547\n",
      "Epoch: 290, Batch number: 36, Loss: 85.16755676269531\n",
      "Epoch: 291, Batch number: 60, Loss: 59.66173553466797\n",
      "Epoch: 293, Batch number: 8, Loss: 71.77755737304688\n",
      "Epoch: 294, Batch number: 32, Loss: 55.489532470703125\n",
      "Epoch: 295, Batch number: 56, Loss: 80.67384338378906\n",
      "Epoch: 297, Batch number: 4, Loss: 77.93772888183594\n",
      "Epoch: 298, Batch number: 28, Loss: 68.68721771240234\n",
      "Epoch: 299, Batch number: 52, Loss: 52.84407043457031\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4419.79443359375\n",
      "Epoch: 2, Batch number: 24, Loss: 4154.3408203125\n",
      "Epoch: 3, Batch number: 48, Loss: 3762.203125\n",
      "Epoch: 4, Batch number: 72, Loss: 3339.54736328125\n",
      "Epoch: 6, Batch number: 20, Loss: 2933.61669921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Batch number: 44, Loss: 2739.0146484375\n",
      "Epoch: 8, Batch number: 68, Loss: 2583.76806640625\n",
      "Epoch: 10, Batch number: 16, Loss: 2410.909912109375\n",
      "Epoch: 11, Batch number: 40, Loss: 2307.927978515625\n",
      "Epoch: 12, Batch number: 64, Loss: 2228.155029296875\n",
      "Epoch: 14, Batch number: 12, Loss: 2111.515869140625\n",
      "Epoch: 15, Batch number: 36, Loss: 2125.14794921875\n",
      "Epoch: 16, Batch number: 60, Loss: 1931.1309814453125\n",
      "Epoch: 18, Batch number: 8, Loss: 1898.404296875\n",
      "Epoch: 19, Batch number: 32, Loss: 1821.6326904296875\n",
      "Epoch: 20, Batch number: 56, Loss: 1812.2137451171875\n",
      "Epoch: 22, Batch number: 4, Loss: 1625.8779296875\n",
      "Epoch: 23, Batch number: 28, Loss: 1629.435791015625\n",
      "Epoch: 24, Batch number: 52, Loss: 1502.8023681640625\n",
      "Epoch: 26, Batch number: 0, Loss: 1540.477294921875\n",
      "Epoch: 27, Batch number: 24, Loss: 1457.628173828125\n",
      "Epoch: 28, Batch number: 48, Loss: 1432.98828125\n",
      "Epoch: 29, Batch number: 72, Loss: 1386.6290283203125\n",
      "Epoch: 31, Batch number: 20, Loss: 1257.9991455078125\n",
      "Epoch: 32, Batch number: 44, Loss: 1256.45703125\n",
      "Epoch: 33, Batch number: 68, Loss: 1214.6041259765625\n",
      "Epoch: 35, Batch number: 16, Loss: 1176.70556640625\n",
      "Epoch: 36, Batch number: 40, Loss: 1095.655029296875\n",
      "Epoch: 37, Batch number: 64, Loss: 1097.9932861328125\n",
      "Epoch: 39, Batch number: 12, Loss: 1020.7411499023438\n",
      "Epoch: 40, Batch number: 36, Loss: 951.2240600585938\n",
      "Epoch: 41, Batch number: 60, Loss: 960.4664306640625\n",
      "Epoch: 43, Batch number: 8, Loss: 907.4436645507812\n",
      "Epoch: 44, Batch number: 32, Loss: 814.4786376953125\n",
      "Epoch: 45, Batch number: 56, Loss: 849.8921508789062\n",
      "Epoch: 47, Batch number: 4, Loss: 858.3714599609375\n",
      "Epoch: 48, Batch number: 28, Loss: 851.518798828125\n",
      "Epoch: 49, Batch number: 52, Loss: 765.954833984375\n",
      "Epoch: 51, Batch number: 0, Loss: 745.8984985351562\n",
      "Epoch: 52, Batch number: 24, Loss: 739.3883666992188\n",
      "Epoch: 53, Batch number: 48, Loss: 754.423828125\n",
      "Epoch: 54, Batch number: 72, Loss: 688.07177734375\n",
      "Epoch: 56, Batch number: 20, Loss: 682.3330078125\n",
      "Epoch: 57, Batch number: 44, Loss: 637.4800415039062\n",
      "Epoch: 58, Batch number: 68, Loss: 646.2675170898438\n",
      "Epoch: 60, Batch number: 16, Loss: 569.870849609375\n",
      "Epoch: 61, Batch number: 40, Loss: 594.4491577148438\n",
      "Epoch: 62, Batch number: 64, Loss: 568.369140625\n",
      "Epoch: 64, Batch number: 12, Loss: 618.401123046875\n",
      "Epoch: 65, Batch number: 36, Loss: 621.9915161132812\n",
      "Epoch: 66, Batch number: 60, Loss: 582.7177734375\n",
      "Epoch: 68, Batch number: 8, Loss: 512.971923828125\n",
      "Epoch: 69, Batch number: 32, Loss: 492.522216796875\n",
      "Epoch: 70, Batch number: 56, Loss: 449.81658935546875\n",
      "Epoch: 72, Batch number: 4, Loss: 461.7391357421875\n",
      "Epoch: 73, Batch number: 28, Loss: 498.1033630371094\n",
      "Epoch: 74, Batch number: 52, Loss: 474.2156066894531\n",
      "Epoch: 76, Batch number: 0, Loss: 424.89898681640625\n",
      "Epoch: 77, Batch number: 24, Loss: 436.1257019042969\n",
      "Epoch: 78, Batch number: 48, Loss: 400.64349365234375\n",
      "Epoch: 79, Batch number: 72, Loss: 402.8998107910156\n",
      "Epoch: 81, Batch number: 20, Loss: 379.19635009765625\n",
      "Epoch: 82, Batch number: 44, Loss: 377.9203796386719\n",
      "Epoch: 83, Batch number: 68, Loss: 418.7647399902344\n",
      "Epoch: 85, Batch number: 16, Loss: 404.4456787109375\n",
      "Epoch: 86, Batch number: 40, Loss: 358.4187927246094\n",
      "Epoch: 87, Batch number: 64, Loss: 349.6109924316406\n",
      "Epoch: 89, Batch number: 12, Loss: 334.8296203613281\n",
      "Epoch: 90, Batch number: 36, Loss: 321.9596252441406\n",
      "Epoch: 91, Batch number: 60, Loss: 281.7320251464844\n",
      "Epoch: 93, Batch number: 8, Loss: 336.1549987792969\n",
      "Epoch: 94, Batch number: 32, Loss: 323.630126953125\n",
      "Epoch: 95, Batch number: 56, Loss: 303.5017395019531\n",
      "Epoch: 97, Batch number: 4, Loss: 310.038330078125\n",
      "Epoch: 98, Batch number: 28, Loss: 248.52191162109375\n",
      "Epoch: 99, Batch number: 52, Loss: 242.58189392089844\n",
      "Epoch: 101, Batch number: 0, Loss: 264.67626953125\n",
      "Epoch: 102, Batch number: 24, Loss: 252.0732879638672\n",
      "Epoch: 103, Batch number: 48, Loss: 254.05850219726562\n",
      "Epoch: 104, Batch number: 72, Loss: 234.69900512695312\n",
      "Epoch: 106, Batch number: 20, Loss: 240.71994018554688\n",
      "Epoch: 107, Batch number: 44, Loss: 246.87637329101562\n",
      "Epoch: 108, Batch number: 68, Loss: 253.39039611816406\n",
      "Epoch: 110, Batch number: 16, Loss: 247.39093017578125\n",
      "Epoch: 111, Batch number: 40, Loss: 253.57017517089844\n",
      "Epoch: 112, Batch number: 64, Loss: 207.86468505859375\n",
      "Epoch: 114, Batch number: 12, Loss: 189.11053466796875\n",
      "Epoch: 115, Batch number: 36, Loss: 212.83486938476562\n",
      "Epoch: 116, Batch number: 60, Loss: 187.59341430664062\n",
      "Epoch: 118, Batch number: 8, Loss: 188.99722290039062\n",
      "Epoch: 119, Batch number: 32, Loss: 170.66281127929688\n",
      "Epoch: 120, Batch number: 56, Loss: 209.90240478515625\n",
      "Epoch: 122, Batch number: 4, Loss: 182.76698303222656\n",
      "Epoch: 123, Batch number: 28, Loss: 178.7101287841797\n",
      "Epoch: 124, Batch number: 52, Loss: 179.5011749267578\n",
      "Epoch: 126, Batch number: 0, Loss: 140.79498291015625\n",
      "Epoch: 127, Batch number: 24, Loss: 167.8157196044922\n",
      "Epoch: 128, Batch number: 48, Loss: 160.40525817871094\n",
      "Epoch: 129, Batch number: 72, Loss: 166.89483642578125\n",
      "Epoch: 131, Batch number: 20, Loss: 161.09820556640625\n",
      "Epoch: 132, Batch number: 44, Loss: 166.28578186035156\n",
      "Epoch: 133, Batch number: 68, Loss: 149.0186767578125\n",
      "Epoch: 135, Batch number: 16, Loss: 142.72938537597656\n",
      "Epoch: 136, Batch number: 40, Loss: 159.77880859375\n",
      "Epoch: 137, Batch number: 64, Loss: 150.69119262695312\n",
      "Epoch: 139, Batch number: 12, Loss: 127.65624237060547\n",
      "Epoch: 140, Batch number: 36, Loss: 136.76080322265625\n",
      "Epoch: 141, Batch number: 60, Loss: 139.9352569580078\n",
      "Epoch: 143, Batch number: 8, Loss: 154.05419921875\n",
      "Epoch: 144, Batch number: 32, Loss: 149.65289306640625\n",
      "Epoch: 145, Batch number: 56, Loss: 129.78302001953125\n",
      "Epoch: 147, Batch number: 4, Loss: 102.32331848144531\n",
      "Epoch: 148, Batch number: 28, Loss: 135.4248809814453\n",
      "Epoch: 149, Batch number: 52, Loss: 130.59634399414062\n",
      "Epoch: 151, Batch number: 0, Loss: 99.56031799316406\n",
      "Epoch: 152, Batch number: 24, Loss: 121.1154556274414\n",
      "Epoch: 153, Batch number: 48, Loss: 131.63229370117188\n",
      "Epoch: 154, Batch number: 72, Loss: 107.43549346923828\n",
      "Epoch: 156, Batch number: 20, Loss: 108.67282104492188\n",
      "Epoch: 157, Batch number: 44, Loss: 104.23580169677734\n",
      "Epoch: 158, Batch number: 68, Loss: 108.91031646728516\n",
      "Epoch: 160, Batch number: 16, Loss: 89.255126953125\n",
      "Epoch: 161, Batch number: 40, Loss: 100.35916900634766\n",
      "Epoch: 162, Batch number: 64, Loss: 97.84013366699219\n",
      "Epoch: 164, Batch number: 12, Loss: 87.97442626953125\n",
      "Epoch: 165, Batch number: 36, Loss: 84.70744323730469\n",
      "Epoch: 166, Batch number: 60, Loss: 113.50881958007812\n",
      "Epoch: 168, Batch number: 8, Loss: 109.650634765625\n",
      "Epoch: 169, Batch number: 32, Loss: 86.3270492553711\n",
      "Epoch: 170, Batch number: 56, Loss: 79.21885681152344\n",
      "Epoch: 172, Batch number: 4, Loss: 102.55009460449219\n",
      "Epoch: 173, Batch number: 28, Loss: 93.7770767211914\n",
      "Epoch: 174, Batch number: 52, Loss: 75.21288299560547\n",
      "Epoch: 176, Batch number: 0, Loss: 87.6012954711914\n",
      "Epoch: 177, Batch number: 24, Loss: 106.99629974365234\n",
      "Epoch: 178, Batch number: 48, Loss: 77.51351928710938\n",
      "Epoch: 179, Batch number: 72, Loss: 78.07989501953125\n",
      "Epoch: 181, Batch number: 20, Loss: 82.9174575805664\n",
      "Epoch: 182, Batch number: 44, Loss: 80.39087677001953\n",
      "Epoch: 183, Batch number: 68, Loss: 79.1320571899414\n",
      "Epoch: 185, Batch number: 16, Loss: 67.77818298339844\n",
      "Epoch: 186, Batch number: 40, Loss: 83.66578674316406\n",
      "Epoch: 187, Batch number: 64, Loss: 92.49185943603516\n",
      "Epoch: 189, Batch number: 12, Loss: 84.27747344970703\n",
      "Epoch: 190, Batch number: 36, Loss: 84.35626983642578\n",
      "Epoch: 191, Batch number: 60, Loss: 73.23229217529297\n",
      "Epoch: 193, Batch number: 8, Loss: 64.0179672241211\n",
      "Epoch: 194, Batch number: 32, Loss: 87.28868865966797\n",
      "Epoch: 195, Batch number: 56, Loss: 82.58312225341797\n",
      "Epoch: 197, Batch number: 4, Loss: 73.15921020507812\n",
      "Epoch: 198, Batch number: 28, Loss: 72.70439910888672\n",
      "Epoch: 199, Batch number: 52, Loss: 53.94758605957031\n",
      "Epoch: 201, Batch number: 0, Loss: 64.05770111083984\n",
      "Epoch: 202, Batch number: 24, Loss: 83.52175903320312\n",
      "Epoch: 203, Batch number: 48, Loss: 80.86853790283203\n",
      "Epoch: 204, Batch number: 72, Loss: 84.0103759765625\n",
      "Epoch: 206, Batch number: 20, Loss: 72.54782104492188\n",
      "Epoch: 207, Batch number: 44, Loss: 85.35379028320312\n",
      "Epoch: 208, Batch number: 68, Loss: 69.7772216796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Batch number: 16, Loss: 66.1487045288086\n",
      "Epoch: 211, Batch number: 40, Loss: 71.86595916748047\n",
      "Epoch: 212, Batch number: 64, Loss: 80.49008178710938\n",
      "Epoch: 214, Batch number: 12, Loss: 56.83868408203125\n",
      "Epoch: 215, Batch number: 36, Loss: 63.957252502441406\n",
      "Epoch: 216, Batch number: 60, Loss: 70.75204467773438\n",
      "Epoch: 218, Batch number: 8, Loss: 61.96112823486328\n",
      "Epoch: 219, Batch number: 32, Loss: 60.23810958862305\n",
      "Epoch: 220, Batch number: 56, Loss: 71.56371307373047\n",
      "Epoch: 222, Batch number: 4, Loss: 55.96025085449219\n",
      "Epoch: 223, Batch number: 28, Loss: 67.40531158447266\n",
      "Epoch: 224, Batch number: 52, Loss: 85.57553100585938\n",
      "Epoch: 226, Batch number: 0, Loss: 59.713924407958984\n",
      "Epoch: 227, Batch number: 24, Loss: 59.62932205200195\n",
      "Epoch: 228, Batch number: 48, Loss: 74.10137176513672\n",
      "Epoch: 229, Batch number: 72, Loss: 60.356712341308594\n",
      "Epoch: 231, Batch number: 20, Loss: 70.97769165039062\n",
      "Epoch: 232, Batch number: 44, Loss: 53.177520751953125\n",
      "Epoch: 233, Batch number: 68, Loss: 76.11690521240234\n",
      "Epoch: 235, Batch number: 16, Loss: 60.816864013671875\n",
      "Epoch: 236, Batch number: 40, Loss: 73.3708724975586\n",
      "Epoch: 237, Batch number: 64, Loss: 64.0823745727539\n",
      "Epoch: 239, Batch number: 12, Loss: 62.358909606933594\n",
      "Epoch: 240, Batch number: 36, Loss: 70.60812377929688\n",
      "Epoch: 241, Batch number: 60, Loss: 72.43862915039062\n",
      "Epoch: 243, Batch number: 8, Loss: 54.27301788330078\n",
      "Epoch: 244, Batch number: 32, Loss: 50.543968200683594\n",
      "Epoch: 245, Batch number: 56, Loss: 70.4025650024414\n",
      "Epoch: 247, Batch number: 4, Loss: 53.748992919921875\n",
      "Epoch: 248, Batch number: 28, Loss: 61.65424728393555\n",
      "Epoch: 249, Batch number: 52, Loss: 43.48935317993164\n",
      "Epoch: 251, Batch number: 0, Loss: 57.268489837646484\n",
      "Epoch: 252, Batch number: 24, Loss: 54.43110275268555\n",
      "Epoch: 253, Batch number: 48, Loss: 55.33464431762695\n",
      "Epoch: 254, Batch number: 72, Loss: 58.13436508178711\n",
      "Epoch: 256, Batch number: 20, Loss: 58.09929275512695\n",
      "Epoch: 257, Batch number: 44, Loss: 51.42185974121094\n",
      "Epoch: 258, Batch number: 68, Loss: 51.431114196777344\n",
      "Epoch: 260, Batch number: 16, Loss: 54.38441848754883\n",
      "Epoch: 261, Batch number: 40, Loss: 52.2877197265625\n",
      "Epoch: 262, Batch number: 64, Loss: 71.75639343261719\n",
      "Epoch: 264, Batch number: 12, Loss: 56.47216796875\n",
      "Epoch: 265, Batch number: 36, Loss: 45.68787384033203\n",
      "Epoch: 266, Batch number: 60, Loss: 68.57041931152344\n",
      "Epoch: 268, Batch number: 8, Loss: 59.086971282958984\n",
      "Epoch: 269, Batch number: 32, Loss: 43.39507293701172\n",
      "Epoch: 270, Batch number: 56, Loss: 76.01811218261719\n",
      "Epoch: 272, Batch number: 4, Loss: 49.211280822753906\n",
      "Epoch: 273, Batch number: 28, Loss: 53.84224319458008\n",
      "Epoch: 274, Batch number: 52, Loss: 61.60453796386719\n",
      "Epoch: 276, Batch number: 0, Loss: 55.594200134277344\n",
      "Epoch: 277, Batch number: 24, Loss: 56.13422393798828\n",
      "Epoch: 278, Batch number: 48, Loss: 47.4034538269043\n",
      "Epoch: 279, Batch number: 72, Loss: 51.019371032714844\n",
      "Epoch: 281, Batch number: 20, Loss: 50.64531707763672\n",
      "Epoch: 282, Batch number: 44, Loss: 42.080535888671875\n",
      "Epoch: 283, Batch number: 68, Loss: 58.627281188964844\n",
      "Epoch: 285, Batch number: 16, Loss: 43.72386932373047\n",
      "Epoch: 286, Batch number: 40, Loss: 42.70698928833008\n",
      "Epoch: 287, Batch number: 64, Loss: 53.81415557861328\n",
      "Epoch: 289, Batch number: 12, Loss: 43.4419059753418\n",
      "Epoch: 290, Batch number: 36, Loss: 49.055091857910156\n",
      "Epoch: 291, Batch number: 60, Loss: 55.77037048339844\n",
      "Epoch: 293, Batch number: 8, Loss: 51.70733642578125\n",
      "Epoch: 294, Batch number: 32, Loss: 60.18456268310547\n",
      "Epoch: 295, Batch number: 56, Loss: 40.10572052001953\n",
      "Epoch: 297, Batch number: 4, Loss: 52.17253112792969\n",
      "Epoch: 298, Batch number: 28, Loss: 56.90888977050781\n",
      "Epoch: 299, Batch number: 52, Loss: 46.35859680175781\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4416.9033203125\n",
      "Epoch: 2, Batch number: 24, Loss: 4056.08349609375\n",
      "Epoch: 3, Batch number: 48, Loss: 3620.605224609375\n",
      "Epoch: 4, Batch number: 72, Loss: 3063.388916015625\n",
      "Epoch: 6, Batch number: 20, Loss: 2700.88232421875\n",
      "Epoch: 7, Batch number: 44, Loss: 2425.787353515625\n",
      "Epoch: 8, Batch number: 68, Loss: 2467.1591796875\n",
      "Epoch: 10, Batch number: 16, Loss: 2300.168212890625\n",
      "Epoch: 11, Batch number: 40, Loss: 2277.8447265625\n",
      "Epoch: 12, Batch number: 64, Loss: 2121.8798828125\n",
      "Epoch: 14, Batch number: 12, Loss: 1935.69873046875\n",
      "Epoch: 15, Batch number: 36, Loss: 1867.6710205078125\n",
      "Epoch: 16, Batch number: 60, Loss: 1752.771240234375\n",
      "Epoch: 18, Batch number: 8, Loss: 1670.9820556640625\n",
      "Epoch: 19, Batch number: 32, Loss: 1537.347412109375\n",
      "Epoch: 20, Batch number: 56, Loss: 1552.260009765625\n",
      "Epoch: 22, Batch number: 4, Loss: 1410.995361328125\n",
      "Epoch: 23, Batch number: 28, Loss: 1412.73828125\n",
      "Epoch: 24, Batch number: 52, Loss: 1376.912841796875\n",
      "Epoch: 26, Batch number: 0, Loss: 1265.71240234375\n",
      "Epoch: 27, Batch number: 24, Loss: 1186.906494140625\n",
      "Epoch: 28, Batch number: 48, Loss: 1126.9659423828125\n",
      "Epoch: 29, Batch number: 72, Loss: 1073.1136474609375\n",
      "Epoch: 31, Batch number: 20, Loss: 1011.7186889648438\n",
      "Epoch: 32, Batch number: 44, Loss: 1014.18505859375\n",
      "Epoch: 33, Batch number: 68, Loss: 958.8515625\n",
      "Epoch: 35, Batch number: 16, Loss: 915.8958129882812\n",
      "Epoch: 36, Batch number: 40, Loss: 834.2142333984375\n",
      "Epoch: 37, Batch number: 64, Loss: 874.0508422851562\n",
      "Epoch: 39, Batch number: 12, Loss: 801.1849365234375\n",
      "Epoch: 40, Batch number: 36, Loss: 769.1245727539062\n",
      "Epoch: 41, Batch number: 60, Loss: 735.822998046875\n",
      "Epoch: 43, Batch number: 8, Loss: 707.3492431640625\n",
      "Epoch: 44, Batch number: 32, Loss: 688.694091796875\n",
      "Epoch: 45, Batch number: 56, Loss: 682.43701171875\n",
      "Epoch: 47, Batch number: 4, Loss: 575.9029541015625\n",
      "Epoch: 48, Batch number: 28, Loss: 623.6553955078125\n",
      "Epoch: 49, Batch number: 52, Loss: 626.5178833007812\n",
      "Epoch: 51, Batch number: 0, Loss: 557.0667114257812\n",
      "Epoch: 52, Batch number: 24, Loss: 598.632080078125\n",
      "Epoch: 53, Batch number: 48, Loss: 531.749755859375\n",
      "Epoch: 54, Batch number: 72, Loss: 543.9088134765625\n",
      "Epoch: 56, Batch number: 20, Loss: 478.13470458984375\n",
      "Epoch: 57, Batch number: 44, Loss: 453.3971862792969\n",
      "Epoch: 58, Batch number: 68, Loss: 514.5549926757812\n",
      "Epoch: 60, Batch number: 16, Loss: 451.2479553222656\n",
      "Epoch: 61, Batch number: 40, Loss: 453.57696533203125\n",
      "Epoch: 62, Batch number: 64, Loss: 429.2881164550781\n",
      "Epoch: 64, Batch number: 12, Loss: 447.8407897949219\n",
      "Epoch: 65, Batch number: 36, Loss: 389.31512451171875\n",
      "Epoch: 66, Batch number: 60, Loss: 422.0051574707031\n",
      "Epoch: 68, Batch number: 8, Loss: 355.8003845214844\n",
      "Epoch: 69, Batch number: 32, Loss: 338.0496520996094\n",
      "Epoch: 70, Batch number: 56, Loss: 344.1235656738281\n",
      "Epoch: 72, Batch number: 4, Loss: 308.0086669921875\n",
      "Epoch: 73, Batch number: 28, Loss: 326.9360656738281\n",
      "Epoch: 74, Batch number: 52, Loss: 296.3609924316406\n",
      "Epoch: 76, Batch number: 0, Loss: 358.6175537109375\n",
      "Epoch: 77, Batch number: 24, Loss: 306.55731201171875\n",
      "Epoch: 78, Batch number: 48, Loss: 290.2565002441406\n",
      "Epoch: 79, Batch number: 72, Loss: 272.1712341308594\n",
      "Epoch: 81, Batch number: 20, Loss: 251.7022247314453\n",
      "Epoch: 82, Batch number: 44, Loss: 255.13172912597656\n",
      "Epoch: 83, Batch number: 68, Loss: 267.2189025878906\n",
      "Epoch: 85, Batch number: 16, Loss: 275.48529052734375\n",
      "Epoch: 86, Batch number: 40, Loss: 215.49468994140625\n",
      "Epoch: 87, Batch number: 64, Loss: 223.43817138671875\n",
      "Epoch: 89, Batch number: 12, Loss: 204.01791381835938\n",
      "Epoch: 90, Batch number: 36, Loss: 199.5315399169922\n",
      "Epoch: 91, Batch number: 60, Loss: 246.6468505859375\n",
      "Epoch: 93, Batch number: 8, Loss: 229.81509399414062\n",
      "Epoch: 94, Batch number: 32, Loss: 187.8013916015625\n",
      "Epoch: 95, Batch number: 56, Loss: 185.47125244140625\n",
      "Epoch: 97, Batch number: 4, Loss: 174.78518676757812\n",
      "Epoch: 98, Batch number: 28, Loss: 165.88235473632812\n",
      "Epoch: 99, Batch number: 52, Loss: 181.13662719726562\n",
      "Epoch: 101, Batch number: 0, Loss: 162.3660888671875\n",
      "Epoch: 102, Batch number: 24, Loss: 211.57568359375\n",
      "Epoch: 103, Batch number: 48, Loss: 175.61236572265625\n",
      "Epoch: 104, Batch number: 72, Loss: 162.4594268798828\n",
      "Epoch: 106, Batch number: 20, Loss: 147.4261932373047\n",
      "Epoch: 107, Batch number: 44, Loss: 167.34552001953125\n",
      "Epoch: 108, Batch number: 68, Loss: 156.36181640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 16, Loss: 143.38792419433594\n",
      "Epoch: 111, Batch number: 40, Loss: 131.06451416015625\n",
      "Epoch: 112, Batch number: 64, Loss: 154.00572204589844\n",
      "Epoch: 114, Batch number: 12, Loss: 123.07542419433594\n",
      "Epoch: 115, Batch number: 36, Loss: 127.19145965576172\n",
      "Epoch: 116, Batch number: 60, Loss: 121.90693664550781\n",
      "Epoch: 118, Batch number: 8, Loss: 130.57244873046875\n",
      "Epoch: 119, Batch number: 32, Loss: 156.89175415039062\n",
      "Epoch: 120, Batch number: 56, Loss: 126.46786499023438\n",
      "Epoch: 122, Batch number: 4, Loss: 116.24615478515625\n",
      "Epoch: 123, Batch number: 28, Loss: 129.58937072753906\n",
      "Epoch: 124, Batch number: 52, Loss: 119.58103942871094\n",
      "Epoch: 126, Batch number: 0, Loss: 106.81123352050781\n",
      "Epoch: 127, Batch number: 24, Loss: 113.03765869140625\n",
      "Epoch: 128, Batch number: 48, Loss: 129.98008728027344\n",
      "Epoch: 129, Batch number: 72, Loss: 112.50222778320312\n",
      "Epoch: 131, Batch number: 20, Loss: 116.2191390991211\n",
      "Epoch: 132, Batch number: 44, Loss: 130.43997192382812\n",
      "Epoch: 133, Batch number: 68, Loss: 99.92544555664062\n",
      "Epoch: 135, Batch number: 16, Loss: 89.79125213623047\n",
      "Epoch: 136, Batch number: 40, Loss: 93.12242126464844\n",
      "Epoch: 137, Batch number: 64, Loss: 101.39189910888672\n",
      "Epoch: 139, Batch number: 12, Loss: 103.60020446777344\n",
      "Epoch: 140, Batch number: 36, Loss: 85.67703247070312\n",
      "Epoch: 141, Batch number: 60, Loss: 75.41253662109375\n",
      "Epoch: 143, Batch number: 8, Loss: 97.11031341552734\n",
      "Epoch: 144, Batch number: 32, Loss: 88.47605895996094\n",
      "Epoch: 145, Batch number: 56, Loss: 106.01316833496094\n",
      "Epoch: 147, Batch number: 4, Loss: 81.36981964111328\n",
      "Epoch: 148, Batch number: 28, Loss: 97.36498260498047\n",
      "Epoch: 149, Batch number: 52, Loss: 104.6345443725586\n",
      "Epoch: 151, Batch number: 0, Loss: 77.83146667480469\n",
      "Epoch: 152, Batch number: 24, Loss: 88.56062316894531\n",
      "Epoch: 153, Batch number: 48, Loss: 79.17528533935547\n",
      "Epoch: 154, Batch number: 72, Loss: 89.13286590576172\n",
      "Epoch: 156, Batch number: 20, Loss: 86.88550567626953\n",
      "Epoch: 157, Batch number: 44, Loss: 64.51921844482422\n",
      "Epoch: 158, Batch number: 68, Loss: 110.26460266113281\n",
      "Epoch: 160, Batch number: 16, Loss: 92.97657012939453\n",
      "Epoch: 161, Batch number: 40, Loss: 71.29501342773438\n",
      "Epoch: 162, Batch number: 64, Loss: 83.55046081542969\n",
      "Epoch: 164, Batch number: 12, Loss: 77.75983428955078\n",
      "Epoch: 165, Batch number: 36, Loss: 86.41255950927734\n",
      "Epoch: 166, Batch number: 60, Loss: 101.26063537597656\n",
      "Epoch: 168, Batch number: 8, Loss: 70.70401763916016\n",
      "Epoch: 169, Batch number: 32, Loss: 89.69424438476562\n",
      "Epoch: 170, Batch number: 56, Loss: 81.49555969238281\n",
      "Epoch: 172, Batch number: 4, Loss: 78.3498764038086\n",
      "Epoch: 173, Batch number: 28, Loss: 58.805355072021484\n",
      "Epoch: 174, Batch number: 52, Loss: 86.87699890136719\n",
      "Epoch: 176, Batch number: 0, Loss: 71.8795394897461\n",
      "Epoch: 177, Batch number: 24, Loss: 66.53669738769531\n",
      "Epoch: 178, Batch number: 48, Loss: 89.92141723632812\n",
      "Epoch: 179, Batch number: 72, Loss: 63.11440658569336\n",
      "Epoch: 181, Batch number: 20, Loss: 64.31700897216797\n",
      "Epoch: 182, Batch number: 44, Loss: 61.520729064941406\n",
      "Epoch: 183, Batch number: 68, Loss: 61.08158874511719\n",
      "Epoch: 185, Batch number: 16, Loss: 67.31755065917969\n",
      "Epoch: 186, Batch number: 40, Loss: 58.45515441894531\n",
      "Epoch: 187, Batch number: 64, Loss: 82.82252502441406\n",
      "Epoch: 189, Batch number: 12, Loss: 59.25464630126953\n",
      "Epoch: 190, Batch number: 36, Loss: 60.39387512207031\n",
      "Epoch: 191, Batch number: 60, Loss: 76.26880645751953\n",
      "Epoch: 193, Batch number: 8, Loss: 55.83856201171875\n",
      "Epoch: 194, Batch number: 32, Loss: 60.9257926940918\n",
      "Epoch: 195, Batch number: 56, Loss: 55.74945068359375\n",
      "Epoch: 197, Batch number: 4, Loss: 57.535972595214844\n",
      "Epoch: 198, Batch number: 28, Loss: 60.40544891357422\n",
      "Epoch: 199, Batch number: 52, Loss: 69.68612670898438\n",
      "Epoch: 201, Batch number: 0, Loss: 59.81954574584961\n",
      "Epoch: 202, Batch number: 24, Loss: 66.19434356689453\n",
      "Epoch: 203, Batch number: 48, Loss: 73.69095611572266\n",
      "Epoch: 204, Batch number: 72, Loss: 60.450496673583984\n",
      "Epoch: 206, Batch number: 20, Loss: 71.75847625732422\n",
      "Epoch: 207, Batch number: 44, Loss: 70.91836547851562\n",
      "Epoch: 208, Batch number: 68, Loss: 69.65713500976562\n",
      "Epoch: 210, Batch number: 16, Loss: 46.560264587402344\n",
      "Epoch: 211, Batch number: 40, Loss: 70.68136596679688\n",
      "Epoch: 212, Batch number: 64, Loss: 71.9194107055664\n",
      "Epoch: 214, Batch number: 12, Loss: 60.23049545288086\n",
      "Epoch: 215, Batch number: 36, Loss: 63.264305114746094\n",
      "Epoch: 216, Batch number: 60, Loss: 78.40320587158203\n",
      "Epoch: 218, Batch number: 8, Loss: 50.683013916015625\n",
      "Epoch: 219, Batch number: 32, Loss: 59.12702178955078\n",
      "Epoch: 220, Batch number: 56, Loss: 50.7642822265625\n",
      "Epoch: 222, Batch number: 4, Loss: 70.36659240722656\n",
      "Epoch: 223, Batch number: 28, Loss: 59.977821350097656\n",
      "Epoch: 224, Batch number: 52, Loss: 63.755191802978516\n",
      "Epoch: 226, Batch number: 0, Loss: 67.46292114257812\n",
      "Epoch: 227, Batch number: 24, Loss: 67.33133697509766\n",
      "Epoch: 228, Batch number: 48, Loss: 61.04668045043945\n",
      "Epoch: 229, Batch number: 72, Loss: 60.69163131713867\n",
      "Epoch: 231, Batch number: 20, Loss: 63.658626556396484\n",
      "Epoch: 232, Batch number: 44, Loss: 61.349212646484375\n",
      "Epoch: 233, Batch number: 68, Loss: 59.805355072021484\n",
      "Epoch: 235, Batch number: 16, Loss: 56.80485534667969\n",
      "Epoch: 236, Batch number: 40, Loss: 29.831405639648438\n",
      "Epoch: 237, Batch number: 64, Loss: 51.939266204833984\n",
      "Epoch: 239, Batch number: 12, Loss: 45.799781799316406\n",
      "Epoch: 240, Batch number: 36, Loss: 61.170780181884766\n",
      "Epoch: 241, Batch number: 60, Loss: 87.70374298095703\n",
      "Epoch: 243, Batch number: 8, Loss: 53.105655670166016\n",
      "Epoch: 244, Batch number: 32, Loss: 56.954410552978516\n",
      "Epoch: 245, Batch number: 56, Loss: 45.852134704589844\n",
      "Epoch: 247, Batch number: 4, Loss: 46.56574249267578\n",
      "Epoch: 248, Batch number: 28, Loss: 47.7298583984375\n",
      "Epoch: 249, Batch number: 52, Loss: 54.814720153808594\n",
      "Epoch: 251, Batch number: 0, Loss: 47.669219970703125\n",
      "Epoch: 252, Batch number: 24, Loss: 52.15098571777344\n",
      "Epoch: 253, Batch number: 48, Loss: 52.65431213378906\n",
      "Epoch: 254, Batch number: 72, Loss: 59.669044494628906\n",
      "Epoch: 256, Batch number: 20, Loss: 51.936439514160156\n",
      "Epoch: 257, Batch number: 44, Loss: 44.22964859008789\n",
      "Epoch: 258, Batch number: 68, Loss: 53.59273147583008\n",
      "Epoch: 260, Batch number: 16, Loss: 46.28823471069336\n",
      "Epoch: 261, Batch number: 40, Loss: 52.248817443847656\n",
      "Epoch: 262, Batch number: 64, Loss: 56.31421661376953\n",
      "Epoch: 264, Batch number: 12, Loss: 45.50989532470703\n",
      "Epoch: 265, Batch number: 36, Loss: 50.63328552246094\n",
      "Epoch: 266, Batch number: 60, Loss: 54.82462692260742\n",
      "Epoch: 268, Batch number: 8, Loss: 48.487239837646484\n",
      "Epoch: 269, Batch number: 32, Loss: 36.17728042602539\n",
      "Epoch: 270, Batch number: 56, Loss: 56.81120681762695\n",
      "Epoch: 272, Batch number: 4, Loss: 72.29478454589844\n",
      "Epoch: 273, Batch number: 28, Loss: 58.787010192871094\n",
      "Epoch: 274, Batch number: 52, Loss: 51.061492919921875\n",
      "Epoch: 276, Batch number: 0, Loss: 53.26615905761719\n",
      "Epoch: 277, Batch number: 24, Loss: 39.327919006347656\n",
      "Epoch: 278, Batch number: 48, Loss: 49.874698638916016\n",
      "Epoch: 279, Batch number: 72, Loss: 53.824195861816406\n",
      "Epoch: 281, Batch number: 20, Loss: 43.56879806518555\n",
      "Epoch: 282, Batch number: 44, Loss: 61.35554504394531\n",
      "Epoch: 283, Batch number: 68, Loss: 65.35211944580078\n",
      "Epoch: 285, Batch number: 16, Loss: 54.38444137573242\n",
      "Epoch: 286, Batch number: 40, Loss: 50.95026397705078\n",
      "Epoch: 287, Batch number: 64, Loss: 51.385337829589844\n",
      "Epoch: 289, Batch number: 12, Loss: 47.76002502441406\n",
      "Epoch: 290, Batch number: 36, Loss: 62.402915954589844\n",
      "Epoch: 291, Batch number: 60, Loss: 54.91223907470703\n",
      "Epoch: 293, Batch number: 8, Loss: 47.66441345214844\n",
      "Epoch: 294, Batch number: 32, Loss: 43.44947052001953\n",
      "Epoch: 295, Batch number: 56, Loss: 46.64472198486328\n",
      "Epoch: 297, Batch number: 4, Loss: 61.30834197998047\n",
      "Epoch: 298, Batch number: 28, Loss: 54.59716033935547\n",
      "Epoch: 299, Batch number: 52, Loss: 42.833106994628906\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4398.8212890625\n",
      "Epoch: 2, Batch number: 24, Loss: 3905.4150390625\n",
      "Epoch: 3, Batch number: 48, Loss: 3313.118408203125\n",
      "Epoch: 4, Batch number: 72, Loss: 2875.33154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Batch number: 20, Loss: 2485.947998046875\n",
      "Epoch: 7, Batch number: 44, Loss: 2307.02880859375\n",
      "Epoch: 8, Batch number: 68, Loss: 2115.986328125\n",
      "Epoch: 10, Batch number: 16, Loss: 2032.0400390625\n",
      "Epoch: 11, Batch number: 40, Loss: 1911.1064453125\n",
      "Epoch: 12, Batch number: 64, Loss: 1736.1317138671875\n",
      "Epoch: 14, Batch number: 12, Loss: 1621.7001953125\n",
      "Epoch: 15, Batch number: 36, Loss: 1495.48828125\n",
      "Epoch: 16, Batch number: 60, Loss: 1472.3026123046875\n",
      "Epoch: 18, Batch number: 8, Loss: 1227.8343505859375\n",
      "Epoch: 19, Batch number: 32, Loss: 1340.82373046875\n",
      "Epoch: 20, Batch number: 56, Loss: 1209.3167724609375\n",
      "Epoch: 22, Batch number: 4, Loss: 1005.2872924804688\n",
      "Epoch: 23, Batch number: 28, Loss: 984.4849853515625\n",
      "Epoch: 24, Batch number: 52, Loss: 930.751953125\n",
      "Epoch: 26, Batch number: 0, Loss: 889.8583374023438\n",
      "Epoch: 27, Batch number: 24, Loss: 912.5494384765625\n",
      "Epoch: 28, Batch number: 48, Loss: 799.0283203125\n",
      "Epoch: 29, Batch number: 72, Loss: 813.641845703125\n",
      "Epoch: 31, Batch number: 20, Loss: 729.4566650390625\n",
      "Epoch: 32, Batch number: 44, Loss: 733.9779052734375\n",
      "Epoch: 33, Batch number: 68, Loss: 638.354736328125\n",
      "Epoch: 35, Batch number: 16, Loss: 565.7991333007812\n",
      "Epoch: 36, Batch number: 40, Loss: 638.815185546875\n",
      "Epoch: 37, Batch number: 64, Loss: 612.6152954101562\n",
      "Epoch: 39, Batch number: 12, Loss: 487.8136291503906\n",
      "Epoch: 40, Batch number: 36, Loss: 502.6120300292969\n",
      "Epoch: 41, Batch number: 60, Loss: 489.9065246582031\n",
      "Epoch: 43, Batch number: 8, Loss: 449.2110290527344\n",
      "Epoch: 44, Batch number: 32, Loss: 441.1761169433594\n",
      "Epoch: 45, Batch number: 56, Loss: 410.01312255859375\n",
      "Epoch: 47, Batch number: 4, Loss: 386.1112060546875\n",
      "Epoch: 48, Batch number: 28, Loss: 381.15777587890625\n",
      "Epoch: 49, Batch number: 52, Loss: 405.4977722167969\n",
      "Epoch: 51, Batch number: 0, Loss: 357.31048583984375\n",
      "Epoch: 52, Batch number: 24, Loss: 336.5533447265625\n",
      "Epoch: 53, Batch number: 48, Loss: 341.876220703125\n",
      "Epoch: 54, Batch number: 72, Loss: 310.6702575683594\n",
      "Epoch: 56, Batch number: 20, Loss: 273.8407897949219\n",
      "Epoch: 57, Batch number: 44, Loss: 336.64111328125\n",
      "Epoch: 58, Batch number: 68, Loss: 298.5615539550781\n",
      "Epoch: 60, Batch number: 16, Loss: 319.7158508300781\n",
      "Epoch: 61, Batch number: 40, Loss: 251.2853546142578\n",
      "Epoch: 62, Batch number: 64, Loss: 243.70285034179688\n",
      "Epoch: 64, Batch number: 12, Loss: 241.87396240234375\n",
      "Epoch: 65, Batch number: 36, Loss: 257.56842041015625\n",
      "Epoch: 66, Batch number: 60, Loss: 226.5553436279297\n",
      "Epoch: 68, Batch number: 8, Loss: 242.00631713867188\n",
      "Epoch: 69, Batch number: 32, Loss: 229.84866333007812\n",
      "Epoch: 70, Batch number: 56, Loss: 217.73089599609375\n",
      "Epoch: 72, Batch number: 4, Loss: 167.0994873046875\n",
      "Epoch: 73, Batch number: 28, Loss: 169.77557373046875\n",
      "Epoch: 74, Batch number: 52, Loss: 194.280517578125\n",
      "Epoch: 76, Batch number: 0, Loss: 167.4636993408203\n",
      "Epoch: 77, Batch number: 24, Loss: 164.1009979248047\n",
      "Epoch: 78, Batch number: 48, Loss: 161.06201171875\n",
      "Epoch: 79, Batch number: 72, Loss: 205.32518005371094\n",
      "Epoch: 81, Batch number: 20, Loss: 157.61141967773438\n",
      "Epoch: 82, Batch number: 44, Loss: 149.6996612548828\n",
      "Epoch: 83, Batch number: 68, Loss: 138.1049346923828\n",
      "Epoch: 85, Batch number: 16, Loss: 148.91256713867188\n",
      "Epoch: 86, Batch number: 40, Loss: 136.16937255859375\n",
      "Epoch: 87, Batch number: 64, Loss: 151.812255859375\n",
      "Epoch: 89, Batch number: 12, Loss: 142.00595092773438\n",
      "Epoch: 90, Batch number: 36, Loss: 135.3440399169922\n",
      "Epoch: 91, Batch number: 60, Loss: 115.8289794921875\n",
      "Epoch: 93, Batch number: 8, Loss: 134.19198608398438\n",
      "Epoch: 94, Batch number: 32, Loss: 116.32177734375\n",
      "Epoch: 95, Batch number: 56, Loss: 96.16319274902344\n",
      "Epoch: 97, Batch number: 4, Loss: 118.98851776123047\n",
      "Epoch: 98, Batch number: 28, Loss: 99.57687377929688\n",
      "Epoch: 99, Batch number: 52, Loss: 133.53085327148438\n",
      "Epoch: 101, Batch number: 0, Loss: 105.43934631347656\n",
      "Epoch: 102, Batch number: 24, Loss: 109.60839080810547\n",
      "Epoch: 103, Batch number: 48, Loss: 109.41629791259766\n",
      "Epoch: 104, Batch number: 72, Loss: 95.71721649169922\n",
      "Epoch: 106, Batch number: 20, Loss: 108.28533172607422\n",
      "Epoch: 107, Batch number: 44, Loss: 113.0673828125\n",
      "Epoch: 108, Batch number: 68, Loss: 94.14744567871094\n",
      "Epoch: 110, Batch number: 16, Loss: 95.95875549316406\n",
      "Epoch: 111, Batch number: 40, Loss: 122.32019805908203\n",
      "Epoch: 112, Batch number: 64, Loss: 99.2630386352539\n",
      "Epoch: 114, Batch number: 12, Loss: 85.98260498046875\n",
      "Epoch: 115, Batch number: 36, Loss: 105.46951293945312\n",
      "Epoch: 116, Batch number: 60, Loss: 97.67704772949219\n",
      "Epoch: 118, Batch number: 8, Loss: 69.25909423828125\n",
      "Epoch: 119, Batch number: 32, Loss: 71.26136779785156\n",
      "Epoch: 120, Batch number: 56, Loss: 121.81214904785156\n",
      "Epoch: 122, Batch number: 4, Loss: 93.34800720214844\n",
      "Epoch: 123, Batch number: 28, Loss: 49.46702575683594\n",
      "Epoch: 124, Batch number: 52, Loss: 89.8677978515625\n",
      "Epoch: 126, Batch number: 0, Loss: 61.90947341918945\n",
      "Epoch: 127, Batch number: 24, Loss: 85.02631378173828\n",
      "Epoch: 128, Batch number: 48, Loss: 93.36970520019531\n",
      "Epoch: 129, Batch number: 72, Loss: 68.857666015625\n",
      "Epoch: 131, Batch number: 20, Loss: 67.22422790527344\n",
      "Epoch: 132, Batch number: 44, Loss: 69.29177856445312\n",
      "Epoch: 133, Batch number: 68, Loss: 88.1307601928711\n",
      "Epoch: 135, Batch number: 16, Loss: 74.82994079589844\n",
      "Epoch: 136, Batch number: 40, Loss: 77.72599792480469\n",
      "Epoch: 137, Batch number: 64, Loss: 98.10404205322266\n",
      "Epoch: 139, Batch number: 12, Loss: 68.65646362304688\n",
      "Epoch: 140, Batch number: 36, Loss: 80.65686798095703\n",
      "Epoch: 141, Batch number: 60, Loss: 71.91126251220703\n",
      "Epoch: 143, Batch number: 8, Loss: 60.850852966308594\n",
      "Epoch: 144, Batch number: 32, Loss: 87.59298706054688\n",
      "Epoch: 145, Batch number: 56, Loss: 60.20848083496094\n",
      "Epoch: 147, Batch number: 4, Loss: 47.89466857910156\n",
      "Epoch: 148, Batch number: 28, Loss: 57.649845123291016\n",
      "Epoch: 149, Batch number: 52, Loss: 52.9500732421875\n",
      "Epoch: 151, Batch number: 0, Loss: 66.8266372680664\n",
      "Epoch: 152, Batch number: 24, Loss: 65.8726577758789\n",
      "Epoch: 153, Batch number: 48, Loss: 69.00386810302734\n",
      "Epoch: 154, Batch number: 72, Loss: 73.17024993896484\n",
      "Epoch: 156, Batch number: 20, Loss: 60.97854232788086\n",
      "Epoch: 157, Batch number: 44, Loss: 62.802772521972656\n",
      "Epoch: 158, Batch number: 68, Loss: 89.97088623046875\n",
      "Epoch: 160, Batch number: 16, Loss: 56.52494812011719\n",
      "Epoch: 161, Batch number: 40, Loss: 64.37088012695312\n",
      "Epoch: 162, Batch number: 64, Loss: 48.375267028808594\n",
      "Epoch: 164, Batch number: 12, Loss: 62.22941207885742\n",
      "Epoch: 165, Batch number: 36, Loss: 71.75230407714844\n",
      "Epoch: 166, Batch number: 60, Loss: 75.79082489013672\n",
      "Epoch: 168, Batch number: 8, Loss: 51.64231872558594\n",
      "Epoch: 169, Batch number: 32, Loss: 61.67961502075195\n",
      "Epoch: 170, Batch number: 56, Loss: 53.93008041381836\n",
      "Epoch: 172, Batch number: 4, Loss: 55.932682037353516\n",
      "Epoch: 173, Batch number: 28, Loss: 52.82256317138672\n",
      "Epoch: 174, Batch number: 52, Loss: 60.732322692871094\n",
      "Epoch: 176, Batch number: 0, Loss: 56.82365417480469\n",
      "Epoch: 177, Batch number: 24, Loss: 59.17011260986328\n",
      "Epoch: 178, Batch number: 48, Loss: 59.00929641723633\n",
      "Epoch: 179, Batch number: 72, Loss: 56.284488677978516\n",
      "Epoch: 181, Batch number: 20, Loss: 61.23382568359375\n",
      "Epoch: 182, Batch number: 44, Loss: 69.30941772460938\n",
      "Epoch: 183, Batch number: 68, Loss: 67.08174133300781\n",
      "Epoch: 185, Batch number: 16, Loss: 60.882774353027344\n",
      "Epoch: 186, Batch number: 40, Loss: 44.01079559326172\n",
      "Epoch: 187, Batch number: 64, Loss: 77.3019790649414\n",
      "Epoch: 189, Batch number: 12, Loss: 56.60066604614258\n",
      "Epoch: 190, Batch number: 36, Loss: 33.44023895263672\n",
      "Epoch: 191, Batch number: 60, Loss: 58.842769622802734\n",
      "Epoch: 193, Batch number: 8, Loss: 57.93312454223633\n",
      "Epoch: 194, Batch number: 32, Loss: 47.27162170410156\n",
      "Epoch: 195, Batch number: 56, Loss: 51.95559310913086\n",
      "Epoch: 197, Batch number: 4, Loss: 67.49469757080078\n",
      "Epoch: 198, Batch number: 28, Loss: 50.19511795043945\n",
      "Epoch: 199, Batch number: 52, Loss: 76.61939239501953\n",
      "Epoch: 201, Batch number: 0, Loss: 64.53994750976562\n",
      "Epoch: 202, Batch number: 24, Loss: 48.308746337890625\n",
      "Epoch: 203, Batch number: 48, Loss: 63.63082504272461\n",
      "Epoch: 204, Batch number: 72, Loss: 51.180912017822266\n",
      "Epoch: 206, Batch number: 20, Loss: 48.69481658935547\n",
      "Epoch: 207, Batch number: 44, Loss: 64.24710083007812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 51.38190841674805\n",
      "Epoch: 210, Batch number: 16, Loss: 36.699886322021484\n",
      "Epoch: 211, Batch number: 40, Loss: 60.0110969543457\n",
      "Epoch: 212, Batch number: 64, Loss: 50.54644775390625\n",
      "Epoch: 214, Batch number: 12, Loss: 37.49278259277344\n",
      "Epoch: 215, Batch number: 36, Loss: 37.83599090576172\n",
      "Epoch: 216, Batch number: 60, Loss: 55.484397888183594\n",
      "Epoch: 218, Batch number: 8, Loss: 51.37116241455078\n",
      "Epoch: 219, Batch number: 32, Loss: 49.91912078857422\n",
      "Epoch: 220, Batch number: 56, Loss: 41.22936248779297\n",
      "Epoch: 222, Batch number: 4, Loss: 40.296348571777344\n",
      "Epoch: 223, Batch number: 28, Loss: 44.404052734375\n",
      "Epoch: 224, Batch number: 52, Loss: 34.32273483276367\n",
      "Epoch: 226, Batch number: 0, Loss: 50.66326904296875\n",
      "Epoch: 227, Batch number: 24, Loss: 49.827327728271484\n",
      "Epoch: 228, Batch number: 48, Loss: 66.11309814453125\n",
      "Epoch: 229, Batch number: 72, Loss: 56.42374801635742\n",
      "Epoch: 231, Batch number: 20, Loss: 77.26561737060547\n",
      "Epoch: 232, Batch number: 44, Loss: 38.94442367553711\n",
      "Epoch: 233, Batch number: 68, Loss: 40.786895751953125\n",
      "Epoch: 235, Batch number: 16, Loss: 40.5338134765625\n",
      "Epoch: 236, Batch number: 40, Loss: 43.55607223510742\n",
      "Epoch: 237, Batch number: 64, Loss: 47.792999267578125\n",
      "Epoch: 239, Batch number: 12, Loss: 54.694400787353516\n",
      "Epoch: 240, Batch number: 36, Loss: 53.097660064697266\n",
      "Epoch: 241, Batch number: 60, Loss: 54.25348663330078\n",
      "Epoch: 243, Batch number: 8, Loss: 58.97007751464844\n",
      "Epoch: 244, Batch number: 32, Loss: 53.96757888793945\n",
      "Epoch: 245, Batch number: 56, Loss: 46.49064636230469\n",
      "Epoch: 247, Batch number: 4, Loss: 44.69560241699219\n",
      "Epoch: 248, Batch number: 28, Loss: 51.90278244018555\n",
      "Epoch: 249, Batch number: 52, Loss: 49.77238464355469\n",
      "Epoch: 251, Batch number: 0, Loss: 49.70538330078125\n",
      "Epoch: 252, Batch number: 24, Loss: 52.49005126953125\n",
      "Epoch: 253, Batch number: 48, Loss: 46.801475524902344\n",
      "Epoch: 254, Batch number: 72, Loss: 47.92097473144531\n",
      "Epoch: 256, Batch number: 20, Loss: 46.98927688598633\n",
      "Epoch: 257, Batch number: 44, Loss: 62.16921615600586\n",
      "Epoch: 258, Batch number: 68, Loss: 57.48992156982422\n",
      "Epoch: 260, Batch number: 16, Loss: 55.94496536254883\n",
      "Epoch: 261, Batch number: 40, Loss: 43.87642288208008\n",
      "Epoch: 262, Batch number: 64, Loss: 59.24608612060547\n",
      "Epoch: 264, Batch number: 12, Loss: 45.09410858154297\n",
      "Epoch: 265, Batch number: 36, Loss: 36.882965087890625\n",
      "Epoch: 266, Batch number: 60, Loss: 52.92060089111328\n",
      "Epoch: 268, Batch number: 8, Loss: 42.967674255371094\n",
      "Epoch: 269, Batch number: 32, Loss: 41.57155227661133\n",
      "Epoch: 270, Batch number: 56, Loss: 40.40602111816406\n",
      "Epoch: 272, Batch number: 4, Loss: 42.61492156982422\n",
      "Epoch: 273, Batch number: 28, Loss: 40.58214569091797\n",
      "Epoch: 274, Batch number: 52, Loss: 41.75978088378906\n",
      "Epoch: 276, Batch number: 0, Loss: 59.07229232788086\n",
      "Epoch: 277, Batch number: 24, Loss: 56.558563232421875\n",
      "Epoch: 278, Batch number: 48, Loss: 48.48652648925781\n",
      "Epoch: 279, Batch number: 72, Loss: 54.58038330078125\n",
      "Epoch: 281, Batch number: 20, Loss: 28.226720809936523\n",
      "Epoch: 282, Batch number: 44, Loss: 35.94523620605469\n",
      "Epoch: 283, Batch number: 68, Loss: 53.82550811767578\n",
      "Epoch: 285, Batch number: 16, Loss: 52.82756805419922\n",
      "Epoch: 286, Batch number: 40, Loss: 42.78135299682617\n",
      "Epoch: 287, Batch number: 64, Loss: 63.71537399291992\n",
      "Epoch: 289, Batch number: 12, Loss: 42.12807083129883\n",
      "Epoch: 290, Batch number: 36, Loss: 50.673789978027344\n",
      "Epoch: 291, Batch number: 60, Loss: 47.38530349731445\n",
      "Epoch: 293, Batch number: 8, Loss: 36.15456771850586\n",
      "Epoch: 294, Batch number: 32, Loss: 58.10377502441406\n",
      "Epoch: 295, Batch number: 56, Loss: 40.88484191894531\n",
      "Epoch: 297, Batch number: 4, Loss: 37.46141815185547\n",
      "Epoch: 298, Batch number: 28, Loss: 32.360904693603516\n",
      "Epoch: 299, Batch number: 52, Loss: 52.756309509277344\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4416.0126953125\n",
      "Epoch: 2, Batch number: 24, Loss: 3687.980224609375\n",
      "Epoch: 3, Batch number: 48, Loss: 3142.138916015625\n",
      "Epoch: 4, Batch number: 72, Loss: 2706.633056640625\n",
      "Epoch: 6, Batch number: 20, Loss: 2271.2021484375\n",
      "Epoch: 7, Batch number: 44, Loss: 2116.4111328125\n",
      "Epoch: 8, Batch number: 68, Loss: 1960.8775634765625\n",
      "Epoch: 10, Batch number: 16, Loss: 1690.163818359375\n",
      "Epoch: 11, Batch number: 40, Loss: 1621.99560546875\n",
      "Epoch: 12, Batch number: 64, Loss: 1524.4222412109375\n",
      "Epoch: 14, Batch number: 12, Loss: 1361.8050537109375\n",
      "Epoch: 15, Batch number: 36, Loss: 1283.00390625\n",
      "Epoch: 16, Batch number: 60, Loss: 1111.265380859375\n",
      "Epoch: 18, Batch number: 8, Loss: 1050.1002197265625\n",
      "Epoch: 19, Batch number: 32, Loss: 1051.30419921875\n",
      "Epoch: 20, Batch number: 56, Loss: 945.8362426757812\n",
      "Epoch: 22, Batch number: 4, Loss: 838.0808715820312\n",
      "Epoch: 23, Batch number: 28, Loss: 808.8412475585938\n",
      "Epoch: 24, Batch number: 52, Loss: 735.9271240234375\n",
      "Epoch: 26, Batch number: 0, Loss: 787.1707153320312\n",
      "Epoch: 27, Batch number: 24, Loss: 666.0000610351562\n",
      "Epoch: 28, Batch number: 48, Loss: 623.5283813476562\n",
      "Epoch: 29, Batch number: 72, Loss: 601.8318481445312\n",
      "Epoch: 31, Batch number: 20, Loss: 509.95196533203125\n",
      "Epoch: 32, Batch number: 44, Loss: 532.590576171875\n",
      "Epoch: 33, Batch number: 68, Loss: 502.6128845214844\n",
      "Epoch: 35, Batch number: 16, Loss: 513.4231567382812\n",
      "Epoch: 36, Batch number: 40, Loss: 411.0107421875\n",
      "Epoch: 37, Batch number: 64, Loss: 432.96844482421875\n",
      "Epoch: 39, Batch number: 12, Loss: 394.0137634277344\n",
      "Epoch: 40, Batch number: 36, Loss: 382.24957275390625\n",
      "Epoch: 41, Batch number: 60, Loss: 350.537353515625\n",
      "Epoch: 43, Batch number: 8, Loss: 352.677978515625\n",
      "Epoch: 44, Batch number: 32, Loss: 303.37908935546875\n",
      "Epoch: 45, Batch number: 56, Loss: 301.6007080078125\n",
      "Epoch: 47, Batch number: 4, Loss: 271.79266357421875\n",
      "Epoch: 48, Batch number: 28, Loss: 257.5567932128906\n",
      "Epoch: 49, Batch number: 52, Loss: 265.62811279296875\n",
      "Epoch: 51, Batch number: 0, Loss: 195.33631896972656\n",
      "Epoch: 52, Batch number: 24, Loss: 267.39349365234375\n",
      "Epoch: 53, Batch number: 48, Loss: 248.01141357421875\n",
      "Epoch: 54, Batch number: 72, Loss: 248.33042907714844\n",
      "Epoch: 56, Batch number: 20, Loss: 186.38275146484375\n",
      "Epoch: 57, Batch number: 44, Loss: 226.35269165039062\n",
      "Epoch: 58, Batch number: 68, Loss: 202.9241180419922\n",
      "Epoch: 60, Batch number: 16, Loss: 166.66769409179688\n",
      "Epoch: 61, Batch number: 40, Loss: 192.87110900878906\n",
      "Epoch: 62, Batch number: 64, Loss: 185.70938110351562\n",
      "Epoch: 64, Batch number: 12, Loss: 154.19766235351562\n",
      "Epoch: 65, Batch number: 36, Loss: 185.01686096191406\n",
      "Epoch: 66, Batch number: 60, Loss: 151.6572265625\n",
      "Epoch: 68, Batch number: 8, Loss: 137.04039001464844\n",
      "Epoch: 69, Batch number: 32, Loss: 129.36920166015625\n",
      "Epoch: 70, Batch number: 56, Loss: 126.2879638671875\n",
      "Epoch: 72, Batch number: 4, Loss: 167.2737274169922\n",
      "Epoch: 73, Batch number: 28, Loss: 130.115966796875\n",
      "Epoch: 74, Batch number: 52, Loss: 137.6795654296875\n",
      "Epoch: 76, Batch number: 0, Loss: 136.49217224121094\n",
      "Epoch: 77, Batch number: 24, Loss: 116.40438079833984\n",
      "Epoch: 78, Batch number: 48, Loss: 135.55079650878906\n",
      "Epoch: 79, Batch number: 72, Loss: 128.50535583496094\n",
      "Epoch: 81, Batch number: 20, Loss: 109.07367706298828\n",
      "Epoch: 82, Batch number: 44, Loss: 100.83495330810547\n",
      "Epoch: 83, Batch number: 68, Loss: 109.49434661865234\n",
      "Epoch: 85, Batch number: 16, Loss: 85.95309448242188\n",
      "Epoch: 86, Batch number: 40, Loss: 107.63321685791016\n",
      "Epoch: 87, Batch number: 64, Loss: 97.5621337890625\n",
      "Epoch: 89, Batch number: 12, Loss: 110.43897247314453\n",
      "Epoch: 90, Batch number: 36, Loss: 95.98494720458984\n",
      "Epoch: 91, Batch number: 60, Loss: 122.85779571533203\n",
      "Epoch: 93, Batch number: 8, Loss: 86.69268035888672\n",
      "Epoch: 94, Batch number: 32, Loss: 108.7001953125\n",
      "Epoch: 95, Batch number: 56, Loss: 90.62368774414062\n",
      "Epoch: 97, Batch number: 4, Loss: 92.07540130615234\n",
      "Epoch: 98, Batch number: 28, Loss: 99.9450454711914\n",
      "Epoch: 99, Batch number: 52, Loss: 86.40608215332031\n",
      "Epoch: 101, Batch number: 0, Loss: 56.56855392456055\n",
      "Epoch: 102, Batch number: 24, Loss: 85.93043518066406\n",
      "Epoch: 103, Batch number: 48, Loss: 94.65664672851562\n",
      "Epoch: 104, Batch number: 72, Loss: 85.8076171875\n",
      "Epoch: 106, Batch number: 20, Loss: 79.61776733398438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 107.00924682617188\n",
      "Epoch: 108, Batch number: 68, Loss: 84.9699935913086\n",
      "Epoch: 110, Batch number: 16, Loss: 71.50926208496094\n",
      "Epoch: 111, Batch number: 40, Loss: 75.44097137451172\n",
      "Epoch: 112, Batch number: 64, Loss: 71.5919189453125\n",
      "Epoch: 114, Batch number: 12, Loss: 75.06584930419922\n",
      "Epoch: 115, Batch number: 36, Loss: 65.54720306396484\n",
      "Epoch: 116, Batch number: 60, Loss: 60.158203125\n",
      "Epoch: 118, Batch number: 8, Loss: 70.111083984375\n",
      "Epoch: 119, Batch number: 32, Loss: 60.649070739746094\n",
      "Epoch: 120, Batch number: 56, Loss: 81.35478210449219\n",
      "Epoch: 122, Batch number: 4, Loss: 56.95874786376953\n",
      "Epoch: 123, Batch number: 28, Loss: 70.24400329589844\n",
      "Epoch: 124, Batch number: 52, Loss: 65.45856475830078\n",
      "Epoch: 126, Batch number: 0, Loss: 56.78107452392578\n",
      "Epoch: 127, Batch number: 24, Loss: 63.087432861328125\n",
      "Epoch: 128, Batch number: 48, Loss: 59.33127212524414\n",
      "Epoch: 129, Batch number: 72, Loss: 58.94664764404297\n",
      "Epoch: 131, Batch number: 20, Loss: 83.31078338623047\n",
      "Epoch: 132, Batch number: 44, Loss: 77.6106185913086\n",
      "Epoch: 133, Batch number: 68, Loss: 74.42724609375\n",
      "Epoch: 135, Batch number: 16, Loss: 73.12932586669922\n",
      "Epoch: 136, Batch number: 40, Loss: 49.67186737060547\n",
      "Epoch: 137, Batch number: 64, Loss: 72.89945983886719\n",
      "Epoch: 139, Batch number: 12, Loss: 62.19620895385742\n",
      "Epoch: 140, Batch number: 36, Loss: 63.043460845947266\n",
      "Epoch: 141, Batch number: 60, Loss: 68.86234283447266\n",
      "Epoch: 143, Batch number: 8, Loss: 58.72405242919922\n",
      "Epoch: 144, Batch number: 32, Loss: 48.02696228027344\n",
      "Epoch: 145, Batch number: 56, Loss: 65.90240478515625\n",
      "Epoch: 147, Batch number: 4, Loss: 69.70978546142578\n",
      "Epoch: 148, Batch number: 28, Loss: 49.41997528076172\n",
      "Epoch: 149, Batch number: 52, Loss: 83.75041961669922\n",
      "Epoch: 151, Batch number: 0, Loss: 49.100894927978516\n",
      "Epoch: 152, Batch number: 24, Loss: 54.78657531738281\n",
      "Epoch: 153, Batch number: 48, Loss: 74.91697692871094\n",
      "Epoch: 154, Batch number: 72, Loss: 60.70409393310547\n",
      "Epoch: 156, Batch number: 20, Loss: 64.60479736328125\n",
      "Epoch: 157, Batch number: 44, Loss: 46.917755126953125\n",
      "Epoch: 158, Batch number: 68, Loss: 64.24156188964844\n",
      "Epoch: 160, Batch number: 16, Loss: 34.03639221191406\n",
      "Epoch: 161, Batch number: 40, Loss: 63.99312973022461\n",
      "Epoch: 162, Batch number: 64, Loss: 52.163169860839844\n",
      "Epoch: 164, Batch number: 12, Loss: 56.854183197021484\n",
      "Epoch: 165, Batch number: 36, Loss: 58.97118377685547\n",
      "Epoch: 166, Batch number: 60, Loss: 57.2320556640625\n",
      "Epoch: 168, Batch number: 8, Loss: 42.682029724121094\n",
      "Epoch: 169, Batch number: 32, Loss: 61.731285095214844\n",
      "Epoch: 170, Batch number: 56, Loss: 58.97472381591797\n",
      "Epoch: 172, Batch number: 4, Loss: 39.82337951660156\n",
      "Epoch: 173, Batch number: 28, Loss: 62.29608917236328\n",
      "Epoch: 174, Batch number: 52, Loss: 53.555694580078125\n",
      "Epoch: 176, Batch number: 0, Loss: 49.80795669555664\n",
      "Epoch: 177, Batch number: 24, Loss: 53.26655197143555\n",
      "Epoch: 178, Batch number: 48, Loss: 67.32389068603516\n",
      "Epoch: 179, Batch number: 72, Loss: 54.428321838378906\n",
      "Epoch: 181, Batch number: 20, Loss: 47.170814514160156\n",
      "Epoch: 182, Batch number: 44, Loss: 41.21366882324219\n",
      "Epoch: 183, Batch number: 68, Loss: 72.47601318359375\n",
      "Epoch: 185, Batch number: 16, Loss: 50.77852249145508\n",
      "Epoch: 186, Batch number: 40, Loss: 43.1876220703125\n",
      "Epoch: 187, Batch number: 64, Loss: 39.448543548583984\n",
      "Epoch: 189, Batch number: 12, Loss: 47.78242492675781\n",
      "Epoch: 190, Batch number: 36, Loss: 56.61619567871094\n",
      "Epoch: 191, Batch number: 60, Loss: 66.72573852539062\n",
      "Epoch: 193, Batch number: 8, Loss: 51.7422981262207\n",
      "Epoch: 194, Batch number: 32, Loss: 47.481773376464844\n",
      "Epoch: 195, Batch number: 56, Loss: 44.105316162109375\n",
      "Epoch: 197, Batch number: 4, Loss: 54.452796936035156\n",
      "Epoch: 198, Batch number: 28, Loss: 43.347900390625\n",
      "Epoch: 199, Batch number: 52, Loss: 62.91073989868164\n",
      "Epoch: 201, Batch number: 0, Loss: 49.130496978759766\n",
      "Epoch: 202, Batch number: 24, Loss: 54.54460144042969\n",
      "Epoch: 203, Batch number: 48, Loss: 42.74695587158203\n",
      "Epoch: 204, Batch number: 72, Loss: 71.16227722167969\n",
      "Epoch: 206, Batch number: 20, Loss: 37.85518264770508\n",
      "Epoch: 207, Batch number: 44, Loss: 65.6626205444336\n",
      "Epoch: 208, Batch number: 68, Loss: 60.406890869140625\n",
      "Epoch: 210, Batch number: 16, Loss: 51.21992492675781\n",
      "Epoch: 211, Batch number: 40, Loss: 61.2359504699707\n",
      "Epoch: 212, Batch number: 64, Loss: 61.18324279785156\n",
      "Epoch: 214, Batch number: 12, Loss: 64.38909149169922\n",
      "Epoch: 215, Batch number: 36, Loss: 60.173988342285156\n",
      "Epoch: 216, Batch number: 60, Loss: 63.97210693359375\n",
      "Epoch: 218, Batch number: 8, Loss: 61.420692443847656\n",
      "Epoch: 219, Batch number: 32, Loss: 45.557891845703125\n",
      "Epoch: 220, Batch number: 56, Loss: 44.865543365478516\n",
      "Epoch: 222, Batch number: 4, Loss: 48.12024688720703\n",
      "Epoch: 223, Batch number: 28, Loss: 50.22882080078125\n",
      "Epoch: 224, Batch number: 52, Loss: 60.2540168762207\n",
      "Epoch: 226, Batch number: 0, Loss: 63.74005126953125\n",
      "Epoch: 227, Batch number: 24, Loss: 43.863216400146484\n",
      "Epoch: 228, Batch number: 48, Loss: 40.28466033935547\n",
      "Epoch: 229, Batch number: 72, Loss: 59.69672393798828\n",
      "Epoch: 231, Batch number: 20, Loss: 23.45467185974121\n",
      "Epoch: 232, Batch number: 44, Loss: 46.423912048339844\n",
      "Epoch: 233, Batch number: 68, Loss: 48.24806213378906\n",
      "Epoch: 235, Batch number: 16, Loss: 63.238380432128906\n",
      "Epoch: 236, Batch number: 40, Loss: 53.502593994140625\n",
      "Epoch: 237, Batch number: 64, Loss: 60.637046813964844\n",
      "Epoch: 239, Batch number: 12, Loss: 37.63633728027344\n",
      "Epoch: 240, Batch number: 36, Loss: 39.686309814453125\n",
      "Epoch: 241, Batch number: 60, Loss: 50.8863525390625\n",
      "Epoch: 243, Batch number: 8, Loss: 34.803993225097656\n",
      "Epoch: 244, Batch number: 32, Loss: 31.19861602783203\n",
      "Epoch: 245, Batch number: 56, Loss: 38.928314208984375\n",
      "Epoch: 247, Batch number: 4, Loss: 47.35468292236328\n",
      "Epoch: 248, Batch number: 28, Loss: 50.002044677734375\n",
      "Epoch: 249, Batch number: 52, Loss: 41.74131774902344\n",
      "Epoch: 251, Batch number: 0, Loss: 44.22686004638672\n",
      "Epoch: 252, Batch number: 24, Loss: 28.469825744628906\n",
      "Epoch: 253, Batch number: 48, Loss: 70.55023956298828\n",
      "Epoch: 254, Batch number: 72, Loss: 51.32038879394531\n",
      "Epoch: 256, Batch number: 20, Loss: 50.06098556518555\n",
      "Epoch: 257, Batch number: 44, Loss: 21.7439022064209\n",
      "Epoch: 258, Batch number: 68, Loss: 59.01093292236328\n",
      "Epoch: 260, Batch number: 16, Loss: 43.23064041137695\n",
      "Epoch: 261, Batch number: 40, Loss: 58.13197326660156\n",
      "Epoch: 262, Batch number: 64, Loss: 37.92042541503906\n",
      "Epoch: 264, Batch number: 12, Loss: 44.877166748046875\n",
      "Epoch: 265, Batch number: 36, Loss: 41.47578430175781\n",
      "Epoch: 266, Batch number: 60, Loss: 38.21485137939453\n",
      "Epoch: 268, Batch number: 8, Loss: 35.13996124267578\n",
      "Epoch: 269, Batch number: 32, Loss: 48.92063903808594\n",
      "Epoch: 270, Batch number: 56, Loss: 42.276039123535156\n",
      "Epoch: 272, Batch number: 4, Loss: 36.90458679199219\n",
      "Epoch: 273, Batch number: 28, Loss: 23.20411491394043\n",
      "Epoch: 274, Batch number: 52, Loss: 35.10295867919922\n",
      "Epoch: 276, Batch number: 0, Loss: 52.31172180175781\n",
      "Epoch: 277, Batch number: 24, Loss: 46.18465805053711\n",
      "Epoch: 278, Batch number: 48, Loss: 53.83835983276367\n",
      "Epoch: 279, Batch number: 72, Loss: 60.72967529296875\n",
      "Epoch: 281, Batch number: 20, Loss: 61.50492858886719\n",
      "Epoch: 282, Batch number: 44, Loss: 54.95306396484375\n",
      "Epoch: 283, Batch number: 68, Loss: 44.42716979980469\n",
      "Epoch: 285, Batch number: 16, Loss: 43.504600524902344\n",
      "Epoch: 286, Batch number: 40, Loss: 38.059654235839844\n",
      "Epoch: 287, Batch number: 64, Loss: 53.381919860839844\n",
      "Epoch: 289, Batch number: 12, Loss: 27.7647647857666\n",
      "Epoch: 290, Batch number: 36, Loss: 63.187477111816406\n",
      "Epoch: 291, Batch number: 60, Loss: 49.77210998535156\n",
      "Epoch: 293, Batch number: 8, Loss: 45.45021438598633\n",
      "Epoch: 294, Batch number: 32, Loss: 58.669639587402344\n",
      "Epoch: 295, Batch number: 56, Loss: 65.56944274902344\n",
      "Epoch: 297, Batch number: 4, Loss: 39.25543975830078\n",
      "Epoch: 298, Batch number: 28, Loss: 55.845359802246094\n",
      "Epoch: 299, Batch number: 52, Loss: 38.06214141845703\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4407.0927734375\n",
      "Epoch: 2, Batch number: 24, Loss: 4306.68798828125\n",
      "Epoch: 3, Batch number: 48, Loss: 4192.04833984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch number: 72, Loss: 3980.02734375\n",
      "Epoch: 6, Batch number: 20, Loss: 3630.97021484375\n",
      "Epoch: 7, Batch number: 44, Loss: 3340.61376953125\n",
      "Epoch: 8, Batch number: 68, Loss: 3037.250732421875\n",
      "Epoch: 10, Batch number: 16, Loss: 3006.539306640625\n",
      "Epoch: 11, Batch number: 40, Loss: 2930.766845703125\n",
      "Epoch: 12, Batch number: 64, Loss: 2861.010498046875\n",
      "Epoch: 14, Batch number: 12, Loss: 2719.523681640625\n",
      "Epoch: 15, Batch number: 36, Loss: 2705.563232421875\n",
      "Epoch: 16, Batch number: 60, Loss: 2701.653076171875\n",
      "Epoch: 18, Batch number: 8, Loss: 2767.62158203125\n",
      "Epoch: 19, Batch number: 32, Loss: 2603.083740234375\n",
      "Epoch: 20, Batch number: 56, Loss: 2624.162841796875\n",
      "Epoch: 22, Batch number: 4, Loss: 2630.466796875\n",
      "Epoch: 23, Batch number: 28, Loss: 2481.464599609375\n",
      "Epoch: 24, Batch number: 52, Loss: 2466.251220703125\n",
      "Epoch: 26, Batch number: 0, Loss: 2532.80615234375\n",
      "Epoch: 27, Batch number: 24, Loss: 2444.528076171875\n",
      "Epoch: 28, Batch number: 48, Loss: 2429.333740234375\n",
      "Epoch: 29, Batch number: 72, Loss: 2359.71875\n",
      "Epoch: 31, Batch number: 20, Loss: 2316.64892578125\n",
      "Epoch: 32, Batch number: 44, Loss: 2348.1005859375\n",
      "Epoch: 33, Batch number: 68, Loss: 2299.15478515625\n",
      "Epoch: 35, Batch number: 16, Loss: 2312.412353515625\n",
      "Epoch: 36, Batch number: 40, Loss: 2239.5947265625\n",
      "Epoch: 37, Batch number: 64, Loss: 2161.071044921875\n",
      "Epoch: 39, Batch number: 12, Loss: 2150.5263671875\n",
      "Epoch: 40, Batch number: 36, Loss: 2057.30126953125\n",
      "Epoch: 41, Batch number: 60, Loss: 2156.787841796875\n",
      "Epoch: 43, Batch number: 8, Loss: 2005.714111328125\n",
      "Epoch: 44, Batch number: 32, Loss: 2038.259521484375\n",
      "Epoch: 45, Batch number: 56, Loss: 1982.9677734375\n",
      "Epoch: 47, Batch number: 4, Loss: 1958.3282470703125\n",
      "Epoch: 48, Batch number: 28, Loss: 1903.984375\n",
      "Epoch: 49, Batch number: 52, Loss: 1931.9163818359375\n",
      "Epoch: 51, Batch number: 0, Loss: 1945.457763671875\n",
      "Epoch: 52, Batch number: 24, Loss: 1890.8388671875\n",
      "Epoch: 53, Batch number: 48, Loss: 1875.192626953125\n",
      "Epoch: 54, Batch number: 72, Loss: 1856.9256591796875\n",
      "Epoch: 56, Batch number: 20, Loss: 1890.674560546875\n",
      "Epoch: 57, Batch number: 44, Loss: 1789.5006103515625\n",
      "Epoch: 58, Batch number: 68, Loss: 1752.58642578125\n",
      "Epoch: 60, Batch number: 16, Loss: 1747.7337646484375\n",
      "Epoch: 61, Batch number: 40, Loss: 1728.2391357421875\n",
      "Epoch: 62, Batch number: 64, Loss: 1697.7802734375\n",
      "Epoch: 64, Batch number: 12, Loss: 1689.465576171875\n",
      "Epoch: 65, Batch number: 36, Loss: 1661.3204345703125\n",
      "Epoch: 66, Batch number: 60, Loss: 1662.7852783203125\n",
      "Epoch: 68, Batch number: 8, Loss: 1529.1475830078125\n",
      "Epoch: 69, Batch number: 32, Loss: 1587.080322265625\n",
      "Epoch: 70, Batch number: 56, Loss: 1531.7344970703125\n",
      "Epoch: 72, Batch number: 4, Loss: 1453.22021484375\n",
      "Epoch: 73, Batch number: 28, Loss: 1502.708984375\n",
      "Epoch: 74, Batch number: 52, Loss: 1509.42626953125\n",
      "Epoch: 76, Batch number: 0, Loss: 1446.01708984375\n",
      "Epoch: 77, Batch number: 24, Loss: 1503.65966796875\n",
      "Epoch: 78, Batch number: 48, Loss: 1404.7462158203125\n",
      "Epoch: 79, Batch number: 72, Loss: 1450.1968994140625\n",
      "Epoch: 81, Batch number: 20, Loss: 1296.0107421875\n",
      "Epoch: 82, Batch number: 44, Loss: 1417.2724609375\n",
      "Epoch: 83, Batch number: 68, Loss: 1390.0228271484375\n",
      "Epoch: 85, Batch number: 16, Loss: 1427.31982421875\n",
      "Epoch: 86, Batch number: 40, Loss: 1332.106201171875\n",
      "Epoch: 87, Batch number: 64, Loss: 1290.335693359375\n",
      "Epoch: 89, Batch number: 12, Loss: 1287.706787109375\n",
      "Epoch: 90, Batch number: 36, Loss: 1274.8585205078125\n",
      "Epoch: 91, Batch number: 60, Loss: 1333.00634765625\n",
      "Epoch: 93, Batch number: 8, Loss: 1271.05908203125\n",
      "Epoch: 94, Batch number: 32, Loss: 1284.7537841796875\n",
      "Epoch: 95, Batch number: 56, Loss: 1218.175048828125\n",
      "Epoch: 97, Batch number: 4, Loss: 1203.8558349609375\n",
      "Epoch: 98, Batch number: 28, Loss: 1172.496337890625\n",
      "Epoch: 99, Batch number: 52, Loss: 1189.2469482421875\n",
      "Epoch: 101, Batch number: 0, Loss: 1217.237060546875\n",
      "Epoch: 102, Batch number: 24, Loss: 1142.028076171875\n",
      "Epoch: 103, Batch number: 48, Loss: 1099.4158935546875\n",
      "Epoch: 104, Batch number: 72, Loss: 1183.6881103515625\n",
      "Epoch: 106, Batch number: 20, Loss: 1093.263916015625\n",
      "Epoch: 107, Batch number: 44, Loss: 1149.6160888671875\n",
      "Epoch: 108, Batch number: 68, Loss: 1200.81494140625\n",
      "Epoch: 110, Batch number: 16, Loss: 1085.4920654296875\n",
      "Epoch: 111, Batch number: 40, Loss: 1069.441162109375\n",
      "Epoch: 112, Batch number: 64, Loss: 1014.65771484375\n",
      "Epoch: 114, Batch number: 12, Loss: 1082.92822265625\n",
      "Epoch: 115, Batch number: 36, Loss: 1065.863525390625\n",
      "Epoch: 116, Batch number: 60, Loss: 1014.3766479492188\n",
      "Epoch: 118, Batch number: 8, Loss: 984.6798706054688\n",
      "Epoch: 119, Batch number: 32, Loss: 1020.3218383789062\n",
      "Epoch: 120, Batch number: 56, Loss: 1038.3385009765625\n",
      "Epoch: 122, Batch number: 4, Loss: 985.7041015625\n",
      "Epoch: 123, Batch number: 28, Loss: 1011.8370971679688\n",
      "Epoch: 124, Batch number: 52, Loss: 953.0975952148438\n",
      "Epoch: 126, Batch number: 0, Loss: 913.430419921875\n",
      "Epoch: 127, Batch number: 24, Loss: 954.3884887695312\n",
      "Epoch: 128, Batch number: 48, Loss: 880.6253662109375\n",
      "Epoch: 129, Batch number: 72, Loss: 957.4700317382812\n",
      "Epoch: 131, Batch number: 20, Loss: 914.1386108398438\n",
      "Epoch: 132, Batch number: 44, Loss: 934.13916015625\n",
      "Epoch: 133, Batch number: 68, Loss: 895.9558715820312\n",
      "Epoch: 135, Batch number: 16, Loss: 932.5628662109375\n",
      "Epoch: 136, Batch number: 40, Loss: 807.0021362304688\n",
      "Epoch: 137, Batch number: 64, Loss: 898.9005737304688\n",
      "Epoch: 139, Batch number: 12, Loss: 859.7913818359375\n",
      "Epoch: 140, Batch number: 36, Loss: 862.9857788085938\n",
      "Epoch: 141, Batch number: 60, Loss: 803.9080810546875\n",
      "Epoch: 143, Batch number: 8, Loss: 830.8657836914062\n",
      "Epoch: 144, Batch number: 32, Loss: 854.9367065429688\n",
      "Epoch: 145, Batch number: 56, Loss: 812.8936157226562\n",
      "Epoch: 147, Batch number: 4, Loss: 825.926513671875\n",
      "Epoch: 148, Batch number: 28, Loss: 772.732666015625\n",
      "Epoch: 149, Batch number: 52, Loss: 824.76025390625\n",
      "Epoch: 151, Batch number: 0, Loss: 806.7482299804688\n",
      "Epoch: 152, Batch number: 24, Loss: 768.15771484375\n",
      "Epoch: 153, Batch number: 48, Loss: 834.86767578125\n",
      "Epoch: 154, Batch number: 72, Loss: 767.558349609375\n",
      "Epoch: 156, Batch number: 20, Loss: 749.544677734375\n",
      "Epoch: 157, Batch number: 44, Loss: 765.504150390625\n",
      "Epoch: 158, Batch number: 68, Loss: 780.80908203125\n",
      "Epoch: 160, Batch number: 16, Loss: 705.4334106445312\n",
      "Epoch: 161, Batch number: 40, Loss: 772.2444458007812\n",
      "Epoch: 162, Batch number: 64, Loss: 695.2193603515625\n",
      "Epoch: 164, Batch number: 12, Loss: 673.9358520507812\n",
      "Epoch: 165, Batch number: 36, Loss: 703.2899780273438\n",
      "Epoch: 166, Batch number: 60, Loss: 701.2255859375\n",
      "Epoch: 168, Batch number: 8, Loss: 734.0037841796875\n",
      "Epoch: 169, Batch number: 32, Loss: 673.2785034179688\n",
      "Epoch: 170, Batch number: 56, Loss: 672.7827758789062\n",
      "Epoch: 172, Batch number: 4, Loss: 594.7675170898438\n",
      "Epoch: 173, Batch number: 28, Loss: 749.21630859375\n",
      "Epoch: 174, Batch number: 52, Loss: 633.2669677734375\n",
      "Epoch: 176, Batch number: 0, Loss: 690.2964477539062\n",
      "Epoch: 177, Batch number: 24, Loss: 597.3634033203125\n",
      "Epoch: 178, Batch number: 48, Loss: 628.3671875\n",
      "Epoch: 179, Batch number: 72, Loss: 595.2672729492188\n",
      "Epoch: 181, Batch number: 20, Loss: 588.0615844726562\n",
      "Epoch: 182, Batch number: 44, Loss: 587.4502563476562\n",
      "Epoch: 183, Batch number: 68, Loss: 627.3224487304688\n",
      "Epoch: 185, Batch number: 16, Loss: 582.5598754882812\n",
      "Epoch: 186, Batch number: 40, Loss: 591.472900390625\n",
      "Epoch: 187, Batch number: 64, Loss: 565.3936767578125\n",
      "Epoch: 189, Batch number: 12, Loss: 553.0349731445312\n",
      "Epoch: 190, Batch number: 36, Loss: 551.5509033203125\n",
      "Epoch: 191, Batch number: 60, Loss: 625.9627685546875\n",
      "Epoch: 193, Batch number: 8, Loss: 605.0582275390625\n",
      "Epoch: 194, Batch number: 32, Loss: 557.159912109375\n",
      "Epoch: 195, Batch number: 56, Loss: 539.2293701171875\n",
      "Epoch: 197, Batch number: 4, Loss: 529.4302978515625\n",
      "Epoch: 198, Batch number: 28, Loss: 535.6245727539062\n",
      "Epoch: 199, Batch number: 52, Loss: 502.34698486328125\n",
      "Epoch: 201, Batch number: 0, Loss: 549.52197265625\n",
      "Epoch: 202, Batch number: 24, Loss: 546.705078125\n",
      "Epoch: 203, Batch number: 48, Loss: 530.5758666992188\n",
      "Epoch: 204, Batch number: 72, Loss: 511.66497802734375\n",
      "Epoch: 206, Batch number: 20, Loss: 504.0142517089844\n",
      "Epoch: 207, Batch number: 44, Loss: 463.59686279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 479.16082763671875\n",
      "Epoch: 210, Batch number: 16, Loss: 486.30126953125\n",
      "Epoch: 211, Batch number: 40, Loss: 446.9779052734375\n",
      "Epoch: 212, Batch number: 64, Loss: 441.9864501953125\n",
      "Epoch: 214, Batch number: 12, Loss: 530.8770751953125\n",
      "Epoch: 215, Batch number: 36, Loss: 494.1182861328125\n",
      "Epoch: 216, Batch number: 60, Loss: 506.3964538574219\n",
      "Epoch: 218, Batch number: 8, Loss: 434.1010437011719\n",
      "Epoch: 219, Batch number: 32, Loss: 380.8110046386719\n",
      "Epoch: 220, Batch number: 56, Loss: 453.07830810546875\n",
      "Epoch: 222, Batch number: 4, Loss: 441.41925048828125\n",
      "Epoch: 223, Batch number: 28, Loss: 421.1352844238281\n",
      "Epoch: 224, Batch number: 52, Loss: 451.3851013183594\n",
      "Epoch: 226, Batch number: 0, Loss: 433.08026123046875\n",
      "Epoch: 227, Batch number: 24, Loss: 414.499755859375\n",
      "Epoch: 228, Batch number: 48, Loss: 428.0910949707031\n",
      "Epoch: 229, Batch number: 72, Loss: 459.5117492675781\n",
      "Epoch: 231, Batch number: 20, Loss: 435.5219421386719\n",
      "Epoch: 232, Batch number: 44, Loss: 423.47430419921875\n",
      "Epoch: 233, Batch number: 68, Loss: 415.19329833984375\n",
      "Epoch: 235, Batch number: 16, Loss: 413.91522216796875\n",
      "Epoch: 236, Batch number: 40, Loss: 408.0662536621094\n",
      "Epoch: 237, Batch number: 64, Loss: 355.21783447265625\n",
      "Epoch: 239, Batch number: 12, Loss: 398.79815673828125\n",
      "Epoch: 240, Batch number: 36, Loss: 391.647216796875\n",
      "Epoch: 241, Batch number: 60, Loss: 335.53546142578125\n",
      "Epoch: 243, Batch number: 8, Loss: 348.4722595214844\n",
      "Epoch: 244, Batch number: 32, Loss: 356.4216613769531\n",
      "Epoch: 245, Batch number: 56, Loss: 338.03790283203125\n",
      "Epoch: 247, Batch number: 4, Loss: 335.400390625\n",
      "Epoch: 248, Batch number: 28, Loss: 381.2467041015625\n",
      "Epoch: 249, Batch number: 52, Loss: 347.14361572265625\n",
      "Epoch: 251, Batch number: 0, Loss: 339.2811584472656\n",
      "Epoch: 252, Batch number: 24, Loss: 340.7906188964844\n",
      "Epoch: 253, Batch number: 48, Loss: 278.7314453125\n",
      "Epoch: 254, Batch number: 72, Loss: 340.89453125\n",
      "Epoch: 256, Batch number: 20, Loss: 329.5380554199219\n",
      "Epoch: 257, Batch number: 44, Loss: 364.34600830078125\n",
      "Epoch: 258, Batch number: 68, Loss: 345.1271057128906\n",
      "Epoch: 260, Batch number: 16, Loss: 363.223388671875\n",
      "Epoch: 261, Batch number: 40, Loss: 292.03668212890625\n",
      "Epoch: 262, Batch number: 64, Loss: 284.0914611816406\n",
      "Epoch: 264, Batch number: 12, Loss: 320.9767761230469\n",
      "Epoch: 265, Batch number: 36, Loss: 328.3692321777344\n",
      "Epoch: 266, Batch number: 60, Loss: 263.1460266113281\n",
      "Epoch: 268, Batch number: 8, Loss: 337.1609802246094\n",
      "Epoch: 269, Batch number: 32, Loss: 257.43914794921875\n",
      "Epoch: 270, Batch number: 56, Loss: 287.4410095214844\n",
      "Epoch: 272, Batch number: 4, Loss: 309.3059387207031\n",
      "Epoch: 273, Batch number: 28, Loss: 268.9589538574219\n",
      "Epoch: 274, Batch number: 52, Loss: 304.0981140136719\n",
      "Epoch: 276, Batch number: 0, Loss: 278.0334777832031\n",
      "Epoch: 277, Batch number: 24, Loss: 238.005615234375\n",
      "Epoch: 278, Batch number: 48, Loss: 289.3981018066406\n",
      "Epoch: 279, Batch number: 72, Loss: 254.6927947998047\n",
      "Epoch: 281, Batch number: 20, Loss: 292.64849853515625\n",
      "Epoch: 282, Batch number: 44, Loss: 250.23391723632812\n",
      "Epoch: 283, Batch number: 68, Loss: 255.9193878173828\n",
      "Epoch: 285, Batch number: 16, Loss: 205.28866577148438\n",
      "Epoch: 286, Batch number: 40, Loss: 304.67218017578125\n",
      "Epoch: 287, Batch number: 64, Loss: 255.0791015625\n",
      "Epoch: 289, Batch number: 12, Loss: 203.55702209472656\n",
      "Epoch: 290, Batch number: 36, Loss: 285.20025634765625\n",
      "Epoch: 291, Batch number: 60, Loss: 270.89788818359375\n",
      "Epoch: 293, Batch number: 8, Loss: 251.60433959960938\n",
      "Epoch: 294, Batch number: 32, Loss: 241.2268524169922\n",
      "Epoch: 295, Batch number: 56, Loss: 268.5406188964844\n",
      "Epoch: 297, Batch number: 4, Loss: 222.3264617919922\n",
      "Epoch: 298, Batch number: 28, Loss: 238.77651977539062\n",
      "Epoch: 299, Batch number: 52, Loss: 207.310791015625\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4408.47509765625\n",
      "Epoch: 2, Batch number: 24, Loss: 4218.32080078125\n",
      "Epoch: 3, Batch number: 48, Loss: 3985.306640625\n",
      "Epoch: 4, Batch number: 72, Loss: 3583.126953125\n",
      "Epoch: 6, Batch number: 20, Loss: 3156.223876953125\n",
      "Epoch: 7, Batch number: 44, Loss: 2925.758056640625\n",
      "Epoch: 8, Batch number: 68, Loss: 2774.667724609375\n",
      "Epoch: 10, Batch number: 16, Loss: 2830.71240234375\n",
      "Epoch: 11, Batch number: 40, Loss: 2548.554931640625\n",
      "Epoch: 12, Batch number: 64, Loss: 2646.611083984375\n",
      "Epoch: 14, Batch number: 12, Loss: 2470.8935546875\n",
      "Epoch: 15, Batch number: 36, Loss: 2469.2060546875\n",
      "Epoch: 16, Batch number: 60, Loss: 2405.106201171875\n",
      "Epoch: 18, Batch number: 8, Loss: 2397.925537109375\n",
      "Epoch: 19, Batch number: 32, Loss: 2309.70263671875\n",
      "Epoch: 20, Batch number: 56, Loss: 2255.6171875\n",
      "Epoch: 22, Batch number: 4, Loss: 2159.089599609375\n",
      "Epoch: 23, Batch number: 28, Loss: 2119.09228515625\n",
      "Epoch: 24, Batch number: 52, Loss: 2156.16064453125\n",
      "Epoch: 26, Batch number: 0, Loss: 2000.4241943359375\n",
      "Epoch: 27, Batch number: 24, Loss: 1920.2554931640625\n",
      "Epoch: 28, Batch number: 48, Loss: 1955.135986328125\n",
      "Epoch: 29, Batch number: 72, Loss: 1907.6033935546875\n",
      "Epoch: 31, Batch number: 20, Loss: 1888.853271484375\n",
      "Epoch: 32, Batch number: 44, Loss: 1767.548095703125\n",
      "Epoch: 33, Batch number: 68, Loss: 1765.4366455078125\n",
      "Epoch: 35, Batch number: 16, Loss: 1728.307373046875\n",
      "Epoch: 36, Batch number: 40, Loss: 1696.4417724609375\n",
      "Epoch: 37, Batch number: 64, Loss: 1614.504150390625\n",
      "Epoch: 39, Batch number: 12, Loss: 1565.6712646484375\n",
      "Epoch: 40, Batch number: 36, Loss: 1563.6014404296875\n",
      "Epoch: 41, Batch number: 60, Loss: 1472.709228515625\n",
      "Epoch: 43, Batch number: 8, Loss: 1507.2364501953125\n",
      "Epoch: 44, Batch number: 32, Loss: 1443.9189453125\n",
      "Epoch: 45, Batch number: 56, Loss: 1442.75146484375\n",
      "Epoch: 47, Batch number: 4, Loss: 1408.7542724609375\n",
      "Epoch: 48, Batch number: 28, Loss: 1277.5267333984375\n",
      "Epoch: 49, Batch number: 52, Loss: 1312.82958984375\n",
      "Epoch: 51, Batch number: 0, Loss: 1319.741943359375\n",
      "Epoch: 52, Batch number: 24, Loss: 1314.4791259765625\n",
      "Epoch: 53, Batch number: 48, Loss: 1257.97021484375\n",
      "Epoch: 54, Batch number: 72, Loss: 1285.4454345703125\n",
      "Epoch: 56, Batch number: 20, Loss: 1187.7520751953125\n",
      "Epoch: 57, Batch number: 44, Loss: 1143.690673828125\n",
      "Epoch: 58, Batch number: 68, Loss: 1098.5379638671875\n",
      "Epoch: 60, Batch number: 16, Loss: 1147.0435791015625\n",
      "Epoch: 61, Batch number: 40, Loss: 1060.029541015625\n",
      "Epoch: 62, Batch number: 64, Loss: 1091.230712890625\n",
      "Epoch: 64, Batch number: 12, Loss: 1018.9965209960938\n",
      "Epoch: 65, Batch number: 36, Loss: 1025.1763916015625\n",
      "Epoch: 66, Batch number: 60, Loss: 928.6324462890625\n",
      "Epoch: 68, Batch number: 8, Loss: 899.2996826171875\n",
      "Epoch: 69, Batch number: 32, Loss: 943.3802490234375\n",
      "Epoch: 70, Batch number: 56, Loss: 899.7781982421875\n",
      "Epoch: 72, Batch number: 4, Loss: 893.7338256835938\n",
      "Epoch: 73, Batch number: 28, Loss: 866.942626953125\n",
      "Epoch: 74, Batch number: 52, Loss: 888.4710693359375\n",
      "Epoch: 76, Batch number: 0, Loss: 912.6021728515625\n",
      "Epoch: 77, Batch number: 24, Loss: 813.626953125\n",
      "Epoch: 78, Batch number: 48, Loss: 814.4039306640625\n",
      "Epoch: 79, Batch number: 72, Loss: 815.9313354492188\n",
      "Epoch: 81, Batch number: 20, Loss: 759.889404296875\n",
      "Epoch: 82, Batch number: 44, Loss: 824.880126953125\n",
      "Epoch: 83, Batch number: 68, Loss: 782.943115234375\n",
      "Epoch: 85, Batch number: 16, Loss: 708.7520751953125\n",
      "Epoch: 86, Batch number: 40, Loss: 704.5682983398438\n",
      "Epoch: 87, Batch number: 64, Loss: 680.434814453125\n",
      "Epoch: 89, Batch number: 12, Loss: 694.4762573242188\n",
      "Epoch: 90, Batch number: 36, Loss: 671.1356811523438\n",
      "Epoch: 91, Batch number: 60, Loss: 669.7191772460938\n",
      "Epoch: 93, Batch number: 8, Loss: 628.0359497070312\n",
      "Epoch: 94, Batch number: 32, Loss: 581.8827514648438\n",
      "Epoch: 95, Batch number: 56, Loss: 604.81591796875\n",
      "Epoch: 97, Batch number: 4, Loss: 587.18798828125\n",
      "Epoch: 98, Batch number: 28, Loss: 596.2192993164062\n",
      "Epoch: 99, Batch number: 52, Loss: 558.1728515625\n",
      "Epoch: 101, Batch number: 0, Loss: 590.4420776367188\n",
      "Epoch: 102, Batch number: 24, Loss: 531.8707275390625\n",
      "Epoch: 103, Batch number: 48, Loss: 538.7611694335938\n",
      "Epoch: 104, Batch number: 72, Loss: 522.7969970703125\n",
      "Epoch: 106, Batch number: 20, Loss: 534.1923828125\n",
      "Epoch: 107, Batch number: 44, Loss: 510.8689270019531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Batch number: 68, Loss: 528.340087890625\n",
      "Epoch: 110, Batch number: 16, Loss: 498.2450256347656\n",
      "Epoch: 111, Batch number: 40, Loss: 466.84100341796875\n",
      "Epoch: 112, Batch number: 64, Loss: 481.3875732421875\n",
      "Epoch: 114, Batch number: 12, Loss: 438.2561950683594\n",
      "Epoch: 115, Batch number: 36, Loss: 456.71099853515625\n",
      "Epoch: 116, Batch number: 60, Loss: 398.46856689453125\n",
      "Epoch: 118, Batch number: 8, Loss: 409.944580078125\n",
      "Epoch: 119, Batch number: 32, Loss: 486.3676452636719\n",
      "Epoch: 120, Batch number: 56, Loss: 425.7526550292969\n",
      "Epoch: 122, Batch number: 4, Loss: 365.13677978515625\n",
      "Epoch: 123, Batch number: 28, Loss: 356.74407958984375\n",
      "Epoch: 124, Batch number: 52, Loss: 403.0973815917969\n",
      "Epoch: 126, Batch number: 0, Loss: 387.067626953125\n",
      "Epoch: 127, Batch number: 24, Loss: 367.94195556640625\n",
      "Epoch: 128, Batch number: 48, Loss: 420.463134765625\n",
      "Epoch: 129, Batch number: 72, Loss: 319.9982604980469\n",
      "Epoch: 131, Batch number: 20, Loss: 365.388916015625\n",
      "Epoch: 132, Batch number: 44, Loss: 407.0677185058594\n",
      "Epoch: 133, Batch number: 68, Loss: 334.2003173828125\n",
      "Epoch: 135, Batch number: 16, Loss: 290.0986328125\n",
      "Epoch: 136, Batch number: 40, Loss: 326.1620788574219\n",
      "Epoch: 137, Batch number: 64, Loss: 330.9309997558594\n",
      "Epoch: 139, Batch number: 12, Loss: 287.1983642578125\n",
      "Epoch: 140, Batch number: 36, Loss: 272.4928283691406\n",
      "Epoch: 141, Batch number: 60, Loss: 248.7611541748047\n",
      "Epoch: 143, Batch number: 8, Loss: 306.8890075683594\n",
      "Epoch: 144, Batch number: 32, Loss: 245.30377197265625\n",
      "Epoch: 145, Batch number: 56, Loss: 245.56414794921875\n",
      "Epoch: 147, Batch number: 4, Loss: 265.77728271484375\n",
      "Epoch: 148, Batch number: 28, Loss: 278.094970703125\n",
      "Epoch: 149, Batch number: 52, Loss: 261.6669006347656\n",
      "Epoch: 151, Batch number: 0, Loss: 235.96426391601562\n",
      "Epoch: 152, Batch number: 24, Loss: 234.3832244873047\n",
      "Epoch: 153, Batch number: 48, Loss: 257.3887023925781\n",
      "Epoch: 154, Batch number: 72, Loss: 237.28878784179688\n",
      "Epoch: 156, Batch number: 20, Loss: 234.3636016845703\n",
      "Epoch: 157, Batch number: 44, Loss: 217.79627990722656\n",
      "Epoch: 158, Batch number: 68, Loss: 257.6919250488281\n",
      "Epoch: 160, Batch number: 16, Loss: 185.86825561523438\n",
      "Epoch: 161, Batch number: 40, Loss: 213.77926635742188\n",
      "Epoch: 162, Batch number: 64, Loss: 216.5841064453125\n",
      "Epoch: 164, Batch number: 12, Loss: 184.52972412109375\n",
      "Epoch: 165, Batch number: 36, Loss: 189.4032745361328\n",
      "Epoch: 166, Batch number: 60, Loss: 189.4226531982422\n",
      "Epoch: 168, Batch number: 8, Loss: 196.28382873535156\n",
      "Epoch: 169, Batch number: 32, Loss: 190.3649444580078\n",
      "Epoch: 170, Batch number: 56, Loss: 187.22604370117188\n",
      "Epoch: 172, Batch number: 4, Loss: 162.9257354736328\n",
      "Epoch: 173, Batch number: 28, Loss: 165.891845703125\n",
      "Epoch: 174, Batch number: 52, Loss: 172.91952514648438\n",
      "Epoch: 176, Batch number: 0, Loss: 185.11351013183594\n",
      "Epoch: 177, Batch number: 24, Loss: 148.20899963378906\n",
      "Epoch: 178, Batch number: 48, Loss: 150.35995483398438\n",
      "Epoch: 179, Batch number: 72, Loss: 174.2310028076172\n",
      "Epoch: 181, Batch number: 20, Loss: 146.7736358642578\n",
      "Epoch: 182, Batch number: 44, Loss: 142.14268493652344\n",
      "Epoch: 183, Batch number: 68, Loss: 165.68174743652344\n",
      "Epoch: 185, Batch number: 16, Loss: 127.31898498535156\n",
      "Epoch: 186, Batch number: 40, Loss: 124.7326889038086\n",
      "Epoch: 187, Batch number: 64, Loss: 121.61555480957031\n",
      "Epoch: 189, Batch number: 12, Loss: 141.6138916015625\n",
      "Epoch: 190, Batch number: 36, Loss: 110.31364440917969\n",
      "Epoch: 191, Batch number: 60, Loss: 130.24603271484375\n",
      "Epoch: 193, Batch number: 8, Loss: 117.66863250732422\n",
      "Epoch: 194, Batch number: 32, Loss: 136.95782470703125\n",
      "Epoch: 195, Batch number: 56, Loss: 108.50416564941406\n",
      "Epoch: 197, Batch number: 4, Loss: 127.62107849121094\n",
      "Epoch: 198, Batch number: 28, Loss: 123.16930389404297\n",
      "Epoch: 199, Batch number: 52, Loss: 102.28077697753906\n",
      "Epoch: 201, Batch number: 0, Loss: 99.94161987304688\n",
      "Epoch: 202, Batch number: 24, Loss: 132.0215301513672\n",
      "Epoch: 203, Batch number: 48, Loss: 92.9844741821289\n",
      "Epoch: 204, Batch number: 72, Loss: 102.41809844970703\n",
      "Epoch: 206, Batch number: 20, Loss: 86.10006713867188\n",
      "Epoch: 207, Batch number: 44, Loss: 108.09992218017578\n",
      "Epoch: 208, Batch number: 68, Loss: 80.7994384765625\n",
      "Epoch: 210, Batch number: 16, Loss: 93.94255065917969\n",
      "Epoch: 211, Batch number: 40, Loss: 81.5434799194336\n",
      "Epoch: 212, Batch number: 64, Loss: 101.0228271484375\n",
      "Epoch: 214, Batch number: 12, Loss: 81.12416076660156\n",
      "Epoch: 215, Batch number: 36, Loss: 77.16024780273438\n",
      "Epoch: 216, Batch number: 60, Loss: 74.30290222167969\n",
      "Epoch: 218, Batch number: 8, Loss: 81.40945434570312\n",
      "Epoch: 219, Batch number: 32, Loss: 91.51220703125\n",
      "Epoch: 220, Batch number: 56, Loss: 81.01825714111328\n",
      "Epoch: 222, Batch number: 4, Loss: 66.3003158569336\n",
      "Epoch: 223, Batch number: 28, Loss: 73.78755187988281\n",
      "Epoch: 224, Batch number: 52, Loss: 72.23739624023438\n",
      "Epoch: 226, Batch number: 0, Loss: 70.12691497802734\n",
      "Epoch: 227, Batch number: 24, Loss: 72.84508514404297\n",
      "Epoch: 228, Batch number: 48, Loss: 64.18502044677734\n",
      "Epoch: 229, Batch number: 72, Loss: 72.86542510986328\n",
      "Epoch: 231, Batch number: 20, Loss: 78.1375503540039\n",
      "Epoch: 232, Batch number: 44, Loss: 76.93798065185547\n",
      "Epoch: 233, Batch number: 68, Loss: 60.337276458740234\n",
      "Epoch: 235, Batch number: 16, Loss: 44.42862319946289\n",
      "Epoch: 236, Batch number: 40, Loss: 57.73993682861328\n",
      "Epoch: 237, Batch number: 64, Loss: 64.35607147216797\n",
      "Epoch: 239, Batch number: 12, Loss: 47.09141159057617\n",
      "Epoch: 240, Batch number: 36, Loss: 58.301727294921875\n",
      "Epoch: 241, Batch number: 60, Loss: 57.64488983154297\n",
      "Epoch: 243, Batch number: 8, Loss: 57.56397247314453\n",
      "Epoch: 244, Batch number: 32, Loss: 51.01876449584961\n",
      "Epoch: 245, Batch number: 56, Loss: 78.15265655517578\n",
      "Epoch: 247, Batch number: 4, Loss: 54.458126068115234\n",
      "Epoch: 248, Batch number: 28, Loss: 54.99330139160156\n",
      "Epoch: 249, Batch number: 52, Loss: 45.99666976928711\n",
      "Epoch: 251, Batch number: 0, Loss: 49.31582260131836\n",
      "Epoch: 252, Batch number: 24, Loss: 41.458412170410156\n",
      "Epoch: 253, Batch number: 48, Loss: 38.150909423828125\n",
      "Epoch: 254, Batch number: 72, Loss: 56.13500213623047\n",
      "Epoch: 256, Batch number: 20, Loss: 44.38043212890625\n",
      "Epoch: 257, Batch number: 44, Loss: 41.280052185058594\n",
      "Epoch: 258, Batch number: 68, Loss: 39.86116027832031\n",
      "Epoch: 260, Batch number: 16, Loss: 41.267601013183594\n",
      "Epoch: 261, Batch number: 40, Loss: 46.1013069152832\n",
      "Epoch: 262, Batch number: 64, Loss: 53.7837028503418\n",
      "Epoch: 264, Batch number: 12, Loss: 44.24010467529297\n",
      "Epoch: 265, Batch number: 36, Loss: 47.38715362548828\n",
      "Epoch: 266, Batch number: 60, Loss: 45.331809997558594\n",
      "Epoch: 268, Batch number: 8, Loss: 31.664793014526367\n",
      "Epoch: 269, Batch number: 32, Loss: 36.19934844970703\n",
      "Epoch: 270, Batch number: 56, Loss: 31.40842056274414\n",
      "Epoch: 272, Batch number: 4, Loss: 38.23294448852539\n",
      "Epoch: 273, Batch number: 28, Loss: 32.36931610107422\n",
      "Epoch: 274, Batch number: 52, Loss: 24.335721969604492\n",
      "Epoch: 276, Batch number: 0, Loss: 29.50334930419922\n",
      "Epoch: 277, Batch number: 24, Loss: 32.32862854003906\n",
      "Epoch: 278, Batch number: 48, Loss: 38.402259826660156\n",
      "Epoch: 279, Batch number: 72, Loss: 42.1750373840332\n",
      "Epoch: 281, Batch number: 20, Loss: 27.543031692504883\n",
      "Epoch: 282, Batch number: 44, Loss: 29.697784423828125\n",
      "Epoch: 283, Batch number: 68, Loss: 34.91219711303711\n",
      "Epoch: 285, Batch number: 16, Loss: 30.775571823120117\n",
      "Epoch: 286, Batch number: 40, Loss: 27.273433685302734\n",
      "Epoch: 287, Batch number: 64, Loss: 26.707550048828125\n",
      "Epoch: 289, Batch number: 12, Loss: 34.692604064941406\n",
      "Epoch: 290, Batch number: 36, Loss: 30.39844512939453\n",
      "Epoch: 291, Batch number: 60, Loss: 22.357898712158203\n",
      "Epoch: 293, Batch number: 8, Loss: 33.39173126220703\n",
      "Epoch: 294, Batch number: 32, Loss: 22.796279907226562\n",
      "Epoch: 295, Batch number: 56, Loss: 25.768882751464844\n",
      "Epoch: 297, Batch number: 4, Loss: 23.12518310546875\n",
      "Epoch: 298, Batch number: 28, Loss: 27.651405334472656\n",
      "Epoch: 299, Batch number: 52, Loss: 25.49620819091797\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4410.19482421875\n",
      "Epoch: 2, Batch number: 24, Loss: 4139.8154296875\n",
      "Epoch: 3, Batch number: 48, Loss: 3729.08642578125\n",
      "Epoch: 4, Batch number: 72, Loss: 3175.962890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Batch number: 20, Loss: 2876.79931640625\n",
      "Epoch: 7, Batch number: 44, Loss: 2725.5146484375\n",
      "Epoch: 8, Batch number: 68, Loss: 2775.987548828125\n",
      "Epoch: 10, Batch number: 16, Loss: 2462.76171875\n",
      "Epoch: 11, Batch number: 40, Loss: 2432.40185546875\n",
      "Epoch: 12, Batch number: 64, Loss: 2398.9091796875\n",
      "Epoch: 14, Batch number: 12, Loss: 2298.080322265625\n",
      "Epoch: 15, Batch number: 36, Loss: 2231.2880859375\n",
      "Epoch: 16, Batch number: 60, Loss: 2247.1044921875\n",
      "Epoch: 18, Batch number: 8, Loss: 2038.431884765625\n",
      "Epoch: 19, Batch number: 32, Loss: 1973.506591796875\n",
      "Epoch: 20, Batch number: 56, Loss: 1921.2174072265625\n",
      "Epoch: 22, Batch number: 4, Loss: 1893.5460205078125\n",
      "Epoch: 23, Batch number: 28, Loss: 1763.9639892578125\n",
      "Epoch: 24, Batch number: 52, Loss: 1726.6724853515625\n",
      "Epoch: 26, Batch number: 0, Loss: 1666.7762451171875\n",
      "Epoch: 27, Batch number: 24, Loss: 1590.7777099609375\n",
      "Epoch: 28, Batch number: 48, Loss: 1547.62451171875\n",
      "Epoch: 29, Batch number: 72, Loss: 1562.9871826171875\n",
      "Epoch: 31, Batch number: 20, Loss: 1462.7530517578125\n",
      "Epoch: 32, Batch number: 44, Loss: 1470.3197021484375\n",
      "Epoch: 33, Batch number: 68, Loss: 1362.39697265625\n",
      "Epoch: 35, Batch number: 16, Loss: 1327.7803955078125\n",
      "Epoch: 36, Batch number: 40, Loss: 1263.2220458984375\n",
      "Epoch: 37, Batch number: 64, Loss: 1161.4293212890625\n",
      "Epoch: 39, Batch number: 12, Loss: 1239.029541015625\n",
      "Epoch: 40, Batch number: 36, Loss: 1197.19580078125\n",
      "Epoch: 41, Batch number: 60, Loss: 1131.6446533203125\n",
      "Epoch: 43, Batch number: 8, Loss: 1194.4478759765625\n",
      "Epoch: 44, Batch number: 32, Loss: 1024.66162109375\n",
      "Epoch: 45, Batch number: 56, Loss: 1095.150390625\n",
      "Epoch: 47, Batch number: 4, Loss: 1002.4244995117188\n",
      "Epoch: 48, Batch number: 28, Loss: 927.9011840820312\n",
      "Epoch: 49, Batch number: 52, Loss: 933.2962646484375\n",
      "Epoch: 51, Batch number: 0, Loss: 862.7267456054688\n",
      "Epoch: 52, Batch number: 24, Loss: 824.0001831054688\n",
      "Epoch: 53, Batch number: 48, Loss: 857.3441162109375\n",
      "Epoch: 54, Batch number: 72, Loss: 864.2489624023438\n",
      "Epoch: 56, Batch number: 20, Loss: 805.6438598632812\n",
      "Epoch: 57, Batch number: 44, Loss: 808.93408203125\n",
      "Epoch: 58, Batch number: 68, Loss: 772.6902465820312\n",
      "Epoch: 60, Batch number: 16, Loss: 760.4512939453125\n",
      "Epoch: 61, Batch number: 40, Loss: 688.550048828125\n",
      "Epoch: 62, Batch number: 64, Loss: 686.5382690429688\n",
      "Epoch: 64, Batch number: 12, Loss: 688.7020874023438\n",
      "Epoch: 65, Batch number: 36, Loss: 743.8196411132812\n",
      "Epoch: 66, Batch number: 60, Loss: 644.262451171875\n",
      "Epoch: 68, Batch number: 8, Loss: 633.3045043945312\n",
      "Epoch: 69, Batch number: 32, Loss: 649.234619140625\n",
      "Epoch: 70, Batch number: 56, Loss: 516.9552001953125\n",
      "Epoch: 72, Batch number: 4, Loss: 556.136474609375\n",
      "Epoch: 73, Batch number: 28, Loss: 556.5418701171875\n",
      "Epoch: 74, Batch number: 52, Loss: 522.9385375976562\n",
      "Epoch: 76, Batch number: 0, Loss: 517.7261352539062\n",
      "Epoch: 77, Batch number: 24, Loss: 509.94793701171875\n",
      "Epoch: 78, Batch number: 48, Loss: 513.7792358398438\n",
      "Epoch: 79, Batch number: 72, Loss: 509.117919921875\n",
      "Epoch: 81, Batch number: 20, Loss: 474.2588806152344\n",
      "Epoch: 82, Batch number: 44, Loss: 447.1481628417969\n",
      "Epoch: 83, Batch number: 68, Loss: 430.9306945800781\n",
      "Epoch: 85, Batch number: 16, Loss: 440.25323486328125\n",
      "Epoch: 86, Batch number: 40, Loss: 402.9055480957031\n",
      "Epoch: 87, Batch number: 64, Loss: 366.0631103515625\n",
      "Epoch: 89, Batch number: 12, Loss: 348.7488098144531\n",
      "Epoch: 90, Batch number: 36, Loss: 367.4828796386719\n",
      "Epoch: 91, Batch number: 60, Loss: 374.9358825683594\n",
      "Epoch: 93, Batch number: 8, Loss: 352.6187744140625\n",
      "Epoch: 94, Batch number: 32, Loss: 338.68316650390625\n",
      "Epoch: 95, Batch number: 56, Loss: 351.51507568359375\n",
      "Epoch: 97, Batch number: 4, Loss: 329.5336608886719\n",
      "Epoch: 98, Batch number: 28, Loss: 309.4601135253906\n",
      "Epoch: 99, Batch number: 52, Loss: 307.6258544921875\n",
      "Epoch: 101, Batch number: 0, Loss: 305.5553283691406\n",
      "Epoch: 102, Batch number: 24, Loss: 307.01116943359375\n",
      "Epoch: 103, Batch number: 48, Loss: 302.0743408203125\n",
      "Epoch: 104, Batch number: 72, Loss: 274.5761413574219\n",
      "Epoch: 106, Batch number: 20, Loss: 296.6643981933594\n",
      "Epoch: 107, Batch number: 44, Loss: 240.42416381835938\n",
      "Epoch: 108, Batch number: 68, Loss: 250.16912841796875\n",
      "Epoch: 110, Batch number: 16, Loss: 252.53173828125\n",
      "Epoch: 111, Batch number: 40, Loss: 235.06089782714844\n",
      "Epoch: 112, Batch number: 64, Loss: 238.2576141357422\n",
      "Epoch: 114, Batch number: 12, Loss: 233.9290313720703\n",
      "Epoch: 115, Batch number: 36, Loss: 194.8367156982422\n",
      "Epoch: 116, Batch number: 60, Loss: 218.70260620117188\n",
      "Epoch: 118, Batch number: 8, Loss: 214.38475036621094\n",
      "Epoch: 119, Batch number: 32, Loss: 185.550048828125\n",
      "Epoch: 120, Batch number: 56, Loss: 176.81137084960938\n",
      "Epoch: 122, Batch number: 4, Loss: 178.99256896972656\n",
      "Epoch: 123, Batch number: 28, Loss: 175.47744750976562\n",
      "Epoch: 124, Batch number: 52, Loss: 197.6029815673828\n",
      "Epoch: 126, Batch number: 0, Loss: 173.71514892578125\n",
      "Epoch: 127, Batch number: 24, Loss: 204.61279296875\n",
      "Epoch: 128, Batch number: 48, Loss: 193.3378448486328\n",
      "Epoch: 129, Batch number: 72, Loss: 146.34230041503906\n",
      "Epoch: 131, Batch number: 20, Loss: 147.88880920410156\n",
      "Epoch: 132, Batch number: 44, Loss: 148.99862670898438\n",
      "Epoch: 133, Batch number: 68, Loss: 184.27291870117188\n",
      "Epoch: 135, Batch number: 16, Loss: 143.4156036376953\n",
      "Epoch: 136, Batch number: 40, Loss: 129.36865234375\n",
      "Epoch: 137, Batch number: 64, Loss: 133.8694610595703\n",
      "Epoch: 139, Batch number: 12, Loss: 129.0491943359375\n",
      "Epoch: 140, Batch number: 36, Loss: 142.15953063964844\n",
      "Epoch: 141, Batch number: 60, Loss: 101.54203033447266\n",
      "Epoch: 143, Batch number: 8, Loss: 105.64258575439453\n",
      "Epoch: 144, Batch number: 32, Loss: 116.21186065673828\n",
      "Epoch: 145, Batch number: 56, Loss: 135.59072875976562\n",
      "Epoch: 147, Batch number: 4, Loss: 105.85595703125\n",
      "Epoch: 148, Batch number: 28, Loss: 99.29789733886719\n",
      "Epoch: 149, Batch number: 52, Loss: 115.54896545410156\n",
      "Epoch: 151, Batch number: 0, Loss: 115.19171905517578\n",
      "Epoch: 152, Batch number: 24, Loss: 86.84194946289062\n",
      "Epoch: 153, Batch number: 48, Loss: 71.47083282470703\n",
      "Epoch: 154, Batch number: 72, Loss: 92.52938842773438\n",
      "Epoch: 156, Batch number: 20, Loss: 89.12918090820312\n",
      "Epoch: 157, Batch number: 44, Loss: 84.95145416259766\n",
      "Epoch: 158, Batch number: 68, Loss: 88.24037170410156\n",
      "Epoch: 160, Batch number: 16, Loss: 88.53956604003906\n",
      "Epoch: 161, Batch number: 40, Loss: 92.11856079101562\n",
      "Epoch: 162, Batch number: 64, Loss: 61.7734260559082\n",
      "Epoch: 164, Batch number: 12, Loss: 76.75542449951172\n",
      "Epoch: 165, Batch number: 36, Loss: 70.73932647705078\n",
      "Epoch: 166, Batch number: 60, Loss: 66.48828125\n",
      "Epoch: 168, Batch number: 8, Loss: 66.25970458984375\n",
      "Epoch: 169, Batch number: 32, Loss: 74.65323638916016\n",
      "Epoch: 170, Batch number: 56, Loss: 74.43528747558594\n",
      "Epoch: 172, Batch number: 4, Loss: 62.60518264770508\n",
      "Epoch: 173, Batch number: 28, Loss: 51.37213897705078\n",
      "Epoch: 174, Batch number: 52, Loss: 73.99801635742188\n",
      "Epoch: 176, Batch number: 0, Loss: 52.906089782714844\n",
      "Epoch: 177, Batch number: 24, Loss: 46.082298278808594\n",
      "Epoch: 178, Batch number: 48, Loss: 53.81963348388672\n",
      "Epoch: 179, Batch number: 72, Loss: 65.26512145996094\n",
      "Epoch: 181, Batch number: 20, Loss: 49.174964904785156\n",
      "Epoch: 182, Batch number: 44, Loss: 53.4190559387207\n",
      "Epoch: 183, Batch number: 68, Loss: 56.62235641479492\n",
      "Epoch: 185, Batch number: 16, Loss: 44.13547897338867\n",
      "Epoch: 186, Batch number: 40, Loss: 61.38862991333008\n",
      "Epoch: 187, Batch number: 64, Loss: 41.070152282714844\n",
      "Epoch: 189, Batch number: 12, Loss: 52.01285934448242\n",
      "Epoch: 190, Batch number: 36, Loss: 42.47713088989258\n",
      "Epoch: 191, Batch number: 60, Loss: 33.43135452270508\n",
      "Epoch: 193, Batch number: 8, Loss: 50.156028747558594\n",
      "Epoch: 194, Batch number: 32, Loss: 44.93669891357422\n",
      "Epoch: 195, Batch number: 56, Loss: 42.85762405395508\n",
      "Epoch: 197, Batch number: 4, Loss: 37.78791809082031\n",
      "Epoch: 198, Batch number: 28, Loss: 35.653873443603516\n",
      "Epoch: 199, Batch number: 52, Loss: 37.07410430908203\n",
      "Epoch: 201, Batch number: 0, Loss: 40.41118621826172\n",
      "Epoch: 202, Batch number: 24, Loss: 31.834339141845703\n",
      "Epoch: 203, Batch number: 48, Loss: 32.32073211669922\n",
      "Epoch: 204, Batch number: 72, Loss: 41.5180778503418\n",
      "Epoch: 206, Batch number: 20, Loss: 32.10250473022461\n",
      "Epoch: 207, Batch number: 44, Loss: 34.37077713012695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 33.48646545410156\n",
      "Epoch: 210, Batch number: 16, Loss: 29.437273025512695\n",
      "Epoch: 211, Batch number: 40, Loss: 34.170188903808594\n",
      "Epoch: 212, Batch number: 64, Loss: 26.435123443603516\n",
      "Epoch: 214, Batch number: 12, Loss: 29.999439239501953\n",
      "Epoch: 215, Batch number: 36, Loss: 29.52587127685547\n",
      "Epoch: 216, Batch number: 60, Loss: 31.979469299316406\n",
      "Epoch: 218, Batch number: 8, Loss: 32.806697845458984\n",
      "Epoch: 219, Batch number: 32, Loss: 30.614055633544922\n",
      "Epoch: 220, Batch number: 56, Loss: 32.41533279418945\n",
      "Epoch: 222, Batch number: 4, Loss: 21.847877502441406\n",
      "Epoch: 223, Batch number: 28, Loss: 28.431232452392578\n",
      "Epoch: 224, Batch number: 52, Loss: 21.328683853149414\n",
      "Epoch: 226, Batch number: 0, Loss: 28.196855545043945\n",
      "Epoch: 227, Batch number: 24, Loss: 32.133575439453125\n",
      "Epoch: 228, Batch number: 48, Loss: 31.62584686279297\n",
      "Epoch: 229, Batch number: 72, Loss: 29.529396057128906\n",
      "Epoch: 231, Batch number: 20, Loss: 29.821916580200195\n",
      "Epoch: 232, Batch number: 44, Loss: 25.004600524902344\n",
      "Epoch: 233, Batch number: 68, Loss: 23.856403350830078\n",
      "Epoch: 235, Batch number: 16, Loss: 18.55069923400879\n",
      "Epoch: 236, Batch number: 40, Loss: 20.425365447998047\n",
      "Epoch: 237, Batch number: 64, Loss: 22.95526123046875\n",
      "Epoch: 239, Batch number: 12, Loss: 26.2288875579834\n",
      "Epoch: 240, Batch number: 36, Loss: 18.729637145996094\n",
      "Epoch: 241, Batch number: 60, Loss: 21.427766799926758\n",
      "Epoch: 243, Batch number: 8, Loss: 18.82077407836914\n",
      "Epoch: 244, Batch number: 32, Loss: 15.897189140319824\n",
      "Epoch: 245, Batch number: 56, Loss: 24.10399627685547\n",
      "Epoch: 247, Batch number: 4, Loss: 17.455041885375977\n",
      "Epoch: 248, Batch number: 28, Loss: 16.598365783691406\n",
      "Epoch: 249, Batch number: 52, Loss: 20.876304626464844\n",
      "Epoch: 251, Batch number: 0, Loss: 18.910457611083984\n",
      "Epoch: 252, Batch number: 24, Loss: 25.287643432617188\n",
      "Epoch: 253, Batch number: 48, Loss: 24.839763641357422\n",
      "Epoch: 254, Batch number: 72, Loss: 18.877241134643555\n",
      "Epoch: 256, Batch number: 20, Loss: 19.60110855102539\n",
      "Epoch: 257, Batch number: 44, Loss: 25.16571807861328\n",
      "Epoch: 258, Batch number: 68, Loss: 16.432859420776367\n",
      "Epoch: 260, Batch number: 16, Loss: 20.865821838378906\n",
      "Epoch: 261, Batch number: 40, Loss: 16.1607666015625\n",
      "Epoch: 262, Batch number: 64, Loss: 14.913485527038574\n",
      "Epoch: 264, Batch number: 12, Loss: 16.779434204101562\n",
      "Epoch: 265, Batch number: 36, Loss: 16.67900848388672\n",
      "Epoch: 266, Batch number: 60, Loss: 23.472816467285156\n",
      "Epoch: 268, Batch number: 8, Loss: 19.355281829833984\n",
      "Epoch: 269, Batch number: 32, Loss: 11.262901306152344\n",
      "Epoch: 270, Batch number: 56, Loss: 16.948566436767578\n",
      "Epoch: 272, Batch number: 4, Loss: 8.56924819946289\n",
      "Epoch: 273, Batch number: 28, Loss: 14.268444061279297\n",
      "Epoch: 274, Batch number: 52, Loss: 11.804231643676758\n",
      "Epoch: 276, Batch number: 0, Loss: 15.938434600830078\n",
      "Epoch: 277, Batch number: 24, Loss: 11.482831954956055\n",
      "Epoch: 278, Batch number: 48, Loss: 14.537182807922363\n",
      "Epoch: 279, Batch number: 72, Loss: 11.971057891845703\n",
      "Epoch: 281, Batch number: 20, Loss: 11.680048942565918\n",
      "Epoch: 282, Batch number: 44, Loss: 11.772743225097656\n",
      "Epoch: 283, Batch number: 68, Loss: 12.222521781921387\n",
      "Epoch: 285, Batch number: 16, Loss: 13.67807388305664\n",
      "Epoch: 286, Batch number: 40, Loss: 13.726792335510254\n",
      "Epoch: 287, Batch number: 64, Loss: 11.850790023803711\n",
      "Epoch: 289, Batch number: 12, Loss: 15.362215995788574\n",
      "Epoch: 290, Batch number: 36, Loss: 13.205571174621582\n",
      "Epoch: 291, Batch number: 60, Loss: 8.666325569152832\n",
      "Epoch: 293, Batch number: 8, Loss: 9.720863342285156\n",
      "Epoch: 294, Batch number: 32, Loss: 16.514760971069336\n",
      "Epoch: 295, Batch number: 56, Loss: 9.781208038330078\n",
      "Epoch: 297, Batch number: 4, Loss: 11.308016777038574\n",
      "Epoch: 298, Batch number: 28, Loss: 14.273297309875488\n",
      "Epoch: 299, Batch number: 52, Loss: 13.792801856994629\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4415.1708984375\n",
      "Epoch: 2, Batch number: 24, Loss: 4034.14599609375\n",
      "Epoch: 3, Batch number: 48, Loss: 3522.49951171875\n",
      "Epoch: 4, Batch number: 72, Loss: 3068.2431640625\n",
      "Epoch: 6, Batch number: 20, Loss: 2896.523193359375\n",
      "Epoch: 7, Batch number: 44, Loss: 2721.96337890625\n",
      "Epoch: 8, Batch number: 68, Loss: 2518.95751953125\n",
      "Epoch: 10, Batch number: 16, Loss: 2375.552490234375\n",
      "Epoch: 11, Batch number: 40, Loss: 2399.087646484375\n",
      "Epoch: 12, Batch number: 64, Loss: 2242.331298828125\n",
      "Epoch: 14, Batch number: 12, Loss: 2065.696533203125\n",
      "Epoch: 15, Batch number: 36, Loss: 2046.5069580078125\n",
      "Epoch: 16, Batch number: 60, Loss: 1974.0303955078125\n",
      "Epoch: 18, Batch number: 8, Loss: 1885.776123046875\n",
      "Epoch: 19, Batch number: 32, Loss: 1890.0809326171875\n",
      "Epoch: 20, Batch number: 56, Loss: 1723.873291015625\n",
      "Epoch: 22, Batch number: 4, Loss: 1590.296630859375\n",
      "Epoch: 23, Batch number: 28, Loss: 1554.645751953125\n",
      "Epoch: 24, Batch number: 52, Loss: 1557.6787109375\n",
      "Epoch: 26, Batch number: 0, Loss: 1395.00048828125\n",
      "Epoch: 27, Batch number: 24, Loss: 1337.73876953125\n",
      "Epoch: 28, Batch number: 48, Loss: 1349.52734375\n",
      "Epoch: 29, Batch number: 72, Loss: 1264.648193359375\n",
      "Epoch: 31, Batch number: 20, Loss: 1224.3033447265625\n",
      "Epoch: 32, Batch number: 44, Loss: 1132.3013916015625\n",
      "Epoch: 33, Batch number: 68, Loss: 1140.9302978515625\n",
      "Epoch: 35, Batch number: 16, Loss: 1129.874755859375\n",
      "Epoch: 36, Batch number: 40, Loss: 1065.6427001953125\n",
      "Epoch: 37, Batch number: 64, Loss: 1011.3978881835938\n",
      "Epoch: 39, Batch number: 12, Loss: 947.2659912109375\n",
      "Epoch: 40, Batch number: 36, Loss: 1003.84375\n",
      "Epoch: 41, Batch number: 60, Loss: 927.4434814453125\n",
      "Epoch: 43, Batch number: 8, Loss: 823.7713012695312\n",
      "Epoch: 44, Batch number: 32, Loss: 882.8480224609375\n",
      "Epoch: 45, Batch number: 56, Loss: 854.8805541992188\n",
      "Epoch: 47, Batch number: 4, Loss: 760.6323852539062\n",
      "Epoch: 48, Batch number: 28, Loss: 793.5068359375\n",
      "Epoch: 49, Batch number: 52, Loss: 744.4619140625\n",
      "Epoch: 51, Batch number: 0, Loss: 689.5609130859375\n",
      "Epoch: 52, Batch number: 24, Loss: 601.9475708007812\n",
      "Epoch: 53, Batch number: 48, Loss: 681.5523071289062\n",
      "Epoch: 54, Batch number: 72, Loss: 599.0978393554688\n",
      "Epoch: 56, Batch number: 20, Loss: 582.3587646484375\n",
      "Epoch: 57, Batch number: 44, Loss: 555.9695434570312\n",
      "Epoch: 58, Batch number: 68, Loss: 544.3504028320312\n",
      "Epoch: 60, Batch number: 16, Loss: 543.8677978515625\n",
      "Epoch: 61, Batch number: 40, Loss: 483.7619323730469\n",
      "Epoch: 62, Batch number: 64, Loss: 553.6610717773438\n",
      "Epoch: 64, Batch number: 12, Loss: 463.3401184082031\n",
      "Epoch: 65, Batch number: 36, Loss: 500.5653991699219\n",
      "Epoch: 66, Batch number: 60, Loss: 495.14056396484375\n",
      "Epoch: 68, Batch number: 8, Loss: 430.8970031738281\n",
      "Epoch: 69, Batch number: 32, Loss: 405.9697570800781\n",
      "Epoch: 70, Batch number: 56, Loss: 438.1842346191406\n",
      "Epoch: 72, Batch number: 4, Loss: 381.2543029785156\n",
      "Epoch: 73, Batch number: 28, Loss: 377.7375793457031\n",
      "Epoch: 74, Batch number: 52, Loss: 345.78900146484375\n",
      "Epoch: 76, Batch number: 0, Loss: 384.1751708984375\n",
      "Epoch: 77, Batch number: 24, Loss: 369.2169189453125\n",
      "Epoch: 78, Batch number: 48, Loss: 323.5887145996094\n",
      "Epoch: 79, Batch number: 72, Loss: 338.3648986816406\n",
      "Epoch: 81, Batch number: 20, Loss: 304.64642333984375\n",
      "Epoch: 82, Batch number: 44, Loss: 309.1976623535156\n",
      "Epoch: 83, Batch number: 68, Loss: 298.1181640625\n",
      "Epoch: 85, Batch number: 16, Loss: 253.45013427734375\n",
      "Epoch: 86, Batch number: 40, Loss: 260.9442138671875\n",
      "Epoch: 87, Batch number: 64, Loss: 271.3307800292969\n",
      "Epoch: 89, Batch number: 12, Loss: 237.71336364746094\n",
      "Epoch: 90, Batch number: 36, Loss: 235.68502807617188\n",
      "Epoch: 91, Batch number: 60, Loss: 215.84768676757812\n",
      "Epoch: 93, Batch number: 8, Loss: 184.04421997070312\n",
      "Epoch: 94, Batch number: 32, Loss: 204.24623107910156\n",
      "Epoch: 95, Batch number: 56, Loss: 227.05645751953125\n",
      "Epoch: 97, Batch number: 4, Loss: 195.38023376464844\n",
      "Epoch: 98, Batch number: 28, Loss: 199.1923065185547\n",
      "Epoch: 99, Batch number: 52, Loss: 214.0093231201172\n",
      "Epoch: 101, Batch number: 0, Loss: 181.4190216064453\n",
      "Epoch: 102, Batch number: 24, Loss: 159.85459899902344\n",
      "Epoch: 103, Batch number: 48, Loss: 147.4286651611328\n",
      "Epoch: 104, Batch number: 72, Loss: 179.66531372070312\n",
      "Epoch: 106, Batch number: 20, Loss: 148.74244689941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 133.01023864746094\n",
      "Epoch: 108, Batch number: 68, Loss: 146.47723388671875\n",
      "Epoch: 110, Batch number: 16, Loss: 147.15704345703125\n",
      "Epoch: 111, Batch number: 40, Loss: 139.41671752929688\n",
      "Epoch: 112, Batch number: 64, Loss: 140.9846954345703\n",
      "Epoch: 114, Batch number: 12, Loss: 127.38453674316406\n",
      "Epoch: 115, Batch number: 36, Loss: 117.19593048095703\n",
      "Epoch: 116, Batch number: 60, Loss: 134.39190673828125\n",
      "Epoch: 118, Batch number: 8, Loss: 118.88227844238281\n",
      "Epoch: 119, Batch number: 32, Loss: 114.29545593261719\n",
      "Epoch: 120, Batch number: 56, Loss: 117.43024444580078\n",
      "Epoch: 122, Batch number: 4, Loss: 93.58918762207031\n",
      "Epoch: 123, Batch number: 28, Loss: 98.54481506347656\n",
      "Epoch: 124, Batch number: 52, Loss: 126.0041275024414\n",
      "Epoch: 126, Batch number: 0, Loss: 78.23291778564453\n",
      "Epoch: 127, Batch number: 24, Loss: 92.51487731933594\n",
      "Epoch: 128, Batch number: 48, Loss: 99.62059020996094\n",
      "Epoch: 129, Batch number: 72, Loss: 104.42208862304688\n",
      "Epoch: 131, Batch number: 20, Loss: 73.80642700195312\n",
      "Epoch: 132, Batch number: 44, Loss: 74.83966827392578\n",
      "Epoch: 133, Batch number: 68, Loss: 81.69786834716797\n",
      "Epoch: 135, Batch number: 16, Loss: 69.79045867919922\n",
      "Epoch: 136, Batch number: 40, Loss: 78.4994888305664\n",
      "Epoch: 137, Batch number: 64, Loss: 65.85287475585938\n",
      "Epoch: 139, Batch number: 12, Loss: 57.02534103393555\n",
      "Epoch: 140, Batch number: 36, Loss: 85.33934020996094\n",
      "Epoch: 141, Batch number: 60, Loss: 70.97004699707031\n",
      "Epoch: 143, Batch number: 8, Loss: 59.67475128173828\n",
      "Epoch: 144, Batch number: 32, Loss: 54.35433578491211\n",
      "Epoch: 145, Batch number: 56, Loss: 52.78240203857422\n",
      "Epoch: 147, Batch number: 4, Loss: 59.1375732421875\n",
      "Epoch: 148, Batch number: 28, Loss: 64.26737976074219\n",
      "Epoch: 149, Batch number: 52, Loss: 62.15220260620117\n",
      "Epoch: 151, Batch number: 0, Loss: 54.41455841064453\n",
      "Epoch: 152, Batch number: 24, Loss: 67.22457885742188\n",
      "Epoch: 153, Batch number: 48, Loss: 54.686038970947266\n",
      "Epoch: 154, Batch number: 72, Loss: 57.193668365478516\n",
      "Epoch: 156, Batch number: 20, Loss: 43.673667907714844\n",
      "Epoch: 157, Batch number: 44, Loss: 41.10798645019531\n",
      "Epoch: 158, Batch number: 68, Loss: 51.08797073364258\n",
      "Epoch: 160, Batch number: 16, Loss: 40.02400588989258\n",
      "Epoch: 161, Batch number: 40, Loss: 44.01774597167969\n",
      "Epoch: 162, Batch number: 64, Loss: 44.95854187011719\n",
      "Epoch: 164, Batch number: 12, Loss: 35.65296936035156\n",
      "Epoch: 165, Batch number: 36, Loss: 39.30398178100586\n",
      "Epoch: 166, Batch number: 60, Loss: 39.27948760986328\n",
      "Epoch: 168, Batch number: 8, Loss: 40.202301025390625\n",
      "Epoch: 169, Batch number: 32, Loss: 44.13485336303711\n",
      "Epoch: 170, Batch number: 56, Loss: 34.66886901855469\n",
      "Epoch: 172, Batch number: 4, Loss: 37.31673812866211\n",
      "Epoch: 173, Batch number: 28, Loss: 32.38316345214844\n",
      "Epoch: 174, Batch number: 52, Loss: 34.50732421875\n",
      "Epoch: 176, Batch number: 0, Loss: 39.689857482910156\n",
      "Epoch: 177, Batch number: 24, Loss: 28.26301383972168\n",
      "Epoch: 178, Batch number: 48, Loss: 29.319520950317383\n",
      "Epoch: 179, Batch number: 72, Loss: 31.7322998046875\n",
      "Epoch: 181, Batch number: 20, Loss: 26.00098419189453\n",
      "Epoch: 182, Batch number: 44, Loss: 32.36355209350586\n",
      "Epoch: 183, Batch number: 68, Loss: 30.93169403076172\n",
      "Epoch: 185, Batch number: 16, Loss: 28.109832763671875\n",
      "Epoch: 186, Batch number: 40, Loss: 23.75238037109375\n",
      "Epoch: 187, Batch number: 64, Loss: 30.44647216796875\n",
      "Epoch: 189, Batch number: 12, Loss: 32.39657974243164\n",
      "Epoch: 190, Batch number: 36, Loss: 31.670265197753906\n",
      "Epoch: 191, Batch number: 60, Loss: 31.31591033935547\n",
      "Epoch: 193, Batch number: 8, Loss: 23.361753463745117\n",
      "Epoch: 194, Batch number: 32, Loss: 29.432552337646484\n",
      "Epoch: 195, Batch number: 56, Loss: 22.131450653076172\n",
      "Epoch: 197, Batch number: 4, Loss: 26.660888671875\n",
      "Epoch: 198, Batch number: 28, Loss: 21.152923583984375\n",
      "Epoch: 199, Batch number: 52, Loss: 26.448101043701172\n",
      "Epoch: 201, Batch number: 0, Loss: 22.020374298095703\n",
      "Epoch: 202, Batch number: 24, Loss: 24.070602416992188\n",
      "Epoch: 203, Batch number: 48, Loss: 17.19951057434082\n",
      "Epoch: 204, Batch number: 72, Loss: 18.69149398803711\n",
      "Epoch: 206, Batch number: 20, Loss: 18.589630126953125\n",
      "Epoch: 207, Batch number: 44, Loss: 18.068946838378906\n",
      "Epoch: 208, Batch number: 68, Loss: 19.27103042602539\n",
      "Epoch: 210, Batch number: 16, Loss: 14.443754196166992\n",
      "Epoch: 211, Batch number: 40, Loss: 18.76378059387207\n",
      "Epoch: 212, Batch number: 64, Loss: 14.489150047302246\n",
      "Epoch: 214, Batch number: 12, Loss: 15.88994312286377\n",
      "Epoch: 215, Batch number: 36, Loss: 29.530858993530273\n",
      "Epoch: 216, Batch number: 60, Loss: 17.560922622680664\n",
      "Epoch: 218, Batch number: 8, Loss: 20.842456817626953\n",
      "Epoch: 219, Batch number: 32, Loss: 12.806870460510254\n",
      "Epoch: 220, Batch number: 56, Loss: 16.291534423828125\n",
      "Epoch: 222, Batch number: 4, Loss: 22.56031036376953\n",
      "Epoch: 223, Batch number: 28, Loss: 12.747684478759766\n",
      "Epoch: 224, Batch number: 52, Loss: 12.17365837097168\n",
      "Epoch: 226, Batch number: 0, Loss: 20.030183792114258\n",
      "Epoch: 227, Batch number: 24, Loss: 20.22753143310547\n",
      "Epoch: 228, Batch number: 48, Loss: 16.505661010742188\n",
      "Epoch: 229, Batch number: 72, Loss: 20.589540481567383\n",
      "Epoch: 231, Batch number: 20, Loss: 10.93681526184082\n",
      "Epoch: 232, Batch number: 44, Loss: 15.174297332763672\n",
      "Epoch: 233, Batch number: 68, Loss: 14.532827377319336\n",
      "Epoch: 235, Batch number: 16, Loss: 14.420734405517578\n",
      "Epoch: 236, Batch number: 40, Loss: 10.817360877990723\n",
      "Epoch: 237, Batch number: 64, Loss: 12.25803279876709\n",
      "Epoch: 239, Batch number: 12, Loss: 16.169628143310547\n",
      "Epoch: 240, Batch number: 36, Loss: 15.171868324279785\n",
      "Epoch: 241, Batch number: 60, Loss: 12.35857105255127\n",
      "Epoch: 243, Batch number: 8, Loss: 11.999114036560059\n",
      "Epoch: 244, Batch number: 32, Loss: 16.316871643066406\n",
      "Epoch: 245, Batch number: 56, Loss: 15.21565055847168\n",
      "Epoch: 247, Batch number: 4, Loss: 19.332012176513672\n",
      "Epoch: 248, Batch number: 28, Loss: 12.913065910339355\n",
      "Epoch: 249, Batch number: 52, Loss: 11.170771598815918\n",
      "Epoch: 251, Batch number: 0, Loss: 15.421939849853516\n",
      "Epoch: 252, Batch number: 24, Loss: 10.123884201049805\n",
      "Epoch: 253, Batch number: 48, Loss: 8.674460411071777\n",
      "Epoch: 254, Batch number: 72, Loss: 15.129094123840332\n",
      "Epoch: 256, Batch number: 20, Loss: 9.87095832824707\n",
      "Epoch: 257, Batch number: 44, Loss: 11.512937545776367\n",
      "Epoch: 258, Batch number: 68, Loss: 12.91578197479248\n",
      "Epoch: 260, Batch number: 16, Loss: 10.963995933532715\n",
      "Epoch: 261, Batch number: 40, Loss: 12.008316993713379\n",
      "Epoch: 262, Batch number: 64, Loss: 10.225893020629883\n",
      "Epoch: 264, Batch number: 12, Loss: 7.300284385681152\n",
      "Epoch: 265, Batch number: 36, Loss: 12.56902027130127\n",
      "Epoch: 266, Batch number: 60, Loss: 5.692180633544922\n",
      "Epoch: 268, Batch number: 8, Loss: 9.97211742401123\n",
      "Epoch: 269, Batch number: 32, Loss: 11.917333602905273\n",
      "Epoch: 270, Batch number: 56, Loss: 13.858503341674805\n",
      "Epoch: 272, Batch number: 4, Loss: 8.610614776611328\n",
      "Epoch: 273, Batch number: 28, Loss: 11.340752601623535\n",
      "Epoch: 274, Batch number: 52, Loss: 9.748164176940918\n",
      "Epoch: 276, Batch number: 0, Loss: 16.190082550048828\n",
      "Epoch: 277, Batch number: 24, Loss: 13.353273391723633\n",
      "Epoch: 278, Batch number: 48, Loss: 14.265235900878906\n",
      "Epoch: 279, Batch number: 72, Loss: 13.6025390625\n",
      "Epoch: 281, Batch number: 20, Loss: 14.399187088012695\n",
      "Epoch: 282, Batch number: 44, Loss: 11.907341957092285\n",
      "Epoch: 283, Batch number: 68, Loss: 11.628584861755371\n",
      "Epoch: 285, Batch number: 16, Loss: 11.579402923583984\n",
      "Epoch: 286, Batch number: 40, Loss: 8.148630142211914\n",
      "Epoch: 287, Batch number: 64, Loss: 13.05178451538086\n",
      "Epoch: 289, Batch number: 12, Loss: 8.675175666809082\n",
      "Epoch: 290, Batch number: 36, Loss: 16.21005630493164\n",
      "Epoch: 291, Batch number: 60, Loss: 8.39516544342041\n",
      "Epoch: 293, Batch number: 8, Loss: 5.551984786987305\n",
      "Epoch: 294, Batch number: 32, Loss: 10.326855659484863\n",
      "Epoch: 295, Batch number: 56, Loss: 6.5304975509643555\n",
      "Epoch: 297, Batch number: 4, Loss: 6.186631202697754\n",
      "Epoch: 298, Batch number: 28, Loss: 11.010293006896973\n",
      "Epoch: 299, Batch number: 52, Loss: 9.32124137878418\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4402.58056640625\n",
      "Epoch: 2, Batch number: 24, Loss: 3872.066162109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch number: 48, Loss: 3241.713623046875\n",
      "Epoch: 4, Batch number: 72, Loss: 2879.61083984375\n",
      "Epoch: 6, Batch number: 20, Loss: 2545.627685546875\n",
      "Epoch: 7, Batch number: 44, Loss: 2431.02197265625\n",
      "Epoch: 8, Batch number: 68, Loss: 2335.003173828125\n",
      "Epoch: 10, Batch number: 16, Loss: 1998.9884033203125\n",
      "Epoch: 11, Batch number: 40, Loss: 1997.062255859375\n",
      "Epoch: 12, Batch number: 64, Loss: 1957.3121337890625\n",
      "Epoch: 14, Batch number: 12, Loss: 1769.394287109375\n",
      "Epoch: 15, Batch number: 36, Loss: 1717.3446044921875\n",
      "Epoch: 16, Batch number: 60, Loss: 1608.167236328125\n",
      "Epoch: 18, Batch number: 8, Loss: 1446.677734375\n",
      "Epoch: 19, Batch number: 32, Loss: 1379.159912109375\n",
      "Epoch: 20, Batch number: 56, Loss: 1388.4698486328125\n",
      "Epoch: 22, Batch number: 4, Loss: 1309.186279296875\n",
      "Epoch: 23, Batch number: 28, Loss: 1182.187744140625\n",
      "Epoch: 24, Batch number: 52, Loss: 1129.92041015625\n",
      "Epoch: 26, Batch number: 0, Loss: 1062.9039306640625\n",
      "Epoch: 27, Batch number: 24, Loss: 1017.5454711914062\n",
      "Epoch: 28, Batch number: 48, Loss: 1019.5806884765625\n",
      "Epoch: 29, Batch number: 72, Loss: 979.6721801757812\n",
      "Epoch: 31, Batch number: 20, Loss: 871.4060668945312\n",
      "Epoch: 32, Batch number: 44, Loss: 910.6398315429688\n",
      "Epoch: 33, Batch number: 68, Loss: 812.3917846679688\n",
      "Epoch: 35, Batch number: 16, Loss: 739.0856323242188\n",
      "Epoch: 36, Batch number: 40, Loss: 723.7362670898438\n",
      "Epoch: 37, Batch number: 64, Loss: 721.7926635742188\n",
      "Epoch: 39, Batch number: 12, Loss: 697.514892578125\n",
      "Epoch: 40, Batch number: 36, Loss: 664.2417602539062\n",
      "Epoch: 41, Batch number: 60, Loss: 611.3928833007812\n",
      "Epoch: 43, Batch number: 8, Loss: 599.2272338867188\n",
      "Epoch: 44, Batch number: 32, Loss: 545.7265014648438\n",
      "Epoch: 45, Batch number: 56, Loss: 533.6005859375\n",
      "Epoch: 47, Batch number: 4, Loss: 546.1983032226562\n",
      "Epoch: 48, Batch number: 28, Loss: 469.4056396484375\n",
      "Epoch: 49, Batch number: 52, Loss: 463.1483459472656\n",
      "Epoch: 51, Batch number: 0, Loss: 481.6147766113281\n",
      "Epoch: 52, Batch number: 24, Loss: 384.0277099609375\n",
      "Epoch: 53, Batch number: 48, Loss: 387.6340637207031\n",
      "Epoch: 54, Batch number: 72, Loss: 372.6799621582031\n",
      "Epoch: 56, Batch number: 20, Loss: 349.6639404296875\n",
      "Epoch: 57, Batch number: 44, Loss: 368.88092041015625\n",
      "Epoch: 58, Batch number: 68, Loss: 313.03558349609375\n",
      "Epoch: 60, Batch number: 16, Loss: 329.26239013671875\n",
      "Epoch: 61, Batch number: 40, Loss: 307.5224304199219\n",
      "Epoch: 62, Batch number: 64, Loss: 316.6073303222656\n",
      "Epoch: 64, Batch number: 12, Loss: 270.2995910644531\n",
      "Epoch: 65, Batch number: 36, Loss: 284.6392517089844\n",
      "Epoch: 66, Batch number: 60, Loss: 238.95050048828125\n",
      "Epoch: 68, Batch number: 8, Loss: 241.66488647460938\n",
      "Epoch: 69, Batch number: 32, Loss: 249.29180908203125\n",
      "Epoch: 70, Batch number: 56, Loss: 245.57293701171875\n",
      "Epoch: 72, Batch number: 4, Loss: 203.67434692382812\n",
      "Epoch: 73, Batch number: 28, Loss: 181.750732421875\n",
      "Epoch: 74, Batch number: 52, Loss: 182.31190490722656\n",
      "Epoch: 76, Batch number: 0, Loss: 177.7001953125\n",
      "Epoch: 77, Batch number: 24, Loss: 164.77427673339844\n",
      "Epoch: 78, Batch number: 48, Loss: 160.20704650878906\n",
      "Epoch: 79, Batch number: 72, Loss: 178.7367706298828\n",
      "Epoch: 81, Batch number: 20, Loss: 148.7492218017578\n",
      "Epoch: 82, Batch number: 44, Loss: 128.55548095703125\n",
      "Epoch: 83, Batch number: 68, Loss: 146.06712341308594\n",
      "Epoch: 85, Batch number: 16, Loss: 130.58990478515625\n",
      "Epoch: 86, Batch number: 40, Loss: 128.3642578125\n",
      "Epoch: 87, Batch number: 64, Loss: 125.17643737792969\n",
      "Epoch: 89, Batch number: 12, Loss: 113.0140151977539\n",
      "Epoch: 90, Batch number: 36, Loss: 128.1419677734375\n",
      "Epoch: 91, Batch number: 60, Loss: 133.98959350585938\n",
      "Epoch: 93, Batch number: 8, Loss: 118.00704956054688\n",
      "Epoch: 94, Batch number: 32, Loss: 84.90241241455078\n",
      "Epoch: 95, Batch number: 56, Loss: 119.48344421386719\n",
      "Epoch: 97, Batch number: 4, Loss: 97.43321228027344\n",
      "Epoch: 98, Batch number: 28, Loss: 82.6666259765625\n",
      "Epoch: 99, Batch number: 52, Loss: 87.40682983398438\n",
      "Epoch: 101, Batch number: 0, Loss: 84.36404418945312\n",
      "Epoch: 102, Batch number: 24, Loss: 87.18879699707031\n",
      "Epoch: 103, Batch number: 48, Loss: 80.91896057128906\n",
      "Epoch: 104, Batch number: 72, Loss: 83.16922760009766\n",
      "Epoch: 106, Batch number: 20, Loss: 54.76630783081055\n",
      "Epoch: 107, Batch number: 44, Loss: 71.57050323486328\n",
      "Epoch: 108, Batch number: 68, Loss: 63.553916931152344\n",
      "Epoch: 110, Batch number: 16, Loss: 75.427734375\n",
      "Epoch: 111, Batch number: 40, Loss: 69.25640106201172\n",
      "Epoch: 112, Batch number: 64, Loss: 60.52684783935547\n",
      "Epoch: 114, Batch number: 12, Loss: 57.87598419189453\n",
      "Epoch: 115, Batch number: 36, Loss: 50.912010192871094\n",
      "Epoch: 116, Batch number: 60, Loss: 63.306663513183594\n",
      "Epoch: 118, Batch number: 8, Loss: 63.52809524536133\n",
      "Epoch: 119, Batch number: 32, Loss: 56.146392822265625\n",
      "Epoch: 120, Batch number: 56, Loss: 56.72120666503906\n",
      "Epoch: 122, Batch number: 4, Loss: 39.79415512084961\n",
      "Epoch: 123, Batch number: 28, Loss: 58.82081985473633\n",
      "Epoch: 124, Batch number: 52, Loss: 38.368980407714844\n",
      "Epoch: 126, Batch number: 0, Loss: 36.470977783203125\n",
      "Epoch: 127, Batch number: 24, Loss: 50.87651062011719\n",
      "Epoch: 128, Batch number: 48, Loss: 55.87650680541992\n",
      "Epoch: 129, Batch number: 72, Loss: 41.98724365234375\n",
      "Epoch: 131, Batch number: 20, Loss: 34.825767517089844\n",
      "Epoch: 132, Batch number: 44, Loss: 43.52412414550781\n",
      "Epoch: 133, Batch number: 68, Loss: 48.27968978881836\n",
      "Epoch: 135, Batch number: 16, Loss: 32.937957763671875\n",
      "Epoch: 136, Batch number: 40, Loss: 32.90056610107422\n",
      "Epoch: 137, Batch number: 64, Loss: 31.64673614501953\n",
      "Epoch: 139, Batch number: 12, Loss: 30.247657775878906\n",
      "Epoch: 140, Batch number: 36, Loss: 35.3276481628418\n",
      "Epoch: 141, Batch number: 60, Loss: 37.289493560791016\n",
      "Epoch: 143, Batch number: 8, Loss: 27.91273307800293\n",
      "Epoch: 144, Batch number: 32, Loss: 29.918216705322266\n",
      "Epoch: 145, Batch number: 56, Loss: 27.598777770996094\n",
      "Epoch: 147, Batch number: 4, Loss: 27.326845169067383\n",
      "Epoch: 148, Batch number: 28, Loss: 29.03714370727539\n",
      "Epoch: 149, Batch number: 52, Loss: 25.00983428955078\n",
      "Epoch: 151, Batch number: 0, Loss: 23.73065948486328\n",
      "Epoch: 152, Batch number: 24, Loss: 23.604576110839844\n",
      "Epoch: 153, Batch number: 48, Loss: 26.753564834594727\n",
      "Epoch: 154, Batch number: 72, Loss: 22.548954010009766\n",
      "Epoch: 156, Batch number: 20, Loss: 24.84544563293457\n",
      "Epoch: 157, Batch number: 44, Loss: 29.058765411376953\n",
      "Epoch: 158, Batch number: 68, Loss: 19.420150756835938\n",
      "Epoch: 160, Batch number: 16, Loss: 30.856178283691406\n",
      "Epoch: 161, Batch number: 40, Loss: 25.015716552734375\n",
      "Epoch: 162, Batch number: 64, Loss: 21.43337631225586\n",
      "Epoch: 164, Batch number: 12, Loss: 31.990678787231445\n",
      "Epoch: 165, Batch number: 36, Loss: 19.934772491455078\n",
      "Epoch: 166, Batch number: 60, Loss: 19.354774475097656\n",
      "Epoch: 168, Batch number: 8, Loss: 21.229053497314453\n",
      "Epoch: 169, Batch number: 32, Loss: 18.934520721435547\n",
      "Epoch: 170, Batch number: 56, Loss: 17.873308181762695\n",
      "Epoch: 172, Batch number: 4, Loss: 19.58885955810547\n",
      "Epoch: 173, Batch number: 28, Loss: 13.299738883972168\n",
      "Epoch: 174, Batch number: 52, Loss: 20.575477600097656\n",
      "Epoch: 176, Batch number: 0, Loss: 15.745760917663574\n",
      "Epoch: 177, Batch number: 24, Loss: 18.076725006103516\n",
      "Epoch: 178, Batch number: 48, Loss: 20.982460021972656\n",
      "Epoch: 179, Batch number: 72, Loss: 14.621707916259766\n",
      "Epoch: 181, Batch number: 20, Loss: 22.07877540588379\n",
      "Epoch: 182, Batch number: 44, Loss: 17.44015121459961\n",
      "Epoch: 183, Batch number: 68, Loss: 22.99338150024414\n",
      "Epoch: 185, Batch number: 16, Loss: 14.597983360290527\n",
      "Epoch: 186, Batch number: 40, Loss: 16.49463653564453\n",
      "Epoch: 187, Batch number: 64, Loss: 20.32294464111328\n",
      "Epoch: 189, Batch number: 12, Loss: 11.532816886901855\n",
      "Epoch: 190, Batch number: 36, Loss: 11.753058433532715\n",
      "Epoch: 191, Batch number: 60, Loss: 16.007217407226562\n",
      "Epoch: 193, Batch number: 8, Loss: 20.482398986816406\n",
      "Epoch: 194, Batch number: 32, Loss: 15.885220527648926\n",
      "Epoch: 195, Batch number: 56, Loss: 7.372920989990234\n",
      "Epoch: 197, Batch number: 4, Loss: 15.6278657913208\n",
      "Epoch: 198, Batch number: 28, Loss: 9.732226371765137\n",
      "Epoch: 199, Batch number: 52, Loss: 11.984888076782227\n",
      "Epoch: 201, Batch number: 0, Loss: 12.474382400512695\n",
      "Epoch: 202, Batch number: 24, Loss: 13.714690208435059\n",
      "Epoch: 203, Batch number: 48, Loss: 12.953874588012695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204, Batch number: 72, Loss: 16.68515396118164\n",
      "Epoch: 206, Batch number: 20, Loss: 11.350470542907715\n",
      "Epoch: 207, Batch number: 44, Loss: 8.952167510986328\n",
      "Epoch: 208, Batch number: 68, Loss: 26.44786834716797\n",
      "Epoch: 210, Batch number: 16, Loss: 9.522605895996094\n",
      "Epoch: 211, Batch number: 40, Loss: 13.076823234558105\n",
      "Epoch: 212, Batch number: 64, Loss: 10.624056816101074\n",
      "Epoch: 214, Batch number: 12, Loss: 6.7504425048828125\n",
      "Epoch: 215, Batch number: 36, Loss: 15.859024047851562\n",
      "Epoch: 216, Batch number: 60, Loss: 8.253900527954102\n",
      "Epoch: 218, Batch number: 8, Loss: 12.952371597290039\n",
      "Epoch: 219, Batch number: 32, Loss: 10.85450267791748\n",
      "Epoch: 220, Batch number: 56, Loss: 18.50762176513672\n",
      "Epoch: 222, Batch number: 4, Loss: 12.502884864807129\n",
      "Epoch: 223, Batch number: 28, Loss: 10.14499282836914\n",
      "Epoch: 224, Batch number: 52, Loss: 9.162249565124512\n",
      "Epoch: 226, Batch number: 0, Loss: 5.71583366394043\n",
      "Epoch: 227, Batch number: 24, Loss: 9.347224235534668\n",
      "Epoch: 228, Batch number: 48, Loss: 7.137871742248535\n",
      "Epoch: 229, Batch number: 72, Loss: 9.310943603515625\n",
      "Epoch: 231, Batch number: 20, Loss: 10.840338706970215\n",
      "Epoch: 232, Batch number: 44, Loss: 7.544899940490723\n",
      "Epoch: 233, Batch number: 68, Loss: 14.19996452331543\n",
      "Epoch: 235, Batch number: 16, Loss: 9.340326309204102\n",
      "Epoch: 236, Batch number: 40, Loss: 15.007203102111816\n",
      "Epoch: 237, Batch number: 64, Loss: 19.32892608642578\n",
      "Epoch: 239, Batch number: 12, Loss: 7.272087097167969\n",
      "Epoch: 240, Batch number: 36, Loss: 8.040237426757812\n",
      "Epoch: 241, Batch number: 60, Loss: 12.098093032836914\n",
      "Epoch: 243, Batch number: 8, Loss: 10.800705909729004\n",
      "Epoch: 244, Batch number: 32, Loss: 10.776407241821289\n",
      "Epoch: 245, Batch number: 56, Loss: 8.680893898010254\n",
      "Epoch: 247, Batch number: 4, Loss: 5.041228294372559\n",
      "Epoch: 248, Batch number: 28, Loss: 4.808341026306152\n",
      "Epoch: 249, Batch number: 52, Loss: 8.589757919311523\n",
      "Epoch: 251, Batch number: 0, Loss: 11.41055679321289\n",
      "Epoch: 252, Batch number: 24, Loss: 2.832082748413086\n",
      "Epoch: 253, Batch number: 48, Loss: 7.305575370788574\n",
      "Epoch: 254, Batch number: 72, Loss: 6.776044845581055\n",
      "Epoch: 256, Batch number: 20, Loss: 10.825470924377441\n",
      "Epoch: 257, Batch number: 44, Loss: 7.628914833068848\n",
      "Epoch: 258, Batch number: 68, Loss: 11.296111106872559\n",
      "Epoch: 260, Batch number: 16, Loss: 11.158534049987793\n",
      "Epoch: 261, Batch number: 40, Loss: 7.704947471618652\n",
      "Epoch: 262, Batch number: 64, Loss: 12.500859260559082\n",
      "Epoch: 264, Batch number: 12, Loss: 15.557976722717285\n",
      "Epoch: 265, Batch number: 36, Loss: 10.348429679870605\n",
      "Epoch: 266, Batch number: 60, Loss: 7.2331132888793945\n",
      "Epoch: 268, Batch number: 8, Loss: 6.143861770629883\n",
      "Epoch: 269, Batch number: 32, Loss: 9.813222885131836\n",
      "Epoch: 270, Batch number: 56, Loss: 5.176207542419434\n",
      "Epoch: 272, Batch number: 4, Loss: 6.730792999267578\n",
      "Epoch: 273, Batch number: 28, Loss: 8.209650039672852\n",
      "Epoch: 274, Batch number: 52, Loss: 9.211281776428223\n",
      "Epoch: 276, Batch number: 0, Loss: 7.558279991149902\n",
      "Epoch: 277, Batch number: 24, Loss: 7.188991546630859\n",
      "Epoch: 278, Batch number: 48, Loss: 8.803951263427734\n",
      "Epoch: 279, Batch number: 72, Loss: 8.167223930358887\n",
      "Epoch: 281, Batch number: 20, Loss: 5.819736480712891\n",
      "Epoch: 282, Batch number: 44, Loss: 4.589168548583984\n",
      "Epoch: 283, Batch number: 68, Loss: 12.955033302307129\n",
      "Epoch: 285, Batch number: 16, Loss: 11.991361618041992\n",
      "Epoch: 286, Batch number: 40, Loss: 4.405081748962402\n",
      "Epoch: 287, Batch number: 64, Loss: 7.999982833862305\n",
      "Epoch: 289, Batch number: 12, Loss: 8.928192138671875\n",
      "Epoch: 290, Batch number: 36, Loss: 7.792632102966309\n",
      "Epoch: 291, Batch number: 60, Loss: 7.000505447387695\n",
      "Epoch: 293, Batch number: 8, Loss: 5.647892951965332\n",
      "Epoch: 294, Batch number: 32, Loss: 5.69558048248291\n",
      "Epoch: 295, Batch number: 56, Loss: 13.28271770477295\n",
      "Epoch: 297, Batch number: 4, Loss: 6.664272308349609\n",
      "Epoch: 298, Batch number: 28, Loss: 7.559576988220215\n",
      "Epoch: 299, Batch number: 52, Loss: 8.49035930633545\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4407.6484375\n",
      "Epoch: 2, Batch number: 24, Loss: 3699.1015625\n",
      "Epoch: 3, Batch number: 48, Loss: 3080.650634765625\n",
      "Epoch: 4, Batch number: 72, Loss: 2686.18310546875\n",
      "Epoch: 6, Batch number: 20, Loss: 2515.560302734375\n",
      "Epoch: 7, Batch number: 44, Loss: 2105.53955078125\n",
      "Epoch: 8, Batch number: 68, Loss: 2140.068603515625\n",
      "Epoch: 10, Batch number: 16, Loss: 1828.800048828125\n",
      "Epoch: 11, Batch number: 40, Loss: 1821.2183837890625\n",
      "Epoch: 12, Batch number: 64, Loss: 1704.6363525390625\n",
      "Epoch: 14, Batch number: 12, Loss: 1567.919921875\n",
      "Epoch: 15, Batch number: 36, Loss: 1456.646484375\n",
      "Epoch: 16, Batch number: 60, Loss: 1397.6185302734375\n",
      "Epoch: 18, Batch number: 8, Loss: 1286.55712890625\n",
      "Epoch: 19, Batch number: 32, Loss: 1169.6478271484375\n",
      "Epoch: 20, Batch number: 56, Loss: 1102.6265869140625\n",
      "Epoch: 22, Batch number: 4, Loss: 1043.673095703125\n",
      "Epoch: 23, Batch number: 28, Loss: 916.9175415039062\n",
      "Epoch: 24, Batch number: 52, Loss: 910.9002685546875\n",
      "Epoch: 26, Batch number: 0, Loss: 831.4846801757812\n",
      "Epoch: 27, Batch number: 24, Loss: 791.0360717773438\n",
      "Epoch: 28, Batch number: 48, Loss: 719.7372436523438\n",
      "Epoch: 29, Batch number: 72, Loss: 789.6076049804688\n",
      "Epoch: 31, Batch number: 20, Loss: 681.5504150390625\n",
      "Epoch: 32, Batch number: 44, Loss: 592.9104614257812\n",
      "Epoch: 33, Batch number: 68, Loss: 648.8179931640625\n",
      "Epoch: 35, Batch number: 16, Loss: 524.8764038085938\n",
      "Epoch: 36, Batch number: 40, Loss: 553.9343872070312\n",
      "Epoch: 37, Batch number: 64, Loss: 512.794921875\n",
      "Epoch: 39, Batch number: 12, Loss: 492.9697265625\n",
      "Epoch: 40, Batch number: 36, Loss: 440.8710021972656\n",
      "Epoch: 41, Batch number: 60, Loss: 418.0365295410156\n",
      "Epoch: 43, Batch number: 8, Loss: 388.2341003417969\n",
      "Epoch: 44, Batch number: 32, Loss: 361.88201904296875\n",
      "Epoch: 45, Batch number: 56, Loss: 339.7823791503906\n",
      "Epoch: 47, Batch number: 4, Loss: 323.6396789550781\n",
      "Epoch: 48, Batch number: 28, Loss: 293.1222839355469\n",
      "Epoch: 49, Batch number: 52, Loss: 269.66937255859375\n",
      "Epoch: 51, Batch number: 0, Loss: 284.1449279785156\n",
      "Epoch: 52, Batch number: 24, Loss: 266.6936950683594\n",
      "Epoch: 53, Batch number: 48, Loss: 273.65576171875\n",
      "Epoch: 54, Batch number: 72, Loss: 232.06382751464844\n",
      "Epoch: 56, Batch number: 20, Loss: 208.6133270263672\n",
      "Epoch: 57, Batch number: 44, Loss: 188.85194396972656\n",
      "Epoch: 58, Batch number: 68, Loss: 221.2438201904297\n",
      "Epoch: 60, Batch number: 16, Loss: 217.4281463623047\n",
      "Epoch: 61, Batch number: 40, Loss: 193.66864013671875\n",
      "Epoch: 62, Batch number: 64, Loss: 176.3687286376953\n",
      "Epoch: 64, Batch number: 12, Loss: 177.20762634277344\n",
      "Epoch: 65, Batch number: 36, Loss: 159.91725158691406\n",
      "Epoch: 66, Batch number: 60, Loss: 167.6036376953125\n",
      "Epoch: 68, Batch number: 8, Loss: 168.193115234375\n",
      "Epoch: 69, Batch number: 32, Loss: 145.09613037109375\n",
      "Epoch: 70, Batch number: 56, Loss: 112.96444702148438\n",
      "Epoch: 72, Batch number: 4, Loss: 116.16159057617188\n",
      "Epoch: 73, Batch number: 28, Loss: 114.19520568847656\n",
      "Epoch: 74, Batch number: 52, Loss: 123.23993682861328\n",
      "Epoch: 76, Batch number: 0, Loss: 94.73289489746094\n",
      "Epoch: 77, Batch number: 24, Loss: 111.0277099609375\n",
      "Epoch: 78, Batch number: 48, Loss: 104.41471862792969\n",
      "Epoch: 79, Batch number: 72, Loss: 114.8921127319336\n",
      "Epoch: 81, Batch number: 20, Loss: 90.0394058227539\n",
      "Epoch: 82, Batch number: 44, Loss: 95.56166076660156\n",
      "Epoch: 83, Batch number: 68, Loss: 86.59397888183594\n",
      "Epoch: 85, Batch number: 16, Loss: 88.19827270507812\n",
      "Epoch: 86, Batch number: 40, Loss: 97.18557739257812\n",
      "Epoch: 87, Batch number: 64, Loss: 81.78833770751953\n",
      "Epoch: 89, Batch number: 12, Loss: 74.24687194824219\n",
      "Epoch: 90, Batch number: 36, Loss: 72.59956359863281\n",
      "Epoch: 91, Batch number: 60, Loss: 70.5439453125\n",
      "Epoch: 93, Batch number: 8, Loss: 64.7158203125\n",
      "Epoch: 94, Batch number: 32, Loss: 62.06328582763672\n",
      "Epoch: 95, Batch number: 56, Loss: 57.350677490234375\n",
      "Epoch: 97, Batch number: 4, Loss: 51.517250061035156\n",
      "Epoch: 98, Batch number: 28, Loss: 52.969181060791016\n",
      "Epoch: 99, Batch number: 52, Loss: 43.72960662841797\n",
      "Epoch: 101, Batch number: 0, Loss: 47.24332046508789\n",
      "Epoch: 102, Batch number: 24, Loss: 48.575077056884766\n",
      "Epoch: 103, Batch number: 48, Loss: 50.29240036010742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104, Batch number: 72, Loss: 58.23502731323242\n",
      "Epoch: 106, Batch number: 20, Loss: 55.66876983642578\n",
      "Epoch: 107, Batch number: 44, Loss: 44.92753982543945\n",
      "Epoch: 108, Batch number: 68, Loss: 41.77700424194336\n",
      "Epoch: 110, Batch number: 16, Loss: 38.38847732543945\n",
      "Epoch: 111, Batch number: 40, Loss: 34.23410415649414\n",
      "Epoch: 112, Batch number: 64, Loss: 39.43063735961914\n",
      "Epoch: 114, Batch number: 12, Loss: 31.902841567993164\n",
      "Epoch: 115, Batch number: 36, Loss: 31.734786987304688\n",
      "Epoch: 116, Batch number: 60, Loss: 35.92164611816406\n",
      "Epoch: 118, Batch number: 8, Loss: 29.763427734375\n",
      "Epoch: 119, Batch number: 32, Loss: 33.44788360595703\n",
      "Epoch: 120, Batch number: 56, Loss: 26.05401611328125\n",
      "Epoch: 122, Batch number: 4, Loss: 24.463600158691406\n",
      "Epoch: 123, Batch number: 28, Loss: 34.48988342285156\n",
      "Epoch: 124, Batch number: 52, Loss: 23.256248474121094\n",
      "Epoch: 126, Batch number: 0, Loss: 28.828121185302734\n",
      "Epoch: 127, Batch number: 24, Loss: 25.808320999145508\n",
      "Epoch: 128, Batch number: 48, Loss: 26.505104064941406\n",
      "Epoch: 129, Batch number: 72, Loss: 31.952213287353516\n",
      "Epoch: 131, Batch number: 20, Loss: 25.574613571166992\n",
      "Epoch: 132, Batch number: 44, Loss: 23.149295806884766\n",
      "Epoch: 133, Batch number: 68, Loss: 31.933059692382812\n",
      "Epoch: 135, Batch number: 16, Loss: 19.79374122619629\n",
      "Epoch: 136, Batch number: 40, Loss: 21.410993576049805\n",
      "Epoch: 137, Batch number: 64, Loss: 23.80475425720215\n",
      "Epoch: 139, Batch number: 12, Loss: 18.61944580078125\n",
      "Epoch: 140, Batch number: 36, Loss: 19.41901397705078\n",
      "Epoch: 141, Batch number: 60, Loss: 25.791824340820312\n",
      "Epoch: 143, Batch number: 8, Loss: 17.875080108642578\n",
      "Epoch: 144, Batch number: 32, Loss: 16.68980598449707\n",
      "Epoch: 145, Batch number: 56, Loss: 22.558258056640625\n",
      "Epoch: 147, Batch number: 4, Loss: 19.39539909362793\n",
      "Epoch: 148, Batch number: 28, Loss: 20.85928726196289\n",
      "Epoch: 149, Batch number: 52, Loss: 22.25353240966797\n",
      "Epoch: 151, Batch number: 0, Loss: 15.790974617004395\n",
      "Epoch: 152, Batch number: 24, Loss: 15.998003959655762\n",
      "Epoch: 153, Batch number: 48, Loss: 13.74550724029541\n",
      "Epoch: 154, Batch number: 72, Loss: 13.864330291748047\n",
      "Epoch: 156, Batch number: 20, Loss: 12.914750099182129\n",
      "Epoch: 157, Batch number: 44, Loss: 17.57787322998047\n",
      "Epoch: 158, Batch number: 68, Loss: 14.082808494567871\n",
      "Epoch: 160, Batch number: 16, Loss: 16.94542694091797\n",
      "Epoch: 161, Batch number: 40, Loss: 20.338115692138672\n",
      "Epoch: 162, Batch number: 64, Loss: 16.061065673828125\n",
      "Epoch: 164, Batch number: 12, Loss: 12.092578887939453\n",
      "Epoch: 165, Batch number: 36, Loss: 20.120752334594727\n",
      "Epoch: 166, Batch number: 60, Loss: 13.051589012145996\n",
      "Epoch: 168, Batch number: 8, Loss: 13.784793853759766\n",
      "Epoch: 169, Batch number: 32, Loss: 17.760744094848633\n",
      "Epoch: 170, Batch number: 56, Loss: 14.510221481323242\n",
      "Epoch: 172, Batch number: 4, Loss: 12.54834270477295\n",
      "Epoch: 173, Batch number: 28, Loss: 15.570542335510254\n",
      "Epoch: 174, Batch number: 52, Loss: 19.489917755126953\n",
      "Epoch: 176, Batch number: 0, Loss: 8.825886726379395\n",
      "Epoch: 177, Batch number: 24, Loss: 17.176151275634766\n",
      "Epoch: 178, Batch number: 48, Loss: 13.366188049316406\n",
      "Epoch: 179, Batch number: 72, Loss: 10.876890182495117\n",
      "Epoch: 181, Batch number: 20, Loss: 16.10159683227539\n",
      "Epoch: 182, Batch number: 44, Loss: 10.617938041687012\n",
      "Epoch: 183, Batch number: 68, Loss: 17.40948486328125\n",
      "Epoch: 185, Batch number: 16, Loss: 10.457484245300293\n",
      "Epoch: 186, Batch number: 40, Loss: 19.854095458984375\n",
      "Epoch: 187, Batch number: 64, Loss: 8.016838073730469\n",
      "Epoch: 189, Batch number: 12, Loss: 11.548951148986816\n",
      "Epoch: 190, Batch number: 36, Loss: 11.955914497375488\n",
      "Epoch: 191, Batch number: 60, Loss: 13.843606948852539\n",
      "Epoch: 193, Batch number: 8, Loss: 7.855765342712402\n",
      "Epoch: 194, Batch number: 32, Loss: 9.355453491210938\n",
      "Epoch: 195, Batch number: 56, Loss: 8.900440216064453\n",
      "Epoch: 197, Batch number: 4, Loss: 6.527105331420898\n",
      "Epoch: 198, Batch number: 28, Loss: 7.719683647155762\n",
      "Epoch: 199, Batch number: 52, Loss: 14.802376747131348\n",
      "Epoch: 201, Batch number: 0, Loss: 8.008233070373535\n",
      "Epoch: 202, Batch number: 24, Loss: 8.289312362670898\n",
      "Epoch: 203, Batch number: 48, Loss: 6.0477495193481445\n",
      "Epoch: 204, Batch number: 72, Loss: 9.837223052978516\n",
      "Epoch: 206, Batch number: 20, Loss: 11.173413276672363\n",
      "Epoch: 207, Batch number: 44, Loss: 6.328693389892578\n",
      "Epoch: 208, Batch number: 68, Loss: 8.55879020690918\n",
      "Epoch: 210, Batch number: 16, Loss: 8.265519142150879\n",
      "Epoch: 211, Batch number: 40, Loss: 13.214394569396973\n",
      "Epoch: 212, Batch number: 64, Loss: 9.140406608581543\n",
      "Epoch: 214, Batch number: 12, Loss: 17.030906677246094\n",
      "Epoch: 215, Batch number: 36, Loss: 14.025651931762695\n",
      "Epoch: 216, Batch number: 60, Loss: 5.341972351074219\n",
      "Epoch: 218, Batch number: 8, Loss: 9.549796104431152\n",
      "Epoch: 219, Batch number: 32, Loss: 12.890852928161621\n",
      "Epoch: 220, Batch number: 56, Loss: 8.13913345336914\n",
      "Epoch: 222, Batch number: 4, Loss: 7.504764556884766\n",
      "Epoch: 223, Batch number: 28, Loss: 7.002265930175781\n",
      "Epoch: 224, Batch number: 52, Loss: 9.686640739440918\n",
      "Epoch: 226, Batch number: 0, Loss: 8.024761199951172\n",
      "Epoch: 227, Batch number: 24, Loss: 5.412104606628418\n",
      "Epoch: 228, Batch number: 48, Loss: 7.447379112243652\n",
      "Epoch: 229, Batch number: 72, Loss: 8.819060325622559\n",
      "Epoch: 231, Batch number: 20, Loss: 9.231218338012695\n",
      "Epoch: 232, Batch number: 44, Loss: 9.868693351745605\n",
      "Epoch: 233, Batch number: 68, Loss: 7.9775390625\n",
      "Epoch: 235, Batch number: 16, Loss: 11.784111976623535\n",
      "Epoch: 236, Batch number: 40, Loss: 5.315756797790527\n",
      "Epoch: 237, Batch number: 64, Loss: 13.645883560180664\n",
      "Epoch: 239, Batch number: 12, Loss: 13.188511848449707\n",
      "Epoch: 240, Batch number: 36, Loss: 9.856337547302246\n",
      "Epoch: 241, Batch number: 60, Loss: 8.189437866210938\n",
      "Epoch: 243, Batch number: 8, Loss: 10.195777893066406\n",
      "Epoch: 244, Batch number: 32, Loss: 11.699033737182617\n",
      "Epoch: 245, Batch number: 56, Loss: 6.5289764404296875\n",
      "Epoch: 247, Batch number: 4, Loss: 7.839350700378418\n",
      "Epoch: 248, Batch number: 28, Loss: 5.42669677734375\n",
      "Epoch: 249, Batch number: 52, Loss: 8.335033416748047\n",
      "Epoch: 251, Batch number: 0, Loss: 11.941424369812012\n",
      "Epoch: 252, Batch number: 24, Loss: 8.598219871520996\n",
      "Epoch: 253, Batch number: 48, Loss: 6.085610389709473\n",
      "Epoch: 254, Batch number: 72, Loss: 7.668373107910156\n",
      "Epoch: 256, Batch number: 20, Loss: 9.122479438781738\n",
      "Epoch: 257, Batch number: 44, Loss: 4.2522382736206055\n",
      "Epoch: 258, Batch number: 68, Loss: 8.553430557250977\n",
      "Epoch: 260, Batch number: 16, Loss: 8.517097473144531\n",
      "Epoch: 261, Batch number: 40, Loss: 7.7650146484375\n",
      "Epoch: 262, Batch number: 64, Loss: 14.327425956726074\n",
      "Epoch: 264, Batch number: 12, Loss: 5.973641395568848\n",
      "Epoch: 265, Batch number: 36, Loss: 10.652256965637207\n",
      "Epoch: 266, Batch number: 60, Loss: 11.054250717163086\n",
      "Epoch: 268, Batch number: 8, Loss: 14.31328296661377\n",
      "Epoch: 269, Batch number: 32, Loss: 11.331380844116211\n",
      "Epoch: 270, Batch number: 56, Loss: 10.156476974487305\n",
      "Epoch: 272, Batch number: 4, Loss: 7.827566146850586\n",
      "Epoch: 273, Batch number: 28, Loss: 9.854151725769043\n",
      "Epoch: 274, Batch number: 52, Loss: 8.611474990844727\n",
      "Epoch: 276, Batch number: 0, Loss: 3.3509902954101562\n",
      "Epoch: 277, Batch number: 24, Loss: 14.494790077209473\n",
      "Epoch: 278, Batch number: 48, Loss: 9.879884719848633\n",
      "Epoch: 279, Batch number: 72, Loss: 9.25490951538086\n",
      "Epoch: 281, Batch number: 20, Loss: 6.886919021606445\n",
      "Epoch: 282, Batch number: 44, Loss: 7.493287086486816\n",
      "Epoch: 283, Batch number: 68, Loss: 13.030874252319336\n",
      "Epoch: 285, Batch number: 16, Loss: 12.738743782043457\n",
      "Epoch: 286, Batch number: 40, Loss: 6.884661674499512\n",
      "Epoch: 287, Batch number: 64, Loss: 6.254804611206055\n",
      "Epoch: 289, Batch number: 12, Loss: 5.827668190002441\n",
      "Epoch: 290, Batch number: 36, Loss: 4.141510009765625\n",
      "Epoch: 291, Batch number: 60, Loss: 7.52363395690918\n",
      "Epoch: 293, Batch number: 8, Loss: 7.105956077575684\n",
      "Epoch: 294, Batch number: 32, Loss: 6.616467475891113\n",
      "Epoch: 295, Batch number: 56, Loss: 7.4541215896606445\n",
      "Epoch: 297, Batch number: 4, Loss: 18.685335159301758\n",
      "Epoch: 298, Batch number: 28, Loss: 10.85366439819336\n",
      "Epoch: 299, Batch number: 52, Loss: 10.238729476928711\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4410.3671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 24, Loss: 4306.19970703125\n",
      "Epoch: 3, Batch number: 48, Loss: 4143.44970703125\n",
      "Epoch: 4, Batch number: 72, Loss: 3892.9541015625\n",
      "Epoch: 6, Batch number: 20, Loss: 3493.333740234375\n",
      "Epoch: 7, Batch number: 44, Loss: 3188.455078125\n",
      "Epoch: 8, Batch number: 68, Loss: 3057.314697265625\n",
      "Epoch: 10, Batch number: 16, Loss: 2938.15869140625\n",
      "Epoch: 11, Batch number: 40, Loss: 3010.731201171875\n",
      "Epoch: 12, Batch number: 64, Loss: 2916.422607421875\n",
      "Epoch: 14, Batch number: 12, Loss: 2938.66357421875\n",
      "Epoch: 15, Batch number: 36, Loss: 2758.30810546875\n",
      "Epoch: 16, Batch number: 60, Loss: 2647.141845703125\n",
      "Epoch: 18, Batch number: 8, Loss: 2634.6591796875\n",
      "Epoch: 19, Batch number: 32, Loss: 2647.39892578125\n",
      "Epoch: 20, Batch number: 56, Loss: 2601.80908203125\n",
      "Epoch: 22, Batch number: 4, Loss: 2603.45947265625\n",
      "Epoch: 23, Batch number: 28, Loss: 2590.309814453125\n",
      "Epoch: 24, Batch number: 52, Loss: 2660.26708984375\n",
      "Epoch: 26, Batch number: 0, Loss: 2452.669189453125\n",
      "Epoch: 27, Batch number: 24, Loss: 2586.20947265625\n",
      "Epoch: 28, Batch number: 48, Loss: 2555.7275390625\n",
      "Epoch: 29, Batch number: 72, Loss: 2512.106201171875\n",
      "Epoch: 31, Batch number: 20, Loss: 2397.3505859375\n",
      "Epoch: 32, Batch number: 44, Loss: 2439.740966796875\n",
      "Epoch: 33, Batch number: 68, Loss: 2413.35595703125\n",
      "Epoch: 35, Batch number: 16, Loss: 2287.298583984375\n",
      "Epoch: 36, Batch number: 40, Loss: 2350.214599609375\n",
      "Epoch: 37, Batch number: 64, Loss: 2303.71337890625\n",
      "Epoch: 39, Batch number: 12, Loss: 2259.856201171875\n",
      "Epoch: 40, Batch number: 36, Loss: 2279.7724609375\n",
      "Epoch: 41, Batch number: 60, Loss: 2134.5634765625\n",
      "Epoch: 43, Batch number: 8, Loss: 2207.90625\n",
      "Epoch: 44, Batch number: 32, Loss: 2174.59716796875\n",
      "Epoch: 45, Batch number: 56, Loss: 2082.736572265625\n",
      "Epoch: 47, Batch number: 4, Loss: 2158.386962890625\n",
      "Epoch: 48, Batch number: 28, Loss: 2084.72607421875\n",
      "Epoch: 49, Batch number: 52, Loss: 2122.567626953125\n",
      "Epoch: 51, Batch number: 0, Loss: 2023.9522705078125\n",
      "Epoch: 52, Batch number: 24, Loss: 1978.3896484375\n",
      "Epoch: 53, Batch number: 48, Loss: 1940.880126953125\n",
      "Epoch: 54, Batch number: 72, Loss: 1961.7916259765625\n",
      "Epoch: 56, Batch number: 20, Loss: 2008.008544921875\n",
      "Epoch: 57, Batch number: 44, Loss: 1952.9705810546875\n",
      "Epoch: 58, Batch number: 68, Loss: 1909.2470703125\n",
      "Epoch: 60, Batch number: 16, Loss: 1794.6417236328125\n",
      "Epoch: 61, Batch number: 40, Loss: 1862.342529296875\n",
      "Epoch: 62, Batch number: 64, Loss: 1835.30712890625\n",
      "Epoch: 64, Batch number: 12, Loss: 1842.4112548828125\n",
      "Epoch: 65, Batch number: 36, Loss: 1730.27099609375\n",
      "Epoch: 66, Batch number: 60, Loss: 1775.3817138671875\n",
      "Epoch: 68, Batch number: 8, Loss: 1609.3326416015625\n",
      "Epoch: 69, Batch number: 32, Loss: 1802.505859375\n",
      "Epoch: 70, Batch number: 56, Loss: 1750.4674072265625\n",
      "Epoch: 72, Batch number: 4, Loss: 1682.95751953125\n",
      "Epoch: 73, Batch number: 28, Loss: 1762.229736328125\n",
      "Epoch: 74, Batch number: 52, Loss: 1669.9754638671875\n",
      "Epoch: 76, Batch number: 0, Loss: 1585.5009765625\n",
      "Epoch: 77, Batch number: 24, Loss: 1585.9407958984375\n",
      "Epoch: 78, Batch number: 48, Loss: 1598.0252685546875\n",
      "Epoch: 79, Batch number: 72, Loss: 1617.409912109375\n",
      "Epoch: 81, Batch number: 20, Loss: 1479.5250244140625\n",
      "Epoch: 82, Batch number: 44, Loss: 1501.9814453125\n",
      "Epoch: 83, Batch number: 68, Loss: 1495.81689453125\n",
      "Epoch: 85, Batch number: 16, Loss: 1482.478515625\n",
      "Epoch: 86, Batch number: 40, Loss: 1443.1566162109375\n",
      "Epoch: 87, Batch number: 64, Loss: 1422.69287109375\n",
      "Epoch: 89, Batch number: 12, Loss: 1440.0001220703125\n",
      "Epoch: 90, Batch number: 36, Loss: 1446.9595947265625\n",
      "Epoch: 91, Batch number: 60, Loss: 1390.69091796875\n",
      "Epoch: 93, Batch number: 8, Loss: 1484.509033203125\n",
      "Epoch: 94, Batch number: 32, Loss: 1377.7110595703125\n",
      "Epoch: 95, Batch number: 56, Loss: 1361.4642333984375\n",
      "Epoch: 97, Batch number: 4, Loss: 1359.3480224609375\n",
      "Epoch: 98, Batch number: 28, Loss: 1324.141845703125\n",
      "Epoch: 99, Batch number: 52, Loss: 1301.2030029296875\n",
      "Epoch: 101, Batch number: 0, Loss: 1352.73095703125\n",
      "Epoch: 102, Batch number: 24, Loss: 1257.7467041015625\n",
      "Epoch: 103, Batch number: 48, Loss: 1266.8818359375\n",
      "Epoch: 104, Batch number: 72, Loss: 1304.9498291015625\n",
      "Epoch: 106, Batch number: 20, Loss: 1212.8511962890625\n",
      "Epoch: 107, Batch number: 44, Loss: 1216.2476806640625\n",
      "Epoch: 108, Batch number: 68, Loss: 1193.4560546875\n",
      "Epoch: 110, Batch number: 16, Loss: 1231.20947265625\n",
      "Epoch: 111, Batch number: 40, Loss: 1307.1551513671875\n",
      "Epoch: 112, Batch number: 64, Loss: 1152.329345703125\n",
      "Epoch: 114, Batch number: 12, Loss: 1190.786865234375\n",
      "Epoch: 115, Batch number: 36, Loss: 1128.1842041015625\n",
      "Epoch: 116, Batch number: 60, Loss: 1173.9031982421875\n",
      "Epoch: 118, Batch number: 8, Loss: 1117.8251953125\n",
      "Epoch: 119, Batch number: 32, Loss: 1122.65625\n",
      "Epoch: 120, Batch number: 56, Loss: 1133.5919189453125\n",
      "Epoch: 122, Batch number: 4, Loss: 1088.5240478515625\n",
      "Epoch: 123, Batch number: 28, Loss: 1157.0323486328125\n",
      "Epoch: 124, Batch number: 52, Loss: 1099.050048828125\n",
      "Epoch: 126, Batch number: 0, Loss: 1111.9632568359375\n",
      "Epoch: 127, Batch number: 24, Loss: 1148.881591796875\n",
      "Epoch: 128, Batch number: 48, Loss: 1081.4013671875\n",
      "Epoch: 129, Batch number: 72, Loss: 1053.919189453125\n",
      "Epoch: 131, Batch number: 20, Loss: 1004.418212890625\n",
      "Epoch: 132, Batch number: 44, Loss: 1093.223876953125\n",
      "Epoch: 133, Batch number: 68, Loss: 1001.5751342773438\n",
      "Epoch: 135, Batch number: 16, Loss: 1039.5845947265625\n",
      "Epoch: 136, Batch number: 40, Loss: 966.4198608398438\n",
      "Epoch: 137, Batch number: 64, Loss: 1006.7242431640625\n",
      "Epoch: 139, Batch number: 12, Loss: 909.9675903320312\n",
      "Epoch: 140, Batch number: 36, Loss: 1029.8299560546875\n",
      "Epoch: 141, Batch number: 60, Loss: 990.3709716796875\n",
      "Epoch: 143, Batch number: 8, Loss: 985.7332763671875\n",
      "Epoch: 144, Batch number: 32, Loss: 949.4827270507812\n",
      "Epoch: 145, Batch number: 56, Loss: 864.26806640625\n",
      "Epoch: 147, Batch number: 4, Loss: 891.2955932617188\n",
      "Epoch: 148, Batch number: 28, Loss: 923.6604614257812\n",
      "Epoch: 149, Batch number: 52, Loss: 939.517333984375\n",
      "Epoch: 151, Batch number: 0, Loss: 863.326416015625\n",
      "Epoch: 152, Batch number: 24, Loss: 948.52392578125\n",
      "Epoch: 153, Batch number: 48, Loss: 946.8565673828125\n",
      "Epoch: 154, Batch number: 72, Loss: 946.8150634765625\n",
      "Epoch: 156, Batch number: 20, Loss: 939.6731567382812\n",
      "Epoch: 157, Batch number: 44, Loss: 904.7122802734375\n",
      "Epoch: 158, Batch number: 68, Loss: 894.164794921875\n",
      "Epoch: 160, Batch number: 16, Loss: 945.9917602539062\n",
      "Epoch: 161, Batch number: 40, Loss: 874.3399047851562\n",
      "Epoch: 162, Batch number: 64, Loss: 850.6142578125\n",
      "Epoch: 164, Batch number: 12, Loss: 834.2123413085938\n",
      "Epoch: 165, Batch number: 36, Loss: 807.2754516601562\n",
      "Epoch: 166, Batch number: 60, Loss: 851.9088745117188\n",
      "Epoch: 168, Batch number: 8, Loss: 729.508056640625\n",
      "Epoch: 169, Batch number: 32, Loss: 808.5087280273438\n",
      "Epoch: 170, Batch number: 56, Loss: 826.2221069335938\n",
      "Epoch: 172, Batch number: 4, Loss: 803.654541015625\n",
      "Epoch: 173, Batch number: 28, Loss: 773.2529296875\n",
      "Epoch: 174, Batch number: 52, Loss: 643.884033203125\n",
      "Epoch: 176, Batch number: 0, Loss: 786.6217651367188\n",
      "Epoch: 177, Batch number: 24, Loss: 755.6126708984375\n",
      "Epoch: 178, Batch number: 48, Loss: 792.573974609375\n",
      "Epoch: 179, Batch number: 72, Loss: 729.8558959960938\n",
      "Epoch: 181, Batch number: 20, Loss: 729.281982421875\n",
      "Epoch: 182, Batch number: 44, Loss: 708.6565551757812\n",
      "Epoch: 183, Batch number: 68, Loss: 809.196533203125\n",
      "Epoch: 185, Batch number: 16, Loss: 665.5228881835938\n",
      "Epoch: 186, Batch number: 40, Loss: 694.6832885742188\n",
      "Epoch: 187, Batch number: 64, Loss: 785.4351196289062\n",
      "Epoch: 189, Batch number: 12, Loss: 672.0381469726562\n",
      "Epoch: 190, Batch number: 36, Loss: 701.1510620117188\n",
      "Epoch: 191, Batch number: 60, Loss: 691.164306640625\n",
      "Epoch: 193, Batch number: 8, Loss: 721.03076171875\n",
      "Epoch: 194, Batch number: 32, Loss: 648.1727294921875\n",
      "Epoch: 195, Batch number: 56, Loss: 679.0950927734375\n",
      "Epoch: 197, Batch number: 4, Loss: 684.72607421875\n",
      "Epoch: 198, Batch number: 28, Loss: 619.1917724609375\n",
      "Epoch: 199, Batch number: 52, Loss: 630.6173095703125\n",
      "Epoch: 201, Batch number: 0, Loss: 646.4959716796875\n",
      "Epoch: 202, Batch number: 24, Loss: 620.351806640625\n",
      "Epoch: 203, Batch number: 48, Loss: 672.6278076171875\n",
      "Epoch: 204, Batch number: 72, Loss: 648.771728515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 664.2459106445312\n",
      "Epoch: 207, Batch number: 44, Loss: 562.2839965820312\n",
      "Epoch: 208, Batch number: 68, Loss: 600.0479125976562\n",
      "Epoch: 210, Batch number: 16, Loss: 628.6263427734375\n",
      "Epoch: 211, Batch number: 40, Loss: 571.10107421875\n",
      "Epoch: 212, Batch number: 64, Loss: 633.4797973632812\n",
      "Epoch: 214, Batch number: 12, Loss: 581.0971069335938\n",
      "Epoch: 215, Batch number: 36, Loss: 556.6416015625\n",
      "Epoch: 216, Batch number: 60, Loss: 573.5430908203125\n",
      "Epoch: 218, Batch number: 8, Loss: 601.9688720703125\n",
      "Epoch: 219, Batch number: 32, Loss: 563.1104125976562\n",
      "Epoch: 220, Batch number: 56, Loss: 541.2042846679688\n",
      "Epoch: 222, Batch number: 4, Loss: 597.8074340820312\n",
      "Epoch: 223, Batch number: 28, Loss: 559.3863525390625\n",
      "Epoch: 224, Batch number: 52, Loss: 526.8856201171875\n",
      "Epoch: 226, Batch number: 0, Loss: 554.4127807617188\n",
      "Epoch: 227, Batch number: 24, Loss: 528.3509521484375\n",
      "Epoch: 228, Batch number: 48, Loss: 552.5245361328125\n",
      "Epoch: 229, Batch number: 72, Loss: 529.2348022460938\n",
      "Epoch: 231, Batch number: 20, Loss: 539.0918579101562\n",
      "Epoch: 232, Batch number: 44, Loss: 566.5095825195312\n",
      "Epoch: 233, Batch number: 68, Loss: 453.0010986328125\n",
      "Epoch: 235, Batch number: 16, Loss: 473.3301086425781\n",
      "Epoch: 236, Batch number: 40, Loss: 521.8993530273438\n",
      "Epoch: 237, Batch number: 64, Loss: 502.95831298828125\n",
      "Epoch: 239, Batch number: 12, Loss: 477.7452392578125\n",
      "Epoch: 240, Batch number: 36, Loss: 496.4147033691406\n",
      "Epoch: 241, Batch number: 60, Loss: 426.0379943847656\n",
      "Epoch: 243, Batch number: 8, Loss: 463.06201171875\n",
      "Epoch: 244, Batch number: 32, Loss: 400.9206237792969\n",
      "Epoch: 245, Batch number: 56, Loss: 422.9786376953125\n",
      "Epoch: 247, Batch number: 4, Loss: 425.52374267578125\n",
      "Epoch: 248, Batch number: 28, Loss: 459.02294921875\n",
      "Epoch: 249, Batch number: 52, Loss: 476.53399658203125\n",
      "Epoch: 251, Batch number: 0, Loss: 419.25347900390625\n",
      "Epoch: 252, Batch number: 24, Loss: 448.8602294921875\n",
      "Epoch: 253, Batch number: 48, Loss: 410.2852478027344\n",
      "Epoch: 254, Batch number: 72, Loss: 414.4774169921875\n",
      "Epoch: 256, Batch number: 20, Loss: 444.2273254394531\n",
      "Epoch: 257, Batch number: 44, Loss: 414.8144836425781\n",
      "Epoch: 258, Batch number: 68, Loss: 438.0511474609375\n",
      "Epoch: 260, Batch number: 16, Loss: 378.2198181152344\n",
      "Epoch: 261, Batch number: 40, Loss: 389.1297607421875\n",
      "Epoch: 262, Batch number: 64, Loss: 392.9656677246094\n",
      "Epoch: 264, Batch number: 12, Loss: 398.19317626953125\n",
      "Epoch: 265, Batch number: 36, Loss: 392.439697265625\n",
      "Epoch: 266, Batch number: 60, Loss: 390.5978088378906\n",
      "Epoch: 268, Batch number: 8, Loss: 381.08538818359375\n",
      "Epoch: 269, Batch number: 32, Loss: 353.4988098144531\n",
      "Epoch: 270, Batch number: 56, Loss: 384.460693359375\n",
      "Epoch: 272, Batch number: 4, Loss: 379.78460693359375\n",
      "Epoch: 273, Batch number: 28, Loss: 393.4753112792969\n",
      "Epoch: 274, Batch number: 52, Loss: 376.7673645019531\n",
      "Epoch: 276, Batch number: 0, Loss: 354.6630859375\n",
      "Epoch: 277, Batch number: 24, Loss: 323.64398193359375\n",
      "Epoch: 278, Batch number: 48, Loss: 361.75567626953125\n",
      "Epoch: 279, Batch number: 72, Loss: 351.12738037109375\n",
      "Epoch: 281, Batch number: 20, Loss: 331.3762512207031\n",
      "Epoch: 282, Batch number: 44, Loss: 341.38897705078125\n",
      "Epoch: 283, Batch number: 68, Loss: 348.4894714355469\n",
      "Epoch: 285, Batch number: 16, Loss: 299.63397216796875\n",
      "Epoch: 286, Batch number: 40, Loss: 323.5265197753906\n",
      "Epoch: 287, Batch number: 64, Loss: 341.0706787109375\n",
      "Epoch: 289, Batch number: 12, Loss: 324.04248046875\n",
      "Epoch: 290, Batch number: 36, Loss: 281.4725646972656\n",
      "Epoch: 291, Batch number: 60, Loss: 308.90545654296875\n",
      "Epoch: 293, Batch number: 8, Loss: 317.4085388183594\n",
      "Epoch: 294, Batch number: 32, Loss: 293.0781555175781\n",
      "Epoch: 295, Batch number: 56, Loss: 293.18133544921875\n",
      "Epoch: 297, Batch number: 4, Loss: 283.27569580078125\n",
      "Epoch: 298, Batch number: 28, Loss: 279.53631591796875\n",
      "Epoch: 299, Batch number: 52, Loss: 274.8257751464844\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4409.7802734375\n",
      "Epoch: 2, Batch number: 24, Loss: 4231.2587890625\n",
      "Epoch: 3, Batch number: 48, Loss: 3924.022705078125\n",
      "Epoch: 4, Batch number: 72, Loss: 3425.84423828125\n",
      "Epoch: 6, Batch number: 20, Loss: 3114.71142578125\n",
      "Epoch: 7, Batch number: 44, Loss: 2831.081787109375\n",
      "Epoch: 8, Batch number: 68, Loss: 2943.73046875\n",
      "Epoch: 10, Batch number: 16, Loss: 2752.73193359375\n",
      "Epoch: 11, Batch number: 40, Loss: 2645.188232421875\n",
      "Epoch: 12, Batch number: 64, Loss: 2560.639892578125\n",
      "Epoch: 14, Batch number: 12, Loss: 2580.578857421875\n",
      "Epoch: 15, Batch number: 36, Loss: 2657.516357421875\n",
      "Epoch: 16, Batch number: 60, Loss: 2465.548828125\n",
      "Epoch: 18, Batch number: 8, Loss: 2378.0\n",
      "Epoch: 19, Batch number: 32, Loss: 2364.385498046875\n",
      "Epoch: 20, Batch number: 56, Loss: 2395.4658203125\n",
      "Epoch: 22, Batch number: 4, Loss: 2292.33349609375\n",
      "Epoch: 23, Batch number: 28, Loss: 2235.928466796875\n",
      "Epoch: 24, Batch number: 52, Loss: 2215.4150390625\n",
      "Epoch: 26, Batch number: 0, Loss: 2139.688720703125\n",
      "Epoch: 27, Batch number: 24, Loss: 2185.945068359375\n",
      "Epoch: 28, Batch number: 48, Loss: 2050.27490234375\n",
      "Epoch: 29, Batch number: 72, Loss: 1923.2467041015625\n",
      "Epoch: 31, Batch number: 20, Loss: 1949.20703125\n",
      "Epoch: 32, Batch number: 44, Loss: 1952.5994873046875\n",
      "Epoch: 33, Batch number: 68, Loss: 1958.378173828125\n",
      "Epoch: 35, Batch number: 16, Loss: 1845.6409912109375\n",
      "Epoch: 36, Batch number: 40, Loss: 1775.865234375\n",
      "Epoch: 37, Batch number: 64, Loss: 1865.2989501953125\n",
      "Epoch: 39, Batch number: 12, Loss: 1665.5986328125\n",
      "Epoch: 40, Batch number: 36, Loss: 1714.57861328125\n",
      "Epoch: 41, Batch number: 60, Loss: 1646.1038818359375\n",
      "Epoch: 43, Batch number: 8, Loss: 1627.7213134765625\n",
      "Epoch: 44, Batch number: 32, Loss: 1527.4827880859375\n",
      "Epoch: 45, Batch number: 56, Loss: 1642.14306640625\n",
      "Epoch: 47, Batch number: 4, Loss: 1522.345703125\n",
      "Epoch: 48, Batch number: 28, Loss: 1477.21875\n",
      "Epoch: 49, Batch number: 52, Loss: 1467.38427734375\n",
      "Epoch: 51, Batch number: 0, Loss: 1355.172607421875\n",
      "Epoch: 52, Batch number: 24, Loss: 1389.01806640625\n",
      "Epoch: 53, Batch number: 48, Loss: 1340.131103515625\n",
      "Epoch: 54, Batch number: 72, Loss: 1411.3966064453125\n",
      "Epoch: 56, Batch number: 20, Loss: 1270.1329345703125\n",
      "Epoch: 57, Batch number: 44, Loss: 1266.0799560546875\n",
      "Epoch: 58, Batch number: 68, Loss: 1268.771240234375\n",
      "Epoch: 60, Batch number: 16, Loss: 1250.7301025390625\n",
      "Epoch: 61, Batch number: 40, Loss: 1201.15380859375\n",
      "Epoch: 62, Batch number: 64, Loss: 1192.7099609375\n",
      "Epoch: 64, Batch number: 12, Loss: 1151.0587158203125\n",
      "Epoch: 65, Batch number: 36, Loss: 1141.9520263671875\n",
      "Epoch: 66, Batch number: 60, Loss: 1106.948486328125\n",
      "Epoch: 68, Batch number: 8, Loss: 1049.061767578125\n",
      "Epoch: 69, Batch number: 32, Loss: 1162.0645751953125\n",
      "Epoch: 70, Batch number: 56, Loss: 1025.5125732421875\n",
      "Epoch: 72, Batch number: 4, Loss: 954.6563720703125\n",
      "Epoch: 73, Batch number: 28, Loss: 1043.2052001953125\n",
      "Epoch: 74, Batch number: 52, Loss: 945.5548706054688\n",
      "Epoch: 76, Batch number: 0, Loss: 946.1568603515625\n",
      "Epoch: 77, Batch number: 24, Loss: 922.4564819335938\n",
      "Epoch: 78, Batch number: 48, Loss: 913.5408935546875\n",
      "Epoch: 79, Batch number: 72, Loss: 876.5687866210938\n",
      "Epoch: 81, Batch number: 20, Loss: 852.980224609375\n",
      "Epoch: 82, Batch number: 44, Loss: 859.0120849609375\n",
      "Epoch: 83, Batch number: 68, Loss: 945.6444702148438\n",
      "Epoch: 85, Batch number: 16, Loss: 853.6695556640625\n",
      "Epoch: 86, Batch number: 40, Loss: 835.2421264648438\n",
      "Epoch: 87, Batch number: 64, Loss: 843.328125\n",
      "Epoch: 89, Batch number: 12, Loss: 865.7008666992188\n",
      "Epoch: 90, Batch number: 36, Loss: 798.1571655273438\n",
      "Epoch: 91, Batch number: 60, Loss: 785.6467895507812\n",
      "Epoch: 93, Batch number: 8, Loss: 779.51171875\n",
      "Epoch: 94, Batch number: 32, Loss: 757.5128784179688\n",
      "Epoch: 95, Batch number: 56, Loss: 691.5259399414062\n",
      "Epoch: 97, Batch number: 4, Loss: 712.9237060546875\n",
      "Epoch: 98, Batch number: 28, Loss: 749.0701904296875\n",
      "Epoch: 99, Batch number: 52, Loss: 701.97509765625\n",
      "Epoch: 101, Batch number: 0, Loss: 700.5326538085938\n",
      "Epoch: 102, Batch number: 24, Loss: 680.8723754882812\n",
      "Epoch: 103, Batch number: 48, Loss: 650.6415405273438\n",
      "Epoch: 104, Batch number: 72, Loss: 653.5547485351562\n",
      "Epoch: 106, Batch number: 20, Loss: 601.3582763671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 608.2353515625\n",
      "Epoch: 108, Batch number: 68, Loss: 598.5827026367188\n",
      "Epoch: 110, Batch number: 16, Loss: 574.2925415039062\n",
      "Epoch: 111, Batch number: 40, Loss: 577.763671875\n",
      "Epoch: 112, Batch number: 64, Loss: 628.8222045898438\n",
      "Epoch: 114, Batch number: 12, Loss: 565.3673095703125\n",
      "Epoch: 115, Batch number: 36, Loss: 530.5703735351562\n",
      "Epoch: 116, Batch number: 60, Loss: 549.179931640625\n",
      "Epoch: 118, Batch number: 8, Loss: 521.1978149414062\n",
      "Epoch: 119, Batch number: 32, Loss: 517.372802734375\n",
      "Epoch: 120, Batch number: 56, Loss: 528.0608520507812\n",
      "Epoch: 122, Batch number: 4, Loss: 462.8305358886719\n",
      "Epoch: 123, Batch number: 28, Loss: 489.802490234375\n",
      "Epoch: 124, Batch number: 52, Loss: 472.2850646972656\n",
      "Epoch: 126, Batch number: 0, Loss: 478.250732421875\n",
      "Epoch: 127, Batch number: 24, Loss: 493.2417297363281\n",
      "Epoch: 128, Batch number: 48, Loss: 482.37835693359375\n",
      "Epoch: 129, Batch number: 72, Loss: 457.85601806640625\n",
      "Epoch: 131, Batch number: 20, Loss: 397.2845153808594\n",
      "Epoch: 132, Batch number: 44, Loss: 373.8578186035156\n",
      "Epoch: 133, Batch number: 68, Loss: 374.8819885253906\n",
      "Epoch: 135, Batch number: 16, Loss: 417.19482421875\n",
      "Epoch: 136, Batch number: 40, Loss: 376.38079833984375\n",
      "Epoch: 137, Batch number: 64, Loss: 397.19085693359375\n",
      "Epoch: 139, Batch number: 12, Loss: 382.3742980957031\n",
      "Epoch: 140, Batch number: 36, Loss: 348.9512939453125\n",
      "Epoch: 141, Batch number: 60, Loss: 336.16680908203125\n",
      "Epoch: 143, Batch number: 8, Loss: 294.3070983886719\n",
      "Epoch: 144, Batch number: 32, Loss: 337.2747497558594\n",
      "Epoch: 145, Batch number: 56, Loss: 363.0313720703125\n",
      "Epoch: 147, Batch number: 4, Loss: 340.13128662109375\n",
      "Epoch: 148, Batch number: 28, Loss: 317.93695068359375\n",
      "Epoch: 149, Batch number: 52, Loss: 312.09869384765625\n",
      "Epoch: 151, Batch number: 0, Loss: 278.25567626953125\n",
      "Epoch: 152, Batch number: 24, Loss: 280.33349609375\n",
      "Epoch: 153, Batch number: 48, Loss: 282.1193542480469\n",
      "Epoch: 154, Batch number: 72, Loss: 308.5321044921875\n",
      "Epoch: 156, Batch number: 20, Loss: 275.60382080078125\n",
      "Epoch: 157, Batch number: 44, Loss: 302.8760681152344\n",
      "Epoch: 158, Batch number: 68, Loss: 224.9305419921875\n",
      "Epoch: 160, Batch number: 16, Loss: 244.6705322265625\n",
      "Epoch: 161, Batch number: 40, Loss: 232.50157165527344\n",
      "Epoch: 162, Batch number: 64, Loss: 240.78099060058594\n",
      "Epoch: 164, Batch number: 12, Loss: 235.76708984375\n",
      "Epoch: 165, Batch number: 36, Loss: 261.85205078125\n",
      "Epoch: 166, Batch number: 60, Loss: 245.42242431640625\n",
      "Epoch: 168, Batch number: 8, Loss: 257.9154052734375\n",
      "Epoch: 169, Batch number: 32, Loss: 228.50990295410156\n",
      "Epoch: 170, Batch number: 56, Loss: 249.73013305664062\n",
      "Epoch: 172, Batch number: 4, Loss: 207.4144287109375\n",
      "Epoch: 173, Batch number: 28, Loss: 203.27362060546875\n",
      "Epoch: 174, Batch number: 52, Loss: 226.7776336669922\n",
      "Epoch: 176, Batch number: 0, Loss: 194.3980712890625\n",
      "Epoch: 177, Batch number: 24, Loss: 196.01963806152344\n",
      "Epoch: 178, Batch number: 48, Loss: 209.4771728515625\n",
      "Epoch: 179, Batch number: 72, Loss: 188.6744842529297\n",
      "Epoch: 181, Batch number: 20, Loss: 185.09500122070312\n",
      "Epoch: 182, Batch number: 44, Loss: 189.69757080078125\n",
      "Epoch: 183, Batch number: 68, Loss: 188.29409790039062\n",
      "Epoch: 185, Batch number: 16, Loss: 164.35418701171875\n",
      "Epoch: 186, Batch number: 40, Loss: 186.0354461669922\n",
      "Epoch: 187, Batch number: 64, Loss: 174.71163940429688\n",
      "Epoch: 189, Batch number: 12, Loss: 137.74746704101562\n",
      "Epoch: 190, Batch number: 36, Loss: 154.82522583007812\n",
      "Epoch: 191, Batch number: 60, Loss: 148.5679931640625\n",
      "Epoch: 193, Batch number: 8, Loss: 155.12669372558594\n",
      "Epoch: 194, Batch number: 32, Loss: 151.31019592285156\n",
      "Epoch: 195, Batch number: 56, Loss: 163.5401153564453\n",
      "Epoch: 197, Batch number: 4, Loss: 137.93914794921875\n",
      "Epoch: 198, Batch number: 28, Loss: 151.21786499023438\n",
      "Epoch: 199, Batch number: 52, Loss: 156.7421112060547\n",
      "Epoch: 201, Batch number: 0, Loss: 113.41795349121094\n",
      "Epoch: 202, Batch number: 24, Loss: 122.69574737548828\n",
      "Epoch: 203, Batch number: 48, Loss: 104.03764343261719\n",
      "Epoch: 204, Batch number: 72, Loss: 128.84234619140625\n",
      "Epoch: 206, Batch number: 20, Loss: 115.2984390258789\n",
      "Epoch: 207, Batch number: 44, Loss: 106.77761840820312\n",
      "Epoch: 208, Batch number: 68, Loss: 108.94685363769531\n",
      "Epoch: 210, Batch number: 16, Loss: 116.70182037353516\n",
      "Epoch: 211, Batch number: 40, Loss: 109.25376892089844\n",
      "Epoch: 212, Batch number: 64, Loss: 88.0696792602539\n",
      "Epoch: 214, Batch number: 12, Loss: 93.68701171875\n",
      "Epoch: 215, Batch number: 36, Loss: 98.66831970214844\n",
      "Epoch: 216, Batch number: 60, Loss: 124.21768951416016\n",
      "Epoch: 218, Batch number: 8, Loss: 101.07257080078125\n",
      "Epoch: 219, Batch number: 32, Loss: 124.99729919433594\n",
      "Epoch: 220, Batch number: 56, Loss: 87.01578521728516\n",
      "Epoch: 222, Batch number: 4, Loss: 119.27845764160156\n",
      "Epoch: 223, Batch number: 28, Loss: 102.13858795166016\n",
      "Epoch: 224, Batch number: 52, Loss: 102.00885009765625\n",
      "Epoch: 226, Batch number: 0, Loss: 86.33090209960938\n",
      "Epoch: 227, Batch number: 24, Loss: 90.6044692993164\n",
      "Epoch: 228, Batch number: 48, Loss: 90.88760375976562\n",
      "Epoch: 229, Batch number: 72, Loss: 83.1253433227539\n",
      "Epoch: 231, Batch number: 20, Loss: 71.43589782714844\n",
      "Epoch: 232, Batch number: 44, Loss: 77.76335906982422\n",
      "Epoch: 233, Batch number: 68, Loss: 74.73977661132812\n",
      "Epoch: 235, Batch number: 16, Loss: 78.48345947265625\n",
      "Epoch: 236, Batch number: 40, Loss: 80.6944580078125\n",
      "Epoch: 237, Batch number: 64, Loss: 74.7081069946289\n",
      "Epoch: 239, Batch number: 12, Loss: 69.09783172607422\n",
      "Epoch: 240, Batch number: 36, Loss: 64.34605407714844\n",
      "Epoch: 241, Batch number: 60, Loss: 63.93645477294922\n",
      "Epoch: 243, Batch number: 8, Loss: 60.492774963378906\n",
      "Epoch: 244, Batch number: 32, Loss: 46.0546875\n",
      "Epoch: 245, Batch number: 56, Loss: 64.16671752929688\n",
      "Epoch: 247, Batch number: 4, Loss: 54.369815826416016\n",
      "Epoch: 248, Batch number: 28, Loss: 70.42134857177734\n",
      "Epoch: 249, Batch number: 52, Loss: 56.50883865356445\n",
      "Epoch: 251, Batch number: 0, Loss: 70.9551010131836\n",
      "Epoch: 252, Batch number: 24, Loss: 42.59468460083008\n",
      "Epoch: 253, Batch number: 48, Loss: 42.555450439453125\n",
      "Epoch: 254, Batch number: 72, Loss: 60.539676666259766\n",
      "Epoch: 256, Batch number: 20, Loss: 36.48847961425781\n",
      "Epoch: 257, Batch number: 44, Loss: 45.388214111328125\n",
      "Epoch: 258, Batch number: 68, Loss: 51.989200592041016\n",
      "Epoch: 260, Batch number: 16, Loss: 52.13752365112305\n",
      "Epoch: 261, Batch number: 40, Loss: 45.00190734863281\n",
      "Epoch: 262, Batch number: 64, Loss: 53.233680725097656\n",
      "Epoch: 264, Batch number: 12, Loss: 36.137725830078125\n",
      "Epoch: 265, Batch number: 36, Loss: 33.659263610839844\n",
      "Epoch: 266, Batch number: 60, Loss: 42.268638610839844\n",
      "Epoch: 268, Batch number: 8, Loss: 49.71922302246094\n",
      "Epoch: 269, Batch number: 32, Loss: 35.803035736083984\n",
      "Epoch: 270, Batch number: 56, Loss: 40.45884704589844\n",
      "Epoch: 272, Batch number: 4, Loss: 34.48325729370117\n",
      "Epoch: 273, Batch number: 28, Loss: 36.460227966308594\n",
      "Epoch: 274, Batch number: 52, Loss: 35.32933044433594\n",
      "Epoch: 276, Batch number: 0, Loss: 36.42729949951172\n",
      "Epoch: 277, Batch number: 24, Loss: 33.57398986816406\n",
      "Epoch: 278, Batch number: 48, Loss: 51.367591857910156\n",
      "Epoch: 279, Batch number: 72, Loss: 35.421478271484375\n",
      "Epoch: 281, Batch number: 20, Loss: 28.972496032714844\n",
      "Epoch: 282, Batch number: 44, Loss: 29.814529418945312\n",
      "Epoch: 283, Batch number: 68, Loss: 35.67108917236328\n",
      "Epoch: 285, Batch number: 16, Loss: 32.68744659423828\n",
      "Epoch: 286, Batch number: 40, Loss: 26.491943359375\n",
      "Epoch: 287, Batch number: 64, Loss: 26.471080780029297\n",
      "Epoch: 289, Batch number: 12, Loss: 25.417884826660156\n",
      "Epoch: 290, Batch number: 36, Loss: 35.081871032714844\n",
      "Epoch: 291, Batch number: 60, Loss: 26.712797164916992\n",
      "Epoch: 293, Batch number: 8, Loss: 38.08094787597656\n",
      "Epoch: 294, Batch number: 32, Loss: 28.521167755126953\n",
      "Epoch: 295, Batch number: 56, Loss: 29.624221801757812\n",
      "Epoch: 297, Batch number: 4, Loss: 29.927356719970703\n",
      "Epoch: 298, Batch number: 28, Loss: 21.838823318481445\n",
      "Epoch: 299, Batch number: 52, Loss: 22.161033630371094\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4413.447265625\n",
      "Epoch: 2, Batch number: 24, Loss: 4130.42236328125\n",
      "Epoch: 3, Batch number: 48, Loss: 3678.064697265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch number: 72, Loss: 3224.27783203125\n",
      "Epoch: 6, Batch number: 20, Loss: 2908.752685546875\n",
      "Epoch: 7, Batch number: 44, Loss: 2820.038818359375\n",
      "Epoch: 8, Batch number: 68, Loss: 2688.367431640625\n",
      "Epoch: 10, Batch number: 16, Loss: 2554.703125\n",
      "Epoch: 11, Batch number: 40, Loss: 2605.600341796875\n",
      "Epoch: 12, Batch number: 64, Loss: 2496.31787109375\n",
      "Epoch: 14, Batch number: 12, Loss: 2351.843017578125\n",
      "Epoch: 15, Batch number: 36, Loss: 2231.96240234375\n",
      "Epoch: 16, Batch number: 60, Loss: 2306.73876953125\n",
      "Epoch: 18, Batch number: 8, Loss: 2175.480224609375\n",
      "Epoch: 19, Batch number: 32, Loss: 2225.526123046875\n",
      "Epoch: 20, Batch number: 56, Loss: 2024.001708984375\n",
      "Epoch: 22, Batch number: 4, Loss: 2072.9384765625\n",
      "Epoch: 23, Batch number: 28, Loss: 1911.9512939453125\n",
      "Epoch: 24, Batch number: 52, Loss: 1891.611572265625\n",
      "Epoch: 26, Batch number: 0, Loss: 1838.603759765625\n",
      "Epoch: 27, Batch number: 24, Loss: 1743.7537841796875\n",
      "Epoch: 28, Batch number: 48, Loss: 1741.2706298828125\n",
      "Epoch: 29, Batch number: 72, Loss: 1725.96484375\n",
      "Epoch: 31, Batch number: 20, Loss: 1533.02783203125\n",
      "Epoch: 32, Batch number: 44, Loss: 1499.808837890625\n",
      "Epoch: 33, Batch number: 68, Loss: 1560.1123046875\n",
      "Epoch: 35, Batch number: 16, Loss: 1499.6190185546875\n",
      "Epoch: 36, Batch number: 40, Loss: 1492.3167724609375\n",
      "Epoch: 37, Batch number: 64, Loss: 1453.3834228515625\n",
      "Epoch: 39, Batch number: 12, Loss: 1364.3690185546875\n",
      "Epoch: 40, Batch number: 36, Loss: 1360.4718017578125\n",
      "Epoch: 41, Batch number: 60, Loss: 1181.1827392578125\n",
      "Epoch: 43, Batch number: 8, Loss: 1284.9481201171875\n",
      "Epoch: 44, Batch number: 32, Loss: 1152.669677734375\n",
      "Epoch: 45, Batch number: 56, Loss: 1174.9825439453125\n",
      "Epoch: 47, Batch number: 4, Loss: 1089.7939453125\n",
      "Epoch: 48, Batch number: 28, Loss: 1084.2149658203125\n",
      "Epoch: 49, Batch number: 52, Loss: 1130.8016357421875\n",
      "Epoch: 51, Batch number: 0, Loss: 987.133056640625\n",
      "Epoch: 52, Batch number: 24, Loss: 953.0210571289062\n",
      "Epoch: 53, Batch number: 48, Loss: 928.6591796875\n",
      "Epoch: 54, Batch number: 72, Loss: 968.7201538085938\n",
      "Epoch: 56, Batch number: 20, Loss: 979.2549438476562\n",
      "Epoch: 57, Batch number: 44, Loss: 929.1796875\n",
      "Epoch: 58, Batch number: 68, Loss: 906.7576293945312\n",
      "Epoch: 60, Batch number: 16, Loss: 832.8438720703125\n",
      "Epoch: 61, Batch number: 40, Loss: 859.3934326171875\n",
      "Epoch: 62, Batch number: 64, Loss: 851.9944458007812\n",
      "Epoch: 64, Batch number: 12, Loss: 775.4027709960938\n",
      "Epoch: 65, Batch number: 36, Loss: 844.6580810546875\n",
      "Epoch: 66, Batch number: 60, Loss: 813.771240234375\n",
      "Epoch: 68, Batch number: 8, Loss: 806.842041015625\n",
      "Epoch: 69, Batch number: 32, Loss: 734.3980712890625\n",
      "Epoch: 70, Batch number: 56, Loss: 722.7646484375\n",
      "Epoch: 72, Batch number: 4, Loss: 658.2196655273438\n",
      "Epoch: 73, Batch number: 28, Loss: 745.3455200195312\n",
      "Epoch: 74, Batch number: 52, Loss: 745.60888671875\n",
      "Epoch: 76, Batch number: 0, Loss: 623.5580444335938\n",
      "Epoch: 77, Batch number: 24, Loss: 660.9270629882812\n",
      "Epoch: 78, Batch number: 48, Loss: 617.9481811523438\n",
      "Epoch: 79, Batch number: 72, Loss: 597.529296875\n",
      "Epoch: 81, Batch number: 20, Loss: 607.0526733398438\n",
      "Epoch: 82, Batch number: 44, Loss: 597.629638671875\n",
      "Epoch: 83, Batch number: 68, Loss: 553.0872192382812\n",
      "Epoch: 85, Batch number: 16, Loss: 579.0828857421875\n",
      "Epoch: 86, Batch number: 40, Loss: 460.3518981933594\n",
      "Epoch: 87, Batch number: 64, Loss: 491.5921936035156\n",
      "Epoch: 89, Batch number: 12, Loss: 473.1607971191406\n",
      "Epoch: 90, Batch number: 36, Loss: 427.40875244140625\n",
      "Epoch: 91, Batch number: 60, Loss: 455.0591125488281\n",
      "Epoch: 93, Batch number: 8, Loss: 441.8144836425781\n",
      "Epoch: 94, Batch number: 32, Loss: 458.4744873046875\n",
      "Epoch: 95, Batch number: 56, Loss: 415.0393981933594\n",
      "Epoch: 97, Batch number: 4, Loss: 411.5003356933594\n",
      "Epoch: 98, Batch number: 28, Loss: 439.4476013183594\n",
      "Epoch: 99, Batch number: 52, Loss: 385.2032775878906\n",
      "Epoch: 101, Batch number: 0, Loss: 402.15997314453125\n",
      "Epoch: 102, Batch number: 24, Loss: 378.10870361328125\n",
      "Epoch: 103, Batch number: 48, Loss: 402.11419677734375\n",
      "Epoch: 104, Batch number: 72, Loss: 383.5883483886719\n",
      "Epoch: 106, Batch number: 20, Loss: 392.42999267578125\n",
      "Epoch: 107, Batch number: 44, Loss: 315.4132080078125\n",
      "Epoch: 108, Batch number: 68, Loss: 314.4505615234375\n",
      "Epoch: 110, Batch number: 16, Loss: 300.4320983886719\n",
      "Epoch: 111, Batch number: 40, Loss: 283.00042724609375\n",
      "Epoch: 112, Batch number: 64, Loss: 295.490478515625\n",
      "Epoch: 114, Batch number: 12, Loss: 276.130615234375\n",
      "Epoch: 115, Batch number: 36, Loss: 264.708984375\n",
      "Epoch: 116, Batch number: 60, Loss: 285.06072998046875\n",
      "Epoch: 118, Batch number: 8, Loss: 233.48133850097656\n",
      "Epoch: 119, Batch number: 32, Loss: 251.8070068359375\n",
      "Epoch: 120, Batch number: 56, Loss: 285.6531982421875\n",
      "Epoch: 122, Batch number: 4, Loss: 250.21759033203125\n",
      "Epoch: 123, Batch number: 28, Loss: 260.7915344238281\n",
      "Epoch: 124, Batch number: 52, Loss: 234.08192443847656\n",
      "Epoch: 126, Batch number: 0, Loss: 200.98428344726562\n",
      "Epoch: 127, Batch number: 24, Loss: 206.3880615234375\n",
      "Epoch: 128, Batch number: 48, Loss: 205.02647399902344\n",
      "Epoch: 129, Batch number: 72, Loss: 183.11595153808594\n",
      "Epoch: 131, Batch number: 20, Loss: 190.07257080078125\n",
      "Epoch: 132, Batch number: 44, Loss: 188.48118591308594\n",
      "Epoch: 133, Batch number: 68, Loss: 179.2322998046875\n",
      "Epoch: 135, Batch number: 16, Loss: 160.3663330078125\n",
      "Epoch: 136, Batch number: 40, Loss: 152.97442626953125\n",
      "Epoch: 137, Batch number: 64, Loss: 187.68528747558594\n",
      "Epoch: 139, Batch number: 12, Loss: 155.2535400390625\n",
      "Epoch: 140, Batch number: 36, Loss: 141.8233642578125\n",
      "Epoch: 141, Batch number: 60, Loss: 163.69500732421875\n",
      "Epoch: 143, Batch number: 8, Loss: 138.6553497314453\n",
      "Epoch: 144, Batch number: 32, Loss: 135.70751953125\n",
      "Epoch: 145, Batch number: 56, Loss: 138.57872009277344\n",
      "Epoch: 147, Batch number: 4, Loss: 134.65853881835938\n",
      "Epoch: 148, Batch number: 28, Loss: 117.31163787841797\n",
      "Epoch: 149, Batch number: 52, Loss: 145.1546630859375\n",
      "Epoch: 151, Batch number: 0, Loss: 117.46599578857422\n",
      "Epoch: 152, Batch number: 24, Loss: 138.5540008544922\n",
      "Epoch: 153, Batch number: 48, Loss: 130.20831298828125\n",
      "Epoch: 154, Batch number: 72, Loss: 118.16381072998047\n",
      "Epoch: 156, Batch number: 20, Loss: 104.86791229248047\n",
      "Epoch: 157, Batch number: 44, Loss: 98.79150390625\n",
      "Epoch: 158, Batch number: 68, Loss: 88.26899719238281\n",
      "Epoch: 160, Batch number: 16, Loss: 78.25335693359375\n",
      "Epoch: 161, Batch number: 40, Loss: 90.09259796142578\n",
      "Epoch: 162, Batch number: 64, Loss: 88.45799255371094\n",
      "Epoch: 164, Batch number: 12, Loss: 91.66655731201172\n",
      "Epoch: 165, Batch number: 36, Loss: 96.07293701171875\n",
      "Epoch: 166, Batch number: 60, Loss: 88.64049530029297\n",
      "Epoch: 168, Batch number: 8, Loss: 88.90178680419922\n",
      "Epoch: 169, Batch number: 32, Loss: 88.37187957763672\n",
      "Epoch: 170, Batch number: 56, Loss: 90.99546813964844\n",
      "Epoch: 172, Batch number: 4, Loss: 61.124168395996094\n",
      "Epoch: 173, Batch number: 28, Loss: 84.60140991210938\n",
      "Epoch: 174, Batch number: 52, Loss: 66.47622680664062\n",
      "Epoch: 176, Batch number: 0, Loss: 69.18843841552734\n",
      "Epoch: 177, Batch number: 24, Loss: 67.14137268066406\n",
      "Epoch: 178, Batch number: 48, Loss: 59.64947509765625\n",
      "Epoch: 179, Batch number: 72, Loss: 69.24298095703125\n",
      "Epoch: 181, Batch number: 20, Loss: 58.67156982421875\n",
      "Epoch: 182, Batch number: 44, Loss: 60.471858978271484\n",
      "Epoch: 183, Batch number: 68, Loss: 52.166019439697266\n",
      "Epoch: 185, Batch number: 16, Loss: 58.65013885498047\n",
      "Epoch: 186, Batch number: 40, Loss: 52.95384979248047\n",
      "Epoch: 187, Batch number: 64, Loss: 59.078060150146484\n",
      "Epoch: 189, Batch number: 12, Loss: 45.81740188598633\n",
      "Epoch: 190, Batch number: 36, Loss: 54.92349624633789\n",
      "Epoch: 191, Batch number: 60, Loss: 43.29169845581055\n",
      "Epoch: 193, Batch number: 8, Loss: 43.07852554321289\n",
      "Epoch: 194, Batch number: 32, Loss: 53.550750732421875\n",
      "Epoch: 195, Batch number: 56, Loss: 47.22813034057617\n",
      "Epoch: 197, Batch number: 4, Loss: 40.73268508911133\n",
      "Epoch: 198, Batch number: 28, Loss: 37.960044860839844\n",
      "Epoch: 199, Batch number: 52, Loss: 45.934898376464844\n",
      "Epoch: 201, Batch number: 0, Loss: 37.736263275146484\n",
      "Epoch: 202, Batch number: 24, Loss: 39.556121826171875\n",
      "Epoch: 203, Batch number: 48, Loss: 45.98151779174805\n",
      "Epoch: 204, Batch number: 72, Loss: 34.02869415283203\n",
      "Epoch: 206, Batch number: 20, Loss: 34.266822814941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207, Batch number: 44, Loss: 35.31901168823242\n",
      "Epoch: 208, Batch number: 68, Loss: 33.2122802734375\n",
      "Epoch: 210, Batch number: 16, Loss: 32.74144744873047\n",
      "Epoch: 211, Batch number: 40, Loss: 38.4315299987793\n",
      "Epoch: 212, Batch number: 64, Loss: 29.831634521484375\n",
      "Epoch: 214, Batch number: 12, Loss: 30.949764251708984\n",
      "Epoch: 215, Batch number: 36, Loss: 29.426156997680664\n",
      "Epoch: 216, Batch number: 60, Loss: 28.864463806152344\n",
      "Epoch: 218, Batch number: 8, Loss: 31.73432731628418\n",
      "Epoch: 219, Batch number: 32, Loss: 25.386699676513672\n",
      "Epoch: 220, Batch number: 56, Loss: 26.215591430664062\n",
      "Epoch: 222, Batch number: 4, Loss: 25.57903289794922\n",
      "Epoch: 223, Batch number: 28, Loss: 26.505321502685547\n",
      "Epoch: 224, Batch number: 52, Loss: 19.361515045166016\n",
      "Epoch: 226, Batch number: 0, Loss: 21.391883850097656\n",
      "Epoch: 227, Batch number: 24, Loss: 22.98709487915039\n",
      "Epoch: 228, Batch number: 48, Loss: 25.123891830444336\n",
      "Epoch: 229, Batch number: 72, Loss: 21.660354614257812\n",
      "Epoch: 231, Batch number: 20, Loss: 19.534648895263672\n",
      "Epoch: 232, Batch number: 44, Loss: 19.263439178466797\n",
      "Epoch: 233, Batch number: 68, Loss: 21.63018798828125\n",
      "Epoch: 235, Batch number: 16, Loss: 19.440998077392578\n",
      "Epoch: 236, Batch number: 40, Loss: 16.807411193847656\n",
      "Epoch: 237, Batch number: 64, Loss: 19.51518440246582\n",
      "Epoch: 239, Batch number: 12, Loss: 22.332082748413086\n",
      "Epoch: 240, Batch number: 36, Loss: 17.07412338256836\n",
      "Epoch: 241, Batch number: 60, Loss: 20.292444229125977\n",
      "Epoch: 243, Batch number: 8, Loss: 17.067825317382812\n",
      "Epoch: 244, Batch number: 32, Loss: 16.957130432128906\n",
      "Epoch: 245, Batch number: 56, Loss: 20.324377059936523\n",
      "Epoch: 247, Batch number: 4, Loss: 18.01866340637207\n",
      "Epoch: 248, Batch number: 28, Loss: 14.887653350830078\n",
      "Epoch: 249, Batch number: 52, Loss: 14.029093742370605\n",
      "Epoch: 251, Batch number: 0, Loss: 10.928805351257324\n",
      "Epoch: 252, Batch number: 24, Loss: 14.502314567565918\n",
      "Epoch: 253, Batch number: 48, Loss: 16.390663146972656\n",
      "Epoch: 254, Batch number: 72, Loss: 14.673259735107422\n",
      "Epoch: 256, Batch number: 20, Loss: 12.111656188964844\n",
      "Epoch: 257, Batch number: 44, Loss: 18.422256469726562\n",
      "Epoch: 258, Batch number: 68, Loss: 12.651399612426758\n",
      "Epoch: 260, Batch number: 16, Loss: 19.700611114501953\n",
      "Epoch: 261, Batch number: 40, Loss: 15.414649963378906\n",
      "Epoch: 262, Batch number: 64, Loss: 13.92733383178711\n",
      "Epoch: 264, Batch number: 12, Loss: 12.870201110839844\n",
      "Epoch: 265, Batch number: 36, Loss: 15.533003807067871\n",
      "Epoch: 266, Batch number: 60, Loss: 11.68704891204834\n",
      "Epoch: 268, Batch number: 8, Loss: 11.713176727294922\n",
      "Epoch: 269, Batch number: 32, Loss: 10.225930213928223\n",
      "Epoch: 270, Batch number: 56, Loss: 10.256678581237793\n",
      "Epoch: 272, Batch number: 4, Loss: 9.212539672851562\n",
      "Epoch: 273, Batch number: 28, Loss: 7.127351760864258\n",
      "Epoch: 274, Batch number: 52, Loss: 8.237424850463867\n",
      "Epoch: 276, Batch number: 0, Loss: 9.887266159057617\n",
      "Epoch: 277, Batch number: 24, Loss: 7.223923683166504\n",
      "Epoch: 278, Batch number: 48, Loss: 12.486681938171387\n",
      "Epoch: 279, Batch number: 72, Loss: 10.103407859802246\n",
      "Epoch: 281, Batch number: 20, Loss: 9.359580039978027\n",
      "Epoch: 282, Batch number: 44, Loss: 10.378820419311523\n",
      "Epoch: 283, Batch number: 68, Loss: 9.851299285888672\n",
      "Epoch: 285, Batch number: 16, Loss: 11.603376388549805\n",
      "Epoch: 286, Batch number: 40, Loss: 7.79752254486084\n",
      "Epoch: 287, Batch number: 64, Loss: 9.146570205688477\n",
      "Epoch: 289, Batch number: 12, Loss: 12.103079795837402\n",
      "Epoch: 290, Batch number: 36, Loss: 7.502371788024902\n",
      "Epoch: 291, Batch number: 60, Loss: 5.9330854415893555\n",
      "Epoch: 293, Batch number: 8, Loss: 7.730656623840332\n",
      "Epoch: 294, Batch number: 32, Loss: 14.76540756225586\n",
      "Epoch: 295, Batch number: 56, Loss: 10.416118621826172\n",
      "Epoch: 297, Batch number: 4, Loss: 5.463430404663086\n",
      "Epoch: 298, Batch number: 28, Loss: 5.5199785232543945\n",
      "Epoch: 299, Batch number: 52, Loss: 7.273919105529785\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4408.7939453125\n",
      "Epoch: 2, Batch number: 24, Loss: 4035.328125\n",
      "Epoch: 3, Batch number: 48, Loss: 3487.6943359375\n",
      "Epoch: 4, Batch number: 72, Loss: 3072.818115234375\n",
      "Epoch: 6, Batch number: 20, Loss: 2885.96044921875\n",
      "Epoch: 7, Batch number: 44, Loss: 2681.072998046875\n",
      "Epoch: 8, Batch number: 68, Loss: 2676.387451171875\n",
      "Epoch: 10, Batch number: 16, Loss: 2425.18505859375\n",
      "Epoch: 11, Batch number: 40, Loss: 2312.264892578125\n",
      "Epoch: 12, Batch number: 64, Loss: 2351.60302734375\n",
      "Epoch: 14, Batch number: 12, Loss: 2282.892333984375\n",
      "Epoch: 15, Batch number: 36, Loss: 2171.17138671875\n",
      "Epoch: 16, Batch number: 60, Loss: 2188.7646484375\n",
      "Epoch: 18, Batch number: 8, Loss: 2015.3370361328125\n",
      "Epoch: 19, Batch number: 32, Loss: 1907.2706298828125\n",
      "Epoch: 20, Batch number: 56, Loss: 1890.647705078125\n",
      "Epoch: 22, Batch number: 4, Loss: 1842.69677734375\n",
      "Epoch: 23, Batch number: 28, Loss: 1650.895263671875\n",
      "Epoch: 24, Batch number: 52, Loss: 1650.48779296875\n",
      "Epoch: 26, Batch number: 0, Loss: 1542.9813232421875\n",
      "Epoch: 27, Batch number: 24, Loss: 1589.7381591796875\n",
      "Epoch: 28, Batch number: 48, Loss: 1473.508056640625\n",
      "Epoch: 29, Batch number: 72, Loss: 1413.4921875\n",
      "Epoch: 31, Batch number: 20, Loss: 1327.9984130859375\n",
      "Epoch: 32, Batch number: 44, Loss: 1354.6890869140625\n",
      "Epoch: 33, Batch number: 68, Loss: 1285.560302734375\n",
      "Epoch: 35, Batch number: 16, Loss: 1251.2340087890625\n",
      "Epoch: 36, Batch number: 40, Loss: 1171.007080078125\n",
      "Epoch: 37, Batch number: 64, Loss: 1191.5816650390625\n",
      "Epoch: 39, Batch number: 12, Loss: 1063.5904541015625\n",
      "Epoch: 40, Batch number: 36, Loss: 1081.7020263671875\n",
      "Epoch: 41, Batch number: 60, Loss: 1061.8536376953125\n",
      "Epoch: 43, Batch number: 8, Loss: 1065.1326904296875\n",
      "Epoch: 44, Batch number: 32, Loss: 914.3909301757812\n",
      "Epoch: 45, Batch number: 56, Loss: 963.661865234375\n",
      "Epoch: 47, Batch number: 4, Loss: 885.4953002929688\n",
      "Epoch: 48, Batch number: 28, Loss: 866.380126953125\n",
      "Epoch: 49, Batch number: 52, Loss: 831.28515625\n",
      "Epoch: 51, Batch number: 0, Loss: 791.7902221679688\n",
      "Epoch: 52, Batch number: 24, Loss: 787.1482543945312\n",
      "Epoch: 53, Batch number: 48, Loss: 792.2079467773438\n",
      "Epoch: 54, Batch number: 72, Loss: 755.1619873046875\n",
      "Epoch: 56, Batch number: 20, Loss: 736.383056640625\n",
      "Epoch: 57, Batch number: 44, Loss: 763.2744750976562\n",
      "Epoch: 58, Batch number: 68, Loss: 678.0853271484375\n",
      "Epoch: 60, Batch number: 16, Loss: 643.4892578125\n",
      "Epoch: 61, Batch number: 40, Loss: 642.2550048828125\n",
      "Epoch: 62, Batch number: 64, Loss: 645.7282104492188\n",
      "Epoch: 64, Batch number: 12, Loss: 576.1464233398438\n",
      "Epoch: 65, Batch number: 36, Loss: 582.8038940429688\n",
      "Epoch: 66, Batch number: 60, Loss: 502.2204284667969\n",
      "Epoch: 68, Batch number: 8, Loss: 497.2229919433594\n",
      "Epoch: 69, Batch number: 32, Loss: 494.5875549316406\n",
      "Epoch: 70, Batch number: 56, Loss: 432.834716796875\n",
      "Epoch: 72, Batch number: 4, Loss: 429.6928405761719\n",
      "Epoch: 73, Batch number: 28, Loss: 434.6292419433594\n",
      "Epoch: 74, Batch number: 52, Loss: 425.9484558105469\n",
      "Epoch: 76, Batch number: 0, Loss: 439.0263366699219\n",
      "Epoch: 77, Batch number: 24, Loss: 398.80670166015625\n",
      "Epoch: 78, Batch number: 48, Loss: 423.0610046386719\n",
      "Epoch: 79, Batch number: 72, Loss: 394.9162902832031\n",
      "Epoch: 81, Batch number: 20, Loss: 355.38714599609375\n",
      "Epoch: 82, Batch number: 44, Loss: 338.0559387207031\n",
      "Epoch: 83, Batch number: 68, Loss: 379.33062744140625\n",
      "Epoch: 85, Batch number: 16, Loss: 328.72857666015625\n",
      "Epoch: 86, Batch number: 40, Loss: 330.2719421386719\n",
      "Epoch: 87, Batch number: 64, Loss: 318.00115966796875\n",
      "Epoch: 89, Batch number: 12, Loss: 309.91900634765625\n",
      "Epoch: 90, Batch number: 36, Loss: 260.54754638671875\n",
      "Epoch: 91, Batch number: 60, Loss: 299.0024108886719\n",
      "Epoch: 93, Batch number: 8, Loss: 269.4701843261719\n",
      "Epoch: 94, Batch number: 32, Loss: 242.1648712158203\n",
      "Epoch: 95, Batch number: 56, Loss: 258.4420471191406\n",
      "Epoch: 97, Batch number: 4, Loss: 217.65487670898438\n",
      "Epoch: 98, Batch number: 28, Loss: 235.90223693847656\n",
      "Epoch: 99, Batch number: 52, Loss: 230.0393829345703\n",
      "Epoch: 101, Batch number: 0, Loss: 214.39956665039062\n",
      "Epoch: 102, Batch number: 24, Loss: 219.59078979492188\n",
      "Epoch: 103, Batch number: 48, Loss: 228.4128875732422\n",
      "Epoch: 104, Batch number: 72, Loss: 184.36495971679688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106, Batch number: 20, Loss: 229.09417724609375\n",
      "Epoch: 107, Batch number: 44, Loss: 180.73825073242188\n",
      "Epoch: 108, Batch number: 68, Loss: 186.42181396484375\n",
      "Epoch: 110, Batch number: 16, Loss: 173.5504608154297\n",
      "Epoch: 111, Batch number: 40, Loss: 180.15818786621094\n",
      "Epoch: 112, Batch number: 64, Loss: 164.31863403320312\n",
      "Epoch: 114, Batch number: 12, Loss: 163.431640625\n",
      "Epoch: 115, Batch number: 36, Loss: 143.9077911376953\n",
      "Epoch: 116, Batch number: 60, Loss: 131.16392517089844\n",
      "Epoch: 118, Batch number: 8, Loss: 137.7639617919922\n",
      "Epoch: 119, Batch number: 32, Loss: 142.57266235351562\n",
      "Epoch: 120, Batch number: 56, Loss: 129.9823455810547\n",
      "Epoch: 122, Batch number: 4, Loss: 121.21617126464844\n",
      "Epoch: 123, Batch number: 28, Loss: 108.77942657470703\n",
      "Epoch: 124, Batch number: 52, Loss: 113.85075378417969\n",
      "Epoch: 126, Batch number: 0, Loss: 103.43618774414062\n",
      "Epoch: 127, Batch number: 24, Loss: 118.02228546142578\n",
      "Epoch: 128, Batch number: 48, Loss: 107.06661224365234\n",
      "Epoch: 129, Batch number: 72, Loss: 118.92384338378906\n",
      "Epoch: 131, Batch number: 20, Loss: 96.07781982421875\n",
      "Epoch: 132, Batch number: 44, Loss: 104.95206451416016\n",
      "Epoch: 133, Batch number: 68, Loss: 86.04364013671875\n",
      "Epoch: 135, Batch number: 16, Loss: 75.0058364868164\n",
      "Epoch: 136, Batch number: 40, Loss: 72.95457458496094\n",
      "Epoch: 137, Batch number: 64, Loss: 92.73147583007812\n",
      "Epoch: 139, Batch number: 12, Loss: 75.46456146240234\n",
      "Epoch: 140, Batch number: 36, Loss: 82.46625518798828\n",
      "Epoch: 141, Batch number: 60, Loss: 74.21226501464844\n",
      "Epoch: 143, Batch number: 8, Loss: 74.71498107910156\n",
      "Epoch: 144, Batch number: 32, Loss: 74.41134643554688\n",
      "Epoch: 145, Batch number: 56, Loss: 72.55216979980469\n",
      "Epoch: 147, Batch number: 4, Loss: 72.9611587524414\n",
      "Epoch: 148, Batch number: 28, Loss: 58.98930740356445\n",
      "Epoch: 149, Batch number: 52, Loss: 60.12761306762695\n",
      "Epoch: 151, Batch number: 0, Loss: 62.87195587158203\n",
      "Epoch: 152, Batch number: 24, Loss: 51.92265701293945\n",
      "Epoch: 153, Batch number: 48, Loss: 52.08769226074219\n",
      "Epoch: 154, Batch number: 72, Loss: 52.165382385253906\n",
      "Epoch: 156, Batch number: 20, Loss: 45.43415832519531\n",
      "Epoch: 157, Batch number: 44, Loss: 57.17516326904297\n",
      "Epoch: 158, Batch number: 68, Loss: 49.669464111328125\n",
      "Epoch: 160, Batch number: 16, Loss: 47.23668670654297\n",
      "Epoch: 161, Batch number: 40, Loss: 41.43225860595703\n",
      "Epoch: 162, Batch number: 64, Loss: 41.76845169067383\n",
      "Epoch: 164, Batch number: 12, Loss: 34.45264434814453\n",
      "Epoch: 165, Batch number: 36, Loss: 41.73674774169922\n",
      "Epoch: 166, Batch number: 60, Loss: 42.5377197265625\n",
      "Epoch: 168, Batch number: 8, Loss: 47.41974639892578\n",
      "Epoch: 169, Batch number: 32, Loss: 40.446529388427734\n",
      "Epoch: 170, Batch number: 56, Loss: 38.188968658447266\n",
      "Epoch: 172, Batch number: 4, Loss: 31.678794860839844\n",
      "Epoch: 173, Batch number: 28, Loss: 31.34466552734375\n",
      "Epoch: 174, Batch number: 52, Loss: 31.585237503051758\n",
      "Epoch: 176, Batch number: 0, Loss: 30.908573150634766\n",
      "Epoch: 177, Batch number: 24, Loss: 27.800048828125\n",
      "Epoch: 178, Batch number: 48, Loss: 26.055095672607422\n",
      "Epoch: 179, Batch number: 72, Loss: 28.29361343383789\n",
      "Epoch: 181, Batch number: 20, Loss: 39.039642333984375\n",
      "Epoch: 182, Batch number: 44, Loss: 28.29694175720215\n",
      "Epoch: 183, Batch number: 68, Loss: 27.617290496826172\n",
      "Epoch: 185, Batch number: 16, Loss: 25.146387100219727\n",
      "Epoch: 186, Batch number: 40, Loss: 25.38553237915039\n",
      "Epoch: 187, Batch number: 64, Loss: 29.887968063354492\n",
      "Epoch: 189, Batch number: 12, Loss: 17.216583251953125\n",
      "Epoch: 190, Batch number: 36, Loss: 30.132156372070312\n",
      "Epoch: 191, Batch number: 60, Loss: 24.021305084228516\n",
      "Epoch: 193, Batch number: 8, Loss: 18.809532165527344\n",
      "Epoch: 194, Batch number: 32, Loss: 18.39699935913086\n",
      "Epoch: 195, Batch number: 56, Loss: 18.79566764831543\n",
      "Epoch: 197, Batch number: 4, Loss: 23.74087905883789\n",
      "Epoch: 198, Batch number: 28, Loss: 22.278850555419922\n",
      "Epoch: 199, Batch number: 52, Loss: 18.384193420410156\n",
      "Epoch: 201, Batch number: 0, Loss: 13.570700645446777\n",
      "Epoch: 202, Batch number: 24, Loss: 18.570491790771484\n",
      "Epoch: 203, Batch number: 48, Loss: 17.214168548583984\n",
      "Epoch: 204, Batch number: 72, Loss: 14.27463150024414\n",
      "Epoch: 206, Batch number: 20, Loss: 16.05042266845703\n",
      "Epoch: 207, Batch number: 44, Loss: 15.84736442565918\n",
      "Epoch: 208, Batch number: 68, Loss: 19.404220581054688\n",
      "Epoch: 210, Batch number: 16, Loss: 15.490488052368164\n",
      "Epoch: 211, Batch number: 40, Loss: 18.22570037841797\n",
      "Epoch: 212, Batch number: 64, Loss: 14.871671676635742\n",
      "Epoch: 214, Batch number: 12, Loss: 14.904311180114746\n",
      "Epoch: 215, Batch number: 36, Loss: 16.040008544921875\n",
      "Epoch: 216, Batch number: 60, Loss: 14.607242584228516\n",
      "Epoch: 218, Batch number: 8, Loss: 12.63663101196289\n",
      "Epoch: 219, Batch number: 32, Loss: 13.222489356994629\n",
      "Epoch: 220, Batch number: 56, Loss: 15.19836711883545\n",
      "Epoch: 222, Batch number: 4, Loss: 9.667423248291016\n",
      "Epoch: 223, Batch number: 28, Loss: 15.559357643127441\n",
      "Epoch: 224, Batch number: 52, Loss: 8.348681449890137\n",
      "Epoch: 226, Batch number: 0, Loss: 8.808197021484375\n",
      "Epoch: 227, Batch number: 24, Loss: 10.250398635864258\n",
      "Epoch: 228, Batch number: 48, Loss: 8.963638305664062\n",
      "Epoch: 229, Batch number: 72, Loss: 10.093701362609863\n",
      "Epoch: 231, Batch number: 20, Loss: 9.728309631347656\n",
      "Epoch: 232, Batch number: 44, Loss: 10.718016624450684\n",
      "Epoch: 233, Batch number: 68, Loss: 9.697284698486328\n",
      "Epoch: 235, Batch number: 16, Loss: 10.102728843688965\n",
      "Epoch: 236, Batch number: 40, Loss: 9.334915161132812\n",
      "Epoch: 237, Batch number: 64, Loss: 7.511191368103027\n",
      "Epoch: 239, Batch number: 12, Loss: 12.379265785217285\n",
      "Epoch: 240, Batch number: 36, Loss: 6.994088172912598\n",
      "Epoch: 241, Batch number: 60, Loss: 7.381813049316406\n",
      "Epoch: 243, Batch number: 8, Loss: 6.922817230224609\n",
      "Epoch: 244, Batch number: 32, Loss: 10.659659385681152\n",
      "Epoch: 245, Batch number: 56, Loss: 8.213643074035645\n",
      "Epoch: 247, Batch number: 4, Loss: 7.078064918518066\n",
      "Epoch: 248, Batch number: 28, Loss: 9.293265342712402\n",
      "Epoch: 249, Batch number: 52, Loss: 8.280460357666016\n",
      "Epoch: 251, Batch number: 0, Loss: 8.078554153442383\n",
      "Epoch: 252, Batch number: 24, Loss: 7.108037948608398\n",
      "Epoch: 253, Batch number: 48, Loss: 8.916882514953613\n",
      "Epoch: 254, Batch number: 72, Loss: 7.029455184936523\n",
      "Epoch: 256, Batch number: 20, Loss: 7.654714584350586\n",
      "Epoch: 257, Batch number: 44, Loss: 5.315247535705566\n",
      "Epoch: 258, Batch number: 68, Loss: 6.58929443359375\n",
      "Epoch: 260, Batch number: 16, Loss: 5.243659973144531\n",
      "Epoch: 261, Batch number: 40, Loss: 6.299588203430176\n",
      "Epoch: 262, Batch number: 64, Loss: 5.7722272872924805\n",
      "Epoch: 264, Batch number: 12, Loss: 5.898279190063477\n",
      "Epoch: 265, Batch number: 36, Loss: 6.902636528015137\n",
      "Epoch: 266, Batch number: 60, Loss: 5.155067443847656\n",
      "Epoch: 268, Batch number: 8, Loss: 4.122392654418945\n",
      "Epoch: 269, Batch number: 32, Loss: 5.677549362182617\n",
      "Epoch: 270, Batch number: 56, Loss: 6.908751487731934\n",
      "Epoch: 272, Batch number: 4, Loss: 5.255252838134766\n",
      "Epoch: 273, Batch number: 28, Loss: 8.994791984558105\n",
      "Epoch: 274, Batch number: 52, Loss: 4.639714241027832\n",
      "Epoch: 276, Batch number: 0, Loss: 6.915998458862305\n",
      "Epoch: 277, Batch number: 24, Loss: 3.1997947692871094\n",
      "Epoch: 278, Batch number: 48, Loss: 4.317334175109863\n",
      "Epoch: 279, Batch number: 72, Loss: 8.253549575805664\n",
      "Epoch: 281, Batch number: 20, Loss: 3.8513593673706055\n",
      "Epoch: 282, Batch number: 44, Loss: 5.1178178787231445\n",
      "Epoch: 283, Batch number: 68, Loss: 4.589927673339844\n",
      "Epoch: 285, Batch number: 16, Loss: 4.303895950317383\n",
      "Epoch: 286, Batch number: 40, Loss: 3.156752586364746\n",
      "Epoch: 287, Batch number: 64, Loss: 6.34742546081543\n",
      "Epoch: 289, Batch number: 12, Loss: 3.904574394226074\n",
      "Epoch: 290, Batch number: 36, Loss: 4.2243804931640625\n",
      "Epoch: 291, Batch number: 60, Loss: 4.698273658752441\n",
      "Epoch: 293, Batch number: 8, Loss: 8.657329559326172\n",
      "Epoch: 294, Batch number: 32, Loss: 4.916965484619141\n",
      "Epoch: 295, Batch number: 56, Loss: 2.8270511627197266\n",
      "Epoch: 297, Batch number: 4, Loss: 3.015599250793457\n",
      "Epoch: 298, Batch number: 28, Loss: 2.4425573348999023\n",
      "Epoch: 299, Batch number: 52, Loss: 3.4479236602783203\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4409.33447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 24, Loss: 3877.097900390625\n",
      "Epoch: 3, Batch number: 48, Loss: 3172.9169921875\n",
      "Epoch: 4, Batch number: 72, Loss: 2944.3154296875\n",
      "Epoch: 6, Batch number: 20, Loss: 2702.54638671875\n",
      "Epoch: 7, Batch number: 44, Loss: 2503.741455078125\n",
      "Epoch: 8, Batch number: 68, Loss: 2441.9228515625\n",
      "Epoch: 10, Batch number: 16, Loss: 2308.5205078125\n",
      "Epoch: 11, Batch number: 40, Loss: 2113.218017578125\n",
      "Epoch: 12, Batch number: 64, Loss: 2069.8046875\n",
      "Epoch: 14, Batch number: 12, Loss: 1918.765625\n",
      "Epoch: 15, Batch number: 36, Loss: 1827.3984375\n",
      "Epoch: 16, Batch number: 60, Loss: 1773.4925537109375\n",
      "Epoch: 18, Batch number: 8, Loss: 1760.4517822265625\n",
      "Epoch: 19, Batch number: 32, Loss: 1554.372314453125\n",
      "Epoch: 20, Batch number: 56, Loss: 1545.80908203125\n",
      "Epoch: 22, Batch number: 4, Loss: 1415.2393798828125\n",
      "Epoch: 23, Batch number: 28, Loss: 1294.5723876953125\n",
      "Epoch: 24, Batch number: 52, Loss: 1302.566162109375\n",
      "Epoch: 26, Batch number: 0, Loss: 1172.9959716796875\n",
      "Epoch: 27, Batch number: 24, Loss: 1177.941162109375\n",
      "Epoch: 28, Batch number: 48, Loss: 1086.1131591796875\n",
      "Epoch: 29, Batch number: 72, Loss: 1055.824951171875\n",
      "Epoch: 31, Batch number: 20, Loss: 1049.479736328125\n",
      "Epoch: 32, Batch number: 44, Loss: 963.07958984375\n",
      "Epoch: 33, Batch number: 68, Loss: 946.2869873046875\n",
      "Epoch: 35, Batch number: 16, Loss: 902.0927734375\n",
      "Epoch: 36, Batch number: 40, Loss: 877.3857421875\n",
      "Epoch: 37, Batch number: 64, Loss: 781.7012939453125\n",
      "Epoch: 39, Batch number: 12, Loss: 769.2395629882812\n",
      "Epoch: 40, Batch number: 36, Loss: 698.4989624023438\n",
      "Epoch: 41, Batch number: 60, Loss: 722.9913940429688\n",
      "Epoch: 43, Batch number: 8, Loss: 726.9137573242188\n",
      "Epoch: 44, Batch number: 32, Loss: 685.861328125\n",
      "Epoch: 45, Batch number: 56, Loss: 585.0139770507812\n",
      "Epoch: 47, Batch number: 4, Loss: 535.2371215820312\n",
      "Epoch: 48, Batch number: 28, Loss: 579.4595336914062\n",
      "Epoch: 49, Batch number: 52, Loss: 528.7238159179688\n",
      "Epoch: 51, Batch number: 0, Loss: 519.3261108398438\n",
      "Epoch: 52, Batch number: 24, Loss: 518.8076171875\n",
      "Epoch: 53, Batch number: 48, Loss: 438.252685546875\n",
      "Epoch: 54, Batch number: 72, Loss: 422.13653564453125\n",
      "Epoch: 56, Batch number: 20, Loss: 418.26824951171875\n",
      "Epoch: 57, Batch number: 44, Loss: 408.0022888183594\n",
      "Epoch: 58, Batch number: 68, Loss: 392.34051513671875\n",
      "Epoch: 60, Batch number: 16, Loss: 393.0405578613281\n",
      "Epoch: 61, Batch number: 40, Loss: 391.5245666503906\n",
      "Epoch: 62, Batch number: 64, Loss: 341.60760498046875\n",
      "Epoch: 64, Batch number: 12, Loss: 280.10955810546875\n",
      "Epoch: 65, Batch number: 36, Loss: 322.4487609863281\n",
      "Epoch: 66, Batch number: 60, Loss: 296.50714111328125\n",
      "Epoch: 68, Batch number: 8, Loss: 291.10992431640625\n",
      "Epoch: 69, Batch number: 32, Loss: 262.9825439453125\n",
      "Epoch: 70, Batch number: 56, Loss: 247.606689453125\n",
      "Epoch: 72, Batch number: 4, Loss: 251.60519409179688\n",
      "Epoch: 73, Batch number: 28, Loss: 254.24462890625\n",
      "Epoch: 74, Batch number: 52, Loss: 208.07089233398438\n",
      "Epoch: 76, Batch number: 0, Loss: 206.1813507080078\n",
      "Epoch: 77, Batch number: 24, Loss: 213.3712921142578\n",
      "Epoch: 78, Batch number: 48, Loss: 211.57974243164062\n",
      "Epoch: 79, Batch number: 72, Loss: 218.10568237304688\n",
      "Epoch: 81, Batch number: 20, Loss: 175.36720275878906\n",
      "Epoch: 82, Batch number: 44, Loss: 178.23690795898438\n",
      "Epoch: 83, Batch number: 68, Loss: 203.95094299316406\n",
      "Epoch: 85, Batch number: 16, Loss: 162.3978729248047\n",
      "Epoch: 86, Batch number: 40, Loss: 145.19195556640625\n",
      "Epoch: 87, Batch number: 64, Loss: 135.9136199951172\n",
      "Epoch: 89, Batch number: 12, Loss: 135.92166137695312\n",
      "Epoch: 90, Batch number: 36, Loss: 117.0175552368164\n",
      "Epoch: 91, Batch number: 60, Loss: 136.67916870117188\n",
      "Epoch: 93, Batch number: 8, Loss: 108.3792724609375\n",
      "Epoch: 94, Batch number: 32, Loss: 127.78044891357422\n",
      "Epoch: 95, Batch number: 56, Loss: 102.63353729248047\n",
      "Epoch: 97, Batch number: 4, Loss: 100.46720886230469\n",
      "Epoch: 98, Batch number: 28, Loss: 96.39633178710938\n",
      "Epoch: 99, Batch number: 52, Loss: 116.7263412475586\n",
      "Epoch: 101, Batch number: 0, Loss: 90.95565032958984\n",
      "Epoch: 102, Batch number: 24, Loss: 86.23867797851562\n",
      "Epoch: 103, Batch number: 48, Loss: 81.41979217529297\n",
      "Epoch: 104, Batch number: 72, Loss: 98.3602523803711\n",
      "Epoch: 106, Batch number: 20, Loss: 86.06652069091797\n",
      "Epoch: 107, Batch number: 44, Loss: 72.68292999267578\n",
      "Epoch: 108, Batch number: 68, Loss: 72.33807373046875\n",
      "Epoch: 110, Batch number: 16, Loss: 72.07514953613281\n",
      "Epoch: 111, Batch number: 40, Loss: 72.87248992919922\n",
      "Epoch: 112, Batch number: 64, Loss: 65.7341079711914\n",
      "Epoch: 114, Batch number: 12, Loss: 52.79054641723633\n",
      "Epoch: 115, Batch number: 36, Loss: 57.49824523925781\n",
      "Epoch: 116, Batch number: 60, Loss: 60.68263244628906\n",
      "Epoch: 118, Batch number: 8, Loss: 51.73072814941406\n",
      "Epoch: 119, Batch number: 32, Loss: 59.90388488769531\n",
      "Epoch: 120, Batch number: 56, Loss: 44.44465637207031\n",
      "Epoch: 122, Batch number: 4, Loss: 44.75379943847656\n",
      "Epoch: 123, Batch number: 28, Loss: 49.94750213623047\n",
      "Epoch: 124, Batch number: 52, Loss: 53.38479995727539\n",
      "Epoch: 126, Batch number: 0, Loss: 41.58638000488281\n",
      "Epoch: 127, Batch number: 24, Loss: 41.00133514404297\n",
      "Epoch: 128, Batch number: 48, Loss: 54.00547790527344\n",
      "Epoch: 129, Batch number: 72, Loss: 41.145301818847656\n",
      "Epoch: 131, Batch number: 20, Loss: 37.46474075317383\n",
      "Epoch: 132, Batch number: 44, Loss: 33.767852783203125\n",
      "Epoch: 133, Batch number: 68, Loss: 34.642250061035156\n",
      "Epoch: 135, Batch number: 16, Loss: 36.379188537597656\n",
      "Epoch: 136, Batch number: 40, Loss: 27.360576629638672\n",
      "Epoch: 137, Batch number: 64, Loss: 32.05931091308594\n",
      "Epoch: 139, Batch number: 12, Loss: 23.517871856689453\n",
      "Epoch: 140, Batch number: 36, Loss: 29.970935821533203\n",
      "Epoch: 141, Batch number: 60, Loss: 29.47347640991211\n",
      "Epoch: 143, Batch number: 8, Loss: 27.568660736083984\n",
      "Epoch: 144, Batch number: 32, Loss: 26.02260971069336\n",
      "Epoch: 145, Batch number: 56, Loss: 26.539772033691406\n",
      "Epoch: 147, Batch number: 4, Loss: 28.08448028564453\n",
      "Epoch: 148, Batch number: 28, Loss: 27.936643600463867\n",
      "Epoch: 149, Batch number: 52, Loss: 29.64442253112793\n",
      "Epoch: 151, Batch number: 0, Loss: 22.66267204284668\n",
      "Epoch: 152, Batch number: 24, Loss: 20.814889907836914\n",
      "Epoch: 153, Batch number: 48, Loss: 19.368358612060547\n",
      "Epoch: 154, Batch number: 72, Loss: 22.49758529663086\n",
      "Epoch: 156, Batch number: 20, Loss: 19.785701751708984\n",
      "Epoch: 157, Batch number: 44, Loss: 23.506092071533203\n",
      "Epoch: 158, Batch number: 68, Loss: 19.53870964050293\n",
      "Epoch: 160, Batch number: 16, Loss: 17.463315963745117\n",
      "Epoch: 161, Batch number: 40, Loss: 12.762982368469238\n",
      "Epoch: 162, Batch number: 64, Loss: 12.750448226928711\n",
      "Epoch: 164, Batch number: 12, Loss: 14.711831092834473\n",
      "Epoch: 165, Batch number: 36, Loss: 15.031699180603027\n",
      "Epoch: 166, Batch number: 60, Loss: 17.751331329345703\n",
      "Epoch: 168, Batch number: 8, Loss: 16.898969650268555\n",
      "Epoch: 169, Batch number: 32, Loss: 17.973114013671875\n",
      "Epoch: 170, Batch number: 56, Loss: 20.12740707397461\n",
      "Epoch: 172, Batch number: 4, Loss: 14.594457626342773\n",
      "Epoch: 173, Batch number: 28, Loss: 12.138688087463379\n",
      "Epoch: 174, Batch number: 52, Loss: 11.070233345031738\n",
      "Epoch: 176, Batch number: 0, Loss: 9.820828437805176\n",
      "Epoch: 177, Batch number: 24, Loss: 11.182591438293457\n",
      "Epoch: 178, Batch number: 48, Loss: 12.408499717712402\n",
      "Epoch: 179, Batch number: 72, Loss: 11.420376777648926\n",
      "Epoch: 181, Batch number: 20, Loss: 16.39667510986328\n",
      "Epoch: 182, Batch number: 44, Loss: 10.08959674835205\n",
      "Epoch: 183, Batch number: 68, Loss: 15.287935256958008\n",
      "Epoch: 185, Batch number: 16, Loss: 10.099422454833984\n",
      "Epoch: 186, Batch number: 40, Loss: 11.906783103942871\n",
      "Epoch: 187, Batch number: 64, Loss: 11.249292373657227\n",
      "Epoch: 189, Batch number: 12, Loss: 10.126137733459473\n",
      "Epoch: 190, Batch number: 36, Loss: 10.560622215270996\n",
      "Epoch: 191, Batch number: 60, Loss: 11.191511154174805\n",
      "Epoch: 193, Batch number: 8, Loss: 10.744745254516602\n",
      "Epoch: 194, Batch number: 32, Loss: 9.81263256072998\n",
      "Epoch: 195, Batch number: 56, Loss: 9.723716735839844\n",
      "Epoch: 197, Batch number: 4, Loss: 10.292906761169434\n",
      "Epoch: 198, Batch number: 28, Loss: 5.8976850509643555\n",
      "Epoch: 199, Batch number: 52, Loss: 7.35568904876709\n",
      "Epoch: 201, Batch number: 0, Loss: 6.228336334228516\n",
      "Epoch: 202, Batch number: 24, Loss: 6.175484657287598\n",
      "Epoch: 203, Batch number: 48, Loss: 11.477821350097656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204, Batch number: 72, Loss: 7.060848236083984\n",
      "Epoch: 206, Batch number: 20, Loss: 5.742708206176758\n",
      "Epoch: 207, Batch number: 44, Loss: 6.474853515625\n",
      "Epoch: 208, Batch number: 68, Loss: 7.613517761230469\n",
      "Epoch: 210, Batch number: 16, Loss: 7.334769248962402\n",
      "Epoch: 211, Batch number: 40, Loss: 5.50883674621582\n",
      "Epoch: 212, Batch number: 64, Loss: 5.581432342529297\n",
      "Epoch: 214, Batch number: 12, Loss: 7.698513031005859\n",
      "Epoch: 215, Batch number: 36, Loss: 6.095161437988281\n",
      "Epoch: 216, Batch number: 60, Loss: 5.54305362701416\n",
      "Epoch: 218, Batch number: 8, Loss: 7.27880859375\n",
      "Epoch: 219, Batch number: 32, Loss: 5.515908241271973\n",
      "Epoch: 220, Batch number: 56, Loss: 8.178969383239746\n",
      "Epoch: 222, Batch number: 4, Loss: 8.311806678771973\n",
      "Epoch: 223, Batch number: 28, Loss: 6.96873664855957\n",
      "Epoch: 224, Batch number: 52, Loss: 7.631158828735352\n",
      "Epoch: 226, Batch number: 0, Loss: 5.496280670166016\n",
      "Epoch: 227, Batch number: 24, Loss: 5.109504699707031\n",
      "Epoch: 228, Batch number: 48, Loss: 8.947328567504883\n",
      "Epoch: 229, Batch number: 72, Loss: 5.435534477233887\n",
      "Epoch: 231, Batch number: 20, Loss: 4.117117881774902\n",
      "Epoch: 232, Batch number: 44, Loss: 2.9251976013183594\n",
      "Epoch: 233, Batch number: 68, Loss: 3.5104331970214844\n",
      "Epoch: 235, Batch number: 16, Loss: 4.216569900512695\n",
      "Epoch: 236, Batch number: 40, Loss: 4.072190284729004\n",
      "Epoch: 237, Batch number: 64, Loss: 3.6007204055786133\n",
      "Epoch: 239, Batch number: 12, Loss: 8.204753875732422\n",
      "Epoch: 240, Batch number: 36, Loss: 5.281498908996582\n",
      "Epoch: 241, Batch number: 60, Loss: 2.5925064086914062\n",
      "Epoch: 243, Batch number: 8, Loss: 5.173398017883301\n",
      "Epoch: 244, Batch number: 32, Loss: 3.2771215438842773\n",
      "Epoch: 245, Batch number: 56, Loss: 5.396554946899414\n",
      "Epoch: 247, Batch number: 4, Loss: 2.910799026489258\n",
      "Epoch: 248, Batch number: 28, Loss: 9.104578018188477\n",
      "Epoch: 249, Batch number: 52, Loss: 4.362112998962402\n",
      "Epoch: 251, Batch number: 0, Loss: 3.3905344009399414\n",
      "Epoch: 252, Batch number: 24, Loss: 4.189112663269043\n",
      "Epoch: 253, Batch number: 48, Loss: 3.220335006713867\n",
      "Epoch: 254, Batch number: 72, Loss: 4.466893196105957\n",
      "Epoch: 256, Batch number: 20, Loss: 4.851548194885254\n",
      "Epoch: 257, Batch number: 44, Loss: 3.8521060943603516\n",
      "Epoch: 258, Batch number: 68, Loss: 4.439349174499512\n",
      "Epoch: 260, Batch number: 16, Loss: 4.124117851257324\n",
      "Epoch: 261, Batch number: 40, Loss: 3.3583288192749023\n",
      "Epoch: 262, Batch number: 64, Loss: 2.11474609375\n",
      "Epoch: 264, Batch number: 12, Loss: 2.4740657806396484\n",
      "Epoch: 265, Batch number: 36, Loss: 2.69193172454834\n",
      "Epoch: 266, Batch number: 60, Loss: 3.634103775024414\n",
      "Epoch: 268, Batch number: 8, Loss: 4.141916275024414\n",
      "Epoch: 269, Batch number: 32, Loss: 1.527033805847168\n",
      "Epoch: 270, Batch number: 56, Loss: 2.523632049560547\n",
      "Epoch: 272, Batch number: 4, Loss: 2.790837287902832\n",
      "Epoch: 273, Batch number: 28, Loss: 1.7286548614501953\n",
      "Epoch: 274, Batch number: 52, Loss: 10.327731132507324\n",
      "Epoch: 276, Batch number: 0, Loss: 2.015645980834961\n",
      "Epoch: 277, Batch number: 24, Loss: 2.5053672790527344\n",
      "Epoch: 278, Batch number: 48, Loss: 3.5205564498901367\n",
      "Epoch: 279, Batch number: 72, Loss: 1.5131864547729492\n",
      "Epoch: 281, Batch number: 20, Loss: 3.503575325012207\n",
      "Epoch: 282, Batch number: 44, Loss: 1.6839618682861328\n",
      "Epoch: 283, Batch number: 68, Loss: 3.50213623046875\n",
      "Epoch: 285, Batch number: 16, Loss: 2.897494316101074\n",
      "Epoch: 286, Batch number: 40, Loss: 4.434880256652832\n",
      "Epoch: 287, Batch number: 64, Loss: 1.9752283096313477\n",
      "Epoch: 289, Batch number: 12, Loss: 3.5152807235717773\n",
      "Epoch: 290, Batch number: 36, Loss: 3.5082550048828125\n",
      "Epoch: 291, Batch number: 60, Loss: 2.3480567932128906\n",
      "Epoch: 293, Batch number: 8, Loss: 2.324690818786621\n",
      "Epoch: 294, Batch number: 32, Loss: 2.3972110748291016\n",
      "Epoch: 295, Batch number: 56, Loss: 6.379117965698242\n",
      "Epoch: 297, Batch number: 4, Loss: 2.8299484252929688\n",
      "Epoch: 298, Batch number: 28, Loss: 2.2722396850585938\n",
      "Epoch: 299, Batch number: 52, Loss: 3.4441146850585938\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4406.73388671875\n",
      "Epoch: 2, Batch number: 24, Loss: 3724.09130859375\n",
      "Epoch: 3, Batch number: 48, Loss: 3059.971923828125\n",
      "Epoch: 4, Batch number: 72, Loss: 2843.53857421875\n",
      "Epoch: 6, Batch number: 20, Loss: 2447.140625\n",
      "Epoch: 7, Batch number: 44, Loss: 2345.43408203125\n",
      "Epoch: 8, Batch number: 68, Loss: 2147.55078125\n",
      "Epoch: 10, Batch number: 16, Loss: 1997.08544921875\n",
      "Epoch: 11, Batch number: 40, Loss: 1975.69091796875\n",
      "Epoch: 12, Batch number: 64, Loss: 1824.7471923828125\n",
      "Epoch: 14, Batch number: 12, Loss: 1642.0693359375\n",
      "Epoch: 15, Batch number: 36, Loss: 1499.0831298828125\n",
      "Epoch: 16, Batch number: 60, Loss: 1450.86181640625\n",
      "Epoch: 18, Batch number: 8, Loss: 1334.9197998046875\n",
      "Epoch: 19, Batch number: 32, Loss: 1333.0594482421875\n",
      "Epoch: 20, Batch number: 56, Loss: 1183.770263671875\n",
      "Epoch: 22, Batch number: 4, Loss: 1168.3095703125\n",
      "Epoch: 23, Batch number: 28, Loss: 1038.0543212890625\n",
      "Epoch: 24, Batch number: 52, Loss: 1054.0040283203125\n",
      "Epoch: 26, Batch number: 0, Loss: 940.4633178710938\n",
      "Epoch: 27, Batch number: 24, Loss: 928.4234619140625\n",
      "Epoch: 28, Batch number: 48, Loss: 863.5333251953125\n",
      "Epoch: 29, Batch number: 72, Loss: 797.18017578125\n",
      "Epoch: 31, Batch number: 20, Loss: 763.9730834960938\n",
      "Epoch: 32, Batch number: 44, Loss: 732.9908447265625\n",
      "Epoch: 33, Batch number: 68, Loss: 756.6776733398438\n",
      "Epoch: 35, Batch number: 16, Loss: 678.1285400390625\n",
      "Epoch: 36, Batch number: 40, Loss: 653.2939453125\n",
      "Epoch: 37, Batch number: 64, Loss: 625.4691772460938\n",
      "Epoch: 39, Batch number: 12, Loss: 611.7777709960938\n",
      "Epoch: 40, Batch number: 36, Loss: 578.361328125\n",
      "Epoch: 41, Batch number: 60, Loss: 519.7864379882812\n",
      "Epoch: 43, Batch number: 8, Loss: 496.3854064941406\n",
      "Epoch: 44, Batch number: 32, Loss: 466.6671447753906\n",
      "Epoch: 45, Batch number: 56, Loss: 377.73809814453125\n",
      "Epoch: 47, Batch number: 4, Loss: 420.553466796875\n",
      "Epoch: 48, Batch number: 28, Loss: 418.067626953125\n",
      "Epoch: 49, Batch number: 52, Loss: 385.1523742675781\n",
      "Epoch: 51, Batch number: 0, Loss: 303.4017333984375\n",
      "Epoch: 52, Batch number: 24, Loss: 309.69036865234375\n",
      "Epoch: 53, Batch number: 48, Loss: 325.4195556640625\n",
      "Epoch: 54, Batch number: 72, Loss: 333.072021484375\n",
      "Epoch: 56, Batch number: 20, Loss: 306.6558837890625\n",
      "Epoch: 57, Batch number: 44, Loss: 269.4803466796875\n",
      "Epoch: 58, Batch number: 68, Loss: 239.43826293945312\n",
      "Epoch: 60, Batch number: 16, Loss: 260.9243469238281\n",
      "Epoch: 61, Batch number: 40, Loss: 223.42440795898438\n",
      "Epoch: 62, Batch number: 64, Loss: 223.8394775390625\n",
      "Epoch: 64, Batch number: 12, Loss: 204.17987060546875\n",
      "Epoch: 65, Batch number: 36, Loss: 214.84780883789062\n",
      "Epoch: 66, Batch number: 60, Loss: 182.3428192138672\n",
      "Epoch: 68, Batch number: 8, Loss: 173.6964111328125\n",
      "Epoch: 69, Batch number: 32, Loss: 174.50933837890625\n",
      "Epoch: 70, Batch number: 56, Loss: 177.96786499023438\n",
      "Epoch: 72, Batch number: 4, Loss: 140.38351440429688\n",
      "Epoch: 73, Batch number: 28, Loss: 137.00729370117188\n",
      "Epoch: 74, Batch number: 52, Loss: 146.384033203125\n",
      "Epoch: 76, Batch number: 0, Loss: 122.70884704589844\n",
      "Epoch: 77, Batch number: 24, Loss: 111.63126373291016\n",
      "Epoch: 78, Batch number: 48, Loss: 115.07763671875\n",
      "Epoch: 79, Batch number: 72, Loss: 100.9871826171875\n",
      "Epoch: 81, Batch number: 20, Loss: 100.504638671875\n",
      "Epoch: 82, Batch number: 44, Loss: 91.09491729736328\n",
      "Epoch: 83, Batch number: 68, Loss: 90.22400665283203\n",
      "Epoch: 85, Batch number: 16, Loss: 102.10742950439453\n",
      "Epoch: 86, Batch number: 40, Loss: 89.08250427246094\n",
      "Epoch: 87, Batch number: 64, Loss: 79.44241333007812\n",
      "Epoch: 89, Batch number: 12, Loss: 63.10784149169922\n",
      "Epoch: 90, Batch number: 36, Loss: 84.71210479736328\n",
      "Epoch: 91, Batch number: 60, Loss: 72.08930206298828\n",
      "Epoch: 93, Batch number: 8, Loss: 65.57579040527344\n",
      "Epoch: 94, Batch number: 32, Loss: 60.80016326904297\n",
      "Epoch: 95, Batch number: 56, Loss: 67.09587860107422\n",
      "Epoch: 97, Batch number: 4, Loss: 71.31243896484375\n",
      "Epoch: 98, Batch number: 28, Loss: 59.111366271972656\n",
      "Epoch: 99, Batch number: 52, Loss: 53.503726959228516\n",
      "Epoch: 101, Batch number: 0, Loss: 49.017704010009766\n",
      "Epoch: 102, Batch number: 24, Loss: 49.837711334228516\n",
      "Epoch: 103, Batch number: 48, Loss: 51.6612663269043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104, Batch number: 72, Loss: 48.335243225097656\n",
      "Epoch: 106, Batch number: 20, Loss: 53.68397903442383\n",
      "Epoch: 107, Batch number: 44, Loss: 39.10881805419922\n",
      "Epoch: 108, Batch number: 68, Loss: 39.77998733520508\n",
      "Epoch: 110, Batch number: 16, Loss: 39.26304244995117\n",
      "Epoch: 111, Batch number: 40, Loss: 36.99287414550781\n",
      "Epoch: 112, Batch number: 64, Loss: 37.47081756591797\n",
      "Epoch: 114, Batch number: 12, Loss: 36.676048278808594\n",
      "Epoch: 115, Batch number: 36, Loss: 32.56069564819336\n",
      "Epoch: 116, Batch number: 60, Loss: 31.652446746826172\n",
      "Epoch: 118, Batch number: 8, Loss: 25.374691009521484\n",
      "Epoch: 119, Batch number: 32, Loss: 33.95105743408203\n",
      "Epoch: 120, Batch number: 56, Loss: 39.56808090209961\n",
      "Epoch: 122, Batch number: 4, Loss: 30.26001739501953\n",
      "Epoch: 123, Batch number: 28, Loss: 27.001943588256836\n",
      "Epoch: 124, Batch number: 52, Loss: 25.120643615722656\n",
      "Epoch: 126, Batch number: 0, Loss: 22.735111236572266\n",
      "Epoch: 127, Batch number: 24, Loss: 19.0353946685791\n",
      "Epoch: 128, Batch number: 48, Loss: 25.082780838012695\n",
      "Epoch: 129, Batch number: 72, Loss: 21.356775283813477\n",
      "Epoch: 131, Batch number: 20, Loss: 26.36060333251953\n",
      "Epoch: 132, Batch number: 44, Loss: 21.756532669067383\n",
      "Epoch: 133, Batch number: 68, Loss: 18.69706916809082\n",
      "Epoch: 135, Batch number: 16, Loss: 18.937782287597656\n",
      "Epoch: 136, Batch number: 40, Loss: 19.26568603515625\n",
      "Epoch: 137, Batch number: 64, Loss: 17.698833465576172\n",
      "Epoch: 139, Batch number: 12, Loss: 14.121569633483887\n",
      "Epoch: 140, Batch number: 36, Loss: 21.642906188964844\n",
      "Epoch: 141, Batch number: 60, Loss: 16.477230072021484\n",
      "Epoch: 143, Batch number: 8, Loss: 17.634647369384766\n",
      "Epoch: 144, Batch number: 32, Loss: 19.16497039794922\n",
      "Epoch: 145, Batch number: 56, Loss: 22.61474609375\n",
      "Epoch: 147, Batch number: 4, Loss: 14.102989196777344\n",
      "Epoch: 148, Batch number: 28, Loss: 14.375015258789062\n",
      "Epoch: 149, Batch number: 52, Loss: 18.55400848388672\n",
      "Epoch: 151, Batch number: 0, Loss: 15.407490730285645\n",
      "Epoch: 152, Batch number: 24, Loss: 15.092662811279297\n",
      "Epoch: 153, Batch number: 48, Loss: 13.918974876403809\n",
      "Epoch: 154, Batch number: 72, Loss: 9.401702880859375\n",
      "Epoch: 156, Batch number: 20, Loss: 15.129855155944824\n",
      "Epoch: 157, Batch number: 44, Loss: 9.967214584350586\n",
      "Epoch: 158, Batch number: 68, Loss: 15.999728202819824\n",
      "Epoch: 160, Batch number: 16, Loss: 11.929874420166016\n",
      "Epoch: 161, Batch number: 40, Loss: 10.682413101196289\n",
      "Epoch: 162, Batch number: 64, Loss: 12.251641273498535\n",
      "Epoch: 164, Batch number: 12, Loss: 7.8778581619262695\n",
      "Epoch: 165, Batch number: 36, Loss: 12.237322807312012\n",
      "Epoch: 166, Batch number: 60, Loss: 12.75562572479248\n",
      "Epoch: 168, Batch number: 8, Loss: 12.111390113830566\n",
      "Epoch: 169, Batch number: 32, Loss: 9.339265823364258\n",
      "Epoch: 170, Batch number: 56, Loss: 9.272205352783203\n",
      "Epoch: 172, Batch number: 4, Loss: 5.817659378051758\n",
      "Epoch: 173, Batch number: 28, Loss: 7.509799957275391\n",
      "Epoch: 174, Batch number: 52, Loss: 7.730218887329102\n",
      "Epoch: 176, Batch number: 0, Loss: 5.564749717712402\n",
      "Epoch: 177, Batch number: 24, Loss: 7.456665992736816\n",
      "Epoch: 178, Batch number: 48, Loss: 8.589797973632812\n",
      "Epoch: 179, Batch number: 72, Loss: 7.302013397216797\n",
      "Epoch: 181, Batch number: 20, Loss: 5.61870002746582\n",
      "Epoch: 182, Batch number: 44, Loss: 4.573430061340332\n",
      "Epoch: 183, Batch number: 68, Loss: 5.99492073059082\n",
      "Epoch: 185, Batch number: 16, Loss: 4.96498966217041\n",
      "Epoch: 186, Batch number: 40, Loss: 9.700821876525879\n",
      "Epoch: 187, Batch number: 64, Loss: 6.321902275085449\n",
      "Epoch: 189, Batch number: 12, Loss: 7.289724349975586\n",
      "Epoch: 190, Batch number: 36, Loss: 8.276713371276855\n",
      "Epoch: 191, Batch number: 60, Loss: 4.737662315368652\n",
      "Epoch: 193, Batch number: 8, Loss: 4.801239013671875\n",
      "Epoch: 194, Batch number: 32, Loss: 10.14463996887207\n",
      "Epoch: 195, Batch number: 56, Loss: 5.6297454833984375\n",
      "Epoch: 197, Batch number: 4, Loss: 8.678459167480469\n",
      "Epoch: 198, Batch number: 28, Loss: 4.881302833557129\n",
      "Epoch: 199, Batch number: 52, Loss: 5.7015485763549805\n",
      "Epoch: 201, Batch number: 0, Loss: 3.5835647583007812\n",
      "Epoch: 202, Batch number: 24, Loss: 4.582424163818359\n",
      "Epoch: 203, Batch number: 48, Loss: 5.790885925292969\n",
      "Epoch: 204, Batch number: 72, Loss: 8.523950576782227\n",
      "Epoch: 206, Batch number: 20, Loss: 5.541532516479492\n",
      "Epoch: 207, Batch number: 44, Loss: 5.603193283081055\n",
      "Epoch: 208, Batch number: 68, Loss: 7.554587364196777\n",
      "Epoch: 210, Batch number: 16, Loss: 5.665335655212402\n",
      "Epoch: 211, Batch number: 40, Loss: 4.259230613708496\n",
      "Epoch: 212, Batch number: 64, Loss: 4.5923004150390625\n",
      "Epoch: 214, Batch number: 12, Loss: 5.74800968170166\n",
      "Epoch: 215, Batch number: 36, Loss: 7.8119707107543945\n",
      "Epoch: 216, Batch number: 60, Loss: 3.9294300079345703\n",
      "Epoch: 218, Batch number: 8, Loss: 2.1286582946777344\n",
      "Epoch: 219, Batch number: 32, Loss: 4.1904401779174805\n",
      "Epoch: 220, Batch number: 56, Loss: 2.7703256607055664\n",
      "Epoch: 222, Batch number: 4, Loss: 2.9951066970825195\n",
      "Epoch: 223, Batch number: 28, Loss: 4.147040367126465\n",
      "Epoch: 224, Batch number: 52, Loss: 3.6559524536132812\n",
      "Epoch: 226, Batch number: 0, Loss: 4.560694694519043\n",
      "Epoch: 227, Batch number: 24, Loss: 2.0532751083374023\n",
      "Epoch: 228, Batch number: 48, Loss: 3.127835273742676\n",
      "Epoch: 229, Batch number: 72, Loss: 5.453762054443359\n",
      "Epoch: 231, Batch number: 20, Loss: 2.3740978240966797\n",
      "Epoch: 232, Batch number: 44, Loss: 3.787454605102539\n",
      "Epoch: 233, Batch number: 68, Loss: 2.041855812072754\n",
      "Epoch: 235, Batch number: 16, Loss: 3.0257606506347656\n",
      "Epoch: 236, Batch number: 40, Loss: 1.7087640762329102\n",
      "Epoch: 237, Batch number: 64, Loss: 2.2676496505737305\n",
      "Epoch: 239, Batch number: 12, Loss: 3.1813106536865234\n",
      "Epoch: 240, Batch number: 36, Loss: 6.202610969543457\n",
      "Epoch: 241, Batch number: 60, Loss: 7.556488990783691\n",
      "Epoch: 243, Batch number: 8, Loss: 2.4378042221069336\n",
      "Epoch: 244, Batch number: 32, Loss: 5.175671577453613\n",
      "Epoch: 245, Batch number: 56, Loss: 6.999139785766602\n",
      "Epoch: 247, Batch number: 4, Loss: 2.360276222229004\n",
      "Epoch: 248, Batch number: 28, Loss: 4.474747657775879\n",
      "Epoch: 249, Batch number: 52, Loss: 4.128549575805664\n",
      "Epoch: 251, Batch number: 0, Loss: 1.4477930068969727\n",
      "Epoch: 252, Batch number: 24, Loss: 1.8910675048828125\n",
      "Epoch: 253, Batch number: 48, Loss: 2.9094743728637695\n",
      "Epoch: 254, Batch number: 72, Loss: 5.5611419677734375\n",
      "Epoch: 256, Batch number: 20, Loss: 3.2446775436401367\n",
      "Epoch: 257, Batch number: 44, Loss: 1.986196517944336\n",
      "Epoch: 258, Batch number: 68, Loss: 2.435596466064453\n",
      "Epoch: 260, Batch number: 16, Loss: 3.091623306274414\n",
      "Epoch: 261, Batch number: 40, Loss: 2.86185359954834\n",
      "Epoch: 262, Batch number: 64, Loss: 4.618391036987305\n",
      "Epoch: 264, Batch number: 12, Loss: 2.625692367553711\n",
      "Epoch: 265, Batch number: 36, Loss: 4.179408073425293\n",
      "Epoch: 266, Batch number: 60, Loss: 1.0949249267578125\n",
      "Epoch: 268, Batch number: 8, Loss: 4.249131202697754\n",
      "Epoch: 269, Batch number: 32, Loss: 1.2717304229736328\n",
      "Epoch: 270, Batch number: 56, Loss: 7.732771873474121\n",
      "Epoch: 272, Batch number: 4, Loss: 2.6785688400268555\n",
      "Epoch: 273, Batch number: 28, Loss: 2.7773962020874023\n",
      "Epoch: 274, Batch number: 52, Loss: 7.128776550292969\n",
      "Epoch: 276, Batch number: 0, Loss: 3.7328014373779297\n",
      "Epoch: 277, Batch number: 24, Loss: 2.8820953369140625\n",
      "Epoch: 278, Batch number: 48, Loss: 2.7927370071411133\n",
      "Epoch: 279, Batch number: 72, Loss: 2.603830337524414\n",
      "Epoch: 281, Batch number: 20, Loss: 3.196126937866211\n",
      "Epoch: 282, Batch number: 44, Loss: 2.7398300170898438\n",
      "Epoch: 283, Batch number: 68, Loss: 2.173598289489746\n",
      "Epoch: 285, Batch number: 16, Loss: 3.979180335998535\n",
      "Epoch: 286, Batch number: 40, Loss: 2.9723196029663086\n",
      "Epoch: 287, Batch number: 64, Loss: 2.613615036010742\n",
      "Epoch: 289, Batch number: 12, Loss: 1.087911605834961\n",
      "Epoch: 290, Batch number: 36, Loss: 1.0796127319335938\n",
      "Epoch: 291, Batch number: 60, Loss: 2.5947532653808594\n",
      "Epoch: 293, Batch number: 8, Loss: 1.7246322631835938\n",
      "Epoch: 294, Batch number: 32, Loss: 2.012383460998535\n",
      "Epoch: 295, Batch number: 56, Loss: 0.9291706085205078\n",
      "Epoch: 297, Batch number: 4, Loss: 1.936539649963379\n",
      "Epoch: 298, Batch number: 28, Loss: 3.1881017684936523\n",
      "Epoch: 299, Batch number: 52, Loss: 2.141956329345703\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4399.05078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 24, Loss: 4292.34716796875\n",
      "Epoch: 3, Batch number: 48, Loss: 4130.58203125\n",
      "Epoch: 4, Batch number: 72, Loss: 3813.348388671875\n",
      "Epoch: 6, Batch number: 20, Loss: 3385.738525390625\n",
      "Epoch: 7, Batch number: 44, Loss: 3153.12548828125\n",
      "Epoch: 8, Batch number: 68, Loss: 3094.604736328125\n",
      "Epoch: 10, Batch number: 16, Loss: 3107.564697265625\n",
      "Epoch: 11, Batch number: 40, Loss: 3031.95166015625\n",
      "Epoch: 12, Batch number: 64, Loss: 2929.361572265625\n",
      "Epoch: 14, Batch number: 12, Loss: 2923.22900390625\n",
      "Epoch: 15, Batch number: 36, Loss: 2913.81591796875\n",
      "Epoch: 16, Batch number: 60, Loss: 2896.521728515625\n",
      "Epoch: 18, Batch number: 8, Loss: 2891.450927734375\n",
      "Epoch: 19, Batch number: 32, Loss: 2703.866455078125\n",
      "Epoch: 20, Batch number: 56, Loss: 2692.526123046875\n",
      "Epoch: 22, Batch number: 4, Loss: 2676.0087890625\n",
      "Epoch: 23, Batch number: 28, Loss: 2728.661865234375\n",
      "Epoch: 24, Batch number: 52, Loss: 2645.810302734375\n",
      "Epoch: 26, Batch number: 0, Loss: 2601.163330078125\n",
      "Epoch: 27, Batch number: 24, Loss: 2632.447998046875\n",
      "Epoch: 28, Batch number: 48, Loss: 2553.7451171875\n",
      "Epoch: 29, Batch number: 72, Loss: 2486.408935546875\n",
      "Epoch: 31, Batch number: 20, Loss: 2477.785400390625\n",
      "Epoch: 32, Batch number: 44, Loss: 2369.15869140625\n",
      "Epoch: 33, Batch number: 68, Loss: 2465.447998046875\n",
      "Epoch: 35, Batch number: 16, Loss: 2467.3974609375\n",
      "Epoch: 36, Batch number: 40, Loss: 2388.529296875\n",
      "Epoch: 37, Batch number: 64, Loss: 2502.77783203125\n",
      "Epoch: 39, Batch number: 12, Loss: 2383.08251953125\n",
      "Epoch: 40, Batch number: 36, Loss: 2370.98681640625\n",
      "Epoch: 41, Batch number: 60, Loss: 2360.346435546875\n",
      "Epoch: 43, Batch number: 8, Loss: 2395.243896484375\n",
      "Epoch: 44, Batch number: 32, Loss: 2367.403076171875\n",
      "Epoch: 45, Batch number: 56, Loss: 2274.4814453125\n",
      "Epoch: 47, Batch number: 4, Loss: 2199.8564453125\n",
      "Epoch: 48, Batch number: 28, Loss: 2220.760498046875\n",
      "Epoch: 49, Batch number: 52, Loss: 2215.11767578125\n",
      "Epoch: 51, Batch number: 0, Loss: 2090.349365234375\n",
      "Epoch: 52, Batch number: 24, Loss: 2229.6572265625\n",
      "Epoch: 53, Batch number: 48, Loss: 2052.349853515625\n",
      "Epoch: 54, Batch number: 72, Loss: 2052.458984375\n",
      "Epoch: 56, Batch number: 20, Loss: 1898.4168701171875\n",
      "Epoch: 57, Batch number: 44, Loss: 2081.086669921875\n",
      "Epoch: 58, Batch number: 68, Loss: 2027.240234375\n",
      "Epoch: 60, Batch number: 16, Loss: 2000.6561279296875\n",
      "Epoch: 61, Batch number: 40, Loss: 1910.560546875\n",
      "Epoch: 62, Batch number: 64, Loss: 1989.636474609375\n",
      "Epoch: 64, Batch number: 12, Loss: 1913.1842041015625\n",
      "Epoch: 65, Batch number: 36, Loss: 1992.80810546875\n",
      "Epoch: 66, Batch number: 60, Loss: 1896.090087890625\n",
      "Epoch: 68, Batch number: 8, Loss: 1942.2320556640625\n",
      "Epoch: 69, Batch number: 32, Loss: 1861.2705078125\n",
      "Epoch: 70, Batch number: 56, Loss: 1759.7183837890625\n",
      "Epoch: 72, Batch number: 4, Loss: 1725.4786376953125\n",
      "Epoch: 73, Batch number: 28, Loss: 1857.889404296875\n",
      "Epoch: 74, Batch number: 52, Loss: 1718.9857177734375\n",
      "Epoch: 76, Batch number: 0, Loss: 1716.7012939453125\n",
      "Epoch: 77, Batch number: 24, Loss: 1774.47705078125\n",
      "Epoch: 78, Batch number: 48, Loss: 1768.0970458984375\n",
      "Epoch: 79, Batch number: 72, Loss: 1662.6375732421875\n",
      "Epoch: 81, Batch number: 20, Loss: 1639.835205078125\n",
      "Epoch: 82, Batch number: 44, Loss: 1621.8551025390625\n",
      "Epoch: 83, Batch number: 68, Loss: 1673.7880859375\n",
      "Epoch: 85, Batch number: 16, Loss: 1584.8157958984375\n",
      "Epoch: 86, Batch number: 40, Loss: 1626.0518798828125\n",
      "Epoch: 87, Batch number: 64, Loss: 1561.2623291015625\n",
      "Epoch: 89, Batch number: 12, Loss: 1587.011962890625\n",
      "Epoch: 90, Batch number: 36, Loss: 1563.190673828125\n",
      "Epoch: 91, Batch number: 60, Loss: 1468.947265625\n",
      "Epoch: 93, Batch number: 8, Loss: 1537.1826171875\n",
      "Epoch: 94, Batch number: 32, Loss: 1491.88916015625\n",
      "Epoch: 95, Batch number: 56, Loss: 1464.0992431640625\n",
      "Epoch: 97, Batch number: 4, Loss: 1435.4207763671875\n",
      "Epoch: 98, Batch number: 28, Loss: 1443.2158203125\n",
      "Epoch: 99, Batch number: 52, Loss: 1444.54931640625\n",
      "Epoch: 101, Batch number: 0, Loss: 1384.17333984375\n",
      "Epoch: 102, Batch number: 24, Loss: 1475.72900390625\n",
      "Epoch: 103, Batch number: 48, Loss: 1420.931396484375\n",
      "Epoch: 104, Batch number: 72, Loss: 1407.04736328125\n",
      "Epoch: 106, Batch number: 20, Loss: 1357.62353515625\n",
      "Epoch: 107, Batch number: 44, Loss: 1395.8070068359375\n",
      "Epoch: 108, Batch number: 68, Loss: 1358.878662109375\n",
      "Epoch: 110, Batch number: 16, Loss: 1307.6650390625\n",
      "Epoch: 111, Batch number: 40, Loss: 1310.2772216796875\n",
      "Epoch: 112, Batch number: 64, Loss: 1343.647705078125\n",
      "Epoch: 114, Batch number: 12, Loss: 1277.137939453125\n",
      "Epoch: 115, Batch number: 36, Loss: 1269.98095703125\n",
      "Epoch: 116, Batch number: 60, Loss: 1250.862060546875\n",
      "Epoch: 118, Batch number: 8, Loss: 1281.4853515625\n",
      "Epoch: 119, Batch number: 32, Loss: 1225.8399658203125\n",
      "Epoch: 120, Batch number: 56, Loss: 1229.838623046875\n",
      "Epoch: 122, Batch number: 4, Loss: 1214.9498291015625\n",
      "Epoch: 123, Batch number: 28, Loss: 1175.126220703125\n",
      "Epoch: 124, Batch number: 52, Loss: 1209.1846923828125\n",
      "Epoch: 126, Batch number: 0, Loss: 1182.7537841796875\n",
      "Epoch: 127, Batch number: 24, Loss: 1168.7052001953125\n",
      "Epoch: 128, Batch number: 48, Loss: 1143.6064453125\n",
      "Epoch: 129, Batch number: 72, Loss: 1093.0052490234375\n",
      "Epoch: 131, Batch number: 20, Loss: 1182.0877685546875\n",
      "Epoch: 132, Batch number: 44, Loss: 1129.38525390625\n",
      "Epoch: 133, Batch number: 68, Loss: 1236.212158203125\n",
      "Epoch: 135, Batch number: 16, Loss: 1071.2935791015625\n",
      "Epoch: 136, Batch number: 40, Loss: 1118.337646484375\n",
      "Epoch: 137, Batch number: 64, Loss: 1104.5831298828125\n",
      "Epoch: 139, Batch number: 12, Loss: 1009.648681640625\n",
      "Epoch: 140, Batch number: 36, Loss: 1074.2852783203125\n",
      "Epoch: 141, Batch number: 60, Loss: 1058.6824951171875\n",
      "Epoch: 143, Batch number: 8, Loss: 1118.3494873046875\n",
      "Epoch: 144, Batch number: 32, Loss: 1059.23095703125\n",
      "Epoch: 145, Batch number: 56, Loss: 1040.095703125\n",
      "Epoch: 147, Batch number: 4, Loss: 1102.733642578125\n",
      "Epoch: 148, Batch number: 28, Loss: 1026.9952392578125\n",
      "Epoch: 149, Batch number: 52, Loss: 1041.102294921875\n",
      "Epoch: 151, Batch number: 0, Loss: 995.764404296875\n",
      "Epoch: 152, Batch number: 24, Loss: 1015.5419921875\n",
      "Epoch: 153, Batch number: 48, Loss: 976.267822265625\n",
      "Epoch: 154, Batch number: 72, Loss: 990.6817016601562\n",
      "Epoch: 156, Batch number: 20, Loss: 1001.9313354492188\n",
      "Epoch: 157, Batch number: 44, Loss: 970.285400390625\n",
      "Epoch: 158, Batch number: 68, Loss: 1058.4716796875\n",
      "Epoch: 160, Batch number: 16, Loss: 928.9932250976562\n",
      "Epoch: 161, Batch number: 40, Loss: 977.8368530273438\n",
      "Epoch: 162, Batch number: 64, Loss: 938.48046875\n",
      "Epoch: 164, Batch number: 12, Loss: 922.1224975585938\n",
      "Epoch: 165, Batch number: 36, Loss: 937.7938232421875\n",
      "Epoch: 166, Batch number: 60, Loss: 904.8360595703125\n",
      "Epoch: 168, Batch number: 8, Loss: 881.8046875\n",
      "Epoch: 169, Batch number: 32, Loss: 890.0272216796875\n",
      "Epoch: 170, Batch number: 56, Loss: 847.2722778320312\n",
      "Epoch: 172, Batch number: 4, Loss: 863.6636962890625\n",
      "Epoch: 173, Batch number: 28, Loss: 904.559814453125\n",
      "Epoch: 174, Batch number: 52, Loss: 873.5213012695312\n",
      "Epoch: 176, Batch number: 0, Loss: 828.09814453125\n",
      "Epoch: 177, Batch number: 24, Loss: 872.75244140625\n",
      "Epoch: 178, Batch number: 48, Loss: 833.7588500976562\n",
      "Epoch: 179, Batch number: 72, Loss: 796.8392944335938\n",
      "Epoch: 181, Batch number: 20, Loss: 829.708740234375\n",
      "Epoch: 182, Batch number: 44, Loss: 816.575927734375\n",
      "Epoch: 183, Batch number: 68, Loss: 873.032470703125\n",
      "Epoch: 185, Batch number: 16, Loss: 750.3797607421875\n",
      "Epoch: 186, Batch number: 40, Loss: 866.7655029296875\n",
      "Epoch: 187, Batch number: 64, Loss: 778.800537109375\n",
      "Epoch: 189, Batch number: 12, Loss: 795.7625122070312\n",
      "Epoch: 190, Batch number: 36, Loss: 739.227783203125\n",
      "Epoch: 191, Batch number: 60, Loss: 812.4637451171875\n",
      "Epoch: 193, Batch number: 8, Loss: 719.6282348632812\n",
      "Epoch: 194, Batch number: 32, Loss: 740.9107055664062\n",
      "Epoch: 195, Batch number: 56, Loss: 715.9107666015625\n",
      "Epoch: 197, Batch number: 4, Loss: 731.5205688476562\n",
      "Epoch: 198, Batch number: 28, Loss: 740.0179443359375\n",
      "Epoch: 199, Batch number: 52, Loss: 732.4639892578125\n",
      "Epoch: 201, Batch number: 0, Loss: 723.0225830078125\n",
      "Epoch: 202, Batch number: 24, Loss: 684.1263427734375\n",
      "Epoch: 203, Batch number: 48, Loss: 684.4366455078125\n",
      "Epoch: 204, Batch number: 72, Loss: 681.2556762695312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 206, Batch number: 20, Loss: 729.1513671875\n",
      "Epoch: 207, Batch number: 44, Loss: 721.3798828125\n",
      "Epoch: 208, Batch number: 68, Loss: 664.8870849609375\n",
      "Epoch: 210, Batch number: 16, Loss: 770.09423828125\n",
      "Epoch: 211, Batch number: 40, Loss: 712.7677001953125\n",
      "Epoch: 212, Batch number: 64, Loss: 678.7469482421875\n",
      "Epoch: 214, Batch number: 12, Loss: 680.8869018554688\n",
      "Epoch: 215, Batch number: 36, Loss: 641.4813842773438\n",
      "Epoch: 216, Batch number: 60, Loss: 673.4490356445312\n",
      "Epoch: 218, Batch number: 8, Loss: 675.5548095703125\n",
      "Epoch: 219, Batch number: 32, Loss: 656.3572387695312\n",
      "Epoch: 220, Batch number: 56, Loss: 625.515380859375\n",
      "Epoch: 222, Batch number: 4, Loss: 595.0816650390625\n",
      "Epoch: 223, Batch number: 28, Loss: 625.443359375\n",
      "Epoch: 224, Batch number: 52, Loss: 642.4403686523438\n",
      "Epoch: 226, Batch number: 0, Loss: 582.8001098632812\n",
      "Epoch: 227, Batch number: 24, Loss: 586.0532836914062\n",
      "Epoch: 228, Batch number: 48, Loss: 653.3435668945312\n",
      "Epoch: 229, Batch number: 72, Loss: 560.8245849609375\n",
      "Epoch: 231, Batch number: 20, Loss: 560.9814453125\n",
      "Epoch: 232, Batch number: 44, Loss: 581.0071411132812\n",
      "Epoch: 233, Batch number: 68, Loss: 543.8690185546875\n",
      "Epoch: 235, Batch number: 16, Loss: 607.9844970703125\n",
      "Epoch: 236, Batch number: 40, Loss: 541.3805541992188\n",
      "Epoch: 237, Batch number: 64, Loss: 539.086669921875\n",
      "Epoch: 239, Batch number: 12, Loss: 572.8423461914062\n",
      "Epoch: 240, Batch number: 36, Loss: 586.3450317382812\n",
      "Epoch: 241, Batch number: 60, Loss: 484.55670166015625\n",
      "Epoch: 243, Batch number: 8, Loss: 559.2218017578125\n",
      "Epoch: 244, Batch number: 32, Loss: 572.1765747070312\n",
      "Epoch: 245, Batch number: 56, Loss: 547.85107421875\n",
      "Epoch: 247, Batch number: 4, Loss: 494.187744140625\n",
      "Epoch: 248, Batch number: 28, Loss: 529.9481811523438\n",
      "Epoch: 249, Batch number: 52, Loss: 522.024658203125\n",
      "Epoch: 251, Batch number: 0, Loss: 571.8057861328125\n",
      "Epoch: 252, Batch number: 24, Loss: 535.0267333984375\n",
      "Epoch: 253, Batch number: 48, Loss: 557.3762817382812\n",
      "Epoch: 254, Batch number: 72, Loss: 552.3523559570312\n",
      "Epoch: 256, Batch number: 20, Loss: 516.1752319335938\n",
      "Epoch: 257, Batch number: 44, Loss: 505.6911315917969\n",
      "Epoch: 258, Batch number: 68, Loss: 430.94476318359375\n",
      "Epoch: 260, Batch number: 16, Loss: 496.6025085449219\n",
      "Epoch: 261, Batch number: 40, Loss: 456.0303039550781\n",
      "Epoch: 262, Batch number: 64, Loss: 503.8111572265625\n",
      "Epoch: 264, Batch number: 12, Loss: 448.8814392089844\n",
      "Epoch: 265, Batch number: 36, Loss: 513.3640747070312\n",
      "Epoch: 266, Batch number: 60, Loss: 489.694091796875\n",
      "Epoch: 268, Batch number: 8, Loss: 504.50909423828125\n",
      "Epoch: 269, Batch number: 32, Loss: 423.7740783691406\n",
      "Epoch: 270, Batch number: 56, Loss: 496.594482421875\n",
      "Epoch: 272, Batch number: 4, Loss: 457.76776123046875\n",
      "Epoch: 273, Batch number: 28, Loss: 417.9896545410156\n",
      "Epoch: 274, Batch number: 52, Loss: 440.71588134765625\n",
      "Epoch: 276, Batch number: 0, Loss: 394.33905029296875\n",
      "Epoch: 277, Batch number: 24, Loss: 419.9796142578125\n",
      "Epoch: 278, Batch number: 48, Loss: 381.39208984375\n",
      "Epoch: 279, Batch number: 72, Loss: 372.3664245605469\n",
      "Epoch: 281, Batch number: 20, Loss: 425.837890625\n",
      "Epoch: 282, Batch number: 44, Loss: 401.1402893066406\n",
      "Epoch: 283, Batch number: 68, Loss: 393.9535217285156\n",
      "Epoch: 285, Batch number: 16, Loss: 387.16156005859375\n",
      "Epoch: 286, Batch number: 40, Loss: 409.6245422363281\n",
      "Epoch: 287, Batch number: 64, Loss: 429.9410400390625\n",
      "Epoch: 289, Batch number: 12, Loss: 365.7679443359375\n",
      "Epoch: 290, Batch number: 36, Loss: 413.1258239746094\n",
      "Epoch: 291, Batch number: 60, Loss: 387.04486083984375\n",
      "Epoch: 293, Batch number: 8, Loss: 362.4112854003906\n",
      "Epoch: 294, Batch number: 32, Loss: 381.4635925292969\n",
      "Epoch: 295, Batch number: 56, Loss: 345.05010986328125\n",
      "Epoch: 297, Batch number: 4, Loss: 373.4167175292969\n",
      "Epoch: 298, Batch number: 28, Loss: 375.4394226074219\n",
      "Epoch: 299, Batch number: 52, Loss: 370.06689453125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4403.36767578125\n",
      "Epoch: 2, Batch number: 24, Loss: 4192.7353515625\n",
      "Epoch: 3, Batch number: 48, Loss: 3820.5263671875\n",
      "Epoch: 4, Batch number: 72, Loss: 3299.050537109375\n",
      "Epoch: 6, Batch number: 20, Loss: 3055.108154296875\n",
      "Epoch: 7, Batch number: 44, Loss: 3003.09423828125\n",
      "Epoch: 8, Batch number: 68, Loss: 2867.400146484375\n",
      "Epoch: 10, Batch number: 16, Loss: 2773.143798828125\n",
      "Epoch: 11, Batch number: 40, Loss: 2737.70947265625\n",
      "Epoch: 12, Batch number: 64, Loss: 2597.2236328125\n",
      "Epoch: 14, Batch number: 12, Loss: 2626.257568359375\n",
      "Epoch: 15, Batch number: 36, Loss: 2591.117431640625\n",
      "Epoch: 16, Batch number: 60, Loss: 2527.5087890625\n",
      "Epoch: 18, Batch number: 8, Loss: 2512.503173828125\n",
      "Epoch: 19, Batch number: 32, Loss: 2640.96728515625\n",
      "Epoch: 20, Batch number: 56, Loss: 2386.77783203125\n",
      "Epoch: 22, Batch number: 4, Loss: 2486.0\n",
      "Epoch: 23, Batch number: 28, Loss: 2306.01904296875\n",
      "Epoch: 24, Batch number: 52, Loss: 2283.029052734375\n",
      "Epoch: 26, Batch number: 0, Loss: 2346.66357421875\n",
      "Epoch: 27, Batch number: 24, Loss: 2190.98583984375\n",
      "Epoch: 28, Batch number: 48, Loss: 2294.836181640625\n",
      "Epoch: 29, Batch number: 72, Loss: 2200.52880859375\n",
      "Epoch: 31, Batch number: 20, Loss: 2039.4814453125\n",
      "Epoch: 32, Batch number: 44, Loss: 2056.977294921875\n",
      "Epoch: 33, Batch number: 68, Loss: 2004.4246826171875\n",
      "Epoch: 35, Batch number: 16, Loss: 1962.2908935546875\n",
      "Epoch: 36, Batch number: 40, Loss: 1959.149658203125\n",
      "Epoch: 37, Batch number: 64, Loss: 1881.750732421875\n",
      "Epoch: 39, Batch number: 12, Loss: 1895.5908203125\n",
      "Epoch: 40, Batch number: 36, Loss: 1812.4937744140625\n",
      "Epoch: 41, Batch number: 60, Loss: 1814.5457763671875\n",
      "Epoch: 43, Batch number: 8, Loss: 1680.387451171875\n",
      "Epoch: 44, Batch number: 32, Loss: 1741.0966796875\n",
      "Epoch: 45, Batch number: 56, Loss: 1737.6180419921875\n",
      "Epoch: 47, Batch number: 4, Loss: 1662.409912109375\n",
      "Epoch: 48, Batch number: 28, Loss: 1643.451416015625\n",
      "Epoch: 49, Batch number: 52, Loss: 1577.698974609375\n",
      "Epoch: 51, Batch number: 0, Loss: 1552.9310302734375\n",
      "Epoch: 52, Batch number: 24, Loss: 1582.066650390625\n",
      "Epoch: 53, Batch number: 48, Loss: 1428.1065673828125\n",
      "Epoch: 54, Batch number: 72, Loss: 1443.164794921875\n",
      "Epoch: 56, Batch number: 20, Loss: 1481.0028076171875\n",
      "Epoch: 57, Batch number: 44, Loss: 1395.73828125\n",
      "Epoch: 58, Batch number: 68, Loss: 1415.4468994140625\n",
      "Epoch: 60, Batch number: 16, Loss: 1292.560791015625\n",
      "Epoch: 61, Batch number: 40, Loss: 1337.31689453125\n",
      "Epoch: 62, Batch number: 64, Loss: 1365.0401611328125\n",
      "Epoch: 64, Batch number: 12, Loss: 1351.91064453125\n",
      "Epoch: 65, Batch number: 36, Loss: 1234.9769287109375\n",
      "Epoch: 66, Batch number: 60, Loss: 1293.691650390625\n",
      "Epoch: 68, Batch number: 8, Loss: 1177.241943359375\n",
      "Epoch: 69, Batch number: 32, Loss: 1193.9561767578125\n",
      "Epoch: 70, Batch number: 56, Loss: 1206.48046875\n",
      "Epoch: 72, Batch number: 4, Loss: 1255.611572265625\n",
      "Epoch: 73, Batch number: 28, Loss: 1187.1016845703125\n",
      "Epoch: 74, Batch number: 52, Loss: 1137.7452392578125\n",
      "Epoch: 76, Batch number: 0, Loss: 1092.083740234375\n",
      "Epoch: 77, Batch number: 24, Loss: 1096.7298583984375\n",
      "Epoch: 78, Batch number: 48, Loss: 1104.1805419921875\n",
      "Epoch: 79, Batch number: 72, Loss: 1082.699951171875\n",
      "Epoch: 81, Batch number: 20, Loss: 1042.47705078125\n",
      "Epoch: 82, Batch number: 44, Loss: 1018.0926513671875\n",
      "Epoch: 83, Batch number: 68, Loss: 1052.038818359375\n",
      "Epoch: 85, Batch number: 16, Loss: 974.3153686523438\n",
      "Epoch: 86, Batch number: 40, Loss: 954.2216796875\n",
      "Epoch: 87, Batch number: 64, Loss: 944.56982421875\n",
      "Epoch: 89, Batch number: 12, Loss: 916.4952392578125\n",
      "Epoch: 90, Batch number: 36, Loss: 935.1399536132812\n",
      "Epoch: 91, Batch number: 60, Loss: 941.4605102539062\n",
      "Epoch: 93, Batch number: 8, Loss: 861.6841430664062\n",
      "Epoch: 94, Batch number: 32, Loss: 874.9290771484375\n",
      "Epoch: 95, Batch number: 56, Loss: 876.786376953125\n",
      "Epoch: 97, Batch number: 4, Loss: 837.4405517578125\n",
      "Epoch: 98, Batch number: 28, Loss: 859.1547241210938\n",
      "Epoch: 99, Batch number: 52, Loss: 811.8130493164062\n",
      "Epoch: 101, Batch number: 0, Loss: 812.81298828125\n",
      "Epoch: 102, Batch number: 24, Loss: 754.565185546875\n",
      "Epoch: 103, Batch number: 48, Loss: 773.494873046875\n",
      "Epoch: 104, Batch number: 72, Loss: 798.5201416015625\n",
      "Epoch: 106, Batch number: 20, Loss: 687.6862182617188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 739.1738891601562\n",
      "Epoch: 108, Batch number: 68, Loss: 726.8621215820312\n",
      "Epoch: 110, Batch number: 16, Loss: 700.7946166992188\n",
      "Epoch: 111, Batch number: 40, Loss: 720.636962890625\n",
      "Epoch: 112, Batch number: 64, Loss: 653.0431518554688\n",
      "Epoch: 114, Batch number: 12, Loss: 629.80078125\n",
      "Epoch: 115, Batch number: 36, Loss: 671.6403198242188\n",
      "Epoch: 116, Batch number: 60, Loss: 652.7333984375\n",
      "Epoch: 118, Batch number: 8, Loss: 719.9247436523438\n",
      "Epoch: 119, Batch number: 32, Loss: 647.4373779296875\n",
      "Epoch: 120, Batch number: 56, Loss: 668.6755981445312\n",
      "Epoch: 122, Batch number: 4, Loss: 635.7234497070312\n",
      "Epoch: 123, Batch number: 28, Loss: 607.3155517578125\n",
      "Epoch: 124, Batch number: 52, Loss: 622.1236572265625\n",
      "Epoch: 126, Batch number: 0, Loss: 555.3812866210938\n",
      "Epoch: 127, Batch number: 24, Loss: 549.2742309570312\n",
      "Epoch: 128, Batch number: 48, Loss: 531.8515014648438\n",
      "Epoch: 129, Batch number: 72, Loss: 571.3375244140625\n",
      "Epoch: 131, Batch number: 20, Loss: 490.3374328613281\n",
      "Epoch: 132, Batch number: 44, Loss: 490.1719970703125\n",
      "Epoch: 133, Batch number: 68, Loss: 480.1206970214844\n",
      "Epoch: 135, Batch number: 16, Loss: 522.3599243164062\n",
      "Epoch: 136, Batch number: 40, Loss: 497.4717712402344\n",
      "Epoch: 137, Batch number: 64, Loss: 513.8895874023438\n",
      "Epoch: 139, Batch number: 12, Loss: 523.7708129882812\n",
      "Epoch: 140, Batch number: 36, Loss: 447.9549255371094\n",
      "Epoch: 141, Batch number: 60, Loss: 482.20379638671875\n",
      "Epoch: 143, Batch number: 8, Loss: 416.78118896484375\n",
      "Epoch: 144, Batch number: 32, Loss: 458.18292236328125\n",
      "Epoch: 145, Batch number: 56, Loss: 440.4143371582031\n",
      "Epoch: 147, Batch number: 4, Loss: 435.28778076171875\n",
      "Epoch: 148, Batch number: 28, Loss: 410.1426086425781\n",
      "Epoch: 149, Batch number: 52, Loss: 409.03564453125\n",
      "Epoch: 151, Batch number: 0, Loss: 386.8527526855469\n",
      "Epoch: 152, Batch number: 24, Loss: 398.68890380859375\n",
      "Epoch: 153, Batch number: 48, Loss: 371.02105712890625\n",
      "Epoch: 154, Batch number: 72, Loss: 396.8682861328125\n",
      "Epoch: 156, Batch number: 20, Loss: 382.08056640625\n",
      "Epoch: 157, Batch number: 44, Loss: 364.1404724121094\n",
      "Epoch: 158, Batch number: 68, Loss: 340.9585876464844\n",
      "Epoch: 160, Batch number: 16, Loss: 340.46759033203125\n",
      "Epoch: 161, Batch number: 40, Loss: 368.35028076171875\n",
      "Epoch: 162, Batch number: 64, Loss: 338.624267578125\n",
      "Epoch: 164, Batch number: 12, Loss: 317.30108642578125\n",
      "Epoch: 165, Batch number: 36, Loss: 323.1434020996094\n",
      "Epoch: 166, Batch number: 60, Loss: 295.2320861816406\n",
      "Epoch: 168, Batch number: 8, Loss: 307.09716796875\n",
      "Epoch: 169, Batch number: 32, Loss: 325.0126953125\n",
      "Epoch: 170, Batch number: 56, Loss: 291.10284423828125\n",
      "Epoch: 172, Batch number: 4, Loss: 255.1912841796875\n",
      "Epoch: 173, Batch number: 28, Loss: 273.51251220703125\n",
      "Epoch: 174, Batch number: 52, Loss: 286.2798767089844\n",
      "Epoch: 176, Batch number: 0, Loss: 267.6487121582031\n",
      "Epoch: 177, Batch number: 24, Loss: 260.09613037109375\n",
      "Epoch: 178, Batch number: 48, Loss: 277.787353515625\n",
      "Epoch: 179, Batch number: 72, Loss: 265.6826477050781\n",
      "Epoch: 181, Batch number: 20, Loss: 222.32308959960938\n",
      "Epoch: 182, Batch number: 44, Loss: 272.64544677734375\n",
      "Epoch: 183, Batch number: 68, Loss: 245.93380737304688\n",
      "Epoch: 185, Batch number: 16, Loss: 257.9971618652344\n",
      "Epoch: 186, Batch number: 40, Loss: 262.1580810546875\n",
      "Epoch: 187, Batch number: 64, Loss: 233.37344360351562\n",
      "Epoch: 189, Batch number: 12, Loss: 238.57748413085938\n",
      "Epoch: 190, Batch number: 36, Loss: 204.69151306152344\n",
      "Epoch: 191, Batch number: 60, Loss: 208.63796997070312\n",
      "Epoch: 193, Batch number: 8, Loss: 194.847412109375\n",
      "Epoch: 194, Batch number: 32, Loss: 207.1003875732422\n",
      "Epoch: 195, Batch number: 56, Loss: 190.33734130859375\n",
      "Epoch: 197, Batch number: 4, Loss: 199.15438842773438\n",
      "Epoch: 198, Batch number: 28, Loss: 205.652099609375\n",
      "Epoch: 199, Batch number: 52, Loss: 197.39772033691406\n",
      "Epoch: 201, Batch number: 0, Loss: 188.22573852539062\n",
      "Epoch: 202, Batch number: 24, Loss: 198.4672088623047\n",
      "Epoch: 203, Batch number: 48, Loss: 175.4412384033203\n",
      "Epoch: 204, Batch number: 72, Loss: 156.9158477783203\n",
      "Epoch: 206, Batch number: 20, Loss: 184.79432678222656\n",
      "Epoch: 207, Batch number: 44, Loss: 179.9361572265625\n",
      "Epoch: 208, Batch number: 68, Loss: 135.39158630371094\n",
      "Epoch: 210, Batch number: 16, Loss: 160.8317108154297\n",
      "Epoch: 211, Batch number: 40, Loss: 149.44735717773438\n",
      "Epoch: 212, Batch number: 64, Loss: 147.1688232421875\n",
      "Epoch: 214, Batch number: 12, Loss: 163.39599609375\n",
      "Epoch: 215, Batch number: 36, Loss: 153.2015838623047\n",
      "Epoch: 216, Batch number: 60, Loss: 143.80931091308594\n",
      "Epoch: 218, Batch number: 8, Loss: 147.3619384765625\n",
      "Epoch: 219, Batch number: 32, Loss: 136.2208709716797\n",
      "Epoch: 220, Batch number: 56, Loss: 129.5198516845703\n",
      "Epoch: 222, Batch number: 4, Loss: 121.4529800415039\n",
      "Epoch: 223, Batch number: 28, Loss: 141.7086944580078\n",
      "Epoch: 224, Batch number: 52, Loss: 133.5271453857422\n",
      "Epoch: 226, Batch number: 0, Loss: 106.10791015625\n",
      "Epoch: 227, Batch number: 24, Loss: 124.58983612060547\n",
      "Epoch: 228, Batch number: 48, Loss: 117.30059051513672\n",
      "Epoch: 229, Batch number: 72, Loss: 117.8155288696289\n",
      "Epoch: 231, Batch number: 20, Loss: 98.79997253417969\n",
      "Epoch: 232, Batch number: 44, Loss: 108.80236053466797\n",
      "Epoch: 233, Batch number: 68, Loss: 104.96627807617188\n",
      "Epoch: 235, Batch number: 16, Loss: 120.48753356933594\n",
      "Epoch: 236, Batch number: 40, Loss: 108.77384185791016\n",
      "Epoch: 237, Batch number: 64, Loss: 98.97328186035156\n",
      "Epoch: 239, Batch number: 12, Loss: 112.7373275756836\n",
      "Epoch: 240, Batch number: 36, Loss: 80.25529479980469\n",
      "Epoch: 241, Batch number: 60, Loss: 88.11018371582031\n",
      "Epoch: 243, Batch number: 8, Loss: 93.83434295654297\n",
      "Epoch: 244, Batch number: 32, Loss: 79.05187225341797\n",
      "Epoch: 245, Batch number: 56, Loss: 80.29408264160156\n",
      "Epoch: 247, Batch number: 4, Loss: 89.18327331542969\n",
      "Epoch: 248, Batch number: 28, Loss: 85.99576568603516\n",
      "Epoch: 249, Batch number: 52, Loss: 76.1790771484375\n",
      "Epoch: 251, Batch number: 0, Loss: 72.93762969970703\n",
      "Epoch: 252, Batch number: 24, Loss: 71.49604797363281\n",
      "Epoch: 253, Batch number: 48, Loss: 72.35928344726562\n",
      "Epoch: 254, Batch number: 72, Loss: 69.04469299316406\n",
      "Epoch: 256, Batch number: 20, Loss: 77.11209869384766\n",
      "Epoch: 257, Batch number: 44, Loss: 62.9435920715332\n",
      "Epoch: 258, Batch number: 68, Loss: 68.74797821044922\n",
      "Epoch: 260, Batch number: 16, Loss: 62.84705352783203\n",
      "Epoch: 261, Batch number: 40, Loss: 59.62248992919922\n",
      "Epoch: 262, Batch number: 64, Loss: 74.75776672363281\n",
      "Epoch: 264, Batch number: 12, Loss: 63.17151641845703\n",
      "Epoch: 265, Batch number: 36, Loss: 51.420143127441406\n",
      "Epoch: 266, Batch number: 60, Loss: 52.09843826293945\n",
      "Epoch: 268, Batch number: 8, Loss: 61.44176483154297\n",
      "Epoch: 269, Batch number: 32, Loss: 53.32177734375\n",
      "Epoch: 270, Batch number: 56, Loss: 70.46959686279297\n",
      "Epoch: 272, Batch number: 4, Loss: 53.340023040771484\n",
      "Epoch: 273, Batch number: 28, Loss: 46.364097595214844\n",
      "Epoch: 274, Batch number: 52, Loss: 59.99998474121094\n",
      "Epoch: 276, Batch number: 0, Loss: 54.84069061279297\n",
      "Epoch: 277, Batch number: 24, Loss: 41.44292449951172\n",
      "Epoch: 278, Batch number: 48, Loss: 51.892391204833984\n",
      "Epoch: 279, Batch number: 72, Loss: 51.59486389160156\n",
      "Epoch: 281, Batch number: 20, Loss: 43.80420684814453\n",
      "Epoch: 282, Batch number: 44, Loss: 46.46759033203125\n",
      "Epoch: 283, Batch number: 68, Loss: 52.84837341308594\n",
      "Epoch: 285, Batch number: 16, Loss: 43.4599723815918\n",
      "Epoch: 286, Batch number: 40, Loss: 56.45915222167969\n",
      "Epoch: 287, Batch number: 64, Loss: 40.10226821899414\n",
      "Epoch: 289, Batch number: 12, Loss: 41.87337112426758\n",
      "Epoch: 290, Batch number: 36, Loss: 30.441051483154297\n",
      "Epoch: 291, Batch number: 60, Loss: 40.82631301879883\n",
      "Epoch: 293, Batch number: 8, Loss: 35.08126449584961\n",
      "Epoch: 294, Batch number: 32, Loss: 34.851951599121094\n",
      "Epoch: 295, Batch number: 56, Loss: 48.99216842651367\n",
      "Epoch: 297, Batch number: 4, Loss: 35.52729797363281\n",
      "Epoch: 298, Batch number: 28, Loss: 35.71265411376953\n",
      "Epoch: 299, Batch number: 52, Loss: 34.90896987915039\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4400.31298828125\n",
      "Epoch: 2, Batch number: 24, Loss: 4107.6669921875\n",
      "Epoch: 3, Batch number: 48, Loss: 3580.576904296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch number: 72, Loss: 3198.061767578125\n",
      "Epoch: 6, Batch number: 20, Loss: 2992.9130859375\n",
      "Epoch: 7, Batch number: 44, Loss: 2888.240478515625\n",
      "Epoch: 8, Batch number: 68, Loss: 2785.9287109375\n",
      "Epoch: 10, Batch number: 16, Loss: 2657.6904296875\n",
      "Epoch: 11, Batch number: 40, Loss: 2522.894287109375\n",
      "Epoch: 12, Batch number: 64, Loss: 2562.244140625\n",
      "Epoch: 14, Batch number: 12, Loss: 2509.46435546875\n",
      "Epoch: 15, Batch number: 36, Loss: 2423.08154296875\n",
      "Epoch: 16, Batch number: 60, Loss: 2314.333740234375\n",
      "Epoch: 18, Batch number: 8, Loss: 2269.804931640625\n",
      "Epoch: 19, Batch number: 32, Loss: 2256.130859375\n",
      "Epoch: 20, Batch number: 56, Loss: 2122.001708984375\n",
      "Epoch: 22, Batch number: 4, Loss: 2052.235595703125\n",
      "Epoch: 23, Batch number: 28, Loss: 2069.806884765625\n",
      "Epoch: 24, Batch number: 52, Loss: 2067.862548828125\n",
      "Epoch: 26, Batch number: 0, Loss: 1944.55322265625\n",
      "Epoch: 27, Batch number: 24, Loss: 2020.1314697265625\n",
      "Epoch: 28, Batch number: 48, Loss: 1922.433349609375\n",
      "Epoch: 29, Batch number: 72, Loss: 1841.442626953125\n",
      "Epoch: 31, Batch number: 20, Loss: 1724.05078125\n",
      "Epoch: 32, Batch number: 44, Loss: 1702.4937744140625\n",
      "Epoch: 33, Batch number: 68, Loss: 1661.93017578125\n",
      "Epoch: 35, Batch number: 16, Loss: 1598.3046875\n",
      "Epoch: 36, Batch number: 40, Loss: 1615.4000244140625\n",
      "Epoch: 37, Batch number: 64, Loss: 1549.503662109375\n",
      "Epoch: 39, Batch number: 12, Loss: 1437.8009033203125\n",
      "Epoch: 40, Batch number: 36, Loss: 1416.77197265625\n",
      "Epoch: 41, Batch number: 60, Loss: 1391.4949951171875\n",
      "Epoch: 43, Batch number: 8, Loss: 1375.1851806640625\n",
      "Epoch: 44, Batch number: 32, Loss: 1375.3775634765625\n",
      "Epoch: 45, Batch number: 56, Loss: 1328.262451171875\n",
      "Epoch: 47, Batch number: 4, Loss: 1295.8466796875\n",
      "Epoch: 48, Batch number: 28, Loss: 1256.2479248046875\n",
      "Epoch: 49, Batch number: 52, Loss: 1263.9061279296875\n",
      "Epoch: 51, Batch number: 0, Loss: 1187.614990234375\n",
      "Epoch: 52, Batch number: 24, Loss: 1186.6181640625\n",
      "Epoch: 53, Batch number: 48, Loss: 1240.3670654296875\n",
      "Epoch: 54, Batch number: 72, Loss: 1156.1734619140625\n",
      "Epoch: 56, Batch number: 20, Loss: 1094.5872802734375\n",
      "Epoch: 57, Batch number: 44, Loss: 1085.4659423828125\n",
      "Epoch: 58, Batch number: 68, Loss: 1092.662841796875\n",
      "Epoch: 60, Batch number: 16, Loss: 976.9949951171875\n",
      "Epoch: 61, Batch number: 40, Loss: 997.1257934570312\n",
      "Epoch: 62, Batch number: 64, Loss: 955.855224609375\n",
      "Epoch: 64, Batch number: 12, Loss: 915.7977294921875\n",
      "Epoch: 65, Batch number: 36, Loss: 868.861083984375\n",
      "Epoch: 66, Batch number: 60, Loss: 908.840087890625\n",
      "Epoch: 68, Batch number: 8, Loss: 849.2156372070312\n",
      "Epoch: 69, Batch number: 32, Loss: 815.8102416992188\n",
      "Epoch: 70, Batch number: 56, Loss: 804.2725830078125\n",
      "Epoch: 72, Batch number: 4, Loss: 799.2789916992188\n",
      "Epoch: 73, Batch number: 28, Loss: 801.6341552734375\n",
      "Epoch: 74, Batch number: 52, Loss: 759.6478271484375\n",
      "Epoch: 76, Batch number: 0, Loss: 864.1017456054688\n",
      "Epoch: 77, Batch number: 24, Loss: 736.3174438476562\n",
      "Epoch: 78, Batch number: 48, Loss: 712.0233154296875\n",
      "Epoch: 79, Batch number: 72, Loss: 673.44091796875\n",
      "Epoch: 81, Batch number: 20, Loss: 684.5542602539062\n",
      "Epoch: 82, Batch number: 44, Loss: 643.4556884765625\n",
      "Epoch: 83, Batch number: 68, Loss: 706.761474609375\n",
      "Epoch: 85, Batch number: 16, Loss: 643.49951171875\n",
      "Epoch: 86, Batch number: 40, Loss: 612.4811401367188\n",
      "Epoch: 87, Batch number: 64, Loss: 683.5184936523438\n",
      "Epoch: 89, Batch number: 12, Loss: 612.5202026367188\n",
      "Epoch: 90, Batch number: 36, Loss: 582.2071533203125\n",
      "Epoch: 91, Batch number: 60, Loss: 573.8026733398438\n",
      "Epoch: 93, Batch number: 8, Loss: 548.3670043945312\n",
      "Epoch: 94, Batch number: 32, Loss: 521.4749755859375\n",
      "Epoch: 95, Batch number: 56, Loss: 500.5736083984375\n",
      "Epoch: 97, Batch number: 4, Loss: 534.8330688476562\n",
      "Epoch: 98, Batch number: 28, Loss: 522.5587768554688\n",
      "Epoch: 99, Batch number: 52, Loss: 477.6410217285156\n",
      "Epoch: 101, Batch number: 0, Loss: 461.8525695800781\n",
      "Epoch: 102, Batch number: 24, Loss: 438.73126220703125\n",
      "Epoch: 103, Batch number: 48, Loss: 424.9954833984375\n",
      "Epoch: 104, Batch number: 72, Loss: 479.3809509277344\n",
      "Epoch: 106, Batch number: 20, Loss: 395.3606872558594\n",
      "Epoch: 107, Batch number: 44, Loss: 458.9664611816406\n",
      "Epoch: 108, Batch number: 68, Loss: 452.43353271484375\n",
      "Epoch: 110, Batch number: 16, Loss: 403.0918273925781\n",
      "Epoch: 111, Batch number: 40, Loss: 367.3785095214844\n",
      "Epoch: 112, Batch number: 64, Loss: 412.67474365234375\n",
      "Epoch: 114, Batch number: 12, Loss: 387.6500244140625\n",
      "Epoch: 115, Batch number: 36, Loss: 356.4458312988281\n",
      "Epoch: 116, Batch number: 60, Loss: 329.59991455078125\n",
      "Epoch: 118, Batch number: 8, Loss: 350.3538513183594\n",
      "Epoch: 119, Batch number: 32, Loss: 330.6885986328125\n",
      "Epoch: 120, Batch number: 56, Loss: 334.1240234375\n",
      "Epoch: 122, Batch number: 4, Loss: 267.25921630859375\n",
      "Epoch: 123, Batch number: 28, Loss: 292.4337158203125\n",
      "Epoch: 124, Batch number: 52, Loss: 291.98956298828125\n",
      "Epoch: 126, Batch number: 0, Loss: 306.21722412109375\n",
      "Epoch: 127, Batch number: 24, Loss: 280.1042785644531\n",
      "Epoch: 128, Batch number: 48, Loss: 275.32513427734375\n",
      "Epoch: 129, Batch number: 72, Loss: 225.08872985839844\n",
      "Epoch: 131, Batch number: 20, Loss: 233.22998046875\n",
      "Epoch: 132, Batch number: 44, Loss: 263.4331359863281\n",
      "Epoch: 133, Batch number: 68, Loss: 278.95941162109375\n",
      "Epoch: 135, Batch number: 16, Loss: 238.1171112060547\n",
      "Epoch: 136, Batch number: 40, Loss: 217.84947204589844\n",
      "Epoch: 137, Batch number: 64, Loss: 222.55442810058594\n",
      "Epoch: 139, Batch number: 12, Loss: 214.4847869873047\n",
      "Epoch: 140, Batch number: 36, Loss: 199.27969360351562\n",
      "Epoch: 141, Batch number: 60, Loss: 215.65843200683594\n",
      "Epoch: 143, Batch number: 8, Loss: 202.7013397216797\n",
      "Epoch: 144, Batch number: 32, Loss: 186.32212829589844\n",
      "Epoch: 145, Batch number: 56, Loss: 200.58692932128906\n",
      "Epoch: 147, Batch number: 4, Loss: 181.91566467285156\n",
      "Epoch: 148, Batch number: 28, Loss: 192.51736450195312\n",
      "Epoch: 149, Batch number: 52, Loss: 170.46331787109375\n",
      "Epoch: 151, Batch number: 0, Loss: 169.09555053710938\n",
      "Epoch: 152, Batch number: 24, Loss: 171.27963256835938\n",
      "Epoch: 153, Batch number: 48, Loss: 168.61187744140625\n",
      "Epoch: 154, Batch number: 72, Loss: 144.70748901367188\n",
      "Epoch: 156, Batch number: 20, Loss: 142.02838134765625\n",
      "Epoch: 157, Batch number: 44, Loss: 125.93059539794922\n",
      "Epoch: 158, Batch number: 68, Loss: 138.98281860351562\n",
      "Epoch: 160, Batch number: 16, Loss: 129.07394409179688\n",
      "Epoch: 161, Batch number: 40, Loss: 128.00039672851562\n",
      "Epoch: 162, Batch number: 64, Loss: 142.81768798828125\n",
      "Epoch: 164, Batch number: 12, Loss: 101.77982330322266\n",
      "Epoch: 165, Batch number: 36, Loss: 110.3938980102539\n",
      "Epoch: 166, Batch number: 60, Loss: 119.74826049804688\n",
      "Epoch: 168, Batch number: 8, Loss: 95.42747497558594\n",
      "Epoch: 169, Batch number: 32, Loss: 90.9683837890625\n",
      "Epoch: 170, Batch number: 56, Loss: 97.43955993652344\n",
      "Epoch: 172, Batch number: 4, Loss: 109.16063690185547\n",
      "Epoch: 173, Batch number: 28, Loss: 100.0750732421875\n",
      "Epoch: 174, Batch number: 52, Loss: 105.73490905761719\n",
      "Epoch: 176, Batch number: 0, Loss: 89.03221130371094\n",
      "Epoch: 177, Batch number: 24, Loss: 89.99790954589844\n",
      "Epoch: 178, Batch number: 48, Loss: 72.33238983154297\n",
      "Epoch: 179, Batch number: 72, Loss: 96.5809555053711\n",
      "Epoch: 181, Batch number: 20, Loss: 95.6150894165039\n",
      "Epoch: 182, Batch number: 44, Loss: 70.38006591796875\n",
      "Epoch: 183, Batch number: 68, Loss: 80.81146240234375\n",
      "Epoch: 185, Batch number: 16, Loss: 78.35440063476562\n",
      "Epoch: 186, Batch number: 40, Loss: 79.6814193725586\n",
      "Epoch: 187, Batch number: 64, Loss: 84.0469741821289\n",
      "Epoch: 189, Batch number: 12, Loss: 63.818302154541016\n",
      "Epoch: 190, Batch number: 36, Loss: 58.52666473388672\n",
      "Epoch: 191, Batch number: 60, Loss: 57.66134262084961\n",
      "Epoch: 193, Batch number: 8, Loss: 61.18186569213867\n",
      "Epoch: 194, Batch number: 32, Loss: 64.1246109008789\n",
      "Epoch: 195, Batch number: 56, Loss: 57.05619812011719\n",
      "Epoch: 197, Batch number: 4, Loss: 63.24542999267578\n",
      "Epoch: 198, Batch number: 28, Loss: 54.78496551513672\n",
      "Epoch: 199, Batch number: 52, Loss: 53.25752258300781\n",
      "Epoch: 201, Batch number: 0, Loss: 54.41352844238281\n",
      "Epoch: 202, Batch number: 24, Loss: 53.66156005859375\n",
      "Epoch: 203, Batch number: 48, Loss: 57.177772521972656\n",
      "Epoch: 204, Batch number: 72, Loss: 51.16936492919922\n",
      "Epoch: 206, Batch number: 20, Loss: 63.2708740234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207, Batch number: 44, Loss: 49.890865325927734\n",
      "Epoch: 208, Batch number: 68, Loss: 54.93516540527344\n",
      "Epoch: 210, Batch number: 16, Loss: 42.396240234375\n",
      "Epoch: 211, Batch number: 40, Loss: 44.285011291503906\n",
      "Epoch: 212, Batch number: 64, Loss: 47.72724533081055\n",
      "Epoch: 214, Batch number: 12, Loss: 37.344886779785156\n",
      "Epoch: 215, Batch number: 36, Loss: 50.99140167236328\n",
      "Epoch: 216, Batch number: 60, Loss: 44.4864501953125\n",
      "Epoch: 218, Batch number: 8, Loss: 36.147953033447266\n",
      "Epoch: 219, Batch number: 32, Loss: 32.105106353759766\n",
      "Epoch: 220, Batch number: 56, Loss: 38.30104064941406\n",
      "Epoch: 222, Batch number: 4, Loss: 34.47168731689453\n",
      "Epoch: 223, Batch number: 28, Loss: 32.32196044921875\n",
      "Epoch: 224, Batch number: 52, Loss: 37.32234191894531\n",
      "Epoch: 226, Batch number: 0, Loss: 32.00999069213867\n",
      "Epoch: 227, Batch number: 24, Loss: 32.5682373046875\n",
      "Epoch: 228, Batch number: 48, Loss: 32.52205276489258\n",
      "Epoch: 229, Batch number: 72, Loss: 37.52348709106445\n",
      "Epoch: 231, Batch number: 20, Loss: 25.050312042236328\n",
      "Epoch: 232, Batch number: 44, Loss: 33.461483001708984\n",
      "Epoch: 233, Batch number: 68, Loss: 27.193025588989258\n",
      "Epoch: 235, Batch number: 16, Loss: 27.918638229370117\n",
      "Epoch: 236, Batch number: 40, Loss: 26.80126190185547\n",
      "Epoch: 237, Batch number: 64, Loss: 33.45990753173828\n",
      "Epoch: 239, Batch number: 12, Loss: 25.49875259399414\n",
      "Epoch: 240, Batch number: 36, Loss: 30.721973419189453\n",
      "Epoch: 241, Batch number: 60, Loss: 28.45903205871582\n",
      "Epoch: 243, Batch number: 8, Loss: 25.57274627685547\n",
      "Epoch: 244, Batch number: 32, Loss: 23.306791305541992\n",
      "Epoch: 245, Batch number: 56, Loss: 29.662628173828125\n",
      "Epoch: 247, Batch number: 4, Loss: 21.1728515625\n",
      "Epoch: 248, Batch number: 28, Loss: 23.328929901123047\n",
      "Epoch: 249, Batch number: 52, Loss: 19.371734619140625\n",
      "Epoch: 251, Batch number: 0, Loss: 19.34795379638672\n",
      "Epoch: 252, Batch number: 24, Loss: 17.367399215698242\n",
      "Epoch: 253, Batch number: 48, Loss: 19.16150665283203\n",
      "Epoch: 254, Batch number: 72, Loss: 19.689990997314453\n",
      "Epoch: 256, Batch number: 20, Loss: 17.142162322998047\n",
      "Epoch: 257, Batch number: 44, Loss: 16.884723663330078\n",
      "Epoch: 258, Batch number: 68, Loss: 21.598979949951172\n",
      "Epoch: 260, Batch number: 16, Loss: 16.612857818603516\n",
      "Epoch: 261, Batch number: 40, Loss: 18.79075813293457\n",
      "Epoch: 262, Batch number: 64, Loss: 22.936880111694336\n",
      "Epoch: 264, Batch number: 12, Loss: 15.466765403747559\n",
      "Epoch: 265, Batch number: 36, Loss: 15.960370063781738\n",
      "Epoch: 266, Batch number: 60, Loss: 15.912300109863281\n",
      "Epoch: 268, Batch number: 8, Loss: 17.3124942779541\n",
      "Epoch: 269, Batch number: 32, Loss: 18.095861434936523\n",
      "Epoch: 270, Batch number: 56, Loss: 14.417929649353027\n",
      "Epoch: 272, Batch number: 4, Loss: 14.23526668548584\n",
      "Epoch: 273, Batch number: 28, Loss: 12.665209770202637\n",
      "Epoch: 274, Batch number: 52, Loss: 16.813465118408203\n",
      "Epoch: 276, Batch number: 0, Loss: 14.350981712341309\n",
      "Epoch: 277, Batch number: 24, Loss: 14.826669692993164\n",
      "Epoch: 278, Batch number: 48, Loss: 13.177383422851562\n",
      "Epoch: 279, Batch number: 72, Loss: 18.529468536376953\n",
      "Epoch: 281, Batch number: 20, Loss: 14.457669258117676\n",
      "Epoch: 282, Batch number: 44, Loss: 13.194055557250977\n",
      "Epoch: 283, Batch number: 68, Loss: 13.809361457824707\n",
      "Epoch: 285, Batch number: 16, Loss: 12.350443840026855\n",
      "Epoch: 286, Batch number: 40, Loss: 15.305047035217285\n",
      "Epoch: 287, Batch number: 64, Loss: 10.266727447509766\n",
      "Epoch: 289, Batch number: 12, Loss: 11.91639232635498\n",
      "Epoch: 290, Batch number: 36, Loss: 12.328492164611816\n",
      "Epoch: 291, Batch number: 60, Loss: 9.406075477600098\n",
      "Epoch: 293, Batch number: 8, Loss: 16.04342269897461\n",
      "Epoch: 294, Batch number: 32, Loss: 9.556140899658203\n",
      "Epoch: 295, Batch number: 56, Loss: 11.046202659606934\n",
      "Epoch: 297, Batch number: 4, Loss: 9.452094078063965\n",
      "Epoch: 298, Batch number: 28, Loss: 8.887394905090332\n",
      "Epoch: 299, Batch number: 52, Loss: 12.173282623291016\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4400.72607421875\n",
      "Epoch: 2, Batch number: 24, Loss: 4008.604736328125\n",
      "Epoch: 3, Batch number: 48, Loss: 3412.08544921875\n",
      "Epoch: 4, Batch number: 72, Loss: 3060.03076171875\n",
      "Epoch: 6, Batch number: 20, Loss: 2788.1513671875\n",
      "Epoch: 7, Batch number: 44, Loss: 2691.09423828125\n",
      "Epoch: 8, Batch number: 68, Loss: 2616.91943359375\n",
      "Epoch: 10, Batch number: 16, Loss: 2552.683349609375\n",
      "Epoch: 11, Batch number: 40, Loss: 2462.2001953125\n",
      "Epoch: 12, Batch number: 64, Loss: 2432.574462890625\n",
      "Epoch: 14, Batch number: 12, Loss: 2218.3564453125\n",
      "Epoch: 15, Batch number: 36, Loss: 2264.32666015625\n",
      "Epoch: 16, Batch number: 60, Loss: 2249.1328125\n",
      "Epoch: 18, Batch number: 8, Loss: 2063.916748046875\n",
      "Epoch: 19, Batch number: 32, Loss: 2008.98583984375\n",
      "Epoch: 20, Batch number: 56, Loss: 1972.001220703125\n",
      "Epoch: 22, Batch number: 4, Loss: 1907.0701904296875\n",
      "Epoch: 23, Batch number: 28, Loss: 1817.647705078125\n",
      "Epoch: 24, Batch number: 52, Loss: 1849.837890625\n",
      "Epoch: 26, Batch number: 0, Loss: 1687.2216796875\n",
      "Epoch: 27, Batch number: 24, Loss: 1643.2685546875\n",
      "Epoch: 28, Batch number: 48, Loss: 1585.650146484375\n",
      "Epoch: 29, Batch number: 72, Loss: 1665.5814208984375\n",
      "Epoch: 31, Batch number: 20, Loss: 1470.1258544921875\n",
      "Epoch: 32, Batch number: 44, Loss: 1495.35205078125\n",
      "Epoch: 33, Batch number: 68, Loss: 1412.820068359375\n",
      "Epoch: 35, Batch number: 16, Loss: 1342.358642578125\n",
      "Epoch: 36, Batch number: 40, Loss: 1408.6798095703125\n",
      "Epoch: 37, Batch number: 64, Loss: 1333.53564453125\n",
      "Epoch: 39, Batch number: 12, Loss: 1298.2764892578125\n",
      "Epoch: 40, Batch number: 36, Loss: 1191.4820556640625\n",
      "Epoch: 41, Batch number: 60, Loss: 1165.4761962890625\n",
      "Epoch: 43, Batch number: 8, Loss: 1113.5257568359375\n",
      "Epoch: 44, Batch number: 32, Loss: 1056.029296875\n",
      "Epoch: 45, Batch number: 56, Loss: 1049.2939453125\n",
      "Epoch: 47, Batch number: 4, Loss: 1061.69091796875\n",
      "Epoch: 48, Batch number: 28, Loss: 974.4024047851562\n",
      "Epoch: 49, Batch number: 52, Loss: 983.3441772460938\n",
      "Epoch: 51, Batch number: 0, Loss: 943.5988159179688\n",
      "Epoch: 52, Batch number: 24, Loss: 908.6504516601562\n",
      "Epoch: 53, Batch number: 48, Loss: 934.530029296875\n",
      "Epoch: 54, Batch number: 72, Loss: 880.31103515625\n",
      "Epoch: 56, Batch number: 20, Loss: 826.7673950195312\n",
      "Epoch: 57, Batch number: 44, Loss: 771.127685546875\n",
      "Epoch: 58, Batch number: 68, Loss: 829.5343627929688\n",
      "Epoch: 60, Batch number: 16, Loss: 738.525390625\n",
      "Epoch: 61, Batch number: 40, Loss: 751.0026245117188\n",
      "Epoch: 62, Batch number: 64, Loss: 740.2389526367188\n",
      "Epoch: 64, Batch number: 12, Loss: 716.1160278320312\n",
      "Epoch: 65, Batch number: 36, Loss: 661.9736328125\n",
      "Epoch: 66, Batch number: 60, Loss: 624.4774780273438\n",
      "Epoch: 68, Batch number: 8, Loss: 637.1200561523438\n",
      "Epoch: 69, Batch number: 32, Loss: 627.3125\n",
      "Epoch: 70, Batch number: 56, Loss: 577.3663330078125\n",
      "Epoch: 72, Batch number: 4, Loss: 622.6492919921875\n",
      "Epoch: 73, Batch number: 28, Loss: 526.3284912109375\n",
      "Epoch: 74, Batch number: 52, Loss: 575.8653564453125\n",
      "Epoch: 76, Batch number: 0, Loss: 506.26324462890625\n",
      "Epoch: 77, Batch number: 24, Loss: 477.9848327636719\n",
      "Epoch: 78, Batch number: 48, Loss: 491.5787658691406\n",
      "Epoch: 79, Batch number: 72, Loss: 498.21142578125\n",
      "Epoch: 81, Batch number: 20, Loss: 469.861572265625\n",
      "Epoch: 82, Batch number: 44, Loss: 440.15966796875\n",
      "Epoch: 83, Batch number: 68, Loss: 452.64141845703125\n",
      "Epoch: 85, Batch number: 16, Loss: 385.29412841796875\n",
      "Epoch: 86, Batch number: 40, Loss: 409.80999755859375\n",
      "Epoch: 87, Batch number: 64, Loss: 391.9403991699219\n",
      "Epoch: 89, Batch number: 12, Loss: 396.6649475097656\n",
      "Epoch: 90, Batch number: 36, Loss: 370.4267578125\n",
      "Epoch: 91, Batch number: 60, Loss: 383.5087585449219\n",
      "Epoch: 93, Batch number: 8, Loss: 355.9405822753906\n",
      "Epoch: 94, Batch number: 32, Loss: 331.6507263183594\n",
      "Epoch: 95, Batch number: 56, Loss: 332.3431396484375\n",
      "Epoch: 97, Batch number: 4, Loss: 304.66180419921875\n",
      "Epoch: 98, Batch number: 28, Loss: 302.4949951171875\n",
      "Epoch: 99, Batch number: 52, Loss: 265.0064392089844\n",
      "Epoch: 101, Batch number: 0, Loss: 279.7258605957031\n",
      "Epoch: 102, Batch number: 24, Loss: 308.746337890625\n",
      "Epoch: 103, Batch number: 48, Loss: 251.24667358398438\n",
      "Epoch: 104, Batch number: 72, Loss: 272.0861511230469\n",
      "Epoch: 106, Batch number: 20, Loss: 268.3446350097656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 259.8984680175781\n",
      "Epoch: 108, Batch number: 68, Loss: 263.98974609375\n",
      "Epoch: 110, Batch number: 16, Loss: 217.49749755859375\n",
      "Epoch: 111, Batch number: 40, Loss: 248.7855224609375\n",
      "Epoch: 112, Batch number: 64, Loss: 224.36087036132812\n",
      "Epoch: 114, Batch number: 12, Loss: 191.56295776367188\n",
      "Epoch: 115, Batch number: 36, Loss: 160.35537719726562\n",
      "Epoch: 116, Batch number: 60, Loss: 190.82777404785156\n",
      "Epoch: 118, Batch number: 8, Loss: 166.2184600830078\n",
      "Epoch: 119, Batch number: 32, Loss: 165.18841552734375\n",
      "Epoch: 120, Batch number: 56, Loss: 179.68896484375\n",
      "Epoch: 122, Batch number: 4, Loss: 166.15463256835938\n",
      "Epoch: 123, Batch number: 28, Loss: 161.0220184326172\n",
      "Epoch: 124, Batch number: 52, Loss: 170.5311279296875\n",
      "Epoch: 126, Batch number: 0, Loss: 162.82603454589844\n",
      "Epoch: 127, Batch number: 24, Loss: 134.6681365966797\n",
      "Epoch: 128, Batch number: 48, Loss: 132.4602813720703\n",
      "Epoch: 129, Batch number: 72, Loss: 145.56336975097656\n",
      "Epoch: 131, Batch number: 20, Loss: 119.84562683105469\n",
      "Epoch: 132, Batch number: 44, Loss: 129.33978271484375\n",
      "Epoch: 133, Batch number: 68, Loss: 117.24018859863281\n",
      "Epoch: 135, Batch number: 16, Loss: 112.9965591430664\n",
      "Epoch: 136, Batch number: 40, Loss: 126.1849136352539\n",
      "Epoch: 137, Batch number: 64, Loss: 95.04014587402344\n",
      "Epoch: 139, Batch number: 12, Loss: 95.79090118408203\n",
      "Epoch: 140, Batch number: 36, Loss: 109.93054962158203\n",
      "Epoch: 141, Batch number: 60, Loss: 106.25554656982422\n",
      "Epoch: 143, Batch number: 8, Loss: 95.97640228271484\n",
      "Epoch: 144, Batch number: 32, Loss: 95.35443878173828\n",
      "Epoch: 145, Batch number: 56, Loss: 104.68286895751953\n",
      "Epoch: 147, Batch number: 4, Loss: 80.4938735961914\n",
      "Epoch: 148, Batch number: 28, Loss: 77.21151733398438\n",
      "Epoch: 149, Batch number: 52, Loss: 87.0797119140625\n",
      "Epoch: 151, Batch number: 0, Loss: 64.19319152832031\n",
      "Epoch: 152, Batch number: 24, Loss: 70.77818298339844\n",
      "Epoch: 153, Batch number: 48, Loss: 83.39171600341797\n",
      "Epoch: 154, Batch number: 72, Loss: 73.94627380371094\n",
      "Epoch: 156, Batch number: 20, Loss: 78.68098449707031\n",
      "Epoch: 157, Batch number: 44, Loss: 70.64958190917969\n",
      "Epoch: 158, Batch number: 68, Loss: 68.64520263671875\n",
      "Epoch: 160, Batch number: 16, Loss: 66.52400207519531\n",
      "Epoch: 161, Batch number: 40, Loss: 55.65234375\n",
      "Epoch: 162, Batch number: 64, Loss: 64.5466079711914\n",
      "Epoch: 164, Batch number: 12, Loss: 48.72895050048828\n",
      "Epoch: 165, Batch number: 36, Loss: 52.15972137451172\n",
      "Epoch: 166, Batch number: 60, Loss: 52.38555145263672\n",
      "Epoch: 168, Batch number: 8, Loss: 57.152713775634766\n",
      "Epoch: 169, Batch number: 32, Loss: 50.30683898925781\n",
      "Epoch: 170, Batch number: 56, Loss: 53.382816314697266\n",
      "Epoch: 172, Batch number: 4, Loss: 57.57273864746094\n",
      "Epoch: 173, Batch number: 28, Loss: 44.07051086425781\n",
      "Epoch: 174, Batch number: 52, Loss: 39.54932403564453\n",
      "Epoch: 176, Batch number: 0, Loss: 37.459861755371094\n",
      "Epoch: 177, Batch number: 24, Loss: 37.7349967956543\n",
      "Epoch: 178, Batch number: 48, Loss: 43.471778869628906\n",
      "Epoch: 179, Batch number: 72, Loss: 44.41600036621094\n",
      "Epoch: 181, Batch number: 20, Loss: 37.538841247558594\n",
      "Epoch: 182, Batch number: 44, Loss: 40.429542541503906\n",
      "Epoch: 183, Batch number: 68, Loss: 37.281314849853516\n",
      "Epoch: 185, Batch number: 16, Loss: 39.10432052612305\n",
      "Epoch: 186, Batch number: 40, Loss: 31.59408950805664\n",
      "Epoch: 187, Batch number: 64, Loss: 34.71550369262695\n",
      "Epoch: 189, Batch number: 12, Loss: 29.19491195678711\n",
      "Epoch: 190, Batch number: 36, Loss: 28.17847442626953\n",
      "Epoch: 191, Batch number: 60, Loss: 32.43147277832031\n",
      "Epoch: 193, Batch number: 8, Loss: 35.876304626464844\n",
      "Epoch: 194, Batch number: 32, Loss: 28.1265926361084\n",
      "Epoch: 195, Batch number: 56, Loss: 27.051071166992188\n",
      "Epoch: 197, Batch number: 4, Loss: 31.98293685913086\n",
      "Epoch: 198, Batch number: 28, Loss: 28.81739044189453\n",
      "Epoch: 199, Batch number: 52, Loss: 29.788700103759766\n",
      "Epoch: 201, Batch number: 0, Loss: 22.002105712890625\n",
      "Epoch: 202, Batch number: 24, Loss: 26.501808166503906\n",
      "Epoch: 203, Batch number: 48, Loss: 19.582077026367188\n",
      "Epoch: 204, Batch number: 72, Loss: 29.799068450927734\n",
      "Epoch: 206, Batch number: 20, Loss: 24.8548526763916\n",
      "Epoch: 207, Batch number: 44, Loss: 22.107940673828125\n",
      "Epoch: 208, Batch number: 68, Loss: 18.577423095703125\n",
      "Epoch: 210, Batch number: 16, Loss: 18.869993209838867\n",
      "Epoch: 211, Batch number: 40, Loss: 19.58987808227539\n",
      "Epoch: 212, Batch number: 64, Loss: 19.355777740478516\n",
      "Epoch: 214, Batch number: 12, Loss: 20.370590209960938\n",
      "Epoch: 215, Batch number: 36, Loss: 18.412330627441406\n",
      "Epoch: 216, Batch number: 60, Loss: 19.745258331298828\n",
      "Epoch: 218, Batch number: 8, Loss: 15.663472175598145\n",
      "Epoch: 219, Batch number: 32, Loss: 19.119407653808594\n",
      "Epoch: 220, Batch number: 56, Loss: 19.564117431640625\n",
      "Epoch: 222, Batch number: 4, Loss: 17.324392318725586\n",
      "Epoch: 223, Batch number: 28, Loss: 14.348390579223633\n",
      "Epoch: 224, Batch number: 52, Loss: 16.998348236083984\n",
      "Epoch: 226, Batch number: 0, Loss: 13.172762870788574\n",
      "Epoch: 227, Batch number: 24, Loss: 18.37234115600586\n",
      "Epoch: 228, Batch number: 48, Loss: 12.086596488952637\n",
      "Epoch: 229, Batch number: 72, Loss: 13.889071464538574\n",
      "Epoch: 231, Batch number: 20, Loss: 13.301465034484863\n",
      "Epoch: 232, Batch number: 44, Loss: 15.391751289367676\n",
      "Epoch: 233, Batch number: 68, Loss: 18.470300674438477\n",
      "Epoch: 235, Batch number: 16, Loss: 14.728302955627441\n",
      "Epoch: 236, Batch number: 40, Loss: 16.371837615966797\n",
      "Epoch: 237, Batch number: 64, Loss: 13.281126022338867\n",
      "Epoch: 239, Batch number: 12, Loss: 10.806086540222168\n",
      "Epoch: 240, Batch number: 36, Loss: 13.666576385498047\n",
      "Epoch: 241, Batch number: 60, Loss: 11.901630401611328\n",
      "Epoch: 243, Batch number: 8, Loss: 13.635412216186523\n",
      "Epoch: 244, Batch number: 32, Loss: 9.280930519104004\n",
      "Epoch: 245, Batch number: 56, Loss: 15.070236206054688\n",
      "Epoch: 247, Batch number: 4, Loss: 10.43511962890625\n",
      "Epoch: 248, Batch number: 28, Loss: 11.98906421661377\n",
      "Epoch: 249, Batch number: 52, Loss: 9.980903625488281\n",
      "Epoch: 251, Batch number: 0, Loss: 13.283364295959473\n",
      "Epoch: 252, Batch number: 24, Loss: 11.79452896118164\n",
      "Epoch: 253, Batch number: 48, Loss: 9.460603713989258\n",
      "Epoch: 254, Batch number: 72, Loss: 11.060256004333496\n",
      "Epoch: 256, Batch number: 20, Loss: 6.555545806884766\n",
      "Epoch: 257, Batch number: 44, Loss: 8.625136375427246\n",
      "Epoch: 258, Batch number: 68, Loss: 12.55703067779541\n",
      "Epoch: 260, Batch number: 16, Loss: 10.655962944030762\n",
      "Epoch: 261, Batch number: 40, Loss: 9.146756172180176\n",
      "Epoch: 262, Batch number: 64, Loss: 10.441720008850098\n",
      "Epoch: 264, Batch number: 12, Loss: 6.081452369689941\n",
      "Epoch: 265, Batch number: 36, Loss: 7.290250778198242\n",
      "Epoch: 266, Batch number: 60, Loss: 9.097063064575195\n",
      "Epoch: 268, Batch number: 8, Loss: 12.37967586517334\n",
      "Epoch: 269, Batch number: 32, Loss: 6.863914489746094\n",
      "Epoch: 270, Batch number: 56, Loss: 8.574576377868652\n",
      "Epoch: 272, Batch number: 4, Loss: 7.862842559814453\n",
      "Epoch: 273, Batch number: 28, Loss: 8.368868827819824\n",
      "Epoch: 274, Batch number: 52, Loss: 9.862810134887695\n",
      "Epoch: 276, Batch number: 0, Loss: 7.304801940917969\n",
      "Epoch: 277, Batch number: 24, Loss: 9.0183744430542\n",
      "Epoch: 278, Batch number: 48, Loss: 6.451943397521973\n",
      "Epoch: 279, Batch number: 72, Loss: 6.180658340454102\n",
      "Epoch: 281, Batch number: 20, Loss: 4.872867584228516\n",
      "Epoch: 282, Batch number: 44, Loss: 6.569301605224609\n",
      "Epoch: 283, Batch number: 68, Loss: 5.128691673278809\n",
      "Epoch: 285, Batch number: 16, Loss: 8.226880073547363\n",
      "Epoch: 286, Batch number: 40, Loss: 5.311772346496582\n",
      "Epoch: 287, Batch number: 64, Loss: 7.493412017822266\n",
      "Epoch: 289, Batch number: 12, Loss: 9.30687427520752\n",
      "Epoch: 290, Batch number: 36, Loss: 6.115796089172363\n",
      "Epoch: 291, Batch number: 60, Loss: 7.540801048278809\n",
      "Epoch: 293, Batch number: 8, Loss: 6.527083396911621\n",
      "Epoch: 294, Batch number: 32, Loss: 4.599508285522461\n",
      "Epoch: 295, Batch number: 56, Loss: 7.805275917053223\n",
      "Epoch: 297, Batch number: 4, Loss: 5.6191205978393555\n",
      "Epoch: 298, Batch number: 28, Loss: 4.085193634033203\n",
      "Epoch: 299, Batch number: 52, Loss: 8.874276161193848\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4409.37890625\n",
      "Epoch: 2, Batch number: 24, Loss: 3838.105224609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch number: 48, Loss: 3122.087646484375\n",
      "Epoch: 4, Batch number: 72, Loss: 2942.25732421875\n",
      "Epoch: 6, Batch number: 20, Loss: 2825.69775390625\n",
      "Epoch: 7, Batch number: 44, Loss: 2627.605712890625\n",
      "Epoch: 8, Batch number: 68, Loss: 2428.84130859375\n",
      "Epoch: 10, Batch number: 16, Loss: 2364.825927734375\n",
      "Epoch: 11, Batch number: 40, Loss: 2172.73388671875\n",
      "Epoch: 12, Batch number: 64, Loss: 2168.682373046875\n",
      "Epoch: 14, Batch number: 12, Loss: 1988.853271484375\n",
      "Epoch: 15, Batch number: 36, Loss: 1999.975341796875\n",
      "Epoch: 16, Batch number: 60, Loss: 1861.403564453125\n",
      "Epoch: 18, Batch number: 8, Loss: 1730.222900390625\n",
      "Epoch: 19, Batch number: 32, Loss: 1738.725830078125\n",
      "Epoch: 20, Batch number: 56, Loss: 1629.88330078125\n",
      "Epoch: 22, Batch number: 4, Loss: 1586.0408935546875\n",
      "Epoch: 23, Batch number: 28, Loss: 1530.6561279296875\n",
      "Epoch: 24, Batch number: 52, Loss: 1464.975341796875\n",
      "Epoch: 26, Batch number: 0, Loss: 1374.746337890625\n",
      "Epoch: 27, Batch number: 24, Loss: 1341.978759765625\n",
      "Epoch: 28, Batch number: 48, Loss: 1244.6400146484375\n",
      "Epoch: 29, Batch number: 72, Loss: 1217.354736328125\n",
      "Epoch: 31, Batch number: 20, Loss: 1131.248291015625\n",
      "Epoch: 32, Batch number: 44, Loss: 1170.4085693359375\n",
      "Epoch: 33, Batch number: 68, Loss: 1069.12255859375\n",
      "Epoch: 35, Batch number: 16, Loss: 983.9415283203125\n",
      "Epoch: 36, Batch number: 40, Loss: 1038.9805908203125\n",
      "Epoch: 37, Batch number: 64, Loss: 952.1264038085938\n",
      "Epoch: 39, Batch number: 12, Loss: 872.0647583007812\n",
      "Epoch: 40, Batch number: 36, Loss: 913.1326293945312\n",
      "Epoch: 41, Batch number: 60, Loss: 828.1948852539062\n",
      "Epoch: 43, Batch number: 8, Loss: 834.5489501953125\n",
      "Epoch: 44, Batch number: 32, Loss: 738.959716796875\n",
      "Epoch: 45, Batch number: 56, Loss: 779.487060546875\n",
      "Epoch: 47, Batch number: 4, Loss: 688.6913452148438\n",
      "Epoch: 48, Batch number: 28, Loss: 692.2965087890625\n",
      "Epoch: 49, Batch number: 52, Loss: 625.51025390625\n",
      "Epoch: 51, Batch number: 0, Loss: 596.0988159179688\n",
      "Epoch: 52, Batch number: 24, Loss: 604.5223388671875\n",
      "Epoch: 53, Batch number: 48, Loss: 611.9332885742188\n",
      "Epoch: 54, Batch number: 72, Loss: 569.9189453125\n",
      "Epoch: 56, Batch number: 20, Loss: 545.7453002929688\n",
      "Epoch: 57, Batch number: 44, Loss: 545.7310791015625\n",
      "Epoch: 58, Batch number: 68, Loss: 499.59478759765625\n",
      "Epoch: 60, Batch number: 16, Loss: 491.69964599609375\n",
      "Epoch: 61, Batch number: 40, Loss: 458.0018310546875\n",
      "Epoch: 62, Batch number: 64, Loss: 456.11627197265625\n",
      "Epoch: 64, Batch number: 12, Loss: 439.03021240234375\n",
      "Epoch: 65, Batch number: 36, Loss: 399.5427551269531\n",
      "Epoch: 66, Batch number: 60, Loss: 387.6155700683594\n",
      "Epoch: 68, Batch number: 8, Loss: 340.45440673828125\n",
      "Epoch: 69, Batch number: 32, Loss: 332.7228088378906\n",
      "Epoch: 70, Batch number: 56, Loss: 345.5476989746094\n",
      "Epoch: 72, Batch number: 4, Loss: 291.7143249511719\n",
      "Epoch: 73, Batch number: 28, Loss: 288.7432861328125\n",
      "Epoch: 74, Batch number: 52, Loss: 317.19610595703125\n",
      "Epoch: 76, Batch number: 0, Loss: 261.1590270996094\n",
      "Epoch: 77, Batch number: 24, Loss: 252.74278259277344\n",
      "Epoch: 78, Batch number: 48, Loss: 250.2937774658203\n",
      "Epoch: 79, Batch number: 72, Loss: 271.2020568847656\n",
      "Epoch: 81, Batch number: 20, Loss: 220.28933715820312\n",
      "Epoch: 82, Batch number: 44, Loss: 196.573486328125\n",
      "Epoch: 83, Batch number: 68, Loss: 207.64578247070312\n",
      "Epoch: 85, Batch number: 16, Loss: 196.9392852783203\n",
      "Epoch: 86, Batch number: 40, Loss: 220.49752807617188\n",
      "Epoch: 87, Batch number: 64, Loss: 182.51568603515625\n",
      "Epoch: 89, Batch number: 12, Loss: 190.74423217773438\n",
      "Epoch: 90, Batch number: 36, Loss: 178.43446350097656\n",
      "Epoch: 91, Batch number: 60, Loss: 178.9926300048828\n",
      "Epoch: 93, Batch number: 8, Loss: 147.86883544921875\n",
      "Epoch: 94, Batch number: 32, Loss: 157.86343383789062\n",
      "Epoch: 95, Batch number: 56, Loss: 138.91622924804688\n",
      "Epoch: 97, Batch number: 4, Loss: 143.7450408935547\n",
      "Epoch: 98, Batch number: 28, Loss: 153.93507385253906\n",
      "Epoch: 99, Batch number: 52, Loss: 129.57150268554688\n",
      "Epoch: 101, Batch number: 0, Loss: 110.82090759277344\n",
      "Epoch: 102, Batch number: 24, Loss: 121.71277618408203\n",
      "Epoch: 103, Batch number: 48, Loss: 119.06092071533203\n",
      "Epoch: 104, Batch number: 72, Loss: 111.5672836303711\n",
      "Epoch: 106, Batch number: 20, Loss: 89.02544403076172\n",
      "Epoch: 107, Batch number: 44, Loss: 121.57383728027344\n",
      "Epoch: 108, Batch number: 68, Loss: 103.78307342529297\n",
      "Epoch: 110, Batch number: 16, Loss: 84.22615814208984\n",
      "Epoch: 111, Batch number: 40, Loss: 82.11408996582031\n",
      "Epoch: 112, Batch number: 64, Loss: 90.84668731689453\n",
      "Epoch: 114, Batch number: 12, Loss: 78.3115234375\n",
      "Epoch: 115, Batch number: 36, Loss: 84.51496887207031\n",
      "Epoch: 116, Batch number: 60, Loss: 71.10830688476562\n",
      "Epoch: 118, Batch number: 8, Loss: 61.947391510009766\n",
      "Epoch: 119, Batch number: 32, Loss: 66.9862289428711\n",
      "Epoch: 120, Batch number: 56, Loss: 70.00730895996094\n",
      "Epoch: 122, Batch number: 4, Loss: 68.78172302246094\n",
      "Epoch: 123, Batch number: 28, Loss: 76.17636108398438\n",
      "Epoch: 124, Batch number: 52, Loss: 66.80467224121094\n",
      "Epoch: 126, Batch number: 0, Loss: 57.44412612915039\n",
      "Epoch: 127, Batch number: 24, Loss: 49.21787643432617\n",
      "Epoch: 128, Batch number: 48, Loss: 48.133148193359375\n",
      "Epoch: 129, Batch number: 72, Loss: 47.348548889160156\n",
      "Epoch: 131, Batch number: 20, Loss: 41.636756896972656\n",
      "Epoch: 132, Batch number: 44, Loss: 51.44730758666992\n",
      "Epoch: 133, Batch number: 68, Loss: 44.7498893737793\n",
      "Epoch: 135, Batch number: 16, Loss: 48.22710418701172\n",
      "Epoch: 136, Batch number: 40, Loss: 36.437686920166016\n",
      "Epoch: 137, Batch number: 64, Loss: 41.311519622802734\n",
      "Epoch: 139, Batch number: 12, Loss: 38.642364501953125\n",
      "Epoch: 140, Batch number: 36, Loss: 39.64848327636719\n",
      "Epoch: 141, Batch number: 60, Loss: 33.59696960449219\n",
      "Epoch: 143, Batch number: 8, Loss: 34.905391693115234\n",
      "Epoch: 144, Batch number: 32, Loss: 37.035980224609375\n",
      "Epoch: 145, Batch number: 56, Loss: 40.25601577758789\n",
      "Epoch: 147, Batch number: 4, Loss: 36.414710998535156\n",
      "Epoch: 148, Batch number: 28, Loss: 34.83963394165039\n",
      "Epoch: 149, Batch number: 52, Loss: 33.504119873046875\n",
      "Epoch: 151, Batch number: 0, Loss: 29.529315948486328\n",
      "Epoch: 152, Batch number: 24, Loss: 28.195293426513672\n",
      "Epoch: 153, Batch number: 48, Loss: 28.008811950683594\n",
      "Epoch: 154, Batch number: 72, Loss: 32.377410888671875\n",
      "Epoch: 156, Batch number: 20, Loss: 23.178543090820312\n",
      "Epoch: 157, Batch number: 44, Loss: 25.873205184936523\n",
      "Epoch: 158, Batch number: 68, Loss: 27.848783493041992\n",
      "Epoch: 160, Batch number: 16, Loss: 23.668743133544922\n",
      "Epoch: 161, Batch number: 40, Loss: 28.83928680419922\n",
      "Epoch: 162, Batch number: 64, Loss: 20.846111297607422\n",
      "Epoch: 164, Batch number: 12, Loss: 17.965618133544922\n",
      "Epoch: 165, Batch number: 36, Loss: 23.918331146240234\n",
      "Epoch: 166, Batch number: 60, Loss: 18.69305419921875\n",
      "Epoch: 168, Batch number: 8, Loss: 22.462039947509766\n",
      "Epoch: 169, Batch number: 32, Loss: 17.359800338745117\n",
      "Epoch: 170, Batch number: 56, Loss: 19.04316520690918\n",
      "Epoch: 172, Batch number: 4, Loss: 25.128223419189453\n",
      "Epoch: 173, Batch number: 28, Loss: 18.537338256835938\n",
      "Epoch: 174, Batch number: 52, Loss: 19.05729866027832\n",
      "Epoch: 176, Batch number: 0, Loss: 17.375476837158203\n",
      "Epoch: 177, Batch number: 24, Loss: 20.228445053100586\n",
      "Epoch: 178, Batch number: 48, Loss: 17.251911163330078\n",
      "Epoch: 179, Batch number: 72, Loss: 19.69073486328125\n",
      "Epoch: 181, Batch number: 20, Loss: 12.602249145507812\n",
      "Epoch: 182, Batch number: 44, Loss: 17.495662689208984\n",
      "Epoch: 183, Batch number: 68, Loss: 13.887998580932617\n",
      "Epoch: 185, Batch number: 16, Loss: 14.57180404663086\n",
      "Epoch: 186, Batch number: 40, Loss: 12.101454734802246\n",
      "Epoch: 187, Batch number: 64, Loss: 15.16667652130127\n",
      "Epoch: 189, Batch number: 12, Loss: 12.234380722045898\n",
      "Epoch: 190, Batch number: 36, Loss: 12.655386924743652\n",
      "Epoch: 191, Batch number: 60, Loss: 12.637837409973145\n",
      "Epoch: 193, Batch number: 8, Loss: 16.68861198425293\n",
      "Epoch: 194, Batch number: 32, Loss: 10.697534561157227\n",
      "Epoch: 195, Batch number: 56, Loss: 11.237449645996094\n",
      "Epoch: 197, Batch number: 4, Loss: 8.59386920928955\n",
      "Epoch: 198, Batch number: 28, Loss: 12.883792877197266\n",
      "Epoch: 199, Batch number: 52, Loss: 13.554069519042969\n",
      "Epoch: 201, Batch number: 0, Loss: 10.518478393554688\n",
      "Epoch: 202, Batch number: 24, Loss: 10.55962085723877\n",
      "Epoch: 203, Batch number: 48, Loss: 12.96894359588623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204, Batch number: 72, Loss: 11.136672019958496\n",
      "Epoch: 206, Batch number: 20, Loss: 10.824405670166016\n",
      "Epoch: 207, Batch number: 44, Loss: 11.637410163879395\n",
      "Epoch: 208, Batch number: 68, Loss: 12.551013946533203\n",
      "Epoch: 210, Batch number: 16, Loss: 6.675990104675293\n",
      "Epoch: 211, Batch number: 40, Loss: 12.927398681640625\n",
      "Epoch: 212, Batch number: 64, Loss: 11.77311897277832\n",
      "Epoch: 214, Batch number: 12, Loss: 6.189859390258789\n",
      "Epoch: 215, Batch number: 36, Loss: 8.977505683898926\n",
      "Epoch: 216, Batch number: 60, Loss: 11.990294456481934\n",
      "Epoch: 218, Batch number: 8, Loss: 9.013001441955566\n",
      "Epoch: 219, Batch number: 32, Loss: 7.7668657302856445\n",
      "Epoch: 220, Batch number: 56, Loss: 9.720598220825195\n",
      "Epoch: 222, Batch number: 4, Loss: 10.605122566223145\n",
      "Epoch: 223, Batch number: 28, Loss: 7.936684608459473\n",
      "Epoch: 224, Batch number: 52, Loss: 5.353494644165039\n",
      "Epoch: 226, Batch number: 0, Loss: 8.572331428527832\n",
      "Epoch: 227, Batch number: 24, Loss: 6.365522384643555\n",
      "Epoch: 228, Batch number: 48, Loss: 7.069794654846191\n",
      "Epoch: 229, Batch number: 72, Loss: 11.52975082397461\n",
      "Epoch: 231, Batch number: 20, Loss: 7.4346513748168945\n",
      "Epoch: 232, Batch number: 44, Loss: 5.07545280456543\n",
      "Epoch: 233, Batch number: 68, Loss: 5.64820671081543\n",
      "Epoch: 235, Batch number: 16, Loss: 10.452199935913086\n",
      "Epoch: 236, Batch number: 40, Loss: 9.130568504333496\n",
      "Epoch: 237, Batch number: 64, Loss: 6.79720401763916\n",
      "Epoch: 239, Batch number: 12, Loss: 7.137531280517578\n",
      "Epoch: 240, Batch number: 36, Loss: 4.350971221923828\n",
      "Epoch: 241, Batch number: 60, Loss: 6.330869674682617\n",
      "Epoch: 243, Batch number: 8, Loss: 5.107721328735352\n",
      "Epoch: 244, Batch number: 32, Loss: 9.74916934967041\n",
      "Epoch: 245, Batch number: 56, Loss: 7.823244094848633\n",
      "Epoch: 247, Batch number: 4, Loss: 4.211820602416992\n",
      "Epoch: 248, Batch number: 28, Loss: 8.483510971069336\n",
      "Epoch: 249, Batch number: 52, Loss: 8.09351921081543\n",
      "Epoch: 251, Batch number: 0, Loss: 7.869446754455566\n",
      "Epoch: 252, Batch number: 24, Loss: 6.013267517089844\n",
      "Epoch: 253, Batch number: 48, Loss: 6.467315673828125\n",
      "Epoch: 254, Batch number: 72, Loss: 5.236481666564941\n",
      "Epoch: 256, Batch number: 20, Loss: 8.429932594299316\n",
      "Epoch: 257, Batch number: 44, Loss: 8.146103858947754\n",
      "Epoch: 258, Batch number: 68, Loss: 5.661579132080078\n",
      "Epoch: 260, Batch number: 16, Loss: 8.442770957946777\n",
      "Epoch: 261, Batch number: 40, Loss: 3.8708581924438477\n",
      "Epoch: 262, Batch number: 64, Loss: 8.341264724731445\n",
      "Epoch: 264, Batch number: 12, Loss: 4.8718976974487305\n",
      "Epoch: 265, Batch number: 36, Loss: 7.42227840423584\n",
      "Epoch: 266, Batch number: 60, Loss: 5.846464157104492\n",
      "Epoch: 268, Batch number: 8, Loss: 7.467902183532715\n",
      "Epoch: 269, Batch number: 32, Loss: 7.813105583190918\n",
      "Epoch: 270, Batch number: 56, Loss: 5.778863906860352\n",
      "Epoch: 272, Batch number: 4, Loss: 5.65484619140625\n",
      "Epoch: 273, Batch number: 28, Loss: 8.963753700256348\n",
      "Epoch: 274, Batch number: 52, Loss: 6.717350006103516\n",
      "Epoch: 276, Batch number: 0, Loss: 3.155702590942383\n",
      "Epoch: 277, Batch number: 24, Loss: 4.837923049926758\n",
      "Epoch: 278, Batch number: 48, Loss: 6.7446441650390625\n",
      "Epoch: 279, Batch number: 72, Loss: 6.199680328369141\n",
      "Epoch: 281, Batch number: 20, Loss: 3.4744319915771484\n",
      "Epoch: 282, Batch number: 44, Loss: 6.311836242675781\n",
      "Epoch: 283, Batch number: 68, Loss: 4.766031265258789\n",
      "Epoch: 285, Batch number: 16, Loss: 3.9206886291503906\n",
      "Epoch: 286, Batch number: 40, Loss: 6.604113578796387\n",
      "Epoch: 287, Batch number: 64, Loss: 2.194255828857422\n",
      "Epoch: 289, Batch number: 12, Loss: 3.0491628646850586\n",
      "Epoch: 290, Batch number: 36, Loss: 4.012406349182129\n",
      "Epoch: 291, Batch number: 60, Loss: 7.20890998840332\n",
      "Epoch: 293, Batch number: 8, Loss: 5.898388862609863\n",
      "Epoch: 294, Batch number: 32, Loss: 5.945703506469727\n",
      "Epoch: 295, Batch number: 56, Loss: 1.189615249633789\n",
      "Epoch: 297, Batch number: 4, Loss: 1.5231800079345703\n",
      "Epoch: 298, Batch number: 28, Loss: 5.797287940979004\n",
      "Epoch: 299, Batch number: 52, Loss: 3.257810592651367\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4398.6455078125\n",
      "Epoch: 2, Batch number: 24, Loss: 3688.234375\n",
      "Epoch: 3, Batch number: 48, Loss: 3176.182861328125\n",
      "Epoch: 4, Batch number: 72, Loss: 2673.701904296875\n",
      "Epoch: 6, Batch number: 20, Loss: 2640.157958984375\n",
      "Epoch: 7, Batch number: 44, Loss: 2438.981201171875\n",
      "Epoch: 8, Batch number: 68, Loss: 2348.03076171875\n",
      "Epoch: 10, Batch number: 16, Loss: 2166.291259765625\n",
      "Epoch: 11, Batch number: 40, Loss: 2081.24169921875\n",
      "Epoch: 12, Batch number: 64, Loss: 1921.9715576171875\n",
      "Epoch: 14, Batch number: 12, Loss: 1771.183349609375\n",
      "Epoch: 15, Batch number: 36, Loss: 1722.396484375\n",
      "Epoch: 16, Batch number: 60, Loss: 1664.0223388671875\n",
      "Epoch: 18, Batch number: 8, Loss: 1496.7125244140625\n",
      "Epoch: 19, Batch number: 32, Loss: 1369.67333984375\n",
      "Epoch: 20, Batch number: 56, Loss: 1376.4906005859375\n",
      "Epoch: 22, Batch number: 4, Loss: 1246.3043212890625\n",
      "Epoch: 23, Batch number: 28, Loss: 1236.0228271484375\n",
      "Epoch: 24, Batch number: 52, Loss: 1197.7108154296875\n",
      "Epoch: 26, Batch number: 0, Loss: 1085.8419189453125\n",
      "Epoch: 27, Batch number: 24, Loss: 1062.9886474609375\n",
      "Epoch: 28, Batch number: 48, Loss: 1022.6741333007812\n",
      "Epoch: 29, Batch number: 72, Loss: 991.908447265625\n",
      "Epoch: 31, Batch number: 20, Loss: 954.6780395507812\n",
      "Epoch: 32, Batch number: 44, Loss: 872.6560668945312\n",
      "Epoch: 33, Batch number: 68, Loss: 858.8772583007812\n",
      "Epoch: 35, Batch number: 16, Loss: 794.1199340820312\n",
      "Epoch: 36, Batch number: 40, Loss: 798.4812622070312\n",
      "Epoch: 37, Batch number: 64, Loss: 714.2977905273438\n",
      "Epoch: 39, Batch number: 12, Loss: 639.4437255859375\n",
      "Epoch: 40, Batch number: 36, Loss: 669.2923583984375\n",
      "Epoch: 41, Batch number: 60, Loss: 664.9507446289062\n",
      "Epoch: 43, Batch number: 8, Loss: 593.4598388671875\n",
      "Epoch: 44, Batch number: 32, Loss: 617.7364501953125\n",
      "Epoch: 45, Batch number: 56, Loss: 549.4432983398438\n",
      "Epoch: 47, Batch number: 4, Loss: 487.51129150390625\n",
      "Epoch: 48, Batch number: 28, Loss: 476.4620666503906\n",
      "Epoch: 49, Batch number: 52, Loss: 499.5751037597656\n",
      "Epoch: 51, Batch number: 0, Loss: 434.2421875\n",
      "Epoch: 52, Batch number: 24, Loss: 420.07916259765625\n",
      "Epoch: 53, Batch number: 48, Loss: 364.7372131347656\n",
      "Epoch: 54, Batch number: 72, Loss: 370.1606140136719\n",
      "Epoch: 56, Batch number: 20, Loss: 349.093017578125\n",
      "Epoch: 57, Batch number: 44, Loss: 354.93316650390625\n",
      "Epoch: 58, Batch number: 68, Loss: 310.0875244140625\n",
      "Epoch: 60, Batch number: 16, Loss: 308.9118347167969\n",
      "Epoch: 61, Batch number: 40, Loss: 305.8042907714844\n",
      "Epoch: 62, Batch number: 64, Loss: 259.4446105957031\n",
      "Epoch: 64, Batch number: 12, Loss: 273.8966064453125\n",
      "Epoch: 65, Batch number: 36, Loss: 252.2321319580078\n",
      "Epoch: 66, Batch number: 60, Loss: 255.6464385986328\n",
      "Epoch: 68, Batch number: 8, Loss: 223.78555297851562\n",
      "Epoch: 69, Batch number: 32, Loss: 227.89463806152344\n",
      "Epoch: 70, Batch number: 56, Loss: 205.7746124267578\n",
      "Epoch: 72, Batch number: 4, Loss: 190.1925506591797\n",
      "Epoch: 73, Batch number: 28, Loss: 170.42889404296875\n",
      "Epoch: 74, Batch number: 52, Loss: 164.16192626953125\n",
      "Epoch: 76, Batch number: 0, Loss: 153.09744262695312\n",
      "Epoch: 77, Batch number: 24, Loss: 160.42413330078125\n",
      "Epoch: 78, Batch number: 48, Loss: 155.22825622558594\n",
      "Epoch: 79, Batch number: 72, Loss: 145.14498901367188\n",
      "Epoch: 81, Batch number: 20, Loss: 152.2819366455078\n",
      "Epoch: 82, Batch number: 44, Loss: 137.63250732421875\n",
      "Epoch: 83, Batch number: 68, Loss: 117.98267364501953\n",
      "Epoch: 85, Batch number: 16, Loss: 132.75184631347656\n",
      "Epoch: 86, Batch number: 40, Loss: 110.39881134033203\n",
      "Epoch: 87, Batch number: 64, Loss: 97.82829284667969\n",
      "Epoch: 89, Batch number: 12, Loss: 99.53617095947266\n",
      "Epoch: 90, Batch number: 36, Loss: 93.42390441894531\n",
      "Epoch: 91, Batch number: 60, Loss: 89.30374145507812\n",
      "Epoch: 93, Batch number: 8, Loss: 81.93709564208984\n",
      "Epoch: 94, Batch number: 32, Loss: 82.42937469482422\n",
      "Epoch: 95, Batch number: 56, Loss: 79.6572265625\n",
      "Epoch: 97, Batch number: 4, Loss: 75.23098754882812\n",
      "Epoch: 98, Batch number: 28, Loss: 77.11930847167969\n",
      "Epoch: 99, Batch number: 52, Loss: 59.289939880371094\n",
      "Epoch: 101, Batch number: 0, Loss: 69.85044860839844\n",
      "Epoch: 102, Batch number: 24, Loss: 57.693359375\n",
      "Epoch: 103, Batch number: 48, Loss: 63.45575714111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104, Batch number: 72, Loss: 72.09943389892578\n",
      "Epoch: 106, Batch number: 20, Loss: 48.7333984375\n",
      "Epoch: 107, Batch number: 44, Loss: 66.18826293945312\n",
      "Epoch: 108, Batch number: 68, Loss: 50.69942092895508\n",
      "Epoch: 110, Batch number: 16, Loss: 41.49842071533203\n",
      "Epoch: 111, Batch number: 40, Loss: 52.50600051879883\n",
      "Epoch: 112, Batch number: 64, Loss: 44.24965286254883\n",
      "Epoch: 114, Batch number: 12, Loss: 43.9984245300293\n",
      "Epoch: 115, Batch number: 36, Loss: 40.07708740234375\n",
      "Epoch: 116, Batch number: 60, Loss: 39.65165328979492\n",
      "Epoch: 118, Batch number: 8, Loss: 38.87590789794922\n",
      "Epoch: 119, Batch number: 32, Loss: 33.17747116088867\n",
      "Epoch: 120, Batch number: 56, Loss: 38.57463073730469\n",
      "Epoch: 122, Batch number: 4, Loss: 32.496421813964844\n",
      "Epoch: 123, Batch number: 28, Loss: 35.459129333496094\n",
      "Epoch: 124, Batch number: 52, Loss: 35.06310272216797\n",
      "Epoch: 126, Batch number: 0, Loss: 31.36053466796875\n",
      "Epoch: 127, Batch number: 24, Loss: 34.8677864074707\n",
      "Epoch: 128, Batch number: 48, Loss: 27.749601364135742\n",
      "Epoch: 129, Batch number: 72, Loss: 30.27698516845703\n",
      "Epoch: 131, Batch number: 20, Loss: 26.93288230895996\n",
      "Epoch: 132, Batch number: 44, Loss: 28.17193603515625\n",
      "Epoch: 133, Batch number: 68, Loss: 28.97244644165039\n",
      "Epoch: 135, Batch number: 16, Loss: 24.114158630371094\n",
      "Epoch: 136, Batch number: 40, Loss: 29.727577209472656\n",
      "Epoch: 137, Batch number: 64, Loss: 23.369277954101562\n",
      "Epoch: 139, Batch number: 12, Loss: 18.407676696777344\n",
      "Epoch: 140, Batch number: 36, Loss: 22.27536964416504\n",
      "Epoch: 141, Batch number: 60, Loss: 25.83722686767578\n",
      "Epoch: 143, Batch number: 8, Loss: 19.977672576904297\n",
      "Epoch: 144, Batch number: 32, Loss: 18.738357543945312\n",
      "Epoch: 145, Batch number: 56, Loss: 20.96357536315918\n",
      "Epoch: 147, Batch number: 4, Loss: 15.935990333557129\n",
      "Epoch: 148, Batch number: 28, Loss: 16.109516143798828\n",
      "Epoch: 149, Batch number: 52, Loss: 18.920265197753906\n",
      "Epoch: 151, Batch number: 0, Loss: 18.301475524902344\n",
      "Epoch: 152, Batch number: 24, Loss: 15.474392890930176\n",
      "Epoch: 153, Batch number: 48, Loss: 18.31090545654297\n",
      "Epoch: 154, Batch number: 72, Loss: 19.28346061706543\n",
      "Epoch: 156, Batch number: 20, Loss: 15.930082321166992\n",
      "Epoch: 157, Batch number: 44, Loss: 23.76769256591797\n",
      "Epoch: 158, Batch number: 68, Loss: 15.780664443969727\n",
      "Epoch: 160, Batch number: 16, Loss: 18.457393646240234\n",
      "Epoch: 161, Batch number: 40, Loss: 14.21709156036377\n",
      "Epoch: 162, Batch number: 64, Loss: 14.19058609008789\n",
      "Epoch: 164, Batch number: 12, Loss: 11.84253978729248\n",
      "Epoch: 165, Batch number: 36, Loss: 13.678585052490234\n",
      "Epoch: 166, Batch number: 60, Loss: 13.102499961853027\n",
      "Epoch: 168, Batch number: 8, Loss: 10.758899688720703\n",
      "Epoch: 169, Batch number: 32, Loss: 9.578712463378906\n",
      "Epoch: 170, Batch number: 56, Loss: 10.65967845916748\n",
      "Epoch: 172, Batch number: 4, Loss: 10.022224426269531\n",
      "Epoch: 173, Batch number: 28, Loss: 14.879668235778809\n",
      "Epoch: 174, Batch number: 52, Loss: 12.603581428527832\n",
      "Epoch: 176, Batch number: 0, Loss: 9.333070755004883\n",
      "Epoch: 177, Batch number: 24, Loss: 11.528953552246094\n",
      "Epoch: 178, Batch number: 48, Loss: 12.89370059967041\n",
      "Epoch: 179, Batch number: 72, Loss: 16.55245018005371\n",
      "Epoch: 181, Batch number: 20, Loss: 9.290861129760742\n",
      "Epoch: 182, Batch number: 44, Loss: 10.982551574707031\n",
      "Epoch: 183, Batch number: 68, Loss: 12.110641479492188\n",
      "Epoch: 185, Batch number: 16, Loss: 10.596456527709961\n",
      "Epoch: 186, Batch number: 40, Loss: 9.121541976928711\n",
      "Epoch: 187, Batch number: 64, Loss: 9.166818618774414\n",
      "Epoch: 189, Batch number: 12, Loss: 9.334778785705566\n",
      "Epoch: 190, Batch number: 36, Loss: 8.163702011108398\n",
      "Epoch: 191, Batch number: 60, Loss: 9.0816011428833\n",
      "Epoch: 193, Batch number: 8, Loss: 8.566685676574707\n",
      "Epoch: 194, Batch number: 32, Loss: 6.329310417175293\n",
      "Epoch: 195, Batch number: 56, Loss: 7.2461090087890625\n",
      "Epoch: 197, Batch number: 4, Loss: 8.161062240600586\n",
      "Epoch: 198, Batch number: 28, Loss: 13.254863739013672\n",
      "Epoch: 199, Batch number: 52, Loss: 7.207958221435547\n",
      "Epoch: 201, Batch number: 0, Loss: 6.027183532714844\n",
      "Epoch: 202, Batch number: 24, Loss: 8.657832145690918\n",
      "Epoch: 203, Batch number: 48, Loss: 9.433699607849121\n",
      "Epoch: 204, Batch number: 72, Loss: 7.0541181564331055\n",
      "Epoch: 206, Batch number: 20, Loss: 7.198513984680176\n",
      "Epoch: 207, Batch number: 44, Loss: 10.655375480651855\n",
      "Epoch: 208, Batch number: 68, Loss: 6.532203674316406\n",
      "Epoch: 210, Batch number: 16, Loss: 7.826546669006348\n",
      "Epoch: 211, Batch number: 40, Loss: 5.678755760192871\n",
      "Epoch: 212, Batch number: 64, Loss: 9.343561172485352\n",
      "Epoch: 214, Batch number: 12, Loss: 4.772577285766602\n",
      "Epoch: 215, Batch number: 36, Loss: 8.128437995910645\n",
      "Epoch: 216, Batch number: 60, Loss: 8.509326934814453\n",
      "Epoch: 218, Batch number: 8, Loss: 5.531826019287109\n",
      "Epoch: 219, Batch number: 32, Loss: 8.134668350219727\n",
      "Epoch: 220, Batch number: 56, Loss: 6.2418413162231445\n",
      "Epoch: 222, Batch number: 4, Loss: 6.338040351867676\n",
      "Epoch: 223, Batch number: 28, Loss: 2.1492815017700195\n",
      "Epoch: 224, Batch number: 52, Loss: 8.98510456085205\n",
      "Epoch: 226, Batch number: 0, Loss: 8.02088451385498\n",
      "Epoch: 227, Batch number: 24, Loss: 6.574522018432617\n",
      "Epoch: 228, Batch number: 48, Loss: 4.8497724533081055\n",
      "Epoch: 229, Batch number: 72, Loss: 9.160890579223633\n",
      "Epoch: 231, Batch number: 20, Loss: 2.6695117950439453\n",
      "Epoch: 232, Batch number: 44, Loss: 4.410346031188965\n",
      "Epoch: 233, Batch number: 68, Loss: 6.779618263244629\n",
      "Epoch: 235, Batch number: 16, Loss: 4.3679914474487305\n",
      "Epoch: 236, Batch number: 40, Loss: 5.552621841430664\n",
      "Epoch: 237, Batch number: 64, Loss: 5.258296966552734\n",
      "Epoch: 239, Batch number: 12, Loss: 3.3574466705322266\n",
      "Epoch: 240, Batch number: 36, Loss: 6.991143226623535\n",
      "Epoch: 241, Batch number: 60, Loss: 6.334425926208496\n",
      "Epoch: 243, Batch number: 8, Loss: 3.633096694946289\n",
      "Epoch: 244, Batch number: 32, Loss: 4.845790863037109\n",
      "Epoch: 245, Batch number: 56, Loss: 4.612375259399414\n",
      "Epoch: 247, Batch number: 4, Loss: 3.649500846862793\n",
      "Epoch: 248, Batch number: 28, Loss: 3.1374082565307617\n",
      "Epoch: 249, Batch number: 52, Loss: 3.4515209197998047\n",
      "Epoch: 251, Batch number: 0, Loss: 4.230886459350586\n",
      "Epoch: 252, Batch number: 24, Loss: 5.433134078979492\n",
      "Epoch: 253, Batch number: 48, Loss: 7.847846984863281\n",
      "Epoch: 254, Batch number: 72, Loss: 4.934256553649902\n",
      "Epoch: 256, Batch number: 20, Loss: 3.533980369567871\n",
      "Epoch: 257, Batch number: 44, Loss: 2.7725887298583984\n",
      "Epoch: 258, Batch number: 68, Loss: 4.085318565368652\n",
      "Epoch: 260, Batch number: 16, Loss: 3.045001983642578\n",
      "Epoch: 261, Batch number: 40, Loss: 4.758103370666504\n",
      "Epoch: 262, Batch number: 64, Loss: 5.645882606506348\n",
      "Epoch: 264, Batch number: 12, Loss: 1.8742265701293945\n",
      "Epoch: 265, Batch number: 36, Loss: 5.499436378479004\n",
      "Epoch: 266, Batch number: 60, Loss: 8.167813301086426\n",
      "Epoch: 268, Batch number: 8, Loss: 3.943767547607422\n",
      "Epoch: 269, Batch number: 32, Loss: 3.829143524169922\n",
      "Epoch: 270, Batch number: 56, Loss: 6.462102890014648\n",
      "Epoch: 272, Batch number: 4, Loss: 1.6455020904541016\n",
      "Epoch: 273, Batch number: 28, Loss: 2.220004081726074\n",
      "Epoch: 274, Batch number: 52, Loss: 4.1867780685424805\n",
      "Epoch: 276, Batch number: 0, Loss: 4.015568733215332\n",
      "Epoch: 277, Batch number: 24, Loss: 4.016592979431152\n",
      "Epoch: 278, Batch number: 48, Loss: 2.7751617431640625\n",
      "Epoch: 279, Batch number: 72, Loss: 2.8914852142333984\n",
      "Epoch: 281, Batch number: 20, Loss: 5.300400733947754\n",
      "Epoch: 282, Batch number: 44, Loss: 3.4129161834716797\n",
      "Epoch: 283, Batch number: 68, Loss: 3.3375091552734375\n",
      "Epoch: 285, Batch number: 16, Loss: 2.5075931549072266\n",
      "Epoch: 286, Batch number: 40, Loss: 2.4790658950805664\n",
      "Epoch: 287, Batch number: 64, Loss: 4.09879207611084\n",
      "Epoch: 289, Batch number: 12, Loss: 4.6377058029174805\n",
      "Epoch: 290, Batch number: 36, Loss: 7.658198356628418\n",
      "Epoch: 291, Batch number: 60, Loss: 2.7858924865722656\n",
      "Epoch: 293, Batch number: 8, Loss: 4.574545860290527\n",
      "Epoch: 294, Batch number: 32, Loss: 5.173717498779297\n",
      "Epoch: 295, Batch number: 56, Loss: 7.857379913330078\n",
      "Epoch: 297, Batch number: 4, Loss: 2.8100061416625977\n",
      "Epoch: 298, Batch number: 28, Loss: 5.895491600036621\n",
      "Epoch: 299, Batch number: 52, Loss: 5.046561241149902\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4401.888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch number: 24, Loss: 4313.35546875\n",
      "Epoch: 3, Batch number: 48, Loss: 4111.2197265625\n",
      "Epoch: 4, Batch number: 72, Loss: 3826.146240234375\n",
      "Epoch: 6, Batch number: 20, Loss: 3379.7841796875\n",
      "Epoch: 7, Batch number: 44, Loss: 3101.220703125\n",
      "Epoch: 8, Batch number: 68, Loss: 3029.7939453125\n",
      "Epoch: 10, Batch number: 16, Loss: 3129.03515625\n",
      "Epoch: 11, Batch number: 40, Loss: 3037.864501953125\n",
      "Epoch: 12, Batch number: 64, Loss: 3017.923095703125\n",
      "Epoch: 14, Batch number: 12, Loss: 2979.79736328125\n",
      "Epoch: 15, Batch number: 36, Loss: 2979.9794921875\n",
      "Epoch: 16, Batch number: 60, Loss: 2917.802490234375\n",
      "Epoch: 18, Batch number: 8, Loss: 2745.569580078125\n",
      "Epoch: 19, Batch number: 32, Loss: 2812.36767578125\n",
      "Epoch: 20, Batch number: 56, Loss: 2800.56982421875\n",
      "Epoch: 22, Batch number: 4, Loss: 2595.31591796875\n",
      "Epoch: 23, Batch number: 28, Loss: 2691.464599609375\n",
      "Epoch: 24, Batch number: 52, Loss: 2722.608154296875\n",
      "Epoch: 26, Batch number: 0, Loss: 2596.5390625\n",
      "Epoch: 27, Batch number: 24, Loss: 2777.09423828125\n",
      "Epoch: 28, Batch number: 48, Loss: 2631.52880859375\n",
      "Epoch: 29, Batch number: 72, Loss: 2613.55419921875\n",
      "Epoch: 31, Batch number: 20, Loss: 2450.461181640625\n",
      "Epoch: 32, Batch number: 44, Loss: 2586.026123046875\n",
      "Epoch: 33, Batch number: 68, Loss: 2554.8544921875\n",
      "Epoch: 35, Batch number: 16, Loss: 2658.367919921875\n",
      "Epoch: 36, Batch number: 40, Loss: 2550.7607421875\n",
      "Epoch: 37, Batch number: 64, Loss: 2513.472900390625\n",
      "Epoch: 39, Batch number: 12, Loss: 2412.39892578125\n",
      "Epoch: 40, Batch number: 36, Loss: 2453.077392578125\n",
      "Epoch: 41, Batch number: 60, Loss: 2411.359130859375\n",
      "Epoch: 43, Batch number: 8, Loss: 2365.505859375\n",
      "Epoch: 44, Batch number: 32, Loss: 2449.000244140625\n",
      "Epoch: 45, Batch number: 56, Loss: 2277.770751953125\n",
      "Epoch: 47, Batch number: 4, Loss: 2299.35205078125\n",
      "Epoch: 48, Batch number: 28, Loss: 2367.682861328125\n",
      "Epoch: 49, Batch number: 52, Loss: 2294.777587890625\n",
      "Epoch: 51, Batch number: 0, Loss: 2152.615966796875\n",
      "Epoch: 52, Batch number: 24, Loss: 2230.341064453125\n",
      "Epoch: 53, Batch number: 48, Loss: 2212.52978515625\n",
      "Epoch: 54, Batch number: 72, Loss: 2162.150390625\n",
      "Epoch: 56, Batch number: 20, Loss: 2208.558837890625\n",
      "Epoch: 57, Batch number: 44, Loss: 2173.916259765625\n",
      "Epoch: 58, Batch number: 68, Loss: 2114.42724609375\n",
      "Epoch: 60, Batch number: 16, Loss: 2146.964111328125\n",
      "Epoch: 61, Batch number: 40, Loss: 2080.197265625\n",
      "Epoch: 62, Batch number: 64, Loss: 2131.317626953125\n",
      "Epoch: 64, Batch number: 12, Loss: 2029.41162109375\n",
      "Epoch: 65, Batch number: 36, Loss: 2048.46875\n",
      "Epoch: 66, Batch number: 60, Loss: 2009.04052734375\n",
      "Epoch: 68, Batch number: 8, Loss: 2021.923828125\n",
      "Epoch: 69, Batch number: 32, Loss: 2001.7703857421875\n",
      "Epoch: 70, Batch number: 56, Loss: 1913.3973388671875\n",
      "Epoch: 72, Batch number: 4, Loss: 1940.1689453125\n",
      "Epoch: 73, Batch number: 28, Loss: 1851.5748291015625\n",
      "Epoch: 74, Batch number: 52, Loss: 1942.7474365234375\n",
      "Epoch: 76, Batch number: 0, Loss: 1851.7821044921875\n",
      "Epoch: 77, Batch number: 24, Loss: 1870.2193603515625\n",
      "Epoch: 78, Batch number: 48, Loss: 1872.9521484375\n",
      "Epoch: 79, Batch number: 72, Loss: 1840.5556640625\n",
      "Epoch: 81, Batch number: 20, Loss: 1785.4334716796875\n",
      "Epoch: 82, Batch number: 44, Loss: 1760.5904541015625\n",
      "Epoch: 83, Batch number: 68, Loss: 1682.71142578125\n",
      "Epoch: 85, Batch number: 16, Loss: 1817.5120849609375\n",
      "Epoch: 86, Batch number: 40, Loss: 1692.35693359375\n",
      "Epoch: 87, Batch number: 64, Loss: 1701.5977783203125\n",
      "Epoch: 89, Batch number: 12, Loss: 1664.8341064453125\n",
      "Epoch: 90, Batch number: 36, Loss: 1637.77734375\n",
      "Epoch: 91, Batch number: 60, Loss: 1667.10693359375\n",
      "Epoch: 93, Batch number: 8, Loss: 1680.013916015625\n",
      "Epoch: 94, Batch number: 32, Loss: 1633.2728271484375\n",
      "Epoch: 95, Batch number: 56, Loss: 1685.061767578125\n",
      "Epoch: 97, Batch number: 4, Loss: 1621.0997314453125\n",
      "Epoch: 98, Batch number: 28, Loss: 1628.24560546875\n",
      "Epoch: 99, Batch number: 52, Loss: 1522.552490234375\n",
      "Epoch: 101, Batch number: 0, Loss: 1580.779296875\n",
      "Epoch: 102, Batch number: 24, Loss: 1562.2410888671875\n",
      "Epoch: 103, Batch number: 48, Loss: 1544.6065673828125\n",
      "Epoch: 104, Batch number: 72, Loss: 1572.88623046875\n",
      "Epoch: 106, Batch number: 20, Loss: 1516.8876953125\n",
      "Epoch: 107, Batch number: 44, Loss: 1521.2176513671875\n",
      "Epoch: 108, Batch number: 68, Loss: 1520.6470947265625\n",
      "Epoch: 110, Batch number: 16, Loss: 1467.779296875\n",
      "Epoch: 111, Batch number: 40, Loss: 1463.09716796875\n",
      "Epoch: 112, Batch number: 64, Loss: 1460.0338134765625\n",
      "Epoch: 114, Batch number: 12, Loss: 1361.985595703125\n",
      "Epoch: 115, Batch number: 36, Loss: 1348.843017578125\n",
      "Epoch: 116, Batch number: 60, Loss: 1359.40625\n",
      "Epoch: 118, Batch number: 8, Loss: 1337.5694580078125\n",
      "Epoch: 119, Batch number: 32, Loss: 1315.7197265625\n",
      "Epoch: 120, Batch number: 56, Loss: 1346.1025390625\n",
      "Epoch: 122, Batch number: 4, Loss: 1373.310791015625\n",
      "Epoch: 123, Batch number: 28, Loss: 1343.2384033203125\n",
      "Epoch: 124, Batch number: 52, Loss: 1395.5654296875\n",
      "Epoch: 126, Batch number: 0, Loss: 1379.952880859375\n",
      "Epoch: 127, Batch number: 24, Loss: 1339.0098876953125\n",
      "Epoch: 128, Batch number: 48, Loss: 1281.46044921875\n",
      "Epoch: 129, Batch number: 72, Loss: 1268.49609375\n",
      "Epoch: 131, Batch number: 20, Loss: 1288.2061767578125\n",
      "Epoch: 132, Batch number: 44, Loss: 1334.376708984375\n",
      "Epoch: 133, Batch number: 68, Loss: 1248.1690673828125\n",
      "Epoch: 135, Batch number: 16, Loss: 1249.859130859375\n",
      "Epoch: 136, Batch number: 40, Loss: 1257.371337890625\n",
      "Epoch: 137, Batch number: 64, Loss: 1249.3331298828125\n",
      "Epoch: 139, Batch number: 12, Loss: 1217.1566162109375\n",
      "Epoch: 140, Batch number: 36, Loss: 1213.494873046875\n",
      "Epoch: 141, Batch number: 60, Loss: 1256.732666015625\n",
      "Epoch: 143, Batch number: 8, Loss: 1217.7227783203125\n",
      "Epoch: 144, Batch number: 32, Loss: 1164.47412109375\n",
      "Epoch: 145, Batch number: 56, Loss: 1256.8306884765625\n",
      "Epoch: 147, Batch number: 4, Loss: 1117.9105224609375\n",
      "Epoch: 148, Batch number: 28, Loss: 1194.618408203125\n",
      "Epoch: 149, Batch number: 52, Loss: 1176.9166259765625\n",
      "Epoch: 151, Batch number: 0, Loss: 1189.6859130859375\n",
      "Epoch: 152, Batch number: 24, Loss: 1099.17431640625\n",
      "Epoch: 153, Batch number: 48, Loss: 1117.0185546875\n",
      "Epoch: 154, Batch number: 72, Loss: 1077.8189697265625\n",
      "Epoch: 156, Batch number: 20, Loss: 1109.5714111328125\n",
      "Epoch: 157, Batch number: 44, Loss: 1089.5511474609375\n",
      "Epoch: 158, Batch number: 68, Loss: 1049.4371337890625\n",
      "Epoch: 160, Batch number: 16, Loss: 1086.2861328125\n",
      "Epoch: 161, Batch number: 40, Loss: 1083.1783447265625\n",
      "Epoch: 162, Batch number: 64, Loss: 1166.3924560546875\n",
      "Epoch: 164, Batch number: 12, Loss: 1072.7562255859375\n",
      "Epoch: 165, Batch number: 36, Loss: 1008.7489013671875\n",
      "Epoch: 166, Batch number: 60, Loss: 1092.3992919921875\n",
      "Epoch: 168, Batch number: 8, Loss: 1090.8037109375\n",
      "Epoch: 169, Batch number: 32, Loss: 1012.17138671875\n",
      "Epoch: 170, Batch number: 56, Loss: 1046.1131591796875\n",
      "Epoch: 172, Batch number: 4, Loss: 987.4852294921875\n",
      "Epoch: 173, Batch number: 28, Loss: 1016.8413696289062\n",
      "Epoch: 174, Batch number: 52, Loss: 1047.368408203125\n",
      "Epoch: 176, Batch number: 0, Loss: 1002.1516723632812\n",
      "Epoch: 177, Batch number: 24, Loss: 937.30908203125\n",
      "Epoch: 178, Batch number: 48, Loss: 901.794189453125\n",
      "Epoch: 179, Batch number: 72, Loss: 917.7625122070312\n",
      "Epoch: 181, Batch number: 20, Loss: 970.9102172851562\n",
      "Epoch: 182, Batch number: 44, Loss: 947.741455078125\n",
      "Epoch: 183, Batch number: 68, Loss: 925.4931030273438\n",
      "Epoch: 185, Batch number: 16, Loss: 933.5614013671875\n",
      "Epoch: 186, Batch number: 40, Loss: 979.1924438476562\n",
      "Epoch: 187, Batch number: 64, Loss: 939.042236328125\n",
      "Epoch: 189, Batch number: 12, Loss: 901.6402587890625\n",
      "Epoch: 190, Batch number: 36, Loss: 903.5736083984375\n",
      "Epoch: 191, Batch number: 60, Loss: 941.7791137695312\n",
      "Epoch: 193, Batch number: 8, Loss: 885.0978393554688\n",
      "Epoch: 194, Batch number: 32, Loss: 889.7023315429688\n",
      "Epoch: 195, Batch number: 56, Loss: 867.04833984375\n",
      "Epoch: 197, Batch number: 4, Loss: 889.1207885742188\n",
      "Epoch: 198, Batch number: 28, Loss: 892.8792114257812\n",
      "Epoch: 199, Batch number: 52, Loss: 884.611083984375\n",
      "Epoch: 201, Batch number: 0, Loss: 784.1671752929688\n",
      "Epoch: 202, Batch number: 24, Loss: 787.8049926757812\n",
      "Epoch: 203, Batch number: 48, Loss: 885.2291870117188\n",
      "Epoch: 204, Batch number: 72, Loss: 780.8634033203125\n",
      "Epoch: 206, Batch number: 20, Loss: 781.1098022460938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207, Batch number: 44, Loss: 808.364501953125\n",
      "Epoch: 208, Batch number: 68, Loss: 861.7223510742188\n",
      "Epoch: 210, Batch number: 16, Loss: 779.4855346679688\n",
      "Epoch: 211, Batch number: 40, Loss: 757.3309326171875\n",
      "Epoch: 212, Batch number: 64, Loss: 800.5835571289062\n",
      "Epoch: 214, Batch number: 12, Loss: 753.7125854492188\n",
      "Epoch: 215, Batch number: 36, Loss: 786.39404296875\n",
      "Epoch: 216, Batch number: 60, Loss: 730.722900390625\n",
      "Epoch: 218, Batch number: 8, Loss: 781.7916870117188\n",
      "Epoch: 219, Batch number: 32, Loss: 742.9006958007812\n",
      "Epoch: 220, Batch number: 56, Loss: 683.123779296875\n",
      "Epoch: 222, Batch number: 4, Loss: 726.3328857421875\n",
      "Epoch: 223, Batch number: 28, Loss: 748.67919921875\n",
      "Epoch: 224, Batch number: 52, Loss: 735.0866088867188\n",
      "Epoch: 226, Batch number: 0, Loss: 732.7393798828125\n",
      "Epoch: 227, Batch number: 24, Loss: 766.9454956054688\n",
      "Epoch: 228, Batch number: 48, Loss: 738.9642944335938\n",
      "Epoch: 229, Batch number: 72, Loss: 701.0567016601562\n",
      "Epoch: 231, Batch number: 20, Loss: 680.5906982421875\n",
      "Epoch: 232, Batch number: 44, Loss: 683.3445434570312\n",
      "Epoch: 233, Batch number: 68, Loss: 636.953125\n",
      "Epoch: 235, Batch number: 16, Loss: 646.70166015625\n",
      "Epoch: 236, Batch number: 40, Loss: 677.3748779296875\n",
      "Epoch: 237, Batch number: 64, Loss: 668.5257568359375\n",
      "Epoch: 239, Batch number: 12, Loss: 674.1348266601562\n",
      "Epoch: 240, Batch number: 36, Loss: 679.2373046875\n",
      "Epoch: 241, Batch number: 60, Loss: 658.1538696289062\n",
      "Epoch: 243, Batch number: 8, Loss: 647.4345092773438\n",
      "Epoch: 244, Batch number: 32, Loss: 593.7939453125\n",
      "Epoch: 245, Batch number: 56, Loss: 657.0660400390625\n",
      "Epoch: 247, Batch number: 4, Loss: 626.7457275390625\n",
      "Epoch: 248, Batch number: 28, Loss: 620.5347900390625\n",
      "Epoch: 249, Batch number: 52, Loss: 651.4287719726562\n",
      "Epoch: 251, Batch number: 0, Loss: 611.3513793945312\n",
      "Epoch: 252, Batch number: 24, Loss: 554.976318359375\n",
      "Epoch: 253, Batch number: 48, Loss: 583.5404052734375\n",
      "Epoch: 254, Batch number: 72, Loss: 595.8797607421875\n",
      "Epoch: 256, Batch number: 20, Loss: 592.5139770507812\n",
      "Epoch: 257, Batch number: 44, Loss: 557.727783203125\n",
      "Epoch: 258, Batch number: 68, Loss: 575.1903686523438\n",
      "Epoch: 260, Batch number: 16, Loss: 517.8886108398438\n",
      "Epoch: 261, Batch number: 40, Loss: 605.2005004882812\n",
      "Epoch: 262, Batch number: 64, Loss: 530.9039916992188\n",
      "Epoch: 264, Batch number: 12, Loss: 613.9251098632812\n",
      "Epoch: 265, Batch number: 36, Loss: 585.7868041992188\n",
      "Epoch: 266, Batch number: 60, Loss: 564.4246826171875\n",
      "Epoch: 268, Batch number: 8, Loss: 539.1268920898438\n",
      "Epoch: 269, Batch number: 32, Loss: 525.0908203125\n",
      "Epoch: 270, Batch number: 56, Loss: 508.5182189941406\n",
      "Epoch: 272, Batch number: 4, Loss: 621.6852416992188\n",
      "Epoch: 273, Batch number: 28, Loss: 503.0194396972656\n",
      "Epoch: 274, Batch number: 52, Loss: 538.0888671875\n",
      "Epoch: 276, Batch number: 0, Loss: 533.698486328125\n",
      "Epoch: 277, Batch number: 24, Loss: 484.1020812988281\n",
      "Epoch: 278, Batch number: 48, Loss: 505.186767578125\n",
      "Epoch: 279, Batch number: 72, Loss: 513.7173461914062\n",
      "Epoch: 281, Batch number: 20, Loss: 518.1510009765625\n",
      "Epoch: 282, Batch number: 44, Loss: 465.21832275390625\n",
      "Epoch: 283, Batch number: 68, Loss: 488.4219970703125\n",
      "Epoch: 285, Batch number: 16, Loss: 439.8680114746094\n",
      "Epoch: 286, Batch number: 40, Loss: 458.1350402832031\n",
      "Epoch: 287, Batch number: 64, Loss: 475.8785095214844\n",
      "Epoch: 289, Batch number: 12, Loss: 512.2316284179688\n",
      "Epoch: 290, Batch number: 36, Loss: 469.0277404785156\n",
      "Epoch: 291, Batch number: 60, Loss: 461.3863525390625\n",
      "Epoch: 293, Batch number: 8, Loss: 477.3741149902344\n",
      "Epoch: 294, Batch number: 32, Loss: 456.9010925292969\n",
      "Epoch: 295, Batch number: 56, Loss: 446.6602783203125\n",
      "Epoch: 297, Batch number: 4, Loss: 428.9594421386719\n",
      "Epoch: 298, Batch number: 28, Loss: 470.9096984863281\n",
      "Epoch: 299, Batch number: 52, Loss: 455.57879638671875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4406.62841796875\n",
      "Epoch: 2, Batch number: 24, Loss: 4190.296875\n",
      "Epoch: 3, Batch number: 48, Loss: 3843.845947265625\n",
      "Epoch: 4, Batch number: 72, Loss: 3320.739501953125\n",
      "Epoch: 6, Batch number: 20, Loss: 3147.177978515625\n",
      "Epoch: 7, Batch number: 44, Loss: 2991.826416015625\n",
      "Epoch: 8, Batch number: 68, Loss: 3028.76123046875\n",
      "Epoch: 10, Batch number: 16, Loss: 2840.788818359375\n",
      "Epoch: 11, Batch number: 40, Loss: 2815.14453125\n",
      "Epoch: 12, Batch number: 64, Loss: 2782.701171875\n",
      "Epoch: 14, Batch number: 12, Loss: 2743.765625\n",
      "Epoch: 15, Batch number: 36, Loss: 2677.593994140625\n",
      "Epoch: 16, Batch number: 60, Loss: 2737.867431640625\n",
      "Epoch: 18, Batch number: 8, Loss: 2520.232421875\n",
      "Epoch: 19, Batch number: 32, Loss: 2628.749267578125\n",
      "Epoch: 20, Batch number: 56, Loss: 2509.51220703125\n",
      "Epoch: 22, Batch number: 4, Loss: 2530.564697265625\n",
      "Epoch: 23, Batch number: 28, Loss: 2426.8857421875\n",
      "Epoch: 24, Batch number: 52, Loss: 2466.8154296875\n",
      "Epoch: 26, Batch number: 0, Loss: 2344.49365234375\n",
      "Epoch: 27, Batch number: 24, Loss: 2353.54736328125\n",
      "Epoch: 28, Batch number: 48, Loss: 2254.602294921875\n",
      "Epoch: 29, Batch number: 72, Loss: 2227.15087890625\n",
      "Epoch: 31, Batch number: 20, Loss: 2213.047119140625\n",
      "Epoch: 32, Batch number: 44, Loss: 2177.403564453125\n",
      "Epoch: 33, Batch number: 68, Loss: 2208.206787109375\n",
      "Epoch: 35, Batch number: 16, Loss: 2092.9501953125\n",
      "Epoch: 36, Batch number: 40, Loss: 2092.055908203125\n",
      "Epoch: 37, Batch number: 64, Loss: 2109.332763671875\n",
      "Epoch: 39, Batch number: 12, Loss: 1916.0584716796875\n",
      "Epoch: 40, Batch number: 36, Loss: 1947.625\n",
      "Epoch: 41, Batch number: 60, Loss: 1926.0745849609375\n",
      "Epoch: 43, Batch number: 8, Loss: 1815.7584228515625\n",
      "Epoch: 44, Batch number: 32, Loss: 1847.2945556640625\n",
      "Epoch: 45, Batch number: 56, Loss: 1821.67578125\n",
      "Epoch: 47, Batch number: 4, Loss: 1776.357177734375\n",
      "Epoch: 48, Batch number: 28, Loss: 1803.9324951171875\n",
      "Epoch: 49, Batch number: 52, Loss: 1724.564697265625\n",
      "Epoch: 51, Batch number: 0, Loss: 1664.749755859375\n",
      "Epoch: 52, Batch number: 24, Loss: 1664.608154296875\n",
      "Epoch: 53, Batch number: 48, Loss: 1522.6202392578125\n",
      "Epoch: 54, Batch number: 72, Loss: 1613.6470947265625\n",
      "Epoch: 56, Batch number: 20, Loss: 1519.9345703125\n",
      "Epoch: 57, Batch number: 44, Loss: 1508.3843994140625\n",
      "Epoch: 58, Batch number: 68, Loss: 1507.0750732421875\n",
      "Epoch: 60, Batch number: 16, Loss: 1452.6602783203125\n",
      "Epoch: 61, Batch number: 40, Loss: 1514.4339599609375\n",
      "Epoch: 62, Batch number: 64, Loss: 1355.624755859375\n",
      "Epoch: 64, Batch number: 12, Loss: 1372.0079345703125\n",
      "Epoch: 65, Batch number: 36, Loss: 1440.41748046875\n",
      "Epoch: 66, Batch number: 60, Loss: 1446.0748291015625\n",
      "Epoch: 68, Batch number: 8, Loss: 1350.2625732421875\n",
      "Epoch: 69, Batch number: 32, Loss: 1374.3531494140625\n",
      "Epoch: 70, Batch number: 56, Loss: 1336.431640625\n",
      "Epoch: 72, Batch number: 4, Loss: 1291.021484375\n",
      "Epoch: 73, Batch number: 28, Loss: 1267.334716796875\n",
      "Epoch: 74, Batch number: 52, Loss: 1215.1495361328125\n",
      "Epoch: 76, Batch number: 0, Loss: 1173.8114013671875\n",
      "Epoch: 77, Batch number: 24, Loss: 1238.1524658203125\n",
      "Epoch: 78, Batch number: 48, Loss: 1225.66259765625\n",
      "Epoch: 79, Batch number: 72, Loss: 1256.085205078125\n",
      "Epoch: 81, Batch number: 20, Loss: 1190.23193359375\n",
      "Epoch: 82, Batch number: 44, Loss: 1162.815673828125\n",
      "Epoch: 83, Batch number: 68, Loss: 1148.5992431640625\n",
      "Epoch: 85, Batch number: 16, Loss: 1137.3909912109375\n",
      "Epoch: 86, Batch number: 40, Loss: 1059.310791015625\n",
      "Epoch: 87, Batch number: 64, Loss: 1023.01220703125\n",
      "Epoch: 89, Batch number: 12, Loss: 996.4766235351562\n",
      "Epoch: 90, Batch number: 36, Loss: 1041.20849609375\n",
      "Epoch: 91, Batch number: 60, Loss: 1070.45947265625\n",
      "Epoch: 93, Batch number: 8, Loss: 1007.6497802734375\n",
      "Epoch: 94, Batch number: 32, Loss: 1079.249267578125\n",
      "Epoch: 95, Batch number: 56, Loss: 1092.7579345703125\n",
      "Epoch: 97, Batch number: 4, Loss: 979.5838012695312\n",
      "Epoch: 98, Batch number: 28, Loss: 912.2514038085938\n",
      "Epoch: 99, Batch number: 52, Loss: 929.3778076171875\n",
      "Epoch: 101, Batch number: 0, Loss: 908.86767578125\n",
      "Epoch: 102, Batch number: 24, Loss: 913.228515625\n",
      "Epoch: 103, Batch number: 48, Loss: 906.2078857421875\n",
      "Epoch: 104, Batch number: 72, Loss: 870.02099609375\n",
      "Epoch: 106, Batch number: 20, Loss: 916.2191162109375\n",
      "Epoch: 107, Batch number: 44, Loss: 854.5758666992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Batch number: 68, Loss: 833.0298461914062\n",
      "Epoch: 110, Batch number: 16, Loss: 870.9501342773438\n",
      "Epoch: 111, Batch number: 40, Loss: 832.4856567382812\n",
      "Epoch: 112, Batch number: 64, Loss: 882.0645141601562\n",
      "Epoch: 114, Batch number: 12, Loss: 749.5364990234375\n",
      "Epoch: 115, Batch number: 36, Loss: 807.1328735351562\n",
      "Epoch: 116, Batch number: 60, Loss: 774.626953125\n",
      "Epoch: 118, Batch number: 8, Loss: 765.7660522460938\n",
      "Epoch: 119, Batch number: 32, Loss: 752.0225219726562\n",
      "Epoch: 120, Batch number: 56, Loss: 764.7356567382812\n",
      "Epoch: 122, Batch number: 4, Loss: 707.9824829101562\n",
      "Epoch: 123, Batch number: 28, Loss: 689.4476928710938\n",
      "Epoch: 124, Batch number: 52, Loss: 685.1099243164062\n",
      "Epoch: 126, Batch number: 0, Loss: 652.1956176757812\n",
      "Epoch: 127, Batch number: 24, Loss: 646.7903442382812\n",
      "Epoch: 128, Batch number: 48, Loss: 659.0137329101562\n",
      "Epoch: 129, Batch number: 72, Loss: 668.8524780273438\n",
      "Epoch: 131, Batch number: 20, Loss: 645.997802734375\n",
      "Epoch: 132, Batch number: 44, Loss: 623.0848999023438\n",
      "Epoch: 133, Batch number: 68, Loss: 569.5902709960938\n",
      "Epoch: 135, Batch number: 16, Loss: 539.1957397460938\n",
      "Epoch: 136, Batch number: 40, Loss: 587.1279296875\n",
      "Epoch: 137, Batch number: 64, Loss: 584.1871948242188\n",
      "Epoch: 139, Batch number: 12, Loss: 536.9852905273438\n",
      "Epoch: 140, Batch number: 36, Loss: 558.7723388671875\n",
      "Epoch: 141, Batch number: 60, Loss: 589.0817260742188\n",
      "Epoch: 143, Batch number: 8, Loss: 530.2886352539062\n",
      "Epoch: 144, Batch number: 32, Loss: 554.4996337890625\n",
      "Epoch: 145, Batch number: 56, Loss: 498.96881103515625\n",
      "Epoch: 147, Batch number: 4, Loss: 539.2867431640625\n",
      "Epoch: 148, Batch number: 28, Loss: 497.20050048828125\n",
      "Epoch: 149, Batch number: 52, Loss: 574.5201416015625\n",
      "Epoch: 151, Batch number: 0, Loss: 471.9343566894531\n",
      "Epoch: 152, Batch number: 24, Loss: 487.8864440917969\n",
      "Epoch: 153, Batch number: 48, Loss: 477.69342041015625\n",
      "Epoch: 154, Batch number: 72, Loss: 509.29925537109375\n",
      "Epoch: 156, Batch number: 20, Loss: 437.5350036621094\n",
      "Epoch: 157, Batch number: 44, Loss: 445.251220703125\n",
      "Epoch: 158, Batch number: 68, Loss: 473.1250305175781\n",
      "Epoch: 160, Batch number: 16, Loss: 441.1685485839844\n",
      "Epoch: 161, Batch number: 40, Loss: 448.83416748046875\n",
      "Epoch: 162, Batch number: 64, Loss: 414.99407958984375\n",
      "Epoch: 164, Batch number: 12, Loss: 423.37640380859375\n",
      "Epoch: 165, Batch number: 36, Loss: 395.65972900390625\n",
      "Epoch: 166, Batch number: 60, Loss: 400.91357421875\n",
      "Epoch: 168, Batch number: 8, Loss: 382.95965576171875\n",
      "Epoch: 169, Batch number: 32, Loss: 395.24517822265625\n",
      "Epoch: 170, Batch number: 56, Loss: 368.4579162597656\n",
      "Epoch: 172, Batch number: 4, Loss: 357.43585205078125\n",
      "Epoch: 173, Batch number: 28, Loss: 369.3951721191406\n",
      "Epoch: 174, Batch number: 52, Loss: 383.7093811035156\n",
      "Epoch: 176, Batch number: 0, Loss: 329.59808349609375\n",
      "Epoch: 177, Batch number: 24, Loss: 362.12286376953125\n",
      "Epoch: 178, Batch number: 48, Loss: 379.3656005859375\n",
      "Epoch: 179, Batch number: 72, Loss: 334.61083984375\n",
      "Epoch: 181, Batch number: 20, Loss: 290.8421630859375\n",
      "Epoch: 182, Batch number: 44, Loss: 308.5934753417969\n",
      "Epoch: 183, Batch number: 68, Loss: 309.7794189453125\n",
      "Epoch: 185, Batch number: 16, Loss: 311.5323181152344\n",
      "Epoch: 186, Batch number: 40, Loss: 276.8226318359375\n",
      "Epoch: 187, Batch number: 64, Loss: 314.8351745605469\n",
      "Epoch: 189, Batch number: 12, Loss: 255.14266967773438\n",
      "Epoch: 190, Batch number: 36, Loss: 285.35113525390625\n",
      "Epoch: 191, Batch number: 60, Loss: 269.7572021484375\n",
      "Epoch: 193, Batch number: 8, Loss: 264.5715026855469\n",
      "Epoch: 194, Batch number: 32, Loss: 261.2433166503906\n",
      "Epoch: 195, Batch number: 56, Loss: 263.263427734375\n",
      "Epoch: 197, Batch number: 4, Loss: 237.74888610839844\n",
      "Epoch: 198, Batch number: 28, Loss: 250.08230590820312\n",
      "Epoch: 199, Batch number: 52, Loss: 227.08929443359375\n",
      "Epoch: 201, Batch number: 0, Loss: 246.42074584960938\n",
      "Epoch: 202, Batch number: 24, Loss: 265.59332275390625\n",
      "Epoch: 203, Batch number: 48, Loss: 218.54080200195312\n",
      "Epoch: 204, Batch number: 72, Loss: 224.3100128173828\n",
      "Epoch: 206, Batch number: 20, Loss: 225.07589721679688\n",
      "Epoch: 207, Batch number: 44, Loss: 242.86370849609375\n",
      "Epoch: 208, Batch number: 68, Loss: 222.98927307128906\n",
      "Epoch: 210, Batch number: 16, Loss: 213.62753295898438\n",
      "Epoch: 211, Batch number: 40, Loss: 212.9130859375\n",
      "Epoch: 212, Batch number: 64, Loss: 202.58607482910156\n",
      "Epoch: 214, Batch number: 12, Loss: 200.56448364257812\n",
      "Epoch: 215, Batch number: 36, Loss: 158.1875762939453\n",
      "Epoch: 216, Batch number: 60, Loss: 202.022705078125\n",
      "Epoch: 218, Batch number: 8, Loss: 186.84317016601562\n",
      "Epoch: 219, Batch number: 32, Loss: 169.4298553466797\n",
      "Epoch: 220, Batch number: 56, Loss: 158.84535217285156\n",
      "Epoch: 222, Batch number: 4, Loss: 165.6097869873047\n",
      "Epoch: 223, Batch number: 28, Loss: 167.8429718017578\n",
      "Epoch: 224, Batch number: 52, Loss: 192.2075958251953\n",
      "Epoch: 226, Batch number: 0, Loss: 150.6453399658203\n",
      "Epoch: 227, Batch number: 24, Loss: 161.1786651611328\n",
      "Epoch: 228, Batch number: 48, Loss: 139.57936096191406\n",
      "Epoch: 229, Batch number: 72, Loss: 146.30612182617188\n",
      "Epoch: 231, Batch number: 20, Loss: 151.80235290527344\n",
      "Epoch: 232, Batch number: 44, Loss: 141.99853515625\n",
      "Epoch: 233, Batch number: 68, Loss: 137.07872009277344\n",
      "Epoch: 235, Batch number: 16, Loss: 118.41688537597656\n",
      "Epoch: 236, Batch number: 40, Loss: 126.97904205322266\n",
      "Epoch: 237, Batch number: 64, Loss: 136.62767028808594\n",
      "Epoch: 239, Batch number: 12, Loss: 123.57441711425781\n",
      "Epoch: 240, Batch number: 36, Loss: 154.37196350097656\n",
      "Epoch: 241, Batch number: 60, Loss: 127.48974609375\n",
      "Epoch: 243, Batch number: 8, Loss: 129.86878967285156\n",
      "Epoch: 244, Batch number: 32, Loss: 113.43907165527344\n",
      "Epoch: 245, Batch number: 56, Loss: 123.05139923095703\n",
      "Epoch: 247, Batch number: 4, Loss: 121.37056732177734\n",
      "Epoch: 248, Batch number: 28, Loss: 126.78251647949219\n",
      "Epoch: 249, Batch number: 52, Loss: 103.78927612304688\n",
      "Epoch: 251, Batch number: 0, Loss: 109.44499969482422\n",
      "Epoch: 252, Batch number: 24, Loss: 109.17803955078125\n",
      "Epoch: 253, Batch number: 48, Loss: 96.09100341796875\n",
      "Epoch: 254, Batch number: 72, Loss: 92.56596374511719\n",
      "Epoch: 256, Batch number: 20, Loss: 98.26579284667969\n",
      "Epoch: 257, Batch number: 44, Loss: 92.90031433105469\n",
      "Epoch: 258, Batch number: 68, Loss: 103.05027770996094\n",
      "Epoch: 260, Batch number: 16, Loss: 93.8906021118164\n",
      "Epoch: 261, Batch number: 40, Loss: 89.30797576904297\n",
      "Epoch: 262, Batch number: 64, Loss: 86.31160736083984\n",
      "Epoch: 264, Batch number: 12, Loss: 88.6695327758789\n",
      "Epoch: 265, Batch number: 36, Loss: 79.23138427734375\n",
      "Epoch: 266, Batch number: 60, Loss: 80.65394592285156\n",
      "Epoch: 268, Batch number: 8, Loss: 80.17801666259766\n",
      "Epoch: 269, Batch number: 32, Loss: 80.45344543457031\n",
      "Epoch: 270, Batch number: 56, Loss: 79.64250946044922\n",
      "Epoch: 272, Batch number: 4, Loss: 74.17878723144531\n",
      "Epoch: 273, Batch number: 28, Loss: 80.79383850097656\n",
      "Epoch: 274, Batch number: 52, Loss: 79.067138671875\n",
      "Epoch: 276, Batch number: 0, Loss: 81.9103012084961\n",
      "Epoch: 277, Batch number: 24, Loss: 79.35822296142578\n",
      "Epoch: 278, Batch number: 48, Loss: 75.27774047851562\n",
      "Epoch: 279, Batch number: 72, Loss: 70.04670715332031\n",
      "Epoch: 281, Batch number: 20, Loss: 70.51770782470703\n",
      "Epoch: 282, Batch number: 44, Loss: 69.28205871582031\n",
      "Epoch: 283, Batch number: 68, Loss: 71.86832427978516\n",
      "Epoch: 285, Batch number: 16, Loss: 56.32332992553711\n",
      "Epoch: 286, Batch number: 40, Loss: 64.57984924316406\n",
      "Epoch: 287, Batch number: 64, Loss: 60.37164306640625\n",
      "Epoch: 289, Batch number: 12, Loss: 61.19602584838867\n",
      "Epoch: 290, Batch number: 36, Loss: 60.899505615234375\n",
      "Epoch: 291, Batch number: 60, Loss: 60.04875564575195\n",
      "Epoch: 293, Batch number: 8, Loss: 56.20359802246094\n",
      "Epoch: 294, Batch number: 32, Loss: 62.44209289550781\n",
      "Epoch: 295, Batch number: 56, Loss: 48.9655647277832\n",
      "Epoch: 297, Batch number: 4, Loss: 61.235374450683594\n",
      "Epoch: 298, Batch number: 28, Loss: 55.6358642578125\n",
      "Epoch: 299, Batch number: 52, Loss: 63.17285919189453\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4401.65234375\n",
      "Epoch: 2, Batch number: 24, Loss: 4099.05419921875\n",
      "Epoch: 3, Batch number: 48, Loss: 3601.315673828125\n",
      "Epoch: 4, Batch number: 72, Loss: 3111.511474609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Batch number: 20, Loss: 3044.091796875\n",
      "Epoch: 7, Batch number: 44, Loss: 3081.858642578125\n",
      "Epoch: 8, Batch number: 68, Loss: 2774.413330078125\n",
      "Epoch: 10, Batch number: 16, Loss: 2612.4716796875\n",
      "Epoch: 11, Batch number: 40, Loss: 2661.779296875\n",
      "Epoch: 12, Batch number: 64, Loss: 2684.704345703125\n",
      "Epoch: 14, Batch number: 12, Loss: 2538.239501953125\n",
      "Epoch: 15, Batch number: 36, Loss: 2488.30517578125\n",
      "Epoch: 16, Batch number: 60, Loss: 2347.761962890625\n",
      "Epoch: 18, Batch number: 8, Loss: 2303.42333984375\n",
      "Epoch: 19, Batch number: 32, Loss: 2357.7666015625\n",
      "Epoch: 20, Batch number: 56, Loss: 2311.310791015625\n",
      "Epoch: 22, Batch number: 4, Loss: 2197.22802734375\n",
      "Epoch: 23, Batch number: 28, Loss: 2216.697021484375\n",
      "Epoch: 24, Batch number: 52, Loss: 2176.326904296875\n",
      "Epoch: 26, Batch number: 0, Loss: 2075.889404296875\n",
      "Epoch: 27, Batch number: 24, Loss: 2041.965087890625\n",
      "Epoch: 28, Batch number: 48, Loss: 2020.5758056640625\n",
      "Epoch: 29, Batch number: 72, Loss: 1894.322265625\n",
      "Epoch: 31, Batch number: 20, Loss: 1844.78125\n",
      "Epoch: 32, Batch number: 44, Loss: 1859.1285400390625\n",
      "Epoch: 33, Batch number: 68, Loss: 1776.9132080078125\n",
      "Epoch: 35, Batch number: 16, Loss: 1730.192626953125\n",
      "Epoch: 36, Batch number: 40, Loss: 1754.4102783203125\n",
      "Epoch: 37, Batch number: 64, Loss: 1716.0528564453125\n",
      "Epoch: 39, Batch number: 12, Loss: 1563.32666015625\n",
      "Epoch: 40, Batch number: 36, Loss: 1634.607177734375\n",
      "Epoch: 41, Batch number: 60, Loss: 1607.20849609375\n",
      "Epoch: 43, Batch number: 8, Loss: 1565.3165283203125\n",
      "Epoch: 44, Batch number: 32, Loss: 1536.3580322265625\n",
      "Epoch: 45, Batch number: 56, Loss: 1448.983154296875\n",
      "Epoch: 47, Batch number: 4, Loss: 1389.743408203125\n",
      "Epoch: 48, Batch number: 28, Loss: 1320.727783203125\n",
      "Epoch: 49, Batch number: 52, Loss: 1342.0372314453125\n",
      "Epoch: 51, Batch number: 0, Loss: 1362.0718994140625\n",
      "Epoch: 52, Batch number: 24, Loss: 1296.227294921875\n",
      "Epoch: 53, Batch number: 48, Loss: 1298.5340576171875\n",
      "Epoch: 54, Batch number: 72, Loss: 1195.680908203125\n",
      "Epoch: 56, Batch number: 20, Loss: 1168.6949462890625\n",
      "Epoch: 57, Batch number: 44, Loss: 1148.4345703125\n",
      "Epoch: 58, Batch number: 68, Loss: 1215.012451171875\n",
      "Epoch: 60, Batch number: 16, Loss: 1194.1746826171875\n",
      "Epoch: 61, Batch number: 40, Loss: 1084.201171875\n",
      "Epoch: 62, Batch number: 64, Loss: 1086.8309326171875\n",
      "Epoch: 64, Batch number: 12, Loss: 1119.2440185546875\n",
      "Epoch: 65, Batch number: 36, Loss: 1071.58251953125\n",
      "Epoch: 66, Batch number: 60, Loss: 1088.760498046875\n",
      "Epoch: 68, Batch number: 8, Loss: 1022.4791870117188\n",
      "Epoch: 69, Batch number: 32, Loss: 945.3998413085938\n",
      "Epoch: 70, Batch number: 56, Loss: 983.4503173828125\n",
      "Epoch: 72, Batch number: 4, Loss: 913.373291015625\n",
      "Epoch: 73, Batch number: 28, Loss: 914.734375\n",
      "Epoch: 74, Batch number: 52, Loss: 863.1818237304688\n",
      "Epoch: 76, Batch number: 0, Loss: 878.6036987304688\n",
      "Epoch: 77, Batch number: 24, Loss: 832.5318603515625\n",
      "Epoch: 78, Batch number: 48, Loss: 820.3698120117188\n",
      "Epoch: 79, Batch number: 72, Loss: 834.5657958984375\n",
      "Epoch: 81, Batch number: 20, Loss: 822.3528442382812\n",
      "Epoch: 82, Batch number: 44, Loss: 833.5369873046875\n",
      "Epoch: 83, Batch number: 68, Loss: 802.77294921875\n",
      "Epoch: 85, Batch number: 16, Loss: 745.9058227539062\n",
      "Epoch: 86, Batch number: 40, Loss: 785.001708984375\n",
      "Epoch: 87, Batch number: 64, Loss: 736.2078247070312\n",
      "Epoch: 89, Batch number: 12, Loss: 630.7219848632812\n",
      "Epoch: 90, Batch number: 36, Loss: 651.2022705078125\n",
      "Epoch: 91, Batch number: 60, Loss: 700.1100463867188\n",
      "Epoch: 93, Batch number: 8, Loss: 722.68359375\n",
      "Epoch: 94, Batch number: 32, Loss: 642.4470825195312\n",
      "Epoch: 95, Batch number: 56, Loss: 621.7987060546875\n",
      "Epoch: 97, Batch number: 4, Loss: 610.5343017578125\n",
      "Epoch: 98, Batch number: 28, Loss: 580.8968505859375\n",
      "Epoch: 99, Batch number: 52, Loss: 633.3076171875\n",
      "Epoch: 101, Batch number: 0, Loss: 572.3348999023438\n",
      "Epoch: 102, Batch number: 24, Loss: 566.6854248046875\n",
      "Epoch: 103, Batch number: 48, Loss: 533.9449462890625\n",
      "Epoch: 104, Batch number: 72, Loss: 562.1384887695312\n",
      "Epoch: 106, Batch number: 20, Loss: 522.978515625\n",
      "Epoch: 107, Batch number: 44, Loss: 497.3734436035156\n",
      "Epoch: 108, Batch number: 68, Loss: 513.01708984375\n",
      "Epoch: 110, Batch number: 16, Loss: 472.2247314453125\n",
      "Epoch: 111, Batch number: 40, Loss: 507.3935546875\n",
      "Epoch: 112, Batch number: 64, Loss: 431.80804443359375\n",
      "Epoch: 114, Batch number: 12, Loss: 448.4450378417969\n",
      "Epoch: 115, Batch number: 36, Loss: 440.17657470703125\n",
      "Epoch: 116, Batch number: 60, Loss: 406.2777099609375\n",
      "Epoch: 118, Batch number: 8, Loss: 419.64752197265625\n",
      "Epoch: 119, Batch number: 32, Loss: 420.04229736328125\n",
      "Epoch: 120, Batch number: 56, Loss: 397.86016845703125\n",
      "Epoch: 122, Batch number: 4, Loss: 366.7887878417969\n",
      "Epoch: 123, Batch number: 28, Loss: 359.2505798339844\n",
      "Epoch: 124, Batch number: 52, Loss: 364.7786865234375\n",
      "Epoch: 126, Batch number: 0, Loss: 355.9044189453125\n",
      "Epoch: 127, Batch number: 24, Loss: 339.3560791015625\n",
      "Epoch: 128, Batch number: 48, Loss: 365.37091064453125\n",
      "Epoch: 129, Batch number: 72, Loss: 337.98583984375\n",
      "Epoch: 131, Batch number: 20, Loss: 317.0619812011719\n",
      "Epoch: 132, Batch number: 44, Loss: 302.7602844238281\n",
      "Epoch: 133, Batch number: 68, Loss: 311.9351501464844\n",
      "Epoch: 135, Batch number: 16, Loss: 299.3232727050781\n",
      "Epoch: 136, Batch number: 40, Loss: 316.560546875\n",
      "Epoch: 137, Batch number: 64, Loss: 277.89971923828125\n",
      "Epoch: 139, Batch number: 12, Loss: 286.0084228515625\n",
      "Epoch: 140, Batch number: 36, Loss: 278.3377685546875\n",
      "Epoch: 141, Batch number: 60, Loss: 287.9952697753906\n",
      "Epoch: 143, Batch number: 8, Loss: 245.3931427001953\n",
      "Epoch: 144, Batch number: 32, Loss: 237.94619750976562\n",
      "Epoch: 145, Batch number: 56, Loss: 251.3262176513672\n",
      "Epoch: 147, Batch number: 4, Loss: 205.06878662109375\n",
      "Epoch: 148, Batch number: 28, Loss: 221.7672576904297\n",
      "Epoch: 149, Batch number: 52, Loss: 223.91482543945312\n",
      "Epoch: 151, Batch number: 0, Loss: 211.65684509277344\n",
      "Epoch: 152, Batch number: 24, Loss: 213.2444305419922\n",
      "Epoch: 153, Batch number: 48, Loss: 209.4774932861328\n",
      "Epoch: 154, Batch number: 72, Loss: 194.4228515625\n",
      "Epoch: 156, Batch number: 20, Loss: 191.67774963378906\n",
      "Epoch: 157, Batch number: 44, Loss: 200.9477996826172\n",
      "Epoch: 158, Batch number: 68, Loss: 183.72557067871094\n",
      "Epoch: 160, Batch number: 16, Loss: 184.74691772460938\n",
      "Epoch: 161, Batch number: 40, Loss: 186.47021484375\n",
      "Epoch: 162, Batch number: 64, Loss: 189.6930694580078\n",
      "Epoch: 164, Batch number: 12, Loss: 164.0382537841797\n",
      "Epoch: 165, Batch number: 36, Loss: 149.6173553466797\n",
      "Epoch: 166, Batch number: 60, Loss: 148.8051300048828\n",
      "Epoch: 168, Batch number: 8, Loss: 132.55450439453125\n",
      "Epoch: 169, Batch number: 32, Loss: 142.9283447265625\n",
      "Epoch: 170, Batch number: 56, Loss: 158.09576416015625\n",
      "Epoch: 172, Batch number: 4, Loss: 136.13023376464844\n",
      "Epoch: 173, Batch number: 28, Loss: 159.1256561279297\n",
      "Epoch: 174, Batch number: 52, Loss: 139.7930450439453\n",
      "Epoch: 176, Batch number: 0, Loss: 135.6385955810547\n",
      "Epoch: 177, Batch number: 24, Loss: 122.384765625\n",
      "Epoch: 178, Batch number: 48, Loss: 116.21984100341797\n",
      "Epoch: 179, Batch number: 72, Loss: 127.2688217163086\n",
      "Epoch: 181, Batch number: 20, Loss: 119.49099731445312\n",
      "Epoch: 182, Batch number: 44, Loss: 100.07585906982422\n",
      "Epoch: 183, Batch number: 68, Loss: 120.07254791259766\n",
      "Epoch: 185, Batch number: 16, Loss: 98.6981201171875\n",
      "Epoch: 186, Batch number: 40, Loss: 95.6248779296875\n",
      "Epoch: 187, Batch number: 64, Loss: 115.21284484863281\n",
      "Epoch: 189, Batch number: 12, Loss: 102.80667877197266\n",
      "Epoch: 190, Batch number: 36, Loss: 96.41387939453125\n",
      "Epoch: 191, Batch number: 60, Loss: 101.29864501953125\n",
      "Epoch: 193, Batch number: 8, Loss: 94.03523254394531\n",
      "Epoch: 194, Batch number: 32, Loss: 78.77400970458984\n",
      "Epoch: 195, Batch number: 56, Loss: 84.24991607666016\n",
      "Epoch: 197, Batch number: 4, Loss: 81.37565612792969\n",
      "Epoch: 198, Batch number: 28, Loss: 77.98118591308594\n",
      "Epoch: 199, Batch number: 52, Loss: 76.33236694335938\n",
      "Epoch: 201, Batch number: 0, Loss: 86.0908203125\n",
      "Epoch: 202, Batch number: 24, Loss: 86.31302642822266\n",
      "Epoch: 203, Batch number: 48, Loss: 79.0020751953125\n",
      "Epoch: 204, Batch number: 72, Loss: 73.64019012451172\n",
      "Epoch: 206, Batch number: 20, Loss: 71.1193618774414\n",
      "Epoch: 207, Batch number: 44, Loss: 73.42733001708984\n",
      "Epoch: 208, Batch number: 68, Loss: 61.63945007324219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Batch number: 16, Loss: 63.503562927246094\n",
      "Epoch: 211, Batch number: 40, Loss: 68.006591796875\n",
      "Epoch: 212, Batch number: 64, Loss: 55.725135803222656\n",
      "Epoch: 214, Batch number: 12, Loss: 61.92919158935547\n",
      "Epoch: 215, Batch number: 36, Loss: 69.93461608886719\n",
      "Epoch: 216, Batch number: 60, Loss: 59.413394927978516\n",
      "Epoch: 218, Batch number: 8, Loss: 50.97508239746094\n",
      "Epoch: 219, Batch number: 32, Loss: 51.113285064697266\n",
      "Epoch: 220, Batch number: 56, Loss: 58.5330924987793\n",
      "Epoch: 222, Batch number: 4, Loss: 50.77591323852539\n",
      "Epoch: 223, Batch number: 28, Loss: 49.375640869140625\n",
      "Epoch: 224, Batch number: 52, Loss: 54.61962127685547\n",
      "Epoch: 226, Batch number: 0, Loss: 50.15604782104492\n",
      "Epoch: 227, Batch number: 24, Loss: 48.42451477050781\n",
      "Epoch: 228, Batch number: 48, Loss: 50.24494552612305\n",
      "Epoch: 229, Batch number: 72, Loss: 52.2652473449707\n",
      "Epoch: 231, Batch number: 20, Loss: 49.45256805419922\n",
      "Epoch: 232, Batch number: 44, Loss: 45.24019241333008\n",
      "Epoch: 233, Batch number: 68, Loss: 43.34343338012695\n",
      "Epoch: 235, Batch number: 16, Loss: 41.4940071105957\n",
      "Epoch: 236, Batch number: 40, Loss: 38.40997314453125\n",
      "Epoch: 237, Batch number: 64, Loss: 37.799171447753906\n",
      "Epoch: 239, Batch number: 12, Loss: 34.05287170410156\n",
      "Epoch: 240, Batch number: 36, Loss: 42.19194793701172\n",
      "Epoch: 241, Batch number: 60, Loss: 42.55628967285156\n",
      "Epoch: 243, Batch number: 8, Loss: 34.906192779541016\n",
      "Epoch: 244, Batch number: 32, Loss: 36.27712631225586\n",
      "Epoch: 245, Batch number: 56, Loss: 38.7999153137207\n",
      "Epoch: 247, Batch number: 4, Loss: 40.247467041015625\n",
      "Epoch: 248, Batch number: 28, Loss: 38.49090576171875\n",
      "Epoch: 249, Batch number: 52, Loss: 35.21739196777344\n",
      "Epoch: 251, Batch number: 0, Loss: 34.78062438964844\n",
      "Epoch: 252, Batch number: 24, Loss: 35.23002624511719\n",
      "Epoch: 253, Batch number: 48, Loss: 29.90007781982422\n",
      "Epoch: 254, Batch number: 72, Loss: 35.549312591552734\n",
      "Epoch: 256, Batch number: 20, Loss: 32.10276412963867\n",
      "Epoch: 257, Batch number: 44, Loss: 33.00566864013672\n",
      "Epoch: 258, Batch number: 68, Loss: 29.405269622802734\n",
      "Epoch: 260, Batch number: 16, Loss: 32.09835433959961\n",
      "Epoch: 261, Batch number: 40, Loss: 36.06511306762695\n",
      "Epoch: 262, Batch number: 64, Loss: 29.135101318359375\n",
      "Epoch: 264, Batch number: 12, Loss: 29.63140106201172\n",
      "Epoch: 265, Batch number: 36, Loss: 24.250022888183594\n",
      "Epoch: 266, Batch number: 60, Loss: 29.92226791381836\n",
      "Epoch: 268, Batch number: 8, Loss: 30.985071182250977\n",
      "Epoch: 269, Batch number: 32, Loss: 22.016143798828125\n",
      "Epoch: 270, Batch number: 56, Loss: 25.286563873291016\n",
      "Epoch: 272, Batch number: 4, Loss: 23.436464309692383\n",
      "Epoch: 273, Batch number: 28, Loss: 23.531314849853516\n",
      "Epoch: 274, Batch number: 52, Loss: 27.17483139038086\n",
      "Epoch: 276, Batch number: 0, Loss: 31.272884368896484\n",
      "Epoch: 277, Batch number: 24, Loss: 19.562034606933594\n",
      "Epoch: 278, Batch number: 48, Loss: 23.047847747802734\n",
      "Epoch: 279, Batch number: 72, Loss: 26.35199737548828\n",
      "Epoch: 281, Batch number: 20, Loss: 21.104177474975586\n",
      "Epoch: 282, Batch number: 44, Loss: 26.1971435546875\n",
      "Epoch: 283, Batch number: 68, Loss: 23.945337295532227\n",
      "Epoch: 285, Batch number: 16, Loss: 27.117048263549805\n",
      "Epoch: 286, Batch number: 40, Loss: 22.51070785522461\n",
      "Epoch: 287, Batch number: 64, Loss: 19.97531509399414\n",
      "Epoch: 289, Batch number: 12, Loss: 21.514678955078125\n",
      "Epoch: 290, Batch number: 36, Loss: 21.485944747924805\n",
      "Epoch: 291, Batch number: 60, Loss: 29.397302627563477\n",
      "Epoch: 293, Batch number: 8, Loss: 18.415748596191406\n",
      "Epoch: 294, Batch number: 32, Loss: 15.470405578613281\n",
      "Epoch: 295, Batch number: 56, Loss: 25.650985717773438\n",
      "Epoch: 297, Batch number: 4, Loss: 21.499465942382812\n",
      "Epoch: 298, Batch number: 28, Loss: 18.330957412719727\n",
      "Epoch: 299, Batch number: 52, Loss: 17.018756866455078\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4404.42041015625\n",
      "Epoch: 2, Batch number: 24, Loss: 4013.414794921875\n",
      "Epoch: 3, Batch number: 48, Loss: 3356.447021484375\n",
      "Epoch: 4, Batch number: 72, Loss: 3157.454345703125\n",
      "Epoch: 6, Batch number: 20, Loss: 3004.3681640625\n",
      "Epoch: 7, Batch number: 44, Loss: 2839.306396484375\n",
      "Epoch: 8, Batch number: 68, Loss: 2624.1591796875\n",
      "Epoch: 10, Batch number: 16, Loss: 2679.915283203125\n",
      "Epoch: 11, Batch number: 40, Loss: 2508.54296875\n",
      "Epoch: 12, Batch number: 64, Loss: 2491.5322265625\n",
      "Epoch: 14, Batch number: 12, Loss: 2341.16455078125\n",
      "Epoch: 15, Batch number: 36, Loss: 2337.669677734375\n",
      "Epoch: 16, Batch number: 60, Loss: 2364.055419921875\n",
      "Epoch: 18, Batch number: 8, Loss: 2199.9013671875\n",
      "Epoch: 19, Batch number: 32, Loss: 2148.40283203125\n",
      "Epoch: 20, Batch number: 56, Loss: 2063.173583984375\n",
      "Epoch: 22, Batch number: 4, Loss: 2053.288818359375\n",
      "Epoch: 23, Batch number: 28, Loss: 1997.615234375\n",
      "Epoch: 24, Batch number: 52, Loss: 1847.1400146484375\n",
      "Epoch: 26, Batch number: 0, Loss: 1902.5220947265625\n",
      "Epoch: 27, Batch number: 24, Loss: 1794.90966796875\n",
      "Epoch: 28, Batch number: 48, Loss: 1753.513916015625\n",
      "Epoch: 29, Batch number: 72, Loss: 1645.512939453125\n",
      "Epoch: 31, Batch number: 20, Loss: 1632.0869140625\n",
      "Epoch: 32, Batch number: 44, Loss: 1500.4730224609375\n",
      "Epoch: 33, Batch number: 68, Loss: 1540.392822265625\n",
      "Epoch: 35, Batch number: 16, Loss: 1449.3406982421875\n",
      "Epoch: 36, Batch number: 40, Loss: 1473.68017578125\n",
      "Epoch: 37, Batch number: 64, Loss: 1417.66796875\n",
      "Epoch: 39, Batch number: 12, Loss: 1391.1600341796875\n",
      "Epoch: 40, Batch number: 36, Loss: 1381.271728515625\n",
      "Epoch: 41, Batch number: 60, Loss: 1352.1151123046875\n",
      "Epoch: 43, Batch number: 8, Loss: 1225.4439697265625\n",
      "Epoch: 44, Batch number: 32, Loss: 1300.685302734375\n",
      "Epoch: 45, Batch number: 56, Loss: 1272.2166748046875\n",
      "Epoch: 47, Batch number: 4, Loss: 1197.879150390625\n",
      "Epoch: 48, Batch number: 28, Loss: 1245.9012451171875\n",
      "Epoch: 49, Batch number: 52, Loss: 1091.1966552734375\n",
      "Epoch: 51, Batch number: 0, Loss: 1026.9481201171875\n",
      "Epoch: 52, Batch number: 24, Loss: 1016.9453125\n",
      "Epoch: 53, Batch number: 48, Loss: 1007.6459350585938\n",
      "Epoch: 54, Batch number: 72, Loss: 992.64599609375\n",
      "Epoch: 56, Batch number: 20, Loss: 961.286376953125\n",
      "Epoch: 57, Batch number: 44, Loss: 985.8009643554688\n",
      "Epoch: 58, Batch number: 68, Loss: 913.781494140625\n",
      "Epoch: 60, Batch number: 16, Loss: 845.8518676757812\n",
      "Epoch: 61, Batch number: 40, Loss: 887.985107421875\n",
      "Epoch: 62, Batch number: 64, Loss: 844.6964111328125\n",
      "Epoch: 64, Batch number: 12, Loss: 848.4940185546875\n",
      "Epoch: 65, Batch number: 36, Loss: 849.0518798828125\n",
      "Epoch: 66, Batch number: 60, Loss: 845.1194458007812\n",
      "Epoch: 68, Batch number: 8, Loss: 745.0938720703125\n",
      "Epoch: 69, Batch number: 32, Loss: 775.2117309570312\n",
      "Epoch: 70, Batch number: 56, Loss: 756.2680053710938\n",
      "Epoch: 72, Batch number: 4, Loss: 731.6437377929688\n",
      "Epoch: 73, Batch number: 28, Loss: 731.5796508789062\n",
      "Epoch: 74, Batch number: 52, Loss: 700.1962280273438\n",
      "Epoch: 76, Batch number: 0, Loss: 633.6907348632812\n",
      "Epoch: 77, Batch number: 24, Loss: 634.4297485351562\n",
      "Epoch: 78, Batch number: 48, Loss: 628.2936401367188\n",
      "Epoch: 79, Batch number: 72, Loss: 622.7637329101562\n",
      "Epoch: 81, Batch number: 20, Loss: 539.5718994140625\n",
      "Epoch: 82, Batch number: 44, Loss: 583.3630981445312\n",
      "Epoch: 83, Batch number: 68, Loss: 578.1353149414062\n",
      "Epoch: 85, Batch number: 16, Loss: 565.0792236328125\n",
      "Epoch: 86, Batch number: 40, Loss: 496.7729187011719\n",
      "Epoch: 87, Batch number: 64, Loss: 507.812255859375\n",
      "Epoch: 89, Batch number: 12, Loss: 499.5467529296875\n",
      "Epoch: 90, Batch number: 36, Loss: 442.9934387207031\n",
      "Epoch: 91, Batch number: 60, Loss: 481.71051025390625\n",
      "Epoch: 93, Batch number: 8, Loss: 438.02301025390625\n",
      "Epoch: 94, Batch number: 32, Loss: 392.9912414550781\n",
      "Epoch: 95, Batch number: 56, Loss: 394.78021240234375\n",
      "Epoch: 97, Batch number: 4, Loss: 381.37152099609375\n",
      "Epoch: 98, Batch number: 28, Loss: 410.8671875\n",
      "Epoch: 99, Batch number: 52, Loss: 402.18829345703125\n",
      "Epoch: 101, Batch number: 0, Loss: 379.2976379394531\n",
      "Epoch: 102, Batch number: 24, Loss: 399.31317138671875\n",
      "Epoch: 103, Batch number: 48, Loss: 345.0576171875\n",
      "Epoch: 104, Batch number: 72, Loss: 316.6632080078125\n",
      "Epoch: 106, Batch number: 20, Loss: 339.9971923828125\n",
      "Epoch: 107, Batch number: 44, Loss: 328.4962158203125\n",
      "Epoch: 108, Batch number: 68, Loss: 301.6325378417969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 16, Loss: 283.4524841308594\n",
      "Epoch: 111, Batch number: 40, Loss: 309.54412841796875\n",
      "Epoch: 112, Batch number: 64, Loss: 268.28631591796875\n",
      "Epoch: 114, Batch number: 12, Loss: 252.51361083984375\n",
      "Epoch: 115, Batch number: 36, Loss: 259.302734375\n",
      "Epoch: 116, Batch number: 60, Loss: 262.9473876953125\n",
      "Epoch: 118, Batch number: 8, Loss: 237.826416015625\n",
      "Epoch: 119, Batch number: 32, Loss: 238.7337188720703\n",
      "Epoch: 120, Batch number: 56, Loss: 229.0923614501953\n",
      "Epoch: 122, Batch number: 4, Loss: 210.9315948486328\n",
      "Epoch: 123, Batch number: 28, Loss: 227.9501953125\n",
      "Epoch: 124, Batch number: 52, Loss: 216.0503692626953\n",
      "Epoch: 126, Batch number: 0, Loss: 182.22572326660156\n",
      "Epoch: 127, Batch number: 24, Loss: 198.63735961914062\n",
      "Epoch: 128, Batch number: 48, Loss: 227.14691162109375\n",
      "Epoch: 129, Batch number: 72, Loss: 184.96534729003906\n",
      "Epoch: 131, Batch number: 20, Loss: 183.2776336669922\n",
      "Epoch: 132, Batch number: 44, Loss: 184.21563720703125\n",
      "Epoch: 133, Batch number: 68, Loss: 158.40476989746094\n",
      "Epoch: 135, Batch number: 16, Loss: 149.4702606201172\n",
      "Epoch: 136, Batch number: 40, Loss: 150.10684204101562\n",
      "Epoch: 137, Batch number: 64, Loss: 145.0158233642578\n",
      "Epoch: 139, Batch number: 12, Loss: 128.55003356933594\n",
      "Epoch: 140, Batch number: 36, Loss: 147.18215942382812\n",
      "Epoch: 141, Batch number: 60, Loss: 138.07687377929688\n",
      "Epoch: 143, Batch number: 8, Loss: 119.83348083496094\n",
      "Epoch: 144, Batch number: 32, Loss: 129.34634399414062\n",
      "Epoch: 145, Batch number: 56, Loss: 119.1689682006836\n",
      "Epoch: 147, Batch number: 4, Loss: 119.77965545654297\n",
      "Epoch: 148, Batch number: 28, Loss: 133.435546875\n",
      "Epoch: 149, Batch number: 52, Loss: 103.63406372070312\n",
      "Epoch: 151, Batch number: 0, Loss: 101.50993347167969\n",
      "Epoch: 152, Batch number: 24, Loss: 105.40928649902344\n",
      "Epoch: 153, Batch number: 48, Loss: 99.95036315917969\n",
      "Epoch: 154, Batch number: 72, Loss: 114.03805541992188\n",
      "Epoch: 156, Batch number: 20, Loss: 91.40934753417969\n",
      "Epoch: 157, Batch number: 44, Loss: 119.71654510498047\n",
      "Epoch: 158, Batch number: 68, Loss: 93.60836029052734\n",
      "Epoch: 160, Batch number: 16, Loss: 78.6944808959961\n",
      "Epoch: 161, Batch number: 40, Loss: 93.39414978027344\n",
      "Epoch: 162, Batch number: 64, Loss: 80.61483764648438\n",
      "Epoch: 164, Batch number: 12, Loss: 80.54659271240234\n",
      "Epoch: 165, Batch number: 36, Loss: 78.02949523925781\n",
      "Epoch: 166, Batch number: 60, Loss: 79.38188171386719\n",
      "Epoch: 168, Batch number: 8, Loss: 84.5758056640625\n",
      "Epoch: 169, Batch number: 32, Loss: 73.15531921386719\n",
      "Epoch: 170, Batch number: 56, Loss: 82.03323364257812\n",
      "Epoch: 172, Batch number: 4, Loss: 66.85151672363281\n",
      "Epoch: 173, Batch number: 28, Loss: 68.23749542236328\n",
      "Epoch: 174, Batch number: 52, Loss: 60.10240936279297\n",
      "Epoch: 176, Batch number: 0, Loss: 56.913814544677734\n",
      "Epoch: 177, Batch number: 24, Loss: 68.14649200439453\n",
      "Epoch: 178, Batch number: 48, Loss: 65.59679412841797\n",
      "Epoch: 179, Batch number: 72, Loss: 55.05521011352539\n",
      "Epoch: 181, Batch number: 20, Loss: 56.96236801147461\n",
      "Epoch: 182, Batch number: 44, Loss: 61.07377243041992\n",
      "Epoch: 183, Batch number: 68, Loss: 52.24899673461914\n",
      "Epoch: 185, Batch number: 16, Loss: 51.57522201538086\n",
      "Epoch: 186, Batch number: 40, Loss: 52.27001190185547\n",
      "Epoch: 187, Batch number: 64, Loss: 57.31261444091797\n",
      "Epoch: 189, Batch number: 12, Loss: 41.80646896362305\n",
      "Epoch: 190, Batch number: 36, Loss: 46.2496223449707\n",
      "Epoch: 191, Batch number: 60, Loss: 56.824378967285156\n",
      "Epoch: 193, Batch number: 8, Loss: 46.419273376464844\n",
      "Epoch: 194, Batch number: 32, Loss: 56.97303009033203\n",
      "Epoch: 195, Batch number: 56, Loss: 46.69690704345703\n",
      "Epoch: 197, Batch number: 4, Loss: 41.190391540527344\n",
      "Epoch: 198, Batch number: 28, Loss: 45.99664306640625\n",
      "Epoch: 199, Batch number: 52, Loss: 41.9043083190918\n",
      "Epoch: 201, Batch number: 0, Loss: 42.6914176940918\n",
      "Epoch: 202, Batch number: 24, Loss: 44.807003021240234\n",
      "Epoch: 203, Batch number: 48, Loss: 40.97283935546875\n",
      "Epoch: 204, Batch number: 72, Loss: 35.41448974609375\n",
      "Epoch: 206, Batch number: 20, Loss: 29.728126525878906\n",
      "Epoch: 207, Batch number: 44, Loss: 35.476318359375\n",
      "Epoch: 208, Batch number: 68, Loss: 38.98309326171875\n",
      "Epoch: 210, Batch number: 16, Loss: 29.61493492126465\n",
      "Epoch: 211, Batch number: 40, Loss: 36.034751892089844\n",
      "Epoch: 212, Batch number: 64, Loss: 38.08668518066406\n",
      "Epoch: 214, Batch number: 12, Loss: 31.90256118774414\n",
      "Epoch: 215, Batch number: 36, Loss: 28.836782455444336\n",
      "Epoch: 216, Batch number: 60, Loss: 30.535863876342773\n",
      "Epoch: 218, Batch number: 8, Loss: 30.300804138183594\n",
      "Epoch: 219, Batch number: 32, Loss: 30.676593780517578\n",
      "Epoch: 220, Batch number: 56, Loss: 27.659442901611328\n",
      "Epoch: 222, Batch number: 4, Loss: 30.43313980102539\n",
      "Epoch: 223, Batch number: 28, Loss: 26.767074584960938\n",
      "Epoch: 224, Batch number: 52, Loss: 26.915267944335938\n",
      "Epoch: 226, Batch number: 0, Loss: 22.592632293701172\n",
      "Epoch: 227, Batch number: 24, Loss: 29.744979858398438\n",
      "Epoch: 228, Batch number: 48, Loss: 23.31977081298828\n",
      "Epoch: 229, Batch number: 72, Loss: 25.341445922851562\n",
      "Epoch: 231, Batch number: 20, Loss: 21.786544799804688\n",
      "Epoch: 232, Batch number: 44, Loss: 29.845314025878906\n",
      "Epoch: 233, Batch number: 68, Loss: 20.019805908203125\n",
      "Epoch: 235, Batch number: 16, Loss: 26.486726760864258\n",
      "Epoch: 236, Batch number: 40, Loss: 21.546968460083008\n",
      "Epoch: 237, Batch number: 64, Loss: 31.225139617919922\n",
      "Epoch: 239, Batch number: 12, Loss: 19.326210021972656\n",
      "Epoch: 240, Batch number: 36, Loss: 20.84076499938965\n",
      "Epoch: 241, Batch number: 60, Loss: 18.363719940185547\n",
      "Epoch: 243, Batch number: 8, Loss: 22.635700225830078\n",
      "Epoch: 244, Batch number: 32, Loss: 22.008453369140625\n",
      "Epoch: 245, Batch number: 56, Loss: 23.073856353759766\n",
      "Epoch: 247, Batch number: 4, Loss: 18.87612533569336\n",
      "Epoch: 248, Batch number: 28, Loss: 25.788597106933594\n",
      "Epoch: 249, Batch number: 52, Loss: 24.261310577392578\n",
      "Epoch: 251, Batch number: 0, Loss: 16.057039260864258\n",
      "Epoch: 252, Batch number: 24, Loss: 17.35518455505371\n",
      "Epoch: 253, Batch number: 48, Loss: 23.1103515625\n",
      "Epoch: 254, Batch number: 72, Loss: 21.696922302246094\n",
      "Epoch: 256, Batch number: 20, Loss: 19.218881607055664\n",
      "Epoch: 257, Batch number: 44, Loss: 22.992324829101562\n",
      "Epoch: 258, Batch number: 68, Loss: 14.415112495422363\n",
      "Epoch: 260, Batch number: 16, Loss: 19.352806091308594\n",
      "Epoch: 261, Batch number: 40, Loss: 23.87645721435547\n",
      "Epoch: 262, Batch number: 64, Loss: 15.899429321289062\n",
      "Epoch: 264, Batch number: 12, Loss: 22.002979278564453\n",
      "Epoch: 265, Batch number: 36, Loss: 22.21332359313965\n",
      "Epoch: 266, Batch number: 60, Loss: 18.143062591552734\n",
      "Epoch: 268, Batch number: 8, Loss: 17.99246597290039\n",
      "Epoch: 269, Batch number: 32, Loss: 16.774097442626953\n",
      "Epoch: 270, Batch number: 56, Loss: 17.701763153076172\n",
      "Epoch: 272, Batch number: 4, Loss: 21.111343383789062\n",
      "Epoch: 273, Batch number: 28, Loss: 21.704490661621094\n",
      "Epoch: 274, Batch number: 52, Loss: 21.373493194580078\n",
      "Epoch: 276, Batch number: 0, Loss: 26.60110092163086\n",
      "Epoch: 277, Batch number: 24, Loss: 15.153207778930664\n",
      "Epoch: 278, Batch number: 48, Loss: 22.460371017456055\n",
      "Epoch: 279, Batch number: 72, Loss: 17.537240982055664\n",
      "Epoch: 281, Batch number: 20, Loss: 21.490135192871094\n",
      "Epoch: 282, Batch number: 44, Loss: 14.465543746948242\n",
      "Epoch: 283, Batch number: 68, Loss: 14.249492645263672\n",
      "Epoch: 285, Batch number: 16, Loss: 13.336710929870605\n",
      "Epoch: 286, Batch number: 40, Loss: 14.34554672241211\n",
      "Epoch: 287, Batch number: 64, Loss: 9.705214500427246\n",
      "Epoch: 289, Batch number: 12, Loss: 13.60665225982666\n",
      "Epoch: 290, Batch number: 36, Loss: 16.69261932373047\n",
      "Epoch: 291, Batch number: 60, Loss: 15.64752197265625\n",
      "Epoch: 293, Batch number: 8, Loss: 16.123188018798828\n",
      "Epoch: 294, Batch number: 32, Loss: 21.80942726135254\n",
      "Epoch: 295, Batch number: 56, Loss: 17.01346206665039\n",
      "Epoch: 297, Batch number: 4, Loss: 13.779439926147461\n",
      "Epoch: 298, Batch number: 28, Loss: 13.343565940856934\n",
      "Epoch: 299, Batch number: 52, Loss: 15.36189079284668\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4400.9560546875\n",
      "Epoch: 2, Batch number: 24, Loss: 3815.23291015625\n",
      "Epoch: 3, Batch number: 48, Loss: 3139.660888671875\n",
      "Epoch: 4, Batch number: 72, Loss: 2890.510009765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Batch number: 20, Loss: 2687.745849609375\n",
      "Epoch: 7, Batch number: 44, Loss: 2671.986083984375\n",
      "Epoch: 8, Batch number: 68, Loss: 2629.739990234375\n",
      "Epoch: 10, Batch number: 16, Loss: 2383.28369140625\n",
      "Epoch: 11, Batch number: 40, Loss: 2325.0537109375\n",
      "Epoch: 12, Batch number: 64, Loss: 2301.017333984375\n",
      "Epoch: 14, Batch number: 12, Loss: 2186.703857421875\n",
      "Epoch: 15, Batch number: 36, Loss: 2122.824462890625\n",
      "Epoch: 16, Batch number: 60, Loss: 2070.564697265625\n",
      "Epoch: 18, Batch number: 8, Loss: 1948.8648681640625\n",
      "Epoch: 19, Batch number: 32, Loss: 1819.75830078125\n",
      "Epoch: 20, Batch number: 56, Loss: 1739.789306640625\n",
      "Epoch: 22, Batch number: 4, Loss: 1660.4359130859375\n",
      "Epoch: 23, Batch number: 28, Loss: 1579.49609375\n",
      "Epoch: 24, Batch number: 52, Loss: 1592.137939453125\n",
      "Epoch: 26, Batch number: 0, Loss: 1524.8687744140625\n",
      "Epoch: 27, Batch number: 24, Loss: 1421.00634765625\n",
      "Epoch: 28, Batch number: 48, Loss: 1398.232177734375\n",
      "Epoch: 29, Batch number: 72, Loss: 1357.6806640625\n",
      "Epoch: 31, Batch number: 20, Loss: 1244.17822265625\n",
      "Epoch: 32, Batch number: 44, Loss: 1230.72998046875\n",
      "Epoch: 33, Batch number: 68, Loss: 1239.2032470703125\n",
      "Epoch: 35, Batch number: 16, Loss: 1103.3924560546875\n",
      "Epoch: 36, Batch number: 40, Loss: 1112.86328125\n",
      "Epoch: 37, Batch number: 64, Loss: 1066.6025390625\n",
      "Epoch: 39, Batch number: 12, Loss: 1141.4049072265625\n",
      "Epoch: 40, Batch number: 36, Loss: 951.5719604492188\n",
      "Epoch: 41, Batch number: 60, Loss: 964.480712890625\n",
      "Epoch: 43, Batch number: 8, Loss: 928.756591796875\n",
      "Epoch: 44, Batch number: 32, Loss: 940.4496459960938\n",
      "Epoch: 45, Batch number: 56, Loss: 785.102294921875\n",
      "Epoch: 47, Batch number: 4, Loss: 769.4324951171875\n",
      "Epoch: 48, Batch number: 28, Loss: 867.1558227539062\n",
      "Epoch: 49, Batch number: 52, Loss: 827.9212646484375\n",
      "Epoch: 51, Batch number: 0, Loss: 758.8519287109375\n",
      "Epoch: 52, Batch number: 24, Loss: 726.0099487304688\n",
      "Epoch: 53, Batch number: 48, Loss: 706.9280395507812\n",
      "Epoch: 54, Batch number: 72, Loss: 663.625\n",
      "Epoch: 56, Batch number: 20, Loss: 661.05029296875\n",
      "Epoch: 57, Batch number: 44, Loss: 632.8787231445312\n",
      "Epoch: 58, Batch number: 68, Loss: 621.6611328125\n",
      "Epoch: 60, Batch number: 16, Loss: 566.0282592773438\n",
      "Epoch: 61, Batch number: 40, Loss: 522.3937377929688\n",
      "Epoch: 62, Batch number: 64, Loss: 536.4658813476562\n",
      "Epoch: 64, Batch number: 12, Loss: 522.1288452148438\n",
      "Epoch: 65, Batch number: 36, Loss: 509.3822326660156\n",
      "Epoch: 66, Batch number: 60, Loss: 460.06524658203125\n",
      "Epoch: 68, Batch number: 8, Loss: 459.9486389160156\n",
      "Epoch: 69, Batch number: 32, Loss: 435.5081481933594\n",
      "Epoch: 70, Batch number: 56, Loss: 426.90740966796875\n",
      "Epoch: 72, Batch number: 4, Loss: 398.1264953613281\n",
      "Epoch: 73, Batch number: 28, Loss: 371.6202087402344\n",
      "Epoch: 74, Batch number: 52, Loss: 349.5005798339844\n",
      "Epoch: 76, Batch number: 0, Loss: 349.6576232910156\n",
      "Epoch: 77, Batch number: 24, Loss: 329.1724853515625\n",
      "Epoch: 78, Batch number: 48, Loss: 328.57855224609375\n",
      "Epoch: 79, Batch number: 72, Loss: 279.9403076171875\n",
      "Epoch: 81, Batch number: 20, Loss: 288.94122314453125\n",
      "Epoch: 82, Batch number: 44, Loss: 281.5413513183594\n",
      "Epoch: 83, Batch number: 68, Loss: 257.3699035644531\n",
      "Epoch: 85, Batch number: 16, Loss: 253.8031768798828\n",
      "Epoch: 86, Batch number: 40, Loss: 258.3874206542969\n",
      "Epoch: 87, Batch number: 64, Loss: 272.77325439453125\n",
      "Epoch: 89, Batch number: 12, Loss: 229.10772705078125\n",
      "Epoch: 90, Batch number: 36, Loss: 229.15101623535156\n",
      "Epoch: 91, Batch number: 60, Loss: 204.15660095214844\n",
      "Epoch: 93, Batch number: 8, Loss: 200.5469207763672\n",
      "Epoch: 94, Batch number: 32, Loss: 191.37452697753906\n",
      "Epoch: 95, Batch number: 56, Loss: 190.16139221191406\n",
      "Epoch: 97, Batch number: 4, Loss: 175.97398376464844\n",
      "Epoch: 98, Batch number: 28, Loss: 170.6514129638672\n",
      "Epoch: 99, Batch number: 52, Loss: 168.658203125\n",
      "Epoch: 101, Batch number: 0, Loss: 176.7145233154297\n",
      "Epoch: 102, Batch number: 24, Loss: 145.3005828857422\n",
      "Epoch: 103, Batch number: 48, Loss: 154.98779296875\n",
      "Epoch: 104, Batch number: 72, Loss: 154.9591827392578\n",
      "Epoch: 106, Batch number: 20, Loss: 145.02783203125\n",
      "Epoch: 107, Batch number: 44, Loss: 129.06060791015625\n",
      "Epoch: 108, Batch number: 68, Loss: 128.93492126464844\n",
      "Epoch: 110, Batch number: 16, Loss: 111.30361938476562\n",
      "Epoch: 111, Batch number: 40, Loss: 123.99711608886719\n",
      "Epoch: 112, Batch number: 64, Loss: 129.19808959960938\n",
      "Epoch: 114, Batch number: 12, Loss: 96.28961944580078\n",
      "Epoch: 115, Batch number: 36, Loss: 107.39498901367188\n",
      "Epoch: 116, Batch number: 60, Loss: 100.36766052246094\n",
      "Epoch: 118, Batch number: 8, Loss: 109.81522369384766\n",
      "Epoch: 119, Batch number: 32, Loss: 86.0987319946289\n",
      "Epoch: 120, Batch number: 56, Loss: 98.43843841552734\n",
      "Epoch: 122, Batch number: 4, Loss: 86.32418060302734\n",
      "Epoch: 123, Batch number: 28, Loss: 79.83477020263672\n",
      "Epoch: 124, Batch number: 52, Loss: 75.55464935302734\n",
      "Epoch: 126, Batch number: 0, Loss: 81.74651336669922\n",
      "Epoch: 127, Batch number: 24, Loss: 77.04598236083984\n",
      "Epoch: 128, Batch number: 48, Loss: 71.71349334716797\n",
      "Epoch: 129, Batch number: 72, Loss: 69.31685638427734\n",
      "Epoch: 131, Batch number: 20, Loss: 72.82827758789062\n",
      "Epoch: 132, Batch number: 44, Loss: 72.58550262451172\n",
      "Epoch: 133, Batch number: 68, Loss: 74.15677642822266\n",
      "Epoch: 135, Batch number: 16, Loss: 63.747886657714844\n",
      "Epoch: 136, Batch number: 40, Loss: 67.97103881835938\n",
      "Epoch: 137, Batch number: 64, Loss: 57.789649963378906\n",
      "Epoch: 139, Batch number: 12, Loss: 60.42303466796875\n",
      "Epoch: 140, Batch number: 36, Loss: 59.97113800048828\n",
      "Epoch: 141, Batch number: 60, Loss: 52.73344421386719\n",
      "Epoch: 143, Batch number: 8, Loss: 44.51124954223633\n",
      "Epoch: 144, Batch number: 32, Loss: 49.3995475769043\n",
      "Epoch: 145, Batch number: 56, Loss: 58.396942138671875\n",
      "Epoch: 147, Batch number: 4, Loss: 43.00660705566406\n",
      "Epoch: 148, Batch number: 28, Loss: 43.9132080078125\n",
      "Epoch: 149, Batch number: 52, Loss: 45.77219009399414\n",
      "Epoch: 151, Batch number: 0, Loss: 41.138648986816406\n",
      "Epoch: 152, Batch number: 24, Loss: 42.00675582885742\n",
      "Epoch: 153, Batch number: 48, Loss: 39.644126892089844\n",
      "Epoch: 154, Batch number: 72, Loss: 43.078529357910156\n",
      "Epoch: 156, Batch number: 20, Loss: 33.11284637451172\n",
      "Epoch: 157, Batch number: 44, Loss: 38.625274658203125\n",
      "Epoch: 158, Batch number: 68, Loss: 34.86907196044922\n",
      "Epoch: 160, Batch number: 16, Loss: 38.218692779541016\n",
      "Epoch: 161, Batch number: 40, Loss: 45.559181213378906\n",
      "Epoch: 162, Batch number: 64, Loss: 35.585289001464844\n",
      "Epoch: 164, Batch number: 12, Loss: 33.06684112548828\n",
      "Epoch: 165, Batch number: 36, Loss: 33.66389465332031\n",
      "Epoch: 166, Batch number: 60, Loss: 34.207786560058594\n",
      "Epoch: 168, Batch number: 8, Loss: 31.722381591796875\n",
      "Epoch: 169, Batch number: 32, Loss: 34.465301513671875\n",
      "Epoch: 170, Batch number: 56, Loss: 31.77937889099121\n",
      "Epoch: 172, Batch number: 4, Loss: 31.927623748779297\n",
      "Epoch: 173, Batch number: 28, Loss: 28.731060028076172\n",
      "Epoch: 174, Batch number: 52, Loss: 26.273136138916016\n",
      "Epoch: 176, Batch number: 0, Loss: 32.563636779785156\n",
      "Epoch: 177, Batch number: 24, Loss: 28.478107452392578\n",
      "Epoch: 178, Batch number: 48, Loss: 29.018268585205078\n",
      "Epoch: 179, Batch number: 72, Loss: 25.087509155273438\n",
      "Epoch: 181, Batch number: 20, Loss: 22.82805633544922\n",
      "Epoch: 182, Batch number: 44, Loss: 24.20317840576172\n",
      "Epoch: 183, Batch number: 68, Loss: 26.801864624023438\n",
      "Epoch: 185, Batch number: 16, Loss: 24.963550567626953\n",
      "Epoch: 186, Batch number: 40, Loss: 29.4393253326416\n",
      "Epoch: 187, Batch number: 64, Loss: 20.338151931762695\n",
      "Epoch: 189, Batch number: 12, Loss: 21.53244400024414\n",
      "Epoch: 190, Batch number: 36, Loss: 27.129764556884766\n",
      "Epoch: 191, Batch number: 60, Loss: 27.258865356445312\n",
      "Epoch: 193, Batch number: 8, Loss: 23.113771438598633\n",
      "Epoch: 194, Batch number: 32, Loss: 21.1898136138916\n",
      "Epoch: 195, Batch number: 56, Loss: 23.390071868896484\n",
      "Epoch: 197, Batch number: 4, Loss: 17.196002960205078\n",
      "Epoch: 198, Batch number: 28, Loss: 21.96771240234375\n",
      "Epoch: 199, Batch number: 52, Loss: 16.60519027709961\n",
      "Epoch: 201, Batch number: 0, Loss: 23.832929611206055\n",
      "Epoch: 202, Batch number: 24, Loss: 20.010265350341797\n",
      "Epoch: 203, Batch number: 48, Loss: 20.91687774658203\n",
      "Epoch: 204, Batch number: 72, Loss: 22.199758529663086\n",
      "Epoch: 206, Batch number: 20, Loss: 17.324148178100586\n",
      "Epoch: 207, Batch number: 44, Loss: 24.42369842529297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 21.715354919433594\n",
      "Epoch: 210, Batch number: 16, Loss: 19.783523559570312\n",
      "Epoch: 211, Batch number: 40, Loss: 17.57761001586914\n",
      "Epoch: 212, Batch number: 64, Loss: 19.99139404296875\n",
      "Epoch: 214, Batch number: 12, Loss: 12.909432411193848\n",
      "Epoch: 215, Batch number: 36, Loss: 23.366928100585938\n",
      "Epoch: 216, Batch number: 60, Loss: 17.189556121826172\n",
      "Epoch: 218, Batch number: 8, Loss: 18.59783172607422\n",
      "Epoch: 219, Batch number: 32, Loss: 13.060160636901855\n",
      "Epoch: 220, Batch number: 56, Loss: 12.189255714416504\n",
      "Epoch: 222, Batch number: 4, Loss: 12.262720108032227\n",
      "Epoch: 223, Batch number: 28, Loss: 12.822324752807617\n",
      "Epoch: 224, Batch number: 52, Loss: 15.813018798828125\n",
      "Epoch: 226, Batch number: 0, Loss: 14.016189575195312\n",
      "Epoch: 227, Batch number: 24, Loss: 9.141705513000488\n",
      "Epoch: 228, Batch number: 48, Loss: 22.526084899902344\n",
      "Epoch: 229, Batch number: 72, Loss: 24.279029846191406\n",
      "Epoch: 231, Batch number: 20, Loss: 18.201330184936523\n",
      "Epoch: 232, Batch number: 44, Loss: 14.159374237060547\n",
      "Epoch: 233, Batch number: 68, Loss: 18.608680725097656\n",
      "Epoch: 235, Batch number: 16, Loss: 12.087352752685547\n",
      "Epoch: 236, Batch number: 40, Loss: 17.286943435668945\n",
      "Epoch: 237, Batch number: 64, Loss: 19.854124069213867\n",
      "Epoch: 239, Batch number: 12, Loss: 12.322332382202148\n",
      "Epoch: 240, Batch number: 36, Loss: 15.755698204040527\n",
      "Epoch: 241, Batch number: 60, Loss: 20.093259811401367\n",
      "Epoch: 243, Batch number: 8, Loss: 13.991299629211426\n",
      "Epoch: 244, Batch number: 32, Loss: 12.076493263244629\n",
      "Epoch: 245, Batch number: 56, Loss: 10.35255241394043\n",
      "Epoch: 247, Batch number: 4, Loss: 18.239452362060547\n",
      "Epoch: 248, Batch number: 28, Loss: 16.127418518066406\n",
      "Epoch: 249, Batch number: 52, Loss: 12.163378715515137\n",
      "Epoch: 251, Batch number: 0, Loss: 9.989448547363281\n",
      "Epoch: 252, Batch number: 24, Loss: 13.54001235961914\n",
      "Epoch: 253, Batch number: 48, Loss: 11.327816009521484\n",
      "Epoch: 254, Batch number: 72, Loss: 14.161905288696289\n",
      "Epoch: 256, Batch number: 20, Loss: 10.013272285461426\n",
      "Epoch: 257, Batch number: 44, Loss: 15.922906875610352\n",
      "Epoch: 258, Batch number: 68, Loss: 10.270758628845215\n",
      "Epoch: 260, Batch number: 16, Loss: 10.47011947631836\n",
      "Epoch: 261, Batch number: 40, Loss: 12.96063232421875\n",
      "Epoch: 262, Batch number: 64, Loss: 16.458833694458008\n",
      "Epoch: 264, Batch number: 12, Loss: 12.471099853515625\n",
      "Epoch: 265, Batch number: 36, Loss: 11.18929672241211\n",
      "Epoch: 266, Batch number: 60, Loss: 15.266448020935059\n",
      "Epoch: 268, Batch number: 8, Loss: 12.462108612060547\n",
      "Epoch: 269, Batch number: 32, Loss: 10.660685539245605\n",
      "Epoch: 270, Batch number: 56, Loss: 11.471903800964355\n",
      "Epoch: 272, Batch number: 4, Loss: 10.222173690795898\n",
      "Epoch: 273, Batch number: 28, Loss: 13.554374694824219\n",
      "Epoch: 274, Batch number: 52, Loss: 11.111471176147461\n",
      "Epoch: 276, Batch number: 0, Loss: 14.27857494354248\n",
      "Epoch: 277, Batch number: 24, Loss: 10.101690292358398\n",
      "Epoch: 278, Batch number: 48, Loss: 16.420116424560547\n",
      "Epoch: 279, Batch number: 72, Loss: 15.736117362976074\n",
      "Epoch: 281, Batch number: 20, Loss: 12.418185234069824\n",
      "Epoch: 282, Batch number: 44, Loss: 19.95728874206543\n",
      "Epoch: 283, Batch number: 68, Loss: 15.37913990020752\n",
      "Epoch: 285, Batch number: 16, Loss: 13.038480758666992\n",
      "Epoch: 286, Batch number: 40, Loss: 13.983138084411621\n",
      "Epoch: 287, Batch number: 64, Loss: 8.126664161682129\n",
      "Epoch: 289, Batch number: 12, Loss: 12.474495887756348\n",
      "Epoch: 290, Batch number: 36, Loss: 10.579780578613281\n",
      "Epoch: 291, Batch number: 60, Loss: 9.182015419006348\n",
      "Epoch: 293, Batch number: 8, Loss: 12.369351387023926\n",
      "Epoch: 294, Batch number: 32, Loss: 11.011488914489746\n",
      "Epoch: 295, Batch number: 56, Loss: 12.694620132446289\n",
      "Epoch: 297, Batch number: 4, Loss: 9.918375015258789\n",
      "Epoch: 298, Batch number: 28, Loss: 7.520204544067383\n",
      "Epoch: 299, Batch number: 52, Loss: 6.490791320800781\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4406.76123046875\n",
      "Epoch: 2, Batch number: 24, Loss: 3640.49853515625\n",
      "Epoch: 3, Batch number: 48, Loss: 3045.423095703125\n",
      "Epoch: 4, Batch number: 72, Loss: 2932.665771484375\n",
      "Epoch: 6, Batch number: 20, Loss: 2686.589599609375\n",
      "Epoch: 7, Batch number: 44, Loss: 2446.931884765625\n",
      "Epoch: 8, Batch number: 68, Loss: 2383.411376953125\n",
      "Epoch: 10, Batch number: 16, Loss: 2219.1552734375\n",
      "Epoch: 11, Batch number: 40, Loss: 2227.430908203125\n",
      "Epoch: 12, Batch number: 64, Loss: 2147.943359375\n",
      "Epoch: 14, Batch number: 12, Loss: 1943.6817626953125\n",
      "Epoch: 15, Batch number: 36, Loss: 1873.0770263671875\n",
      "Epoch: 16, Batch number: 60, Loss: 1720.4078369140625\n",
      "Epoch: 18, Batch number: 8, Loss: 1661.4156494140625\n",
      "Epoch: 19, Batch number: 32, Loss: 1549.1351318359375\n",
      "Epoch: 20, Batch number: 56, Loss: 1432.433837890625\n",
      "Epoch: 22, Batch number: 4, Loss: 1464.882080078125\n",
      "Epoch: 23, Batch number: 28, Loss: 1342.47021484375\n",
      "Epoch: 24, Batch number: 52, Loss: 1293.4193115234375\n",
      "Epoch: 26, Batch number: 0, Loss: 1273.99853515625\n",
      "Epoch: 27, Batch number: 24, Loss: 1211.877685546875\n",
      "Epoch: 28, Batch number: 48, Loss: 1142.0968017578125\n",
      "Epoch: 29, Batch number: 72, Loss: 1087.1278076171875\n",
      "Epoch: 31, Batch number: 20, Loss: 1005.9453735351562\n",
      "Epoch: 32, Batch number: 44, Loss: 1066.77294921875\n",
      "Epoch: 33, Batch number: 68, Loss: 941.2703857421875\n",
      "Epoch: 35, Batch number: 16, Loss: 899.2127075195312\n",
      "Epoch: 36, Batch number: 40, Loss: 873.8630981445312\n",
      "Epoch: 37, Batch number: 64, Loss: 814.7158203125\n",
      "Epoch: 39, Batch number: 12, Loss: 833.4329223632812\n",
      "Epoch: 40, Batch number: 36, Loss: 740.1264038085938\n",
      "Epoch: 41, Batch number: 60, Loss: 770.016845703125\n",
      "Epoch: 43, Batch number: 8, Loss: 662.7247314453125\n",
      "Epoch: 44, Batch number: 32, Loss: 670.6227416992188\n",
      "Epoch: 45, Batch number: 56, Loss: 680.3279418945312\n",
      "Epoch: 47, Batch number: 4, Loss: 614.3433837890625\n",
      "Epoch: 48, Batch number: 28, Loss: 573.8965454101562\n",
      "Epoch: 49, Batch number: 52, Loss: 590.9735717773438\n",
      "Epoch: 51, Batch number: 0, Loss: 497.8717346191406\n",
      "Epoch: 52, Batch number: 24, Loss: 494.69512939453125\n",
      "Epoch: 53, Batch number: 48, Loss: 507.19378662109375\n",
      "Epoch: 54, Batch number: 72, Loss: 480.11260986328125\n",
      "Epoch: 56, Batch number: 20, Loss: 422.63232421875\n",
      "Epoch: 57, Batch number: 44, Loss: 423.114990234375\n",
      "Epoch: 58, Batch number: 68, Loss: 425.2456359863281\n",
      "Epoch: 60, Batch number: 16, Loss: 387.1167907714844\n",
      "Epoch: 61, Batch number: 40, Loss: 351.37994384765625\n",
      "Epoch: 62, Batch number: 64, Loss: 343.2755432128906\n",
      "Epoch: 64, Batch number: 12, Loss: 354.6553649902344\n",
      "Epoch: 65, Batch number: 36, Loss: 316.6319885253906\n",
      "Epoch: 66, Batch number: 60, Loss: 296.3065490722656\n",
      "Epoch: 68, Batch number: 8, Loss: 302.8300476074219\n",
      "Epoch: 69, Batch number: 32, Loss: 249.01129150390625\n",
      "Epoch: 70, Batch number: 56, Loss: 250.45018005371094\n",
      "Epoch: 72, Batch number: 4, Loss: 239.5354461669922\n",
      "Epoch: 73, Batch number: 28, Loss: 248.62774658203125\n",
      "Epoch: 74, Batch number: 52, Loss: 212.42898559570312\n",
      "Epoch: 76, Batch number: 0, Loss: 184.0648193359375\n",
      "Epoch: 77, Batch number: 24, Loss: 203.68531799316406\n",
      "Epoch: 78, Batch number: 48, Loss: 214.0649871826172\n",
      "Epoch: 79, Batch number: 72, Loss: 204.5078582763672\n",
      "Epoch: 81, Batch number: 20, Loss: 192.90277099609375\n",
      "Epoch: 82, Batch number: 44, Loss: 171.04934692382812\n",
      "Epoch: 83, Batch number: 68, Loss: 172.8944549560547\n",
      "Epoch: 85, Batch number: 16, Loss: 141.81460571289062\n",
      "Epoch: 86, Batch number: 40, Loss: 154.7155303955078\n",
      "Epoch: 87, Batch number: 64, Loss: 146.6156463623047\n",
      "Epoch: 89, Batch number: 12, Loss: 128.49598693847656\n",
      "Epoch: 90, Batch number: 36, Loss: 128.33547973632812\n",
      "Epoch: 91, Batch number: 60, Loss: 122.54149627685547\n",
      "Epoch: 93, Batch number: 8, Loss: 119.55276489257812\n",
      "Epoch: 94, Batch number: 32, Loss: 110.36418914794922\n",
      "Epoch: 95, Batch number: 56, Loss: 108.09552764892578\n",
      "Epoch: 97, Batch number: 4, Loss: 111.16334533691406\n",
      "Epoch: 98, Batch number: 28, Loss: 96.49510192871094\n",
      "Epoch: 99, Batch number: 52, Loss: 95.98556518554688\n",
      "Epoch: 101, Batch number: 0, Loss: 106.05154418945312\n",
      "Epoch: 102, Batch number: 24, Loss: 83.33580780029297\n",
      "Epoch: 103, Batch number: 48, Loss: 81.5078125\n",
      "Epoch: 104, Batch number: 72, Loss: 81.40506744384766\n",
      "Epoch: 106, Batch number: 20, Loss: 72.32658386230469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 79.00160217285156\n",
      "Epoch: 108, Batch number: 68, Loss: 82.60008239746094\n",
      "Epoch: 110, Batch number: 16, Loss: 66.15237426757812\n",
      "Epoch: 111, Batch number: 40, Loss: 60.54639434814453\n",
      "Epoch: 112, Batch number: 64, Loss: 66.10964965820312\n",
      "Epoch: 114, Batch number: 12, Loss: 61.74530792236328\n",
      "Epoch: 115, Batch number: 36, Loss: 59.615028381347656\n",
      "Epoch: 116, Batch number: 60, Loss: 67.64049530029297\n",
      "Epoch: 118, Batch number: 8, Loss: 49.75323486328125\n",
      "Epoch: 119, Batch number: 32, Loss: 59.624671936035156\n",
      "Epoch: 120, Batch number: 56, Loss: 54.767295837402344\n",
      "Epoch: 122, Batch number: 4, Loss: 56.05175018310547\n",
      "Epoch: 123, Batch number: 28, Loss: 54.960426330566406\n",
      "Epoch: 124, Batch number: 52, Loss: 45.94226837158203\n",
      "Epoch: 126, Batch number: 0, Loss: 36.15059280395508\n",
      "Epoch: 127, Batch number: 24, Loss: 47.59651184082031\n",
      "Epoch: 128, Batch number: 48, Loss: 42.875091552734375\n",
      "Epoch: 129, Batch number: 72, Loss: 42.266448974609375\n",
      "Epoch: 131, Batch number: 20, Loss: 33.810279846191406\n",
      "Epoch: 132, Batch number: 44, Loss: 37.83738327026367\n",
      "Epoch: 133, Batch number: 68, Loss: 37.5015754699707\n",
      "Epoch: 135, Batch number: 16, Loss: 40.687164306640625\n",
      "Epoch: 136, Batch number: 40, Loss: 37.653106689453125\n",
      "Epoch: 137, Batch number: 64, Loss: 36.27604675292969\n",
      "Epoch: 139, Batch number: 12, Loss: 38.52463912963867\n",
      "Epoch: 140, Batch number: 36, Loss: 36.49858474731445\n",
      "Epoch: 141, Batch number: 60, Loss: 32.96607208251953\n",
      "Epoch: 143, Batch number: 8, Loss: 31.031997680664062\n",
      "Epoch: 144, Batch number: 32, Loss: 32.10975646972656\n",
      "Epoch: 145, Batch number: 56, Loss: 35.12089538574219\n",
      "Epoch: 147, Batch number: 4, Loss: 28.353546142578125\n",
      "Epoch: 148, Batch number: 28, Loss: 25.442176818847656\n",
      "Epoch: 149, Batch number: 52, Loss: 27.104856491088867\n",
      "Epoch: 151, Batch number: 0, Loss: 26.94870376586914\n",
      "Epoch: 152, Batch number: 24, Loss: 28.08036231994629\n",
      "Epoch: 153, Batch number: 48, Loss: 25.20562171936035\n",
      "Epoch: 154, Batch number: 72, Loss: 30.016857147216797\n",
      "Epoch: 156, Batch number: 20, Loss: 20.438220977783203\n",
      "Epoch: 157, Batch number: 44, Loss: 31.254667282104492\n",
      "Epoch: 158, Batch number: 68, Loss: 29.631410598754883\n",
      "Epoch: 160, Batch number: 16, Loss: 25.372150421142578\n",
      "Epoch: 161, Batch number: 40, Loss: 21.677520751953125\n",
      "Epoch: 162, Batch number: 64, Loss: 24.521488189697266\n",
      "Epoch: 164, Batch number: 12, Loss: 30.70281982421875\n",
      "Epoch: 165, Batch number: 36, Loss: 27.404260635375977\n",
      "Epoch: 166, Batch number: 60, Loss: 23.09256362915039\n",
      "Epoch: 168, Batch number: 8, Loss: 24.29816246032715\n",
      "Epoch: 169, Batch number: 32, Loss: 25.434486389160156\n",
      "Epoch: 170, Batch number: 56, Loss: 21.7342529296875\n",
      "Epoch: 172, Batch number: 4, Loss: 19.29764175415039\n",
      "Epoch: 173, Batch number: 28, Loss: 21.433258056640625\n",
      "Epoch: 174, Batch number: 52, Loss: 21.018978118896484\n",
      "Epoch: 176, Batch number: 0, Loss: 23.201602935791016\n",
      "Epoch: 177, Batch number: 24, Loss: 24.82017707824707\n",
      "Epoch: 178, Batch number: 48, Loss: 17.96939468383789\n",
      "Epoch: 179, Batch number: 72, Loss: 26.951828002929688\n",
      "Epoch: 181, Batch number: 20, Loss: 14.25743579864502\n",
      "Epoch: 182, Batch number: 44, Loss: 23.18218231201172\n",
      "Epoch: 183, Batch number: 68, Loss: 19.671701431274414\n",
      "Epoch: 185, Batch number: 16, Loss: 20.545948028564453\n",
      "Epoch: 186, Batch number: 40, Loss: 21.33075714111328\n",
      "Epoch: 187, Batch number: 64, Loss: 19.20818328857422\n",
      "Epoch: 189, Batch number: 12, Loss: 18.415115356445312\n",
      "Epoch: 190, Batch number: 36, Loss: 12.162443161010742\n",
      "Epoch: 191, Batch number: 60, Loss: 20.518136978149414\n",
      "Epoch: 193, Batch number: 8, Loss: 16.306198120117188\n",
      "Epoch: 194, Batch number: 32, Loss: 18.584766387939453\n",
      "Epoch: 195, Batch number: 56, Loss: 26.356395721435547\n",
      "Epoch: 197, Batch number: 4, Loss: 15.54233169555664\n",
      "Epoch: 198, Batch number: 28, Loss: 14.376189231872559\n",
      "Epoch: 199, Batch number: 52, Loss: 15.734136581420898\n",
      "Epoch: 201, Batch number: 0, Loss: 18.977886199951172\n",
      "Epoch: 202, Batch number: 24, Loss: 13.07182502746582\n",
      "Epoch: 203, Batch number: 48, Loss: 19.178722381591797\n",
      "Epoch: 204, Batch number: 72, Loss: 20.333847045898438\n",
      "Epoch: 206, Batch number: 20, Loss: 15.821200370788574\n",
      "Epoch: 207, Batch number: 44, Loss: 14.524968147277832\n",
      "Epoch: 208, Batch number: 68, Loss: 13.380973815917969\n",
      "Epoch: 210, Batch number: 16, Loss: 13.51844310760498\n",
      "Epoch: 211, Batch number: 40, Loss: 13.715394973754883\n",
      "Epoch: 212, Batch number: 64, Loss: 16.809001922607422\n",
      "Epoch: 214, Batch number: 12, Loss: 14.486481666564941\n",
      "Epoch: 215, Batch number: 36, Loss: 13.190825462341309\n",
      "Epoch: 216, Batch number: 60, Loss: 15.665175437927246\n",
      "Epoch: 218, Batch number: 8, Loss: 14.44979476928711\n",
      "Epoch: 219, Batch number: 32, Loss: 12.725037574768066\n",
      "Epoch: 220, Batch number: 56, Loss: 18.009727478027344\n",
      "Epoch: 222, Batch number: 4, Loss: 9.3612060546875\n",
      "Epoch: 223, Batch number: 28, Loss: 12.508851051330566\n",
      "Epoch: 224, Batch number: 52, Loss: 11.56855583190918\n",
      "Epoch: 226, Batch number: 0, Loss: 15.060942649841309\n",
      "Epoch: 227, Batch number: 24, Loss: 13.93349552154541\n",
      "Epoch: 228, Batch number: 48, Loss: 18.31478500366211\n",
      "Epoch: 229, Batch number: 72, Loss: 15.830397605895996\n",
      "Epoch: 231, Batch number: 20, Loss: 9.861139297485352\n",
      "Epoch: 232, Batch number: 44, Loss: 21.665393829345703\n",
      "Epoch: 233, Batch number: 68, Loss: 14.790765762329102\n",
      "Epoch: 235, Batch number: 16, Loss: 14.49771785736084\n",
      "Epoch: 236, Batch number: 40, Loss: 15.507564544677734\n",
      "Epoch: 237, Batch number: 64, Loss: 9.704804420471191\n",
      "Epoch: 239, Batch number: 12, Loss: 11.352170944213867\n",
      "Epoch: 240, Batch number: 36, Loss: 9.382980346679688\n",
      "Epoch: 241, Batch number: 60, Loss: 12.1438627243042\n",
      "Epoch: 243, Batch number: 8, Loss: 20.652645111083984\n",
      "Epoch: 244, Batch number: 32, Loss: 17.882097244262695\n",
      "Epoch: 245, Batch number: 56, Loss: 21.063980102539062\n",
      "Epoch: 247, Batch number: 4, Loss: 11.355026245117188\n",
      "Epoch: 248, Batch number: 28, Loss: 11.263450622558594\n",
      "Epoch: 249, Batch number: 52, Loss: 6.479011535644531\n",
      "Epoch: 251, Batch number: 0, Loss: 10.438843727111816\n",
      "Epoch: 252, Batch number: 24, Loss: 12.107300758361816\n",
      "Epoch: 253, Batch number: 48, Loss: 12.863308906555176\n",
      "Epoch: 254, Batch number: 72, Loss: 15.928483009338379\n",
      "Epoch: 256, Batch number: 20, Loss: 16.004188537597656\n",
      "Epoch: 257, Batch number: 44, Loss: 8.575539588928223\n",
      "Epoch: 258, Batch number: 68, Loss: 11.12828540802002\n",
      "Epoch: 260, Batch number: 16, Loss: 9.671207427978516\n",
      "Epoch: 261, Batch number: 40, Loss: 15.19522476196289\n",
      "Epoch: 262, Batch number: 64, Loss: 17.981918334960938\n",
      "Epoch: 264, Batch number: 12, Loss: 11.517348289489746\n",
      "Epoch: 265, Batch number: 36, Loss: 8.247917175292969\n",
      "Epoch: 266, Batch number: 60, Loss: 14.580293655395508\n",
      "Epoch: 268, Batch number: 8, Loss: 10.405291557312012\n",
      "Epoch: 269, Batch number: 32, Loss: 10.666123390197754\n",
      "Epoch: 270, Batch number: 56, Loss: 13.622642517089844\n",
      "Epoch: 272, Batch number: 4, Loss: 14.67596435546875\n",
      "Epoch: 273, Batch number: 28, Loss: 10.368362426757812\n",
      "Epoch: 274, Batch number: 52, Loss: 9.652548789978027\n",
      "Epoch: 276, Batch number: 0, Loss: 12.848642349243164\n",
      "Epoch: 277, Batch number: 24, Loss: 12.738720893859863\n",
      "Epoch: 278, Batch number: 48, Loss: 11.133403778076172\n",
      "Epoch: 279, Batch number: 72, Loss: 11.392007827758789\n",
      "Epoch: 281, Batch number: 20, Loss: 14.320591926574707\n",
      "Epoch: 282, Batch number: 44, Loss: 12.550408363342285\n",
      "Epoch: 283, Batch number: 68, Loss: 18.548931121826172\n",
      "Epoch: 285, Batch number: 16, Loss: 11.132375717163086\n",
      "Epoch: 286, Batch number: 40, Loss: 8.481802940368652\n",
      "Epoch: 287, Batch number: 64, Loss: 14.21274185180664\n",
      "Epoch: 289, Batch number: 12, Loss: 13.365227699279785\n",
      "Epoch: 290, Batch number: 36, Loss: 15.815399169921875\n",
      "Epoch: 291, Batch number: 60, Loss: 10.159890174865723\n",
      "Epoch: 293, Batch number: 8, Loss: 12.537084579467773\n",
      "Epoch: 294, Batch number: 32, Loss: 20.193729400634766\n",
      "Epoch: 295, Batch number: 56, Loss: 14.069925308227539\n",
      "Epoch: 297, Batch number: 4, Loss: 9.669906616210938\n",
      "Epoch: 298, Batch number: 28, Loss: 8.337591171264648\n",
      "Epoch: 299, Batch number: 52, Loss: 15.494298934936523\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4403.4228515625\n",
      "Epoch: 2, Batch number: 24, Loss: 4278.2822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch number: 48, Loss: 4065.38232421875\n",
      "Epoch: 4, Batch number: 72, Loss: 3750.33251953125\n",
      "Epoch: 6, Batch number: 20, Loss: 3366.41796875\n",
      "Epoch: 7, Batch number: 44, Loss: 3149.191162109375\n",
      "Epoch: 8, Batch number: 68, Loss: 3187.37890625\n",
      "Epoch: 10, Batch number: 16, Loss: 3037.5654296875\n",
      "Epoch: 11, Batch number: 40, Loss: 3043.822998046875\n",
      "Epoch: 12, Batch number: 64, Loss: 3041.80712890625\n",
      "Epoch: 14, Batch number: 12, Loss: 3063.470703125\n",
      "Epoch: 15, Batch number: 36, Loss: 2940.193359375\n",
      "Epoch: 16, Batch number: 60, Loss: 2993.420166015625\n",
      "Epoch: 18, Batch number: 8, Loss: 2857.307861328125\n",
      "Epoch: 19, Batch number: 32, Loss: 2953.5576171875\n",
      "Epoch: 20, Batch number: 56, Loss: 2872.820068359375\n",
      "Epoch: 22, Batch number: 4, Loss: 2744.323486328125\n",
      "Epoch: 23, Batch number: 28, Loss: 2849.763427734375\n",
      "Epoch: 24, Batch number: 52, Loss: 2848.234619140625\n",
      "Epoch: 26, Batch number: 0, Loss: 2765.244140625\n",
      "Epoch: 27, Batch number: 24, Loss: 2669.582275390625\n",
      "Epoch: 28, Batch number: 48, Loss: 2753.967041015625\n",
      "Epoch: 29, Batch number: 72, Loss: 2654.24365234375\n",
      "Epoch: 31, Batch number: 20, Loss: 2759.5048828125\n",
      "Epoch: 32, Batch number: 44, Loss: 2692.33447265625\n",
      "Epoch: 33, Batch number: 68, Loss: 2614.98291015625\n",
      "Epoch: 35, Batch number: 16, Loss: 2652.015625\n",
      "Epoch: 36, Batch number: 40, Loss: 2604.634521484375\n",
      "Epoch: 37, Batch number: 64, Loss: 2578.1484375\n",
      "Epoch: 39, Batch number: 12, Loss: 2676.954833984375\n",
      "Epoch: 40, Batch number: 36, Loss: 2575.89990234375\n",
      "Epoch: 41, Batch number: 60, Loss: 2446.169189453125\n",
      "Epoch: 43, Batch number: 8, Loss: 2409.021484375\n",
      "Epoch: 44, Batch number: 32, Loss: 2450.47265625\n",
      "Epoch: 45, Batch number: 56, Loss: 2471.91650390625\n",
      "Epoch: 47, Batch number: 4, Loss: 2451.514892578125\n",
      "Epoch: 48, Batch number: 28, Loss: 2482.124755859375\n",
      "Epoch: 49, Batch number: 52, Loss: 2380.428466796875\n",
      "Epoch: 51, Batch number: 0, Loss: 2424.656494140625\n",
      "Epoch: 52, Batch number: 24, Loss: 2361.443603515625\n",
      "Epoch: 53, Batch number: 48, Loss: 2266.501953125\n",
      "Epoch: 54, Batch number: 72, Loss: 2237.831298828125\n",
      "Epoch: 56, Batch number: 20, Loss: 2258.724609375\n",
      "Epoch: 57, Batch number: 44, Loss: 2195.865966796875\n",
      "Epoch: 58, Batch number: 68, Loss: 2323.873046875\n",
      "Epoch: 60, Batch number: 16, Loss: 2236.240966796875\n",
      "Epoch: 61, Batch number: 40, Loss: 2194.9140625\n",
      "Epoch: 62, Batch number: 64, Loss: 2223.2236328125\n",
      "Epoch: 64, Batch number: 12, Loss: 2207.885498046875\n",
      "Epoch: 65, Batch number: 36, Loss: 2127.740234375\n",
      "Epoch: 66, Batch number: 60, Loss: 2242.409423828125\n",
      "Epoch: 68, Batch number: 8, Loss: 2047.65673828125\n",
      "Epoch: 69, Batch number: 32, Loss: 2153.77783203125\n",
      "Epoch: 70, Batch number: 56, Loss: 2060.019287109375\n",
      "Epoch: 72, Batch number: 4, Loss: 2048.04248046875\n",
      "Epoch: 73, Batch number: 28, Loss: 1976.3712158203125\n",
      "Epoch: 74, Batch number: 52, Loss: 2004.4345703125\n",
      "Epoch: 76, Batch number: 0, Loss: 2030.462158203125\n",
      "Epoch: 77, Batch number: 24, Loss: 1963.648681640625\n",
      "Epoch: 78, Batch number: 48, Loss: 2041.2479248046875\n",
      "Epoch: 79, Batch number: 72, Loss: 1881.2552490234375\n",
      "Epoch: 81, Batch number: 20, Loss: 1915.0721435546875\n",
      "Epoch: 82, Batch number: 44, Loss: 1874.8006591796875\n",
      "Epoch: 83, Batch number: 68, Loss: 1854.6221923828125\n",
      "Epoch: 85, Batch number: 16, Loss: 1763.4822998046875\n",
      "Epoch: 86, Batch number: 40, Loss: 1764.5526123046875\n",
      "Epoch: 87, Batch number: 64, Loss: 1844.6617431640625\n",
      "Epoch: 89, Batch number: 12, Loss: 1828.6678466796875\n",
      "Epoch: 90, Batch number: 36, Loss: 1893.5269775390625\n",
      "Epoch: 91, Batch number: 60, Loss: 1826.8701171875\n",
      "Epoch: 93, Batch number: 8, Loss: 1737.32275390625\n",
      "Epoch: 94, Batch number: 32, Loss: 1751.467529296875\n",
      "Epoch: 95, Batch number: 56, Loss: 1828.8350830078125\n",
      "Epoch: 97, Batch number: 4, Loss: 1745.9053955078125\n",
      "Epoch: 98, Batch number: 28, Loss: 1755.065673828125\n",
      "Epoch: 99, Batch number: 52, Loss: 1731.6376953125\n",
      "Epoch: 101, Batch number: 0, Loss: 1681.774658203125\n",
      "Epoch: 102, Batch number: 24, Loss: 1575.2186279296875\n",
      "Epoch: 103, Batch number: 48, Loss: 1662.62451171875\n",
      "Epoch: 104, Batch number: 72, Loss: 1676.53857421875\n",
      "Epoch: 106, Batch number: 20, Loss: 1628.5670166015625\n",
      "Epoch: 107, Batch number: 44, Loss: 1656.7960205078125\n",
      "Epoch: 108, Batch number: 68, Loss: 1603.73681640625\n",
      "Epoch: 110, Batch number: 16, Loss: 1563.289794921875\n",
      "Epoch: 111, Batch number: 40, Loss: 1562.6922607421875\n",
      "Epoch: 112, Batch number: 64, Loss: 1593.885009765625\n",
      "Epoch: 114, Batch number: 12, Loss: 1575.857421875\n",
      "Epoch: 115, Batch number: 36, Loss: 1537.4144287109375\n",
      "Epoch: 116, Batch number: 60, Loss: 1490.0728759765625\n",
      "Epoch: 118, Batch number: 8, Loss: 1506.060302734375\n",
      "Epoch: 119, Batch number: 32, Loss: 1549.4310302734375\n",
      "Epoch: 120, Batch number: 56, Loss: 1510.9205322265625\n",
      "Epoch: 122, Batch number: 4, Loss: 1438.8536376953125\n",
      "Epoch: 123, Batch number: 28, Loss: 1484.2760009765625\n",
      "Epoch: 124, Batch number: 52, Loss: 1436.658447265625\n",
      "Epoch: 126, Batch number: 0, Loss: 1351.0452880859375\n",
      "Epoch: 127, Batch number: 24, Loss: 1473.0703125\n",
      "Epoch: 128, Batch number: 48, Loss: 1316.0220947265625\n",
      "Epoch: 129, Batch number: 72, Loss: 1460.2254638671875\n",
      "Epoch: 131, Batch number: 20, Loss: 1436.4522705078125\n",
      "Epoch: 132, Batch number: 44, Loss: 1381.654052734375\n",
      "Epoch: 133, Batch number: 68, Loss: 1356.13330078125\n",
      "Epoch: 135, Batch number: 16, Loss: 1319.440673828125\n",
      "Epoch: 136, Batch number: 40, Loss: 1351.693359375\n",
      "Epoch: 137, Batch number: 64, Loss: 1236.172119140625\n",
      "Epoch: 139, Batch number: 12, Loss: 1333.5101318359375\n",
      "Epoch: 140, Batch number: 36, Loss: 1383.476806640625\n",
      "Epoch: 141, Batch number: 60, Loss: 1301.9053955078125\n",
      "Epoch: 143, Batch number: 8, Loss: 1294.2275390625\n",
      "Epoch: 144, Batch number: 32, Loss: 1361.73486328125\n",
      "Epoch: 145, Batch number: 56, Loss: 1267.7864990234375\n",
      "Epoch: 147, Batch number: 4, Loss: 1312.1944580078125\n",
      "Epoch: 148, Batch number: 28, Loss: 1271.8385009765625\n",
      "Epoch: 149, Batch number: 52, Loss: 1288.7069091796875\n",
      "Epoch: 151, Batch number: 0, Loss: 1275.5828857421875\n",
      "Epoch: 152, Batch number: 24, Loss: 1200.3048095703125\n",
      "Epoch: 153, Batch number: 48, Loss: 1223.9151611328125\n",
      "Epoch: 154, Batch number: 72, Loss: 1183.989013671875\n",
      "Epoch: 156, Batch number: 20, Loss: 1309.3935546875\n",
      "Epoch: 157, Batch number: 44, Loss: 1171.718505859375\n",
      "Epoch: 158, Batch number: 68, Loss: 1206.467041015625\n",
      "Epoch: 160, Batch number: 16, Loss: 1185.914794921875\n",
      "Epoch: 161, Batch number: 40, Loss: 1188.8856201171875\n",
      "Epoch: 162, Batch number: 64, Loss: 1164.9039306640625\n",
      "Epoch: 164, Batch number: 12, Loss: 1207.6971435546875\n",
      "Epoch: 165, Batch number: 36, Loss: 1157.42578125\n",
      "Epoch: 166, Batch number: 60, Loss: 1194.951171875\n",
      "Epoch: 168, Batch number: 8, Loss: 1172.691162109375\n",
      "Epoch: 169, Batch number: 32, Loss: 1156.7454833984375\n",
      "Epoch: 170, Batch number: 56, Loss: 1039.001953125\n",
      "Epoch: 172, Batch number: 4, Loss: 1124.416015625\n",
      "Epoch: 173, Batch number: 28, Loss: 1038.701171875\n",
      "Epoch: 174, Batch number: 52, Loss: 1145.547119140625\n",
      "Epoch: 176, Batch number: 0, Loss: 1177.554931640625\n",
      "Epoch: 177, Batch number: 24, Loss: 1093.6827392578125\n",
      "Epoch: 178, Batch number: 48, Loss: 1044.99658203125\n",
      "Epoch: 179, Batch number: 72, Loss: 1066.8568115234375\n",
      "Epoch: 181, Batch number: 20, Loss: 1041.3641357421875\n",
      "Epoch: 182, Batch number: 44, Loss: 1045.9779052734375\n",
      "Epoch: 183, Batch number: 68, Loss: 1019.0826416015625\n",
      "Epoch: 185, Batch number: 16, Loss: 1036.0943603515625\n",
      "Epoch: 186, Batch number: 40, Loss: 1008.881591796875\n",
      "Epoch: 187, Batch number: 64, Loss: 1018.1533203125\n",
      "Epoch: 189, Batch number: 12, Loss: 925.3931884765625\n",
      "Epoch: 190, Batch number: 36, Loss: 1039.77783203125\n",
      "Epoch: 191, Batch number: 60, Loss: 957.83349609375\n",
      "Epoch: 193, Batch number: 8, Loss: 987.5658569335938\n",
      "Epoch: 194, Batch number: 32, Loss: 1058.4652099609375\n",
      "Epoch: 195, Batch number: 56, Loss: 1060.9793701171875\n",
      "Epoch: 197, Batch number: 4, Loss: 972.3441772460938\n",
      "Epoch: 198, Batch number: 28, Loss: 964.7285766601562\n",
      "Epoch: 199, Batch number: 52, Loss: 921.8959350585938\n",
      "Epoch: 201, Batch number: 0, Loss: 863.2139892578125\n",
      "Epoch: 202, Batch number: 24, Loss: 964.2225952148438\n",
      "Epoch: 203, Batch number: 48, Loss: 884.9996948242188\n",
      "Epoch: 204, Batch number: 72, Loss: 958.2858276367188\n",
      "Epoch: 206, Batch number: 20, Loss: 969.7350463867188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207, Batch number: 44, Loss: 927.7793579101562\n",
      "Epoch: 208, Batch number: 68, Loss: 949.3043212890625\n",
      "Epoch: 210, Batch number: 16, Loss: 905.3060302734375\n",
      "Epoch: 211, Batch number: 40, Loss: 865.6679077148438\n",
      "Epoch: 212, Batch number: 64, Loss: 948.8893432617188\n",
      "Epoch: 214, Batch number: 12, Loss: 884.936767578125\n",
      "Epoch: 215, Batch number: 36, Loss: 902.4417724609375\n",
      "Epoch: 216, Batch number: 60, Loss: 872.7762451171875\n",
      "Epoch: 218, Batch number: 8, Loss: 816.743896484375\n",
      "Epoch: 219, Batch number: 32, Loss: 952.0030517578125\n",
      "Epoch: 220, Batch number: 56, Loss: 874.7337036132812\n",
      "Epoch: 222, Batch number: 4, Loss: 810.9677734375\n",
      "Epoch: 223, Batch number: 28, Loss: 878.3245239257812\n",
      "Epoch: 224, Batch number: 52, Loss: 790.48046875\n",
      "Epoch: 226, Batch number: 0, Loss: 796.0789184570312\n",
      "Epoch: 227, Batch number: 24, Loss: 864.83203125\n",
      "Epoch: 228, Batch number: 48, Loss: 765.7867431640625\n",
      "Epoch: 229, Batch number: 72, Loss: 815.9138793945312\n",
      "Epoch: 231, Batch number: 20, Loss: 788.384765625\n",
      "Epoch: 232, Batch number: 44, Loss: 779.1099243164062\n",
      "Epoch: 233, Batch number: 68, Loss: 813.6777954101562\n",
      "Epoch: 235, Batch number: 16, Loss: 750.6214599609375\n",
      "Epoch: 236, Batch number: 40, Loss: 743.8538208007812\n",
      "Epoch: 237, Batch number: 64, Loss: 758.1212768554688\n",
      "Epoch: 239, Batch number: 12, Loss: 761.329833984375\n",
      "Epoch: 240, Batch number: 36, Loss: 766.0339965820312\n",
      "Epoch: 241, Batch number: 60, Loss: 756.5383911132812\n",
      "Epoch: 243, Batch number: 8, Loss: 690.7634887695312\n",
      "Epoch: 244, Batch number: 32, Loss: 749.017578125\n",
      "Epoch: 245, Batch number: 56, Loss: 713.1455688476562\n",
      "Epoch: 247, Batch number: 4, Loss: 713.4524536132812\n",
      "Epoch: 248, Batch number: 28, Loss: 794.540283203125\n",
      "Epoch: 249, Batch number: 52, Loss: 702.8916015625\n",
      "Epoch: 251, Batch number: 0, Loss: 688.6157836914062\n",
      "Epoch: 252, Batch number: 24, Loss: 674.890380859375\n",
      "Epoch: 253, Batch number: 48, Loss: 713.8781127929688\n",
      "Epoch: 254, Batch number: 72, Loss: 715.53564453125\n",
      "Epoch: 256, Batch number: 20, Loss: 673.7844848632812\n",
      "Epoch: 257, Batch number: 44, Loss: 696.9444580078125\n",
      "Epoch: 258, Batch number: 68, Loss: 689.3267211914062\n",
      "Epoch: 260, Batch number: 16, Loss: 704.7554321289062\n",
      "Epoch: 261, Batch number: 40, Loss: 709.7634887695312\n",
      "Epoch: 262, Batch number: 64, Loss: 623.204345703125\n",
      "Epoch: 264, Batch number: 12, Loss: 662.260986328125\n",
      "Epoch: 265, Batch number: 36, Loss: 651.9414672851562\n",
      "Epoch: 266, Batch number: 60, Loss: 673.337158203125\n",
      "Epoch: 268, Batch number: 8, Loss: 677.7306518554688\n",
      "Epoch: 269, Batch number: 32, Loss: 675.216796875\n",
      "Epoch: 270, Batch number: 56, Loss: 643.773681640625\n",
      "Epoch: 272, Batch number: 4, Loss: 684.5776977539062\n",
      "Epoch: 273, Batch number: 28, Loss: 645.628662109375\n",
      "Epoch: 274, Batch number: 52, Loss: 666.8545532226562\n",
      "Epoch: 276, Batch number: 0, Loss: 658.8756103515625\n",
      "Epoch: 277, Batch number: 24, Loss: 616.0714111328125\n",
      "Epoch: 278, Batch number: 48, Loss: 643.6288452148438\n",
      "Epoch: 279, Batch number: 72, Loss: 674.1508178710938\n",
      "Epoch: 281, Batch number: 20, Loss: 599.6728515625\n",
      "Epoch: 282, Batch number: 44, Loss: 619.7096557617188\n",
      "Epoch: 283, Batch number: 68, Loss: 610.187255859375\n",
      "Epoch: 285, Batch number: 16, Loss: 533.619140625\n",
      "Epoch: 286, Batch number: 40, Loss: 653.5206298828125\n",
      "Epoch: 287, Batch number: 64, Loss: 539.7224731445312\n",
      "Epoch: 289, Batch number: 12, Loss: 555.6325073242188\n",
      "Epoch: 290, Batch number: 36, Loss: 531.8233642578125\n",
      "Epoch: 291, Batch number: 60, Loss: 589.3903198242188\n",
      "Epoch: 293, Batch number: 8, Loss: 534.9595947265625\n",
      "Epoch: 294, Batch number: 32, Loss: 519.2235107421875\n",
      "Epoch: 295, Batch number: 56, Loss: 552.3627319335938\n",
      "Epoch: 297, Batch number: 4, Loss: 547.1761474609375\n",
      "Epoch: 298, Batch number: 28, Loss: 512.6828002929688\n",
      "Epoch: 299, Batch number: 52, Loss: 512.06689453125\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4400.08837890625\n",
      "Epoch: 2, Batch number: 24, Loss: 4207.0\n",
      "Epoch: 3, Batch number: 48, Loss: 3812.91796875\n",
      "Epoch: 4, Batch number: 72, Loss: 3360.03662109375\n",
      "Epoch: 6, Batch number: 20, Loss: 3028.18115234375\n",
      "Epoch: 7, Batch number: 44, Loss: 2992.6533203125\n",
      "Epoch: 8, Batch number: 68, Loss: 2939.362060546875\n",
      "Epoch: 10, Batch number: 16, Loss: 3000.037353515625\n",
      "Epoch: 11, Batch number: 40, Loss: 2897.8642578125\n",
      "Epoch: 12, Batch number: 64, Loss: 2898.7421875\n",
      "Epoch: 14, Batch number: 12, Loss: 2811.957763671875\n",
      "Epoch: 15, Batch number: 36, Loss: 2732.008056640625\n",
      "Epoch: 16, Batch number: 60, Loss: 2814.0927734375\n",
      "Epoch: 18, Batch number: 8, Loss: 2600.697998046875\n",
      "Epoch: 19, Batch number: 32, Loss: 2656.20849609375\n",
      "Epoch: 20, Batch number: 56, Loss: 2726.4306640625\n",
      "Epoch: 22, Batch number: 4, Loss: 2586.6640625\n",
      "Epoch: 23, Batch number: 28, Loss: 2506.478271484375\n",
      "Epoch: 24, Batch number: 52, Loss: 2521.44287109375\n",
      "Epoch: 26, Batch number: 0, Loss: 2437.428955078125\n",
      "Epoch: 27, Batch number: 24, Loss: 2398.1669921875\n",
      "Epoch: 28, Batch number: 48, Loss: 2337.357177734375\n",
      "Epoch: 29, Batch number: 72, Loss: 2345.3818359375\n",
      "Epoch: 31, Batch number: 20, Loss: 2257.8779296875\n",
      "Epoch: 32, Batch number: 44, Loss: 2204.728271484375\n",
      "Epoch: 33, Batch number: 68, Loss: 2213.0849609375\n",
      "Epoch: 35, Batch number: 16, Loss: 2122.233154296875\n",
      "Epoch: 36, Batch number: 40, Loss: 2194.01318359375\n",
      "Epoch: 37, Batch number: 64, Loss: 2159.24267578125\n",
      "Epoch: 39, Batch number: 12, Loss: 2118.013916015625\n",
      "Epoch: 40, Batch number: 36, Loss: 2082.595458984375\n",
      "Epoch: 41, Batch number: 60, Loss: 2086.710693359375\n",
      "Epoch: 43, Batch number: 8, Loss: 1957.6275634765625\n",
      "Epoch: 44, Batch number: 32, Loss: 1985.33740234375\n",
      "Epoch: 45, Batch number: 56, Loss: 1922.2486572265625\n",
      "Epoch: 47, Batch number: 4, Loss: 2026.4627685546875\n",
      "Epoch: 48, Batch number: 28, Loss: 1937.78515625\n",
      "Epoch: 49, Batch number: 52, Loss: 1876.71484375\n",
      "Epoch: 51, Batch number: 0, Loss: 1800.0423583984375\n",
      "Epoch: 52, Batch number: 24, Loss: 1740.5435791015625\n",
      "Epoch: 53, Batch number: 48, Loss: 1740.1494140625\n",
      "Epoch: 54, Batch number: 72, Loss: 1743.22314453125\n",
      "Epoch: 56, Batch number: 20, Loss: 1675.425048828125\n",
      "Epoch: 57, Batch number: 44, Loss: 1706.5924072265625\n",
      "Epoch: 58, Batch number: 68, Loss: 1679.092529296875\n",
      "Epoch: 60, Batch number: 16, Loss: 1536.9090576171875\n",
      "Epoch: 61, Batch number: 40, Loss: 1634.1370849609375\n",
      "Epoch: 62, Batch number: 64, Loss: 1578.6380615234375\n",
      "Epoch: 64, Batch number: 12, Loss: 1557.928955078125\n",
      "Epoch: 65, Batch number: 36, Loss: 1553.918701171875\n",
      "Epoch: 66, Batch number: 60, Loss: 1454.095458984375\n",
      "Epoch: 68, Batch number: 8, Loss: 1464.7659912109375\n",
      "Epoch: 69, Batch number: 32, Loss: 1435.7169189453125\n",
      "Epoch: 70, Batch number: 56, Loss: 1439.75634765625\n",
      "Epoch: 72, Batch number: 4, Loss: 1401.841064453125\n",
      "Epoch: 73, Batch number: 28, Loss: 1467.003173828125\n",
      "Epoch: 74, Batch number: 52, Loss: 1332.232177734375\n",
      "Epoch: 76, Batch number: 0, Loss: 1328.2222900390625\n",
      "Epoch: 77, Batch number: 24, Loss: 1297.3433837890625\n",
      "Epoch: 78, Batch number: 48, Loss: 1361.9188232421875\n",
      "Epoch: 79, Batch number: 72, Loss: 1268.3558349609375\n",
      "Epoch: 81, Batch number: 20, Loss: 1270.331787109375\n",
      "Epoch: 82, Batch number: 44, Loss: 1248.033447265625\n",
      "Epoch: 83, Batch number: 68, Loss: 1244.651611328125\n",
      "Epoch: 85, Batch number: 16, Loss: 1271.73974609375\n",
      "Epoch: 86, Batch number: 40, Loss: 1203.7745361328125\n",
      "Epoch: 87, Batch number: 64, Loss: 1245.420166015625\n",
      "Epoch: 89, Batch number: 12, Loss: 1184.716552734375\n",
      "Epoch: 90, Batch number: 36, Loss: 1139.6424560546875\n",
      "Epoch: 91, Batch number: 60, Loss: 1181.8330078125\n",
      "Epoch: 93, Batch number: 8, Loss: 1132.4818115234375\n",
      "Epoch: 94, Batch number: 32, Loss: 1142.793212890625\n",
      "Epoch: 95, Batch number: 56, Loss: 1158.820556640625\n",
      "Epoch: 97, Batch number: 4, Loss: 1052.3997802734375\n",
      "Epoch: 98, Batch number: 28, Loss: 1071.6617431640625\n",
      "Epoch: 99, Batch number: 52, Loss: 1072.3909912109375\n",
      "Epoch: 101, Batch number: 0, Loss: 1057.3677978515625\n",
      "Epoch: 102, Batch number: 24, Loss: 1015.5740966796875\n",
      "Epoch: 103, Batch number: 48, Loss: 1107.04052734375\n",
      "Epoch: 104, Batch number: 72, Loss: 950.0341186523438\n",
      "Epoch: 106, Batch number: 20, Loss: 1011.7384033203125\n",
      "Epoch: 107, Batch number: 44, Loss: 997.5431518554688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Batch number: 68, Loss: 1052.91748046875\n",
      "Epoch: 110, Batch number: 16, Loss: 909.810546875\n",
      "Epoch: 111, Batch number: 40, Loss: 969.4803466796875\n",
      "Epoch: 112, Batch number: 64, Loss: 912.0791015625\n",
      "Epoch: 114, Batch number: 12, Loss: 905.3264770507812\n",
      "Epoch: 115, Batch number: 36, Loss: 832.1715698242188\n",
      "Epoch: 116, Batch number: 60, Loss: 839.1625366210938\n",
      "Epoch: 118, Batch number: 8, Loss: 875.5374145507812\n",
      "Epoch: 119, Batch number: 32, Loss: 879.513427734375\n",
      "Epoch: 120, Batch number: 56, Loss: 876.6103515625\n",
      "Epoch: 122, Batch number: 4, Loss: 830.7553100585938\n",
      "Epoch: 123, Batch number: 28, Loss: 809.6321411132812\n",
      "Epoch: 124, Batch number: 52, Loss: 808.9540405273438\n",
      "Epoch: 126, Batch number: 0, Loss: 834.0032958984375\n",
      "Epoch: 127, Batch number: 24, Loss: 783.6637573242188\n",
      "Epoch: 128, Batch number: 48, Loss: 825.9521484375\n",
      "Epoch: 129, Batch number: 72, Loss: 785.4005126953125\n",
      "Epoch: 131, Batch number: 20, Loss: 718.3320922851562\n",
      "Epoch: 132, Batch number: 44, Loss: 694.811279296875\n",
      "Epoch: 133, Batch number: 68, Loss: 724.5250244140625\n",
      "Epoch: 135, Batch number: 16, Loss: 692.0047607421875\n",
      "Epoch: 136, Batch number: 40, Loss: 763.1192626953125\n",
      "Epoch: 137, Batch number: 64, Loss: 720.9410400390625\n",
      "Epoch: 139, Batch number: 12, Loss: 716.8009643554688\n",
      "Epoch: 140, Batch number: 36, Loss: 689.092041015625\n",
      "Epoch: 141, Batch number: 60, Loss: 610.8160400390625\n",
      "Epoch: 143, Batch number: 8, Loss: 679.9500732421875\n",
      "Epoch: 144, Batch number: 32, Loss: 610.6875\n",
      "Epoch: 145, Batch number: 56, Loss: 638.1095581054688\n",
      "Epoch: 147, Batch number: 4, Loss: 631.7439575195312\n",
      "Epoch: 148, Batch number: 28, Loss: 662.7522583007812\n",
      "Epoch: 149, Batch number: 52, Loss: 626.0701293945312\n",
      "Epoch: 151, Batch number: 0, Loss: 571.8335571289062\n",
      "Epoch: 152, Batch number: 24, Loss: 611.9849853515625\n",
      "Epoch: 153, Batch number: 48, Loss: 613.3759155273438\n",
      "Epoch: 154, Batch number: 72, Loss: 552.0843505859375\n",
      "Epoch: 156, Batch number: 20, Loss: 591.7355346679688\n",
      "Epoch: 157, Batch number: 44, Loss: 577.1636962890625\n",
      "Epoch: 158, Batch number: 68, Loss: 599.8588256835938\n",
      "Epoch: 160, Batch number: 16, Loss: 538.2482299804688\n",
      "Epoch: 161, Batch number: 40, Loss: 501.1926574707031\n",
      "Epoch: 162, Batch number: 64, Loss: 506.8769226074219\n",
      "Epoch: 164, Batch number: 12, Loss: 483.14898681640625\n",
      "Epoch: 165, Batch number: 36, Loss: 513.8665771484375\n",
      "Epoch: 166, Batch number: 60, Loss: 488.86566162109375\n",
      "Epoch: 168, Batch number: 8, Loss: 470.777587890625\n",
      "Epoch: 169, Batch number: 32, Loss: 483.572998046875\n",
      "Epoch: 170, Batch number: 56, Loss: 484.31866455078125\n",
      "Epoch: 172, Batch number: 4, Loss: 523.4089965820312\n",
      "Epoch: 173, Batch number: 28, Loss: 464.2426452636719\n",
      "Epoch: 174, Batch number: 52, Loss: 436.30072021484375\n",
      "Epoch: 176, Batch number: 0, Loss: 452.89910888671875\n",
      "Epoch: 177, Batch number: 24, Loss: 394.5440979003906\n",
      "Epoch: 178, Batch number: 48, Loss: 408.3463439941406\n",
      "Epoch: 179, Batch number: 72, Loss: 420.314697265625\n",
      "Epoch: 181, Batch number: 20, Loss: 414.7633361816406\n",
      "Epoch: 182, Batch number: 44, Loss: 387.7574157714844\n",
      "Epoch: 183, Batch number: 68, Loss: 403.10986328125\n",
      "Epoch: 185, Batch number: 16, Loss: 355.0811462402344\n",
      "Epoch: 186, Batch number: 40, Loss: 427.4835205078125\n",
      "Epoch: 187, Batch number: 64, Loss: 381.8273010253906\n",
      "Epoch: 189, Batch number: 12, Loss: 353.9708557128906\n",
      "Epoch: 190, Batch number: 36, Loss: 365.0162048339844\n",
      "Epoch: 191, Batch number: 60, Loss: 351.27899169921875\n",
      "Epoch: 193, Batch number: 8, Loss: 311.1671447753906\n",
      "Epoch: 194, Batch number: 32, Loss: 351.13037109375\n",
      "Epoch: 195, Batch number: 56, Loss: 349.0542907714844\n",
      "Epoch: 197, Batch number: 4, Loss: 342.1772155761719\n",
      "Epoch: 198, Batch number: 28, Loss: 362.2073059082031\n",
      "Epoch: 199, Batch number: 52, Loss: 310.0523681640625\n",
      "Epoch: 201, Batch number: 0, Loss: 295.5655517578125\n",
      "Epoch: 202, Batch number: 24, Loss: 298.59112548828125\n",
      "Epoch: 203, Batch number: 48, Loss: 349.2466125488281\n",
      "Epoch: 204, Batch number: 72, Loss: 295.50543212890625\n",
      "Epoch: 206, Batch number: 20, Loss: 299.6826477050781\n",
      "Epoch: 207, Batch number: 44, Loss: 320.04095458984375\n",
      "Epoch: 208, Batch number: 68, Loss: 293.3501281738281\n",
      "Epoch: 210, Batch number: 16, Loss: 278.5625305175781\n",
      "Epoch: 211, Batch number: 40, Loss: 231.0145721435547\n",
      "Epoch: 212, Batch number: 64, Loss: 272.85076904296875\n",
      "Epoch: 214, Batch number: 12, Loss: 227.80697631835938\n",
      "Epoch: 215, Batch number: 36, Loss: 275.9748840332031\n",
      "Epoch: 216, Batch number: 60, Loss: 241.9894561767578\n",
      "Epoch: 218, Batch number: 8, Loss: 245.58140563964844\n",
      "Epoch: 219, Batch number: 32, Loss: 235.74526977539062\n",
      "Epoch: 220, Batch number: 56, Loss: 215.0798797607422\n",
      "Epoch: 222, Batch number: 4, Loss: 218.987548828125\n",
      "Epoch: 223, Batch number: 28, Loss: 207.2393341064453\n",
      "Epoch: 224, Batch number: 52, Loss: 227.14437866210938\n",
      "Epoch: 226, Batch number: 0, Loss: 206.2527618408203\n",
      "Epoch: 227, Batch number: 24, Loss: 205.38131713867188\n",
      "Epoch: 228, Batch number: 48, Loss: 196.69851684570312\n",
      "Epoch: 229, Batch number: 72, Loss: 187.20205688476562\n",
      "Epoch: 231, Batch number: 20, Loss: 183.6687774658203\n",
      "Epoch: 232, Batch number: 44, Loss: 173.26365661621094\n",
      "Epoch: 233, Batch number: 68, Loss: 196.75131225585938\n",
      "Epoch: 235, Batch number: 16, Loss: 179.16656494140625\n",
      "Epoch: 236, Batch number: 40, Loss: 206.9971160888672\n",
      "Epoch: 237, Batch number: 64, Loss: 185.538330078125\n",
      "Epoch: 239, Batch number: 12, Loss: 175.5140380859375\n",
      "Epoch: 240, Batch number: 36, Loss: 167.41574096679688\n",
      "Epoch: 241, Batch number: 60, Loss: 182.42214965820312\n",
      "Epoch: 243, Batch number: 8, Loss: 172.69366455078125\n",
      "Epoch: 244, Batch number: 32, Loss: 150.62657165527344\n",
      "Epoch: 245, Batch number: 56, Loss: 174.38461303710938\n",
      "Epoch: 247, Batch number: 4, Loss: 155.4342498779297\n",
      "Epoch: 248, Batch number: 28, Loss: 151.64710998535156\n",
      "Epoch: 249, Batch number: 52, Loss: 154.5917205810547\n",
      "Epoch: 251, Batch number: 0, Loss: 142.62667846679688\n",
      "Epoch: 252, Batch number: 24, Loss: 155.5203857421875\n",
      "Epoch: 253, Batch number: 48, Loss: 145.00047302246094\n",
      "Epoch: 254, Batch number: 72, Loss: 146.4271240234375\n",
      "Epoch: 256, Batch number: 20, Loss: 126.013427734375\n",
      "Epoch: 257, Batch number: 44, Loss: 134.77684020996094\n",
      "Epoch: 258, Batch number: 68, Loss: 139.48849487304688\n",
      "Epoch: 260, Batch number: 16, Loss: 124.39984130859375\n",
      "Epoch: 261, Batch number: 40, Loss: 129.33290100097656\n",
      "Epoch: 262, Batch number: 64, Loss: 118.04753875732422\n",
      "Epoch: 264, Batch number: 12, Loss: 109.07425689697266\n",
      "Epoch: 265, Batch number: 36, Loss: 115.41886901855469\n",
      "Epoch: 266, Batch number: 60, Loss: 126.06309509277344\n",
      "Epoch: 268, Batch number: 8, Loss: 121.0018081665039\n",
      "Epoch: 269, Batch number: 32, Loss: 117.41006469726562\n",
      "Epoch: 270, Batch number: 56, Loss: 113.38960266113281\n",
      "Epoch: 272, Batch number: 4, Loss: 103.7190933227539\n",
      "Epoch: 273, Batch number: 28, Loss: 100.69835662841797\n",
      "Epoch: 274, Batch number: 52, Loss: 103.39381408691406\n",
      "Epoch: 276, Batch number: 0, Loss: 109.01345825195312\n",
      "Epoch: 277, Batch number: 24, Loss: 103.42652130126953\n",
      "Epoch: 278, Batch number: 48, Loss: 93.54937744140625\n",
      "Epoch: 279, Batch number: 72, Loss: 111.34940338134766\n",
      "Epoch: 281, Batch number: 20, Loss: 86.2344741821289\n",
      "Epoch: 282, Batch number: 44, Loss: 104.16502380371094\n",
      "Epoch: 283, Batch number: 68, Loss: 85.01609802246094\n",
      "Epoch: 285, Batch number: 16, Loss: 86.10218048095703\n",
      "Epoch: 286, Batch number: 40, Loss: 98.04151153564453\n",
      "Epoch: 287, Batch number: 64, Loss: 87.7379150390625\n",
      "Epoch: 289, Batch number: 12, Loss: 80.52116394042969\n",
      "Epoch: 290, Batch number: 36, Loss: 73.44679260253906\n",
      "Epoch: 291, Batch number: 60, Loss: 83.71632385253906\n",
      "Epoch: 293, Batch number: 8, Loss: 88.67061614990234\n",
      "Epoch: 294, Batch number: 32, Loss: 85.13018798828125\n",
      "Epoch: 295, Batch number: 56, Loss: 70.02439880371094\n",
      "Epoch: 297, Batch number: 4, Loss: 75.95558166503906\n",
      "Epoch: 298, Batch number: 28, Loss: 80.4151840209961\n",
      "Epoch: 299, Batch number: 52, Loss: 81.58247375488281\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4399.6396484375\n",
      "Epoch: 2, Batch number: 24, Loss: 4076.96240234375\n",
      "Epoch: 3, Batch number: 48, Loss: 3544.787841796875\n",
      "Epoch: 4, Batch number: 72, Loss: 3166.265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Batch number: 20, Loss: 3080.70947265625\n",
      "Epoch: 7, Batch number: 44, Loss: 3009.39013671875\n",
      "Epoch: 8, Batch number: 68, Loss: 2881.16552734375\n",
      "Epoch: 10, Batch number: 16, Loss: 2719.746337890625\n",
      "Epoch: 11, Batch number: 40, Loss: 2708.154541015625\n",
      "Epoch: 12, Batch number: 64, Loss: 2702.94140625\n",
      "Epoch: 14, Batch number: 12, Loss: 2601.52392578125\n",
      "Epoch: 15, Batch number: 36, Loss: 2695.266357421875\n",
      "Epoch: 16, Batch number: 60, Loss: 2449.438720703125\n",
      "Epoch: 18, Batch number: 8, Loss: 2472.1416015625\n",
      "Epoch: 19, Batch number: 32, Loss: 2430.5693359375\n",
      "Epoch: 20, Batch number: 56, Loss: 2435.42919921875\n",
      "Epoch: 22, Batch number: 4, Loss: 2316.137451171875\n",
      "Epoch: 23, Batch number: 28, Loss: 2306.250244140625\n",
      "Epoch: 24, Batch number: 52, Loss: 2277.963623046875\n",
      "Epoch: 26, Batch number: 0, Loss: 2221.923828125\n",
      "Epoch: 27, Batch number: 24, Loss: 2199.067626953125\n",
      "Epoch: 28, Batch number: 48, Loss: 2131.44140625\n",
      "Epoch: 29, Batch number: 72, Loss: 2079.9365234375\n",
      "Epoch: 31, Batch number: 20, Loss: 2027.6259765625\n",
      "Epoch: 32, Batch number: 44, Loss: 2037.126953125\n",
      "Epoch: 33, Batch number: 68, Loss: 1916.7852783203125\n",
      "Epoch: 35, Batch number: 16, Loss: 1933.109619140625\n",
      "Epoch: 36, Batch number: 40, Loss: 1916.2568359375\n",
      "Epoch: 37, Batch number: 64, Loss: 1819.3763427734375\n",
      "Epoch: 39, Batch number: 12, Loss: 1799.6383056640625\n",
      "Epoch: 40, Batch number: 36, Loss: 1629.124755859375\n",
      "Epoch: 41, Batch number: 60, Loss: 1740.5673828125\n",
      "Epoch: 43, Batch number: 8, Loss: 1676.5943603515625\n",
      "Epoch: 44, Batch number: 32, Loss: 1601.8892822265625\n",
      "Epoch: 45, Batch number: 56, Loss: 1586.7913818359375\n",
      "Epoch: 47, Batch number: 4, Loss: 1556.8406982421875\n",
      "Epoch: 48, Batch number: 28, Loss: 1530.6759033203125\n",
      "Epoch: 49, Batch number: 52, Loss: 1496.825927734375\n",
      "Epoch: 51, Batch number: 0, Loss: 1405.487548828125\n",
      "Epoch: 52, Batch number: 24, Loss: 1403.0625\n",
      "Epoch: 53, Batch number: 48, Loss: 1369.920166015625\n",
      "Epoch: 54, Batch number: 72, Loss: 1387.42724609375\n",
      "Epoch: 56, Batch number: 20, Loss: 1330.84326171875\n",
      "Epoch: 57, Batch number: 44, Loss: 1365.0928955078125\n",
      "Epoch: 58, Batch number: 68, Loss: 1325.066162109375\n",
      "Epoch: 60, Batch number: 16, Loss: 1213.9412841796875\n",
      "Epoch: 61, Batch number: 40, Loss: 1165.608642578125\n",
      "Epoch: 62, Batch number: 64, Loss: 1241.966796875\n",
      "Epoch: 64, Batch number: 12, Loss: 1219.251708984375\n",
      "Epoch: 65, Batch number: 36, Loss: 1189.2462158203125\n",
      "Epoch: 66, Batch number: 60, Loss: 1179.5888671875\n",
      "Epoch: 68, Batch number: 8, Loss: 1216.888671875\n",
      "Epoch: 69, Batch number: 32, Loss: 1076.9681396484375\n",
      "Epoch: 70, Batch number: 56, Loss: 1078.06591796875\n",
      "Epoch: 72, Batch number: 4, Loss: 1073.6312255859375\n",
      "Epoch: 73, Batch number: 28, Loss: 1001.0698852539062\n",
      "Epoch: 74, Batch number: 52, Loss: 975.5748291015625\n",
      "Epoch: 76, Batch number: 0, Loss: 1001.3563842773438\n",
      "Epoch: 77, Batch number: 24, Loss: 1005.885009765625\n",
      "Epoch: 78, Batch number: 48, Loss: 932.6696166992188\n",
      "Epoch: 79, Batch number: 72, Loss: 873.674072265625\n",
      "Epoch: 81, Batch number: 20, Loss: 939.4308471679688\n",
      "Epoch: 82, Batch number: 44, Loss: 900.3731689453125\n",
      "Epoch: 83, Batch number: 68, Loss: 955.3170166015625\n",
      "Epoch: 85, Batch number: 16, Loss: 917.4364624023438\n",
      "Epoch: 86, Batch number: 40, Loss: 805.52099609375\n",
      "Epoch: 87, Batch number: 64, Loss: 888.2060546875\n",
      "Epoch: 89, Batch number: 12, Loss: 831.541015625\n",
      "Epoch: 90, Batch number: 36, Loss: 832.7818603515625\n",
      "Epoch: 91, Batch number: 60, Loss: 791.3731079101562\n",
      "Epoch: 93, Batch number: 8, Loss: 821.6564331054688\n",
      "Epoch: 94, Batch number: 32, Loss: 778.9832153320312\n",
      "Epoch: 95, Batch number: 56, Loss: 689.0739135742188\n",
      "Epoch: 97, Batch number: 4, Loss: 741.4071044921875\n",
      "Epoch: 98, Batch number: 28, Loss: 671.5610961914062\n",
      "Epoch: 99, Batch number: 52, Loss: 726.140380859375\n",
      "Epoch: 101, Batch number: 0, Loss: 615.6004028320312\n",
      "Epoch: 102, Batch number: 24, Loss: 674.20947265625\n",
      "Epoch: 103, Batch number: 48, Loss: 650.3850708007812\n",
      "Epoch: 104, Batch number: 72, Loss: 663.1385498046875\n",
      "Epoch: 106, Batch number: 20, Loss: 618.7566528320312\n",
      "Epoch: 107, Batch number: 44, Loss: 614.9511108398438\n",
      "Epoch: 108, Batch number: 68, Loss: 597.6201782226562\n",
      "Epoch: 110, Batch number: 16, Loss: 573.1649780273438\n",
      "Epoch: 111, Batch number: 40, Loss: 584.1403198242188\n",
      "Epoch: 112, Batch number: 64, Loss: 556.4332275390625\n",
      "Epoch: 114, Batch number: 12, Loss: 564.6001586914062\n",
      "Epoch: 115, Batch number: 36, Loss: 548.633544921875\n",
      "Epoch: 116, Batch number: 60, Loss: 548.0390625\n",
      "Epoch: 118, Batch number: 8, Loss: 495.7690124511719\n",
      "Epoch: 119, Batch number: 32, Loss: 517.8385620117188\n",
      "Epoch: 120, Batch number: 56, Loss: 519.062744140625\n",
      "Epoch: 122, Batch number: 4, Loss: 469.1726379394531\n",
      "Epoch: 123, Batch number: 28, Loss: 481.4318542480469\n",
      "Epoch: 124, Batch number: 52, Loss: 452.7247619628906\n",
      "Epoch: 126, Batch number: 0, Loss: 479.77874755859375\n",
      "Epoch: 127, Batch number: 24, Loss: 441.200439453125\n",
      "Epoch: 128, Batch number: 48, Loss: 432.9044494628906\n",
      "Epoch: 129, Batch number: 72, Loss: 405.3744201660156\n",
      "Epoch: 131, Batch number: 20, Loss: 415.0720520019531\n",
      "Epoch: 132, Batch number: 44, Loss: 393.503173828125\n",
      "Epoch: 133, Batch number: 68, Loss: 405.7334899902344\n",
      "Epoch: 135, Batch number: 16, Loss: 368.14971923828125\n",
      "Epoch: 136, Batch number: 40, Loss: 381.76922607421875\n",
      "Epoch: 137, Batch number: 64, Loss: 312.8242492675781\n",
      "Epoch: 139, Batch number: 12, Loss: 349.6947326660156\n",
      "Epoch: 140, Batch number: 36, Loss: 364.4482421875\n",
      "Epoch: 141, Batch number: 60, Loss: 368.1179504394531\n",
      "Epoch: 143, Batch number: 8, Loss: 302.7868347167969\n",
      "Epoch: 144, Batch number: 32, Loss: 293.4763488769531\n",
      "Epoch: 145, Batch number: 56, Loss: 296.8376159667969\n",
      "Epoch: 147, Batch number: 4, Loss: 296.6073303222656\n",
      "Epoch: 148, Batch number: 28, Loss: 294.1553649902344\n",
      "Epoch: 149, Batch number: 52, Loss: 290.19561767578125\n",
      "Epoch: 151, Batch number: 0, Loss: 307.094970703125\n",
      "Epoch: 152, Batch number: 24, Loss: 235.7716064453125\n",
      "Epoch: 153, Batch number: 48, Loss: 282.1882019042969\n",
      "Epoch: 154, Batch number: 72, Loss: 225.7859649658203\n",
      "Epoch: 156, Batch number: 20, Loss: 241.59153747558594\n",
      "Epoch: 157, Batch number: 44, Loss: 254.2657470703125\n",
      "Epoch: 158, Batch number: 68, Loss: 227.0924072265625\n",
      "Epoch: 160, Batch number: 16, Loss: 224.9478302001953\n",
      "Epoch: 161, Batch number: 40, Loss: 208.8949432373047\n",
      "Epoch: 162, Batch number: 64, Loss: 224.51637268066406\n",
      "Epoch: 164, Batch number: 12, Loss: 217.13992309570312\n",
      "Epoch: 165, Batch number: 36, Loss: 207.8822021484375\n",
      "Epoch: 166, Batch number: 60, Loss: 212.8878173828125\n",
      "Epoch: 168, Batch number: 8, Loss: 202.7840118408203\n",
      "Epoch: 169, Batch number: 32, Loss: 183.2025146484375\n",
      "Epoch: 170, Batch number: 56, Loss: 209.03713989257812\n",
      "Epoch: 172, Batch number: 4, Loss: 189.7238006591797\n",
      "Epoch: 173, Batch number: 28, Loss: 195.66270446777344\n",
      "Epoch: 174, Batch number: 52, Loss: 168.50128173828125\n",
      "Epoch: 176, Batch number: 0, Loss: 177.8030242919922\n",
      "Epoch: 177, Batch number: 24, Loss: 165.02699279785156\n",
      "Epoch: 178, Batch number: 48, Loss: 168.10064697265625\n",
      "Epoch: 179, Batch number: 72, Loss: 178.84263610839844\n",
      "Epoch: 181, Batch number: 20, Loss: 153.68724060058594\n",
      "Epoch: 182, Batch number: 44, Loss: 163.4845733642578\n",
      "Epoch: 183, Batch number: 68, Loss: 167.4427947998047\n",
      "Epoch: 185, Batch number: 16, Loss: 133.20860290527344\n",
      "Epoch: 186, Batch number: 40, Loss: 137.75503540039062\n",
      "Epoch: 187, Batch number: 64, Loss: 147.4872589111328\n",
      "Epoch: 189, Batch number: 12, Loss: 149.16827392578125\n",
      "Epoch: 190, Batch number: 36, Loss: 128.2437286376953\n",
      "Epoch: 191, Batch number: 60, Loss: 128.30661010742188\n",
      "Epoch: 193, Batch number: 8, Loss: 121.58931732177734\n",
      "Epoch: 194, Batch number: 32, Loss: 112.29669189453125\n",
      "Epoch: 195, Batch number: 56, Loss: 116.76907348632812\n",
      "Epoch: 197, Batch number: 4, Loss: 108.10619354248047\n",
      "Epoch: 198, Batch number: 28, Loss: 95.97583770751953\n",
      "Epoch: 199, Batch number: 52, Loss: 103.37974548339844\n",
      "Epoch: 201, Batch number: 0, Loss: 97.12741088867188\n",
      "Epoch: 202, Batch number: 24, Loss: 104.89210510253906\n",
      "Epoch: 203, Batch number: 48, Loss: 94.03598022460938\n",
      "Epoch: 204, Batch number: 72, Loss: 107.17794036865234\n",
      "Epoch: 206, Batch number: 20, Loss: 86.2232666015625\n",
      "Epoch: 207, Batch number: 44, Loss: 88.53814697265625\n",
      "Epoch: 208, Batch number: 68, Loss: 99.05216217041016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Batch number: 16, Loss: 93.05508422851562\n",
      "Epoch: 211, Batch number: 40, Loss: 87.13314819335938\n",
      "Epoch: 212, Batch number: 64, Loss: 90.48905944824219\n",
      "Epoch: 214, Batch number: 12, Loss: 82.87752532958984\n",
      "Epoch: 215, Batch number: 36, Loss: 85.55232238769531\n",
      "Epoch: 216, Batch number: 60, Loss: 83.64021301269531\n",
      "Epoch: 218, Batch number: 8, Loss: 76.1435546875\n",
      "Epoch: 219, Batch number: 32, Loss: 76.30467224121094\n",
      "Epoch: 220, Batch number: 56, Loss: 73.75363159179688\n",
      "Epoch: 222, Batch number: 4, Loss: 71.71202087402344\n",
      "Epoch: 223, Batch number: 28, Loss: 69.66886901855469\n",
      "Epoch: 224, Batch number: 52, Loss: 68.24578094482422\n",
      "Epoch: 226, Batch number: 0, Loss: 66.66056060791016\n",
      "Epoch: 227, Batch number: 24, Loss: 61.77782440185547\n",
      "Epoch: 228, Batch number: 48, Loss: 66.42042541503906\n",
      "Epoch: 229, Batch number: 72, Loss: 65.34115600585938\n",
      "Epoch: 231, Batch number: 20, Loss: 59.27066421508789\n",
      "Epoch: 232, Batch number: 44, Loss: 61.710968017578125\n",
      "Epoch: 233, Batch number: 68, Loss: 67.56112670898438\n",
      "Epoch: 235, Batch number: 16, Loss: 52.98796844482422\n",
      "Epoch: 236, Batch number: 40, Loss: 50.644805908203125\n",
      "Epoch: 237, Batch number: 64, Loss: 57.85320281982422\n",
      "Epoch: 239, Batch number: 12, Loss: 49.240089416503906\n",
      "Epoch: 240, Batch number: 36, Loss: 62.60544967651367\n",
      "Epoch: 241, Batch number: 60, Loss: 57.4963493347168\n",
      "Epoch: 243, Batch number: 8, Loss: 53.6726188659668\n",
      "Epoch: 244, Batch number: 32, Loss: 43.709266662597656\n",
      "Epoch: 245, Batch number: 56, Loss: 51.50807571411133\n",
      "Epoch: 247, Batch number: 4, Loss: 45.47781753540039\n",
      "Epoch: 248, Batch number: 28, Loss: 47.91332244873047\n",
      "Epoch: 249, Batch number: 52, Loss: 47.49201965332031\n",
      "Epoch: 251, Batch number: 0, Loss: 49.06614685058594\n",
      "Epoch: 252, Batch number: 24, Loss: 45.908409118652344\n",
      "Epoch: 253, Batch number: 48, Loss: 44.375816345214844\n",
      "Epoch: 254, Batch number: 72, Loss: 49.74740982055664\n",
      "Epoch: 256, Batch number: 20, Loss: 47.71320343017578\n",
      "Epoch: 257, Batch number: 44, Loss: 41.80315017700195\n",
      "Epoch: 258, Batch number: 68, Loss: 51.636329650878906\n",
      "Epoch: 260, Batch number: 16, Loss: 43.34968948364258\n",
      "Epoch: 261, Batch number: 40, Loss: 38.911258697509766\n",
      "Epoch: 262, Batch number: 64, Loss: 45.32273483276367\n",
      "Epoch: 264, Batch number: 12, Loss: 42.37123107910156\n",
      "Epoch: 265, Batch number: 36, Loss: 38.50873565673828\n",
      "Epoch: 266, Batch number: 60, Loss: 46.12369155883789\n",
      "Epoch: 268, Batch number: 8, Loss: 41.32228469848633\n",
      "Epoch: 269, Batch number: 32, Loss: 40.6295280456543\n",
      "Epoch: 270, Batch number: 56, Loss: 35.459068298339844\n",
      "Epoch: 272, Batch number: 4, Loss: 39.9763298034668\n",
      "Epoch: 273, Batch number: 28, Loss: 38.104042053222656\n",
      "Epoch: 274, Batch number: 52, Loss: 30.710491180419922\n",
      "Epoch: 276, Batch number: 0, Loss: 33.73748016357422\n",
      "Epoch: 277, Batch number: 24, Loss: 35.441375732421875\n",
      "Epoch: 278, Batch number: 48, Loss: 33.883907318115234\n",
      "Epoch: 279, Batch number: 72, Loss: 32.89973449707031\n",
      "Epoch: 281, Batch number: 20, Loss: 36.534175872802734\n",
      "Epoch: 282, Batch number: 44, Loss: 36.8110466003418\n",
      "Epoch: 283, Batch number: 68, Loss: 36.78459930419922\n",
      "Epoch: 285, Batch number: 16, Loss: 33.9208984375\n",
      "Epoch: 286, Batch number: 40, Loss: 32.398136138916016\n",
      "Epoch: 287, Batch number: 64, Loss: 34.878379821777344\n",
      "Epoch: 289, Batch number: 12, Loss: 30.063396453857422\n",
      "Epoch: 290, Batch number: 36, Loss: 29.916120529174805\n",
      "Epoch: 291, Batch number: 60, Loss: 28.249698638916016\n",
      "Epoch: 293, Batch number: 8, Loss: 30.661365509033203\n",
      "Epoch: 294, Batch number: 32, Loss: 28.591880798339844\n",
      "Epoch: 295, Batch number: 56, Loss: 31.023807525634766\n",
      "Epoch: 297, Batch number: 4, Loss: 33.63166046142578\n",
      "Epoch: 298, Batch number: 28, Loss: 24.19913673400879\n",
      "Epoch: 299, Batch number: 52, Loss: 36.44291305541992\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4396.70263671875\n",
      "Epoch: 2, Batch number: 24, Loss: 3990.235595703125\n",
      "Epoch: 3, Batch number: 48, Loss: 3303.44140625\n",
      "Epoch: 4, Batch number: 72, Loss: 3243.571533203125\n",
      "Epoch: 6, Batch number: 20, Loss: 2948.817626953125\n",
      "Epoch: 7, Batch number: 44, Loss: 2859.481689453125\n",
      "Epoch: 8, Batch number: 68, Loss: 2807.18310546875\n",
      "Epoch: 10, Batch number: 16, Loss: 2792.365478515625\n",
      "Epoch: 11, Batch number: 40, Loss: 2656.181884765625\n",
      "Epoch: 12, Batch number: 64, Loss: 2579.054931640625\n",
      "Epoch: 14, Batch number: 12, Loss: 2508.97119140625\n",
      "Epoch: 15, Batch number: 36, Loss: 2488.859130859375\n",
      "Epoch: 16, Batch number: 60, Loss: 2442.425048828125\n",
      "Epoch: 18, Batch number: 8, Loss: 2331.83935546875\n",
      "Epoch: 19, Batch number: 32, Loss: 2250.989501953125\n",
      "Epoch: 20, Batch number: 56, Loss: 2246.153076171875\n",
      "Epoch: 22, Batch number: 4, Loss: 2216.384033203125\n",
      "Epoch: 23, Batch number: 28, Loss: 2080.054443359375\n",
      "Epoch: 24, Batch number: 52, Loss: 2035.0885009765625\n",
      "Epoch: 26, Batch number: 0, Loss: 1982.0115966796875\n",
      "Epoch: 27, Batch number: 24, Loss: 1923.190185546875\n",
      "Epoch: 28, Batch number: 48, Loss: 1826.16650390625\n",
      "Epoch: 29, Batch number: 72, Loss: 1805.68212890625\n",
      "Epoch: 31, Batch number: 20, Loss: 1709.4091796875\n",
      "Epoch: 32, Batch number: 44, Loss: 1764.2017822265625\n",
      "Epoch: 33, Batch number: 68, Loss: 1771.1729736328125\n",
      "Epoch: 35, Batch number: 16, Loss: 1704.154052734375\n",
      "Epoch: 36, Batch number: 40, Loss: 1622.621826171875\n",
      "Epoch: 37, Batch number: 64, Loss: 1595.110107421875\n",
      "Epoch: 39, Batch number: 12, Loss: 1540.91552734375\n",
      "Epoch: 40, Batch number: 36, Loss: 1504.8106689453125\n",
      "Epoch: 41, Batch number: 60, Loss: 1460.373291015625\n",
      "Epoch: 43, Batch number: 8, Loss: 1386.19970703125\n",
      "Epoch: 44, Batch number: 32, Loss: 1346.3538818359375\n",
      "Epoch: 45, Batch number: 56, Loss: 1334.5657958984375\n",
      "Epoch: 47, Batch number: 4, Loss: 1356.909423828125\n",
      "Epoch: 48, Batch number: 28, Loss: 1304.91455078125\n",
      "Epoch: 49, Batch number: 52, Loss: 1279.7291259765625\n",
      "Epoch: 51, Batch number: 0, Loss: 1146.58984375\n",
      "Epoch: 52, Batch number: 24, Loss: 1189.6849365234375\n",
      "Epoch: 53, Batch number: 48, Loss: 1129.5010986328125\n",
      "Epoch: 54, Batch number: 72, Loss: 1132.01953125\n",
      "Epoch: 56, Batch number: 20, Loss: 1132.980224609375\n",
      "Epoch: 57, Batch number: 44, Loss: 1093.7601318359375\n",
      "Epoch: 58, Batch number: 68, Loss: 1108.5572509765625\n",
      "Epoch: 60, Batch number: 16, Loss: 972.7091064453125\n",
      "Epoch: 61, Batch number: 40, Loss: 1047.2508544921875\n",
      "Epoch: 62, Batch number: 64, Loss: 970.0161743164062\n",
      "Epoch: 64, Batch number: 12, Loss: 924.7227172851562\n",
      "Epoch: 65, Batch number: 36, Loss: 1001.0599365234375\n",
      "Epoch: 66, Batch number: 60, Loss: 869.9071044921875\n",
      "Epoch: 68, Batch number: 8, Loss: 910.6005249023438\n",
      "Epoch: 69, Batch number: 32, Loss: 870.8258056640625\n",
      "Epoch: 70, Batch number: 56, Loss: 897.09130859375\n",
      "Epoch: 72, Batch number: 4, Loss: 817.8370971679688\n",
      "Epoch: 73, Batch number: 28, Loss: 844.2487182617188\n",
      "Epoch: 74, Batch number: 52, Loss: 857.9013671875\n",
      "Epoch: 76, Batch number: 0, Loss: 746.0382690429688\n",
      "Epoch: 77, Batch number: 24, Loss: 780.1168823242188\n",
      "Epoch: 78, Batch number: 48, Loss: 721.4238891601562\n",
      "Epoch: 79, Batch number: 72, Loss: 758.968994140625\n",
      "Epoch: 81, Batch number: 20, Loss: 704.3511352539062\n",
      "Epoch: 82, Batch number: 44, Loss: 686.3497314453125\n",
      "Epoch: 83, Batch number: 68, Loss: 640.8418579101562\n",
      "Epoch: 85, Batch number: 16, Loss: 619.9859008789062\n",
      "Epoch: 86, Batch number: 40, Loss: 644.9591064453125\n",
      "Epoch: 87, Batch number: 64, Loss: 609.5535278320312\n",
      "Epoch: 89, Batch number: 12, Loss: 556.7002563476562\n",
      "Epoch: 90, Batch number: 36, Loss: 545.7530517578125\n",
      "Epoch: 91, Batch number: 60, Loss: 577.6903076171875\n",
      "Epoch: 93, Batch number: 8, Loss: 539.0537109375\n",
      "Epoch: 94, Batch number: 32, Loss: 507.10931396484375\n",
      "Epoch: 95, Batch number: 56, Loss: 491.54522705078125\n",
      "Epoch: 97, Batch number: 4, Loss: 506.8112487792969\n",
      "Epoch: 98, Batch number: 28, Loss: 463.0713806152344\n",
      "Epoch: 99, Batch number: 52, Loss: 455.3163146972656\n",
      "Epoch: 101, Batch number: 0, Loss: 462.4898681640625\n",
      "Epoch: 102, Batch number: 24, Loss: 432.65106201171875\n",
      "Epoch: 103, Batch number: 48, Loss: 441.6495361328125\n",
      "Epoch: 104, Batch number: 72, Loss: 433.02044677734375\n",
      "Epoch: 106, Batch number: 20, Loss: 378.77545166015625\n",
      "Epoch: 107, Batch number: 44, Loss: 372.9237976074219\n",
      "Epoch: 108, Batch number: 68, Loss: 396.6709289550781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 16, Loss: 402.35076904296875\n",
      "Epoch: 111, Batch number: 40, Loss: 338.7144470214844\n",
      "Epoch: 112, Batch number: 64, Loss: 340.5148010253906\n",
      "Epoch: 114, Batch number: 12, Loss: 342.9582824707031\n",
      "Epoch: 115, Batch number: 36, Loss: 325.28936767578125\n",
      "Epoch: 116, Batch number: 60, Loss: 311.0164489746094\n",
      "Epoch: 118, Batch number: 8, Loss: 294.69378662109375\n",
      "Epoch: 119, Batch number: 32, Loss: 306.17535400390625\n",
      "Epoch: 120, Batch number: 56, Loss: 292.2026062011719\n",
      "Epoch: 122, Batch number: 4, Loss: 281.0908203125\n",
      "Epoch: 123, Batch number: 28, Loss: 296.29736328125\n",
      "Epoch: 124, Batch number: 52, Loss: 307.3621826171875\n",
      "Epoch: 126, Batch number: 0, Loss: 258.00335693359375\n",
      "Epoch: 127, Batch number: 24, Loss: 263.9443054199219\n",
      "Epoch: 128, Batch number: 48, Loss: 257.7471923828125\n",
      "Epoch: 129, Batch number: 72, Loss: 251.591796875\n",
      "Epoch: 131, Batch number: 20, Loss: 215.09962463378906\n",
      "Epoch: 132, Batch number: 44, Loss: 221.69334411621094\n",
      "Epoch: 133, Batch number: 68, Loss: 216.22637939453125\n",
      "Epoch: 135, Batch number: 16, Loss: 188.837158203125\n",
      "Epoch: 136, Batch number: 40, Loss: 201.3968963623047\n",
      "Epoch: 137, Batch number: 64, Loss: 215.04562377929688\n",
      "Epoch: 139, Batch number: 12, Loss: 172.1427001953125\n",
      "Epoch: 140, Batch number: 36, Loss: 188.6412353515625\n",
      "Epoch: 141, Batch number: 60, Loss: 171.96925354003906\n",
      "Epoch: 143, Batch number: 8, Loss: 156.23577880859375\n",
      "Epoch: 144, Batch number: 32, Loss: 155.3714141845703\n",
      "Epoch: 145, Batch number: 56, Loss: 170.3843994140625\n",
      "Epoch: 147, Batch number: 4, Loss: 166.34266662597656\n",
      "Epoch: 148, Batch number: 28, Loss: 132.42825317382812\n",
      "Epoch: 149, Batch number: 52, Loss: 134.90567016601562\n",
      "Epoch: 151, Batch number: 0, Loss: 131.03677368164062\n",
      "Epoch: 152, Batch number: 24, Loss: 133.8105926513672\n",
      "Epoch: 153, Batch number: 48, Loss: 129.81869506835938\n",
      "Epoch: 154, Batch number: 72, Loss: 137.48394775390625\n",
      "Epoch: 156, Batch number: 20, Loss: 126.0795669555664\n",
      "Epoch: 157, Batch number: 44, Loss: 122.61239624023438\n",
      "Epoch: 158, Batch number: 68, Loss: 110.41682434082031\n",
      "Epoch: 160, Batch number: 16, Loss: 114.30757141113281\n",
      "Epoch: 161, Batch number: 40, Loss: 114.98625183105469\n",
      "Epoch: 162, Batch number: 64, Loss: 111.65062713623047\n",
      "Epoch: 164, Batch number: 12, Loss: 99.44316864013672\n",
      "Epoch: 165, Batch number: 36, Loss: 105.92634582519531\n",
      "Epoch: 166, Batch number: 60, Loss: 106.25674438476562\n",
      "Epoch: 168, Batch number: 8, Loss: 93.19647216796875\n",
      "Epoch: 169, Batch number: 32, Loss: 96.18183898925781\n",
      "Epoch: 170, Batch number: 56, Loss: 88.95987701416016\n",
      "Epoch: 172, Batch number: 4, Loss: 99.26555633544922\n",
      "Epoch: 173, Batch number: 28, Loss: 93.07754516601562\n",
      "Epoch: 174, Batch number: 52, Loss: 70.94467163085938\n",
      "Epoch: 176, Batch number: 0, Loss: 72.95547485351562\n",
      "Epoch: 177, Batch number: 24, Loss: 77.07728576660156\n",
      "Epoch: 178, Batch number: 48, Loss: 85.1709213256836\n",
      "Epoch: 179, Batch number: 72, Loss: 79.26686096191406\n",
      "Epoch: 181, Batch number: 20, Loss: 73.6906509399414\n",
      "Epoch: 182, Batch number: 44, Loss: 80.16924285888672\n",
      "Epoch: 183, Batch number: 68, Loss: 80.82068634033203\n",
      "Epoch: 185, Batch number: 16, Loss: 60.209503173828125\n",
      "Epoch: 186, Batch number: 40, Loss: 64.23409271240234\n",
      "Epoch: 187, Batch number: 64, Loss: 64.14530181884766\n",
      "Epoch: 189, Batch number: 12, Loss: 65.51349639892578\n",
      "Epoch: 190, Batch number: 36, Loss: 68.34672546386719\n",
      "Epoch: 191, Batch number: 60, Loss: 65.30741882324219\n",
      "Epoch: 193, Batch number: 8, Loss: 50.28866958618164\n",
      "Epoch: 194, Batch number: 32, Loss: 59.78585433959961\n",
      "Epoch: 195, Batch number: 56, Loss: 58.90920639038086\n",
      "Epoch: 197, Batch number: 4, Loss: 54.386695861816406\n",
      "Epoch: 198, Batch number: 28, Loss: 57.68598937988281\n",
      "Epoch: 199, Batch number: 52, Loss: 55.4788932800293\n",
      "Epoch: 201, Batch number: 0, Loss: 53.088497161865234\n",
      "Epoch: 202, Batch number: 24, Loss: 51.442203521728516\n",
      "Epoch: 203, Batch number: 48, Loss: 61.455787658691406\n",
      "Epoch: 204, Batch number: 72, Loss: 50.78079605102539\n",
      "Epoch: 206, Batch number: 20, Loss: 52.0457878112793\n",
      "Epoch: 207, Batch number: 44, Loss: 46.202178955078125\n",
      "Epoch: 208, Batch number: 68, Loss: 46.53541946411133\n",
      "Epoch: 210, Batch number: 16, Loss: 49.722801208496094\n",
      "Epoch: 211, Batch number: 40, Loss: 48.28497314453125\n",
      "Epoch: 212, Batch number: 64, Loss: 46.75403594970703\n",
      "Epoch: 214, Batch number: 12, Loss: 39.31248474121094\n",
      "Epoch: 215, Batch number: 36, Loss: 34.60530090332031\n",
      "Epoch: 216, Batch number: 60, Loss: 41.22058868408203\n",
      "Epoch: 218, Batch number: 8, Loss: 42.102291107177734\n",
      "Epoch: 219, Batch number: 32, Loss: 44.51142501831055\n",
      "Epoch: 220, Batch number: 56, Loss: 39.23801040649414\n",
      "Epoch: 222, Batch number: 4, Loss: 39.26152801513672\n",
      "Epoch: 223, Batch number: 28, Loss: 39.835514068603516\n",
      "Epoch: 224, Batch number: 52, Loss: 35.2479133605957\n",
      "Epoch: 226, Batch number: 0, Loss: 34.879119873046875\n",
      "Epoch: 227, Batch number: 24, Loss: 34.507564544677734\n",
      "Epoch: 228, Batch number: 48, Loss: 32.51854705810547\n",
      "Epoch: 229, Batch number: 72, Loss: 38.578277587890625\n",
      "Epoch: 231, Batch number: 20, Loss: 31.74353790283203\n",
      "Epoch: 232, Batch number: 44, Loss: 34.415462493896484\n",
      "Epoch: 233, Batch number: 68, Loss: 34.66259002685547\n",
      "Epoch: 235, Batch number: 16, Loss: 35.941837310791016\n",
      "Epoch: 236, Batch number: 40, Loss: 29.81761932373047\n",
      "Epoch: 237, Batch number: 64, Loss: 41.45269012451172\n",
      "Epoch: 239, Batch number: 12, Loss: 27.935327529907227\n",
      "Epoch: 240, Batch number: 36, Loss: 31.567684173583984\n",
      "Epoch: 241, Batch number: 60, Loss: 32.6627082824707\n",
      "Epoch: 243, Batch number: 8, Loss: 31.692428588867188\n",
      "Epoch: 244, Batch number: 32, Loss: 34.349369049072266\n",
      "Epoch: 245, Batch number: 56, Loss: 36.110958099365234\n",
      "Epoch: 247, Batch number: 4, Loss: 30.15265655517578\n",
      "Epoch: 248, Batch number: 28, Loss: 32.69858932495117\n",
      "Epoch: 249, Batch number: 52, Loss: 27.660606384277344\n",
      "Epoch: 251, Batch number: 0, Loss: 25.56805419921875\n",
      "Epoch: 252, Batch number: 24, Loss: 28.11705780029297\n",
      "Epoch: 253, Batch number: 48, Loss: 19.769493103027344\n",
      "Epoch: 254, Batch number: 72, Loss: 42.76665496826172\n",
      "Epoch: 256, Batch number: 20, Loss: 25.260356903076172\n",
      "Epoch: 257, Batch number: 44, Loss: 28.993404388427734\n",
      "Epoch: 258, Batch number: 68, Loss: 26.339197158813477\n",
      "Epoch: 260, Batch number: 16, Loss: 28.587238311767578\n",
      "Epoch: 261, Batch number: 40, Loss: 28.040950775146484\n",
      "Epoch: 262, Batch number: 64, Loss: 25.015892028808594\n",
      "Epoch: 264, Batch number: 12, Loss: 31.712421417236328\n",
      "Epoch: 265, Batch number: 36, Loss: 26.974742889404297\n",
      "Epoch: 266, Batch number: 60, Loss: 31.94109344482422\n",
      "Epoch: 268, Batch number: 8, Loss: 26.526193618774414\n",
      "Epoch: 269, Batch number: 32, Loss: 24.652435302734375\n",
      "Epoch: 270, Batch number: 56, Loss: 27.129873275756836\n",
      "Epoch: 272, Batch number: 4, Loss: 29.69107437133789\n",
      "Epoch: 273, Batch number: 28, Loss: 26.137229919433594\n",
      "Epoch: 274, Batch number: 52, Loss: 21.841646194458008\n",
      "Epoch: 276, Batch number: 0, Loss: 20.98370933532715\n",
      "Epoch: 277, Batch number: 24, Loss: 22.15130615234375\n",
      "Epoch: 278, Batch number: 48, Loss: 27.945796966552734\n",
      "Epoch: 279, Batch number: 72, Loss: 19.883716583251953\n",
      "Epoch: 281, Batch number: 20, Loss: 23.169734954833984\n",
      "Epoch: 282, Batch number: 44, Loss: 28.896053314208984\n",
      "Epoch: 283, Batch number: 68, Loss: 28.136520385742188\n",
      "Epoch: 285, Batch number: 16, Loss: 18.968860626220703\n",
      "Epoch: 286, Batch number: 40, Loss: 25.111434936523438\n",
      "Epoch: 287, Batch number: 64, Loss: 21.975387573242188\n",
      "Epoch: 289, Batch number: 12, Loss: 26.088943481445312\n",
      "Epoch: 290, Batch number: 36, Loss: 23.747325897216797\n",
      "Epoch: 291, Batch number: 60, Loss: 23.48995590209961\n",
      "Epoch: 293, Batch number: 8, Loss: 29.262784957885742\n",
      "Epoch: 294, Batch number: 32, Loss: 17.637495040893555\n",
      "Epoch: 295, Batch number: 56, Loss: 24.011276245117188\n",
      "Epoch: 297, Batch number: 4, Loss: 24.967098236083984\n",
      "Epoch: 298, Batch number: 28, Loss: 22.383424758911133\n",
      "Epoch: 299, Batch number: 52, Loss: 22.885608673095703\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4396.9404296875\n",
      "Epoch: 2, Batch number: 24, Loss: 3837.234375\n",
      "Epoch: 3, Batch number: 48, Loss: 3204.6611328125\n",
      "Epoch: 4, Batch number: 72, Loss: 3054.895263671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Batch number: 20, Loss: 2836.0869140625\n",
      "Epoch: 7, Batch number: 44, Loss: 2717.14404296875\n",
      "Epoch: 8, Batch number: 68, Loss: 2654.20361328125\n",
      "Epoch: 10, Batch number: 16, Loss: 2497.918701171875\n",
      "Epoch: 11, Batch number: 40, Loss: 2389.108642578125\n",
      "Epoch: 12, Batch number: 64, Loss: 2297.2451171875\n",
      "Epoch: 14, Batch number: 12, Loss: 2270.572509765625\n",
      "Epoch: 15, Batch number: 36, Loss: 2182.806640625\n",
      "Epoch: 16, Batch number: 60, Loss: 2157.91455078125\n",
      "Epoch: 18, Batch number: 8, Loss: 2053.690673828125\n",
      "Epoch: 19, Batch number: 32, Loss: 1999.57470703125\n",
      "Epoch: 20, Batch number: 56, Loss: 1884.672607421875\n",
      "Epoch: 22, Batch number: 4, Loss: 1804.4166259765625\n",
      "Epoch: 23, Batch number: 28, Loss: 1758.3795166015625\n",
      "Epoch: 24, Batch number: 52, Loss: 1727.2843017578125\n",
      "Epoch: 26, Batch number: 0, Loss: 1607.67333984375\n",
      "Epoch: 27, Batch number: 24, Loss: 1506.3837890625\n",
      "Epoch: 28, Batch number: 48, Loss: 1544.6351318359375\n",
      "Epoch: 29, Batch number: 72, Loss: 1441.3807373046875\n",
      "Epoch: 31, Batch number: 20, Loss: 1442.7237548828125\n",
      "Epoch: 32, Batch number: 44, Loss: 1400.5418701171875\n",
      "Epoch: 33, Batch number: 68, Loss: 1365.1734619140625\n",
      "Epoch: 35, Batch number: 16, Loss: 1234.9818115234375\n",
      "Epoch: 36, Batch number: 40, Loss: 1263.4033203125\n",
      "Epoch: 37, Batch number: 64, Loss: 1194.310546875\n",
      "Epoch: 39, Batch number: 12, Loss: 1184.259033203125\n",
      "Epoch: 40, Batch number: 36, Loss: 1103.9061279296875\n",
      "Epoch: 41, Batch number: 60, Loss: 1167.2301025390625\n",
      "Epoch: 43, Batch number: 8, Loss: 1090.0775146484375\n",
      "Epoch: 44, Batch number: 32, Loss: 1001.5958251953125\n",
      "Epoch: 45, Batch number: 56, Loss: 1010.5465087890625\n",
      "Epoch: 47, Batch number: 4, Loss: 1002.5929565429688\n",
      "Epoch: 48, Batch number: 28, Loss: 968.3773193359375\n",
      "Epoch: 49, Batch number: 52, Loss: 915.3807373046875\n",
      "Epoch: 51, Batch number: 0, Loss: 912.9541015625\n",
      "Epoch: 52, Batch number: 24, Loss: 817.849609375\n",
      "Epoch: 53, Batch number: 48, Loss: 858.0570068359375\n",
      "Epoch: 54, Batch number: 72, Loss: 773.3602905273438\n",
      "Epoch: 56, Batch number: 20, Loss: 769.5958251953125\n",
      "Epoch: 57, Batch number: 44, Loss: 726.3948974609375\n",
      "Epoch: 58, Batch number: 68, Loss: 729.369140625\n",
      "Epoch: 60, Batch number: 16, Loss: 694.0813598632812\n",
      "Epoch: 61, Batch number: 40, Loss: 609.2924194335938\n",
      "Epoch: 62, Batch number: 64, Loss: 646.3235473632812\n",
      "Epoch: 64, Batch number: 12, Loss: 644.1862182617188\n",
      "Epoch: 65, Batch number: 36, Loss: 612.6649169921875\n",
      "Epoch: 66, Batch number: 60, Loss: 618.1427612304688\n",
      "Epoch: 68, Batch number: 8, Loss: 559.30419921875\n",
      "Epoch: 69, Batch number: 32, Loss: 556.0807495117188\n",
      "Epoch: 70, Batch number: 56, Loss: 483.7784118652344\n",
      "Epoch: 72, Batch number: 4, Loss: 505.28607177734375\n",
      "Epoch: 73, Batch number: 28, Loss: 479.8079833984375\n",
      "Epoch: 74, Batch number: 52, Loss: 444.45849609375\n",
      "Epoch: 76, Batch number: 0, Loss: 466.6529235839844\n",
      "Epoch: 77, Batch number: 24, Loss: 433.98931884765625\n",
      "Epoch: 78, Batch number: 48, Loss: 438.149169921875\n",
      "Epoch: 79, Batch number: 72, Loss: 399.217529296875\n",
      "Epoch: 81, Batch number: 20, Loss: 384.6910705566406\n",
      "Epoch: 82, Batch number: 44, Loss: 339.9807434082031\n",
      "Epoch: 83, Batch number: 68, Loss: 311.3511047363281\n",
      "Epoch: 85, Batch number: 16, Loss: 333.32781982421875\n",
      "Epoch: 86, Batch number: 40, Loss: 290.72491455078125\n",
      "Epoch: 87, Batch number: 64, Loss: 294.5790100097656\n",
      "Epoch: 89, Batch number: 12, Loss: 315.25042724609375\n",
      "Epoch: 90, Batch number: 36, Loss: 291.95263671875\n",
      "Epoch: 91, Batch number: 60, Loss: 273.7227783203125\n",
      "Epoch: 93, Batch number: 8, Loss: 264.5505676269531\n",
      "Epoch: 94, Batch number: 32, Loss: 259.90289306640625\n",
      "Epoch: 95, Batch number: 56, Loss: 241.46690368652344\n",
      "Epoch: 97, Batch number: 4, Loss: 207.58673095703125\n",
      "Epoch: 98, Batch number: 28, Loss: 218.6712646484375\n",
      "Epoch: 99, Batch number: 52, Loss: 224.07640075683594\n",
      "Epoch: 101, Batch number: 0, Loss: 198.7894744873047\n",
      "Epoch: 102, Batch number: 24, Loss: 214.57908630371094\n",
      "Epoch: 103, Batch number: 48, Loss: 197.2266845703125\n",
      "Epoch: 104, Batch number: 72, Loss: 185.47348022460938\n",
      "Epoch: 106, Batch number: 20, Loss: 156.07408142089844\n",
      "Epoch: 107, Batch number: 44, Loss: 167.30612182617188\n",
      "Epoch: 108, Batch number: 68, Loss: 164.38938903808594\n",
      "Epoch: 110, Batch number: 16, Loss: 166.14077758789062\n",
      "Epoch: 111, Batch number: 40, Loss: 145.96966552734375\n",
      "Epoch: 112, Batch number: 64, Loss: 147.37722778320312\n",
      "Epoch: 114, Batch number: 12, Loss: 143.4392852783203\n",
      "Epoch: 115, Batch number: 36, Loss: 125.74011993408203\n",
      "Epoch: 116, Batch number: 60, Loss: 142.44020080566406\n",
      "Epoch: 118, Batch number: 8, Loss: 113.43563842773438\n",
      "Epoch: 119, Batch number: 32, Loss: 123.0895004272461\n",
      "Epoch: 120, Batch number: 56, Loss: 128.99937438964844\n",
      "Epoch: 122, Batch number: 4, Loss: 116.16902160644531\n",
      "Epoch: 123, Batch number: 28, Loss: 108.54804229736328\n",
      "Epoch: 124, Batch number: 52, Loss: 104.48558807373047\n",
      "Epoch: 126, Batch number: 0, Loss: 92.58106231689453\n",
      "Epoch: 127, Batch number: 24, Loss: 93.87164306640625\n",
      "Epoch: 128, Batch number: 48, Loss: 117.54219055175781\n",
      "Epoch: 129, Batch number: 72, Loss: 96.74359130859375\n",
      "Epoch: 131, Batch number: 20, Loss: 93.5296401977539\n",
      "Epoch: 132, Batch number: 44, Loss: 90.2623291015625\n",
      "Epoch: 133, Batch number: 68, Loss: 89.87437438964844\n",
      "Epoch: 135, Batch number: 16, Loss: 76.5780029296875\n",
      "Epoch: 136, Batch number: 40, Loss: 87.17010498046875\n",
      "Epoch: 137, Batch number: 64, Loss: 79.74384307861328\n",
      "Epoch: 139, Batch number: 12, Loss: 72.7944107055664\n",
      "Epoch: 140, Batch number: 36, Loss: 72.57598876953125\n",
      "Epoch: 141, Batch number: 60, Loss: 74.78377532958984\n",
      "Epoch: 143, Batch number: 8, Loss: 66.41004943847656\n",
      "Epoch: 144, Batch number: 32, Loss: 59.48902893066406\n",
      "Epoch: 145, Batch number: 56, Loss: 57.1412353515625\n",
      "Epoch: 147, Batch number: 4, Loss: 66.5191650390625\n",
      "Epoch: 148, Batch number: 28, Loss: 60.494529724121094\n",
      "Epoch: 149, Batch number: 52, Loss: 58.57368850708008\n",
      "Epoch: 151, Batch number: 0, Loss: 58.68047332763672\n",
      "Epoch: 152, Batch number: 24, Loss: 52.546119689941406\n",
      "Epoch: 153, Batch number: 48, Loss: 56.111236572265625\n",
      "Epoch: 154, Batch number: 72, Loss: 53.955482482910156\n",
      "Epoch: 156, Batch number: 20, Loss: 46.4620246887207\n",
      "Epoch: 157, Batch number: 44, Loss: 53.4417610168457\n",
      "Epoch: 158, Batch number: 68, Loss: 56.869667053222656\n",
      "Epoch: 160, Batch number: 16, Loss: 41.75285720825195\n",
      "Epoch: 161, Batch number: 40, Loss: 41.85814666748047\n",
      "Epoch: 162, Batch number: 64, Loss: 42.66596603393555\n",
      "Epoch: 164, Batch number: 12, Loss: 46.0587158203125\n",
      "Epoch: 165, Batch number: 36, Loss: 53.48198699951172\n",
      "Epoch: 166, Batch number: 60, Loss: 42.09402847290039\n",
      "Epoch: 168, Batch number: 8, Loss: 42.10084533691406\n",
      "Epoch: 169, Batch number: 32, Loss: 45.96182632446289\n",
      "Epoch: 170, Batch number: 56, Loss: 43.05133819580078\n",
      "Epoch: 172, Batch number: 4, Loss: 32.88572311401367\n",
      "Epoch: 173, Batch number: 28, Loss: 42.404056549072266\n",
      "Epoch: 174, Batch number: 52, Loss: 39.397220611572266\n",
      "Epoch: 176, Batch number: 0, Loss: 38.90656280517578\n",
      "Epoch: 177, Batch number: 24, Loss: 43.076934814453125\n",
      "Epoch: 178, Batch number: 48, Loss: 35.99213409423828\n",
      "Epoch: 179, Batch number: 72, Loss: 33.982418060302734\n",
      "Epoch: 181, Batch number: 20, Loss: 34.780784606933594\n",
      "Epoch: 182, Batch number: 44, Loss: 34.96153259277344\n",
      "Epoch: 183, Batch number: 68, Loss: 40.88466262817383\n",
      "Epoch: 185, Batch number: 16, Loss: 40.01352310180664\n",
      "Epoch: 186, Batch number: 40, Loss: 32.56608963012695\n",
      "Epoch: 187, Batch number: 64, Loss: 28.684545516967773\n",
      "Epoch: 189, Batch number: 12, Loss: 29.19999122619629\n",
      "Epoch: 190, Batch number: 36, Loss: 41.43724060058594\n",
      "Epoch: 191, Batch number: 60, Loss: 34.2746467590332\n",
      "Epoch: 193, Batch number: 8, Loss: 30.79522705078125\n",
      "Epoch: 194, Batch number: 32, Loss: 39.59767150878906\n",
      "Epoch: 195, Batch number: 56, Loss: 31.37466812133789\n",
      "Epoch: 197, Batch number: 4, Loss: 38.59766387939453\n",
      "Epoch: 198, Batch number: 28, Loss: 31.785755157470703\n",
      "Epoch: 199, Batch number: 52, Loss: 36.85443115234375\n",
      "Epoch: 201, Batch number: 0, Loss: 22.94717788696289\n",
      "Epoch: 202, Batch number: 24, Loss: 24.292789459228516\n",
      "Epoch: 203, Batch number: 48, Loss: 31.791181564331055\n",
      "Epoch: 204, Batch number: 72, Loss: 34.93094253540039\n",
      "Epoch: 206, Batch number: 20, Loss: 25.543323516845703\n",
      "Epoch: 207, Batch number: 44, Loss: 31.76293182373047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 24.96459197998047\n",
      "Epoch: 210, Batch number: 16, Loss: 36.5880241394043\n",
      "Epoch: 211, Batch number: 40, Loss: 28.868938446044922\n",
      "Epoch: 212, Batch number: 64, Loss: 32.47420120239258\n",
      "Epoch: 214, Batch number: 12, Loss: 26.8626708984375\n",
      "Epoch: 215, Batch number: 36, Loss: 30.523300170898438\n",
      "Epoch: 216, Batch number: 60, Loss: 25.724082946777344\n",
      "Epoch: 218, Batch number: 8, Loss: 24.08887481689453\n",
      "Epoch: 219, Batch number: 32, Loss: 25.39051628112793\n",
      "Epoch: 220, Batch number: 56, Loss: 26.806203842163086\n",
      "Epoch: 222, Batch number: 4, Loss: 25.058792114257812\n",
      "Epoch: 223, Batch number: 28, Loss: 23.20039176940918\n",
      "Epoch: 224, Batch number: 52, Loss: 21.618986129760742\n",
      "Epoch: 226, Batch number: 0, Loss: 27.042797088623047\n",
      "Epoch: 227, Batch number: 24, Loss: 28.501808166503906\n",
      "Epoch: 228, Batch number: 48, Loss: 31.199981689453125\n",
      "Epoch: 229, Batch number: 72, Loss: 22.316701889038086\n",
      "Epoch: 231, Batch number: 20, Loss: 23.960712432861328\n",
      "Epoch: 232, Batch number: 44, Loss: 27.09770393371582\n",
      "Epoch: 233, Batch number: 68, Loss: 28.2716064453125\n",
      "Epoch: 235, Batch number: 16, Loss: 33.56721496582031\n",
      "Epoch: 236, Batch number: 40, Loss: 25.61032485961914\n",
      "Epoch: 237, Batch number: 64, Loss: 24.296371459960938\n",
      "Epoch: 239, Batch number: 12, Loss: 33.450626373291016\n",
      "Epoch: 240, Batch number: 36, Loss: 23.607982635498047\n",
      "Epoch: 241, Batch number: 60, Loss: 19.79445457458496\n",
      "Epoch: 243, Batch number: 8, Loss: 25.08124542236328\n",
      "Epoch: 244, Batch number: 32, Loss: 19.935688018798828\n",
      "Epoch: 245, Batch number: 56, Loss: 22.73443603515625\n",
      "Epoch: 247, Batch number: 4, Loss: 17.112659454345703\n",
      "Epoch: 248, Batch number: 28, Loss: 28.615705490112305\n",
      "Epoch: 249, Batch number: 52, Loss: 28.66264533996582\n",
      "Epoch: 251, Batch number: 0, Loss: 22.2733154296875\n",
      "Epoch: 252, Batch number: 24, Loss: 24.08774185180664\n",
      "Epoch: 253, Batch number: 48, Loss: 26.537616729736328\n",
      "Epoch: 254, Batch number: 72, Loss: 29.32830047607422\n",
      "Epoch: 256, Batch number: 20, Loss: 22.25851058959961\n",
      "Epoch: 257, Batch number: 44, Loss: 22.549890518188477\n",
      "Epoch: 258, Batch number: 68, Loss: 21.854660034179688\n",
      "Epoch: 260, Batch number: 16, Loss: 21.688831329345703\n",
      "Epoch: 261, Batch number: 40, Loss: 20.762710571289062\n",
      "Epoch: 262, Batch number: 64, Loss: 17.721878051757812\n",
      "Epoch: 264, Batch number: 12, Loss: 27.224472045898438\n",
      "Epoch: 265, Batch number: 36, Loss: 26.437152862548828\n",
      "Epoch: 266, Batch number: 60, Loss: 21.901500701904297\n",
      "Epoch: 268, Batch number: 8, Loss: 15.08486270904541\n",
      "Epoch: 269, Batch number: 32, Loss: 21.48507308959961\n",
      "Epoch: 270, Batch number: 56, Loss: 19.82139778137207\n",
      "Epoch: 272, Batch number: 4, Loss: 15.432409286499023\n",
      "Epoch: 273, Batch number: 28, Loss: 24.08405876159668\n",
      "Epoch: 274, Batch number: 52, Loss: 20.524120330810547\n",
      "Epoch: 276, Batch number: 0, Loss: 19.175016403198242\n",
      "Epoch: 277, Batch number: 24, Loss: 23.18752670288086\n",
      "Epoch: 278, Batch number: 48, Loss: 24.472631454467773\n",
      "Epoch: 279, Batch number: 72, Loss: 27.709636688232422\n",
      "Epoch: 281, Batch number: 20, Loss: 24.923145294189453\n",
      "Epoch: 282, Batch number: 44, Loss: 18.270015716552734\n",
      "Epoch: 283, Batch number: 68, Loss: 23.40373992919922\n",
      "Epoch: 285, Batch number: 16, Loss: 23.42924690246582\n",
      "Epoch: 286, Batch number: 40, Loss: 20.52461814880371\n",
      "Epoch: 287, Batch number: 64, Loss: 25.284393310546875\n",
      "Epoch: 289, Batch number: 12, Loss: 17.442584991455078\n",
      "Epoch: 290, Batch number: 36, Loss: 23.98414421081543\n",
      "Epoch: 291, Batch number: 60, Loss: 19.14834976196289\n",
      "Epoch: 293, Batch number: 8, Loss: 25.387798309326172\n",
      "Epoch: 294, Batch number: 32, Loss: 25.769943237304688\n",
      "Epoch: 295, Batch number: 56, Loss: 20.842147827148438\n",
      "Epoch: 297, Batch number: 4, Loss: 15.169612884521484\n",
      "Epoch: 298, Batch number: 28, Loss: 19.535701751708984\n",
      "Epoch: 299, Batch number: 52, Loss: 29.93963623046875\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4404.75244140625\n",
      "Epoch: 2, Batch number: 24, Loss: 3631.441650390625\n",
      "Epoch: 3, Batch number: 48, Loss: 3022.041259765625\n",
      "Epoch: 4, Batch number: 72, Loss: 2953.431640625\n",
      "Epoch: 6, Batch number: 20, Loss: 2685.56787109375\n",
      "Epoch: 7, Batch number: 44, Loss: 2632.139892578125\n",
      "Epoch: 8, Batch number: 68, Loss: 2536.12646484375\n",
      "Epoch: 10, Batch number: 16, Loss: 2310.901611328125\n",
      "Epoch: 11, Batch number: 40, Loss: 2307.111328125\n",
      "Epoch: 12, Batch number: 64, Loss: 2191.61865234375\n",
      "Epoch: 14, Batch number: 12, Loss: 1985.6968994140625\n",
      "Epoch: 15, Batch number: 36, Loss: 1988.125244140625\n",
      "Epoch: 16, Batch number: 60, Loss: 1900.8221435546875\n",
      "Epoch: 18, Batch number: 8, Loss: 1735.1639404296875\n",
      "Epoch: 19, Batch number: 32, Loss: 1750.05908203125\n",
      "Epoch: 20, Batch number: 56, Loss: 1642.2371826171875\n",
      "Epoch: 22, Batch number: 4, Loss: 1616.906005859375\n",
      "Epoch: 23, Batch number: 28, Loss: 1517.2056884765625\n",
      "Epoch: 24, Batch number: 52, Loss: 1434.6724853515625\n",
      "Epoch: 26, Batch number: 0, Loss: 1420.0628662109375\n",
      "Epoch: 27, Batch number: 24, Loss: 1276.878173828125\n",
      "Epoch: 28, Batch number: 48, Loss: 1310.7864990234375\n",
      "Epoch: 29, Batch number: 72, Loss: 1225.8929443359375\n",
      "Epoch: 31, Batch number: 20, Loss: 1228.5318603515625\n",
      "Epoch: 32, Batch number: 44, Loss: 1105.7706298828125\n",
      "Epoch: 33, Batch number: 68, Loss: 1043.243408203125\n",
      "Epoch: 35, Batch number: 16, Loss: 1070.90478515625\n",
      "Epoch: 36, Batch number: 40, Loss: 1032.044677734375\n",
      "Epoch: 37, Batch number: 64, Loss: 981.4373779296875\n",
      "Epoch: 39, Batch number: 12, Loss: 938.4773559570312\n",
      "Epoch: 40, Batch number: 36, Loss: 916.3557739257812\n",
      "Epoch: 41, Batch number: 60, Loss: 942.799072265625\n",
      "Epoch: 43, Batch number: 8, Loss: 803.9551391601562\n",
      "Epoch: 44, Batch number: 32, Loss: 792.9884643554688\n",
      "Epoch: 45, Batch number: 56, Loss: 798.434326171875\n",
      "Epoch: 47, Batch number: 4, Loss: 801.5759887695312\n",
      "Epoch: 48, Batch number: 28, Loss: 729.7841186523438\n",
      "Epoch: 49, Batch number: 52, Loss: 664.0436401367188\n",
      "Epoch: 51, Batch number: 0, Loss: 615.5933227539062\n",
      "Epoch: 52, Batch number: 24, Loss: 621.7061767578125\n",
      "Epoch: 53, Batch number: 48, Loss: 604.6300048828125\n",
      "Epoch: 54, Batch number: 72, Loss: 511.0286865234375\n",
      "Epoch: 56, Batch number: 20, Loss: 554.4288940429688\n",
      "Epoch: 57, Batch number: 44, Loss: 504.16259765625\n",
      "Epoch: 58, Batch number: 68, Loss: 534.6245727539062\n",
      "Epoch: 60, Batch number: 16, Loss: 454.85693359375\n",
      "Epoch: 61, Batch number: 40, Loss: 466.7844543457031\n",
      "Epoch: 62, Batch number: 64, Loss: 423.8636169433594\n",
      "Epoch: 64, Batch number: 12, Loss: 408.3741760253906\n",
      "Epoch: 65, Batch number: 36, Loss: 345.6187438964844\n",
      "Epoch: 66, Batch number: 60, Loss: 378.8575134277344\n",
      "Epoch: 68, Batch number: 8, Loss: 338.5094909667969\n",
      "Epoch: 69, Batch number: 32, Loss: 307.4648132324219\n",
      "Epoch: 70, Batch number: 56, Loss: 338.74603271484375\n",
      "Epoch: 72, Batch number: 4, Loss: 277.090576171875\n",
      "Epoch: 73, Batch number: 28, Loss: 292.2333068847656\n",
      "Epoch: 74, Batch number: 52, Loss: 281.9935302734375\n",
      "Epoch: 76, Batch number: 0, Loss: 260.76251220703125\n",
      "Epoch: 77, Batch number: 24, Loss: 244.20045471191406\n",
      "Epoch: 78, Batch number: 48, Loss: 253.9856414794922\n",
      "Epoch: 79, Batch number: 72, Loss: 236.40902709960938\n",
      "Epoch: 81, Batch number: 20, Loss: 248.79098510742188\n",
      "Epoch: 82, Batch number: 44, Loss: 233.71090698242188\n",
      "Epoch: 83, Batch number: 68, Loss: 202.95883178710938\n",
      "Epoch: 85, Batch number: 16, Loss: 181.1574249267578\n",
      "Epoch: 86, Batch number: 40, Loss: 179.8558807373047\n",
      "Epoch: 87, Batch number: 64, Loss: 193.39700317382812\n",
      "Epoch: 89, Batch number: 12, Loss: 155.73121643066406\n",
      "Epoch: 90, Batch number: 36, Loss: 148.74407958984375\n",
      "Epoch: 91, Batch number: 60, Loss: 161.73562622070312\n",
      "Epoch: 93, Batch number: 8, Loss: 148.85853576660156\n",
      "Epoch: 94, Batch number: 32, Loss: 139.6724853515625\n",
      "Epoch: 95, Batch number: 56, Loss: 132.25137329101562\n",
      "Epoch: 97, Batch number: 4, Loss: 131.47628784179688\n",
      "Epoch: 98, Batch number: 28, Loss: 114.96321868896484\n",
      "Epoch: 99, Batch number: 52, Loss: 114.27228546142578\n",
      "Epoch: 101, Batch number: 0, Loss: 110.82238006591797\n",
      "Epoch: 102, Batch number: 24, Loss: 103.01913452148438\n",
      "Epoch: 103, Batch number: 48, Loss: 102.8149642944336\n",
      "Epoch: 104, Batch number: 72, Loss: 94.39059448242188\n",
      "Epoch: 106, Batch number: 20, Loss: 101.90029907226562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Batch number: 44, Loss: 88.0291976928711\n",
      "Epoch: 108, Batch number: 68, Loss: 93.22931671142578\n",
      "Epoch: 110, Batch number: 16, Loss: 78.39896392822266\n",
      "Epoch: 111, Batch number: 40, Loss: 83.71064758300781\n",
      "Epoch: 112, Batch number: 64, Loss: 85.31803131103516\n",
      "Epoch: 114, Batch number: 12, Loss: 76.5546646118164\n",
      "Epoch: 115, Batch number: 36, Loss: 83.96029663085938\n",
      "Epoch: 116, Batch number: 60, Loss: 72.76309204101562\n",
      "Epoch: 118, Batch number: 8, Loss: 59.26393127441406\n",
      "Epoch: 119, Batch number: 32, Loss: 72.75625610351562\n",
      "Epoch: 120, Batch number: 56, Loss: 72.97846984863281\n",
      "Epoch: 122, Batch number: 4, Loss: 58.37629699707031\n",
      "Epoch: 123, Batch number: 28, Loss: 56.55205535888672\n",
      "Epoch: 124, Batch number: 52, Loss: 65.39519500732422\n",
      "Epoch: 126, Batch number: 0, Loss: 54.88518524169922\n",
      "Epoch: 127, Batch number: 24, Loss: 57.016937255859375\n",
      "Epoch: 128, Batch number: 48, Loss: 59.51042175292969\n",
      "Epoch: 129, Batch number: 72, Loss: 64.02487182617188\n",
      "Epoch: 131, Batch number: 20, Loss: 54.194419860839844\n",
      "Epoch: 132, Batch number: 44, Loss: 46.37723922729492\n",
      "Epoch: 133, Batch number: 68, Loss: 47.49267578125\n",
      "Epoch: 135, Batch number: 16, Loss: 52.38257598876953\n",
      "Epoch: 136, Batch number: 40, Loss: 50.65428924560547\n",
      "Epoch: 137, Batch number: 64, Loss: 48.71383285522461\n",
      "Epoch: 139, Batch number: 12, Loss: 43.190834045410156\n",
      "Epoch: 140, Batch number: 36, Loss: 50.614723205566406\n",
      "Epoch: 141, Batch number: 60, Loss: 41.94966506958008\n",
      "Epoch: 143, Batch number: 8, Loss: 43.80481719970703\n",
      "Epoch: 144, Batch number: 32, Loss: 39.3638916015625\n",
      "Epoch: 145, Batch number: 56, Loss: 35.59377670288086\n",
      "Epoch: 147, Batch number: 4, Loss: 34.97418975830078\n",
      "Epoch: 148, Batch number: 28, Loss: 40.07914352416992\n",
      "Epoch: 149, Batch number: 52, Loss: 38.4957275390625\n",
      "Epoch: 151, Batch number: 0, Loss: 41.31141662597656\n",
      "Epoch: 152, Batch number: 24, Loss: 37.75533676147461\n",
      "Epoch: 153, Batch number: 48, Loss: 42.32243347167969\n",
      "Epoch: 154, Batch number: 72, Loss: 38.118709564208984\n",
      "Epoch: 156, Batch number: 20, Loss: 27.15960693359375\n",
      "Epoch: 157, Batch number: 44, Loss: 44.39551544189453\n",
      "Epoch: 158, Batch number: 68, Loss: 33.77352523803711\n",
      "Epoch: 160, Batch number: 16, Loss: 36.15325164794922\n",
      "Epoch: 161, Batch number: 40, Loss: 36.57447052001953\n",
      "Epoch: 162, Batch number: 64, Loss: 27.206846237182617\n",
      "Epoch: 164, Batch number: 12, Loss: 35.97161865234375\n",
      "Epoch: 165, Batch number: 36, Loss: 29.32434844970703\n",
      "Epoch: 166, Batch number: 60, Loss: 36.29022979736328\n",
      "Epoch: 168, Batch number: 8, Loss: 31.95168113708496\n",
      "Epoch: 169, Batch number: 32, Loss: 33.46529769897461\n",
      "Epoch: 170, Batch number: 56, Loss: 25.05225944519043\n",
      "Epoch: 172, Batch number: 4, Loss: 27.07520294189453\n",
      "Epoch: 173, Batch number: 28, Loss: 28.273038864135742\n",
      "Epoch: 174, Batch number: 52, Loss: 39.853004455566406\n",
      "Epoch: 176, Batch number: 0, Loss: 31.000347137451172\n",
      "Epoch: 177, Batch number: 24, Loss: 24.344892501831055\n",
      "Epoch: 178, Batch number: 48, Loss: 27.497398376464844\n",
      "Epoch: 179, Batch number: 72, Loss: 28.284038543701172\n",
      "Epoch: 181, Batch number: 20, Loss: 24.575510025024414\n",
      "Epoch: 182, Batch number: 44, Loss: 23.67392349243164\n",
      "Epoch: 183, Batch number: 68, Loss: 24.766984939575195\n",
      "Epoch: 185, Batch number: 16, Loss: 29.041236877441406\n",
      "Epoch: 186, Batch number: 40, Loss: 25.297542572021484\n",
      "Epoch: 187, Batch number: 64, Loss: 26.140697479248047\n",
      "Epoch: 189, Batch number: 12, Loss: 19.549270629882812\n",
      "Epoch: 190, Batch number: 36, Loss: 26.23981475830078\n",
      "Epoch: 191, Batch number: 60, Loss: 23.194408416748047\n",
      "Epoch: 193, Batch number: 8, Loss: 30.385009765625\n",
      "Epoch: 194, Batch number: 32, Loss: 34.48063278198242\n",
      "Epoch: 195, Batch number: 56, Loss: 24.777751922607422\n",
      "Epoch: 197, Batch number: 4, Loss: 27.172828674316406\n",
      "Epoch: 198, Batch number: 28, Loss: 25.227371215820312\n",
      "Epoch: 199, Batch number: 52, Loss: 24.126590728759766\n",
      "Epoch: 201, Batch number: 0, Loss: 18.610214233398438\n",
      "Epoch: 202, Batch number: 24, Loss: 25.688541412353516\n",
      "Epoch: 203, Batch number: 48, Loss: 25.40483283996582\n",
      "Epoch: 204, Batch number: 72, Loss: 20.247148513793945\n",
      "Epoch: 206, Batch number: 20, Loss: 26.19717788696289\n",
      "Epoch: 207, Batch number: 44, Loss: 29.655765533447266\n",
      "Epoch: 208, Batch number: 68, Loss: 22.31487274169922\n",
      "Epoch: 210, Batch number: 16, Loss: 25.31539535522461\n",
      "Epoch: 211, Batch number: 40, Loss: 24.201980590820312\n",
      "Epoch: 212, Batch number: 64, Loss: 27.2542667388916\n",
      "Epoch: 214, Batch number: 12, Loss: 19.92862892150879\n",
      "Epoch: 215, Batch number: 36, Loss: 25.12491226196289\n",
      "Epoch: 216, Batch number: 60, Loss: 23.52049446105957\n",
      "Epoch: 218, Batch number: 8, Loss: 15.98714828491211\n",
      "Epoch: 219, Batch number: 32, Loss: 20.27777671813965\n",
      "Epoch: 220, Batch number: 56, Loss: 25.97156524658203\n",
      "Epoch: 222, Batch number: 4, Loss: 23.26093864440918\n",
      "Epoch: 223, Batch number: 28, Loss: 16.972145080566406\n",
      "Epoch: 224, Batch number: 52, Loss: 23.780494689941406\n",
      "Epoch: 226, Batch number: 0, Loss: 22.856077194213867\n",
      "Epoch: 227, Batch number: 24, Loss: 27.576526641845703\n",
      "Epoch: 228, Batch number: 48, Loss: 22.002090454101562\n",
      "Epoch: 229, Batch number: 72, Loss: 29.115755081176758\n",
      "Epoch: 231, Batch number: 20, Loss: 23.65723991394043\n",
      "Epoch: 232, Batch number: 44, Loss: 20.344017028808594\n",
      "Epoch: 233, Batch number: 68, Loss: 17.817026138305664\n",
      "Epoch: 235, Batch number: 16, Loss: 12.930298805236816\n",
      "Epoch: 236, Batch number: 40, Loss: 16.236309051513672\n",
      "Epoch: 237, Batch number: 64, Loss: 22.15364646911621\n",
      "Epoch: 239, Batch number: 12, Loss: 22.170799255371094\n",
      "Epoch: 240, Batch number: 36, Loss: 19.30999755859375\n",
      "Epoch: 241, Batch number: 60, Loss: 22.65170669555664\n",
      "Epoch: 243, Batch number: 8, Loss: 23.676345825195312\n",
      "Epoch: 244, Batch number: 32, Loss: 16.098831176757812\n",
      "Epoch: 245, Batch number: 56, Loss: 22.016225814819336\n",
      "Epoch: 247, Batch number: 4, Loss: 15.547574996948242\n",
      "Epoch: 248, Batch number: 28, Loss: 15.664441108703613\n",
      "Epoch: 249, Batch number: 52, Loss: 24.613162994384766\n",
      "Epoch: 251, Batch number: 0, Loss: 20.69326400756836\n",
      "Epoch: 252, Batch number: 24, Loss: 15.35412883758545\n",
      "Epoch: 253, Batch number: 48, Loss: 16.41562271118164\n",
      "Epoch: 254, Batch number: 72, Loss: 23.5727481842041\n",
      "Epoch: 256, Batch number: 20, Loss: 17.74835968017578\n",
      "Epoch: 257, Batch number: 44, Loss: 22.081344604492188\n",
      "Epoch: 258, Batch number: 68, Loss: 17.81217384338379\n",
      "Epoch: 260, Batch number: 16, Loss: 19.256723403930664\n",
      "Epoch: 261, Batch number: 40, Loss: 25.483152389526367\n",
      "Epoch: 262, Batch number: 64, Loss: 22.301280975341797\n",
      "Epoch: 264, Batch number: 12, Loss: 27.427631378173828\n",
      "Epoch: 265, Batch number: 36, Loss: 21.580875396728516\n",
      "Epoch: 266, Batch number: 60, Loss: 17.744325637817383\n",
      "Epoch: 268, Batch number: 8, Loss: 21.71491050720215\n",
      "Epoch: 269, Batch number: 32, Loss: 16.84609603881836\n",
      "Epoch: 270, Batch number: 56, Loss: 24.10744857788086\n",
      "Epoch: 272, Batch number: 4, Loss: 11.637429237365723\n",
      "Epoch: 273, Batch number: 28, Loss: 17.45232391357422\n",
      "Epoch: 274, Batch number: 52, Loss: 13.32018756866455\n",
      "Epoch: 276, Batch number: 0, Loss: 14.984733581542969\n",
      "Epoch: 277, Batch number: 24, Loss: 18.046106338500977\n",
      "Epoch: 278, Batch number: 48, Loss: 14.977751731872559\n",
      "Epoch: 279, Batch number: 72, Loss: 27.541446685791016\n",
      "Epoch: 281, Batch number: 20, Loss: 18.575193405151367\n",
      "Epoch: 282, Batch number: 44, Loss: 23.545459747314453\n",
      "Epoch: 283, Batch number: 68, Loss: 15.836970329284668\n",
      "Epoch: 285, Batch number: 16, Loss: 15.461379051208496\n",
      "Epoch: 286, Batch number: 40, Loss: 15.235318183898926\n",
      "Epoch: 287, Batch number: 64, Loss: 19.64385414123535\n",
      "Epoch: 289, Batch number: 12, Loss: 13.743457794189453\n",
      "Epoch: 290, Batch number: 36, Loss: 19.96469497680664\n",
      "Epoch: 291, Batch number: 60, Loss: 25.559078216552734\n",
      "Epoch: 293, Batch number: 8, Loss: 13.798250198364258\n",
      "Epoch: 294, Batch number: 32, Loss: 21.07147979736328\n",
      "Epoch: 295, Batch number: 56, Loss: 12.300237655639648\n",
      "Epoch: 297, Batch number: 4, Loss: 18.71080780029297\n",
      "Epoch: 298, Batch number: 28, Loss: 16.96243667602539\n",
      "Epoch: 299, Batch number: 52, Loss: 16.15326690673828\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4397.91162109375\n",
      "Epoch: 2, Batch number: 24, Loss: 4297.78271484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch number: 48, Loss: 4081.09033203125\n",
      "Epoch: 4, Batch number: 72, Loss: 3750.5908203125\n",
      "Epoch: 6, Batch number: 20, Loss: 3327.395263671875\n",
      "Epoch: 7, Batch number: 44, Loss: 3110.139892578125\n",
      "Epoch: 8, Batch number: 68, Loss: 3173.781005859375\n",
      "Epoch: 10, Batch number: 16, Loss: 3027.039306640625\n",
      "Epoch: 11, Batch number: 40, Loss: 2976.9541015625\n",
      "Epoch: 12, Batch number: 64, Loss: 3114.268310546875\n",
      "Epoch: 14, Batch number: 12, Loss: 2975.4697265625\n",
      "Epoch: 15, Batch number: 36, Loss: 3059.177001953125\n",
      "Epoch: 16, Batch number: 60, Loss: 3008.55126953125\n",
      "Epoch: 18, Batch number: 8, Loss: 2937.454833984375\n",
      "Epoch: 19, Batch number: 32, Loss: 2971.623046875\n",
      "Epoch: 20, Batch number: 56, Loss: 2961.70556640625\n",
      "Epoch: 22, Batch number: 4, Loss: 2903.5654296875\n",
      "Epoch: 23, Batch number: 28, Loss: 2985.8505859375\n",
      "Epoch: 24, Batch number: 52, Loss: 2813.111328125\n",
      "Epoch: 26, Batch number: 0, Loss: 2879.597412109375\n",
      "Epoch: 27, Batch number: 24, Loss: 2825.72998046875\n",
      "Epoch: 28, Batch number: 48, Loss: 2866.636474609375\n",
      "Epoch: 29, Batch number: 72, Loss: 2759.48046875\n",
      "Epoch: 31, Batch number: 20, Loss: 2755.952880859375\n",
      "Epoch: 32, Batch number: 44, Loss: 2720.885498046875\n",
      "Epoch: 33, Batch number: 68, Loss: 2831.8701171875\n",
      "Epoch: 35, Batch number: 16, Loss: 2683.425537109375\n",
      "Epoch: 36, Batch number: 40, Loss: 2608.64013671875\n",
      "Epoch: 37, Batch number: 64, Loss: 2645.025390625\n",
      "Epoch: 39, Batch number: 12, Loss: 2674.60595703125\n",
      "Epoch: 40, Batch number: 36, Loss: 2548.17626953125\n",
      "Epoch: 41, Batch number: 60, Loss: 2549.391357421875\n",
      "Epoch: 43, Batch number: 8, Loss: 2534.836669921875\n",
      "Epoch: 44, Batch number: 32, Loss: 2584.708984375\n",
      "Epoch: 45, Batch number: 56, Loss: 2454.69189453125\n",
      "Epoch: 47, Batch number: 4, Loss: 2575.630615234375\n",
      "Epoch: 48, Batch number: 28, Loss: 2424.580078125\n",
      "Epoch: 49, Batch number: 52, Loss: 2537.27099609375\n",
      "Epoch: 51, Batch number: 0, Loss: 2412.130126953125\n",
      "Epoch: 52, Batch number: 24, Loss: 2503.693115234375\n",
      "Epoch: 53, Batch number: 48, Loss: 2574.353759765625\n",
      "Epoch: 54, Batch number: 72, Loss: 2451.330078125\n",
      "Epoch: 56, Batch number: 20, Loss: 2355.729248046875\n",
      "Epoch: 57, Batch number: 44, Loss: 2307.71923828125\n",
      "Epoch: 58, Batch number: 68, Loss: 2370.662109375\n",
      "Epoch: 60, Batch number: 16, Loss: 2382.00830078125\n",
      "Epoch: 61, Batch number: 40, Loss: 2263.09765625\n",
      "Epoch: 62, Batch number: 64, Loss: 2337.47265625\n",
      "Epoch: 64, Batch number: 12, Loss: 2311.073974609375\n",
      "Epoch: 65, Batch number: 36, Loss: 2215.744873046875\n",
      "Epoch: 66, Batch number: 60, Loss: 2261.42822265625\n",
      "Epoch: 68, Batch number: 8, Loss: 2211.560302734375\n",
      "Epoch: 69, Batch number: 32, Loss: 2142.915771484375\n",
      "Epoch: 70, Batch number: 56, Loss: 2109.04833984375\n",
      "Epoch: 72, Batch number: 4, Loss: 2191.305419921875\n",
      "Epoch: 73, Batch number: 28, Loss: 2091.019287109375\n",
      "Epoch: 74, Batch number: 52, Loss: 2172.472412109375\n",
      "Epoch: 76, Batch number: 0, Loss: 2071.059326171875\n",
      "Epoch: 77, Batch number: 24, Loss: 2078.9873046875\n",
      "Epoch: 78, Batch number: 48, Loss: 2068.84033203125\n",
      "Epoch: 79, Batch number: 72, Loss: 2061.73291015625\n",
      "Epoch: 81, Batch number: 20, Loss: 1947.8914794921875\n",
      "Epoch: 82, Batch number: 44, Loss: 1990.720703125\n",
      "Epoch: 83, Batch number: 68, Loss: 1986.880615234375\n",
      "Epoch: 85, Batch number: 16, Loss: 1931.5245361328125\n",
      "Epoch: 86, Batch number: 40, Loss: 1979.4852294921875\n",
      "Epoch: 87, Batch number: 64, Loss: 1954.3897705078125\n",
      "Epoch: 89, Batch number: 12, Loss: 1932.11474609375\n",
      "Epoch: 90, Batch number: 36, Loss: 1908.575439453125\n",
      "Epoch: 91, Batch number: 60, Loss: 2005.125\n",
      "Epoch: 93, Batch number: 8, Loss: 1769.3289794921875\n",
      "Epoch: 94, Batch number: 32, Loss: 1795.185302734375\n",
      "Epoch: 95, Batch number: 56, Loss: 1912.350830078125\n",
      "Epoch: 97, Batch number: 4, Loss: 1826.29150390625\n",
      "Epoch: 98, Batch number: 28, Loss: 1779.03662109375\n",
      "Epoch: 99, Batch number: 52, Loss: 1859.4876708984375\n",
      "Epoch: 101, Batch number: 0, Loss: 1868.9188232421875\n",
      "Epoch: 102, Batch number: 24, Loss: 1873.5877685546875\n",
      "Epoch: 103, Batch number: 48, Loss: 1756.8983154296875\n",
      "Epoch: 104, Batch number: 72, Loss: 1770.6346435546875\n",
      "Epoch: 106, Batch number: 20, Loss: 1660.5748291015625\n",
      "Epoch: 107, Batch number: 44, Loss: 1750.5445556640625\n",
      "Epoch: 108, Batch number: 68, Loss: 1736.955078125\n",
      "Epoch: 110, Batch number: 16, Loss: 1741.0828857421875\n",
      "Epoch: 111, Batch number: 40, Loss: 1640.0634765625\n",
      "Epoch: 112, Batch number: 64, Loss: 1729.9256591796875\n",
      "Epoch: 114, Batch number: 12, Loss: 1752.00244140625\n",
      "Epoch: 115, Batch number: 36, Loss: 1653.03369140625\n",
      "Epoch: 116, Batch number: 60, Loss: 1621.6041259765625\n",
      "Epoch: 118, Batch number: 8, Loss: 1595.468505859375\n",
      "Epoch: 119, Batch number: 32, Loss: 1610.0804443359375\n",
      "Epoch: 120, Batch number: 56, Loss: 1594.908203125\n",
      "Epoch: 122, Batch number: 4, Loss: 1587.06494140625\n",
      "Epoch: 123, Batch number: 28, Loss: 1475.36376953125\n",
      "Epoch: 124, Batch number: 52, Loss: 1470.787841796875\n",
      "Epoch: 126, Batch number: 0, Loss: 1596.51123046875\n",
      "Epoch: 127, Batch number: 24, Loss: 1542.3685302734375\n",
      "Epoch: 128, Batch number: 48, Loss: 1551.4091796875\n",
      "Epoch: 129, Batch number: 72, Loss: 1558.541259765625\n",
      "Epoch: 131, Batch number: 20, Loss: 1484.9534912109375\n",
      "Epoch: 132, Batch number: 44, Loss: 1499.595703125\n",
      "Epoch: 133, Batch number: 68, Loss: 1473.2698974609375\n",
      "Epoch: 135, Batch number: 16, Loss: 1467.1783447265625\n",
      "Epoch: 136, Batch number: 40, Loss: 1405.4893798828125\n",
      "Epoch: 137, Batch number: 64, Loss: 1457.1634521484375\n",
      "Epoch: 139, Batch number: 12, Loss: 1474.3948974609375\n",
      "Epoch: 140, Batch number: 36, Loss: 1457.083984375\n",
      "Epoch: 141, Batch number: 60, Loss: 1376.89404296875\n",
      "Epoch: 143, Batch number: 8, Loss: 1442.2083740234375\n",
      "Epoch: 144, Batch number: 32, Loss: 1437.810791015625\n",
      "Epoch: 145, Batch number: 56, Loss: 1367.699462890625\n",
      "Epoch: 147, Batch number: 4, Loss: 1426.240478515625\n",
      "Epoch: 148, Batch number: 28, Loss: 1434.3544921875\n",
      "Epoch: 149, Batch number: 52, Loss: 1406.931640625\n",
      "Epoch: 151, Batch number: 0, Loss: 1334.48046875\n",
      "Epoch: 152, Batch number: 24, Loss: 1270.53369140625\n",
      "Epoch: 153, Batch number: 48, Loss: 1429.2401123046875\n",
      "Epoch: 154, Batch number: 72, Loss: 1409.880126953125\n",
      "Epoch: 156, Batch number: 20, Loss: 1379.9398193359375\n",
      "Epoch: 157, Batch number: 44, Loss: 1319.01513671875\n",
      "Epoch: 158, Batch number: 68, Loss: 1397.4638671875\n",
      "Epoch: 160, Batch number: 16, Loss: 1291.7218017578125\n",
      "Epoch: 161, Batch number: 40, Loss: 1259.601806640625\n",
      "Epoch: 162, Batch number: 64, Loss: 1274.150146484375\n",
      "Epoch: 164, Batch number: 12, Loss: 1309.6517333984375\n",
      "Epoch: 165, Batch number: 36, Loss: 1324.417724609375\n",
      "Epoch: 166, Batch number: 60, Loss: 1291.5538330078125\n",
      "Epoch: 168, Batch number: 8, Loss: 1211.6695556640625\n",
      "Epoch: 169, Batch number: 32, Loss: 1226.144775390625\n",
      "Epoch: 170, Batch number: 56, Loss: 1306.340576171875\n",
      "Epoch: 172, Batch number: 4, Loss: 1225.762451171875\n",
      "Epoch: 173, Batch number: 28, Loss: 1179.1170654296875\n",
      "Epoch: 174, Batch number: 52, Loss: 1234.5225830078125\n",
      "Epoch: 176, Batch number: 0, Loss: 1197.619140625\n",
      "Epoch: 177, Batch number: 24, Loss: 1225.6407470703125\n",
      "Epoch: 178, Batch number: 48, Loss: 1093.4249267578125\n",
      "Epoch: 179, Batch number: 72, Loss: 1225.3839111328125\n",
      "Epoch: 181, Batch number: 20, Loss: 1147.4656982421875\n",
      "Epoch: 182, Batch number: 44, Loss: 1180.885986328125\n",
      "Epoch: 183, Batch number: 68, Loss: 1200.5069580078125\n",
      "Epoch: 185, Batch number: 16, Loss: 1170.1895751953125\n",
      "Epoch: 186, Batch number: 40, Loss: 1076.7186279296875\n",
      "Epoch: 187, Batch number: 64, Loss: 1172.1917724609375\n",
      "Epoch: 189, Batch number: 12, Loss: 1107.444091796875\n",
      "Epoch: 190, Batch number: 36, Loss: 1095.343994140625\n",
      "Epoch: 191, Batch number: 60, Loss: 1225.4385986328125\n",
      "Epoch: 193, Batch number: 8, Loss: 1064.092529296875\n",
      "Epoch: 194, Batch number: 32, Loss: 1103.0833740234375\n",
      "Epoch: 195, Batch number: 56, Loss: 1043.4791259765625\n",
      "Epoch: 197, Batch number: 4, Loss: 1071.606689453125\n",
      "Epoch: 198, Batch number: 28, Loss: 1056.742431640625\n",
      "Epoch: 199, Batch number: 52, Loss: 1101.3843994140625\n",
      "Epoch: 201, Batch number: 0, Loss: 1082.7607421875\n",
      "Epoch: 202, Batch number: 24, Loss: 1057.3427734375\n",
      "Epoch: 203, Batch number: 48, Loss: 1037.044677734375\n",
      "Epoch: 204, Batch number: 72, Loss: 1005.29345703125\n",
      "Epoch: 206, Batch number: 20, Loss: 991.5228271484375\n",
      "Epoch: 207, Batch number: 44, Loss: 1069.7672119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 208, Batch number: 68, Loss: 1065.0845947265625\n",
      "Epoch: 210, Batch number: 16, Loss: 975.4473876953125\n",
      "Epoch: 211, Batch number: 40, Loss: 959.5088500976562\n",
      "Epoch: 212, Batch number: 64, Loss: 920.998779296875\n",
      "Epoch: 214, Batch number: 12, Loss: 937.3568115234375\n",
      "Epoch: 215, Batch number: 36, Loss: 940.7293701171875\n",
      "Epoch: 216, Batch number: 60, Loss: 1016.0540771484375\n",
      "Epoch: 218, Batch number: 8, Loss: 935.5452880859375\n",
      "Epoch: 219, Batch number: 32, Loss: 975.5760498046875\n",
      "Epoch: 220, Batch number: 56, Loss: 980.5050048828125\n",
      "Epoch: 222, Batch number: 4, Loss: 997.5626220703125\n",
      "Epoch: 223, Batch number: 28, Loss: 871.6600952148438\n",
      "Epoch: 224, Batch number: 52, Loss: 939.9395751953125\n",
      "Epoch: 226, Batch number: 0, Loss: 906.6578369140625\n",
      "Epoch: 227, Batch number: 24, Loss: 964.462890625\n",
      "Epoch: 228, Batch number: 48, Loss: 886.3692626953125\n",
      "Epoch: 229, Batch number: 72, Loss: 933.4373168945312\n",
      "Epoch: 231, Batch number: 20, Loss: 851.6829223632812\n",
      "Epoch: 232, Batch number: 44, Loss: 872.531005859375\n",
      "Epoch: 233, Batch number: 68, Loss: 892.6624755859375\n",
      "Epoch: 235, Batch number: 16, Loss: 872.7157592773438\n",
      "Epoch: 236, Batch number: 40, Loss: 851.24658203125\n",
      "Epoch: 237, Batch number: 64, Loss: 856.6070556640625\n",
      "Epoch: 239, Batch number: 12, Loss: 826.7498779296875\n",
      "Epoch: 240, Batch number: 36, Loss: 827.1746215820312\n",
      "Epoch: 241, Batch number: 60, Loss: 868.5443725585938\n",
      "Epoch: 243, Batch number: 8, Loss: 853.691162109375\n",
      "Epoch: 244, Batch number: 32, Loss: 844.8890991210938\n",
      "Epoch: 245, Batch number: 56, Loss: 882.6103515625\n",
      "Epoch: 247, Batch number: 4, Loss: 891.8947143554688\n",
      "Epoch: 248, Batch number: 28, Loss: 880.5390014648438\n",
      "Epoch: 249, Batch number: 52, Loss: 841.5028686523438\n",
      "Epoch: 251, Batch number: 0, Loss: 764.9603271484375\n",
      "Epoch: 252, Batch number: 24, Loss: 783.0497436523438\n",
      "Epoch: 253, Batch number: 48, Loss: 808.38916015625\n",
      "Epoch: 254, Batch number: 72, Loss: 799.9645385742188\n",
      "Epoch: 256, Batch number: 20, Loss: 738.8737182617188\n",
      "Epoch: 257, Batch number: 44, Loss: 746.0404663085938\n",
      "Epoch: 258, Batch number: 68, Loss: 799.7620849609375\n",
      "Epoch: 260, Batch number: 16, Loss: 743.2718505859375\n",
      "Epoch: 261, Batch number: 40, Loss: 822.9530639648438\n",
      "Epoch: 262, Batch number: 64, Loss: 726.4286499023438\n",
      "Epoch: 264, Batch number: 12, Loss: 749.8621826171875\n",
      "Epoch: 265, Batch number: 36, Loss: 735.77099609375\n",
      "Epoch: 266, Batch number: 60, Loss: 737.3251342773438\n",
      "Epoch: 268, Batch number: 8, Loss: 728.9093017578125\n",
      "Epoch: 269, Batch number: 32, Loss: 705.0701293945312\n",
      "Epoch: 270, Batch number: 56, Loss: 763.365234375\n",
      "Epoch: 272, Batch number: 4, Loss: 725.5311279296875\n",
      "Epoch: 273, Batch number: 28, Loss: 762.0620727539062\n",
      "Epoch: 274, Batch number: 52, Loss: 734.1765747070312\n",
      "Epoch: 276, Batch number: 0, Loss: 754.2548828125\n",
      "Epoch: 277, Batch number: 24, Loss: 755.5360717773438\n",
      "Epoch: 278, Batch number: 48, Loss: 761.58544921875\n",
      "Epoch: 279, Batch number: 72, Loss: 709.0787963867188\n",
      "Epoch: 281, Batch number: 20, Loss: 683.3651123046875\n",
      "Epoch: 282, Batch number: 44, Loss: 683.1570434570312\n",
      "Epoch: 283, Batch number: 68, Loss: 618.5642700195312\n",
      "Epoch: 285, Batch number: 16, Loss: 645.4959106445312\n",
      "Epoch: 286, Batch number: 40, Loss: 666.620849609375\n",
      "Epoch: 287, Batch number: 64, Loss: 688.2957153320312\n",
      "Epoch: 289, Batch number: 12, Loss: 596.4719848632812\n",
      "Epoch: 290, Batch number: 36, Loss: 619.7520751953125\n",
      "Epoch: 291, Batch number: 60, Loss: 636.2128295898438\n",
      "Epoch: 293, Batch number: 8, Loss: 677.3316650390625\n",
      "Epoch: 294, Batch number: 32, Loss: 632.7990112304688\n",
      "Epoch: 295, Batch number: 56, Loss: 623.4371337890625\n",
      "Epoch: 297, Batch number: 4, Loss: 629.9635009765625\n",
      "Epoch: 298, Batch number: 28, Loss: 603.6992797851562\n",
      "Epoch: 299, Batch number: 52, Loss: 607.8775024414062\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4395.74462890625\n",
      "Epoch: 2, Batch number: 24, Loss: 4188.7451171875\n",
      "Epoch: 3, Batch number: 48, Loss: 3776.9326171875\n",
      "Epoch: 4, Batch number: 72, Loss: 3313.727294921875\n",
      "Epoch: 6, Batch number: 20, Loss: 2995.24365234375\n",
      "Epoch: 7, Batch number: 44, Loss: 3019.931640625\n",
      "Epoch: 8, Batch number: 68, Loss: 3054.731201171875\n",
      "Epoch: 10, Batch number: 16, Loss: 2928.859375\n",
      "Epoch: 11, Batch number: 40, Loss: 2944.42236328125\n",
      "Epoch: 12, Batch number: 64, Loss: 2920.211181640625\n",
      "Epoch: 14, Batch number: 12, Loss: 2837.765380859375\n",
      "Epoch: 15, Batch number: 36, Loss: 2868.680908203125\n",
      "Epoch: 16, Batch number: 60, Loss: 2861.107421875\n",
      "Epoch: 18, Batch number: 8, Loss: 2708.104248046875\n",
      "Epoch: 19, Batch number: 32, Loss: 2843.731201171875\n",
      "Epoch: 20, Batch number: 56, Loss: 2704.952392578125\n",
      "Epoch: 22, Batch number: 4, Loss: 2622.68017578125\n",
      "Epoch: 23, Batch number: 28, Loss: 2708.10400390625\n",
      "Epoch: 24, Batch number: 52, Loss: 2684.14697265625\n",
      "Epoch: 26, Batch number: 0, Loss: 2527.09619140625\n",
      "Epoch: 27, Batch number: 24, Loss: 2619.517333984375\n",
      "Epoch: 28, Batch number: 48, Loss: 2502.15673828125\n",
      "Epoch: 29, Batch number: 72, Loss: 2538.16015625\n",
      "Epoch: 31, Batch number: 20, Loss: 2441.917724609375\n",
      "Epoch: 32, Batch number: 44, Loss: 2401.3955078125\n",
      "Epoch: 33, Batch number: 68, Loss: 2393.48046875\n",
      "Epoch: 35, Batch number: 16, Loss: 2300.923828125\n",
      "Epoch: 36, Batch number: 40, Loss: 2208.39599609375\n",
      "Epoch: 37, Batch number: 64, Loss: 2307.30224609375\n",
      "Epoch: 39, Batch number: 12, Loss: 2203.273681640625\n",
      "Epoch: 40, Batch number: 36, Loss: 2018.376708984375\n",
      "Epoch: 41, Batch number: 60, Loss: 2232.941650390625\n",
      "Epoch: 43, Batch number: 8, Loss: 2189.38623046875\n",
      "Epoch: 44, Batch number: 32, Loss: 2094.053466796875\n",
      "Epoch: 45, Batch number: 56, Loss: 2063.03466796875\n",
      "Epoch: 47, Batch number: 4, Loss: 2027.130615234375\n",
      "Epoch: 48, Batch number: 28, Loss: 2002.8043212890625\n",
      "Epoch: 49, Batch number: 52, Loss: 2065.409423828125\n",
      "Epoch: 51, Batch number: 0, Loss: 1965.006103515625\n",
      "Epoch: 52, Batch number: 24, Loss: 1860.3734130859375\n",
      "Epoch: 53, Batch number: 48, Loss: 1856.48095703125\n",
      "Epoch: 54, Batch number: 72, Loss: 1850.5684814453125\n",
      "Epoch: 56, Batch number: 20, Loss: 1801.86083984375\n",
      "Epoch: 57, Batch number: 44, Loss: 1863.79052734375\n",
      "Epoch: 58, Batch number: 68, Loss: 1751.880126953125\n",
      "Epoch: 60, Batch number: 16, Loss: 1692.3636474609375\n",
      "Epoch: 61, Batch number: 40, Loss: 1694.2884521484375\n",
      "Epoch: 62, Batch number: 64, Loss: 1751.8980712890625\n",
      "Epoch: 64, Batch number: 12, Loss: 1697.8857421875\n",
      "Epoch: 65, Batch number: 36, Loss: 1702.0289306640625\n",
      "Epoch: 66, Batch number: 60, Loss: 1617.3118896484375\n",
      "Epoch: 68, Batch number: 8, Loss: 1589.4024658203125\n",
      "Epoch: 69, Batch number: 32, Loss: 1578.5042724609375\n",
      "Epoch: 70, Batch number: 56, Loss: 1585.3055419921875\n",
      "Epoch: 72, Batch number: 4, Loss: 1562.0916748046875\n",
      "Epoch: 73, Batch number: 28, Loss: 1566.036865234375\n",
      "Epoch: 74, Batch number: 52, Loss: 1515.0723876953125\n",
      "Epoch: 76, Batch number: 0, Loss: 1474.040283203125\n",
      "Epoch: 77, Batch number: 24, Loss: 1436.7855224609375\n",
      "Epoch: 78, Batch number: 48, Loss: 1428.440185546875\n",
      "Epoch: 79, Batch number: 72, Loss: 1424.019287109375\n",
      "Epoch: 81, Batch number: 20, Loss: 1434.0958251953125\n",
      "Epoch: 82, Batch number: 44, Loss: 1468.37353515625\n",
      "Epoch: 83, Batch number: 68, Loss: 1390.56005859375\n",
      "Epoch: 85, Batch number: 16, Loss: 1385.26953125\n",
      "Epoch: 86, Batch number: 40, Loss: 1304.548583984375\n",
      "Epoch: 87, Batch number: 64, Loss: 1392.96240234375\n",
      "Epoch: 89, Batch number: 12, Loss: 1285.6239013671875\n",
      "Epoch: 90, Batch number: 36, Loss: 1258.6339111328125\n",
      "Epoch: 91, Batch number: 60, Loss: 1269.4552001953125\n",
      "Epoch: 93, Batch number: 8, Loss: 1249.2198486328125\n",
      "Epoch: 94, Batch number: 32, Loss: 1216.7257080078125\n",
      "Epoch: 95, Batch number: 56, Loss: 1204.2938232421875\n",
      "Epoch: 97, Batch number: 4, Loss: 1199.939453125\n",
      "Epoch: 98, Batch number: 28, Loss: 1189.528564453125\n",
      "Epoch: 99, Batch number: 52, Loss: 1195.7705078125\n",
      "Epoch: 101, Batch number: 0, Loss: 1115.91455078125\n",
      "Epoch: 102, Batch number: 24, Loss: 1138.198974609375\n",
      "Epoch: 103, Batch number: 48, Loss: 1173.0430908203125\n",
      "Epoch: 104, Batch number: 72, Loss: 1144.4322509765625\n",
      "Epoch: 106, Batch number: 20, Loss: 1137.15576171875\n",
      "Epoch: 107, Batch number: 44, Loss: 1144.246826171875\n",
      "Epoch: 108, Batch number: 68, Loss: 1087.2110595703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 16, Loss: 1067.8695068359375\n",
      "Epoch: 111, Batch number: 40, Loss: 1039.2479248046875\n",
      "Epoch: 112, Batch number: 64, Loss: 1036.6046142578125\n",
      "Epoch: 114, Batch number: 12, Loss: 1059.0238037109375\n",
      "Epoch: 115, Batch number: 36, Loss: 1025.1868896484375\n",
      "Epoch: 116, Batch number: 60, Loss: 1006.6777954101562\n",
      "Epoch: 118, Batch number: 8, Loss: 968.0300903320312\n",
      "Epoch: 119, Batch number: 32, Loss: 982.1450805664062\n",
      "Epoch: 120, Batch number: 56, Loss: 942.5279541015625\n",
      "Epoch: 122, Batch number: 4, Loss: 927.6643676757812\n",
      "Epoch: 123, Batch number: 28, Loss: 912.1168823242188\n",
      "Epoch: 124, Batch number: 52, Loss: 963.5238647460938\n",
      "Epoch: 126, Batch number: 0, Loss: 933.8804321289062\n",
      "Epoch: 127, Batch number: 24, Loss: 946.9678344726562\n",
      "Epoch: 128, Batch number: 48, Loss: 857.22900390625\n",
      "Epoch: 129, Batch number: 72, Loss: 934.0369262695312\n",
      "Epoch: 131, Batch number: 20, Loss: 916.3209838867188\n",
      "Epoch: 132, Batch number: 44, Loss: 890.7031860351562\n",
      "Epoch: 133, Batch number: 68, Loss: 845.5476684570312\n",
      "Epoch: 135, Batch number: 16, Loss: 837.0977783203125\n",
      "Epoch: 136, Batch number: 40, Loss: 785.5390014648438\n",
      "Epoch: 137, Batch number: 64, Loss: 842.495849609375\n",
      "Epoch: 139, Batch number: 12, Loss: 788.9938354492188\n",
      "Epoch: 140, Batch number: 36, Loss: 785.255615234375\n",
      "Epoch: 141, Batch number: 60, Loss: 802.5923461914062\n",
      "Epoch: 143, Batch number: 8, Loss: 781.6639404296875\n",
      "Epoch: 144, Batch number: 32, Loss: 758.9534912109375\n",
      "Epoch: 145, Batch number: 56, Loss: 722.6853637695312\n",
      "Epoch: 147, Batch number: 4, Loss: 707.76220703125\n",
      "Epoch: 148, Batch number: 28, Loss: 717.0572509765625\n",
      "Epoch: 149, Batch number: 52, Loss: 717.1660766601562\n",
      "Epoch: 151, Batch number: 0, Loss: 685.3128051757812\n",
      "Epoch: 152, Batch number: 24, Loss: 681.041748046875\n",
      "Epoch: 153, Batch number: 48, Loss: 678.5096435546875\n",
      "Epoch: 154, Batch number: 72, Loss: 705.7601928710938\n",
      "Epoch: 156, Batch number: 20, Loss: 629.3429565429688\n",
      "Epoch: 157, Batch number: 44, Loss: 656.8971557617188\n",
      "Epoch: 158, Batch number: 68, Loss: 640.5503540039062\n",
      "Epoch: 160, Batch number: 16, Loss: 655.3944702148438\n",
      "Epoch: 161, Batch number: 40, Loss: 652.2874755859375\n",
      "Epoch: 162, Batch number: 64, Loss: 642.4583129882812\n",
      "Epoch: 164, Batch number: 12, Loss: 601.432861328125\n",
      "Epoch: 165, Batch number: 36, Loss: 599.1448974609375\n",
      "Epoch: 166, Batch number: 60, Loss: 617.1861572265625\n",
      "Epoch: 168, Batch number: 8, Loss: 611.6602172851562\n",
      "Epoch: 169, Batch number: 32, Loss: 603.8339233398438\n",
      "Epoch: 170, Batch number: 56, Loss: 585.38916015625\n",
      "Epoch: 172, Batch number: 4, Loss: 481.3190612792969\n",
      "Epoch: 173, Batch number: 28, Loss: 540.4869384765625\n",
      "Epoch: 174, Batch number: 52, Loss: 531.4387817382812\n",
      "Epoch: 176, Batch number: 0, Loss: 551.1683349609375\n",
      "Epoch: 177, Batch number: 24, Loss: 465.6835021972656\n",
      "Epoch: 178, Batch number: 48, Loss: 513.662109375\n",
      "Epoch: 179, Batch number: 72, Loss: 499.9521484375\n",
      "Epoch: 181, Batch number: 20, Loss: 486.7314758300781\n",
      "Epoch: 182, Batch number: 44, Loss: 506.5725402832031\n",
      "Epoch: 183, Batch number: 68, Loss: 516.952392578125\n",
      "Epoch: 185, Batch number: 16, Loss: 512.1598510742188\n",
      "Epoch: 186, Batch number: 40, Loss: 477.4104309082031\n",
      "Epoch: 187, Batch number: 64, Loss: 432.0286560058594\n",
      "Epoch: 189, Batch number: 12, Loss: 443.0694274902344\n",
      "Epoch: 190, Batch number: 36, Loss: 477.08538818359375\n",
      "Epoch: 191, Batch number: 60, Loss: 465.1677551269531\n",
      "Epoch: 193, Batch number: 8, Loss: 424.811279296875\n",
      "Epoch: 194, Batch number: 32, Loss: 390.7630615234375\n",
      "Epoch: 195, Batch number: 56, Loss: 433.0159912109375\n",
      "Epoch: 197, Batch number: 4, Loss: 428.0337219238281\n",
      "Epoch: 198, Batch number: 28, Loss: 426.83685302734375\n",
      "Epoch: 199, Batch number: 52, Loss: 393.79022216796875\n",
      "Epoch: 201, Batch number: 0, Loss: 412.0125732421875\n",
      "Epoch: 202, Batch number: 24, Loss: 371.88714599609375\n",
      "Epoch: 203, Batch number: 48, Loss: 361.85198974609375\n",
      "Epoch: 204, Batch number: 72, Loss: 370.56573486328125\n",
      "Epoch: 206, Batch number: 20, Loss: 380.280029296875\n",
      "Epoch: 207, Batch number: 44, Loss: 367.4781799316406\n",
      "Epoch: 208, Batch number: 68, Loss: 348.6543273925781\n",
      "Epoch: 210, Batch number: 16, Loss: 332.18206787109375\n",
      "Epoch: 211, Batch number: 40, Loss: 331.84869384765625\n",
      "Epoch: 212, Batch number: 64, Loss: 318.4470520019531\n",
      "Epoch: 214, Batch number: 12, Loss: 291.09027099609375\n",
      "Epoch: 215, Batch number: 36, Loss: 315.7730407714844\n",
      "Epoch: 216, Batch number: 60, Loss: 321.7125549316406\n",
      "Epoch: 218, Batch number: 8, Loss: 303.4847717285156\n",
      "Epoch: 219, Batch number: 32, Loss: 300.0123291015625\n",
      "Epoch: 220, Batch number: 56, Loss: 311.7439270019531\n",
      "Epoch: 222, Batch number: 4, Loss: 267.1148986816406\n",
      "Epoch: 223, Batch number: 28, Loss: 283.903076171875\n",
      "Epoch: 224, Batch number: 52, Loss: 266.40435791015625\n",
      "Epoch: 226, Batch number: 0, Loss: 269.9187316894531\n",
      "Epoch: 227, Batch number: 24, Loss: 270.5848083496094\n",
      "Epoch: 228, Batch number: 48, Loss: 243.23081970214844\n",
      "Epoch: 229, Batch number: 72, Loss: 256.3831787109375\n",
      "Epoch: 231, Batch number: 20, Loss: 290.0768737792969\n",
      "Epoch: 232, Batch number: 44, Loss: 249.07933044433594\n",
      "Epoch: 233, Batch number: 68, Loss: 232.737060546875\n",
      "Epoch: 235, Batch number: 16, Loss: 232.97189331054688\n",
      "Epoch: 236, Batch number: 40, Loss: 222.76626586914062\n",
      "Epoch: 237, Batch number: 64, Loss: 215.62123107910156\n",
      "Epoch: 239, Batch number: 12, Loss: 235.1178741455078\n",
      "Epoch: 240, Batch number: 36, Loss: 215.44345092773438\n",
      "Epoch: 241, Batch number: 60, Loss: 243.15634155273438\n",
      "Epoch: 243, Batch number: 8, Loss: 214.57728576660156\n",
      "Epoch: 244, Batch number: 32, Loss: 211.23431396484375\n",
      "Epoch: 245, Batch number: 56, Loss: 202.9163818359375\n",
      "Epoch: 247, Batch number: 4, Loss: 208.6273193359375\n",
      "Epoch: 248, Batch number: 28, Loss: 188.43942260742188\n",
      "Epoch: 249, Batch number: 52, Loss: 223.54917907714844\n",
      "Epoch: 251, Batch number: 0, Loss: 164.96328735351562\n",
      "Epoch: 252, Batch number: 24, Loss: 188.1443328857422\n",
      "Epoch: 253, Batch number: 48, Loss: 180.4977264404297\n",
      "Epoch: 254, Batch number: 72, Loss: 208.12094116210938\n",
      "Epoch: 256, Batch number: 20, Loss: 177.27508544921875\n",
      "Epoch: 257, Batch number: 44, Loss: 166.99623107910156\n",
      "Epoch: 258, Batch number: 68, Loss: 167.8917236328125\n",
      "Epoch: 260, Batch number: 16, Loss: 163.24066162109375\n",
      "Epoch: 261, Batch number: 40, Loss: 176.14012145996094\n",
      "Epoch: 262, Batch number: 64, Loss: 151.05238342285156\n",
      "Epoch: 264, Batch number: 12, Loss: 150.30593872070312\n",
      "Epoch: 265, Batch number: 36, Loss: 140.7398223876953\n",
      "Epoch: 266, Batch number: 60, Loss: 139.7936553955078\n",
      "Epoch: 268, Batch number: 8, Loss: 137.007568359375\n",
      "Epoch: 269, Batch number: 32, Loss: 149.2587127685547\n",
      "Epoch: 270, Batch number: 56, Loss: 130.3194580078125\n",
      "Epoch: 272, Batch number: 4, Loss: 130.90011596679688\n",
      "Epoch: 273, Batch number: 28, Loss: 124.65028381347656\n",
      "Epoch: 274, Batch number: 52, Loss: 126.5438461303711\n",
      "Epoch: 276, Batch number: 0, Loss: 122.1150131225586\n",
      "Epoch: 277, Batch number: 24, Loss: 124.08038330078125\n",
      "Epoch: 278, Batch number: 48, Loss: 124.2273941040039\n",
      "Epoch: 279, Batch number: 72, Loss: 143.4894256591797\n",
      "Epoch: 281, Batch number: 20, Loss: 113.83767700195312\n",
      "Epoch: 282, Batch number: 44, Loss: 123.5856704711914\n",
      "Epoch: 283, Batch number: 68, Loss: 119.41583251953125\n",
      "Epoch: 285, Batch number: 16, Loss: 89.0650634765625\n",
      "Epoch: 286, Batch number: 40, Loss: 111.2484359741211\n",
      "Epoch: 287, Batch number: 64, Loss: 119.58548736572266\n",
      "Epoch: 289, Batch number: 12, Loss: 109.06627655029297\n",
      "Epoch: 290, Batch number: 36, Loss: 100.076904296875\n",
      "Epoch: 291, Batch number: 60, Loss: 109.7498779296875\n",
      "Epoch: 293, Batch number: 8, Loss: 92.51130676269531\n",
      "Epoch: 294, Batch number: 32, Loss: 106.2356185913086\n",
      "Epoch: 295, Batch number: 56, Loss: 100.12207794189453\n",
      "Epoch: 297, Batch number: 4, Loss: 84.4358139038086\n",
      "Epoch: 298, Batch number: 28, Loss: 89.21293640136719\n",
      "Epoch: 299, Batch number: 52, Loss: 96.14836883544922\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4405.74267578125\n",
      "Epoch: 2, Batch number: 24, Loss: 4074.8193359375\n",
      "Epoch: 3, Batch number: 48, Loss: 3465.2216796875\n",
      "Epoch: 4, Batch number: 72, Loss: 3036.676513671875\n",
      "Epoch: 6, Batch number: 20, Loss: 3075.137451171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Batch number: 44, Loss: 3045.542724609375\n",
      "Epoch: 8, Batch number: 68, Loss: 3017.4580078125\n",
      "Epoch: 10, Batch number: 16, Loss: 2999.1220703125\n",
      "Epoch: 11, Batch number: 40, Loss: 2775.592041015625\n",
      "Epoch: 12, Batch number: 64, Loss: 2787.881103515625\n",
      "Epoch: 14, Batch number: 12, Loss: 2671.48291015625\n",
      "Epoch: 15, Batch number: 36, Loss: 2710.56201171875\n",
      "Epoch: 16, Batch number: 60, Loss: 2569.560302734375\n",
      "Epoch: 18, Batch number: 8, Loss: 2629.439697265625\n",
      "Epoch: 19, Batch number: 32, Loss: 2514.30712890625\n",
      "Epoch: 20, Batch number: 56, Loss: 2432.595703125\n",
      "Epoch: 22, Batch number: 4, Loss: 2492.5283203125\n",
      "Epoch: 23, Batch number: 28, Loss: 2391.919921875\n",
      "Epoch: 24, Batch number: 52, Loss: 2414.494140625\n",
      "Epoch: 26, Batch number: 0, Loss: 2382.24609375\n",
      "Epoch: 27, Batch number: 24, Loss: 2353.2119140625\n",
      "Epoch: 28, Batch number: 48, Loss: 2292.7373046875\n",
      "Epoch: 29, Batch number: 72, Loss: 2204.6435546875\n",
      "Epoch: 31, Batch number: 20, Loss: 2147.667724609375\n",
      "Epoch: 32, Batch number: 44, Loss: 2054.638427734375\n",
      "Epoch: 33, Batch number: 68, Loss: 2123.227294921875\n",
      "Epoch: 35, Batch number: 16, Loss: 1985.7578125\n",
      "Epoch: 36, Batch number: 40, Loss: 1951.9119873046875\n",
      "Epoch: 37, Batch number: 64, Loss: 1981.3299560546875\n",
      "Epoch: 39, Batch number: 12, Loss: 1903.9747314453125\n",
      "Epoch: 40, Batch number: 36, Loss: 1833.116943359375\n",
      "Epoch: 41, Batch number: 60, Loss: 1843.6370849609375\n",
      "Epoch: 43, Batch number: 8, Loss: 1808.29248046875\n",
      "Epoch: 44, Batch number: 32, Loss: 1690.635498046875\n",
      "Epoch: 45, Batch number: 56, Loss: 1702.585693359375\n",
      "Epoch: 47, Batch number: 4, Loss: 1596.627197265625\n",
      "Epoch: 48, Batch number: 28, Loss: 1661.205810546875\n",
      "Epoch: 49, Batch number: 52, Loss: 1627.5982666015625\n",
      "Epoch: 51, Batch number: 0, Loss: 1595.7913818359375\n",
      "Epoch: 52, Batch number: 24, Loss: 1506.8590087890625\n",
      "Epoch: 53, Batch number: 48, Loss: 1553.04345703125\n",
      "Epoch: 54, Batch number: 72, Loss: 1493.159912109375\n",
      "Epoch: 56, Batch number: 20, Loss: 1411.457275390625\n",
      "Epoch: 57, Batch number: 44, Loss: 1480.8665771484375\n",
      "Epoch: 58, Batch number: 68, Loss: 1424.477783203125\n",
      "Epoch: 60, Batch number: 16, Loss: 1446.579345703125\n",
      "Epoch: 61, Batch number: 40, Loss: 1289.8565673828125\n",
      "Epoch: 62, Batch number: 64, Loss: 1345.244384765625\n",
      "Epoch: 64, Batch number: 12, Loss: 1236.7113037109375\n",
      "Epoch: 65, Batch number: 36, Loss: 1217.9473876953125\n",
      "Epoch: 66, Batch number: 60, Loss: 1256.1461181640625\n",
      "Epoch: 68, Batch number: 8, Loss: 1181.2421875\n",
      "Epoch: 69, Batch number: 32, Loss: 1274.1697998046875\n",
      "Epoch: 70, Batch number: 56, Loss: 1207.36083984375\n",
      "Epoch: 72, Batch number: 4, Loss: 1202.7669677734375\n",
      "Epoch: 73, Batch number: 28, Loss: 1129.1044921875\n",
      "Epoch: 74, Batch number: 52, Loss: 1146.9537353515625\n",
      "Epoch: 76, Batch number: 0, Loss: 1135.11474609375\n",
      "Epoch: 77, Batch number: 24, Loss: 1091.025634765625\n",
      "Epoch: 78, Batch number: 48, Loss: 1130.053466796875\n",
      "Epoch: 79, Batch number: 72, Loss: 1099.349609375\n",
      "Epoch: 81, Batch number: 20, Loss: 1058.9517822265625\n",
      "Epoch: 82, Batch number: 44, Loss: 1000.5274047851562\n",
      "Epoch: 83, Batch number: 68, Loss: 1002.8713989257812\n",
      "Epoch: 85, Batch number: 16, Loss: 944.3792724609375\n",
      "Epoch: 86, Batch number: 40, Loss: 981.648193359375\n",
      "Epoch: 87, Batch number: 64, Loss: 971.080810546875\n",
      "Epoch: 89, Batch number: 12, Loss: 879.8067626953125\n",
      "Epoch: 90, Batch number: 36, Loss: 947.884521484375\n",
      "Epoch: 91, Batch number: 60, Loss: 939.5008544921875\n",
      "Epoch: 93, Batch number: 8, Loss: 900.7344360351562\n",
      "Epoch: 94, Batch number: 32, Loss: 847.5931396484375\n",
      "Epoch: 95, Batch number: 56, Loss: 857.7930908203125\n",
      "Epoch: 97, Batch number: 4, Loss: 825.0994873046875\n",
      "Epoch: 98, Batch number: 28, Loss: 838.9669799804688\n",
      "Epoch: 99, Batch number: 52, Loss: 826.2192993164062\n",
      "Epoch: 101, Batch number: 0, Loss: 785.0850830078125\n",
      "Epoch: 102, Batch number: 24, Loss: 784.134033203125\n",
      "Epoch: 103, Batch number: 48, Loss: 774.231201171875\n",
      "Epoch: 104, Batch number: 72, Loss: 775.4925537109375\n",
      "Epoch: 106, Batch number: 20, Loss: 723.2757568359375\n",
      "Epoch: 107, Batch number: 44, Loss: 735.7037963867188\n",
      "Epoch: 108, Batch number: 68, Loss: 690.6466674804688\n",
      "Epoch: 110, Batch number: 16, Loss: 633.9541015625\n",
      "Epoch: 111, Batch number: 40, Loss: 667.6829223632812\n",
      "Epoch: 112, Batch number: 64, Loss: 631.1053466796875\n",
      "Epoch: 114, Batch number: 12, Loss: 645.3652954101562\n",
      "Epoch: 115, Batch number: 36, Loss: 620.003173828125\n",
      "Epoch: 116, Batch number: 60, Loss: 640.3839111328125\n",
      "Epoch: 118, Batch number: 8, Loss: 585.7545166015625\n",
      "Epoch: 119, Batch number: 32, Loss: 603.9147338867188\n",
      "Epoch: 120, Batch number: 56, Loss: 563.7540893554688\n",
      "Epoch: 122, Batch number: 4, Loss: 543.3888549804688\n",
      "Epoch: 123, Batch number: 28, Loss: 545.835205078125\n",
      "Epoch: 124, Batch number: 52, Loss: 578.7991333007812\n",
      "Epoch: 126, Batch number: 0, Loss: 540.714111328125\n",
      "Epoch: 127, Batch number: 24, Loss: 530.1009521484375\n",
      "Epoch: 128, Batch number: 48, Loss: 509.9607849121094\n",
      "Epoch: 129, Batch number: 72, Loss: 544.6988525390625\n",
      "Epoch: 131, Batch number: 20, Loss: 535.2073974609375\n",
      "Epoch: 132, Batch number: 44, Loss: 480.0400085449219\n",
      "Epoch: 133, Batch number: 68, Loss: 507.8016662597656\n",
      "Epoch: 135, Batch number: 16, Loss: 446.3710632324219\n",
      "Epoch: 136, Batch number: 40, Loss: 460.7922058105469\n",
      "Epoch: 137, Batch number: 64, Loss: 448.9565734863281\n",
      "Epoch: 139, Batch number: 12, Loss: 402.71728515625\n",
      "Epoch: 140, Batch number: 36, Loss: 403.91668701171875\n",
      "Epoch: 141, Batch number: 60, Loss: 435.4388427734375\n",
      "Epoch: 143, Batch number: 8, Loss: 439.38995361328125\n",
      "Epoch: 144, Batch number: 32, Loss: 388.86181640625\n",
      "Epoch: 145, Batch number: 56, Loss: 380.9796447753906\n",
      "Epoch: 147, Batch number: 4, Loss: 372.60321044921875\n",
      "Epoch: 148, Batch number: 28, Loss: 378.87286376953125\n",
      "Epoch: 149, Batch number: 52, Loss: 380.5987854003906\n",
      "Epoch: 151, Batch number: 0, Loss: 328.7464599609375\n",
      "Epoch: 152, Batch number: 24, Loss: 332.9772033691406\n",
      "Epoch: 153, Batch number: 48, Loss: 325.87652587890625\n",
      "Epoch: 154, Batch number: 72, Loss: 351.100341796875\n",
      "Epoch: 156, Batch number: 20, Loss: 340.58709716796875\n",
      "Epoch: 157, Batch number: 44, Loss: 298.3218994140625\n",
      "Epoch: 158, Batch number: 68, Loss: 284.3053283691406\n",
      "Epoch: 160, Batch number: 16, Loss: 302.6622009277344\n",
      "Epoch: 161, Batch number: 40, Loss: 303.5163269042969\n",
      "Epoch: 162, Batch number: 64, Loss: 275.042724609375\n",
      "Epoch: 164, Batch number: 12, Loss: 264.0395812988281\n",
      "Epoch: 165, Batch number: 36, Loss: 264.71832275390625\n",
      "Epoch: 166, Batch number: 60, Loss: 226.57818603515625\n",
      "Epoch: 168, Batch number: 8, Loss: 269.9792785644531\n",
      "Epoch: 169, Batch number: 32, Loss: 246.77110290527344\n",
      "Epoch: 170, Batch number: 56, Loss: 261.1656188964844\n",
      "Epoch: 172, Batch number: 4, Loss: 221.98939514160156\n",
      "Epoch: 173, Batch number: 28, Loss: 235.68267822265625\n",
      "Epoch: 174, Batch number: 52, Loss: 251.01380920410156\n",
      "Epoch: 176, Batch number: 0, Loss: 198.38731384277344\n",
      "Epoch: 177, Batch number: 24, Loss: 201.6328887939453\n",
      "Epoch: 178, Batch number: 48, Loss: 182.9096221923828\n",
      "Epoch: 179, Batch number: 72, Loss: 202.9558868408203\n",
      "Epoch: 181, Batch number: 20, Loss: 201.76768493652344\n",
      "Epoch: 182, Batch number: 44, Loss: 176.228515625\n",
      "Epoch: 183, Batch number: 68, Loss: 180.31390380859375\n",
      "Epoch: 185, Batch number: 16, Loss: 211.14361572265625\n",
      "Epoch: 186, Batch number: 40, Loss: 175.3933563232422\n",
      "Epoch: 187, Batch number: 64, Loss: 195.6892852783203\n",
      "Epoch: 189, Batch number: 12, Loss: 155.43170166015625\n",
      "Epoch: 190, Batch number: 36, Loss: 173.77651977539062\n",
      "Epoch: 191, Batch number: 60, Loss: 174.75894165039062\n",
      "Epoch: 193, Batch number: 8, Loss: 150.41427612304688\n",
      "Epoch: 194, Batch number: 32, Loss: 147.53268432617188\n",
      "Epoch: 195, Batch number: 56, Loss: 146.93190002441406\n",
      "Epoch: 197, Batch number: 4, Loss: 124.71308135986328\n",
      "Epoch: 198, Batch number: 28, Loss: 129.8797149658203\n",
      "Epoch: 199, Batch number: 52, Loss: 147.394775390625\n",
      "Epoch: 201, Batch number: 0, Loss: 146.20687866210938\n",
      "Epoch: 202, Batch number: 24, Loss: 134.620849609375\n",
      "Epoch: 203, Batch number: 48, Loss: 140.7552490234375\n",
      "Epoch: 204, Batch number: 72, Loss: 143.0948486328125\n",
      "Epoch: 206, Batch number: 20, Loss: 108.16117858886719\n",
      "Epoch: 207, Batch number: 44, Loss: 114.64756774902344\n",
      "Epoch: 208, Batch number: 68, Loss: 119.71107482910156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Batch number: 16, Loss: 111.63005828857422\n",
      "Epoch: 211, Batch number: 40, Loss: 113.08209991455078\n",
      "Epoch: 212, Batch number: 64, Loss: 102.48861694335938\n",
      "Epoch: 214, Batch number: 12, Loss: 102.1417465209961\n",
      "Epoch: 215, Batch number: 36, Loss: 92.54788970947266\n",
      "Epoch: 216, Batch number: 60, Loss: 99.55904388427734\n",
      "Epoch: 218, Batch number: 8, Loss: 93.41531372070312\n",
      "Epoch: 219, Batch number: 32, Loss: 84.86408233642578\n",
      "Epoch: 220, Batch number: 56, Loss: 91.28460693359375\n",
      "Epoch: 222, Batch number: 4, Loss: 89.72809600830078\n",
      "Epoch: 223, Batch number: 28, Loss: 94.45799255371094\n",
      "Epoch: 224, Batch number: 52, Loss: 90.40603637695312\n",
      "Epoch: 226, Batch number: 0, Loss: 68.66834259033203\n",
      "Epoch: 227, Batch number: 24, Loss: 82.5378189086914\n",
      "Epoch: 228, Batch number: 48, Loss: 79.77252197265625\n",
      "Epoch: 229, Batch number: 72, Loss: 74.081787109375\n",
      "Epoch: 231, Batch number: 20, Loss: 73.41429138183594\n",
      "Epoch: 232, Batch number: 44, Loss: 67.07905578613281\n",
      "Epoch: 233, Batch number: 68, Loss: 75.84004211425781\n",
      "Epoch: 235, Batch number: 16, Loss: 71.58444213867188\n",
      "Epoch: 236, Batch number: 40, Loss: 75.5748291015625\n",
      "Epoch: 237, Batch number: 64, Loss: 72.73570251464844\n",
      "Epoch: 239, Batch number: 12, Loss: 65.64193725585938\n",
      "Epoch: 240, Batch number: 36, Loss: 57.9284553527832\n",
      "Epoch: 241, Batch number: 60, Loss: 61.21561050415039\n",
      "Epoch: 243, Batch number: 8, Loss: 63.90107345581055\n",
      "Epoch: 244, Batch number: 32, Loss: 50.830718994140625\n",
      "Epoch: 245, Batch number: 56, Loss: 54.682281494140625\n",
      "Epoch: 247, Batch number: 4, Loss: 55.65297317504883\n",
      "Epoch: 248, Batch number: 28, Loss: 52.93699645996094\n",
      "Epoch: 249, Batch number: 52, Loss: 48.31825256347656\n",
      "Epoch: 251, Batch number: 0, Loss: 54.85401916503906\n",
      "Epoch: 252, Batch number: 24, Loss: 53.63459777832031\n",
      "Epoch: 253, Batch number: 48, Loss: 49.062522888183594\n",
      "Epoch: 254, Batch number: 72, Loss: 58.57184982299805\n",
      "Epoch: 256, Batch number: 20, Loss: 48.63572692871094\n",
      "Epoch: 257, Batch number: 44, Loss: 49.0826530456543\n",
      "Epoch: 258, Batch number: 68, Loss: 55.758544921875\n",
      "Epoch: 260, Batch number: 16, Loss: 42.91667175292969\n",
      "Epoch: 261, Batch number: 40, Loss: 50.91624450683594\n",
      "Epoch: 262, Batch number: 64, Loss: 47.925315856933594\n",
      "Epoch: 264, Batch number: 12, Loss: 45.64874267578125\n",
      "Epoch: 265, Batch number: 36, Loss: 42.131690979003906\n",
      "Epoch: 266, Batch number: 60, Loss: 50.00757598876953\n",
      "Epoch: 268, Batch number: 8, Loss: 44.91482162475586\n",
      "Epoch: 269, Batch number: 32, Loss: 44.23095703125\n",
      "Epoch: 270, Batch number: 56, Loss: 44.65984344482422\n",
      "Epoch: 272, Batch number: 4, Loss: 41.88498306274414\n",
      "Epoch: 273, Batch number: 28, Loss: 39.833900451660156\n",
      "Epoch: 274, Batch number: 52, Loss: 40.453060150146484\n",
      "Epoch: 276, Batch number: 0, Loss: 43.987144470214844\n",
      "Epoch: 277, Batch number: 24, Loss: 32.93613815307617\n",
      "Epoch: 278, Batch number: 48, Loss: 37.68962860107422\n",
      "Epoch: 279, Batch number: 72, Loss: 36.777191162109375\n",
      "Epoch: 281, Batch number: 20, Loss: 35.42655944824219\n",
      "Epoch: 282, Batch number: 44, Loss: 37.87944412231445\n",
      "Epoch: 283, Batch number: 68, Loss: 41.92327880859375\n",
      "Epoch: 285, Batch number: 16, Loss: 40.48067092895508\n",
      "Epoch: 286, Batch number: 40, Loss: 31.247577667236328\n",
      "Epoch: 287, Batch number: 64, Loss: 39.963558197021484\n",
      "Epoch: 289, Batch number: 12, Loss: 32.866790771484375\n",
      "Epoch: 290, Batch number: 36, Loss: 33.146820068359375\n",
      "Epoch: 291, Batch number: 60, Loss: 31.016145706176758\n",
      "Epoch: 293, Batch number: 8, Loss: 28.05083465576172\n",
      "Epoch: 294, Batch number: 32, Loss: 35.988826751708984\n",
      "Epoch: 295, Batch number: 56, Loss: 32.72808837890625\n",
      "Epoch: 297, Batch number: 4, Loss: 32.23881530761719\n",
      "Epoch: 298, Batch number: 28, Loss: 31.679651260375977\n",
      "Epoch: 299, Batch number: 52, Loss: 31.564945220947266\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4402.7177734375\n",
      "Epoch: 2, Batch number: 24, Loss: 3978.91162109375\n",
      "Epoch: 3, Batch number: 48, Loss: 3314.678955078125\n",
      "Epoch: 4, Batch number: 72, Loss: 3068.159423828125\n",
      "Epoch: 6, Batch number: 20, Loss: 3029.66796875\n",
      "Epoch: 7, Batch number: 44, Loss: 2934.8271484375\n",
      "Epoch: 8, Batch number: 68, Loss: 2783.99462890625\n",
      "Epoch: 10, Batch number: 16, Loss: 2892.693115234375\n",
      "Epoch: 11, Batch number: 40, Loss: 2673.737548828125\n",
      "Epoch: 12, Batch number: 64, Loss: 2710.2470703125\n",
      "Epoch: 14, Batch number: 12, Loss: 2680.2373046875\n",
      "Epoch: 15, Batch number: 36, Loss: 2626.931884765625\n",
      "Epoch: 16, Batch number: 60, Loss: 2475.711181640625\n",
      "Epoch: 18, Batch number: 8, Loss: 2380.988525390625\n",
      "Epoch: 19, Batch number: 32, Loss: 2338.478515625\n",
      "Epoch: 20, Batch number: 56, Loss: 2334.10595703125\n",
      "Epoch: 22, Batch number: 4, Loss: 2194.3994140625\n",
      "Epoch: 23, Batch number: 28, Loss: 2179.818603515625\n",
      "Epoch: 24, Batch number: 52, Loss: 2138.01025390625\n",
      "Epoch: 26, Batch number: 0, Loss: 2034.842041015625\n",
      "Epoch: 27, Batch number: 24, Loss: 2059.46142578125\n",
      "Epoch: 28, Batch number: 48, Loss: 2066.507568359375\n",
      "Epoch: 29, Batch number: 72, Loss: 1922.6383056640625\n",
      "Epoch: 31, Batch number: 20, Loss: 1911.275146484375\n",
      "Epoch: 32, Batch number: 44, Loss: 1774.1328125\n",
      "Epoch: 33, Batch number: 68, Loss: 1827.3201904296875\n",
      "Epoch: 35, Batch number: 16, Loss: 1746.18798828125\n",
      "Epoch: 36, Batch number: 40, Loss: 1736.384033203125\n",
      "Epoch: 37, Batch number: 64, Loss: 1662.88232421875\n",
      "Epoch: 39, Batch number: 12, Loss: 1732.9837646484375\n",
      "Epoch: 40, Batch number: 36, Loss: 1659.5740966796875\n",
      "Epoch: 41, Batch number: 60, Loss: 1631.32958984375\n",
      "Epoch: 43, Batch number: 8, Loss: 1510.86669921875\n",
      "Epoch: 44, Batch number: 32, Loss: 1517.65478515625\n",
      "Epoch: 45, Batch number: 56, Loss: 1469.90380859375\n",
      "Epoch: 47, Batch number: 4, Loss: 1394.198974609375\n",
      "Epoch: 48, Batch number: 28, Loss: 1392.3172607421875\n",
      "Epoch: 49, Batch number: 52, Loss: 1341.54833984375\n",
      "Epoch: 51, Batch number: 0, Loss: 1298.3916015625\n",
      "Epoch: 52, Batch number: 24, Loss: 1295.92724609375\n",
      "Epoch: 53, Batch number: 48, Loss: 1291.712890625\n",
      "Epoch: 54, Batch number: 72, Loss: 1249.9376220703125\n",
      "Epoch: 56, Batch number: 20, Loss: 1173.9945068359375\n",
      "Epoch: 57, Batch number: 44, Loss: 1213.168701171875\n",
      "Epoch: 58, Batch number: 68, Loss: 1143.700439453125\n",
      "Epoch: 60, Batch number: 16, Loss: 1178.8153076171875\n",
      "Epoch: 61, Batch number: 40, Loss: 1153.463623046875\n",
      "Epoch: 62, Batch number: 64, Loss: 1126.764892578125\n",
      "Epoch: 64, Batch number: 12, Loss: 1044.669677734375\n",
      "Epoch: 65, Batch number: 36, Loss: 1034.813720703125\n",
      "Epoch: 66, Batch number: 60, Loss: 1074.84326171875\n",
      "Epoch: 68, Batch number: 8, Loss: 1001.2728271484375\n",
      "Epoch: 69, Batch number: 32, Loss: 1005.0216064453125\n",
      "Epoch: 70, Batch number: 56, Loss: 970.0064697265625\n",
      "Epoch: 72, Batch number: 4, Loss: 937.201171875\n",
      "Epoch: 73, Batch number: 28, Loss: 898.09228515625\n",
      "Epoch: 74, Batch number: 52, Loss: 958.8900756835938\n",
      "Epoch: 76, Batch number: 0, Loss: 863.4769897460938\n",
      "Epoch: 77, Batch number: 24, Loss: 852.1497192382812\n",
      "Epoch: 78, Batch number: 48, Loss: 825.3980102539062\n",
      "Epoch: 79, Batch number: 72, Loss: 896.907958984375\n",
      "Epoch: 81, Batch number: 20, Loss: 801.7086181640625\n",
      "Epoch: 82, Batch number: 44, Loss: 836.4046630859375\n",
      "Epoch: 83, Batch number: 68, Loss: 754.310791015625\n",
      "Epoch: 85, Batch number: 16, Loss: 776.625\n",
      "Epoch: 86, Batch number: 40, Loss: 719.3587646484375\n",
      "Epoch: 87, Batch number: 64, Loss: 744.8129272460938\n",
      "Epoch: 89, Batch number: 12, Loss: 671.8462524414062\n",
      "Epoch: 90, Batch number: 36, Loss: 702.3828735351562\n",
      "Epoch: 91, Batch number: 60, Loss: 733.7210083007812\n",
      "Epoch: 93, Batch number: 8, Loss: 657.6976318359375\n",
      "Epoch: 94, Batch number: 32, Loss: 646.6866455078125\n",
      "Epoch: 95, Batch number: 56, Loss: 622.9121704101562\n",
      "Epoch: 97, Batch number: 4, Loss: 597.0036010742188\n",
      "Epoch: 98, Batch number: 28, Loss: 588.8297729492188\n",
      "Epoch: 99, Batch number: 52, Loss: 559.7313232421875\n",
      "Epoch: 101, Batch number: 0, Loss: 540.6030883789062\n",
      "Epoch: 102, Batch number: 24, Loss: 469.38922119140625\n",
      "Epoch: 103, Batch number: 48, Loss: 547.1439819335938\n",
      "Epoch: 104, Batch number: 72, Loss: 493.93768310546875\n",
      "Epoch: 106, Batch number: 20, Loss: 479.39581298828125\n",
      "Epoch: 107, Batch number: 44, Loss: 467.2463684082031\n",
      "Epoch: 108, Batch number: 68, Loss: 503.582763671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 16, Loss: 457.7034912109375\n",
      "Epoch: 111, Batch number: 40, Loss: 487.6540832519531\n",
      "Epoch: 112, Batch number: 64, Loss: 439.6458435058594\n",
      "Epoch: 114, Batch number: 12, Loss: 441.8656005859375\n",
      "Epoch: 115, Batch number: 36, Loss: 416.404296875\n",
      "Epoch: 116, Batch number: 60, Loss: 397.41607666015625\n",
      "Epoch: 118, Batch number: 8, Loss: 369.234619140625\n",
      "Epoch: 119, Batch number: 32, Loss: 378.0069580078125\n",
      "Epoch: 120, Batch number: 56, Loss: 368.1929016113281\n",
      "Epoch: 122, Batch number: 4, Loss: 331.2730712890625\n",
      "Epoch: 123, Batch number: 28, Loss: 332.2565612792969\n",
      "Epoch: 124, Batch number: 52, Loss: 351.5487060546875\n",
      "Epoch: 126, Batch number: 0, Loss: 323.7417297363281\n",
      "Epoch: 127, Batch number: 24, Loss: 343.40960693359375\n",
      "Epoch: 128, Batch number: 48, Loss: 318.115966796875\n",
      "Epoch: 129, Batch number: 72, Loss: 301.1445007324219\n",
      "Epoch: 131, Batch number: 20, Loss: 296.3942565917969\n",
      "Epoch: 132, Batch number: 44, Loss: 268.8673400878906\n",
      "Epoch: 133, Batch number: 68, Loss: 285.99365234375\n",
      "Epoch: 135, Batch number: 16, Loss: 267.4991455078125\n",
      "Epoch: 136, Batch number: 40, Loss: 263.7497863769531\n",
      "Epoch: 137, Batch number: 64, Loss: 256.16851806640625\n",
      "Epoch: 139, Batch number: 12, Loss: 233.91729736328125\n",
      "Epoch: 140, Batch number: 36, Loss: 214.69898986816406\n",
      "Epoch: 141, Batch number: 60, Loss: 220.31362915039062\n",
      "Epoch: 143, Batch number: 8, Loss: 210.91448974609375\n",
      "Epoch: 144, Batch number: 32, Loss: 201.44931030273438\n",
      "Epoch: 145, Batch number: 56, Loss: 197.3331298828125\n",
      "Epoch: 147, Batch number: 4, Loss: 194.41323852539062\n",
      "Epoch: 148, Batch number: 28, Loss: 177.1276397705078\n",
      "Epoch: 149, Batch number: 52, Loss: 184.57955932617188\n",
      "Epoch: 151, Batch number: 0, Loss: 187.22547912597656\n",
      "Epoch: 152, Batch number: 24, Loss: 189.89706420898438\n",
      "Epoch: 153, Batch number: 48, Loss: 176.6610870361328\n",
      "Epoch: 154, Batch number: 72, Loss: 185.2446746826172\n",
      "Epoch: 156, Batch number: 20, Loss: 151.8656463623047\n",
      "Epoch: 157, Batch number: 44, Loss: 153.98423767089844\n",
      "Epoch: 158, Batch number: 68, Loss: 156.589599609375\n",
      "Epoch: 160, Batch number: 16, Loss: 143.3907012939453\n",
      "Epoch: 161, Batch number: 40, Loss: 135.97210693359375\n",
      "Epoch: 162, Batch number: 64, Loss: 132.50331115722656\n",
      "Epoch: 164, Batch number: 12, Loss: 130.6388397216797\n",
      "Epoch: 165, Batch number: 36, Loss: 134.5115509033203\n",
      "Epoch: 166, Batch number: 60, Loss: 142.37884521484375\n",
      "Epoch: 168, Batch number: 8, Loss: 113.61557006835938\n",
      "Epoch: 169, Batch number: 32, Loss: 103.97883605957031\n",
      "Epoch: 170, Batch number: 56, Loss: 115.75679016113281\n",
      "Epoch: 172, Batch number: 4, Loss: 103.79632568359375\n",
      "Epoch: 173, Batch number: 28, Loss: 111.36965942382812\n",
      "Epoch: 174, Batch number: 52, Loss: 107.99027252197266\n",
      "Epoch: 176, Batch number: 0, Loss: 96.6148681640625\n",
      "Epoch: 177, Batch number: 24, Loss: 98.65571594238281\n",
      "Epoch: 178, Batch number: 48, Loss: 89.25365447998047\n",
      "Epoch: 179, Batch number: 72, Loss: 96.0544204711914\n",
      "Epoch: 181, Batch number: 20, Loss: 82.0898208618164\n",
      "Epoch: 182, Batch number: 44, Loss: 80.46471405029297\n",
      "Epoch: 183, Batch number: 68, Loss: 88.94772338867188\n",
      "Epoch: 185, Batch number: 16, Loss: 82.78437805175781\n",
      "Epoch: 186, Batch number: 40, Loss: 85.28712463378906\n",
      "Epoch: 187, Batch number: 64, Loss: 81.05125427246094\n",
      "Epoch: 189, Batch number: 12, Loss: 70.61944580078125\n",
      "Epoch: 190, Batch number: 36, Loss: 80.41162109375\n",
      "Epoch: 191, Batch number: 60, Loss: 69.28074645996094\n",
      "Epoch: 193, Batch number: 8, Loss: 63.06736755371094\n",
      "Epoch: 194, Batch number: 32, Loss: 64.0038833618164\n",
      "Epoch: 195, Batch number: 56, Loss: 70.26044464111328\n",
      "Epoch: 197, Batch number: 4, Loss: 60.697509765625\n",
      "Epoch: 198, Batch number: 28, Loss: 62.71263885498047\n",
      "Epoch: 199, Batch number: 52, Loss: 73.23310852050781\n",
      "Epoch: 201, Batch number: 0, Loss: 65.1536636352539\n",
      "Epoch: 202, Batch number: 24, Loss: 56.34002685546875\n",
      "Epoch: 203, Batch number: 48, Loss: 66.81634521484375\n",
      "Epoch: 204, Batch number: 72, Loss: 54.546630859375\n",
      "Epoch: 206, Batch number: 20, Loss: 53.72564697265625\n",
      "Epoch: 207, Batch number: 44, Loss: 56.88843536376953\n",
      "Epoch: 208, Batch number: 68, Loss: 60.483760833740234\n",
      "Epoch: 210, Batch number: 16, Loss: 53.02848815917969\n",
      "Epoch: 211, Batch number: 40, Loss: 53.413902282714844\n",
      "Epoch: 212, Batch number: 64, Loss: 48.11872863769531\n",
      "Epoch: 214, Batch number: 12, Loss: 37.38133239746094\n",
      "Epoch: 215, Batch number: 36, Loss: 46.13569641113281\n",
      "Epoch: 216, Batch number: 60, Loss: 45.68103790283203\n",
      "Epoch: 218, Batch number: 8, Loss: 41.53474044799805\n",
      "Epoch: 219, Batch number: 32, Loss: 43.414546966552734\n",
      "Epoch: 220, Batch number: 56, Loss: 45.688621520996094\n",
      "Epoch: 222, Batch number: 4, Loss: 44.02925491333008\n",
      "Epoch: 223, Batch number: 28, Loss: 39.6439208984375\n",
      "Epoch: 224, Batch number: 52, Loss: 46.96031951904297\n",
      "Epoch: 226, Batch number: 0, Loss: 30.54656982421875\n",
      "Epoch: 227, Batch number: 24, Loss: 34.19388198852539\n",
      "Epoch: 228, Batch number: 48, Loss: 37.208412170410156\n",
      "Epoch: 229, Batch number: 72, Loss: 46.697208404541016\n",
      "Epoch: 231, Batch number: 20, Loss: 30.326297760009766\n",
      "Epoch: 232, Batch number: 44, Loss: 37.409236907958984\n",
      "Epoch: 233, Batch number: 68, Loss: 42.12123107910156\n",
      "Epoch: 235, Batch number: 16, Loss: 33.36583709716797\n",
      "Epoch: 236, Batch number: 40, Loss: 36.527626037597656\n",
      "Epoch: 237, Batch number: 64, Loss: 38.26191711425781\n",
      "Epoch: 239, Batch number: 12, Loss: 36.72528839111328\n",
      "Epoch: 240, Batch number: 36, Loss: 39.07792282104492\n",
      "Epoch: 241, Batch number: 60, Loss: 39.25632095336914\n",
      "Epoch: 243, Batch number: 8, Loss: 27.260967254638672\n",
      "Epoch: 244, Batch number: 32, Loss: 36.879661560058594\n",
      "Epoch: 245, Batch number: 56, Loss: 33.89458084106445\n",
      "Epoch: 247, Batch number: 4, Loss: 24.836353302001953\n",
      "Epoch: 248, Batch number: 28, Loss: 26.058216094970703\n",
      "Epoch: 249, Batch number: 52, Loss: 27.61545181274414\n",
      "Epoch: 251, Batch number: 0, Loss: 33.41700744628906\n",
      "Epoch: 252, Batch number: 24, Loss: 22.098979949951172\n",
      "Epoch: 253, Batch number: 48, Loss: 27.71658706665039\n",
      "Epoch: 254, Batch number: 72, Loss: 28.066234588623047\n",
      "Epoch: 256, Batch number: 20, Loss: 28.53575897216797\n",
      "Epoch: 257, Batch number: 44, Loss: 23.69947052001953\n",
      "Epoch: 258, Batch number: 68, Loss: 27.675703048706055\n",
      "Epoch: 260, Batch number: 16, Loss: 26.720443725585938\n",
      "Epoch: 261, Batch number: 40, Loss: 25.446990966796875\n",
      "Epoch: 262, Batch number: 64, Loss: 25.574867248535156\n",
      "Epoch: 264, Batch number: 12, Loss: 33.01536560058594\n",
      "Epoch: 265, Batch number: 36, Loss: 28.923484802246094\n",
      "Epoch: 266, Batch number: 60, Loss: 27.351154327392578\n",
      "Epoch: 268, Batch number: 8, Loss: 31.111894607543945\n",
      "Epoch: 269, Batch number: 32, Loss: 28.416366577148438\n",
      "Epoch: 270, Batch number: 56, Loss: 29.45863151550293\n",
      "Epoch: 272, Batch number: 4, Loss: 22.479812622070312\n",
      "Epoch: 273, Batch number: 28, Loss: 31.165136337280273\n",
      "Epoch: 274, Batch number: 52, Loss: 35.5291748046875\n",
      "Epoch: 276, Batch number: 0, Loss: 24.685405731201172\n",
      "Epoch: 277, Batch number: 24, Loss: 21.908161163330078\n",
      "Epoch: 278, Batch number: 48, Loss: 27.381057739257812\n",
      "Epoch: 279, Batch number: 72, Loss: 24.305395126342773\n",
      "Epoch: 281, Batch number: 20, Loss: 22.457067489624023\n",
      "Epoch: 282, Batch number: 44, Loss: 28.313663482666016\n",
      "Epoch: 283, Batch number: 68, Loss: 21.63692283630371\n",
      "Epoch: 285, Batch number: 16, Loss: 22.51813507080078\n",
      "Epoch: 286, Batch number: 40, Loss: 29.129657745361328\n",
      "Epoch: 287, Batch number: 64, Loss: 27.903499603271484\n",
      "Epoch: 289, Batch number: 12, Loss: 24.06861114501953\n",
      "Epoch: 290, Batch number: 36, Loss: 23.88198471069336\n",
      "Epoch: 291, Batch number: 60, Loss: 31.411670684814453\n",
      "Epoch: 293, Batch number: 8, Loss: 36.109886169433594\n",
      "Epoch: 294, Batch number: 32, Loss: 23.89912223815918\n",
      "Epoch: 295, Batch number: 56, Loss: 22.185937881469727\n",
      "Epoch: 297, Batch number: 4, Loss: 21.438812255859375\n",
      "Epoch: 298, Batch number: 28, Loss: 30.85689926147461\n",
      "Epoch: 299, Batch number: 52, Loss: 28.146652221679688\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4399.66259765625\n",
      "Epoch: 2, Batch number: 24, Loss: 3794.953369140625\n",
      "Epoch: 3, Batch number: 48, Loss: 3058.699462890625\n",
      "Epoch: 4, Batch number: 72, Loss: 2953.6123046875\n",
      "Epoch: 6, Batch number: 20, Loss: 2976.111083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Batch number: 44, Loss: 2902.07080078125\n",
      "Epoch: 8, Batch number: 68, Loss: 2652.5478515625\n",
      "Epoch: 10, Batch number: 16, Loss: 2591.64111328125\n",
      "Epoch: 11, Batch number: 40, Loss: 2576.38623046875\n",
      "Epoch: 12, Batch number: 64, Loss: 2438.243896484375\n",
      "Epoch: 14, Batch number: 12, Loss: 2363.208984375\n",
      "Epoch: 15, Batch number: 36, Loss: 2278.858642578125\n",
      "Epoch: 16, Batch number: 60, Loss: 2236.2666015625\n",
      "Epoch: 18, Batch number: 8, Loss: 2272.226806640625\n",
      "Epoch: 19, Batch number: 32, Loss: 2119.14306640625\n",
      "Epoch: 20, Batch number: 56, Loss: 1992.90234375\n",
      "Epoch: 22, Batch number: 4, Loss: 1960.0255126953125\n",
      "Epoch: 23, Batch number: 28, Loss: 1861.860595703125\n",
      "Epoch: 24, Batch number: 52, Loss: 1747.2200927734375\n",
      "Epoch: 26, Batch number: 0, Loss: 1737.92138671875\n",
      "Epoch: 27, Batch number: 24, Loss: 1745.281982421875\n",
      "Epoch: 28, Batch number: 48, Loss: 1611.415771484375\n",
      "Epoch: 29, Batch number: 72, Loss: 1568.45703125\n",
      "Epoch: 31, Batch number: 20, Loss: 1499.087890625\n",
      "Epoch: 32, Batch number: 44, Loss: 1548.4423828125\n",
      "Epoch: 33, Batch number: 68, Loss: 1565.283447265625\n",
      "Epoch: 35, Batch number: 16, Loss: 1381.9638671875\n",
      "Epoch: 36, Batch number: 40, Loss: 1271.7000732421875\n",
      "Epoch: 37, Batch number: 64, Loss: 1360.77197265625\n",
      "Epoch: 39, Batch number: 12, Loss: 1224.054931640625\n",
      "Epoch: 40, Batch number: 36, Loss: 1316.76904296875\n",
      "Epoch: 41, Batch number: 60, Loss: 1322.3104248046875\n",
      "Epoch: 43, Batch number: 8, Loss: 1122.15576171875\n",
      "Epoch: 44, Batch number: 32, Loss: 1114.9205322265625\n",
      "Epoch: 45, Batch number: 56, Loss: 1088.1519775390625\n",
      "Epoch: 47, Batch number: 4, Loss: 1062.077392578125\n",
      "Epoch: 48, Batch number: 28, Loss: 1005.8015747070312\n",
      "Epoch: 49, Batch number: 52, Loss: 1056.5360107421875\n",
      "Epoch: 51, Batch number: 0, Loss: 901.478759765625\n",
      "Epoch: 52, Batch number: 24, Loss: 919.1492309570312\n",
      "Epoch: 53, Batch number: 48, Loss: 988.6404418945312\n",
      "Epoch: 54, Batch number: 72, Loss: 954.6510620117188\n",
      "Epoch: 56, Batch number: 20, Loss: 855.15869140625\n",
      "Epoch: 57, Batch number: 44, Loss: 865.3180541992188\n",
      "Epoch: 58, Batch number: 68, Loss: 901.7042846679688\n",
      "Epoch: 60, Batch number: 16, Loss: 805.0244140625\n",
      "Epoch: 61, Batch number: 40, Loss: 756.8860473632812\n",
      "Epoch: 62, Batch number: 64, Loss: 756.5465087890625\n",
      "Epoch: 64, Batch number: 12, Loss: 714.6356811523438\n",
      "Epoch: 65, Batch number: 36, Loss: 682.3441772460938\n",
      "Epoch: 66, Batch number: 60, Loss: 657.809814453125\n",
      "Epoch: 68, Batch number: 8, Loss: 652.4766235351562\n",
      "Epoch: 69, Batch number: 32, Loss: 667.7857666015625\n",
      "Epoch: 70, Batch number: 56, Loss: 610.2555541992188\n",
      "Epoch: 72, Batch number: 4, Loss: 622.690185546875\n",
      "Epoch: 73, Batch number: 28, Loss: 565.0840454101562\n",
      "Epoch: 74, Batch number: 52, Loss: 539.453369140625\n",
      "Epoch: 76, Batch number: 0, Loss: 516.323974609375\n",
      "Epoch: 77, Batch number: 24, Loss: 489.68255615234375\n",
      "Epoch: 78, Batch number: 48, Loss: 487.0647888183594\n",
      "Epoch: 79, Batch number: 72, Loss: 492.37091064453125\n",
      "Epoch: 81, Batch number: 20, Loss: 467.5906066894531\n",
      "Epoch: 82, Batch number: 44, Loss: 460.8502502441406\n",
      "Epoch: 83, Batch number: 68, Loss: 430.4361877441406\n",
      "Epoch: 85, Batch number: 16, Loss: 385.5162353515625\n",
      "Epoch: 86, Batch number: 40, Loss: 410.5471496582031\n",
      "Epoch: 87, Batch number: 64, Loss: 366.0414123535156\n",
      "Epoch: 89, Batch number: 12, Loss: 345.23095703125\n",
      "Epoch: 90, Batch number: 36, Loss: 312.9414367675781\n",
      "Epoch: 91, Batch number: 60, Loss: 345.73394775390625\n",
      "Epoch: 93, Batch number: 8, Loss: 326.9710693359375\n",
      "Epoch: 94, Batch number: 32, Loss: 315.2699279785156\n",
      "Epoch: 95, Batch number: 56, Loss: 305.8026428222656\n",
      "Epoch: 97, Batch number: 4, Loss: 300.4295349121094\n",
      "Epoch: 98, Batch number: 28, Loss: 281.327880859375\n",
      "Epoch: 99, Batch number: 52, Loss: 276.611328125\n",
      "Epoch: 101, Batch number: 0, Loss: 256.72808837890625\n",
      "Epoch: 102, Batch number: 24, Loss: 237.366455078125\n",
      "Epoch: 103, Batch number: 48, Loss: 248.40090942382812\n",
      "Epoch: 104, Batch number: 72, Loss: 233.09616088867188\n",
      "Epoch: 106, Batch number: 20, Loss: 220.36062622070312\n",
      "Epoch: 107, Batch number: 44, Loss: 225.87826538085938\n",
      "Epoch: 108, Batch number: 68, Loss: 214.89561462402344\n",
      "Epoch: 110, Batch number: 16, Loss: 185.04156494140625\n",
      "Epoch: 111, Batch number: 40, Loss: 187.70094299316406\n",
      "Epoch: 112, Batch number: 64, Loss: 193.37750244140625\n",
      "Epoch: 114, Batch number: 12, Loss: 177.90585327148438\n",
      "Epoch: 115, Batch number: 36, Loss: 168.62123107910156\n",
      "Epoch: 116, Batch number: 60, Loss: 167.45228576660156\n",
      "Epoch: 118, Batch number: 8, Loss: 150.69815063476562\n",
      "Epoch: 119, Batch number: 32, Loss: 145.1451873779297\n",
      "Epoch: 120, Batch number: 56, Loss: 136.99925231933594\n",
      "Epoch: 122, Batch number: 4, Loss: 128.28553771972656\n",
      "Epoch: 123, Batch number: 28, Loss: 121.91871643066406\n",
      "Epoch: 124, Batch number: 52, Loss: 118.77449798583984\n",
      "Epoch: 126, Batch number: 0, Loss: 109.971435546875\n",
      "Epoch: 127, Batch number: 24, Loss: 107.81002044677734\n",
      "Epoch: 128, Batch number: 48, Loss: 111.97193908691406\n",
      "Epoch: 129, Batch number: 72, Loss: 102.42420959472656\n",
      "Epoch: 131, Batch number: 20, Loss: 100.70831298828125\n",
      "Epoch: 132, Batch number: 44, Loss: 92.83345031738281\n",
      "Epoch: 133, Batch number: 68, Loss: 94.00125885009766\n",
      "Epoch: 135, Batch number: 16, Loss: 105.31361389160156\n",
      "Epoch: 136, Batch number: 40, Loss: 97.9080581665039\n",
      "Epoch: 137, Batch number: 64, Loss: 86.50686645507812\n",
      "Epoch: 139, Batch number: 12, Loss: 79.13014221191406\n",
      "Epoch: 140, Batch number: 36, Loss: 84.50349426269531\n",
      "Epoch: 141, Batch number: 60, Loss: 86.82305145263672\n",
      "Epoch: 143, Batch number: 8, Loss: 69.22196197509766\n",
      "Epoch: 144, Batch number: 32, Loss: 71.20648193359375\n",
      "Epoch: 145, Batch number: 56, Loss: 82.91265869140625\n",
      "Epoch: 147, Batch number: 4, Loss: 67.35914611816406\n",
      "Epoch: 148, Batch number: 28, Loss: 55.35193634033203\n",
      "Epoch: 149, Batch number: 52, Loss: 68.5744400024414\n",
      "Epoch: 151, Batch number: 0, Loss: 70.79552459716797\n",
      "Epoch: 152, Batch number: 24, Loss: 67.92497253417969\n",
      "Epoch: 153, Batch number: 48, Loss: 61.90939712524414\n",
      "Epoch: 154, Batch number: 72, Loss: 68.996826171875\n",
      "Epoch: 156, Batch number: 20, Loss: 54.82889175415039\n",
      "Epoch: 157, Batch number: 44, Loss: 55.30827331542969\n",
      "Epoch: 158, Batch number: 68, Loss: 50.34288024902344\n",
      "Epoch: 160, Batch number: 16, Loss: 46.71142578125\n",
      "Epoch: 161, Batch number: 40, Loss: 50.46961212158203\n",
      "Epoch: 162, Batch number: 64, Loss: 56.96974182128906\n",
      "Epoch: 164, Batch number: 12, Loss: 50.429176330566406\n",
      "Epoch: 165, Batch number: 36, Loss: 47.047874450683594\n",
      "Epoch: 166, Batch number: 60, Loss: 56.46101760864258\n",
      "Epoch: 168, Batch number: 8, Loss: 42.53003692626953\n",
      "Epoch: 169, Batch number: 32, Loss: 49.91886520385742\n",
      "Epoch: 170, Batch number: 56, Loss: 44.307701110839844\n",
      "Epoch: 172, Batch number: 4, Loss: 35.290550231933594\n",
      "Epoch: 173, Batch number: 28, Loss: 43.773414611816406\n",
      "Epoch: 174, Batch number: 52, Loss: 39.56232833862305\n",
      "Epoch: 176, Batch number: 0, Loss: 46.119354248046875\n",
      "Epoch: 177, Batch number: 24, Loss: 35.70560073852539\n",
      "Epoch: 178, Batch number: 48, Loss: 41.35462188720703\n",
      "Epoch: 179, Batch number: 72, Loss: 39.63595962524414\n",
      "Epoch: 181, Batch number: 20, Loss: 31.943174362182617\n",
      "Epoch: 182, Batch number: 44, Loss: 40.445701599121094\n",
      "Epoch: 183, Batch number: 68, Loss: 37.95212173461914\n",
      "Epoch: 185, Batch number: 16, Loss: 30.729610443115234\n",
      "Epoch: 186, Batch number: 40, Loss: 33.10858917236328\n",
      "Epoch: 187, Batch number: 64, Loss: 32.195377349853516\n",
      "Epoch: 189, Batch number: 12, Loss: 36.86003875732422\n",
      "Epoch: 190, Batch number: 36, Loss: 37.687644958496094\n",
      "Epoch: 191, Batch number: 60, Loss: 36.47480010986328\n",
      "Epoch: 193, Batch number: 8, Loss: 31.05664825439453\n",
      "Epoch: 194, Batch number: 32, Loss: 31.194814682006836\n",
      "Epoch: 195, Batch number: 56, Loss: 36.275001525878906\n",
      "Epoch: 197, Batch number: 4, Loss: 26.347957611083984\n",
      "Epoch: 198, Batch number: 28, Loss: 36.181907653808594\n",
      "Epoch: 199, Batch number: 52, Loss: 23.058238983154297\n",
      "Epoch: 201, Batch number: 0, Loss: 29.756683349609375\n",
      "Epoch: 202, Batch number: 24, Loss: 24.12696075439453\n",
      "Epoch: 203, Batch number: 48, Loss: 32.22770690917969\n",
      "Epoch: 204, Batch number: 72, Loss: 30.955291748046875\n",
      "Epoch: 206, Batch number: 20, Loss: 24.125171661376953\n",
      "Epoch: 207, Batch number: 44, Loss: 36.7581787109375\n",
      "Epoch: 208, Batch number: 68, Loss: 30.133678436279297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Batch number: 16, Loss: 27.768062591552734\n",
      "Epoch: 211, Batch number: 40, Loss: 27.00054168701172\n",
      "Epoch: 212, Batch number: 64, Loss: 30.31387710571289\n",
      "Epoch: 214, Batch number: 12, Loss: 34.508270263671875\n",
      "Epoch: 215, Batch number: 36, Loss: 22.51934051513672\n",
      "Epoch: 216, Batch number: 60, Loss: 25.08785057067871\n",
      "Epoch: 218, Batch number: 8, Loss: 23.752273559570312\n",
      "Epoch: 219, Batch number: 32, Loss: 26.291698455810547\n",
      "Epoch: 220, Batch number: 56, Loss: 26.94792938232422\n",
      "Epoch: 222, Batch number: 4, Loss: 26.738311767578125\n",
      "Epoch: 223, Batch number: 28, Loss: 28.753864288330078\n",
      "Epoch: 224, Batch number: 52, Loss: 21.869384765625\n",
      "Epoch: 226, Batch number: 0, Loss: 28.215808868408203\n",
      "Epoch: 227, Batch number: 24, Loss: 22.80215835571289\n",
      "Epoch: 228, Batch number: 48, Loss: 35.134239196777344\n",
      "Epoch: 229, Batch number: 72, Loss: 27.051002502441406\n",
      "Epoch: 231, Batch number: 20, Loss: 28.82382583618164\n",
      "Epoch: 232, Batch number: 44, Loss: 27.369930267333984\n",
      "Epoch: 233, Batch number: 68, Loss: 27.18344497680664\n",
      "Epoch: 235, Batch number: 16, Loss: 23.254676818847656\n",
      "Epoch: 236, Batch number: 40, Loss: 21.910255432128906\n",
      "Epoch: 237, Batch number: 64, Loss: 22.72514533996582\n",
      "Epoch: 239, Batch number: 12, Loss: 31.048778533935547\n",
      "Epoch: 240, Batch number: 36, Loss: 22.376827239990234\n",
      "Epoch: 241, Batch number: 60, Loss: 22.78290557861328\n",
      "Epoch: 243, Batch number: 8, Loss: 23.054821014404297\n",
      "Epoch: 244, Batch number: 32, Loss: 22.087867736816406\n",
      "Epoch: 245, Batch number: 56, Loss: 26.330116271972656\n",
      "Epoch: 247, Batch number: 4, Loss: 21.415355682373047\n",
      "Epoch: 248, Batch number: 28, Loss: 20.77737045288086\n",
      "Epoch: 249, Batch number: 52, Loss: 21.926677703857422\n",
      "Epoch: 251, Batch number: 0, Loss: 24.778331756591797\n",
      "Epoch: 252, Batch number: 24, Loss: 19.847530364990234\n",
      "Epoch: 253, Batch number: 48, Loss: 22.520187377929688\n",
      "Epoch: 254, Batch number: 72, Loss: 29.021270751953125\n",
      "Epoch: 256, Batch number: 20, Loss: 24.818252563476562\n",
      "Epoch: 257, Batch number: 44, Loss: 27.538192749023438\n",
      "Epoch: 258, Batch number: 68, Loss: 25.649883270263672\n",
      "Epoch: 260, Batch number: 16, Loss: 22.805078506469727\n",
      "Epoch: 261, Batch number: 40, Loss: 25.762306213378906\n",
      "Epoch: 262, Batch number: 64, Loss: 23.489912033081055\n",
      "Epoch: 264, Batch number: 12, Loss: 23.297222137451172\n",
      "Epoch: 265, Batch number: 36, Loss: 15.336054801940918\n",
      "Epoch: 266, Batch number: 60, Loss: 23.229610443115234\n",
      "Epoch: 268, Batch number: 8, Loss: 25.07512664794922\n",
      "Epoch: 269, Batch number: 32, Loss: 19.597309112548828\n",
      "Epoch: 270, Batch number: 56, Loss: 27.847434997558594\n",
      "Epoch: 272, Batch number: 4, Loss: 23.65953826904297\n",
      "Epoch: 273, Batch number: 28, Loss: 21.181379318237305\n",
      "Epoch: 274, Batch number: 52, Loss: 14.085277557373047\n",
      "Epoch: 276, Batch number: 0, Loss: 19.840587615966797\n",
      "Epoch: 277, Batch number: 24, Loss: 22.370100021362305\n",
      "Epoch: 278, Batch number: 48, Loss: 20.314254760742188\n",
      "Epoch: 279, Batch number: 72, Loss: 27.85934066772461\n",
      "Epoch: 281, Batch number: 20, Loss: 18.59575080871582\n",
      "Epoch: 282, Batch number: 44, Loss: 21.6298828125\n",
      "Epoch: 283, Batch number: 68, Loss: 23.45907974243164\n",
      "Epoch: 285, Batch number: 16, Loss: 17.519712448120117\n",
      "Epoch: 286, Batch number: 40, Loss: 15.902227401733398\n",
      "Epoch: 287, Batch number: 64, Loss: 15.336487770080566\n",
      "Epoch: 289, Batch number: 12, Loss: 20.023534774780273\n",
      "Epoch: 290, Batch number: 36, Loss: 21.76924705505371\n",
      "Epoch: 291, Batch number: 60, Loss: 20.42938232421875\n",
      "Epoch: 293, Batch number: 8, Loss: 21.12394905090332\n",
      "Epoch: 294, Batch number: 32, Loss: 20.54851531982422\n",
      "Epoch: 295, Batch number: 56, Loss: 25.410245895385742\n",
      "Epoch: 297, Batch number: 4, Loss: 17.798240661621094\n",
      "Epoch: 298, Batch number: 28, Loss: 19.57440948486328\n",
      "Epoch: 299, Batch number: 52, Loss: 20.87964630126953\n",
      "Training finished\n",
      "\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 300\n",
      "Running on device (cuda:0)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4392.19775390625\n",
      "Epoch: 2, Batch number: 24, Loss: 3639.524169921875\n",
      "Epoch: 3, Batch number: 48, Loss: 3098.814208984375\n",
      "Epoch: 4, Batch number: 72, Loss: 3033.70849609375\n",
      "Epoch: 6, Batch number: 20, Loss: 2810.407958984375\n",
      "Epoch: 7, Batch number: 44, Loss: 2622.705810546875\n",
      "Epoch: 8, Batch number: 68, Loss: 2573.082763671875\n",
      "Epoch: 10, Batch number: 16, Loss: 2429.538330078125\n",
      "Epoch: 11, Batch number: 40, Loss: 2401.576904296875\n",
      "Epoch: 12, Batch number: 64, Loss: 2313.329833984375\n",
      "Epoch: 14, Batch number: 12, Loss: 2087.280029296875\n",
      "Epoch: 15, Batch number: 36, Loss: 2110.72314453125\n",
      "Epoch: 16, Batch number: 60, Loss: 2024.113037109375\n",
      "Epoch: 18, Batch number: 8, Loss: 1929.5286865234375\n",
      "Epoch: 19, Batch number: 32, Loss: 1897.3729248046875\n",
      "Epoch: 20, Batch number: 56, Loss: 1734.0025634765625\n",
      "Epoch: 22, Batch number: 4, Loss: 1610.345947265625\n",
      "Epoch: 23, Batch number: 28, Loss: 1651.653076171875\n",
      "Epoch: 24, Batch number: 52, Loss: 1570.19287109375\n",
      "Epoch: 26, Batch number: 0, Loss: 1529.3096923828125\n",
      "Epoch: 27, Batch number: 24, Loss: 1461.7762451171875\n",
      "Epoch: 28, Batch number: 48, Loss: 1385.71630859375\n",
      "Epoch: 29, Batch number: 72, Loss: 1377.3212890625\n",
      "Epoch: 31, Batch number: 20, Loss: 1240.813720703125\n",
      "Epoch: 32, Batch number: 44, Loss: 1253.577392578125\n",
      "Epoch: 33, Batch number: 68, Loss: 1223.9156494140625\n",
      "Epoch: 35, Batch number: 16, Loss: 1201.772216796875\n",
      "Epoch: 36, Batch number: 40, Loss: 1138.335205078125\n",
      "Epoch: 37, Batch number: 64, Loss: 1122.073486328125\n",
      "Epoch: 39, Batch number: 12, Loss: 1105.247314453125\n",
      "Epoch: 40, Batch number: 36, Loss: 1040.060302734375\n",
      "Epoch: 41, Batch number: 60, Loss: 985.0681762695312\n",
      "Epoch: 43, Batch number: 8, Loss: 924.5208129882812\n",
      "Epoch: 44, Batch number: 32, Loss: 968.2276611328125\n",
      "Epoch: 45, Batch number: 56, Loss: 893.8419189453125\n",
      "Epoch: 47, Batch number: 4, Loss: 781.5989379882812\n",
      "Epoch: 48, Batch number: 28, Loss: 812.2687377929688\n",
      "Epoch: 49, Batch number: 52, Loss: 752.0784301757812\n",
      "Epoch: 51, Batch number: 0, Loss: 709.3580932617188\n",
      "Epoch: 52, Batch number: 24, Loss: 689.09375\n",
      "Epoch: 53, Batch number: 48, Loss: 701.3599243164062\n",
      "Epoch: 54, Batch number: 72, Loss: 675.3455200195312\n",
      "Epoch: 56, Batch number: 20, Loss: 658.5362548828125\n",
      "Epoch: 57, Batch number: 44, Loss: 591.0311279296875\n",
      "Epoch: 58, Batch number: 68, Loss: 616.8299560546875\n",
      "Epoch: 60, Batch number: 16, Loss: 505.85418701171875\n",
      "Epoch: 61, Batch number: 40, Loss: 544.6444702148438\n",
      "Epoch: 62, Batch number: 64, Loss: 515.5799560546875\n",
      "Epoch: 64, Batch number: 12, Loss: 466.89117431640625\n",
      "Epoch: 65, Batch number: 36, Loss: 445.97528076171875\n",
      "Epoch: 66, Batch number: 60, Loss: 474.2555236816406\n",
      "Epoch: 68, Batch number: 8, Loss: 441.3249816894531\n",
      "Epoch: 69, Batch number: 32, Loss: 411.9170837402344\n",
      "Epoch: 70, Batch number: 56, Loss: 378.61383056640625\n",
      "Epoch: 72, Batch number: 4, Loss: 394.408203125\n",
      "Epoch: 73, Batch number: 28, Loss: 352.1018981933594\n",
      "Epoch: 74, Batch number: 52, Loss: 355.968017578125\n",
      "Epoch: 76, Batch number: 0, Loss: 339.6360778808594\n",
      "Epoch: 77, Batch number: 24, Loss: 310.8498840332031\n",
      "Epoch: 78, Batch number: 48, Loss: 281.37164306640625\n",
      "Epoch: 79, Batch number: 72, Loss: 308.63433837890625\n",
      "Epoch: 81, Batch number: 20, Loss: 271.1681823730469\n",
      "Epoch: 82, Batch number: 44, Loss: 248.9046173095703\n",
      "Epoch: 83, Batch number: 68, Loss: 260.74749755859375\n",
      "Epoch: 85, Batch number: 16, Loss: 226.61224365234375\n",
      "Epoch: 86, Batch number: 40, Loss: 247.027587890625\n",
      "Epoch: 87, Batch number: 64, Loss: 222.934326171875\n",
      "Epoch: 89, Batch number: 12, Loss: 194.1164093017578\n",
      "Epoch: 90, Batch number: 36, Loss: 207.33956909179688\n",
      "Epoch: 91, Batch number: 60, Loss: 215.32086181640625\n",
      "Epoch: 93, Batch number: 8, Loss: 177.56442260742188\n",
      "Epoch: 94, Batch number: 32, Loss: 171.55099487304688\n",
      "Epoch: 95, Batch number: 56, Loss: 153.3168182373047\n",
      "Epoch: 97, Batch number: 4, Loss: 147.79507446289062\n",
      "Epoch: 98, Batch number: 28, Loss: 144.26853942871094\n",
      "Epoch: 99, Batch number: 52, Loss: 139.4986572265625\n",
      "Epoch: 101, Batch number: 0, Loss: 137.988525390625\n",
      "Epoch: 102, Batch number: 24, Loss: 132.67770385742188\n",
      "Epoch: 103, Batch number: 48, Loss: 129.60882568359375\n",
      "Epoch: 104, Batch number: 72, Loss: 135.5741424560547\n",
      "Epoch: 106, Batch number: 20, Loss: 116.46876525878906\n",
      "Epoch: 107, Batch number: 44, Loss: 115.69182586669922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108, Batch number: 68, Loss: 94.63072967529297\n",
      "Epoch: 110, Batch number: 16, Loss: 102.11012268066406\n",
      "Epoch: 111, Batch number: 40, Loss: 97.2010498046875\n",
      "Epoch: 112, Batch number: 64, Loss: 93.67444610595703\n",
      "Epoch: 114, Batch number: 12, Loss: 89.9190673828125\n",
      "Epoch: 115, Batch number: 36, Loss: 91.89225769042969\n",
      "Epoch: 116, Batch number: 60, Loss: 81.66845703125\n",
      "Epoch: 118, Batch number: 8, Loss: 75.94676208496094\n",
      "Epoch: 119, Batch number: 32, Loss: 83.71641540527344\n",
      "Epoch: 120, Batch number: 56, Loss: 78.09906005859375\n",
      "Epoch: 122, Batch number: 4, Loss: 76.06487274169922\n",
      "Epoch: 123, Batch number: 28, Loss: 68.87153625488281\n",
      "Epoch: 124, Batch number: 52, Loss: 73.29224395751953\n",
      "Epoch: 126, Batch number: 0, Loss: 61.04138946533203\n",
      "Epoch: 127, Batch number: 24, Loss: 65.45100402832031\n",
      "Epoch: 128, Batch number: 48, Loss: 65.0193099975586\n",
      "Epoch: 129, Batch number: 72, Loss: 66.26764678955078\n",
      "Epoch: 131, Batch number: 20, Loss: 52.08840560913086\n",
      "Epoch: 132, Batch number: 44, Loss: 60.640289306640625\n",
      "Epoch: 133, Batch number: 68, Loss: 52.72393798828125\n",
      "Epoch: 135, Batch number: 16, Loss: 56.759422302246094\n",
      "Epoch: 136, Batch number: 40, Loss: 56.0740852355957\n",
      "Epoch: 137, Batch number: 64, Loss: 49.57320785522461\n",
      "Epoch: 139, Batch number: 12, Loss: 44.43208312988281\n",
      "Epoch: 140, Batch number: 36, Loss: 49.03099822998047\n",
      "Epoch: 141, Batch number: 60, Loss: 44.69513702392578\n",
      "Epoch: 143, Batch number: 8, Loss: 57.2335090637207\n",
      "Epoch: 144, Batch number: 32, Loss: 45.9189453125\n",
      "Epoch: 145, Batch number: 56, Loss: 51.36997985839844\n",
      "Epoch: 147, Batch number: 4, Loss: 46.46321105957031\n",
      "Epoch: 148, Batch number: 28, Loss: 40.54264831542969\n",
      "Epoch: 149, Batch number: 52, Loss: 38.308082580566406\n",
      "Epoch: 151, Batch number: 0, Loss: 34.33993911743164\n",
      "Epoch: 152, Batch number: 24, Loss: 43.09364700317383\n",
      "Epoch: 153, Batch number: 48, Loss: 40.578372955322266\n",
      "Epoch: 154, Batch number: 72, Loss: 37.972503662109375\n",
      "Epoch: 156, Batch number: 20, Loss: 39.212974548339844\n",
      "Epoch: 157, Batch number: 44, Loss: 38.573360443115234\n",
      "Epoch: 158, Batch number: 68, Loss: 36.251522064208984\n",
      "Epoch: 160, Batch number: 16, Loss: 29.603466033935547\n",
      "Epoch: 161, Batch number: 40, Loss: 33.94801712036133\n",
      "Epoch: 162, Batch number: 64, Loss: 31.890283584594727\n",
      "Epoch: 164, Batch number: 12, Loss: 37.82868194580078\n",
      "Epoch: 165, Batch number: 36, Loss: 40.010154724121094\n",
      "Epoch: 166, Batch number: 60, Loss: 36.66210174560547\n",
      "Epoch: 168, Batch number: 8, Loss: 27.905384063720703\n",
      "Epoch: 169, Batch number: 32, Loss: 34.271488189697266\n",
      "Epoch: 170, Batch number: 56, Loss: 29.746253967285156\n",
      "Epoch: 172, Batch number: 4, Loss: 32.59606170654297\n",
      "Epoch: 173, Batch number: 28, Loss: 34.75718688964844\n",
      "Epoch: 174, Batch number: 52, Loss: 28.657695770263672\n",
      "Epoch: 176, Batch number: 0, Loss: 29.325443267822266\n",
      "Epoch: 177, Batch number: 24, Loss: 34.839088439941406\n",
      "Epoch: 178, Batch number: 48, Loss: 26.851978302001953\n",
      "Epoch: 179, Batch number: 72, Loss: 35.31669998168945\n",
      "Epoch: 181, Batch number: 20, Loss: 35.97156524658203\n",
      "Epoch: 182, Batch number: 44, Loss: 28.24165153503418\n",
      "Epoch: 183, Batch number: 68, Loss: 23.792415618896484\n",
      "Epoch: 185, Batch number: 16, Loss: 28.50684356689453\n",
      "Epoch: 186, Batch number: 40, Loss: 33.479209899902344\n",
      "Epoch: 187, Batch number: 64, Loss: 27.81085968017578\n",
      "Epoch: 189, Batch number: 12, Loss: 25.897659301757812\n",
      "Epoch: 190, Batch number: 36, Loss: 21.85816192626953\n",
      "Epoch: 191, Batch number: 60, Loss: 30.64554214477539\n",
      "Epoch: 193, Batch number: 8, Loss: 28.645408630371094\n",
      "Epoch: 194, Batch number: 32, Loss: 26.4161376953125\n",
      "Epoch: 195, Batch number: 56, Loss: 31.494277954101562\n",
      "Epoch: 197, Batch number: 4, Loss: 21.14672088623047\n",
      "Epoch: 198, Batch number: 28, Loss: 25.90599822998047\n",
      "Epoch: 199, Batch number: 52, Loss: 25.263700485229492\n",
      "Epoch: 201, Batch number: 0, Loss: 28.028900146484375\n",
      "Epoch: 202, Batch number: 24, Loss: 22.108543395996094\n",
      "Epoch: 203, Batch number: 48, Loss: 22.946630477905273\n",
      "Epoch: 204, Batch number: 72, Loss: 22.454540252685547\n",
      "Epoch: 206, Batch number: 20, Loss: 22.86334228515625\n",
      "Epoch: 207, Batch number: 44, Loss: 29.16681480407715\n",
      "Epoch: 208, Batch number: 68, Loss: 28.577953338623047\n",
      "Epoch: 210, Batch number: 16, Loss: 27.451587677001953\n",
      "Epoch: 211, Batch number: 40, Loss: 19.095130920410156\n",
      "Epoch: 212, Batch number: 64, Loss: 24.318275451660156\n",
      "Epoch: 214, Batch number: 12, Loss: 24.715377807617188\n",
      "Epoch: 215, Batch number: 36, Loss: 21.72665786743164\n",
      "Epoch: 216, Batch number: 60, Loss: 21.19058609008789\n",
      "Epoch: 218, Batch number: 8, Loss: 25.27581787109375\n",
      "Epoch: 219, Batch number: 32, Loss: 22.201648712158203\n",
      "Epoch: 220, Batch number: 56, Loss: 31.028194427490234\n",
      "Epoch: 222, Batch number: 4, Loss: 34.63359451293945\n",
      "Epoch: 223, Batch number: 28, Loss: 20.52779769897461\n",
      "Epoch: 224, Batch number: 52, Loss: 21.50659942626953\n",
      "Epoch: 226, Batch number: 0, Loss: 17.649200439453125\n",
      "Epoch: 227, Batch number: 24, Loss: 21.47153091430664\n",
      "Epoch: 228, Batch number: 48, Loss: 24.902908325195312\n",
      "Epoch: 229, Batch number: 72, Loss: 21.63133430480957\n",
      "Epoch: 231, Batch number: 20, Loss: 16.979591369628906\n",
      "Epoch: 232, Batch number: 44, Loss: 24.130983352661133\n",
      "Epoch: 233, Batch number: 68, Loss: 22.039833068847656\n",
      "Epoch: 235, Batch number: 16, Loss: 17.887069702148438\n",
      "Epoch: 236, Batch number: 40, Loss: 26.676258087158203\n",
      "Epoch: 237, Batch number: 64, Loss: 17.68401527404785\n",
      "Epoch: 239, Batch number: 12, Loss: 15.075201988220215\n",
      "Epoch: 240, Batch number: 36, Loss: 21.483346939086914\n",
      "Epoch: 241, Batch number: 60, Loss: 17.874481201171875\n",
      "Epoch: 243, Batch number: 8, Loss: 22.309720993041992\n",
      "Epoch: 244, Batch number: 32, Loss: 19.712810516357422\n",
      "Epoch: 245, Batch number: 56, Loss: 23.318065643310547\n",
      "Epoch: 247, Batch number: 4, Loss: 23.272411346435547\n",
      "Epoch: 248, Batch number: 28, Loss: 22.00326919555664\n",
      "Epoch: 249, Batch number: 52, Loss: 20.88416862487793\n",
      "Epoch: 251, Batch number: 0, Loss: 18.138973236083984\n",
      "Epoch: 252, Batch number: 24, Loss: 26.463825225830078\n",
      "Epoch: 253, Batch number: 48, Loss: 19.338871002197266\n",
      "Epoch: 254, Batch number: 72, Loss: 21.774137496948242\n",
      "Epoch: 256, Batch number: 20, Loss: 21.40376091003418\n",
      "Epoch: 257, Batch number: 44, Loss: 16.834308624267578\n",
      "Epoch: 258, Batch number: 68, Loss: 18.945396423339844\n",
      "Epoch: 260, Batch number: 16, Loss: 23.25088119506836\n",
      "Epoch: 261, Batch number: 40, Loss: 17.773210525512695\n",
      "Epoch: 262, Batch number: 64, Loss: 26.782791137695312\n",
      "Epoch: 264, Batch number: 12, Loss: 23.328731536865234\n",
      "Epoch: 265, Batch number: 36, Loss: 24.86349105834961\n",
      "Epoch: 266, Batch number: 60, Loss: 20.005001068115234\n",
      "Epoch: 268, Batch number: 8, Loss: 18.230527877807617\n",
      "Epoch: 269, Batch number: 32, Loss: 22.45102310180664\n",
      "Epoch: 270, Batch number: 56, Loss: 21.091896057128906\n",
      "Epoch: 272, Batch number: 4, Loss: 17.666322708129883\n",
      "Epoch: 273, Batch number: 28, Loss: 23.110309600830078\n",
      "Epoch: 274, Batch number: 52, Loss: 24.256576538085938\n",
      "Epoch: 276, Batch number: 0, Loss: 16.57103729248047\n",
      "Epoch: 277, Batch number: 24, Loss: 19.517837524414062\n",
      "Epoch: 278, Batch number: 48, Loss: 18.71733283996582\n",
      "Epoch: 279, Batch number: 72, Loss: 24.019908905029297\n",
      "Epoch: 281, Batch number: 20, Loss: 19.590240478515625\n",
      "Epoch: 282, Batch number: 44, Loss: 18.134201049804688\n",
      "Epoch: 283, Batch number: 68, Loss: 31.231491088867188\n",
      "Epoch: 285, Batch number: 16, Loss: 12.458462715148926\n",
      "Epoch: 286, Batch number: 40, Loss: 18.61627769470215\n",
      "Epoch: 287, Batch number: 64, Loss: 22.649269104003906\n",
      "Epoch: 289, Batch number: 12, Loss: 14.993732452392578\n",
      "Epoch: 290, Batch number: 36, Loss: 21.05617904663086\n",
      "Epoch: 291, Batch number: 60, Loss: 22.567893981933594\n",
      "Epoch: 293, Batch number: 8, Loss: 19.803102493286133\n",
      "Epoch: 294, Batch number: 32, Loss: 19.47055435180664\n",
      "Epoch: 295, Batch number: 56, Loss: 19.207088470458984\n",
      "Epoch: 297, Batch number: 4, Loss: 19.951187133789062\n",
      "Epoch: 298, Batch number: 28, Loss: 25.54021644592285\n",
      "Epoch: 299, Batch number: 52, Loss: 25.517810821533203\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'Adam'\n",
    "epochs = 300\n",
    "sample_loss_every = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "for trainer_list in cbow_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"930\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2a344e3da0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (9., 6.)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for trainer_list in cbow_trainers:\n",
    "    for trainer in trainer_list:\n",
    "        ax.plot(trainer.loss_history['iter'],trainer.loss_history['loss'],\n",
    "                label='ws={}, ed={}'.format(trainer.window_size, trainer.embedding_dim))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cbow_trainers.bin', 'wb') as trainerfiles:\n",
    "    pickle.dump(cbow_trainers, trainerfiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
