{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from TorchDataUtils import *\n",
    "from AGNewsDataset import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title Class Label\n",
       "0  Riti           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Title', 'Class Label'])\n",
    "df = df.append({'Title': 'Riti', 'Class Label': 1}, ignore_index=True)\n",
    "df2 = pd.DataFrame(columns=['Title', 'Class Label'])\n",
    "df2 = df2.append(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de datos en NLP\n",
    "\n",
    "Todo esto está sacado de https://github.com/joosthub/PyTorchNLPBook, que es el github del libro que usan en cs224n. El capítulo 3 tiene un ejemplo \"Classifying Sentiment of Restaurant Reviews\" que es la fuente de toda esta información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciclo de trabajo\n",
    "\n",
    "Para hacer un modelo de NLP, hay que hacer varias cosas:\n",
    "\n",
    "1. Preprocesar el texto, de manera de obtener un .csv con todas las muestras de training y de test.\n",
    "\n",
    "2. Definir un vocabulario. Para eso, se suele hacer un objeto a parte que contenga todos los handlers del vocabulario.\n",
    "\n",
    "3. Definir un Vectorizer, que es un objeto que se usa para convertir las muestras del dataset en vectores que se puedan pasar al modelo.\n",
    "\n",
    "4. Definir un objeto Dataset, que represente a las muestras en su conjunto. \n",
    "\n",
    "5. Definir un Dataloader que  maneje el muestreo aleatorio del dataset, la cantidad de muestras de validación, cargar las muestras a las gpu's y eso.\n",
    "\n",
    "6. Recién en este paso, se puede hacer el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "Cantidad de muestras de entrenamiento: 120000\n",
      "Tamaño de cada muestra: 19\n",
      "Categorías: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
      "\n",
      "Test Dataset:\n",
      "Cantidad de muestras de testeo: 7600\n",
      "Tamaño de cada muestra: 17\n",
      "Categorías: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
      "\n",
      "Tamaño del vocabulario: 73916\n",
      "Se usan las palabras del train y del test\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AGNewsDataset(root='./AG_NEWS/', train=True, use_test_tokens=True)\n",
    "test_dataset = AGNewsDataset(root='./AG_NEWS/', train=False, use_test_tokens=True)\n",
    "\n",
    "print(\"\"\"Train Dataset:\n",
    "Cantidad de muestras de entrenamiento: {}\n",
    "Tamaño de cada muestra: {}\n",
    "Categorías: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\"\"\".format(len(train_dataset), len(train_dataset[0][0])))\n",
    "\n",
    "print(\"\"\"Test Dataset:\n",
    "Cantidad de muestras de testeo: {}\n",
    "Tamaño de cada muestra: {}\n",
    "Categorías: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\"\"\".format(len(test_dataset), len(test_dataset[0][0])))\n",
    "\n",
    "print(\"Tamaño del vocabulario: {}\".format(len(train_dataset.vocabulary)))\n",
    "print(\"Se usan las palabras del train y del test\")\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = generate_data_batches(train_dataset, test_dataset,\n",
    "                                                                         batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, n_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.emb(x).mean(dim=1)\n",
    "    \n",
    "    def loss(self, scores, target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        return lf(scores, target)\n",
    "    \n",
    "vocab_size = len(train_dataset.vocabulary)\n",
    "n_classes = 4\n",
    "model = TextClassifier(vocab_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch number: 0\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 0, Batch number: 100\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 0, Batch number: 200\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 0, Batch number: 300\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 0, Batch number: 400\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 0, Batch number: 500\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 0, Batch number: 600\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 0, Batch number: 700\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 0, Batch number: 800\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 0, Batch number: 900\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 1, Batch number: 81\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 1, Batch number: 181\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 1, Batch number: 281\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 1, Batch number: 381\n",
      "Accuracy on validation dataset: 637/2400 (26.54%)\n",
      "\n",
      "Epoch: 1, Batch number: 481\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 1, Batch number: 581\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 1, Batch number: 681\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 1, Batch number: 781\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 1, Batch number: 881\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 2, Batch number: 62\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 2, Batch number: 162\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 2, Batch number: 262\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 2, Batch number: 362\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 2, Batch number: 462\n",
      "Accuracy on validation dataset: 634/2400 (26.42%)\n",
      "\n",
      "Epoch: 2, Batch number: 562\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 2, Batch number: 662\n",
      "Accuracy on validation dataset: 634/2400 (26.42%)\n",
      "\n",
      "Epoch: 2, Batch number: 762\n",
      "Accuracy on validation dataset: 633/2400 (26.38%)\n",
      "\n",
      "Epoch: 2, Batch number: 862\n",
      "Accuracy on validation dataset: 634/2400 (26.42%)\n",
      "\n",
      "Epoch: 3, Batch number: 43\n",
      "Accuracy on validation dataset: 633/2400 (26.38%)\n",
      "\n",
      "Epoch: 3, Batch number: 143\n",
      "Accuracy on validation dataset: 634/2400 (26.42%)\n",
      "\n",
      "Epoch: 3, Batch number: 243\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 3, Batch number: 343\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 3, Batch number: 443\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 3, Batch number: 543\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 3, Batch number: 643\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 3, Batch number: 743\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 3, Batch number: 843\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 4, Batch number: 24\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 4, Batch number: 124\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 4, Batch number: 224\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 4, Batch number: 324\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 4, Batch number: 424\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 4, Batch number: 524\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 4, Batch number: 624\n",
      "Accuracy on validation dataset: 633/2400 (26.38%)\n",
      "\n",
      "Epoch: 4, Batch number: 724\n",
      "Accuracy on validation dataset: 632/2400 (26.33%)\n",
      "\n",
      "Epoch: 4, Batch number: 824\n",
      "Accuracy on validation dataset: 633/2400 (26.38%)\n",
      "\n",
      "Epoch: 5, Batch number: 5\n",
      "Accuracy on validation dataset: 633/2400 (26.38%)\n",
      "\n",
      "Epoch: 5, Batch number: 105\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 205\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 305\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 405\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 505\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 605\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 705\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 805\n",
      "Accuracy on validation dataset: 635/2400 (26.46%)\n",
      "\n",
      "Epoch: 5, Batch number: 905\n",
      "Accuracy on validation dataset: 636/2400 (26.50%)\n",
      "\n",
      "Epoch: 6, Batch number: 86\n",
      "Accuracy on validation dataset: 633/2400 (26.38%)\n",
      "\n",
      "Epoch: 6, Batch number: 186\n",
      "Accuracy on validation dataset: 633/2400 (26.38%)\n",
      "\n",
      "Epoch: 6, Batch number: 286\n",
      "Accuracy on validation dataset: 631/2400 (26.29%)\n",
      "\n",
      "Epoch: 6, Batch number: 386\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 6, Batch number: 486\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 6, Batch number: 586\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 6, Batch number: 686\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 6, Batch number: 786\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 6, Batch number: 886\n",
      "Accuracy on validation dataset: 629/2400 (26.21%)\n",
      "\n",
      "Epoch: 7, Batch number: 67\n",
      "Accuracy on validation dataset: 629/2400 (26.21%)\n",
      "\n",
      "Epoch: 7, Batch number: 167\n",
      "Accuracy on validation dataset: 629/2400 (26.21%)\n",
      "\n",
      "Epoch: 7, Batch number: 267\n",
      "Accuracy on validation dataset: 629/2400 (26.21%)\n",
      "\n",
      "Epoch: 7, Batch number: 367\n",
      "Accuracy on validation dataset: 629/2400 (26.21%)\n",
      "\n",
      "Epoch: 7, Batch number: 467\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 7, Batch number: 567\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 7, Batch number: 667\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 7, Batch number: 767\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 7, Batch number: 867\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 8, Batch number: 48\n",
      "Accuracy on validation dataset: 629/2400 (26.21%)\n",
      "\n",
      "Epoch: 8, Batch number: 148\n",
      "Accuracy on validation dataset: 628/2400 (26.17%)\n",
      "\n",
      "Epoch: 8, Batch number: 248\n",
      "Accuracy on validation dataset: 628/2400 (26.17%)\n",
      "\n",
      "Epoch: 8, Batch number: 348\n",
      "Accuracy on validation dataset: 627/2400 (26.12%)\n",
      "\n",
      "Epoch: 8, Batch number: 448\n",
      "Accuracy on validation dataset: 627/2400 (26.12%)\n",
      "\n",
      "Epoch: 8, Batch number: 548\n",
      "Accuracy on validation dataset: 627/2400 (26.12%)\n",
      "\n",
      "Epoch: 8, Batch number: 648\n",
      "Accuracy on validation dataset: 627/2400 (26.12%)\n",
      "\n",
      "Epoch: 8, Batch number: 748\n",
      "Accuracy on validation dataset: 627/2400 (26.12%)\n",
      "\n",
      "Epoch: 8, Batch number: 848\n",
      "Accuracy on validation dataset: 626/2400 (26.08%)\n",
      "\n",
      "Epoch: 9, Batch number: 29\n",
      "Accuracy on validation dataset: 626/2400 (26.08%)\n",
      "\n",
      "Epoch: 9, Batch number: 129\n",
      "Accuracy on validation dataset: 626/2400 (26.08%)\n",
      "\n",
      "Epoch: 9, Batch number: 229\n",
      "Accuracy on validation dataset: 627/2400 (26.12%)\n",
      "\n",
      "Epoch: 9, Batch number: 329\n",
      "Accuracy on validation dataset: 628/2400 (26.17%)\n",
      "\n",
      "Epoch: 9, Batch number: 429\n",
      "Accuracy on validation dataset: 629/2400 (26.21%)\n",
      "\n",
      "Epoch: 9, Batch number: 529\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 9, Batch number: 629\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 9, Batch number: 729\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n",
      "Epoch: 9, Batch number: 829\n",
      "Accuracy on validation dataset: 630/2400 (26.25%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de las muestras:\n",
    "data = {\n",
    "    'use_gpu': True, # Trasladar o no las muestras a la GPU\n",
    "    'input_dtype': torch.long, # Tipo de dato de las muestras de entrada\n",
    "    'target_dtype': torch.long, # Tipo de dato de las muestras de salida\n",
    "    'train_dataloader': train_dataloader, # Dataset de entrenamiento\n",
    "    'val_dataloader': val_dataloader # Dataset de validación\n",
    "}\n",
    "\n",
    "# Parámetros de optimización:\n",
    "epochs = 10 # Cantidad de epochs\n",
    "sample_loss_every = 100 # Cantidad de iteraciones para calcular la cantidad de aciertos\n",
    "learning_rate = 1e-4 # Tasa de aprendizaje\n",
    "check_on_train = False # Queremos ver los resultados también en el train set\n",
    "\n",
    "# Entrenamiento:\n",
    "performance_history = SGDTrainModel(model, data, epochs, learning_rate, sample_loss_every, check_on_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
