{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de los datos en NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AG's News Topic Classification Dataset\r\n",
      "\r\n",
      "Version 3, Updated 09/09/2015\r\n",
      "\r\n",
      "\r\n",
      "ORIGIN\r\n",
      "\r\n",
      "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity. For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\r\n",
      "\r\n",
      "The AG's news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above. It is used as a text classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\r\n",
      "\r\n",
      "\r\n",
      "DESCRIPTION\r\n",
      "\r\n",
      "The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.\r\n",
      "\r\n",
      "The file classes.txt contains a list of classes corresponding to each label.\r\n",
      "\r\n",
      "The files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 to 4), title and description. The title and description are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\".\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../AG_NEWS/ag_news_csv/readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"3\",\"Wall St. Bears Claw Back Into the Black (Reuters)\",\"Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\"\n",
      "\"3\",\"Carlyle Looks Toward Commercial Aerospace (Reuters)\",\"Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\"\n",
      "\"3\",\"Oil and Economy Cloud Stocks' Outlook (Reuters)\",\"Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\"\n",
      "\"3\",\"Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)\",\"Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\"\n",
      "\"3\",\"Oil prices soar to all-time record, posing new menace to US economy (AFP)\",\"AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\"\n",
      "\"3\",\"Stocks End Up, But Near Year Lows (Reuters)\",\"Reuters - Stocks ended slightly higher on Friday\\but stayed near lows for the year as oil prices surged past  #36;46\\a barrel, offsetting a positive outlook from computer maker\\Dell Inc. (DELL.O)\"\n",
      "\u001b[K:\u001b[Kney Funds Fell in Latest Week (AP)\",\"AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;84\u001b[7m../AG_NEWS/ag_news_csv/train.csv\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!less ../AG_NEWS/ag_news_csv/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"3\",\"Wall St. Bears Claw Back Into the Black (Reuters)\",\"Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def file_generator(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "\n",
    "file_path = '../AG_NEWS/ag_news_csv/train.csv'\n",
    "my_gen = file_generator(file_path)\n",
    "print(next(my_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'b', 'c', 'd', 'e']\n",
      "{'c', 'd', 'e', 'b', 'a'}\n",
      "{'a': 3, 'b': 2}\n"
     ]
    }
   ],
   "source": [
    "l = ['a', 'a', 'b', 'c', 'd', 'e']\n",
    "s = set(l)\n",
    "print(l)\n",
    "print(s)\n",
    "d = {'a':3, 'b':2}\n",
    "if 'c' not in d:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import csv\n",
    "import re\n",
    "\n",
    "class AGNEWS(Dataset):\n",
    "    \n",
    "    def _get_categories(self):\n",
    "        with open(self.root_path + 'classes.txt', 'r') as f:\n",
    "            categories = [line[:-2] for line in f]\n",
    "        return categories\n",
    "    \n",
    "    \n",
    "    def preprocessing(self, sentence):\n",
    "        \"\"\"\n",
    "        Función para preprocesar los datos\n",
    "        \"\"\"\n",
    "        return sentence.split()\n",
    "    \n",
    "    def _get_size_of_longest_sentence(self):\n",
    "        length = 0\n",
    "        with open(self.data_filename, 'r') as f:\n",
    "            csv_file = csv.reader(f)\n",
    "            for line in csv_file:\n",
    "                class_idx, title, description = line\n",
    "                text_length = len(self.preprocessing(title))\n",
    "                if  text_length > length:\n",
    "                    length = text_length \n",
    "                    \n",
    "        return length\n",
    "                \n",
    "    \n",
    "    def _get_vocab(self):\n",
    "        \"\"\"\n",
    "        Devuelve un diccionario con las palabras del vocabulario\n",
    "        y la cantidad de veces que aparece en el corpus.\n",
    "        \"\"\"\n",
    "        \n",
    "        special_tokens = ['<PAD>', '<UNK>']\n",
    "        vocabulary = {token: i for i, token in enumerate(special_tokens)}\n",
    "        \n",
    "        filenames = [self.root_path + 'train.csv', self.root_path + 'test.csv']\n",
    "        for filename in filenames:\n",
    "            with open(filename, 'r') as f:\n",
    "                csv_file = csv.reader(f)\n",
    "                for i, line in enumerate(csv_file):\n",
    "                    class_idx, title, description = line\n",
    "                    title = self.preprocessing(title)\n",
    "                    for word in title:\n",
    "                        if word in vocabulary:\n",
    "                            vocabulary[word] += 1\n",
    "                        else:\n",
    "                            vocabulary[word] = 1\n",
    "                            \n",
    "        return vocabulary\n",
    "        \n",
    "    \n",
    "    def __init__(self, root_path, train=True):\n",
    "        \n",
    "        # Directorio de raíz de los datos:\n",
    "        self.root_path = root_path \n",
    "        \n",
    "        # Elección de datos (entrenamiento o testeo):\n",
    "        if train:\n",
    "            self.data_filename = root_path + 'train.csv'\n",
    "        else:\n",
    "            self.data_filename = root_path + 'test.csv'\n",
    "        \n",
    "        # Obtención de las categorías:\n",
    "        self.categories = self._get_categories()\n",
    "        \n",
    "        # Obtención del vocabulario:\n",
    "        self.vocabulary = self._get_vocab() # Contiene las frecuencias\n",
    "        self.word_to_index = {word: idx for idx, word in enumerate(self.vocabulary)}\n",
    "        self.index_to_word = {idx: word for idx, word in enumerate(self.vocabulary)}\n",
    "        self.size_of_longest_sentence = self._get_size_of_longest_sentence()\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        with open(self.data_filename, 'r') as f:\n",
    "            csv_file = csv.reader(f)\n",
    "            for i, line in enumerate(csv_file):\n",
    "                pass\n",
    "        return i+1\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        with open(self.data_filename, 'r') as f:\n",
    "            csv_file = csv.reader(f)\n",
    "            for i, line in enumerate(csv_file):\n",
    "                if i == idx:\n",
    "                    class_idx, title, description = line\n",
    "                    title = self.preprocessing(title)\n",
    "                    class_idx = int(class_idx)\n",
    "                    break\n",
    "        \n",
    "        title = torch.tensor([self.word_to_index[word] for word in title], dtype=torch.long)\n",
    "        class_idx = torch.tensor(class_idx, dtype=torch.long)\n",
    "        \n",
    "        title = torch.nn.functional.pad(title,\n",
    "                                        pad=(0,self.size_of_longest_sentence - len(title)),\n",
    "                                        mode='constant', \n",
    "                                        value=self.word_to_index['<PAD>'])\n",
    "        \n",
    "        return title, class_idx\n",
    "            \n",
    "        \n",
    "root_path = '../AG_NEWS/ag_news_csv/'\n",
    "train_dataset = AGNEWS(root_path, train=True)\n",
    "test_dataset = AGNEWS(root_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset:  120000\n",
      "Tamaño del vocabulario:  73957\n",
      "(tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0]), tensor(3))\n"
     ]
    }
   ],
   "source": [
    "print('Tamaño del dataset: ', len(train_dataset))\n",
    "print('Tamaño del vocabulario: ', len(train_dataset.vocabulary))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
