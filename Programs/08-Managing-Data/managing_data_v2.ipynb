{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de datos en NLP\n",
    "\n",
    "Todo esto está sacado de https://github.com/joosthub/PyTorchNLPBook, que es el github del libro que usan en cs224n. El capítulo 3 tiene un ejemplo \"Classifying Sentiment of Restaurant Reviews\" que es la fuente de toda esta información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciclo de trabajo\n",
    "\n",
    "Para hacer un modelo de NLP, hay que hacer varias cosas:\n",
    "\n",
    "1. Preprocesar el texto, de manera de obtener un .csv con todas las muestras de training y de test.\n",
    "\n",
    "2. Definir un vocabulario. Para eso, se suele hacer un objeto con todos los handlers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DatasetFicticio(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.samples = [(text, class_idx) for text, class_idx in zip(torch.randint(0, 120000, (120000,10)), torch.randint(0, 4, (120000,)))]\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.samples[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "train_dataset = DatasetFicticio()\n",
    "test_dataset = DatasetFicticio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_batches(train_dataset, test_dataset, # Train y test datasets\n",
    "                          batch_size = 64, # Tamaño del batch\n",
    "                          val_size = .02): # Proporción de muestras utilizadas para validación \n",
    "    \n",
    "    \"\"\"\n",
    "    Función para iterar sobre los batches de muestras. \n",
    "    Devuelve los dataloaders de train / validation / test.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separo las muestras aleatoriamente en Train y Validation:\n",
    "    NUM_TRAIN = int((1 - val_size) * len(train_dataset)) \n",
    "    samples_idx = torch.randperm(len(train_dataset))\n",
    "    train_samples_idx = samples_idx[:NUM_TRAIN]\n",
    "    val_samples_idx = samples_idx[NUM_TRAIN:]\n",
    "    sampler = lambda indices: torch.utils.data.SubsetRandomSampler(indices) # sampler\n",
    "    \n",
    "    # Dataloader para las muestras de entrenamiento:\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   sampler=sampler(train_samples_idx))\n",
    "\n",
    "    # Dataloader para las muestras de validación:\n",
    "    val_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 sampler=sampler(val_samples_idx))\n",
    "\n",
    "    # Dataloader para las muestras de testeo:\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                                  batch_size=batch_size)\n",
    "    \n",
    "    return train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = generate_data_batches(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Accuracy on validation dataset: 617/2400 \n",
      "Epoch: 0, Iteration: 100, Accuracy on validation dataset: 612/2400 \n",
      "Epoch: 0, Iteration: 200, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 0, Iteration: 300, Accuracy on validation dataset: 582/2400 \n",
      "Epoch: 0, Iteration: 400, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 0, Iteration: 500, Accuracy on validation dataset: 624/2400 \n",
      "Epoch: 0, Iteration: 600, Accuracy on validation dataset: 608/2400 \n",
      "Epoch: 0, Iteration: 700, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 0, Iteration: 800, Accuracy on validation dataset: 578/2400 \n",
      "Epoch: 0, Iteration: 900, Accuracy on validation dataset: 595/2400 \n",
      "Epoch: 0, Iteration: 1000, Accuracy on validation dataset: 603/2400 \n",
      "Epoch: 0, Iteration: 1100, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 0, Iteration: 1200, Accuracy on validation dataset: 554/2400 \n",
      "Epoch: 0, Iteration: 1300, Accuracy on validation dataset: 600/2400 \n",
      "Epoch: 0, Iteration: 1400, Accuracy on validation dataset: 581/2400 \n",
      "Epoch: 0, Iteration: 1500, Accuracy on validation dataset: 582/2400 \n",
      "Epoch: 0, Iteration: 1600, Accuracy on validation dataset: 598/2400 \n",
      "Epoch: 0, Iteration: 1700, Accuracy on validation dataset: 590/2400 \n",
      "Epoch: 0, Iteration: 1800, Accuracy on validation dataset: 610/2400 \n",
      "Epoch: 1, Iteration: 62, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 1, Iteration: 162, Accuracy on validation dataset: 615/2400 \n",
      "Epoch: 1, Iteration: 262, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 1, Iteration: 362, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 1, Iteration: 462, Accuracy on validation dataset: 632/2400 \n",
      "Epoch: 1, Iteration: 562, Accuracy on validation dataset: 590/2400 \n",
      "Epoch: 1, Iteration: 662, Accuracy on validation dataset: 612/2400 \n",
      "Epoch: 1, Iteration: 762, Accuracy on validation dataset: 585/2400 \n",
      "Epoch: 1, Iteration: 862, Accuracy on validation dataset: 616/2400 \n",
      "Epoch: 1, Iteration: 962, Accuracy on validation dataset: 612/2400 \n",
      "Epoch: 1, Iteration: 1062, Accuracy on validation dataset: 617/2400 \n",
      "Epoch: 1, Iteration: 1162, Accuracy on validation dataset: 590/2400 \n",
      "Epoch: 1, Iteration: 1262, Accuracy on validation dataset: 590/2400 \n",
      "Epoch: 1, Iteration: 1362, Accuracy on validation dataset: 582/2400 \n",
      "Epoch: 1, Iteration: 1462, Accuracy on validation dataset: 582/2400 \n",
      "Epoch: 1, Iteration: 1562, Accuracy on validation dataset: 612/2400 \n",
      "Epoch: 1, Iteration: 1662, Accuracy on validation dataset: 580/2400 \n",
      "Epoch: 1, Iteration: 1762, Accuracy on validation dataset: 612/2400 \n",
      "Epoch: 2, Iteration: 24, Accuracy on validation dataset: 602/2400 \n",
      "Epoch: 2, Iteration: 124, Accuracy on validation dataset: 612/2400 \n",
      "Epoch: 2, Iteration: 224, Accuracy on validation dataset: 573/2400 \n",
      "Epoch: 2, Iteration: 324, Accuracy on validation dataset: 587/2400 \n",
      "Epoch: 2, Iteration: 424, Accuracy on validation dataset: 586/2400 \n",
      "Epoch: 2, Iteration: 524, Accuracy on validation dataset: 616/2400 \n",
      "Exiting training...\n",
      "Final accuracy on validation dataset: 25.50%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 5)\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "    def loss(self,scores,target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        return lf(scores,target)\n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "def CheckAccuracy(loader, model, device, input_dtype, target_dtype):  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=input_dtype)  \n",
    "            y = y.to(device=device, dtype=target_dtype)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "        return num_correct, num_samples\n",
    "        \n",
    "\n",
    "def TrainModel(model, data, epochs=1, learning_rate=1e-2, sample_loss_every=100):\n",
    "    \n",
    "    input_dtype = data['input_dtype'] \n",
    "    target_dtype = data['target_dtype']\n",
    "    device = data['device']\n",
    "    train_dataloader = data['train_dataloader']\n",
    "    val_dataloader = data['val_dataloader']\n",
    "    \n",
    "    performance_history = {'iter': [], 'loss': [], 'accuracy': []}\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    batch_size = len(train_dataloader)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        for e in range(epochs):\n",
    "            for t, (x,y) in enumerate(train_dataloader):\n",
    "                model.train()\n",
    "                x = x.to(device=device, dtype=input_dtype)\n",
    "                y = y.to(device=device, dtype=target_dtype)\n",
    "\n",
    "                # Forward pass\n",
    "                scores = model(x) \n",
    "\n",
    "                # Backward pass\n",
    "                loss = model.loss(scores,y)                 \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (e * batch_size + t) % sample_loss_every == 0:\n",
    "                    num_correct, num_samples = CheckAccuracy(val_dataloader, model, device, input_dtype, target_dtype)\n",
    "                    performance_history['iter'].append(t)\n",
    "                    performance_history['loss'].append(loss.item())\n",
    "                    performance_history['accuracy'].append(float(num_correct) / num_samples)\n",
    "                    print('Epoch: %d, Iteration: %d, Accuracy on validation dataset: %d/%d ' % (e, t, num_correct, num_samples))\n",
    "                    \n",
    "    except KeyboardInterrupt:\n",
    "        num_correct, num_samples = CheckAccuracy(val_dataloader, model, device, input_dtype, target_dtype)\n",
    "        print('Exiting training...')\n",
    "        print('Final accuracy on validation dataset: %.2f%%' % (100 * float(num_correct) / num_samples) )\n",
    "    \n",
    "    return performance_history\n",
    "\n",
    "\n",
    "# Especificaciones de cómo adquirir los datos para entrenamiento:\n",
    "use_gpu = True\n",
    "if torch.cuda.is_available() and use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "data = {\n",
    "    'device': device,\n",
    "    'input_dtype': torch.float,\n",
    "    'target_dtype': torch.long,\n",
    "    'train_dataloader': train_dataloader,\n",
    "    'val_dataloader': val_dataloader\n",
    "}\n",
    "\n",
    "# Hiperparámetros del modelo y otros:\n",
    "epochs = 10 # Cantidad de epochs\n",
    "sample_loss_every = 100 # Cantidad de iteraciones para calcular la cantidad de aciertos\n",
    "learning_rate = 1e-1 # Tasa de aprendizaje\n",
    "\n",
    "# Entrenamiento:\n",
    "performance_history = TrainModel(model, data, epochs, learning_rate, sample_loss_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from TorchDataUtils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "class DatasetFicticio(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.samples = [(text, class_idx) for text, class_idx in zip(torch.randint(0, 120000, (120000,10)), torch.randint(0, 4, (120000,)))]\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.samples[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "train_dataset = DatasetFicticio()\n",
    "test_dataset = DatasetFicticio()\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 5)\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "    def loss(self,scores,target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        return lf(scores,target)\n",
    "    \n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch number: 0\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 100\n",
      "Accuracy on validation dataset: 588/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 200\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 300\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 400\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 500\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 600\n",
      "Accuracy on validation dataset: 581/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 700\n",
      "Accuracy on validation dataset: 626/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 800\n",
      "Accuracy on validation dataset: 589/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 900\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1000\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1100\n",
      "Accuracy on validation dataset: 625/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1200\n",
      "Accuracy on validation dataset: 583/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1300\n",
      "Accuracy on validation dataset: 628/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1400\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1500\n",
      "Accuracy on validation dataset: 577/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1600\n",
      "Accuracy on validation dataset: 620/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1700\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 0, Batch number: 1800\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 62\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 162\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 262\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 362\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 462\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 562\n",
      "Accuracy on validation dataset: 629/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 662\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 762\n",
      "Accuracy on validation dataset: 618/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 862\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 962\n",
      "Accuracy on validation dataset: 580/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1062\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1162\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1262\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1362\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1462\n",
      "Accuracy on validation dataset: 607/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1562\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1662\n",
      "Accuracy on validation dataset: 601/2400 \n",
      "\n",
      "Epoch: 1, Batch number: 1762\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 24\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 124\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 224\n",
      "Accuracy on validation dataset: 597/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 324\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 424\n",
      "Accuracy on validation dataset: 586/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 524\n",
      "Accuracy on validation dataset: 636/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 624\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 724\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 824\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 924\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1024\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1124\n",
      "Accuracy on validation dataset: 583/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1224\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1324\n",
      "Accuracy on validation dataset: 629/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1424\n",
      "Accuracy on validation dataset: 586/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1524\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1624\n",
      "Accuracy on validation dataset: 600/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1724\n",
      "Accuracy on validation dataset: 616/2400 \n",
      "\n",
      "Epoch: 2, Batch number: 1824\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 86\n",
      "Accuracy on validation dataset: 604/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 186\n",
      "Accuracy on validation dataset: 611/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 286\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 386\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 486\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 586\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 686\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 786\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 886\n",
      "Accuracy on validation dataset: 568/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 986\n",
      "Accuracy on validation dataset: 590/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1086\n",
      "Accuracy on validation dataset: 609/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1186\n",
      "Accuracy on validation dataset: 586/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1286\n",
      "Accuracy on validation dataset: 613/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1386\n",
      "Accuracy on validation dataset: 618/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1486\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1586\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1686\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 3, Batch number: 1786\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 48\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 148\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 248\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 348\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 448\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 548\n",
      "Accuracy on validation dataset: 572/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 648\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 748\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 848\n",
      "Accuracy on validation dataset: 575/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 948\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 1048\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 1148\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 1248\n",
      "Accuracy on validation dataset: 614/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 1348\n",
      "Accuracy on validation dataset: 597/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 1448\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 1548\n",
      "Accuracy on validation dataset: 627/2400 \n",
      "\n",
      "Epoch: 4, Batch number: 1648\n",
      "Accuracy on validation dataset: 584/2400 \n",
      "\n",
      "Exiting training...\n",
      "Final accuracy on validation dataset: 24.58%\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = generate_data_batches(train_dataset, test_dataset)\n",
    "\n",
    "# Especificaciones de cómo adquirir los datos para entrenamiento:\n",
    "use_gpu = True\n",
    "if torch.cuda.is_available() and use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "data = {\n",
    "    'device': device,\n",
    "    'input_dtype': torch.float,\n",
    "    'target_dtype': torch.long,\n",
    "    'train_dataloader': train_dataloader,\n",
    "    'val_dataloader': val_dataloader\n",
    "}\n",
    "\n",
    "# Hiperparámetros del modelo y otros:\n",
    "epochs = 10 # Cantidad de epochs\n",
    "sample_loss_every = 100 # Cantidad de iteraciones para calcular la cantidad de aciertos\n",
    "learning_rate = 1e-1 # Tasa de aprendizaje\n",
    "\n",
    "# Entrenamiento:\n",
    "performance_history = TrainModel(model, data, epochs, learning_rate, sample_loss_every)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
