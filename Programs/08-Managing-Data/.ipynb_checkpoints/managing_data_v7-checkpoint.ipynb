{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"3\",\"Wall St. Bears Claw Back Into the Black (Reuters)\",\"Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\"\r\n",
      "\"3\",\"Carlyle Looks Toward Commercial Aerospace (Reuters)\",\"Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\"\r\n",
      "\"3\",\"Oil and Economy Cloud Stocks' Outlook (Reuters)\",\"Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\"\r\n",
      "\"3\",\"Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)\",\"Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\"\r\n",
      "\"3\",\"Oil prices soar to all-time record, posing new menace to US economy (AFP)\",\"AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\"\r\n",
      "\"3\",\"Stocks End Up, But Near Year Lows (Reuters)\",\"Reuters - Stocks ended slightly higher on Friday\\but stayed near lows for the year as oil prices surged past  #36;46\\a barrel, offsetting a positive outlook from computer maker\\Dell Inc. (DELL.O)\"\r\n",
      "\"3\",\"Money Funds Fell in Latest Week (AP)\",\"AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\"\r\n",
      "\"3\",\"Fed minutes show dissent over inflation (USATODAY.com)\",\"USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.\"\r\n",
      "\"3\",\"Safety Net (Forbes.com)\",\"Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"\"buying insurance was the furthest thing from my mind,\"\" says Riley.\"\r\n",
      "\"3\",\"Wall St. Bears Claw Back Into the Black\",\" NEW YORK (Reuters) - Short-sellers, Wall Street's dwindling  band of ultra-cynics, are seeing green again.\"\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!head AG_NEWS/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_idx</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2</td>\n",
       "      <td>Renteria signing a top-shelf deal</td>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2</td>\n",
       "      <td>Saban not going to Dolphins yet</td>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2</td>\n",
       "      <td>Today's NFL games</td>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2</td>\n",
       "      <td>Nets get Carter from Raptors</td>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class_idx                                              title  \\\n",
       "0               3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1               3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2               3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3               3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4               3  Oil prices soar to all-time record, posing new...   \n",
       "...           ...                                                ...   \n",
       "119995          1  Pakistan's Musharraf Says Won't Quit as Army C...   \n",
       "119996          2                  Renteria signing a top-shelf deal   \n",
       "119997          2                    Saban not going to Dolphins yet   \n",
       "119998          2                                  Today's NFL games   \n",
       "119999          2                       Nets get Carter from Raptors   \n",
       "\n",
       "                                              description  \n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1       Reuters - Private investment firm Carlyle Grou...  \n",
       "2       Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3       Reuters - Authorities have halted oil export\\f...  \n",
       "4       AFP - Tearaway world oil prices, toppling reco...  \n",
       "...                                                   ...  \n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...  \n",
       "119996  Red Sox general manager Theo Epstein acknowled...  \n",
       "119997  The Miami Dolphins will put their courtship of...  \n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...  \n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...  \n",
       "\n",
       "[120000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('AG_NEWS/train.csv',header=None,names=['class_idx', 'title', 'description'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_idx</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>Japan nuclear firm shuts plants</td>\n",
       "      <td>The company running the Japanese nuclear plant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>Veteran inventor in market float</td>\n",
       "      <td>Trevor Baylis, the veteran inventor famous for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>Saudi Arabia to open up oil taps</td>\n",
       "      <td>Saudi Arabia says it is ready to push an extra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>Saudi phone sector gets \\$1bn lift</td>\n",
       "      <td>A group led by the UAE's Etisalat plans to spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>Indians fill rail skills shortage</td>\n",
       "      <td>Network Rail flies in specialist Indian engine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>Steady as they go</td>\n",
       "      <td>BEDFORD -- Scientists at NitroMed Inc. hope th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>Google IPO: Type in 'confusing,' 'secrecy'</td>\n",
       "      <td>I've submitted my bid to buy shares of Google ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>A bargain hunter's paradise</td>\n",
       "      <td>Massachusetts bargain hunters showed up in dro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>Researchers seek to untangle the e-mail thread</td>\n",
       "      <td>E-mail is a victim of its own success. That's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>Microsoft Corp. 2.0: a kinder corporate culture</td>\n",
       "      <td>Even a genius can mess up. Bill Gates was a br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>Letters</td>\n",
       "      <td>Target the abusers of legal weapons We can all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>Somewhere between gleam and gloom</td>\n",
       "      <td>President Bush has been saying that the US eco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>Technology company sues five ex-employees</td>\n",
       "      <td>A Marlborough-based technology company is suin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>Grant to aid Lynn Central Square</td>\n",
       "      <td>Central Square in Lynn should be looking a bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>State grant to aid Lynn; Bank gives Salem \\$10k</td>\n",
       "      <td>Central Square in Lynn should be looking a bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>A New Legal Chapter for a 90's Flameout</td>\n",
       "      <td>A lawsuit against Gary Winnick, the former chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>Will Russia, the Oil Superpower, Flex Its Musc...</td>\n",
       "      <td>Russia is again emerging as a superpower - but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>Switching Titles, if Not Gears, at Dell</td>\n",
       "      <td>Kevin B. Rollins, the new chief executive of D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>For Sale: The Ultimate Status Symbol</td>\n",
       "      <td>With the country in need of cash and rich peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>Quality Gets Swept Away</td>\n",
       "      <td>Quality Distribution is hammered after reporti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_idx                                              title  \\\n",
       "30          3                    Japan nuclear firm shuts plants   \n",
       "31          3                   Veteran inventor in market float   \n",
       "32          3                   Saudi Arabia to open up oil taps   \n",
       "33          3                 Saudi phone sector gets \\$1bn lift   \n",
       "34          3                  Indians fill rail skills shortage   \n",
       "35          3                                  Steady as they go   \n",
       "36          3         Google IPO: Type in 'confusing,' 'secrecy'   \n",
       "37          3                        A bargain hunter's paradise   \n",
       "38          3     Researchers seek to untangle the e-mail thread   \n",
       "39          3    Microsoft Corp. 2.0: a kinder corporate culture   \n",
       "40          3                                            Letters   \n",
       "41          3                  Somewhere between gleam and gloom   \n",
       "42          3         Technology company sues five ex-employees    \n",
       "43          3                   Grant to aid Lynn Central Square   \n",
       "44          3    State grant to aid Lynn; Bank gives Salem \\$10k   \n",
       "45          3            A New Legal Chapter for a 90's Flameout   \n",
       "46          3  Will Russia, the Oil Superpower, Flex Its Musc...   \n",
       "47          3            Switching Titles, if Not Gears, at Dell   \n",
       "48          3               For Sale: The Ultimate Status Symbol   \n",
       "49          3                            Quality Gets Swept Away   \n",
       "\n",
       "                                          description  \n",
       "30  The company running the Japanese nuclear plant...  \n",
       "31  Trevor Baylis, the veteran inventor famous for...  \n",
       "32  Saudi Arabia says it is ready to push an extra...  \n",
       "33  A group led by the UAE's Etisalat plans to spe...  \n",
       "34  Network Rail flies in specialist Indian engine...  \n",
       "35  BEDFORD -- Scientists at NitroMed Inc. hope th...  \n",
       "36  I've submitted my bid to buy shares of Google ...  \n",
       "37  Massachusetts bargain hunters showed up in dro...  \n",
       "38  E-mail is a victim of its own success. That's ...  \n",
       "39  Even a genius can mess up. Bill Gates was a br...  \n",
       "40  Target the abusers of legal weapons We can all...  \n",
       "41  President Bush has been saying that the US eco...  \n",
       "42  A Marlborough-based technology company is suin...  \n",
       "43  Central Square in Lynn should be looking a bit...  \n",
       "44  Central Square in Lynn should be looking a bit...  \n",
       "45  A lawsuit against Gary Winnick, the former chi...  \n",
       "46  Russia is again emerging as a superpower - but...  \n",
       "47  Kevin B. Rollins, the new chief executive of D...  \n",
       "48  With the country in need of cash and rich peop...  \n",
       "49  Quality Distribution is hammered after reporti...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train.iloc[30:50,:].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./ag_news_train_titles.csv',columns=('title',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() missing 2 required positional arguments: 'pat' and 'repl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-65f26e7b8b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/TorchEnv/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m                 )\n\u001b[1;32m   1842\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() missing 2 required positional arguments: 'pat' and 'repl'"
     ]
    }
   ],
   "source": [
    "ds = df['title'].str.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan nuclear firm shuts plants\n",
      "Veteran inventor in market float\n",
      "Saudi Arabia to open up oil taps\n",
      "Saudi phone sector gets \\$1bn lift\n",
      "Indians fill rail skills shortage\n",
      "Steady as they go\n",
      "Google IPO: Type in 'confusing,' 'secrecy'\n",
      "A bargain hunter's paradise\n",
      "Researchers seek to untangle the e-mail thread\n",
      "Microsoft Corp. 2.0: a kinder corporate culture\n"
     ]
    }
   ],
   "source": [
    "df2 = df['title'].iloc[:10]\n",
    "for sample in df2:\n",
    "    print(sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from TorchDataUtils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self._token_to_idx = {}\n",
    "        self._idx_to_token = {}\n",
    "        self._idx_to_freq = {}\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "            self._idx_to_freq[index] += 1\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "            self._idx_to_freq[index] = 1\n",
    "        return index\n",
    "    \n",
    "    def index_to_token(self, index):\n",
    "        \n",
    "        if not isinstance(index, list):\n",
    "            if not isinstance(index, int):\n",
    "                raise NameError(\"'index' must be an integer or list of integers\")\n",
    "            if index not in self._idx_to_token:\n",
    "                raise KeyError('the index {} exeeds the Vocabulary lenght'.format(index))\n",
    "            return self._idx_to_token[index]\n",
    "        \n",
    "        tokens = []\n",
    "        for idx in index:\n",
    "            if not isinstance(idx, int):\n",
    "                raise NameError(\"{} is not an integer\".format(idx))\n",
    "            if idx not in self._idx_to_token:\n",
    "                raise KeyError('the index {} exeeds the Vocabulary lenght'.format(idx))\n",
    "            tokens.append(self._idx_to_token[idx])\n",
    "        return tokens\n",
    "\n",
    "    def token_to_index(self, token):\n",
    "        \n",
    "        if not isinstance(token, list):\n",
    "            if not isinstance(token, str):\n",
    "                raise NameError(\"'token' must be a string or list of strings\")\n",
    "            if token not in self._token_to_idx:\n",
    "                raise KeyError('the token {} is not in the Vocabulary'.format(token))\n",
    "            return self._token_to_idx[token]\n",
    "        \n",
    "        indeces = []\n",
    "        for tk in token:\n",
    "            if not isinstance(tk, str):\n",
    "                raise NameError(\"'token' must be a string or list of strings\")\n",
    "            if tk not in self._token_to_idx:\n",
    "                raise KeyError('the token {} is not in the Vocabulary'.format(tk))\n",
    "            indeces.append(self._token_to_idx[tk])\n",
    "        return indeces\n",
    "    \n",
    "    def get_freq(self, tk_or_idx):\n",
    "        \n",
    "        if isinstance(tk_or_idx, int):\n",
    "            if tk_or_idx not in self._idx_to_token:\n",
    "                raise KeyError('the index {} exeeds the Vocabulary lenght'.format(tk_or_idx))\n",
    "            freq = self._idx_to_freq[tk_or_idx]\n",
    "        elif isinstance(tk_or_idx, str):\n",
    "            if tk_or_idx not in self._token_to_idx:\n",
    "                freq = 0\n",
    "            else:\n",
    "                freq = self._idx_to_freq[self._token_to_idx[tk_or_idx]]\n",
    "        else:\n",
    "            raise KeyError('{} must be either integer or string'.format(tk_or_idx))\n",
    "        \n",
    "        return freq\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size={})>\".format(len(self))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "    \n",
    "    \n",
    "class Vectorizer(object):\n",
    "    \n",
    "    def __init__(self, data, cutoff=25):\n",
    "        \n",
    "        self.vocabulary = Vocabulary()\n",
    "        for sample in data:\n",
    "            for token in sample:\n",
    "                self.vocabulary.add_token(token)\n",
    "        self.num_tokens = len(self.vocabulary)\n",
    "        \n",
    "        self.cutoff = cutoff\n",
    "        ### TO DO:\n",
    "        ### PROCESAMIENTO DEL VOCABULARIO \n",
    "        ### Contar palabras frecuentes, etc. \n",
    "    \n",
    "    def vectorize(self,sample):\n",
    "        one_hot = torch.zeros(self.num_tokens,dtype=torch.float)\n",
    "        for token in sample:\n",
    "            if self.vocabulary.get_freq(token) >= self.cutoff:\n",
    "                one_hot[self.vocabulary.token_to_index(token)] = 1\n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el Train se define un Vectorizer a partir de las muestras de entrenamiento ya preprocesadas. El vectorizer contiene el vocabulario de las muestras. Con ese vocabulario se definen las palabras más usadas y se define un nuevo vocabulario que contiene al token UNK. Ese vocabulario es el que se usa en el entrenamiento y en el test. Cada vez que una muestra contiene una palabra poco frecuente (en el caso de entrenamiento o test) o una palabra desconocida (en el caso del test), se toma como UNK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGNewsPreprocess(data):\n",
    "        \n",
    "    ### TO DO:\n",
    "    ### PREPROCESAMIENTO DEL TEXTO\n",
    "    ### Data cleaning, etc.\n",
    "    sep_token = ' '\n",
    "    splitted_data = data.str.split(sep_token)\n",
    "    return splitted_data\n",
    "\n",
    "    \n",
    "class AGNewsTrainDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, cutoff=25):\n",
    "        \n",
    "        root='./AG_NEWS/train.csv'\n",
    "        df = pd.read_csv(root, header=None, names=['class_idx', 'title', 'description'])\n",
    "        \n",
    "        # Etiquetas:\n",
    "        self.cls_indeces = torch.tensor(df['class_idx'].tolist(), dtype=torch.long) - 1\n",
    "        \n",
    "        # DataSeries con las muestras de entradas:\n",
    "        data = df['title']\n",
    "        self.data = AGNewsPreprocess(data)\n",
    "        \n",
    "        # Vectorizer:\n",
    "        self.vectorizer = Vectorizer(self.data, cutoff=cutoff)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        if type(idx) == torch.Tensor:\n",
    "            idx = idx.item()\n",
    "        return self.vectorizer.vectorize(self.data.iloc[idx]), self.cls_indeces[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cls_indeces)\n",
    "    \n",
    "    \n",
    "    \n",
    "class AGNewsTestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,vectorizer):\n",
    "        \n",
    "        root='./AG_NEWS/test.csv'\n",
    "        df = pd.read_csv(root, header=None, names=['class_idx', 'title', 'description'])\n",
    "        \n",
    "        # Etiquetas:\n",
    "        self.cls_indeces = torch.tensor(df['class_idx'].tolist(), dtype=torch.long) - 1\n",
    "        \n",
    "        # DataSeries con las muestras de entradas:\n",
    "        data = df['title']\n",
    "        self.data = AGNewsPreprocess(data)\n",
    "        \n",
    "        # Vectorizer:\n",
    "        self.vectorizer = vectorizer\n",
    "    \n",
    "    def __getitem__(self,idx): \n",
    "        if type(idx) == torch.Tensor:\n",
    "            idx = idx.item()\n",
    "        return self.vectorizer.vectorize(self.data.iloc[idx]), self.cls_indeces[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cls_indeces)\n",
    "    \n",
    "    \n",
    "def GetAGNewsDataset(cutoff=25):\n",
    "    train_dataset = AGNewsTrainDataset(cutoff=cutoff)\n",
    "    test_dataset = AGNewsTestDataset(train_dataset.vectorizer)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = GetAGNewsDataset()\n",
    "train_dataloader, val_dataloader, test_dataloader = generate_data_batches(train_dataset, test_dataset,\n",
    "                                                                         batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 71762])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 4])\n",
      "tensor([[ 2.3407e-03, -5.7921e-03, -2.9384e-04,  5.0761e-03],\n",
      "        [-1.1365e-03,  6.9859e-03,  5.2174e-03,  1.5252e-05],\n",
      "        [-7.7836e-03, -1.2941e-03,  8.8130e-03, -6.5985e-03],\n",
      "        [-4.3392e-03, -1.3828e-03, -6.9637e-04,  2.8067e-03],\n",
      "        [ 1.3108e-03,  7.9555e-03, -6.0573e-03,  1.2673e-03],\n",
      "        [-4.5509e-03, -1.5158e-04, -3.1026e-03,  5.6222e-03],\n",
      "        [-1.5810e-03,  6.6915e-03,  1.3996e-03, -5.8467e-03],\n",
      "        [-5.9074e-03,  2.9136e-03, -9.8230e-04,  4.0296e-03],\n",
      "        [-3.8239e-03, -1.5737e-03, -3.2134e-03,  3.1358e-03],\n",
      "        [-2.5563e-03, -1.5654e-04,  1.5448e-04,  7.4662e-03],\n",
      "        [-5.2801e-04,  5.8615e-04,  9.8228e-04,  5.2667e-03],\n",
      "        [ 2.9323e-03,  9.8917e-03, -4.6736e-03, -1.3661e-03],\n",
      "        [-8.2826e-03, -5.7163e-04,  5.8180e-03,  4.1671e-04],\n",
      "        [ 3.1668e-03, -1.5713e-03,  3.9105e-03, -8.9253e-03],\n",
      "        [-8.5875e-03,  4.0157e-03, -9.9123e-04,  5.1830e-03],\n",
      "        [-7.6637e-03, -3.1530e-03,  2.2248e-03, -3.0493e-03],\n",
      "        [-1.0075e-02,  5.5316e-04, -1.1377e-03,  5.4948e-03],\n",
      "        [-2.3419e-03,  9.3570e-03,  4.4317e-03, -3.1718e-03],\n",
      "        [ 4.0851e-03,  9.9246e-03,  2.3256e-03,  7.2559e-03],\n",
      "        [ 3.4193e-03,  6.2449e-03,  2.3839e-03,  5.0405e-03],\n",
      "        [-2.4432e-03, -5.9620e-04, -4.3000e-03, -1.6445e-03],\n",
      "        [-1.0668e-02,  2.2585e-03,  3.2579e-03, -6.1063e-03],\n",
      "        [ 3.7981e-04,  1.2792e-03,  1.0203e-03,  7.3373e-03],\n",
      "        [-3.0643e-03,  9.1496e-04, -1.1343e-03,  2.0574e-03],\n",
      "        [-3.5339e-03,  7.5634e-04,  3.7240e-04,  2.2004e-03],\n",
      "        [ 5.5319e-05,  2.4509e-03, -7.1664e-03,  5.9457e-03],\n",
      "        [-2.2970e-03,  5.6964e-03, -3.2932e-03,  7.4068e-03],\n",
      "        [-2.6276e-03, -5.4361e-03, -2.2486e-03,  3.0539e-03],\n",
      "        [-6.1628e-03, -2.2276e-03, -1.6613e-03,  2.2586e-03],\n",
      "        [-3.4427e-04,  3.5323e-05,  1.3404e-04, -3.9470e-03],\n",
      "        [ 2.8721e-03,  4.7318e-03, -1.0535e-03, -4.2297e-04],\n",
      "        [-2.4652e-03,  8.0745e-03,  6.9692e-03,  6.3744e-03],\n",
      "        [-9.6000e-03, -1.7223e-03, -1.2705e-02,  1.5298e-02],\n",
      "        [-5.1166e-03, -4.5867e-04,  7.7450e-03,  1.2692e-03],\n",
      "        [-5.6157e-03,  2.3314e-03, -1.2233e-03,  4.4386e-04],\n",
      "        [-6.0574e-03,  9.0771e-03, -2.4845e-03,  6.5099e-03],\n",
      "        [ 2.8995e-04,  6.4613e-03,  4.8847e-03, -1.3548e-03],\n",
      "        [-2.9966e-04,  3.6508e-03,  4.0884e-03, -1.2717e-03],\n",
      "        [-3.5958e-03, -6.3877e-03, -1.5086e-03,  5.3260e-03],\n",
      "        [-1.4874e-03, -2.8878e-04, -1.8521e-03, -1.7332e-03],\n",
      "        [-5.6497e-03, -7.0594e-03, -5.9344e-03,  6.0260e-03],\n",
      "        [-4.4303e-03,  1.0853e-02, -9.4729e-03,  3.3531e-03],\n",
      "        [ 1.6352e-03, -8.5831e-03, -1.2946e-04,  3.6440e-04],\n",
      "        [ 2.3291e-03, -2.1972e-03, -2.9951e-04, -9.9060e-04],\n",
      "        [ 2.0542e-04, -4.1722e-03,  7.0916e-03,  7.6550e-03],\n",
      "        [-7.2592e-03,  1.8400e-03,  1.6315e-03,  1.0381e-02],\n",
      "        [-7.8859e-03,  5.1020e-03, -1.4562e-03,  7.5904e-03],\n",
      "        [-1.1597e-02,  7.3445e-03, -4.0795e-03, -9.1411e-05],\n",
      "        [-5.5669e-03,  7.0187e-05,  6.7448e-04,  8.6419e-03],\n",
      "        [-1.1675e-04, -1.0985e-04,  5.7027e-04,  7.6255e-03],\n",
      "        [ 3.6352e-03, -3.4018e-05, -2.5323e-03, -2.1070e-03],\n",
      "        [-1.8412e-03,  1.1517e-02, -2.8032e-03,  4.5906e-03],\n",
      "        [-7.0272e-03,  6.3274e-03,  9.7177e-03,  1.1748e-02],\n",
      "        [-6.5077e-03, -3.0120e-05, -1.0396e-03, -2.7738e-03],\n",
      "        [-6.6397e-03,  1.1973e-03,  5.2668e-03, -1.7489e-04],\n",
      "        [-3.6468e-03,  3.3650e-03,  2.2393e-03,  6.7925e-03],\n",
      "        [-1.3789e-03,  7.9409e-04, -5.4344e-03,  1.1666e-02],\n",
      "        [-1.1020e-02,  3.9655e-03,  8.0365e-03,  3.3416e-03],\n",
      "        [-2.1389e-03, -3.0806e-03,  9.4861e-03, -2.9902e-03],\n",
      "        [ 7.4505e-04,  5.7941e-03, -3.7104e-03,  2.3121e-03],\n",
      "        [-4.0365e-03, -2.6534e-03, -2.6098e-03,  9.8187e-03],\n",
      "        [-2.7239e-03,  6.9330e-03,  3.7965e-03, -3.1561e-03],\n",
      "        [-7.2092e-03,  4.8129e-03,  4.5409e-03,  6.2030e-04],\n",
      "        [ 6.4635e-03, -1.1613e-02, -7.6795e-03,  9.6541e-03]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([64, 71762])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 4])\n",
      "tensor([[ 4.2203e-03,  2.5299e-03, -8.7462e-03,  8.3680e-04],\n",
      "        [ 7.1526e-03,  1.3776e-03, -2.7585e-03,  4.3879e-03],\n",
      "        [-1.8898e-05,  5.9139e-03, -4.1777e-03,  9.1980e-03],\n",
      "        [-2.9932e-03, -5.0409e-03, -5.3357e-03, -4.9993e-03],\n",
      "        [ 2.8723e-04,  1.0695e-02, -8.8045e-03, -1.7477e-03],\n",
      "        [-7.6608e-03,  5.5891e-03, -2.9971e-03,  1.3710e-03],\n",
      "        [-3.6598e-03,  5.6275e-03,  2.5908e-03,  9.4142e-03],\n",
      "        [ 1.2226e-03,  3.0203e-03,  2.9153e-03,  3.6627e-03],\n",
      "        [-8.1661e-03, -3.8376e-03,  1.1982e-02,  4.2973e-03],\n",
      "        [-8.2475e-03,  2.0249e-03, -1.1981e-04,  4.5899e-03],\n",
      "        [ 1.0033e-03,  3.1092e-03,  4.0252e-03, -4.0306e-03],\n",
      "        [-9.3547e-03,  1.1247e-02,  5.6197e-03,  8.5566e-03],\n",
      "        [-4.4254e-03,  7.2990e-03, -1.2638e-05, -7.0890e-03],\n",
      "        [-4.1814e-03, -7.7775e-03,  5.9473e-03, -1.3956e-03],\n",
      "        [ 9.5798e-03,  4.7671e-04, -8.9160e-03,  5.3134e-03],\n",
      "        [-7.8432e-04, -2.1539e-03,  8.6496e-03,  8.5064e-03],\n",
      "        [-4.8676e-03,  1.0730e-02,  7.9959e-03, -1.1076e-02],\n",
      "        [ 2.1845e-03,  4.1131e-03,  6.7785e-03,  2.3988e-03],\n",
      "        [-1.6792e-03,  3.1340e-03,  2.2325e-03,  1.1290e-02],\n",
      "        [-8.7739e-03, -2.3606e-03, -7.1800e-03,  6.7033e-03],\n",
      "        [-5.0453e-03,  3.9001e-03,  1.5418e-03,  4.2690e-03],\n",
      "        [-6.4113e-03,  2.7489e-04, -7.9687e-03, -3.2540e-03],\n",
      "        [-6.1375e-03, -6.1314e-03,  3.2559e-03, -4.5547e-03],\n",
      "        [-1.1210e-02,  5.3995e-03, -2.8433e-03,  9.2192e-03],\n",
      "        [-3.7407e-03,  5.8929e-03,  6.9670e-03,  7.3972e-03],\n",
      "        [-9.7572e-03,  1.6832e-03,  2.1641e-03,  1.0291e-02],\n",
      "        [-3.7021e-03,  8.5159e-04,  2.3436e-03,  1.8676e-02],\n",
      "        [ 2.9867e-03,  6.3172e-03, -6.7048e-03,  3.2918e-04],\n",
      "        [-2.9931e-03, -1.2281e-03, -4.8772e-03,  5.5086e-05],\n",
      "        [-9.3738e-03, -2.9800e-03, -5.4614e-03,  7.8143e-03],\n",
      "        [ 1.1099e-03, -2.1676e-03, -6.2492e-03,  9.6011e-03],\n",
      "        [-1.4805e-03,  1.2501e-03, -3.7399e-03,  1.0602e-02],\n",
      "        [-4.0099e-03, -8.0509e-04,  6.2157e-03,  5.9653e-03],\n",
      "        [-5.8805e-03, -4.2133e-03, -2.8961e-03,  6.6113e-04],\n",
      "        [-4.6444e-03, -4.1997e-03, -4.8539e-04, -4.7889e-05],\n",
      "        [-1.7574e-03, -1.4213e-03, -6.3457e-03,  9.4172e-03],\n",
      "        [-2.8589e-03,  4.2917e-03,  1.6128e-03,  9.4397e-04],\n",
      "        [-8.2671e-04,  3.8606e-03,  1.6741e-03, -2.6975e-05],\n",
      "        [ 3.0508e-03,  6.7219e-04, -1.4823e-03,  8.0006e-03],\n",
      "        [-1.0288e-03,  2.0099e-03, -4.3813e-03,  1.9411e-03],\n",
      "        [-7.5932e-03,  7.6174e-03, -2.9315e-03,  2.9716e-03],\n",
      "        [ 8.3007e-03, -1.8585e-03,  5.5323e-03,  1.6680e-03],\n",
      "        [-2.0474e-03,  2.4876e-03,  2.0280e-03,  7.6441e-04],\n",
      "        [-2.0497e-03, -2.0828e-03,  1.8877e-03,  5.6714e-03],\n",
      "        [-5.5514e-03,  3.1885e-03, -6.0100e-03,  4.0860e-03],\n",
      "        [-6.5978e-04,  8.9049e-03, -8.2767e-03,  6.7188e-03],\n",
      "        [-2.0979e-03,  3.1804e-03,  5.5931e-03,  5.1547e-03],\n",
      "        [-5.9787e-03, -8.9239e-04,  4.0591e-03,  8.3475e-03],\n",
      "        [ 2.2255e-03, -5.5376e-03,  2.0659e-04,  7.7297e-03],\n",
      "        [-6.7496e-03,  8.8466e-04, -3.1554e-03,  4.7621e-05],\n",
      "        [-3.2556e-03,  8.7366e-03,  5.1523e-03,  1.2138e-02],\n",
      "        [-3.4129e-03,  6.3512e-03,  7.6272e-03, -3.4855e-03],\n",
      "        [ 4.5242e-03,  5.8468e-03, -3.6545e-03,  5.9935e-03],\n",
      "        [ 5.6235e-03, -4.8781e-03,  5.2805e-03,  4.6741e-03],\n",
      "        [ 5.7444e-03, -9.9147e-03,  9.2240e-04, -2.1148e-04],\n",
      "        [ 9.1655e-03, -1.4498e-02, -1.8550e-03,  1.1253e-02],\n",
      "        [ 1.5592e-03,  8.3509e-03, -5.6119e-03, -7.4367e-03],\n",
      "        [-1.9122e-03,  4.8264e-03, -2.6479e-04, -1.1779e-04],\n",
      "        [-2.9959e-03, -9.5327e-03, -2.1894e-03, -6.3825e-04],\n",
      "        [-3.0158e-04, -1.3998e-03,  1.5955e-03,  6.8197e-03],\n",
      "        [-2.4539e-03, -4.6113e-03,  2.5923e-03,  2.2236e-03],\n",
      "        [-1.7726e-03,  2.7531e-03, -3.1532e-03,  2.3141e-03],\n",
      "        [-8.3711e-03,  8.5543e-03,  2.7442e-04,  1.3700e-02],\n",
      "        [-5.5300e-03,  2.8553e-04,  2.1809e-03,  5.1435e-03]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([64, 71762])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 4])\n",
      "tensor([[ 1.3645e-03,  3.8144e-03, -2.1260e-03, -1.5909e-03],\n",
      "        [-4.6222e-03, -4.9699e-03, -3.1542e-03,  1.2359e-02],\n",
      "        [-7.2074e-04, -1.3679e-04,  8.6447e-03,  8.7325e-03],\n",
      "        [-5.1366e-03,  7.2874e-03, -2.0957e-04,  1.7184e-03],\n",
      "        [ 2.2383e-03, -8.4576e-04, -5.8068e-03,  2.9112e-03],\n",
      "        [-3.3843e-05, -5.6031e-03,  5.5665e-03,  3.1072e-03],\n",
      "        [-3.5339e-03,  7.5634e-04,  3.7240e-04,  2.2004e-03],\n",
      "        [ 8.0786e-04, -3.1712e-04,  1.2857e-03,  6.6800e-04],\n",
      "        [ 2.0018e-03, -7.9907e-04,  3.7783e-03, -2.8491e-04],\n",
      "        [-4.6035e-03,  2.4013e-03, -2.9485e-03,  1.2898e-02],\n",
      "        [ 2.9033e-03,  8.1589e-03, -1.5963e-03,  4.0207e-03],\n",
      "        [ 7.6532e-04,  2.4920e-03,  1.4733e-03,  5.9712e-03],\n",
      "        [ 4.6835e-04, -9.6054e-04, -4.2739e-03,  1.5931e-03],\n",
      "        [ 5.2229e-03, -5.2117e-03, -2.5243e-03,  1.4191e-02],\n",
      "        [ 1.4168e-03,  6.2849e-03, -5.6796e-03,  2.4446e-04],\n",
      "        [-6.4284e-03,  7.2852e-03,  4.3107e-03, -3.8678e-04],\n",
      "        [-5.7861e-03,  5.6811e-03, -2.8115e-03,  4.9537e-03],\n",
      "        [-3.3052e-03, -1.1544e-03, -3.5013e-03,  1.1114e-02],\n",
      "        [ 1.1385e-03,  3.0815e-03, -5.4933e-03,  9.1430e-03],\n",
      "        [ 4.1555e-04, -6.4516e-04,  5.3606e-03, -2.0659e-03],\n",
      "        [-1.1309e-02,  2.8150e-03, -1.5393e-03,  4.5462e-04],\n",
      "        [-4.1165e-03,  1.4672e-03,  4.5858e-03,  7.3582e-03],\n",
      "        [ 1.5388e-03, -9.6574e-03, -1.3967e-02,  2.3908e-03],\n",
      "        [-2.9692e-03,  3.6444e-03, -3.9431e-03,  2.8884e-03],\n",
      "        [-1.2017e-03,  4.5070e-03, -7.6386e-03, -1.3117e-03],\n",
      "        [ 2.8769e-03,  5.3671e-03, -2.0485e-03, -2.2382e-03],\n",
      "        [-7.1059e-03, -1.2159e-02,  2.2877e-03, -3.6426e-03],\n",
      "        [-1.2589e-02,  4.8308e-03, -7.4314e-04,  2.5557e-03],\n",
      "        [-2.5093e-03, -9.6111e-04,  3.7666e-03,  6.9377e-03],\n",
      "        [-2.7241e-03,  1.4729e-03, -5.1355e-05,  5.7002e-03],\n",
      "        [ 4.3513e-04, -1.3176e-03,  2.1336e-03,  4.4403e-04],\n",
      "        [ 9.5416e-04, -2.5367e-04,  5.7755e-03, -3.1294e-03],\n",
      "        [-9.6053e-03, -4.1360e-03,  1.9230e-04,  8.3799e-03],\n",
      "        [-6.3745e-03,  7.7237e-03,  5.0224e-03,  4.0509e-04],\n",
      "        [-7.9059e-03,  4.7227e-03, -1.4241e-02,  3.6695e-03],\n",
      "        [ 5.4769e-03, -3.5876e-04, -1.4481e-03, -4.9066e-03],\n",
      "        [-1.0671e-02, -4.3589e-03, -1.0333e-02, -5.3489e-03],\n",
      "        [-1.4604e-03,  1.1587e-03,  6.9390e-03,  8.8010e-03],\n",
      "        [ 5.2637e-03,  9.3419e-04,  1.9063e-03,  5.7693e-03],\n",
      "        [ 5.1803e-04,  4.5625e-03, -3.2381e-03, -3.1258e-03],\n",
      "        [-3.7482e-03,  4.3005e-03, -4.9714e-04,  1.3994e-03],\n",
      "        [-8.3117e-03, -2.2972e-03,  4.3523e-03,  5.7767e-04],\n",
      "        [-7.8872e-03,  1.0152e-03,  2.5929e-03,  1.2484e-02],\n",
      "        [-2.8645e-03,  2.1587e-03, -3.4498e-03,  1.0147e-02],\n",
      "        [-5.3863e-04, -2.1085e-03,  1.2741e-03,  8.4859e-03],\n",
      "        [-2.3094e-03,  8.9078e-04, -2.5455e-03,  2.6229e-03],\n",
      "        [-5.1334e-03,  1.3278e-03,  3.6455e-03, -4.0462e-03],\n",
      "        [ 9.1370e-06,  3.9535e-03, -1.5714e-03,  7.0173e-03],\n",
      "        [-4.1167e-03,  1.0109e-02, -6.1029e-03, -2.9730e-03],\n",
      "        [-4.5985e-03, -2.6456e-03, -2.9414e-03,  4.4221e-03],\n",
      "        [-6.5043e-03,  3.8128e-04, -9.3541e-03, -3.4949e-03],\n",
      "        [-4.8329e-04,  2.8137e-03,  4.0990e-03, -4.8535e-04],\n",
      "        [ 2.1655e-03,  6.6064e-03, -3.4212e-04,  8.1839e-04],\n",
      "        [-7.7004e-03,  5.0057e-03, -2.3541e-03,  5.2911e-03],\n",
      "        [-7.3173e-05,  2.9146e-04,  1.2291e-03,  1.7710e-03],\n",
      "        [-3.2986e-03, -6.6776e-03,  3.5129e-03,  5.4975e-03],\n",
      "        [-2.8614e-03,  3.6766e-03, -2.7411e-03,  2.0181e-03],\n",
      "        [ 1.0768e-03,  4.5933e-03,  5.2428e-03,  1.2420e-02],\n",
      "        [-4.9345e-03, -1.6790e-03,  3.1923e-03,  7.1360e-03],\n",
      "        [-8.8249e-03,  3.8466e-03,  8.7406e-03,  9.0271e-03],\n",
      "        [-1.2031e-02, -5.9474e-03,  1.1198e-02,  1.1192e-02],\n",
      "        [-5.8679e-04,  3.4644e-03, -3.2881e-04,  1.1608e-03],\n",
      "        [-1.3149e-03,  4.1348e-03,  4.1340e-03,  1.3602e-03],\n",
      "        [-5.3706e-03,  2.7105e-03, -4.5390e-03,  9.5574e-03]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([64, 71762])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 4])\n",
      "tensor([[-2.3779e-03,  6.1364e-04,  1.4110e-03,  1.9947e-03],\n",
      "        [-1.8277e-03,  7.9189e-04,  2.4810e-03,  4.6844e-03],\n",
      "        [-2.0538e-03, -2.8501e-03,  5.8658e-03,  9.0965e-03],\n",
      "        [-7.9934e-03, -8.5242e-04, -4.3493e-03,  2.4153e-03],\n",
      "        [-5.9291e-03, -6.1483e-03, -7.8038e-03,  1.3952e-02],\n",
      "        [-6.6866e-03,  4.6973e-03, -2.1644e-03, -1.3557e-03],\n",
      "        [-1.1167e-02, -4.9893e-03,  8.6229e-04,  4.9561e-05],\n",
      "        [-7.5763e-04, -3.4641e-03,  1.7613e-03,  2.9233e-03],\n",
      "        [-2.5337e-03, -6.6044e-03,  4.7186e-03,  3.0128e-03],\n",
      "        [-1.0480e-02,  3.2561e-03, -2.4542e-03,  1.9898e-03],\n",
      "        [-2.5237e-03,  4.4992e-03, -5.9336e-03,  1.3820e-02],\n",
      "        [-1.2628e-03, -1.9957e-04,  3.5621e-03,  3.1527e-03],\n",
      "        [ 1.1658e-04,  5.0424e-03, -6.3552e-03,  4.7233e-04],\n",
      "        [ 5.4635e-03, -2.2165e-05,  2.1705e-03,  7.4402e-03],\n",
      "        [-7.5740e-03,  2.2919e-03,  8.9641e-03,  2.6663e-03],\n",
      "        [-4.6950e-03, -5.2874e-04, -4.7453e-03,  5.4685e-03],\n",
      "        [-1.0173e-02,  4.5098e-04, -1.6998e-04,  6.9254e-03],\n",
      "        [-4.8050e-03,  7.6544e-03, -3.8381e-05,  1.3580e-03],\n",
      "        [-1.2417e-02, -2.2415e-03, -1.5603e-03, -8.5073e-05],\n",
      "        [-6.1258e-03, -7.5733e-04,  1.3171e-03, -1.1362e-03],\n",
      "        [-6.2480e-03,  5.1383e-03, -7.1065e-03, -2.4624e-04],\n",
      "        [ 2.3945e-03, -2.7329e-04,  9.3267e-03,  5.9397e-03],\n",
      "        [-4.1764e-03,  9.1574e-03, -1.1162e-03, -1.0680e-03],\n",
      "        [ 6.1546e-03, -3.4915e-03, -1.1436e-03,  7.3372e-03],\n",
      "        [ 1.7655e-03,  1.4443e-03,  1.7200e-03,  1.2780e-02],\n",
      "        [ 6.2286e-03,  8.8214e-03,  2.5704e-03,  7.4375e-03],\n",
      "        [-2.3280e-03, -3.3466e-03,  5.2964e-03,  6.9981e-04],\n",
      "        [ 3.5576e-03, -3.7425e-03, -2.3661e-03,  9.9474e-04],\n",
      "        [-5.2809e-03, -4.8148e-03, -5.9256e-03, -5.2827e-03],\n",
      "        [ 1.9309e-04,  5.2457e-03,  3.1788e-03,  5.7037e-03],\n",
      "        [-2.8252e-03, -9.9456e-04, -5.0108e-03,  9.0147e-03],\n",
      "        [-4.1752e-03,  2.7295e-03,  2.2670e-03, -5.1270e-04],\n",
      "        [ 3.0474e-03, -1.7228e-03, -6.5950e-04,  4.9489e-03],\n",
      "        [ 7.9689e-04, -2.4917e-03, -1.1348e-03,  2.4260e-03],\n",
      "        [ 1.7858e-03,  4.5134e-03,  6.3409e-04, -2.5431e-03],\n",
      "        [-5.2619e-03,  1.0343e-03,  6.2261e-03,  9.1649e-03],\n",
      "        [ 7.5953e-03, -1.7832e-03, -6.5983e-03,  1.7733e-03],\n",
      "        [ 8.7411e-03, -2.6805e-03,  7.4850e-03,  3.4319e-03],\n",
      "        [ 1.6802e-03,  6.0104e-03, -8.2620e-03,  1.0100e-02],\n",
      "        [-9.3609e-03, -2.4786e-03,  3.4017e-03,  5.7576e-03],\n",
      "        [ 4.6910e-03,  4.2473e-03,  1.1014e-02,  1.8827e-03],\n",
      "        [-5.2719e-04, -3.1393e-03, -3.8852e-03,  1.6500e-03],\n",
      "        [ 1.2612e-04, -4.6708e-03, -1.1993e-02,  8.8943e-03],\n",
      "        [ 6.7162e-03, -1.1656e-02,  4.1892e-03,  5.0645e-03],\n",
      "        [-4.1929e-03,  5.1526e-03, -6.3526e-03, -1.0054e-02],\n",
      "        [ 5.2918e-03, -3.1055e-03,  5.0634e-03,  2.6458e-03],\n",
      "        [ 2.2650e-03, -4.2846e-03,  6.3491e-04,  7.1611e-03],\n",
      "        [-1.6389e-03, -9.7038e-03,  5.9301e-03,  1.2419e-02],\n",
      "        [-1.9517e-03,  8.9660e-03,  5.9334e-03,  1.0056e-02],\n",
      "        [ 6.4967e-03,  6.8308e-03,  1.1592e-03,  8.5473e-03],\n",
      "        [-1.8063e-03, -8.6828e-03,  4.1792e-03,  2.1056e-03],\n",
      "        [-1.1329e-04,  5.6356e-03, -3.0869e-03,  1.5760e-03],\n",
      "        [-3.3734e-03,  2.5519e-03,  1.6229e-03, -4.2852e-03],\n",
      "        [-1.4785e-02,  8.3193e-03,  2.2196e-03,  1.2257e-02],\n",
      "        [-1.0619e-02,  1.2093e-03, -3.2654e-03,  2.9839e-03],\n",
      "        [-4.9096e-03, -2.0108e-03,  5.2662e-03,  8.6858e-04],\n",
      "        [-3.9521e-03,  1.5754e-03,  2.5482e-03,  2.9390e-03],\n",
      "        [-2.2466e-03,  1.4122e-03, -1.1174e-02,  1.1865e-02],\n",
      "        [-2.0109e-03,  4.8779e-03, -4.6855e-03,  3.7363e-03],\n",
      "        [-4.7087e-03,  1.2492e-03, -9.2516e-04,  1.6940e-03],\n",
      "        [ 1.2611e-03, -1.0801e-02,  1.0762e-03,  2.8063e-04],\n",
      "        [-2.1687e-03, -2.0334e-04, -1.5663e-03,  2.0679e-03],\n",
      "        [-2.2071e-03,  8.5315e-04, -9.9232e-04,  7.5895e-03],\n",
      "        [-4.9676e-03, -2.5080e-03,  1.0509e-02,  4.7300e-03]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([64, 71762])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 4])\n",
      "tensor([[-7.3762e-03, -8.1463e-03,  6.4351e-03,  6.1848e-03],\n",
      "        [-3.1748e-03, -1.3921e-03,  1.9193e-03,  6.7747e-03],\n",
      "        [ 3.0050e-03, -1.8097e-03, -3.1245e-03, -6.7892e-04],\n",
      "        [-9.6568e-03,  7.1988e-04, -4.1620e-05,  4.1547e-03],\n",
      "        [-6.7525e-03, -1.1038e-03, -1.2306e-03,  1.4038e-03],\n",
      "        [-2.9015e-04, -2.2537e-03,  5.5673e-03, -4.1512e-03],\n",
      "        [ 2.4611e-04, -2.0345e-04, -6.4392e-03,  3.3817e-03],\n",
      "        [-7.8398e-03, -4.1705e-04,  5.7151e-04,  6.9406e-03],\n",
      "        [ 2.3184e-03,  3.1303e-03, -5.6820e-03,  6.6504e-03],\n",
      "        [-2.0683e-03,  1.9586e-03, -1.5152e-03,  5.0593e-03],\n",
      "        [-2.2339e-03,  5.4587e-03,  2.3059e-03,  2.7560e-04],\n",
      "        [-9.5073e-04,  3.9157e-04, -4.4665e-03, -2.2615e-03],\n",
      "        [-5.3145e-03,  8.6029e-03, -3.9772e-03, -5.4941e-05],\n",
      "        [-8.0087e-04,  4.3617e-03,  3.9598e-03,  1.1725e-03],\n",
      "        [-1.8220e-03,  4.0729e-03,  3.7704e-03,  3.4711e-03],\n",
      "        [-2.7734e-03,  3.1671e-03,  2.5653e-03,  4.1620e-03],\n",
      "        [-8.9402e-03,  5.7397e-03,  6.8026e-04,  5.7941e-03],\n",
      "        [-7.6179e-03,  1.9916e-03, -5.0446e-03,  1.3784e-03],\n",
      "        [-8.8932e-03, -2.0455e-03,  2.1694e-03,  7.2187e-03],\n",
      "        [-1.1241e-02,  1.0078e-02, -1.1156e-03,  4.1867e-03],\n",
      "        [-9.8088e-03,  5.6389e-03, -5.5117e-03, -2.3998e-03],\n",
      "        [ 2.2320e-03,  8.2753e-03,  4.0620e-03,  1.2623e-02],\n",
      "        [-4.2204e-03,  5.8702e-03,  7.4026e-03,  5.8312e-03],\n",
      "        [-3.3038e-03,  2.4124e-03, -2.1180e-04, -2.9240e-03],\n",
      "        [-9.2741e-04, -2.4361e-03,  5.1331e-03,  6.2346e-03],\n",
      "        [-6.3254e-03,  3.1382e-03, -9.4108e-04,  2.9532e-03],\n",
      "        [ 2.1815e-03,  5.3744e-04,  2.1933e-03,  1.0631e-02],\n",
      "        [ 2.9275e-03,  1.0316e-03,  7.7143e-04,  3.0557e-04],\n",
      "        [-6.6749e-04,  8.2327e-03, -3.8791e-03,  8.3589e-03],\n",
      "        [-1.7087e-03,  6.4626e-03,  1.7148e-03,  3.8827e-03],\n",
      "        [ 4.4529e-03, -2.8247e-03,  2.3217e-03, -3.1765e-03],\n",
      "        [-3.5339e-03,  7.5634e-04,  3.7240e-04,  2.2004e-03],\n",
      "        [-1.9642e-03, -1.8881e-03,  7.5241e-04, -2.3357e-03],\n",
      "        [-5.9043e-03,  5.9981e-04,  9.5904e-05, -6.3298e-04],\n",
      "        [-4.1270e-04, -5.7434e-03, -1.9855e-03,  6.5436e-03],\n",
      "        [ 2.0989e-03,  2.5459e-03, -2.7978e-03,  3.5128e-03],\n",
      "        [ 3.0953e-03, -8.6971e-04, -5.8336e-03, -1.9512e-04],\n",
      "        [-9.4525e-03,  7.7763e-03,  1.0072e-03,  1.7336e-03],\n",
      "        [-6.4975e-03,  2.0315e-03, -6.1017e-03,  1.5792e-03],\n",
      "        [ 4.0531e-03,  1.8583e-03,  1.7498e-03,  5.5198e-05],\n",
      "        [ 8.9504e-03,  1.1734e-02, -6.8050e-03,  1.1223e-02],\n",
      "        [-4.7289e-03, -7.0507e-03, -1.2630e-03,  3.2489e-03],\n",
      "        [-2.4590e-03,  2.0413e-03,  3.4724e-03,  2.3489e-03],\n",
      "        [-7.9235e-03,  3.1969e-03, -1.3580e-03,  4.2008e-03],\n",
      "        [-4.6059e-03,  7.3697e-03,  5.9574e-03, -3.1134e-03],\n",
      "        [-7.1838e-03, -2.0632e-03,  9.7538e-04,  1.1395e-03],\n",
      "        [-3.5786e-03,  5.5828e-03, -2.0021e-03, -9.6989e-04],\n",
      "        [ 4.0520e-03,  3.3058e-03,  3.6778e-03,  3.3533e-03],\n",
      "        [-5.1871e-03,  4.2575e-03, -1.9349e-03,  7.4032e-03],\n",
      "        [-1.2888e-02,  3.1490e-03, -1.2317e-03,  7.6277e-03],\n",
      "        [-5.1819e-03,  3.0033e-03, -3.3080e-04,  5.8701e-03],\n",
      "        [-4.8775e-03, -1.2162e-03, -2.6328e-03,  7.1003e-04],\n",
      "        [-5.9946e-05,  6.7845e-04,  8.7885e-03,  1.3522e-03],\n",
      "        [-2.4294e-04,  9.1077e-03,  5.1438e-03,  7.8966e-03],\n",
      "        [-1.7530e-03, -1.1636e-02,  4.5167e-03,  5.6971e-03],\n",
      "        [ 3.4652e-03,  9.9156e-03, -2.7293e-03, -4.2635e-03],\n",
      "        [ 4.3700e-04, -6.2012e-04,  9.6606e-03,  7.8355e-03],\n",
      "        [-5.9000e-03, -5.6189e-03, -5.4793e-04,  1.9528e-03],\n",
      "        [-1.0544e-03,  3.4532e-03, -8.2117e-04,  5.5785e-03],\n",
      "        [-2.5013e-03, -1.3500e-03, -1.1663e-02,  2.2532e-03],\n",
      "        [-5.6696e-03, -1.7015e-03, -1.4592e-03,  8.0185e-03],\n",
      "        [-3.7584e-03,  5.1106e-04, -2.1305e-03, -4.8004e-04],\n",
      "        [-5.1192e-03,  7.6721e-03, -3.9939e-03,  8.6305e-03],\n",
      "        [ 3.8047e-03, -6.5713e-04,  2.2235e-04, -4.8818e-06]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for t, (x, y) in enumerate(train_dataloader):\n",
    "    print(x.size())\n",
    "    print(y.size())\n",
    "    print(model(x).size())\n",
    "    print(model(x))\n",
    "    if t>3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, n_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.emb = nn.Linear(vocab_size, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.emb(x)\n",
    "    \n",
    "    def loss(self, scores, target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        return lf(scores, target)\n",
    "    \n",
    "vocab_size = len(train_dataset.vectorizer.vocabulary)\n",
    "n_classes = 4\n",
    "model = TextClassifier(vocab_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch number: 0\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 0, Batch number: 100\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 200\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 300\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 400\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 500\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 600\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 700\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 800\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 900\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 1000\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 1100\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 1200\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 1300\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 1400\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 1500\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 1600\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 0, Batch number: 1700\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 0, Batch number: 1800\n",
      "Accuracy on validation dataset: 1337/2400 (55.71%)\n",
      "\n",
      "Epoch: 1, Batch number: 62\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 1, Batch number: 162\n",
      "Accuracy on validation dataset: 1338/2400 (55.75%)\n",
      "\n",
      "Epoch: 1, Batch number: 262\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 362\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 462\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 562\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 662\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 762\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 862\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 962\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 1062\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 1162\n",
      "Accuracy on validation dataset: 1339/2400 (55.79%)\n",
      "\n",
      "Epoch: 1, Batch number: 1262\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 1, Batch number: 1362\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 1, Batch number: 1462\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 1, Batch number: 1562\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 1, Batch number: 1662\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 1, Batch number: 1762\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 2, Batch number: 24\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 2, Batch number: 124\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 2, Batch number: 224\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 2, Batch number: 324\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 2, Batch number: 424\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 524\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 624\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 2, Batch number: 724\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 824\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 924\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1024\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1124\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1224\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1324\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1424\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1524\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1624\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 2, Batch number: 1724\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 2, Batch number: 1824\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 86\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 186\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 3, Batch number: 286\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 386\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 486\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 586\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 686\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 786\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 886\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 986\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1086\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1186\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1286\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1386\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1486\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1586\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1686\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 3, Batch number: 1786\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 4, Batch number: 48\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 4, Batch number: 148\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 4, Batch number: 248\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 4, Batch number: 348\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 448\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 548\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 648\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 748\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 848\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 948\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 1048\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 1148\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 1248\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 1348\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 1448\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 1548\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 4, Batch number: 1648\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 4, Batch number: 1748\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 5, Batch number: 10\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 5, Batch number: 110\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 5, Batch number: 210\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 310\n",
      "Accuracy on validation dataset: 1340/2400 (55.83%)\n",
      "\n",
      "Epoch: 5, Batch number: 410\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 510\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 610\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 710\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 810\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 910\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Batch number: 1010\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 1110\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 5, Batch number: 1210\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 5, Batch number: 1310\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 5, Batch number: 1410\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 5, Batch number: 1510\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 5, Batch number: 1610\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 5, Batch number: 1710\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 5, Batch number: 1810\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 6, Batch number: 72\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 6, Batch number: 172\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 6, Batch number: 272\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 372\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 472\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 6, Batch number: 572\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 672\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 772\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 872\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 972\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 1072\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 1172\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 1272\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 1372\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 1472\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 6, Batch number: 1572\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 6, Batch number: 1672\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 6, Batch number: 1772\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 34\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 7, Batch number: 134\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 7, Batch number: 234\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 7, Batch number: 334\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 434\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 534\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 634\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 7, Batch number: 734\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 834\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 934\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 1034\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 1134\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 7, Batch number: 1234\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 7, Batch number: 1334\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 7, Batch number: 1434\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 7, Batch number: 1534\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 7, Batch number: 1634\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 7, Batch number: 1734\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 7, Batch number: 1834\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 96\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 196\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 296\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 396\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 496\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 596\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 696\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 796\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 896\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 996\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1096\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1196\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1296\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1396\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1496\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1596\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1696\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 8, Batch number: 1796\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 9, Batch number: 58\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 9, Batch number: 158\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 9, Batch number: 258\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 9, Batch number: 358\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 9, Batch number: 458\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 9, Batch number: 558\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 658\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 758\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 9, Batch number: 858\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 958\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 1058\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 1158\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 1258\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 1358\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 1458\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 1558\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 9, Batch number: 1658\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 9, Batch number: 1758\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 10, Batch number: 20\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 10, Batch number: 120\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 10, Batch number: 220\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 10, Batch number: 320\n",
      "Accuracy on validation dataset: 1343/2400 (55.96%)\n",
      "\n",
      "Epoch: 10, Batch number: 420\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 10, Batch number: 520\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 10, Batch number: 620\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 10, Batch number: 720\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 10, Batch number: 820\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 10, Batch number: 920\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 10, Batch number: 1020\n",
      "Accuracy on validation dataset: 1341/2400 (55.88%)\n",
      "\n",
      "Epoch: 10, Batch number: 1120\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 10, Batch number: 1220\n",
      "Accuracy on validation dataset: 1342/2400 (55.92%)\n",
      "\n",
      "Epoch: 10, Batch number: 1320\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 10, Batch number: 1420\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 10, Batch number: 1520\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 10, Batch number: 1620\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 10, Batch number: 1720\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 10, Batch number: 1820\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 82\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Batch number: 182\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 282\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 382\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 482\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 582\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 682\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 782\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 882\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 982\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 1082\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 1182\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 11, Batch number: 1282\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 1382\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 1482\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 1582\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 1682\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 11, Batch number: 1782\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 44\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 12, Batch number: 144\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 244\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 344\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 444\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 544\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 644\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 744\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 844\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 944\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 12, Batch number: 1044\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 12, Batch number: 1144\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 12, Batch number: 1244\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 1344\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 1444\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 12, Batch number: 1544\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 1644\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 12, Batch number: 1744\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 6\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 106\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 206\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 306\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 406\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 506\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 606\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 706\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 806\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 906\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 1006\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 1106\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 1206\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 1306\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 1406\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 1506\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 13, Batch number: 1606\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 1706\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 13, Batch number: 1806\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 14, Batch number: 68\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 14, Batch number: 168\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 14, Batch number: 268\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 14, Batch number: 368\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 14, Batch number: 468\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 14, Batch number: 568\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 14, Batch number: 668\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 14, Batch number: 768\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 14, Batch number: 868\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 14, Batch number: 968\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 14, Batch number: 1068\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 14, Batch number: 1168\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 14, Batch number: 1268\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 14, Batch number: 1368\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 14, Batch number: 1468\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 14, Batch number: 1568\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 14, Batch number: 1668\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 14, Batch number: 1768\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 15, Batch number: 30\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 15, Batch number: 130\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 15, Batch number: 230\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 330\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 15, Batch number: 430\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 15, Batch number: 530\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 15, Batch number: 630\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 15, Batch number: 730\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 830\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 930\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1030\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1130\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1230\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1330\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1430\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1530\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1630\n",
      "Accuracy on validation dataset: 1349/2400 (56.21%)\n",
      "\n",
      "Epoch: 15, Batch number: 1730\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 15, Batch number: 1830\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 92\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 192\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 16, Batch number: 292\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 392\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 492\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 592\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 692\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 792\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 892\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 16, Batch number: 992\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Batch number: 1092\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 1192\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 1292\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 1392\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 1492\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 1592\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 1692\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 16, Batch number: 1792\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 17, Batch number: 54\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 17, Batch number: 154\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 17, Batch number: 254\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 17, Batch number: 354\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 17, Batch number: 454\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 17, Batch number: 554\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 17, Batch number: 654\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 17, Batch number: 754\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 17, Batch number: 854\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 17, Batch number: 954\n",
      "Accuracy on validation dataset: 1344/2400 (56.00%)\n",
      "\n",
      "Epoch: 17, Batch number: 1054\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 17, Batch number: 1154\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 17, Batch number: 1254\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 17, Batch number: 1354\n",
      "Accuracy on validation dataset: 1345/2400 (56.04%)\n",
      "\n",
      "Epoch: 17, Batch number: 1454\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 17, Batch number: 1554\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 17, Batch number: 1654\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 17, Batch number: 1754\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 16\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 18, Batch number: 116\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 216\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 18, Batch number: 316\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 18, Batch number: 416\n",
      "Accuracy on validation dataset: 1346/2400 (56.08%)\n",
      "\n",
      "Epoch: 18, Batch number: 516\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 616\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 716\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 18, Batch number: 816\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 916\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 1016\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 1116\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 18, Batch number: 1216\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 18, Batch number: 1316\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 1416\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 1516\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 1616\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 1716\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 18, Batch number: 1816\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 78\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 178\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 278\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 378\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 478\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 578\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 678\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 19, Batch number: 778\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 19, Batch number: 878\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 978\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 1078\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 1178\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 1278\n",
      "Accuracy on validation dataset: 1347/2400 (56.12%)\n",
      "\n",
      "Epoch: 19, Batch number: 1378\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 19, Batch number: 1478\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 19, Batch number: 1578\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 19, Batch number: 1678\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n",
      "Epoch: 19, Batch number: 1778\n",
      "Accuracy on validation dataset: 1348/2400 (56.17%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de las muestras:\n",
    "data = {\n",
    "    'use_gpu': True, # Trasladar o no las muestras a la GPU\n",
    "    'input_dtype': torch.float, # Tipo de dato de las muestras de entrada\n",
    "    'target_dtype': torch.long, # Tipo de dato de las muestras de salida\n",
    "    'train_dataloader': train_dataloader, # Dataset de entrenamiento\n",
    "    'val_dataloader': val_dataloader # Dataset de validación\n",
    "}\n",
    "\n",
    "# Parámetros de optimización:\n",
    "epochs = 20 # Cantidad de epochs\n",
    "sample_loss_every = 100 # Cantidad de iteraciones para calcular la cantidad de aciertos\n",
    "learning_rate = 1e-4 # Tasa de aprendizaje\n",
    "check_on_train = False # Queremos ver los resultados también en el train set\n",
    "\n",
    "# Entrenamiento:\n",
    "performance_history = SGDTrainModel(model, data, epochs, learning_rate, sample_loss_every, check_on_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
