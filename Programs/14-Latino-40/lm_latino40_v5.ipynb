{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from NLPUtils import *\n",
    "import re\n",
    "import fasttext\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./lm_files/lm_l40_bigram_train_test', 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "    lm_file = [line.decode('iso-8859-1') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el corpus de entrenamiento:\n",
    "with open('trainLM2.txt', 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "    corpus = [['<s>'] + line.decode('iso-8859-1').split(' ')[:-1] + ['</s>'] for line in lines]\n",
    "    \n",
    "corpus = [[token for doc in corpus for token in doc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec trainer created:\n",
      "Window size: 2\n",
      "Number of samples: 48612\n",
      "Vocabulary Size: 5924\n",
      "Number of batches: 95\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n",
      "Dimensi√≥n del espacio de los embeddings: 200\n",
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 150\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 4481.419921875\n",
      "Epoch: 1, Batch number: 10, Loss: 4398.90380859375\n",
      "Epoch: 1, Batch number: 20, Loss: 4332.87255859375\n",
      "Epoch: 1, Batch number: 30, Loss: 4261.369140625\n",
      "Epoch: 1, Batch number: 40, Loss: 4223.4384765625\n",
      "Epoch: 1, Batch number: 50, Loss: 4184.0712890625\n",
      "Epoch: 1, Batch number: 60, Loss: 4089.766357421875\n",
      "Epoch: 1, Batch number: 70, Loss: 4044.928466796875\n",
      "Epoch: 1, Batch number: 80, Loss: 3926.794677734375\n",
      "Epoch: 1, Batch number: 90, Loss: 3919.951416015625\n",
      "Epoch: 2, Batch number: 5, Loss: 3797.621826171875\n",
      "Epoch: 2, Batch number: 15, Loss: 3762.408447265625\n",
      "Epoch: 2, Batch number: 25, Loss: 3662.30517578125\n",
      "Epoch: 2, Batch number: 35, Loss: 3607.469970703125\n",
      "Epoch: 2, Batch number: 45, Loss: 3578.947509765625\n",
      "Epoch: 2, Batch number: 55, Loss: 3512.290771484375\n",
      "Epoch: 2, Batch number: 65, Loss: 3457.19677734375\n",
      "Epoch: 2, Batch number: 75, Loss: 3495.656005859375\n",
      "Epoch: 2, Batch number: 85, Loss: 3353.70556640625\n",
      "Epoch: 3, Batch number: 0, Loss: 3251.78369140625\n",
      "Epoch: 3, Batch number: 10, Loss: 3285.39208984375\n",
      "Epoch: 3, Batch number: 20, Loss: 3103.601806640625\n",
      "Epoch: 3, Batch number: 30, Loss: 3195.732177734375\n",
      "Epoch: 3, Batch number: 40, Loss: 3187.693603515625\n",
      "Epoch: 3, Batch number: 50, Loss: 3090.312255859375\n",
      "Epoch: 3, Batch number: 60, Loss: 3094.427001953125\n",
      "Epoch: 3, Batch number: 70, Loss: 3068.009033203125\n",
      "Epoch: 3, Batch number: 80, Loss: 3092.90869140625\n",
      "Epoch: 3, Batch number: 90, Loss: 2995.54736328125\n",
      "Epoch: 4, Batch number: 5, Loss: 3034.308837890625\n",
      "Epoch: 4, Batch number: 15, Loss: 2823.5185546875\n",
      "Epoch: 4, Batch number: 25, Loss: 2897.078857421875\n",
      "Epoch: 4, Batch number: 35, Loss: 2938.271728515625\n",
      "Epoch: 4, Batch number: 45, Loss: 2811.190185546875\n",
      "Epoch: 4, Batch number: 55, Loss: 2874.88720703125\n",
      "Epoch: 4, Batch number: 65, Loss: 2903.5322265625\n",
      "Epoch: 4, Batch number: 75, Loss: 2946.463134765625\n",
      "Epoch: 4, Batch number: 85, Loss: 2853.642578125\n",
      "Epoch: 5, Batch number: 0, Loss: 2806.558349609375\n",
      "Epoch: 5, Batch number: 10, Loss: 2864.37109375\n",
      "Epoch: 5, Batch number: 20, Loss: 2771.464111328125\n",
      "Epoch: 5, Batch number: 30, Loss: 2730.29296875\n",
      "Epoch: 5, Batch number: 40, Loss: 2691.03173828125\n",
      "Epoch: 5, Batch number: 50, Loss: 2698.716796875\n",
      "Epoch: 5, Batch number: 60, Loss: 2708.662841796875\n",
      "Epoch: 5, Batch number: 70, Loss: 2810.310546875\n",
      "Epoch: 5, Batch number: 80, Loss: 2656.431640625\n",
      "Epoch: 5, Batch number: 90, Loss: 2764.09814453125\n",
      "Epoch: 6, Batch number: 5, Loss: 2622.80224609375\n",
      "Epoch: 6, Batch number: 15, Loss: 2663.49462890625\n",
      "Epoch: 6, Batch number: 25, Loss: 2596.86083984375\n",
      "Epoch: 6, Batch number: 35, Loss: 2634.93359375\n",
      "Epoch: 6, Batch number: 45, Loss: 2645.15625\n",
      "Epoch: 6, Batch number: 55, Loss: 2548.515869140625\n",
      "Epoch: 6, Batch number: 65, Loss: 2629.99462890625\n",
      "Epoch: 6, Batch number: 75, Loss: 2663.090087890625\n",
      "Epoch: 6, Batch number: 85, Loss: 2609.075439453125\n",
      "Epoch: 7, Batch number: 0, Loss: 2559.627685546875\n",
      "Epoch: 7, Batch number: 10, Loss: 2590.843017578125\n",
      "Epoch: 7, Batch number: 20, Loss: 2455.912353515625\n",
      "Epoch: 7, Batch number: 30, Loss: 2553.083251953125\n",
      "Epoch: 7, Batch number: 40, Loss: 2505.526123046875\n",
      "Epoch: 7, Batch number: 50, Loss: 2556.0830078125\n",
      "Epoch: 7, Batch number: 60, Loss: 2466.557861328125\n",
      "Epoch: 7, Batch number: 70, Loss: 2487.202392578125\n",
      "Epoch: 7, Batch number: 80, Loss: 2430.99072265625\n",
      "Epoch: 7, Batch number: 90, Loss: 2398.00732421875\n",
      "Epoch: 8, Batch number: 5, Loss: 2461.150146484375\n",
      "Epoch: 8, Batch number: 15, Loss: 2482.7119140625\n",
      "Epoch: 8, Batch number: 25, Loss: 2455.805908203125\n",
      "Epoch: 8, Batch number: 35, Loss: 2475.528564453125\n",
      "Epoch: 8, Batch number: 45, Loss: 2485.2978515625\n",
      "Epoch: 8, Batch number: 55, Loss: 2436.5732421875\n",
      "Epoch: 8, Batch number: 65, Loss: 2491.9033203125\n",
      "Epoch: 8, Batch number: 75, Loss: 2468.76123046875\n",
      "Epoch: 8, Batch number: 85, Loss: 2415.66357421875\n",
      "Epoch: 9, Batch number: 0, Loss: 2368.5751953125\n",
      "Epoch: 9, Batch number: 10, Loss: 2418.906005859375\n",
      "Epoch: 9, Batch number: 20, Loss: 2338.876220703125\n",
      "Epoch: 9, Batch number: 30, Loss: 2380.694580078125\n",
      "Epoch: 9, Batch number: 40, Loss: 2354.3056640625\n",
      "Epoch: 9, Batch number: 50, Loss: 2465.233642578125\n",
      "Epoch: 9, Batch number: 60, Loss: 2299.777587890625\n",
      "Epoch: 9, Batch number: 70, Loss: 2343.354736328125\n",
      "Epoch: 9, Batch number: 80, Loss: 2367.74560546875\n",
      "Epoch: 9, Batch number: 90, Loss: 2331.69873046875\n",
      "Epoch: 10, Batch number: 5, Loss: 2247.73046875\n",
      "Epoch: 10, Batch number: 15, Loss: 2184.949951171875\n",
      "Epoch: 10, Batch number: 25, Loss: 2247.22216796875\n",
      "Epoch: 10, Batch number: 35, Loss: 2194.05615234375\n",
      "Epoch: 10, Batch number: 45, Loss: 2309.39599609375\n",
      "Epoch: 10, Batch number: 55, Loss: 2199.409423828125\n",
      "Epoch: 10, Batch number: 65, Loss: 2252.7841796875\n",
      "Epoch: 10, Batch number: 75, Loss: 2246.390380859375\n",
      "Epoch: 10, Batch number: 85, Loss: 2196.358154296875\n",
      "Epoch: 11, Batch number: 0, Loss: 2142.16552734375\n",
      "Epoch: 11, Batch number: 10, Loss: 2186.024169921875\n",
      "Epoch: 11, Batch number: 20, Loss: 2188.982177734375\n",
      "Epoch: 11, Batch number: 30, Loss: 2191.54052734375\n",
      "Epoch: 11, Batch number: 40, Loss: 2129.742919921875\n",
      "Epoch: 11, Batch number: 50, Loss: 2201.029541015625\n",
      "Epoch: 11, Batch number: 60, Loss: 2161.55615234375\n",
      "Epoch: 11, Batch number: 70, Loss: 2153.125\n",
      "Epoch: 11, Batch number: 80, Loss: 2149.76123046875\n",
      "Epoch: 11, Batch number: 90, Loss: 2061.3779296875\n",
      "Epoch: 12, Batch number: 5, Loss: 2118.26611328125\n",
      "Epoch: 12, Batch number: 15, Loss: 1943.610595703125\n",
      "Epoch: 12, Batch number: 25, Loss: 2084.7236328125\n",
      "Epoch: 12, Batch number: 35, Loss: 2104.999755859375\n",
      "Epoch: 12, Batch number: 45, Loss: 2062.180419921875\n",
      "Epoch: 12, Batch number: 55, Loss: 2106.735595703125\n",
      "Epoch: 12, Batch number: 65, Loss: 2013.89599609375\n",
      "Epoch: 12, Batch number: 75, Loss: 2041.34619140625\n",
      "Epoch: 12, Batch number: 85, Loss: 2101.221923828125\n",
      "Epoch: 13, Batch number: 0, Loss: 1917.0272216796875\n",
      "Epoch: 13, Batch number: 10, Loss: 1981.143798828125\n",
      "Epoch: 13, Batch number: 20, Loss: 1987.9700927734375\n",
      "Epoch: 13, Batch number: 30, Loss: 1947.098876953125\n",
      "Epoch: 13, Batch number: 40, Loss: 1985.1912841796875\n",
      "Epoch: 13, Batch number: 50, Loss: 1914.2882080078125\n",
      "Epoch: 13, Batch number: 60, Loss: 2016.4974365234375\n",
      "Epoch: 13, Batch number: 70, Loss: 1972.1951904296875\n",
      "Epoch: 13, Batch number: 80, Loss: 1969.4747314453125\n",
      "Epoch: 13, Batch number: 90, Loss: 1951.5576171875\n",
      "Epoch: 14, Batch number: 5, Loss: 1932.714111328125\n",
      "Epoch: 14, Batch number: 15, Loss: 1919.86669921875\n",
      "Epoch: 14, Batch number: 25, Loss: 1882.5003662109375\n",
      "Epoch: 14, Batch number: 35, Loss: 1870.498046875\n",
      "Epoch: 14, Batch number: 45, Loss: 1960.8087158203125\n",
      "Epoch: 14, Batch number: 55, Loss: 1944.1444091796875\n",
      "Epoch: 14, Batch number: 65, Loss: 1886.9971923828125\n",
      "Epoch: 14, Batch number: 75, Loss: 1935.57275390625\n",
      "Epoch: 14, Batch number: 85, Loss: 1851.241943359375\n",
      "Epoch: 15, Batch number: 0, Loss: 1851.026611328125\n",
      "Epoch: 15, Batch number: 10, Loss: 1827.803466796875\n",
      "Epoch: 15, Batch number: 20, Loss: 1782.972900390625\n",
      "Epoch: 15, Batch number: 30, Loss: 1814.01220703125\n",
      "Epoch: 15, Batch number: 40, Loss: 1763.9970703125\n",
      "Epoch: 15, Batch number: 50, Loss: 1822.0155029296875\n",
      "Epoch: 15, Batch number: 60, Loss: 1858.2801513671875\n",
      "Epoch: 15, Batch number: 70, Loss: 1893.14990234375\n",
      "Epoch: 15, Batch number: 80, Loss: 1834.214111328125\n",
      "Epoch: 15, Batch number: 90, Loss: 1872.5260009765625\n",
      "Epoch: 16, Batch number: 5, Loss: 1726.28173828125\n",
      "Epoch: 16, Batch number: 15, Loss: 1845.1375732421875\n",
      "Epoch: 16, Batch number: 25, Loss: 1753.025146484375\n",
      "Epoch: 16, Batch number: 35, Loss: 1801.138427734375\n",
      "Epoch: 16, Batch number: 45, Loss: 1771.599853515625\n",
      "Epoch: 16, Batch number: 55, Loss: 1771.4146728515625\n",
      "Epoch: 16, Batch number: 65, Loss: 1706.658203125\n",
      "Epoch: 16, Batch number: 75, Loss: 1706.08740234375\n",
      "Epoch: 16, Batch number: 85, Loss: 1640.0018310546875\n",
      "Epoch: 17, Batch number: 0, Loss: 1682.7635498046875\n",
      "Epoch: 17, Batch number: 10, Loss: 1748.8377685546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Batch number: 20, Loss: 1666.8836669921875\n",
      "Epoch: 17, Batch number: 30, Loss: 1608.8472900390625\n",
      "Epoch: 17, Batch number: 40, Loss: 1664.707275390625\n",
      "Epoch: 17, Batch number: 50, Loss: 1709.962646484375\n",
      "Epoch: 17, Batch number: 60, Loss: 1697.89013671875\n",
      "Epoch: 17, Batch number: 70, Loss: 1663.6888427734375\n",
      "Epoch: 17, Batch number: 80, Loss: 1692.8197021484375\n",
      "Epoch: 17, Batch number: 90, Loss: 1714.5582275390625\n",
      "Epoch: 18, Batch number: 5, Loss: 1601.245849609375\n",
      "Epoch: 18, Batch number: 15, Loss: 1572.0306396484375\n",
      "Epoch: 18, Batch number: 25, Loss: 1599.45947265625\n",
      "Epoch: 18, Batch number: 35, Loss: 1614.9327392578125\n",
      "Epoch: 18, Batch number: 45, Loss: 1590.056396484375\n",
      "Epoch: 18, Batch number: 55, Loss: 1596.841064453125\n",
      "Epoch: 18, Batch number: 65, Loss: 1601.8326416015625\n",
      "Epoch: 18, Batch number: 75, Loss: 1634.8297119140625\n",
      "Epoch: 18, Batch number: 85, Loss: 1564.9439697265625\n",
      "Epoch: 19, Batch number: 0, Loss: 1529.739013671875\n",
      "Epoch: 19, Batch number: 10, Loss: 1548.29931640625\n",
      "Epoch: 19, Batch number: 20, Loss: 1539.5780029296875\n",
      "Epoch: 19, Batch number: 30, Loss: 1471.376220703125\n",
      "Epoch: 19, Batch number: 40, Loss: 1545.2060546875\n",
      "Epoch: 19, Batch number: 50, Loss: 1515.9150390625\n",
      "Epoch: 19, Batch number: 60, Loss: 1547.7113037109375\n",
      "Epoch: 19, Batch number: 70, Loss: 1607.967529296875\n",
      "Epoch: 19, Batch number: 80, Loss: 1505.4488525390625\n",
      "Epoch: 19, Batch number: 90, Loss: 1564.1259765625\n",
      "Epoch: 20, Batch number: 5, Loss: 1534.222900390625\n",
      "Epoch: 20, Batch number: 15, Loss: 1463.4964599609375\n",
      "Epoch: 20, Batch number: 25, Loss: 1495.640869140625\n",
      "Epoch: 20, Batch number: 35, Loss: 1449.74169921875\n",
      "Epoch: 20, Batch number: 45, Loss: 1519.265869140625\n",
      "Epoch: 20, Batch number: 55, Loss: 1500.0831298828125\n",
      "Epoch: 20, Batch number: 65, Loss: 1485.444580078125\n",
      "Epoch: 20, Batch number: 75, Loss: 1506.4068603515625\n",
      "Epoch: 20, Batch number: 85, Loss: 1448.965576171875\n",
      "Epoch: 21, Batch number: 0, Loss: 1392.940185546875\n",
      "Epoch: 21, Batch number: 10, Loss: 1486.9005126953125\n",
      "Epoch: 21, Batch number: 20, Loss: 1421.4049072265625\n",
      "Epoch: 21, Batch number: 30, Loss: 1474.1368408203125\n",
      "Epoch: 21, Batch number: 40, Loss: 1476.070556640625\n",
      "Epoch: 21, Batch number: 50, Loss: 1472.0421142578125\n",
      "Epoch: 21, Batch number: 60, Loss: 1428.2254638671875\n",
      "Epoch: 21, Batch number: 70, Loss: 1457.4139404296875\n",
      "Epoch: 21, Batch number: 80, Loss: 1418.289794921875\n",
      "Epoch: 21, Batch number: 90, Loss: 1435.6558837890625\n",
      "Epoch: 22, Batch number: 5, Loss: 1350.188720703125\n",
      "Epoch: 22, Batch number: 15, Loss: 1329.955322265625\n",
      "Epoch: 22, Batch number: 25, Loss: 1355.4766845703125\n",
      "Epoch: 22, Batch number: 35, Loss: 1327.5338134765625\n",
      "Epoch: 22, Batch number: 45, Loss: 1397.0936279296875\n",
      "Epoch: 22, Batch number: 55, Loss: 1350.1575927734375\n",
      "Epoch: 22, Batch number: 65, Loss: 1391.171630859375\n",
      "Epoch: 22, Batch number: 75, Loss: 1272.745849609375\n",
      "Epoch: 22, Batch number: 85, Loss: 1374.7357177734375\n",
      "Epoch: 23, Batch number: 0, Loss: 1296.623779296875\n",
      "Epoch: 23, Batch number: 10, Loss: 1373.212158203125\n",
      "Epoch: 23, Batch number: 20, Loss: 1347.0399169921875\n",
      "Epoch: 23, Batch number: 30, Loss: 1202.06640625\n",
      "Epoch: 23, Batch number: 40, Loss: 1308.1375732421875\n",
      "Epoch: 23, Batch number: 50, Loss: 1339.0450439453125\n",
      "Epoch: 23, Batch number: 60, Loss: 1289.8778076171875\n",
      "Epoch: 23, Batch number: 70, Loss: 1315.740478515625\n",
      "Epoch: 23, Batch number: 80, Loss: 1411.3551025390625\n",
      "Epoch: 23, Batch number: 90, Loss: 1291.45751953125\n",
      "Epoch: 24, Batch number: 5, Loss: 1265.32666015625\n",
      "Epoch: 24, Batch number: 15, Loss: 1194.8896484375\n",
      "Epoch: 24, Batch number: 25, Loss: 1335.9703369140625\n",
      "Epoch: 24, Batch number: 35, Loss: 1247.51513671875\n",
      "Epoch: 24, Batch number: 45, Loss: 1301.75439453125\n",
      "Epoch: 24, Batch number: 55, Loss: 1309.277587890625\n",
      "Epoch: 24, Batch number: 65, Loss: 1349.65966796875\n",
      "Epoch: 24, Batch number: 75, Loss: 1193.07177734375\n",
      "Epoch: 24, Batch number: 85, Loss: 1286.9345703125\n",
      "Epoch: 25, Batch number: 0, Loss: 1180.13916015625\n",
      "Epoch: 25, Batch number: 10, Loss: 1156.5980224609375\n",
      "Epoch: 25, Batch number: 20, Loss: 1256.5517578125\n",
      "Epoch: 25, Batch number: 30, Loss: 1282.518310546875\n",
      "Epoch: 25, Batch number: 40, Loss: 1237.026123046875\n",
      "Epoch: 25, Batch number: 50, Loss: 1191.70068359375\n",
      "Epoch: 25, Batch number: 60, Loss: 1261.952880859375\n",
      "Epoch: 25, Batch number: 70, Loss: 1303.068359375\n",
      "Epoch: 25, Batch number: 80, Loss: 1198.99462890625\n",
      "Epoch: 25, Batch number: 90, Loss: 1206.77685546875\n",
      "Epoch: 26, Batch number: 5, Loss: 1220.262939453125\n",
      "Epoch: 26, Batch number: 15, Loss: 1174.8428955078125\n",
      "Epoch: 26, Batch number: 25, Loss: 1145.955322265625\n",
      "Epoch: 26, Batch number: 35, Loss: 1234.052490234375\n",
      "Epoch: 26, Batch number: 45, Loss: 1144.2728271484375\n",
      "Epoch: 26, Batch number: 55, Loss: 1222.49462890625\n",
      "Epoch: 26, Batch number: 65, Loss: 1307.738037109375\n",
      "Epoch: 26, Batch number: 75, Loss: 1199.4132080078125\n",
      "Epoch: 26, Batch number: 85, Loss: 1117.86083984375\n",
      "Epoch: 27, Batch number: 0, Loss: 1233.021728515625\n",
      "Epoch: 27, Batch number: 10, Loss: 1146.4869384765625\n",
      "Epoch: 27, Batch number: 20, Loss: 1143.14111328125\n",
      "Epoch: 27, Batch number: 30, Loss: 1176.6192626953125\n",
      "Epoch: 27, Batch number: 40, Loss: 1108.017822265625\n",
      "Epoch: 27, Batch number: 50, Loss: 1140.1256103515625\n",
      "Epoch: 27, Batch number: 60, Loss: 1163.64892578125\n",
      "Epoch: 27, Batch number: 70, Loss: 1117.587890625\n",
      "Epoch: 27, Batch number: 80, Loss: 1147.15625\n",
      "Epoch: 27, Batch number: 90, Loss: 1140.535400390625\n",
      "Epoch: 28, Batch number: 5, Loss: 1145.445068359375\n",
      "Epoch: 28, Batch number: 15, Loss: 1089.7855224609375\n",
      "Epoch: 28, Batch number: 25, Loss: 1149.564208984375\n",
      "Epoch: 28, Batch number: 35, Loss: 1141.896728515625\n",
      "Epoch: 28, Batch number: 45, Loss: 1139.75537109375\n",
      "Epoch: 28, Batch number: 55, Loss: 1059.2332763671875\n",
      "Epoch: 28, Batch number: 65, Loss: 1086.9998779296875\n",
      "Epoch: 28, Batch number: 75, Loss: 1040.244140625\n",
      "Epoch: 28, Batch number: 85, Loss: 1111.22021484375\n",
      "Epoch: 29, Batch number: 0, Loss: 1059.3720703125\n",
      "Epoch: 29, Batch number: 10, Loss: 1089.489990234375\n",
      "Epoch: 29, Batch number: 20, Loss: 1082.30078125\n",
      "Epoch: 29, Batch number: 30, Loss: 1188.66259765625\n",
      "Epoch: 29, Batch number: 40, Loss: 1046.344970703125\n",
      "Epoch: 29, Batch number: 50, Loss: 1120.75732421875\n",
      "Epoch: 29, Batch number: 60, Loss: 1054.2777099609375\n",
      "Epoch: 29, Batch number: 70, Loss: 1088.7874755859375\n",
      "Epoch: 29, Batch number: 80, Loss: 1093.2274169921875\n",
      "Epoch: 29, Batch number: 90, Loss: 1079.922119140625\n",
      "Epoch: 30, Batch number: 5, Loss: 1091.50732421875\n",
      "Epoch: 30, Batch number: 15, Loss: 1054.152099609375\n",
      "Epoch: 30, Batch number: 25, Loss: 1010.0513305664062\n",
      "Epoch: 30, Batch number: 35, Loss: 1049.9122314453125\n",
      "Epoch: 30, Batch number: 45, Loss: 972.8041381835938\n",
      "Epoch: 30, Batch number: 55, Loss: 1052.289794921875\n",
      "Epoch: 30, Batch number: 65, Loss: 1061.812744140625\n",
      "Epoch: 30, Batch number: 75, Loss: 983.6334838867188\n",
      "Epoch: 30, Batch number: 85, Loss: 1009.9912109375\n",
      "Epoch: 31, Batch number: 0, Loss: 1037.308837890625\n",
      "Epoch: 31, Batch number: 10, Loss: 1041.3309326171875\n",
      "Epoch: 31, Batch number: 20, Loss: 983.3663330078125\n",
      "Epoch: 31, Batch number: 30, Loss: 1080.2181396484375\n",
      "Epoch: 31, Batch number: 40, Loss: 985.9338989257812\n",
      "Epoch: 31, Batch number: 50, Loss: 1001.2140502929688\n",
      "Epoch: 31, Batch number: 60, Loss: 1050.350830078125\n",
      "Epoch: 31, Batch number: 70, Loss: 1005.5968627929688\n",
      "Epoch: 31, Batch number: 80, Loss: 999.4380493164062\n",
      "Epoch: 31, Batch number: 90, Loss: 1070.7786865234375\n",
      "Epoch: 32, Batch number: 5, Loss: 954.1781005859375\n",
      "Epoch: 32, Batch number: 15, Loss: 977.485107421875\n",
      "Epoch: 32, Batch number: 25, Loss: 972.5723266601562\n",
      "Epoch: 32, Batch number: 35, Loss: 935.97900390625\n",
      "Epoch: 32, Batch number: 45, Loss: 956.3379516601562\n",
      "Epoch: 32, Batch number: 55, Loss: 1004.3367919921875\n",
      "Epoch: 32, Batch number: 65, Loss: 972.3722534179688\n",
      "Epoch: 32, Batch number: 75, Loss: 949.4041748046875\n",
      "Epoch: 32, Batch number: 85, Loss: 1024.3388671875\n",
      "Epoch: 33, Batch number: 0, Loss: 922.9949951171875\n",
      "Epoch: 33, Batch number: 10, Loss: 927.2949829101562\n",
      "Epoch: 33, Batch number: 20, Loss: 978.5935668945312\n",
      "Epoch: 33, Batch number: 30, Loss: 975.875244140625\n",
      "Epoch: 33, Batch number: 40, Loss: 940.4298095703125\n",
      "Epoch: 33, Batch number: 50, Loss: 933.055419921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Batch number: 60, Loss: 979.3488159179688\n",
      "Epoch: 33, Batch number: 70, Loss: 975.594482421875\n",
      "Epoch: 33, Batch number: 80, Loss: 971.830078125\n",
      "Epoch: 33, Batch number: 90, Loss: 949.1182861328125\n",
      "Epoch: 34, Batch number: 5, Loss: 913.739501953125\n",
      "Epoch: 34, Batch number: 15, Loss: 976.4524536132812\n",
      "Epoch: 34, Batch number: 25, Loss: 898.6556396484375\n",
      "Epoch: 34, Batch number: 35, Loss: 870.7490234375\n",
      "Epoch: 34, Batch number: 45, Loss: 874.5230102539062\n",
      "Epoch: 34, Batch number: 55, Loss: 1005.0233154296875\n",
      "Epoch: 34, Batch number: 65, Loss: 887.2300415039062\n",
      "Epoch: 34, Batch number: 75, Loss: 972.0214233398438\n",
      "Epoch: 34, Batch number: 85, Loss: 896.2972412109375\n",
      "Epoch: 35, Batch number: 0, Loss: 891.077392578125\n",
      "Epoch: 35, Batch number: 10, Loss: 869.8419799804688\n",
      "Epoch: 35, Batch number: 20, Loss: 914.8162841796875\n",
      "Epoch: 35, Batch number: 30, Loss: 941.7435302734375\n",
      "Epoch: 35, Batch number: 40, Loss: 884.0603637695312\n",
      "Epoch: 35, Batch number: 50, Loss: 998.3129272460938\n",
      "Epoch: 35, Batch number: 60, Loss: 871.0999755859375\n",
      "Epoch: 35, Batch number: 70, Loss: 880.0732421875\n",
      "Epoch: 35, Batch number: 80, Loss: 871.3333129882812\n",
      "Epoch: 35, Batch number: 90, Loss: 909.0072021484375\n",
      "Epoch: 36, Batch number: 5, Loss: 837.83544921875\n",
      "Epoch: 36, Batch number: 15, Loss: 979.8521118164062\n",
      "Epoch: 36, Batch number: 25, Loss: 823.6859741210938\n",
      "Epoch: 36, Batch number: 35, Loss: 849.9198608398438\n",
      "Epoch: 36, Batch number: 45, Loss: 821.9852905273438\n",
      "Epoch: 36, Batch number: 55, Loss: 892.3895874023438\n",
      "Epoch: 36, Batch number: 65, Loss: 844.4561157226562\n",
      "Epoch: 36, Batch number: 75, Loss: 848.4043579101562\n",
      "Epoch: 36, Batch number: 85, Loss: 810.4678955078125\n",
      "Epoch: 37, Batch number: 0, Loss: 863.6231689453125\n",
      "Epoch: 37, Batch number: 10, Loss: 839.26220703125\n",
      "Epoch: 37, Batch number: 20, Loss: 872.3709716796875\n",
      "Epoch: 37, Batch number: 30, Loss: 922.067138671875\n",
      "Epoch: 37, Batch number: 40, Loss: 792.0048217773438\n",
      "Epoch: 37, Batch number: 50, Loss: 832.6427001953125\n",
      "Epoch: 37, Batch number: 60, Loss: 785.5713500976562\n",
      "Epoch: 37, Batch number: 70, Loss: 841.4688720703125\n",
      "Epoch: 37, Batch number: 80, Loss: 862.4821166992188\n",
      "Epoch: 37, Batch number: 90, Loss: 857.7255859375\n",
      "Epoch: 38, Batch number: 5, Loss: 774.9287719726562\n",
      "Epoch: 38, Batch number: 15, Loss: 806.1552734375\n",
      "Epoch: 38, Batch number: 25, Loss: 755.4189453125\n",
      "Epoch: 38, Batch number: 35, Loss: 853.968017578125\n",
      "Epoch: 38, Batch number: 45, Loss: 854.39453125\n",
      "Epoch: 38, Batch number: 55, Loss: 771.206787109375\n",
      "Epoch: 38, Batch number: 65, Loss: 832.679443359375\n",
      "Epoch: 38, Batch number: 75, Loss: 871.8793334960938\n",
      "Epoch: 38, Batch number: 85, Loss: 814.2911376953125\n",
      "Epoch: 39, Batch number: 0, Loss: 813.184326171875\n",
      "Epoch: 39, Batch number: 10, Loss: 764.6610107421875\n",
      "Epoch: 39, Batch number: 20, Loss: 775.7001953125\n",
      "Epoch: 39, Batch number: 30, Loss: 762.0755615234375\n",
      "Epoch: 39, Batch number: 40, Loss: 859.80810546875\n",
      "Epoch: 39, Batch number: 50, Loss: 788.6893310546875\n",
      "Epoch: 39, Batch number: 60, Loss: 851.2957763671875\n",
      "Epoch: 39, Batch number: 70, Loss: 797.8533935546875\n",
      "Epoch: 39, Batch number: 80, Loss: 838.0826416015625\n",
      "Epoch: 39, Batch number: 90, Loss: 720.68798828125\n",
      "Epoch: 40, Batch number: 5, Loss: 770.7073364257812\n",
      "Epoch: 40, Batch number: 15, Loss: 780.3509521484375\n",
      "Epoch: 40, Batch number: 25, Loss: 718.3822631835938\n",
      "Epoch: 40, Batch number: 35, Loss: 806.7239990234375\n",
      "Epoch: 40, Batch number: 45, Loss: 713.4673461914062\n",
      "Epoch: 40, Batch number: 55, Loss: 778.3641967773438\n",
      "Epoch: 40, Batch number: 65, Loss: 755.8519287109375\n",
      "Epoch: 40, Batch number: 75, Loss: 770.5282592773438\n",
      "Epoch: 40, Batch number: 85, Loss: 778.3412475585938\n",
      "Epoch: 41, Batch number: 0, Loss: 726.4862670898438\n",
      "Epoch: 41, Batch number: 10, Loss: 766.2158203125\n",
      "Epoch: 41, Batch number: 20, Loss: 707.8705444335938\n",
      "Epoch: 41, Batch number: 30, Loss: 801.6309814453125\n",
      "Epoch: 41, Batch number: 40, Loss: 759.944580078125\n",
      "Epoch: 41, Batch number: 50, Loss: 724.4356689453125\n",
      "Epoch: 41, Batch number: 60, Loss: 718.953857421875\n",
      "Epoch: 41, Batch number: 70, Loss: 715.8519897460938\n",
      "Epoch: 41, Batch number: 80, Loss: 754.1246337890625\n",
      "Epoch: 41, Batch number: 90, Loss: 775.1864013671875\n",
      "Epoch: 42, Batch number: 5, Loss: 765.6890869140625\n",
      "Epoch: 42, Batch number: 15, Loss: 691.109130859375\n",
      "Epoch: 42, Batch number: 25, Loss: 803.800537109375\n",
      "Epoch: 42, Batch number: 35, Loss: 741.5116577148438\n",
      "Epoch: 42, Batch number: 45, Loss: 765.733154296875\n",
      "Epoch: 42, Batch number: 55, Loss: 679.2642822265625\n",
      "Epoch: 42, Batch number: 65, Loss: 713.9601440429688\n",
      "Epoch: 42, Batch number: 75, Loss: 771.9190673828125\n",
      "Epoch: 42, Batch number: 85, Loss: 682.1395263671875\n",
      "Epoch: 43, Batch number: 0, Loss: 690.5508422851562\n",
      "Epoch: 43, Batch number: 10, Loss: 741.4375610351562\n",
      "Epoch: 43, Batch number: 20, Loss: 721.657470703125\n",
      "Epoch: 43, Batch number: 30, Loss: 753.664306640625\n",
      "Epoch: 43, Batch number: 40, Loss: 659.6871337890625\n",
      "Epoch: 43, Batch number: 50, Loss: 683.506591796875\n",
      "Epoch: 43, Batch number: 60, Loss: 709.9453735351562\n",
      "Epoch: 43, Batch number: 70, Loss: 689.0638427734375\n",
      "Epoch: 43, Batch number: 80, Loss: 757.911865234375\n",
      "Epoch: 43, Batch number: 90, Loss: 662.3693237304688\n",
      "Epoch: 44, Batch number: 5, Loss: 713.1754150390625\n",
      "Epoch: 44, Batch number: 15, Loss: 713.7522583007812\n",
      "Epoch: 44, Batch number: 25, Loss: 696.2769165039062\n",
      "Epoch: 44, Batch number: 35, Loss: 631.7611694335938\n",
      "Epoch: 44, Batch number: 45, Loss: 691.2359008789062\n",
      "Epoch: 44, Batch number: 55, Loss: 627.8975219726562\n",
      "Epoch: 44, Batch number: 65, Loss: 659.4402465820312\n",
      "Epoch: 44, Batch number: 75, Loss: 698.8261108398438\n",
      "Epoch: 44, Batch number: 85, Loss: 697.1416015625\n",
      "Epoch: 45, Batch number: 0, Loss: 639.8568115234375\n",
      "Epoch: 45, Batch number: 10, Loss: 659.7853393554688\n",
      "Epoch: 45, Batch number: 20, Loss: 632.5409545898438\n",
      "Epoch: 45, Batch number: 30, Loss: 613.3070068359375\n",
      "Epoch: 45, Batch number: 40, Loss: 666.4729614257812\n",
      "Epoch: 45, Batch number: 50, Loss: 644.8311767578125\n",
      "Epoch: 45, Batch number: 60, Loss: 610.0656127929688\n",
      "Epoch: 45, Batch number: 70, Loss: 707.878662109375\n",
      "Epoch: 45, Batch number: 80, Loss: 692.7186889648438\n",
      "Epoch: 45, Batch number: 90, Loss: 696.9549560546875\n",
      "Epoch: 46, Batch number: 5, Loss: 625.322021484375\n",
      "Epoch: 46, Batch number: 15, Loss: 653.0497436523438\n",
      "Epoch: 46, Batch number: 25, Loss: 568.8267211914062\n",
      "Epoch: 46, Batch number: 35, Loss: 647.5552978515625\n",
      "Epoch: 46, Batch number: 45, Loss: 671.1453247070312\n",
      "Epoch: 46, Batch number: 55, Loss: 678.9659423828125\n",
      "Epoch: 46, Batch number: 65, Loss: 665.4702758789062\n",
      "Epoch: 46, Batch number: 75, Loss: 695.9042358398438\n",
      "Epoch: 46, Batch number: 85, Loss: 718.3756713867188\n",
      "Epoch: 47, Batch number: 0, Loss: 617.8424072265625\n",
      "Epoch: 47, Batch number: 10, Loss: 606.0262451171875\n",
      "Epoch: 47, Batch number: 20, Loss: 629.951904296875\n",
      "Epoch: 47, Batch number: 30, Loss: 651.5016479492188\n",
      "Epoch: 47, Batch number: 40, Loss: 691.9430541992188\n",
      "Epoch: 47, Batch number: 50, Loss: 653.8651733398438\n",
      "Epoch: 47, Batch number: 60, Loss: 624.8614501953125\n",
      "Epoch: 47, Batch number: 70, Loss: 600.8872680664062\n",
      "Epoch: 47, Batch number: 80, Loss: 582.6808471679688\n",
      "Epoch: 47, Batch number: 90, Loss: 706.1641845703125\n",
      "Epoch: 48, Batch number: 5, Loss: 605.3084106445312\n",
      "Epoch: 48, Batch number: 15, Loss: 657.6808471679688\n",
      "Epoch: 48, Batch number: 25, Loss: 592.6549682617188\n",
      "Epoch: 48, Batch number: 35, Loss: 649.5588989257812\n",
      "Epoch: 48, Batch number: 45, Loss: 591.2427978515625\n",
      "Epoch: 48, Batch number: 55, Loss: 579.1928100585938\n",
      "Epoch: 48, Batch number: 65, Loss: 619.6002807617188\n",
      "Epoch: 48, Batch number: 75, Loss: 601.6651611328125\n",
      "Epoch: 48, Batch number: 85, Loss: 596.4784545898438\n",
      "Epoch: 49, Batch number: 0, Loss: 567.4066772460938\n",
      "Epoch: 49, Batch number: 10, Loss: 569.3881225585938\n",
      "Epoch: 49, Batch number: 20, Loss: 587.7171020507812\n",
      "Epoch: 49, Batch number: 30, Loss: 594.6321411132812\n",
      "Epoch: 49, Batch number: 40, Loss: 588.2674560546875\n",
      "Epoch: 49, Batch number: 50, Loss: 620.3779296875\n",
      "Epoch: 49, Batch number: 60, Loss: 603.0074462890625\n",
      "Epoch: 49, Batch number: 70, Loss: 600.1494750976562\n",
      "Epoch: 49, Batch number: 80, Loss: 566.6185302734375\n",
      "Epoch: 49, Batch number: 90, Loss: 562.8741455078125\n",
      "Epoch: 50, Batch number: 5, Loss: 568.510498046875\n",
      "Epoch: 50, Batch number: 15, Loss: 597.2611083984375\n",
      "Epoch: 50, Batch number: 25, Loss: 601.3675537109375\n",
      "Epoch: 50, Batch number: 35, Loss: 600.7324829101562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Batch number: 45, Loss: 577.988525390625\n",
      "Epoch: 50, Batch number: 55, Loss: 590.8583374023438\n",
      "Epoch: 50, Batch number: 65, Loss: 547.5751953125\n",
      "Epoch: 50, Batch number: 75, Loss: 582.8978881835938\n",
      "Epoch: 50, Batch number: 85, Loss: 575.1235961914062\n",
      "Epoch: 51, Batch number: 0, Loss: 561.315185546875\n",
      "Epoch: 51, Batch number: 10, Loss: 602.1956787109375\n",
      "Epoch: 51, Batch number: 20, Loss: 577.37109375\n",
      "Epoch: 51, Batch number: 30, Loss: 572.1970825195312\n",
      "Epoch: 51, Batch number: 40, Loss: 564.72412109375\n",
      "Epoch: 51, Batch number: 50, Loss: 577.7670288085938\n",
      "Epoch: 51, Batch number: 60, Loss: 583.185791015625\n",
      "Epoch: 51, Batch number: 70, Loss: 515.0237426757812\n",
      "Epoch: 51, Batch number: 80, Loss: 568.6336669921875\n",
      "Epoch: 51, Batch number: 90, Loss: 560.7835693359375\n",
      "Epoch: 52, Batch number: 5, Loss: 532.6783447265625\n",
      "Epoch: 52, Batch number: 15, Loss: 538.6820678710938\n",
      "Epoch: 52, Batch number: 25, Loss: 533.0043334960938\n",
      "Epoch: 52, Batch number: 35, Loss: 556.1841430664062\n",
      "Epoch: 52, Batch number: 45, Loss: 571.755615234375\n",
      "Epoch: 52, Batch number: 55, Loss: 527.1539306640625\n",
      "Epoch: 52, Batch number: 65, Loss: 615.2026977539062\n",
      "Epoch: 52, Batch number: 75, Loss: 535.0383911132812\n",
      "Epoch: 52, Batch number: 85, Loss: 502.76251220703125\n",
      "Epoch: 53, Batch number: 0, Loss: 568.46533203125\n",
      "Epoch: 53, Batch number: 10, Loss: 618.489013671875\n",
      "Epoch: 53, Batch number: 20, Loss: 536.6528930664062\n",
      "Epoch: 53, Batch number: 30, Loss: 513.8936767578125\n",
      "Epoch: 53, Batch number: 40, Loss: 507.1349792480469\n",
      "Epoch: 53, Batch number: 50, Loss: 535.7178955078125\n",
      "Epoch: 53, Batch number: 60, Loss: 527.0999755859375\n",
      "Epoch: 53, Batch number: 70, Loss: 489.8212585449219\n",
      "Epoch: 53, Batch number: 80, Loss: 557.80615234375\n",
      "Epoch: 53, Batch number: 90, Loss: 576.08447265625\n",
      "Epoch: 54, Batch number: 5, Loss: 487.0504455566406\n",
      "Epoch: 54, Batch number: 15, Loss: 514.1693725585938\n",
      "Epoch: 54, Batch number: 25, Loss: 553.9277954101562\n",
      "Epoch: 54, Batch number: 35, Loss: 456.8084716796875\n",
      "Epoch: 54, Batch number: 45, Loss: 520.0974731445312\n",
      "Epoch: 54, Batch number: 55, Loss: 486.5347595214844\n",
      "Epoch: 54, Batch number: 65, Loss: 515.7744140625\n",
      "Epoch: 54, Batch number: 75, Loss: 498.67724609375\n",
      "Epoch: 54, Batch number: 85, Loss: 579.3079833984375\n",
      "Epoch: 55, Batch number: 0, Loss: 502.31427001953125\n",
      "Epoch: 55, Batch number: 10, Loss: 508.3058166503906\n",
      "Epoch: 55, Batch number: 20, Loss: 509.3475341796875\n",
      "Epoch: 55, Batch number: 30, Loss: 463.2893371582031\n",
      "Epoch: 55, Batch number: 40, Loss: 483.7044677734375\n",
      "Epoch: 55, Batch number: 50, Loss: 503.6356506347656\n",
      "Epoch: 55, Batch number: 60, Loss: 549.2376098632812\n",
      "Epoch: 55, Batch number: 70, Loss: 522.184814453125\n",
      "Epoch: 55, Batch number: 80, Loss: 480.2267761230469\n",
      "Epoch: 55, Batch number: 90, Loss: 523.8311157226562\n",
      "Epoch: 56, Batch number: 5, Loss: 412.6609802246094\n",
      "Epoch: 56, Batch number: 15, Loss: 501.2301330566406\n",
      "Epoch: 56, Batch number: 25, Loss: 478.60626220703125\n",
      "Epoch: 56, Batch number: 35, Loss: 494.6875915527344\n",
      "Epoch: 56, Batch number: 45, Loss: 551.4351196289062\n",
      "Epoch: 56, Batch number: 55, Loss: 464.96087646484375\n",
      "Epoch: 56, Batch number: 65, Loss: 490.8713684082031\n",
      "Epoch: 56, Batch number: 75, Loss: 468.254150390625\n",
      "Epoch: 56, Batch number: 85, Loss: 492.2139892578125\n",
      "Epoch: 57, Batch number: 0, Loss: 530.3258666992188\n",
      "Epoch: 57, Batch number: 10, Loss: 442.19097900390625\n",
      "Epoch: 57, Batch number: 20, Loss: 469.4036865234375\n",
      "Epoch: 57, Batch number: 30, Loss: 475.0675964355469\n",
      "Epoch: 57, Batch number: 40, Loss: 468.6177673339844\n",
      "Epoch: 57, Batch number: 50, Loss: 556.0762939453125\n",
      "Epoch: 57, Batch number: 60, Loss: 470.9990234375\n",
      "Epoch: 57, Batch number: 70, Loss: 475.0293884277344\n",
      "Epoch: 57, Batch number: 80, Loss: 464.2908020019531\n",
      "Epoch: 57, Batch number: 90, Loss: 497.0801086425781\n",
      "Epoch: 58, Batch number: 5, Loss: 428.7491760253906\n",
      "Epoch: 58, Batch number: 15, Loss: 417.38043212890625\n",
      "Epoch: 58, Batch number: 25, Loss: 495.80413818359375\n",
      "Epoch: 58, Batch number: 35, Loss: 461.4173583984375\n",
      "Epoch: 58, Batch number: 45, Loss: 456.8968811035156\n",
      "Epoch: 58, Batch number: 55, Loss: 467.00946044921875\n",
      "Epoch: 58, Batch number: 65, Loss: 449.4659423828125\n",
      "Epoch: 58, Batch number: 75, Loss: 448.6394348144531\n",
      "Epoch: 58, Batch number: 85, Loss: 489.7844543457031\n",
      "Epoch: 59, Batch number: 0, Loss: 455.818603515625\n",
      "Epoch: 59, Batch number: 10, Loss: 425.820068359375\n",
      "Epoch: 59, Batch number: 20, Loss: 438.86578369140625\n",
      "Epoch: 59, Batch number: 30, Loss: 474.30029296875\n",
      "Epoch: 59, Batch number: 40, Loss: 458.42694091796875\n",
      "Epoch: 59, Batch number: 50, Loss: 422.1041564941406\n",
      "Epoch: 59, Batch number: 60, Loss: 451.7585754394531\n",
      "Epoch: 59, Batch number: 70, Loss: 437.90826416015625\n",
      "Epoch: 59, Batch number: 80, Loss: 480.66143798828125\n",
      "Epoch: 59, Batch number: 90, Loss: 476.0307922363281\n",
      "Epoch: 60, Batch number: 5, Loss: 414.6802062988281\n",
      "Epoch: 60, Batch number: 15, Loss: 412.3076477050781\n",
      "Epoch: 60, Batch number: 25, Loss: 434.2451477050781\n",
      "Epoch: 60, Batch number: 35, Loss: 414.955810546875\n",
      "Epoch: 60, Batch number: 45, Loss: 418.9208984375\n",
      "Epoch: 60, Batch number: 55, Loss: 419.7433776855469\n",
      "Epoch: 60, Batch number: 65, Loss: 399.8162841796875\n",
      "Epoch: 60, Batch number: 75, Loss: 476.402587890625\n",
      "Epoch: 60, Batch number: 85, Loss: 486.0555419921875\n",
      "Epoch: 61, Batch number: 0, Loss: 431.3814392089844\n",
      "Epoch: 61, Batch number: 10, Loss: 452.0909729003906\n",
      "Epoch: 61, Batch number: 20, Loss: 368.9563293457031\n",
      "Epoch: 61, Batch number: 30, Loss: 452.5795593261719\n",
      "Epoch: 61, Batch number: 40, Loss: 442.52581787109375\n",
      "Epoch: 61, Batch number: 50, Loss: 460.464111328125\n",
      "Epoch: 61, Batch number: 60, Loss: 430.3076477050781\n",
      "Epoch: 61, Batch number: 70, Loss: 432.8435363769531\n",
      "Epoch: 61, Batch number: 80, Loss: 453.2286376953125\n",
      "Epoch: 61, Batch number: 90, Loss: 430.6029052734375\n",
      "Epoch: 62, Batch number: 5, Loss: 444.2530822753906\n",
      "Epoch: 62, Batch number: 15, Loss: 418.75164794921875\n",
      "Epoch: 62, Batch number: 25, Loss: 386.52569580078125\n",
      "Epoch: 62, Batch number: 35, Loss: 425.69805908203125\n",
      "Epoch: 62, Batch number: 45, Loss: 427.37481689453125\n",
      "Epoch: 62, Batch number: 55, Loss: 401.5511169433594\n",
      "Epoch: 62, Batch number: 65, Loss: 407.535400390625\n",
      "Epoch: 62, Batch number: 75, Loss: 442.7586364746094\n",
      "Epoch: 62, Batch number: 85, Loss: 415.6116943359375\n",
      "Epoch: 63, Batch number: 0, Loss: 377.25244140625\n",
      "Epoch: 63, Batch number: 10, Loss: 427.7386169433594\n",
      "Epoch: 63, Batch number: 20, Loss: 358.8378601074219\n",
      "Epoch: 63, Batch number: 30, Loss: 357.0939636230469\n",
      "Epoch: 63, Batch number: 40, Loss: 424.2326354980469\n",
      "Epoch: 63, Batch number: 50, Loss: 424.5788879394531\n",
      "Epoch: 63, Batch number: 60, Loss: 440.1984558105469\n",
      "Epoch: 63, Batch number: 70, Loss: 400.23052978515625\n",
      "Epoch: 63, Batch number: 80, Loss: 384.2743225097656\n",
      "Epoch: 63, Batch number: 90, Loss: 427.6385498046875\n",
      "Epoch: 64, Batch number: 5, Loss: 430.9160461425781\n",
      "Epoch: 64, Batch number: 15, Loss: 378.7474060058594\n",
      "Epoch: 64, Batch number: 25, Loss: 397.96795654296875\n",
      "Epoch: 64, Batch number: 35, Loss: 386.9203186035156\n",
      "Epoch: 64, Batch number: 45, Loss: 418.8843078613281\n",
      "Epoch: 64, Batch number: 55, Loss: 427.1976013183594\n",
      "Epoch: 64, Batch number: 65, Loss: 371.14752197265625\n",
      "Epoch: 64, Batch number: 75, Loss: 391.0088806152344\n",
      "Epoch: 64, Batch number: 85, Loss: 435.3387756347656\n",
      "Epoch: 65, Batch number: 0, Loss: 340.57122802734375\n",
      "Epoch: 65, Batch number: 10, Loss: 416.5189514160156\n",
      "Epoch: 65, Batch number: 20, Loss: 387.7756042480469\n",
      "Epoch: 65, Batch number: 30, Loss: 392.3167724609375\n",
      "Epoch: 65, Batch number: 40, Loss: 378.5856628417969\n",
      "Epoch: 65, Batch number: 50, Loss: 397.84716796875\n",
      "Epoch: 65, Batch number: 60, Loss: 360.98089599609375\n",
      "Epoch: 65, Batch number: 70, Loss: 364.3265075683594\n",
      "Epoch: 65, Batch number: 80, Loss: 424.60968017578125\n",
      "Epoch: 65, Batch number: 90, Loss: 437.8895263671875\n",
      "Epoch: 66, Batch number: 5, Loss: 367.9261474609375\n",
      "Epoch: 66, Batch number: 15, Loss: 374.5887756347656\n",
      "Epoch: 66, Batch number: 25, Loss: 328.0009765625\n",
      "Epoch: 66, Batch number: 35, Loss: 355.5074768066406\n",
      "Epoch: 66, Batch number: 45, Loss: 392.9612121582031\n",
      "Epoch: 66, Batch number: 55, Loss: 378.9336853027344\n",
      "Epoch: 66, Batch number: 65, Loss: 386.1309814453125\n",
      "Epoch: 66, Batch number: 75, Loss: 431.9530944824219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Batch number: 85, Loss: 386.27117919921875\n",
      "Epoch: 67, Batch number: 0, Loss: 391.04107666015625\n",
      "Epoch: 67, Batch number: 10, Loss: 350.91021728515625\n",
      "Epoch: 67, Batch number: 20, Loss: 372.9813232421875\n",
      "Epoch: 67, Batch number: 30, Loss: 374.31158447265625\n",
      "Epoch: 67, Batch number: 40, Loss: 345.84112548828125\n",
      "Epoch: 67, Batch number: 50, Loss: 431.81610107421875\n",
      "Epoch: 67, Batch number: 60, Loss: 353.1802062988281\n",
      "Epoch: 67, Batch number: 70, Loss: 380.1958312988281\n",
      "Epoch: 67, Batch number: 80, Loss: 350.453125\n",
      "Epoch: 67, Batch number: 90, Loss: 455.15887451171875\n",
      "Epoch: 68, Batch number: 5, Loss: 345.751708984375\n",
      "Epoch: 68, Batch number: 15, Loss: 362.1111145019531\n",
      "Epoch: 68, Batch number: 25, Loss: 374.6903381347656\n",
      "Epoch: 68, Batch number: 35, Loss: 299.5086669921875\n",
      "Epoch: 68, Batch number: 45, Loss: 328.2945861816406\n",
      "Epoch: 68, Batch number: 55, Loss: 360.73455810546875\n",
      "Epoch: 68, Batch number: 65, Loss: 327.5744323730469\n",
      "Epoch: 68, Batch number: 75, Loss: 365.4087219238281\n",
      "Epoch: 68, Batch number: 85, Loss: 348.6686706542969\n",
      "Epoch: 69, Batch number: 0, Loss: 335.6243896484375\n",
      "Epoch: 69, Batch number: 10, Loss: 389.3248596191406\n",
      "Epoch: 69, Batch number: 20, Loss: 357.85845947265625\n",
      "Epoch: 69, Batch number: 30, Loss: 372.683837890625\n",
      "Epoch: 69, Batch number: 40, Loss: 386.5150451660156\n",
      "Epoch: 69, Batch number: 50, Loss: 307.5229187011719\n",
      "Epoch: 69, Batch number: 60, Loss: 339.84600830078125\n",
      "Epoch: 69, Batch number: 70, Loss: 306.4779968261719\n",
      "Epoch: 69, Batch number: 80, Loss: 342.44085693359375\n",
      "Epoch: 69, Batch number: 90, Loss: 374.62860107421875\n",
      "Epoch: 70, Batch number: 5, Loss: 349.42242431640625\n",
      "Epoch: 70, Batch number: 15, Loss: 375.09002685546875\n",
      "Epoch: 70, Batch number: 25, Loss: 294.30169677734375\n",
      "Epoch: 70, Batch number: 35, Loss: 331.614501953125\n",
      "Epoch: 70, Batch number: 45, Loss: 306.8564758300781\n",
      "Epoch: 70, Batch number: 55, Loss: 344.26708984375\n",
      "Epoch: 70, Batch number: 65, Loss: 361.909423828125\n",
      "Epoch: 70, Batch number: 75, Loss: 327.429443359375\n",
      "Epoch: 70, Batch number: 85, Loss: 370.09356689453125\n",
      "Epoch: 71, Batch number: 0, Loss: 313.4866943359375\n",
      "Epoch: 71, Batch number: 10, Loss: 279.8386535644531\n",
      "Epoch: 71, Batch number: 20, Loss: 325.0401611328125\n",
      "Epoch: 71, Batch number: 30, Loss: 295.45953369140625\n",
      "Epoch: 71, Batch number: 40, Loss: 368.93084716796875\n",
      "Epoch: 71, Batch number: 50, Loss: 358.3632507324219\n",
      "Epoch: 71, Batch number: 60, Loss: 352.92742919921875\n",
      "Epoch: 71, Batch number: 70, Loss: 327.5303955078125\n",
      "Epoch: 71, Batch number: 80, Loss: 331.1003723144531\n",
      "Epoch: 71, Batch number: 90, Loss: 381.7623596191406\n",
      "Epoch: 72, Batch number: 5, Loss: 351.278076171875\n",
      "Epoch: 72, Batch number: 15, Loss: 306.4064636230469\n",
      "Epoch: 72, Batch number: 25, Loss: 310.4747314453125\n",
      "Epoch: 72, Batch number: 35, Loss: 318.98260498046875\n",
      "Epoch: 72, Batch number: 45, Loss: 322.9237976074219\n",
      "Epoch: 72, Batch number: 55, Loss: 315.90704345703125\n",
      "Epoch: 72, Batch number: 65, Loss: 317.40460205078125\n",
      "Epoch: 72, Batch number: 75, Loss: 328.1688537597656\n",
      "Epoch: 72, Batch number: 85, Loss: 308.5878601074219\n",
      "Epoch: 73, Batch number: 0, Loss: 310.33050537109375\n",
      "Epoch: 73, Batch number: 10, Loss: 247.5503692626953\n",
      "Epoch: 73, Batch number: 20, Loss: 298.0003662109375\n",
      "Epoch: 73, Batch number: 30, Loss: 329.1381530761719\n",
      "Epoch: 73, Batch number: 40, Loss: 340.39410400390625\n",
      "Epoch: 73, Batch number: 50, Loss: 304.5342712402344\n",
      "Epoch: 73, Batch number: 60, Loss: 329.0204772949219\n",
      "Epoch: 73, Batch number: 70, Loss: 314.9125061035156\n",
      "Epoch: 73, Batch number: 80, Loss: 300.9084167480469\n",
      "Epoch: 73, Batch number: 90, Loss: 362.2596435546875\n",
      "Epoch: 74, Batch number: 5, Loss: 313.7239685058594\n",
      "Epoch: 74, Batch number: 15, Loss: 310.4318542480469\n",
      "Epoch: 74, Batch number: 25, Loss: 311.7335205078125\n",
      "Epoch: 74, Batch number: 35, Loss: 307.60394287109375\n",
      "Epoch: 74, Batch number: 45, Loss: 312.50189208984375\n",
      "Epoch: 74, Batch number: 55, Loss: 330.76031494140625\n",
      "Epoch: 74, Batch number: 65, Loss: 329.05499267578125\n",
      "Epoch: 74, Batch number: 75, Loss: 345.4970397949219\n",
      "Epoch: 74, Batch number: 85, Loss: 330.6070556640625\n",
      "Epoch: 75, Batch number: 0, Loss: 335.52630615234375\n",
      "Epoch: 75, Batch number: 10, Loss: 265.6552734375\n",
      "Epoch: 75, Batch number: 20, Loss: 273.86322021484375\n",
      "Epoch: 75, Batch number: 30, Loss: 307.4407958984375\n",
      "Epoch: 75, Batch number: 40, Loss: 307.90704345703125\n",
      "Epoch: 75, Batch number: 50, Loss: 299.5701904296875\n",
      "Epoch: 75, Batch number: 60, Loss: 342.61358642578125\n",
      "Epoch: 75, Batch number: 70, Loss: 322.2728576660156\n",
      "Epoch: 75, Batch number: 80, Loss: 335.5432434082031\n",
      "Epoch: 75, Batch number: 90, Loss: 313.84405517578125\n",
      "Epoch: 76, Batch number: 5, Loss: 290.0321350097656\n",
      "Epoch: 76, Batch number: 15, Loss: 282.0360412597656\n",
      "Epoch: 76, Batch number: 25, Loss: 303.1485290527344\n",
      "Epoch: 76, Batch number: 35, Loss: 337.1726379394531\n",
      "Epoch: 76, Batch number: 45, Loss: 257.4678955078125\n",
      "Epoch: 76, Batch number: 55, Loss: 247.24435424804688\n",
      "Epoch: 76, Batch number: 65, Loss: 330.1805725097656\n",
      "Epoch: 76, Batch number: 75, Loss: 327.5976257324219\n",
      "Epoch: 76, Batch number: 85, Loss: 293.0069274902344\n",
      "Epoch: 77, Batch number: 0, Loss: 273.0920104980469\n",
      "Epoch: 77, Batch number: 10, Loss: 309.84686279296875\n",
      "Epoch: 77, Batch number: 20, Loss: 298.2605895996094\n",
      "Epoch: 77, Batch number: 30, Loss: 292.3092346191406\n",
      "Epoch: 77, Batch number: 40, Loss: 282.216552734375\n",
      "Epoch: 77, Batch number: 50, Loss: 273.2244567871094\n",
      "Epoch: 77, Batch number: 60, Loss: 283.6103515625\n",
      "Epoch: 77, Batch number: 70, Loss: 274.0509948730469\n",
      "Epoch: 77, Batch number: 80, Loss: 308.4957580566406\n",
      "Epoch: 77, Batch number: 90, Loss: 301.64300537109375\n",
      "Epoch: 78, Batch number: 5, Loss: 252.9987030029297\n",
      "Epoch: 78, Batch number: 15, Loss: 274.4667663574219\n",
      "Epoch: 78, Batch number: 25, Loss: 298.7164306640625\n",
      "Epoch: 78, Batch number: 35, Loss: 291.8526611328125\n",
      "Epoch: 78, Batch number: 45, Loss: 292.2660217285156\n",
      "Epoch: 78, Batch number: 55, Loss: 294.7931213378906\n",
      "Epoch: 78, Batch number: 65, Loss: 311.4915466308594\n",
      "Epoch: 78, Batch number: 75, Loss: 274.96142578125\n",
      "Epoch: 78, Batch number: 85, Loss: 284.04339599609375\n",
      "Epoch: 79, Batch number: 0, Loss: 239.5645294189453\n",
      "Epoch: 79, Batch number: 10, Loss: 268.7242431640625\n",
      "Epoch: 79, Batch number: 20, Loss: 288.16845703125\n",
      "Epoch: 79, Batch number: 30, Loss: 291.6954650878906\n",
      "Epoch: 79, Batch number: 40, Loss: 267.0492248535156\n",
      "Epoch: 79, Batch number: 50, Loss: 278.1740417480469\n",
      "Epoch: 79, Batch number: 60, Loss: 301.0042724609375\n",
      "Epoch: 79, Batch number: 70, Loss: 308.23358154296875\n",
      "Epoch: 79, Batch number: 80, Loss: 279.5321960449219\n",
      "Epoch: 79, Batch number: 90, Loss: 273.16387939453125\n",
      "Epoch: 80, Batch number: 5, Loss: 252.8616943359375\n",
      "Epoch: 80, Batch number: 15, Loss: 246.24354553222656\n",
      "Epoch: 80, Batch number: 25, Loss: 271.470703125\n",
      "Epoch: 80, Batch number: 35, Loss: 273.724853515625\n",
      "Epoch: 80, Batch number: 45, Loss: 255.6011962890625\n",
      "Epoch: 80, Batch number: 55, Loss: 269.62884521484375\n",
      "Epoch: 80, Batch number: 65, Loss: 295.57623291015625\n",
      "Epoch: 80, Batch number: 75, Loss: 271.3649597167969\n",
      "Epoch: 80, Batch number: 85, Loss: 267.7505798339844\n",
      "Epoch: 81, Batch number: 0, Loss: 254.9409637451172\n",
      "Epoch: 81, Batch number: 10, Loss: 237.69146728515625\n",
      "Epoch: 81, Batch number: 20, Loss: 264.1200256347656\n",
      "Epoch: 81, Batch number: 30, Loss: 292.6369323730469\n",
      "Epoch: 81, Batch number: 40, Loss: 293.70355224609375\n",
      "Epoch: 81, Batch number: 50, Loss: 251.81129455566406\n",
      "Epoch: 81, Batch number: 60, Loss: 248.27059936523438\n",
      "Epoch: 81, Batch number: 70, Loss: 243.26145935058594\n",
      "Epoch: 81, Batch number: 80, Loss: 280.6732482910156\n",
      "Epoch: 81, Batch number: 90, Loss: 244.47731018066406\n",
      "Epoch: 82, Batch number: 5, Loss: 271.0067138671875\n",
      "Epoch: 82, Batch number: 15, Loss: 230.9688262939453\n",
      "Epoch: 82, Batch number: 25, Loss: 245.45858764648438\n",
      "Epoch: 82, Batch number: 35, Loss: 245.17889404296875\n",
      "Epoch: 82, Batch number: 45, Loss: 269.9197998046875\n",
      "Epoch: 82, Batch number: 55, Loss: 265.85986328125\n",
      "Epoch: 82, Batch number: 65, Loss: 245.8448486328125\n",
      "Epoch: 82, Batch number: 75, Loss: 236.15118408203125\n",
      "Epoch: 82, Batch number: 85, Loss: 284.2049560546875\n",
      "Epoch: 83, Batch number: 0, Loss: 263.5339660644531\n",
      "Epoch: 83, Batch number: 10, Loss: 249.78025817871094\n",
      "Epoch: 83, Batch number: 20, Loss: 225.76026916503906\n",
      "Epoch: 83, Batch number: 30, Loss: 211.68531799316406\n",
      "Epoch: 83, Batch number: 40, Loss: 249.69796752929688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83, Batch number: 50, Loss: 279.92706298828125\n",
      "Epoch: 83, Batch number: 60, Loss: 250.68316650390625\n",
      "Epoch: 83, Batch number: 70, Loss: 245.483154296875\n",
      "Epoch: 83, Batch number: 80, Loss: 247.55731201171875\n",
      "Epoch: 83, Batch number: 90, Loss: 292.1928405761719\n",
      "Epoch: 84, Batch number: 5, Loss: 279.5982360839844\n",
      "Epoch: 84, Batch number: 15, Loss: 277.6109924316406\n",
      "Epoch: 84, Batch number: 25, Loss: 276.2652282714844\n",
      "Epoch: 84, Batch number: 35, Loss: 294.0586242675781\n",
      "Epoch: 84, Batch number: 45, Loss: 259.1260070800781\n",
      "Epoch: 84, Batch number: 55, Loss: 251.5785369873047\n",
      "Epoch: 84, Batch number: 65, Loss: 209.0087432861328\n",
      "Epoch: 84, Batch number: 75, Loss: 231.0155487060547\n",
      "Epoch: 84, Batch number: 85, Loss: 204.29286193847656\n",
      "Epoch: 85, Batch number: 0, Loss: 240.9610595703125\n",
      "Epoch: 85, Batch number: 10, Loss: 244.1203155517578\n",
      "Epoch: 85, Batch number: 20, Loss: 245.85263061523438\n",
      "Epoch: 85, Batch number: 30, Loss: 228.01197814941406\n",
      "Epoch: 85, Batch number: 40, Loss: 244.81155395507812\n",
      "Epoch: 85, Batch number: 50, Loss: 251.9722442626953\n",
      "Epoch: 85, Batch number: 60, Loss: 216.19664001464844\n",
      "Epoch: 85, Batch number: 70, Loss: 227.7720947265625\n",
      "Epoch: 85, Batch number: 80, Loss: 248.7454376220703\n",
      "Epoch: 85, Batch number: 90, Loss: 233.10438537597656\n",
      "Epoch: 86, Batch number: 5, Loss: 243.20834350585938\n",
      "Epoch: 86, Batch number: 15, Loss: 269.39111328125\n",
      "Epoch: 86, Batch number: 25, Loss: 261.8146057128906\n",
      "Epoch: 86, Batch number: 35, Loss: 238.45188903808594\n",
      "Epoch: 86, Batch number: 45, Loss: 244.44076538085938\n",
      "Epoch: 86, Batch number: 55, Loss: 271.56683349609375\n",
      "Epoch: 86, Batch number: 65, Loss: 233.9012908935547\n",
      "Epoch: 86, Batch number: 75, Loss: 280.6319885253906\n",
      "Epoch: 86, Batch number: 85, Loss: 253.09523010253906\n",
      "Epoch: 87, Batch number: 0, Loss: 236.3824462890625\n",
      "Epoch: 87, Batch number: 10, Loss: 214.42530822753906\n",
      "Epoch: 87, Batch number: 20, Loss: 231.02655029296875\n",
      "Epoch: 87, Batch number: 30, Loss: 226.30783081054688\n",
      "Epoch: 87, Batch number: 40, Loss: 218.78109741210938\n",
      "Epoch: 87, Batch number: 50, Loss: 205.83815002441406\n",
      "Epoch: 87, Batch number: 60, Loss: 223.2095489501953\n",
      "Epoch: 87, Batch number: 70, Loss: 233.35438537597656\n",
      "Epoch: 87, Batch number: 80, Loss: 234.6735076904297\n",
      "Epoch: 87, Batch number: 90, Loss: 195.1522979736328\n",
      "Epoch: 88, Batch number: 5, Loss: 182.0998077392578\n",
      "Epoch: 88, Batch number: 15, Loss: 215.74375915527344\n",
      "Epoch: 88, Batch number: 25, Loss: 256.211181640625\n",
      "Epoch: 88, Batch number: 35, Loss: 264.7415771484375\n",
      "Epoch: 88, Batch number: 45, Loss: 221.53155517578125\n",
      "Epoch: 88, Batch number: 55, Loss: 255.1397705078125\n",
      "Epoch: 88, Batch number: 65, Loss: 221.4115447998047\n",
      "Epoch: 88, Batch number: 75, Loss: 212.57423400878906\n",
      "Epoch: 88, Batch number: 85, Loss: 217.02772521972656\n",
      "Epoch: 89, Batch number: 0, Loss: 189.9926300048828\n",
      "Epoch: 89, Batch number: 10, Loss: 231.1543426513672\n",
      "Epoch: 89, Batch number: 20, Loss: 237.16062927246094\n",
      "Epoch: 89, Batch number: 30, Loss: 221.01992797851562\n",
      "Epoch: 89, Batch number: 40, Loss: 204.28695678710938\n",
      "Epoch: 89, Batch number: 50, Loss: 271.9922790527344\n",
      "Epoch: 89, Batch number: 60, Loss: 244.68035888671875\n",
      "Epoch: 89, Batch number: 70, Loss: 205.8765106201172\n",
      "Epoch: 89, Batch number: 80, Loss: 206.96014404296875\n",
      "Epoch: 89, Batch number: 90, Loss: 234.1312255859375\n",
      "Epoch: 90, Batch number: 5, Loss: 201.30447387695312\n",
      "Epoch: 90, Batch number: 15, Loss: 205.30145263671875\n",
      "Epoch: 90, Batch number: 25, Loss: 231.35728454589844\n",
      "Epoch: 90, Batch number: 35, Loss: 239.74685668945312\n",
      "Epoch: 90, Batch number: 45, Loss: 236.14764404296875\n",
      "Epoch: 90, Batch number: 55, Loss: 239.51075744628906\n",
      "Epoch: 90, Batch number: 65, Loss: 216.2576904296875\n",
      "Epoch: 90, Batch number: 75, Loss: 217.6074676513672\n",
      "Epoch: 90, Batch number: 85, Loss: 231.9966278076172\n",
      "Epoch: 91, Batch number: 0, Loss: 217.2216339111328\n",
      "Epoch: 91, Batch number: 10, Loss: 180.8776397705078\n",
      "Epoch: 91, Batch number: 20, Loss: 180.67694091796875\n",
      "Epoch: 91, Batch number: 30, Loss: 202.21868896484375\n",
      "Epoch: 91, Batch number: 40, Loss: 198.88308715820312\n",
      "Epoch: 91, Batch number: 50, Loss: 179.44601440429688\n",
      "Epoch: 91, Batch number: 60, Loss: 196.0316619873047\n",
      "Epoch: 91, Batch number: 70, Loss: 193.8008270263672\n",
      "Epoch: 91, Batch number: 80, Loss: 235.1578826904297\n",
      "Epoch: 91, Batch number: 90, Loss: 204.3762664794922\n",
      "Epoch: 92, Batch number: 5, Loss: 216.49354553222656\n",
      "Epoch: 92, Batch number: 15, Loss: 230.9827423095703\n",
      "Epoch: 92, Batch number: 25, Loss: 209.6778106689453\n",
      "Epoch: 92, Batch number: 35, Loss: 189.2857666015625\n",
      "Epoch: 92, Batch number: 45, Loss: 178.20957946777344\n",
      "Epoch: 92, Batch number: 55, Loss: 249.44454956054688\n",
      "Epoch: 92, Batch number: 65, Loss: 184.68875122070312\n",
      "Epoch: 92, Batch number: 75, Loss: 205.08616638183594\n",
      "Epoch: 92, Batch number: 85, Loss: 209.39892578125\n",
      "Epoch: 93, Batch number: 0, Loss: 206.0444793701172\n",
      "Epoch: 93, Batch number: 10, Loss: 235.9193878173828\n",
      "Epoch: 93, Batch number: 20, Loss: 190.01219177246094\n",
      "Epoch: 93, Batch number: 30, Loss: 196.6054229736328\n",
      "Epoch: 93, Batch number: 40, Loss: 204.61769104003906\n",
      "Epoch: 93, Batch number: 50, Loss: 183.2830810546875\n",
      "Epoch: 93, Batch number: 60, Loss: 213.2320556640625\n",
      "Epoch: 93, Batch number: 70, Loss: 194.13882446289062\n",
      "Epoch: 93, Batch number: 80, Loss: 222.45089721679688\n",
      "Epoch: 93, Batch number: 90, Loss: 210.67771911621094\n",
      "Epoch: 94, Batch number: 5, Loss: 215.3413848876953\n",
      "Epoch: 94, Batch number: 15, Loss: 206.77268981933594\n",
      "Epoch: 94, Batch number: 25, Loss: 189.02716064453125\n",
      "Epoch: 94, Batch number: 35, Loss: 173.09596252441406\n",
      "Epoch: 94, Batch number: 45, Loss: 192.70309448242188\n",
      "Epoch: 94, Batch number: 55, Loss: 189.5024871826172\n",
      "Epoch: 94, Batch number: 65, Loss: 202.30841064453125\n",
      "Epoch: 94, Batch number: 75, Loss: 208.8706817626953\n",
      "Epoch: 94, Batch number: 85, Loss: 233.44793701171875\n",
      "Epoch: 95, Batch number: 0, Loss: 193.4351806640625\n",
      "Epoch: 95, Batch number: 10, Loss: 240.80474853515625\n",
      "Epoch: 95, Batch number: 20, Loss: 233.83544921875\n",
      "Epoch: 95, Batch number: 30, Loss: 170.19195556640625\n",
      "Epoch: 95, Batch number: 40, Loss: 236.3213653564453\n",
      "Epoch: 95, Batch number: 50, Loss: 161.08128356933594\n",
      "Epoch: 95, Batch number: 60, Loss: 213.3907470703125\n",
      "Epoch: 95, Batch number: 70, Loss: 166.56619262695312\n",
      "Epoch: 95, Batch number: 80, Loss: 221.07484436035156\n",
      "Epoch: 95, Batch number: 90, Loss: 178.74476623535156\n",
      "Epoch: 96, Batch number: 5, Loss: 200.75936889648438\n",
      "Epoch: 96, Batch number: 15, Loss: 170.7642059326172\n",
      "Epoch: 96, Batch number: 25, Loss: 179.75704956054688\n",
      "Epoch: 96, Batch number: 35, Loss: 200.0150604248047\n",
      "Epoch: 96, Batch number: 45, Loss: 208.02227783203125\n",
      "Epoch: 96, Batch number: 55, Loss: 193.5030517578125\n",
      "Epoch: 96, Batch number: 65, Loss: 196.41195678710938\n",
      "Epoch: 96, Batch number: 75, Loss: 183.4195556640625\n",
      "Epoch: 96, Batch number: 85, Loss: 196.32925415039062\n",
      "Epoch: 97, Batch number: 0, Loss: 160.66278076171875\n",
      "Epoch: 97, Batch number: 10, Loss: 169.5551300048828\n",
      "Epoch: 97, Batch number: 20, Loss: 181.48977661132812\n",
      "Epoch: 97, Batch number: 30, Loss: 204.71905517578125\n",
      "Epoch: 97, Batch number: 40, Loss: 178.65724182128906\n",
      "Epoch: 97, Batch number: 50, Loss: 205.7949981689453\n",
      "Epoch: 97, Batch number: 60, Loss: 212.78848266601562\n",
      "Epoch: 97, Batch number: 70, Loss: 187.20925903320312\n",
      "Epoch: 97, Batch number: 80, Loss: 212.76344299316406\n",
      "Epoch: 97, Batch number: 90, Loss: 196.8271942138672\n",
      "Epoch: 98, Batch number: 5, Loss: 178.3626708984375\n",
      "Epoch: 98, Batch number: 15, Loss: 144.3946990966797\n",
      "Epoch: 98, Batch number: 25, Loss: 175.75970458984375\n",
      "Epoch: 98, Batch number: 35, Loss: 170.82115173339844\n",
      "Epoch: 98, Batch number: 45, Loss: 170.4140625\n",
      "Epoch: 98, Batch number: 55, Loss: 193.89683532714844\n",
      "Epoch: 98, Batch number: 65, Loss: 194.28643798828125\n",
      "Epoch: 98, Batch number: 75, Loss: 201.82717895507812\n",
      "Epoch: 98, Batch number: 85, Loss: 234.02127075195312\n",
      "Epoch: 99, Batch number: 0, Loss: 166.53819274902344\n",
      "Epoch: 99, Batch number: 10, Loss: 201.44760131835938\n",
      "Epoch: 99, Batch number: 20, Loss: 221.76919555664062\n",
      "Epoch: 99, Batch number: 30, Loss: 156.76092529296875\n",
      "Epoch: 99, Batch number: 40, Loss: 212.7792205810547\n",
      "Epoch: 99, Batch number: 50, Loss: 170.54794311523438\n",
      "Epoch: 99, Batch number: 60, Loss: 191.12139892578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, Batch number: 70, Loss: 177.03170776367188\n",
      "Epoch: 99, Batch number: 80, Loss: 179.03662109375\n",
      "Epoch: 99, Batch number: 90, Loss: 189.9117889404297\n",
      "Epoch: 100, Batch number: 5, Loss: 162.3243408203125\n",
      "Epoch: 100, Batch number: 15, Loss: 174.95533752441406\n",
      "Epoch: 100, Batch number: 25, Loss: 162.7518768310547\n",
      "Epoch: 100, Batch number: 35, Loss: 219.35287475585938\n",
      "Epoch: 100, Batch number: 45, Loss: 170.97677612304688\n",
      "Epoch: 100, Batch number: 55, Loss: 180.15280151367188\n",
      "Epoch: 100, Batch number: 65, Loss: 174.03427124023438\n",
      "Epoch: 100, Batch number: 75, Loss: 183.55638122558594\n",
      "Epoch: 100, Batch number: 85, Loss: 182.4425048828125\n",
      "Epoch: 101, Batch number: 0, Loss: 184.43185424804688\n",
      "Epoch: 101, Batch number: 10, Loss: 168.0742645263672\n",
      "Epoch: 101, Batch number: 20, Loss: 208.41555786132812\n",
      "Epoch: 101, Batch number: 30, Loss: 201.6700897216797\n",
      "Epoch: 101, Batch number: 40, Loss: 172.63131713867188\n",
      "Epoch: 101, Batch number: 50, Loss: 185.78123474121094\n",
      "Epoch: 101, Batch number: 60, Loss: 191.85653686523438\n",
      "Epoch: 101, Batch number: 70, Loss: 148.91452026367188\n",
      "Epoch: 101, Batch number: 80, Loss: 185.21527099609375\n",
      "Epoch: 101, Batch number: 90, Loss: 206.81195068359375\n",
      "Epoch: 102, Batch number: 5, Loss: 197.5675811767578\n",
      "Epoch: 102, Batch number: 15, Loss: 164.8749237060547\n",
      "Epoch: 102, Batch number: 25, Loss: 188.02195739746094\n",
      "Epoch: 102, Batch number: 35, Loss: 174.02401733398438\n",
      "Epoch: 102, Batch number: 45, Loss: 171.75779724121094\n",
      "Epoch: 102, Batch number: 55, Loss: 161.11151123046875\n",
      "Epoch: 102, Batch number: 65, Loss: 155.8299102783203\n",
      "Epoch: 102, Batch number: 75, Loss: 148.71780395507812\n",
      "Epoch: 102, Batch number: 85, Loss: 206.91046142578125\n",
      "Epoch: 103, Batch number: 0, Loss: 176.3848114013672\n",
      "Epoch: 103, Batch number: 10, Loss: 158.1902618408203\n",
      "Epoch: 103, Batch number: 20, Loss: 161.5430908203125\n",
      "Epoch: 103, Batch number: 30, Loss: 176.07720947265625\n",
      "Epoch: 103, Batch number: 40, Loss: 148.83657836914062\n",
      "Epoch: 103, Batch number: 50, Loss: 156.29148864746094\n",
      "Epoch: 103, Batch number: 60, Loss: 166.34278869628906\n",
      "Epoch: 103, Batch number: 70, Loss: 185.46495056152344\n",
      "Epoch: 103, Batch number: 80, Loss: 175.19149780273438\n",
      "Epoch: 103, Batch number: 90, Loss: 162.17738342285156\n",
      "Epoch: 104, Batch number: 5, Loss: 173.41627502441406\n",
      "Epoch: 104, Batch number: 15, Loss: 160.43804931640625\n",
      "Epoch: 104, Batch number: 25, Loss: 210.03822326660156\n",
      "Epoch: 104, Batch number: 35, Loss: 163.31198120117188\n",
      "Epoch: 104, Batch number: 45, Loss: 144.3054656982422\n",
      "Epoch: 104, Batch number: 55, Loss: 139.4390869140625\n",
      "Epoch: 104, Batch number: 65, Loss: 170.21876525878906\n",
      "Epoch: 104, Batch number: 75, Loss: 173.80943298339844\n",
      "Epoch: 104, Batch number: 85, Loss: 173.03028869628906\n",
      "Epoch: 105, Batch number: 0, Loss: 170.14674377441406\n",
      "Epoch: 105, Batch number: 10, Loss: 128.5944366455078\n",
      "Epoch: 105, Batch number: 20, Loss: 133.15969848632812\n",
      "Epoch: 105, Batch number: 30, Loss: 194.65084838867188\n",
      "Epoch: 105, Batch number: 40, Loss: 187.17613220214844\n",
      "Epoch: 105, Batch number: 50, Loss: 169.6962127685547\n",
      "Epoch: 105, Batch number: 60, Loss: 181.57107543945312\n",
      "Epoch: 105, Batch number: 70, Loss: 191.8501739501953\n",
      "Epoch: 105, Batch number: 80, Loss: 199.69573974609375\n",
      "Epoch: 105, Batch number: 90, Loss: 159.4645538330078\n",
      "Epoch: 106, Batch number: 5, Loss: 161.24319458007812\n",
      "Epoch: 106, Batch number: 15, Loss: 147.21630859375\n",
      "Epoch: 106, Batch number: 25, Loss: 172.14869689941406\n",
      "Epoch: 106, Batch number: 35, Loss: 176.9600067138672\n",
      "Epoch: 106, Batch number: 45, Loss: 168.09231567382812\n",
      "Epoch: 106, Batch number: 55, Loss: 223.92449951171875\n",
      "Epoch: 106, Batch number: 65, Loss: 198.7715301513672\n",
      "Epoch: 106, Batch number: 75, Loss: 183.00917053222656\n",
      "Epoch: 106, Batch number: 85, Loss: 137.40692138671875\n",
      "Epoch: 107, Batch number: 0, Loss: 163.51416015625\n",
      "Epoch: 107, Batch number: 10, Loss: 134.55783081054688\n",
      "Epoch: 107, Batch number: 20, Loss: 166.19918823242188\n",
      "Epoch: 107, Batch number: 30, Loss: 188.77085876464844\n",
      "Epoch: 107, Batch number: 40, Loss: 142.07022094726562\n",
      "Epoch: 107, Batch number: 50, Loss: 149.7308349609375\n",
      "Epoch: 107, Batch number: 60, Loss: 182.07754516601562\n",
      "Epoch: 107, Batch number: 70, Loss: 166.37432861328125\n",
      "Epoch: 107, Batch number: 80, Loss: 165.27197265625\n",
      "Epoch: 107, Batch number: 90, Loss: 178.33251953125\n",
      "Epoch: 108, Batch number: 5, Loss: 151.5530242919922\n",
      "Epoch: 108, Batch number: 15, Loss: 133.0848388671875\n",
      "Epoch: 108, Batch number: 25, Loss: 146.63136291503906\n",
      "Epoch: 108, Batch number: 35, Loss: 144.49623107910156\n",
      "Epoch: 108, Batch number: 45, Loss: 169.1452178955078\n",
      "Epoch: 108, Batch number: 55, Loss: 146.6727752685547\n",
      "Epoch: 108, Batch number: 65, Loss: 142.95516967773438\n",
      "Epoch: 108, Batch number: 75, Loss: 171.34950256347656\n",
      "Epoch: 108, Batch number: 85, Loss: 130.909423828125\n",
      "Epoch: 109, Batch number: 0, Loss: 157.31101989746094\n",
      "Epoch: 109, Batch number: 10, Loss: 118.2942123413086\n",
      "Epoch: 109, Batch number: 20, Loss: 132.0498809814453\n",
      "Epoch: 109, Batch number: 30, Loss: 172.34048461914062\n",
      "Epoch: 109, Batch number: 40, Loss: 152.70652770996094\n",
      "Epoch: 109, Batch number: 50, Loss: 176.79241943359375\n",
      "Epoch: 109, Batch number: 60, Loss: 143.99928283691406\n",
      "Epoch: 109, Batch number: 70, Loss: 210.80352783203125\n",
      "Epoch: 109, Batch number: 80, Loss: 162.20626831054688\n",
      "Epoch: 109, Batch number: 90, Loss: 172.0157470703125\n",
      "Epoch: 110, Batch number: 5, Loss: 181.4202423095703\n",
      "Epoch: 110, Batch number: 15, Loss: 133.4147186279297\n",
      "Epoch: 110, Batch number: 25, Loss: 144.9387969970703\n",
      "Epoch: 110, Batch number: 35, Loss: 142.58706665039062\n",
      "Epoch: 110, Batch number: 45, Loss: 157.81060791015625\n",
      "Epoch: 110, Batch number: 55, Loss: 169.97274780273438\n",
      "Epoch: 110, Batch number: 65, Loss: 188.3116912841797\n",
      "Epoch: 110, Batch number: 75, Loss: 167.42181396484375\n",
      "Epoch: 110, Batch number: 85, Loss: 143.2069854736328\n",
      "Epoch: 111, Batch number: 0, Loss: 151.98243713378906\n",
      "Epoch: 111, Batch number: 10, Loss: 174.70306396484375\n",
      "Epoch: 111, Batch number: 20, Loss: 127.61549377441406\n",
      "Epoch: 111, Batch number: 30, Loss: 173.47052001953125\n",
      "Epoch: 111, Batch number: 40, Loss: 131.67977905273438\n",
      "Epoch: 111, Batch number: 50, Loss: 140.51840209960938\n",
      "Epoch: 111, Batch number: 60, Loss: 179.619140625\n",
      "Epoch: 111, Batch number: 70, Loss: 137.42381286621094\n",
      "Epoch: 111, Batch number: 80, Loss: 142.1472930908203\n",
      "Epoch: 111, Batch number: 90, Loss: 157.9766845703125\n",
      "Epoch: 112, Batch number: 5, Loss: 128.22096252441406\n",
      "Epoch: 112, Batch number: 15, Loss: 163.5457000732422\n",
      "Epoch: 112, Batch number: 25, Loss: 158.4927978515625\n",
      "Epoch: 112, Batch number: 35, Loss: 162.26499938964844\n",
      "Epoch: 112, Batch number: 45, Loss: 158.3363800048828\n",
      "Epoch: 112, Batch number: 55, Loss: 154.25094604492188\n",
      "Epoch: 112, Batch number: 65, Loss: 156.10009765625\n",
      "Epoch: 112, Batch number: 75, Loss: 154.21192932128906\n",
      "Epoch: 112, Batch number: 85, Loss: 140.74179077148438\n",
      "Epoch: 113, Batch number: 0, Loss: 133.87220764160156\n",
      "Epoch: 113, Batch number: 10, Loss: 160.44317626953125\n",
      "Epoch: 113, Batch number: 20, Loss: 136.8679656982422\n",
      "Epoch: 113, Batch number: 30, Loss: 154.34317016601562\n",
      "Epoch: 113, Batch number: 40, Loss: 164.85684204101562\n",
      "Epoch: 113, Batch number: 50, Loss: 150.69200134277344\n",
      "Epoch: 113, Batch number: 60, Loss: 133.5982666015625\n",
      "Epoch: 113, Batch number: 70, Loss: 151.97732543945312\n",
      "Epoch: 113, Batch number: 80, Loss: 143.22373962402344\n",
      "Epoch: 113, Batch number: 90, Loss: 128.97544860839844\n",
      "Epoch: 114, Batch number: 5, Loss: 136.70901489257812\n",
      "Epoch: 114, Batch number: 15, Loss: 144.37413024902344\n",
      "Epoch: 114, Batch number: 25, Loss: 140.2645263671875\n",
      "Epoch: 114, Batch number: 35, Loss: 145.34075927734375\n",
      "Epoch: 114, Batch number: 45, Loss: 135.3763427734375\n",
      "Epoch: 114, Batch number: 55, Loss: 131.5828094482422\n",
      "Epoch: 114, Batch number: 65, Loss: 140.26394653320312\n",
      "Epoch: 114, Batch number: 75, Loss: 130.5001220703125\n",
      "Epoch: 114, Batch number: 85, Loss: 148.2495574951172\n",
      "Epoch: 115, Batch number: 0, Loss: 140.17416381835938\n",
      "Epoch: 115, Batch number: 10, Loss: 118.64149475097656\n",
      "Epoch: 115, Batch number: 20, Loss: 140.24977111816406\n",
      "Epoch: 115, Batch number: 30, Loss: 136.90040588378906\n",
      "Epoch: 115, Batch number: 40, Loss: 168.48214721679688\n",
      "Epoch: 115, Batch number: 50, Loss: 133.20701599121094\n",
      "Epoch: 115, Batch number: 60, Loss: 125.91585540771484\n",
      "Epoch: 115, Batch number: 70, Loss: 149.96304321289062\n",
      "Epoch: 115, Batch number: 80, Loss: 134.42825317382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115, Batch number: 90, Loss: 147.38934326171875\n",
      "Epoch: 116, Batch number: 5, Loss: 125.87702178955078\n",
      "Epoch: 116, Batch number: 15, Loss: 114.67236328125\n",
      "Epoch: 116, Batch number: 25, Loss: 150.02928161621094\n",
      "Epoch: 116, Batch number: 35, Loss: 122.18453979492188\n",
      "Epoch: 116, Batch number: 45, Loss: 135.93563842773438\n",
      "Epoch: 116, Batch number: 55, Loss: 136.51597595214844\n",
      "Epoch: 116, Batch number: 65, Loss: 177.81362915039062\n",
      "Epoch: 116, Batch number: 75, Loss: 161.4140625\n",
      "Epoch: 116, Batch number: 85, Loss: 152.45297241210938\n",
      "Epoch: 117, Batch number: 0, Loss: 138.03213500976562\n",
      "Epoch: 117, Batch number: 10, Loss: 128.93045043945312\n",
      "Epoch: 117, Batch number: 20, Loss: 157.71072387695312\n",
      "Epoch: 117, Batch number: 30, Loss: 135.59432983398438\n",
      "Epoch: 117, Batch number: 40, Loss: 130.15631103515625\n",
      "Epoch: 117, Batch number: 50, Loss: 124.72649383544922\n",
      "Epoch: 117, Batch number: 60, Loss: 136.12884521484375\n",
      "Epoch: 117, Batch number: 70, Loss: 122.80330657958984\n",
      "Epoch: 117, Batch number: 80, Loss: 155.27243041992188\n",
      "Epoch: 117, Batch number: 90, Loss: 147.63113403320312\n",
      "Epoch: 118, Batch number: 5, Loss: 141.0398712158203\n",
      "Epoch: 118, Batch number: 15, Loss: 143.9282684326172\n",
      "Epoch: 118, Batch number: 25, Loss: 156.5205535888672\n",
      "Epoch: 118, Batch number: 35, Loss: 165.74989318847656\n",
      "Epoch: 118, Batch number: 45, Loss: 137.94888305664062\n",
      "Epoch: 118, Batch number: 55, Loss: 116.23433685302734\n",
      "Epoch: 118, Batch number: 65, Loss: 165.04603576660156\n",
      "Epoch: 118, Batch number: 75, Loss: 143.97250366210938\n",
      "Epoch: 118, Batch number: 85, Loss: 132.37442016601562\n",
      "Epoch: 119, Batch number: 0, Loss: 177.80191040039062\n",
      "Epoch: 119, Batch number: 10, Loss: 144.5729522705078\n",
      "Epoch: 119, Batch number: 20, Loss: 167.50833129882812\n",
      "Epoch: 119, Batch number: 30, Loss: 137.01109313964844\n",
      "Epoch: 119, Batch number: 40, Loss: 149.86337280273438\n",
      "Epoch: 119, Batch number: 50, Loss: 131.655517578125\n",
      "Epoch: 119, Batch number: 60, Loss: 149.02842712402344\n",
      "Epoch: 119, Batch number: 70, Loss: 147.96409606933594\n",
      "Epoch: 119, Batch number: 80, Loss: 140.26649475097656\n",
      "Epoch: 119, Batch number: 90, Loss: 141.36203002929688\n",
      "Epoch: 120, Batch number: 5, Loss: 126.58695220947266\n",
      "Epoch: 120, Batch number: 15, Loss: 154.8985595703125\n",
      "Epoch: 120, Batch number: 25, Loss: 127.29412841796875\n",
      "Epoch: 120, Batch number: 35, Loss: 141.9560089111328\n",
      "Epoch: 120, Batch number: 45, Loss: 143.30679321289062\n",
      "Epoch: 120, Batch number: 55, Loss: 131.15708923339844\n",
      "Epoch: 120, Batch number: 65, Loss: 133.2202606201172\n",
      "Epoch: 120, Batch number: 75, Loss: 138.2083282470703\n",
      "Epoch: 120, Batch number: 85, Loss: 117.45818328857422\n",
      "Epoch: 121, Batch number: 0, Loss: 126.99151611328125\n",
      "Epoch: 121, Batch number: 10, Loss: 152.8017578125\n",
      "Epoch: 121, Batch number: 20, Loss: 135.18667602539062\n",
      "Epoch: 121, Batch number: 30, Loss: 132.34010314941406\n",
      "Epoch: 121, Batch number: 40, Loss: 140.3760223388672\n",
      "Epoch: 121, Batch number: 50, Loss: 126.67666625976562\n",
      "Epoch: 121, Batch number: 60, Loss: 144.60440063476562\n",
      "Epoch: 121, Batch number: 70, Loss: 164.28646850585938\n",
      "Epoch: 121, Batch number: 80, Loss: 123.76072692871094\n",
      "Epoch: 121, Batch number: 90, Loss: 136.4852294921875\n",
      "Epoch: 122, Batch number: 5, Loss: 121.65454864501953\n",
      "Epoch: 122, Batch number: 15, Loss: 118.98170471191406\n",
      "Epoch: 122, Batch number: 25, Loss: 117.89140319824219\n",
      "Epoch: 122, Batch number: 35, Loss: 129.9461212158203\n",
      "Epoch: 122, Batch number: 45, Loss: 139.15731811523438\n",
      "Epoch: 122, Batch number: 55, Loss: 123.98880004882812\n",
      "Epoch: 122, Batch number: 65, Loss: 143.80990600585938\n",
      "Epoch: 122, Batch number: 75, Loss: 155.2173309326172\n",
      "Epoch: 122, Batch number: 85, Loss: 143.85194396972656\n",
      "Epoch: 123, Batch number: 0, Loss: 105.86119079589844\n",
      "Epoch: 123, Batch number: 10, Loss: 111.45987701416016\n",
      "Epoch: 123, Batch number: 20, Loss: 140.40103149414062\n",
      "Epoch: 123, Batch number: 30, Loss: 144.03213500976562\n",
      "Epoch: 123, Batch number: 40, Loss: 124.33412170410156\n",
      "Epoch: 123, Batch number: 50, Loss: 140.5790252685547\n",
      "Epoch: 123, Batch number: 60, Loss: 114.96248626708984\n",
      "Epoch: 123, Batch number: 70, Loss: 128.0076904296875\n",
      "Epoch: 123, Batch number: 80, Loss: 116.94622802734375\n",
      "Epoch: 123, Batch number: 90, Loss: 121.10822296142578\n",
      "Epoch: 124, Batch number: 5, Loss: 154.24264526367188\n",
      "Epoch: 124, Batch number: 15, Loss: 96.69202423095703\n",
      "Epoch: 124, Batch number: 25, Loss: 111.99916076660156\n",
      "Epoch: 124, Batch number: 35, Loss: 138.9974365234375\n",
      "Epoch: 124, Batch number: 45, Loss: 119.10802459716797\n",
      "Epoch: 124, Batch number: 55, Loss: 132.02613830566406\n",
      "Epoch: 124, Batch number: 65, Loss: 143.0844268798828\n",
      "Epoch: 124, Batch number: 75, Loss: 140.30484008789062\n",
      "Epoch: 124, Batch number: 85, Loss: 121.69658660888672\n",
      "Epoch: 125, Batch number: 0, Loss: 128.3251953125\n",
      "Epoch: 125, Batch number: 10, Loss: 91.15170288085938\n",
      "Epoch: 125, Batch number: 20, Loss: 110.90982055664062\n",
      "Epoch: 125, Batch number: 30, Loss: 124.1613540649414\n",
      "Epoch: 125, Batch number: 40, Loss: 119.25894927978516\n",
      "Epoch: 125, Batch number: 50, Loss: 150.8475341796875\n",
      "Epoch: 125, Batch number: 60, Loss: 133.11895751953125\n",
      "Epoch: 125, Batch number: 70, Loss: 126.20137023925781\n",
      "Epoch: 125, Batch number: 80, Loss: 115.22219848632812\n",
      "Epoch: 125, Batch number: 90, Loss: 162.7080078125\n",
      "Epoch: 126, Batch number: 5, Loss: 132.1214141845703\n",
      "Epoch: 126, Batch number: 15, Loss: 129.76104736328125\n",
      "Epoch: 126, Batch number: 25, Loss: 127.02458953857422\n",
      "Epoch: 126, Batch number: 35, Loss: 124.6939468383789\n",
      "Epoch: 126, Batch number: 45, Loss: 121.06625366210938\n",
      "Epoch: 126, Batch number: 55, Loss: 113.35327911376953\n",
      "Epoch: 126, Batch number: 65, Loss: 118.80146789550781\n",
      "Epoch: 126, Batch number: 75, Loss: 128.79855346679688\n",
      "Epoch: 126, Batch number: 85, Loss: 143.89292907714844\n",
      "Epoch: 127, Batch number: 0, Loss: 156.75021362304688\n",
      "Epoch: 127, Batch number: 10, Loss: 121.76884460449219\n",
      "Epoch: 127, Batch number: 20, Loss: 131.22662353515625\n",
      "Epoch: 127, Batch number: 30, Loss: 122.40921783447266\n",
      "Epoch: 127, Batch number: 40, Loss: 120.38836669921875\n",
      "Epoch: 127, Batch number: 50, Loss: 122.30674743652344\n",
      "Epoch: 127, Batch number: 60, Loss: 104.85558319091797\n",
      "Epoch: 127, Batch number: 70, Loss: 125.0476303100586\n",
      "Epoch: 127, Batch number: 80, Loss: 118.65618896484375\n",
      "Epoch: 127, Batch number: 90, Loss: 139.99722290039062\n",
      "Epoch: 128, Batch number: 5, Loss: 133.93606567382812\n",
      "Epoch: 128, Batch number: 15, Loss: 112.23778533935547\n",
      "Epoch: 128, Batch number: 25, Loss: 115.89787292480469\n",
      "Epoch: 128, Batch number: 35, Loss: 115.69906616210938\n",
      "Epoch: 128, Batch number: 45, Loss: 140.8310089111328\n",
      "Epoch: 128, Batch number: 55, Loss: 110.6441421508789\n",
      "Epoch: 128, Batch number: 65, Loss: 114.25173950195312\n",
      "Epoch: 128, Batch number: 75, Loss: 101.19397735595703\n",
      "Epoch: 128, Batch number: 85, Loss: 125.66864776611328\n",
      "Epoch: 129, Batch number: 0, Loss: 119.63020324707031\n",
      "Epoch: 129, Batch number: 10, Loss: 121.15350341796875\n",
      "Epoch: 129, Batch number: 20, Loss: 121.33313751220703\n",
      "Epoch: 129, Batch number: 30, Loss: 108.5783920288086\n",
      "Epoch: 129, Batch number: 40, Loss: 133.50552368164062\n",
      "Epoch: 129, Batch number: 50, Loss: 91.53180694580078\n",
      "Epoch: 129, Batch number: 60, Loss: 117.04875946044922\n",
      "Epoch: 129, Batch number: 70, Loss: 117.0610580444336\n",
      "Epoch: 129, Batch number: 80, Loss: 112.27728271484375\n",
      "Epoch: 129, Batch number: 90, Loss: 112.0072021484375\n",
      "Epoch: 130, Batch number: 5, Loss: 97.71538543701172\n",
      "Epoch: 130, Batch number: 15, Loss: 134.7743682861328\n",
      "Epoch: 130, Batch number: 25, Loss: 120.80719757080078\n",
      "Epoch: 130, Batch number: 35, Loss: 102.64376831054688\n",
      "Epoch: 130, Batch number: 45, Loss: 112.75004577636719\n",
      "Epoch: 130, Batch number: 55, Loss: 116.0406723022461\n",
      "Epoch: 130, Batch number: 65, Loss: 109.35680389404297\n",
      "Epoch: 130, Batch number: 75, Loss: 129.44696044921875\n",
      "Epoch: 130, Batch number: 85, Loss: 135.32305908203125\n",
      "Epoch: 131, Batch number: 0, Loss: 108.68896484375\n",
      "Epoch: 131, Batch number: 10, Loss: 126.9537353515625\n",
      "Epoch: 131, Batch number: 20, Loss: 100.4881362915039\n",
      "Epoch: 131, Batch number: 30, Loss: 133.72938537597656\n",
      "Epoch: 131, Batch number: 40, Loss: 127.36637115478516\n",
      "Epoch: 131, Batch number: 50, Loss: 111.63558959960938\n",
      "Epoch: 131, Batch number: 60, Loss: 114.64007568359375\n",
      "Epoch: 131, Batch number: 70, Loss: 108.68269348144531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131, Batch number: 80, Loss: 127.43476867675781\n",
      "Epoch: 131, Batch number: 90, Loss: 126.59567260742188\n",
      "Epoch: 132, Batch number: 5, Loss: 114.57534790039062\n",
      "Epoch: 132, Batch number: 15, Loss: 94.42430114746094\n",
      "Epoch: 132, Batch number: 25, Loss: 98.76695251464844\n",
      "Epoch: 132, Batch number: 35, Loss: 127.63948059082031\n",
      "Epoch: 132, Batch number: 45, Loss: 118.9023208618164\n",
      "Epoch: 132, Batch number: 55, Loss: 115.8570556640625\n",
      "Epoch: 132, Batch number: 65, Loss: 111.89317321777344\n",
      "Epoch: 132, Batch number: 75, Loss: 146.99119567871094\n",
      "Epoch: 132, Batch number: 85, Loss: 125.3924560546875\n",
      "Epoch: 133, Batch number: 0, Loss: 99.56885528564453\n",
      "Epoch: 133, Batch number: 10, Loss: 99.85383605957031\n",
      "Epoch: 133, Batch number: 20, Loss: 94.50347900390625\n",
      "Epoch: 133, Batch number: 30, Loss: 118.0601806640625\n",
      "Epoch: 133, Batch number: 40, Loss: 84.2557373046875\n",
      "Epoch: 133, Batch number: 50, Loss: 132.43971252441406\n",
      "Epoch: 133, Batch number: 60, Loss: 115.188720703125\n",
      "Epoch: 133, Batch number: 70, Loss: 133.6805877685547\n",
      "Epoch: 133, Batch number: 80, Loss: 108.64288330078125\n",
      "Epoch: 133, Batch number: 90, Loss: 109.19796752929688\n",
      "Epoch: 134, Batch number: 5, Loss: 109.63912200927734\n",
      "Epoch: 134, Batch number: 15, Loss: 107.79141998291016\n",
      "Epoch: 134, Batch number: 25, Loss: 83.83056640625\n",
      "Epoch: 134, Batch number: 35, Loss: 91.31621551513672\n",
      "Epoch: 134, Batch number: 45, Loss: 118.44233703613281\n",
      "Epoch: 134, Batch number: 55, Loss: 109.3468017578125\n",
      "Epoch: 134, Batch number: 65, Loss: 114.7852554321289\n",
      "Epoch: 134, Batch number: 75, Loss: 111.26495361328125\n",
      "Epoch: 134, Batch number: 85, Loss: 129.8352508544922\n",
      "Epoch: 135, Batch number: 0, Loss: 87.75546264648438\n",
      "Epoch: 135, Batch number: 10, Loss: 87.65071105957031\n",
      "Epoch: 135, Batch number: 20, Loss: 114.26406860351562\n",
      "Epoch: 135, Batch number: 30, Loss: 131.857666015625\n",
      "Epoch: 135, Batch number: 40, Loss: 117.83290100097656\n",
      "Epoch: 135, Batch number: 50, Loss: 128.06126403808594\n",
      "Epoch: 135, Batch number: 60, Loss: 86.95207977294922\n",
      "Epoch: 135, Batch number: 70, Loss: 116.83502197265625\n",
      "Epoch: 135, Batch number: 80, Loss: 121.87470245361328\n",
      "Epoch: 135, Batch number: 90, Loss: 91.12384796142578\n",
      "Epoch: 136, Batch number: 5, Loss: 106.11790466308594\n",
      "Epoch: 136, Batch number: 15, Loss: 107.94769287109375\n",
      "Epoch: 136, Batch number: 25, Loss: 92.79769134521484\n",
      "Epoch: 136, Batch number: 35, Loss: 92.84616088867188\n",
      "Epoch: 136, Batch number: 45, Loss: 102.62873077392578\n",
      "Epoch: 136, Batch number: 55, Loss: 107.30694580078125\n",
      "Epoch: 136, Batch number: 65, Loss: 101.35104370117188\n",
      "Epoch: 136, Batch number: 75, Loss: 125.38842010498047\n",
      "Epoch: 136, Batch number: 85, Loss: 114.79629516601562\n",
      "Epoch: 137, Batch number: 0, Loss: 92.80296325683594\n",
      "Epoch: 137, Batch number: 10, Loss: 108.6922378540039\n",
      "Epoch: 137, Batch number: 20, Loss: 124.19413757324219\n",
      "Epoch: 137, Batch number: 30, Loss: 117.47489166259766\n",
      "Epoch: 137, Batch number: 40, Loss: 106.44051361083984\n",
      "Epoch: 137, Batch number: 50, Loss: 98.75728607177734\n",
      "Epoch: 137, Batch number: 60, Loss: 105.1107177734375\n",
      "Epoch: 137, Batch number: 70, Loss: 113.20770263671875\n",
      "Epoch: 137, Batch number: 80, Loss: 107.40502166748047\n",
      "Epoch: 137, Batch number: 90, Loss: 118.61492156982422\n",
      "Epoch: 138, Batch number: 5, Loss: 102.93531036376953\n",
      "Epoch: 138, Batch number: 15, Loss: 89.07379150390625\n",
      "Epoch: 138, Batch number: 25, Loss: 95.4488296508789\n",
      "Epoch: 138, Batch number: 35, Loss: 111.39273834228516\n",
      "Epoch: 138, Batch number: 45, Loss: 90.69819641113281\n",
      "Epoch: 138, Batch number: 55, Loss: 110.3508529663086\n",
      "Epoch: 138, Batch number: 65, Loss: 122.4821548461914\n",
      "Epoch: 138, Batch number: 75, Loss: 111.93941497802734\n",
      "Epoch: 138, Batch number: 85, Loss: 107.33547973632812\n",
      "Epoch: 139, Batch number: 0, Loss: 101.98775482177734\n",
      "Epoch: 139, Batch number: 10, Loss: 126.05543518066406\n",
      "Epoch: 139, Batch number: 20, Loss: 105.60192108154297\n",
      "Epoch: 139, Batch number: 30, Loss: 105.93318176269531\n",
      "Epoch: 139, Batch number: 40, Loss: 120.4015121459961\n",
      "Epoch: 139, Batch number: 50, Loss: 104.50567626953125\n",
      "Epoch: 139, Batch number: 60, Loss: 86.45603942871094\n",
      "Epoch: 139, Batch number: 70, Loss: 120.17692565917969\n",
      "Epoch: 139, Batch number: 80, Loss: 104.7984848022461\n",
      "Epoch: 139, Batch number: 90, Loss: 116.22038269042969\n",
      "Epoch: 140, Batch number: 5, Loss: 98.93927001953125\n",
      "Epoch: 140, Batch number: 15, Loss: 123.48486328125\n",
      "Epoch: 140, Batch number: 25, Loss: 114.62683868408203\n",
      "Epoch: 140, Batch number: 35, Loss: 103.23371124267578\n",
      "Epoch: 140, Batch number: 45, Loss: 95.28914642333984\n",
      "Epoch: 140, Batch number: 55, Loss: 109.60660552978516\n",
      "Epoch: 140, Batch number: 65, Loss: 98.71939086914062\n",
      "Epoch: 140, Batch number: 75, Loss: 104.9471206665039\n",
      "Epoch: 140, Batch number: 85, Loss: 108.44715118408203\n",
      "Epoch: 141, Batch number: 0, Loss: 90.83071899414062\n",
      "Epoch: 141, Batch number: 10, Loss: 104.53486633300781\n",
      "Epoch: 141, Batch number: 20, Loss: 88.48728942871094\n",
      "Epoch: 141, Batch number: 30, Loss: 113.90811157226562\n",
      "Epoch: 141, Batch number: 40, Loss: 109.78661346435547\n",
      "Epoch: 141, Batch number: 50, Loss: 107.10765075683594\n",
      "Epoch: 141, Batch number: 60, Loss: 101.68279266357422\n",
      "Epoch: 141, Batch number: 70, Loss: 107.0880355834961\n",
      "Epoch: 141, Batch number: 80, Loss: 112.64593505859375\n",
      "Epoch: 141, Batch number: 90, Loss: 128.99453735351562\n",
      "Epoch: 142, Batch number: 5, Loss: 113.50226593017578\n",
      "Epoch: 142, Batch number: 15, Loss: 89.32135009765625\n",
      "Epoch: 142, Batch number: 25, Loss: 107.53116607666016\n",
      "Epoch: 142, Batch number: 35, Loss: 91.12757873535156\n",
      "Epoch: 142, Batch number: 45, Loss: 100.82891845703125\n",
      "Epoch: 142, Batch number: 55, Loss: 111.79375457763672\n",
      "Epoch: 142, Batch number: 65, Loss: 138.5697021484375\n",
      "Epoch: 142, Batch number: 75, Loss: 99.07176208496094\n",
      "Epoch: 142, Batch number: 85, Loss: 93.11787414550781\n",
      "Epoch: 143, Batch number: 0, Loss: 115.07090759277344\n",
      "Epoch: 143, Batch number: 10, Loss: 88.79969024658203\n",
      "Epoch: 143, Batch number: 20, Loss: 103.61021423339844\n",
      "Epoch: 143, Batch number: 30, Loss: 95.35183715820312\n",
      "Epoch: 143, Batch number: 40, Loss: 92.9236831665039\n",
      "Epoch: 143, Batch number: 50, Loss: 104.89366149902344\n",
      "Epoch: 143, Batch number: 60, Loss: 94.85633850097656\n",
      "Epoch: 143, Batch number: 70, Loss: 126.71912384033203\n",
      "Epoch: 143, Batch number: 80, Loss: 122.78193664550781\n",
      "Epoch: 143, Batch number: 90, Loss: 106.8035888671875\n",
      "Epoch: 144, Batch number: 5, Loss: 86.37590789794922\n",
      "Epoch: 144, Batch number: 15, Loss: 91.96283721923828\n",
      "Epoch: 144, Batch number: 25, Loss: 93.3624038696289\n",
      "Epoch: 144, Batch number: 35, Loss: 108.38787841796875\n",
      "Epoch: 144, Batch number: 45, Loss: 108.91447448730469\n",
      "Epoch: 144, Batch number: 55, Loss: 103.1706771850586\n",
      "Epoch: 144, Batch number: 65, Loss: 109.92570495605469\n",
      "Epoch: 144, Batch number: 75, Loss: 94.80902099609375\n",
      "Epoch: 144, Batch number: 85, Loss: 130.43533325195312\n",
      "Epoch: 145, Batch number: 0, Loss: 128.89158630371094\n",
      "Epoch: 145, Batch number: 10, Loss: 78.68782043457031\n",
      "Epoch: 145, Batch number: 20, Loss: 113.2803726196289\n",
      "Epoch: 145, Batch number: 30, Loss: 90.99726104736328\n",
      "Epoch: 145, Batch number: 40, Loss: 80.91259002685547\n",
      "Epoch: 145, Batch number: 50, Loss: 100.35426330566406\n",
      "Epoch: 145, Batch number: 60, Loss: 86.77466583251953\n",
      "Epoch: 145, Batch number: 70, Loss: 108.42166137695312\n",
      "Epoch: 145, Batch number: 80, Loss: 89.19091796875\n",
      "Epoch: 145, Batch number: 90, Loss: 103.69164276123047\n",
      "Epoch: 146, Batch number: 5, Loss: 95.53982543945312\n",
      "Epoch: 146, Batch number: 15, Loss: 70.86095428466797\n",
      "Epoch: 146, Batch number: 25, Loss: 85.04141998291016\n",
      "Epoch: 146, Batch number: 35, Loss: 102.37154388427734\n",
      "Epoch: 146, Batch number: 45, Loss: 103.03844451904297\n",
      "Epoch: 146, Batch number: 55, Loss: 99.26638793945312\n",
      "Epoch: 146, Batch number: 65, Loss: 84.68596649169922\n",
      "Epoch: 146, Batch number: 75, Loss: 111.38790130615234\n",
      "Epoch: 146, Batch number: 85, Loss: 100.3003921508789\n",
      "Epoch: 147, Batch number: 0, Loss: 95.55061340332031\n",
      "Epoch: 147, Batch number: 10, Loss: 89.37664794921875\n",
      "Epoch: 147, Batch number: 20, Loss: 86.92202758789062\n",
      "Epoch: 147, Batch number: 30, Loss: 95.95178985595703\n",
      "Epoch: 147, Batch number: 40, Loss: 83.83523559570312\n",
      "Epoch: 147, Batch number: 50, Loss: 92.01918029785156\n",
      "Epoch: 147, Batch number: 60, Loss: 108.15066528320312\n",
      "Epoch: 147, Batch number: 70, Loss: 124.06387329101562\n",
      "Epoch: 147, Batch number: 80, Loss: 83.5025863647461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147, Batch number: 90, Loss: 117.02488708496094\n",
      "Epoch: 148, Batch number: 5, Loss: 80.59514617919922\n",
      "Epoch: 148, Batch number: 15, Loss: 96.38876342773438\n",
      "Epoch: 148, Batch number: 25, Loss: 102.18623352050781\n",
      "Epoch: 148, Batch number: 35, Loss: 84.48875427246094\n",
      "Epoch: 148, Batch number: 45, Loss: 71.03653717041016\n",
      "Epoch: 148, Batch number: 55, Loss: 90.73805236816406\n",
      "Epoch: 148, Batch number: 65, Loss: 86.6068115234375\n",
      "Epoch: 148, Batch number: 75, Loss: 97.34827423095703\n",
      "Epoch: 148, Batch number: 85, Loss: 78.01703643798828\n",
      "Epoch: 149, Batch number: 0, Loss: 103.14219665527344\n",
      "Epoch: 149, Batch number: 10, Loss: 102.76763153076172\n",
      "Epoch: 149, Batch number: 20, Loss: 90.27376556396484\n",
      "Epoch: 149, Batch number: 30, Loss: 81.4084243774414\n",
      "Epoch: 149, Batch number: 40, Loss: 107.82283020019531\n",
      "Epoch: 149, Batch number: 50, Loss: 103.40794372558594\n",
      "Epoch: 149, Batch number: 60, Loss: 92.10921478271484\n",
      "Epoch: 149, Batch number: 70, Loss: 93.35690307617188\n",
      "Epoch: 149, Batch number: 80, Loss: 94.65738677978516\n",
      "Epoch: 149, Batch number: 90, Loss: 84.9501953125\n",
      "Epoch: 150, Batch number: 5, Loss: 82.68733215332031\n",
      "Epoch: 150, Batch number: 15, Loss: 96.73693084716797\n",
      "Epoch: 150, Batch number: 25, Loss: 109.04264068603516\n",
      "Epoch: 150, Batch number: 35, Loss: 102.47784423828125\n",
      "Epoch: 150, Batch number: 45, Loss: 109.8445053100586\n",
      "Epoch: 150, Batch number: 55, Loss: 104.47932434082031\n",
      "Epoch: 150, Batch number: 65, Loss: 103.10435485839844\n",
      "Epoch: 150, Batch number: 75, Loss: 132.3496856689453\n",
      "Epoch: 150, Batch number: 85, Loss: 108.58152770996094\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos:\n",
    "\n",
    "window_size = 2           # Tama√±o de la ventana del contexto.\n",
    "cutoff_freq = 0           # Palabras con una frecuencia menor o igual a cutoff_freq son exclu√≠das del vocabulario.\n",
    "batch_size = 512          # Tama√±o del batch.\n",
    "\n",
    "model = 'CBOW'            # M√©todo de entrenamiento.\n",
    "embedding_dim = 200       # Dimensi√≥n del espacio de los word vectors.\n",
    "device = 'cuda:1'         # Dispositivo sobre el cual se entrena. \n",
    "state_dict = None         # Par√°metros pre-entrenados.\n",
    "paralelize = False        # Flag para decirle al programa que use las 2 gpus\n",
    "\n",
    "trainer = Word2vecTrainer(corpus,cutoff_freq=cutoff_freq,window_size=window_size,batch_size=batch_size)\n",
    "trainer.InitModel(model=model, state_dict=state_dict, device=device, paralelize=paralelize, embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 5e-05\n",
      "Number of epochs: 150\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 66.24236297607422\n",
      "Epoch: 1, Batch number: 10, Loss: 101.70799255371094\n",
      "Epoch: 1, Batch number: 20, Loss: 94.98567962646484\n",
      "Epoch: 1, Batch number: 30, Loss: 99.78288269042969\n",
      "Epoch: 1, Batch number: 40, Loss: 97.64937591552734\n",
      "Epoch: 1, Batch number: 50, Loss: 107.68511199951172\n",
      "Epoch: 1, Batch number: 60, Loss: 74.23890686035156\n",
      "Epoch: 1, Batch number: 70, Loss: 92.66578674316406\n",
      "Epoch: 1, Batch number: 80, Loss: 97.53971862792969\n",
      "Epoch: 1, Batch number: 90, Loss: 88.74398803710938\n",
      "Epoch: 2, Batch number: 5, Loss: 67.59140014648438\n",
      "Epoch: 2, Batch number: 15, Loss: 94.34934997558594\n",
      "Epoch: 2, Batch number: 25, Loss: 110.85012817382812\n",
      "Epoch: 2, Batch number: 35, Loss: 91.55830383300781\n",
      "Epoch: 2, Batch number: 45, Loss: 90.45902252197266\n",
      "Epoch: 2, Batch number: 55, Loss: 79.17151641845703\n",
      "Epoch: 2, Batch number: 65, Loss: 116.04524993896484\n",
      "Epoch: 2, Batch number: 75, Loss: 92.02190399169922\n",
      "Epoch: 2, Batch number: 85, Loss: 92.48639678955078\n",
      "Epoch: 3, Batch number: 0, Loss: 116.89031982421875\n",
      "Epoch: 3, Batch number: 10, Loss: 83.51849365234375\n",
      "Epoch: 3, Batch number: 20, Loss: 105.10140991210938\n",
      "Epoch: 3, Batch number: 30, Loss: 99.88028717041016\n",
      "Epoch: 3, Batch number: 40, Loss: 99.09429168701172\n",
      "Epoch: 3, Batch number: 50, Loss: 104.63837432861328\n",
      "Epoch: 3, Batch number: 60, Loss: 98.86589050292969\n",
      "Epoch: 3, Batch number: 70, Loss: 84.68084716796875\n",
      "Epoch: 3, Batch number: 80, Loss: 105.57652282714844\n",
      "Epoch: 3, Batch number: 90, Loss: 85.85306549072266\n",
      "Epoch: 4, Batch number: 5, Loss: 99.33379364013672\n",
      "Epoch: 4, Batch number: 15, Loss: 90.36589050292969\n",
      "Epoch: 4, Batch number: 25, Loss: 110.38538360595703\n",
      "Epoch: 4, Batch number: 35, Loss: 87.0216064453125\n",
      "Epoch: 4, Batch number: 45, Loss: 114.98416900634766\n",
      "Epoch: 4, Batch number: 55, Loss: 91.07154846191406\n",
      "Epoch: 4, Batch number: 65, Loss: 87.55651092529297\n",
      "Epoch: 4, Batch number: 75, Loss: 84.12090301513672\n",
      "Epoch: 4, Batch number: 85, Loss: 90.81134033203125\n",
      "Epoch: 5, Batch number: 0, Loss: 80.26139068603516\n",
      "Epoch: 5, Batch number: 10, Loss: 128.4062957763672\n",
      "Epoch: 5, Batch number: 20, Loss: 107.41857147216797\n",
      "Epoch: 5, Batch number: 30, Loss: 100.28459167480469\n",
      "Epoch: 5, Batch number: 40, Loss: 63.846961975097656\n",
      "Epoch: 5, Batch number: 50, Loss: 89.13300323486328\n",
      "Epoch: 5, Batch number: 60, Loss: 68.9666748046875\n",
      "Epoch: 5, Batch number: 70, Loss: 108.49828338623047\n",
      "Epoch: 5, Batch number: 80, Loss: 100.03578186035156\n",
      "Epoch: 5, Batch number: 90, Loss: 89.32792663574219\n",
      "Epoch: 6, Batch number: 5, Loss: 87.77238464355469\n",
      "Epoch: 6, Batch number: 15, Loss: 92.9341812133789\n",
      "Epoch: 6, Batch number: 25, Loss: 86.9437484741211\n",
      "Epoch: 6, Batch number: 35, Loss: 106.31355285644531\n",
      "Epoch: 6, Batch number: 45, Loss: 109.42571258544922\n",
      "Epoch: 6, Batch number: 55, Loss: 86.12592315673828\n",
      "Epoch: 6, Batch number: 65, Loss: 87.63569641113281\n",
      "Epoch: 6, Batch number: 75, Loss: 78.42639923095703\n",
      "Epoch: 6, Batch number: 85, Loss: 81.3912582397461\n",
      "Epoch: 7, Batch number: 0, Loss: 83.92074584960938\n",
      "Epoch: 7, Batch number: 10, Loss: 93.05113220214844\n",
      "Epoch: 7, Batch number: 20, Loss: 70.8791732788086\n",
      "Epoch: 7, Batch number: 30, Loss: 74.26786041259766\n",
      "Epoch: 7, Batch number: 40, Loss: 107.55683135986328\n",
      "Epoch: 7, Batch number: 50, Loss: 99.39275360107422\n",
      "Epoch: 7, Batch number: 60, Loss: 84.79684448242188\n",
      "Epoch: 7, Batch number: 70, Loss: 87.19330596923828\n",
      "Epoch: 7, Batch number: 80, Loss: 74.72870635986328\n",
      "Epoch: 7, Batch number: 90, Loss: 97.0493392944336\n",
      "Epoch: 8, Batch number: 5, Loss: 88.18521118164062\n",
      "Epoch: 8, Batch number: 15, Loss: 71.84243774414062\n",
      "Epoch: 8, Batch number: 25, Loss: 89.82980346679688\n",
      "Epoch: 8, Batch number: 35, Loss: 95.27536010742188\n",
      "Epoch: 8, Batch number: 45, Loss: 113.50819396972656\n",
      "Epoch: 8, Batch number: 55, Loss: 102.28425598144531\n",
      "Epoch: 8, Batch number: 65, Loss: 76.90947723388672\n",
      "Epoch: 8, Batch number: 75, Loss: 95.97209167480469\n",
      "Epoch: 8, Batch number: 85, Loss: 91.84341430664062\n",
      "Epoch: 9, Batch number: 0, Loss: 108.55619812011719\n",
      "Epoch: 9, Batch number: 10, Loss: 115.97241973876953\n",
      "Epoch: 9, Batch number: 20, Loss: 89.02272033691406\n",
      "Epoch: 9, Batch number: 30, Loss: 79.4098892211914\n",
      "Epoch: 9, Batch number: 40, Loss: 86.36383056640625\n",
      "Epoch: 9, Batch number: 50, Loss: 75.08464050292969\n",
      "Epoch: 9, Batch number: 60, Loss: 77.29495239257812\n",
      "Epoch: 9, Batch number: 70, Loss: 83.87677001953125\n",
      "Epoch: 9, Batch number: 80, Loss: 111.9547119140625\n",
      "Epoch: 9, Batch number: 90, Loss: 86.64035034179688\n",
      "Epoch: 10, Batch number: 5, Loss: 80.86779022216797\n",
      "Epoch: 10, Batch number: 15, Loss: 106.03379821777344\n",
      "Epoch: 10, Batch number: 25, Loss: 84.72478485107422\n",
      "Epoch: 10, Batch number: 35, Loss: 99.72311401367188\n",
      "Epoch: 10, Batch number: 45, Loss: 102.18914794921875\n",
      "Epoch: 10, Batch number: 55, Loss: 65.47357177734375\n",
      "Epoch: 10, Batch number: 65, Loss: 80.72099304199219\n",
      "Epoch: 10, Batch number: 75, Loss: 94.27571105957031\n",
      "Epoch: 10, Batch number: 85, Loss: 81.95856475830078\n",
      "Epoch: 11, Batch number: 0, Loss: 82.63587188720703\n",
      "Epoch: 11, Batch number: 10, Loss: 100.62101745605469\n",
      "Epoch: 11, Batch number: 20, Loss: 80.48806762695312\n",
      "Epoch: 11, Batch number: 30, Loss: 74.89443969726562\n",
      "Epoch: 11, Batch number: 40, Loss: 81.33447265625\n",
      "Epoch: 11, Batch number: 50, Loss: 103.25569152832031\n",
      "Epoch: 11, Batch number: 60, Loss: 88.16857147216797\n",
      "Epoch: 11, Batch number: 70, Loss: 87.309326171875\n",
      "Epoch: 11, Batch number: 80, Loss: 94.75303649902344\n",
      "Epoch: 11, Batch number: 90, Loss: 109.70743560791016\n",
      "Epoch: 12, Batch number: 5, Loss: 101.08673858642578\n",
      "Epoch: 12, Batch number: 15, Loss: 82.37770080566406\n",
      "Epoch: 12, Batch number: 25, Loss: 91.63795471191406\n",
      "Epoch: 12, Batch number: 35, Loss: 96.87427520751953\n",
      "Epoch: 12, Batch number: 45, Loss: 94.67738342285156\n",
      "Epoch: 12, Batch number: 55, Loss: 90.22277069091797\n",
      "Epoch: 12, Batch number: 65, Loss: 102.94915008544922\n",
      "Epoch: 12, Batch number: 75, Loss: 91.2413558959961\n",
      "Epoch: 12, Batch number: 85, Loss: 91.31053161621094\n",
      "Epoch: 13, Batch number: 0, Loss: 78.75586700439453\n",
      "Epoch: 13, Batch number: 10, Loss: 76.70540618896484\n",
      "Epoch: 13, Batch number: 20, Loss: 93.27925872802734\n",
      "Epoch: 13, Batch number: 30, Loss: 93.15851593017578\n",
      "Epoch: 13, Batch number: 40, Loss: 99.31624603271484\n",
      "Epoch: 13, Batch number: 50, Loss: 87.0470962524414\n",
      "Epoch: 13, Batch number: 60, Loss: 82.71273803710938\n",
      "Epoch: 13, Batch number: 70, Loss: 65.04083251953125\n",
      "Epoch: 13, Batch number: 80, Loss: 74.66283416748047\n",
      "Epoch: 13, Batch number: 90, Loss: 86.21222686767578\n",
      "Epoch: 14, Batch number: 5, Loss: 86.19181823730469\n",
      "Epoch: 14, Batch number: 15, Loss: 83.55794525146484\n",
      "Epoch: 14, Batch number: 25, Loss: 98.02908325195312\n",
      "Epoch: 14, Batch number: 35, Loss: 94.68850708007812\n",
      "Epoch: 14, Batch number: 45, Loss: 79.31660461425781\n",
      "Epoch: 14, Batch number: 55, Loss: 66.10812377929688\n",
      "Epoch: 14, Batch number: 65, Loss: 86.1267318725586\n",
      "Epoch: 14, Batch number: 75, Loss: 82.76234436035156\n",
      "Epoch: 14, Batch number: 85, Loss: 116.80416870117188\n",
      "Epoch: 15, Batch number: 0, Loss: 92.43549346923828\n",
      "Epoch: 15, Batch number: 10, Loss: 90.15663146972656\n",
      "Epoch: 15, Batch number: 20, Loss: 75.49971008300781\n",
      "Epoch: 15, Batch number: 30, Loss: 78.52822875976562\n",
      "Epoch: 15, Batch number: 40, Loss: 89.65515899658203\n",
      "Epoch: 15, Batch number: 50, Loss: 72.63838195800781\n",
      "Epoch: 15, Batch number: 60, Loss: 70.68831634521484\n",
      "Epoch: 15, Batch number: 70, Loss: 85.95262908935547\n",
      "Epoch: 15, Batch number: 80, Loss: 121.6328353881836\n",
      "Epoch: 15, Batch number: 90, Loss: 103.92176818847656\n",
      "Epoch: 16, Batch number: 5, Loss: 93.4668197631836\n",
      "Epoch: 16, Batch number: 15, Loss: 108.13397216796875\n",
      "Epoch: 16, Batch number: 25, Loss: 87.18551635742188\n",
      "Epoch: 16, Batch number: 35, Loss: 81.96293640136719\n",
      "Epoch: 16, Batch number: 45, Loss: 78.84803771972656\n",
      "Epoch: 16, Batch number: 55, Loss: 108.06190490722656\n",
      "Epoch: 16, Batch number: 65, Loss: 77.7208251953125\n",
      "Epoch: 16, Batch number: 75, Loss: 88.76311492919922\n",
      "Epoch: 16, Batch number: 85, Loss: 77.51826477050781\n",
      "Epoch: 17, Batch number: 0, Loss: 85.14688110351562\n",
      "Epoch: 17, Batch number: 10, Loss: 96.37207794189453\n",
      "Epoch: 17, Batch number: 20, Loss: 112.40650939941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Batch number: 30, Loss: 94.51021575927734\n",
      "Epoch: 17, Batch number: 40, Loss: 63.7860221862793\n",
      "Epoch: 17, Batch number: 50, Loss: 106.34960174560547\n",
      "Epoch: 17, Batch number: 60, Loss: 79.8295669555664\n",
      "Epoch: 17, Batch number: 70, Loss: 83.40621948242188\n",
      "Epoch: 17, Batch number: 80, Loss: 88.38886260986328\n",
      "Epoch: 17, Batch number: 90, Loss: 87.67735290527344\n",
      "Epoch: 18, Batch number: 5, Loss: 74.39984893798828\n",
      "Epoch: 18, Batch number: 15, Loss: 109.98320007324219\n",
      "Epoch: 18, Batch number: 25, Loss: 101.43897247314453\n",
      "Epoch: 18, Batch number: 35, Loss: 106.14339447021484\n",
      "Epoch: 18, Batch number: 45, Loss: 79.77194213867188\n",
      "Epoch: 18, Batch number: 55, Loss: 81.88912200927734\n",
      "Epoch: 18, Batch number: 65, Loss: 87.53842163085938\n",
      "Epoch: 18, Batch number: 75, Loss: 74.71806335449219\n",
      "Epoch: 18, Batch number: 85, Loss: 94.2664794921875\n",
      "Epoch: 19, Batch number: 0, Loss: 86.07586669921875\n",
      "Epoch: 19, Batch number: 10, Loss: 119.21308135986328\n",
      "Epoch: 19, Batch number: 20, Loss: 105.87179565429688\n",
      "Epoch: 19, Batch number: 30, Loss: 95.6767807006836\n",
      "Epoch: 19, Batch number: 40, Loss: 83.31446075439453\n",
      "Epoch: 19, Batch number: 50, Loss: 84.24378967285156\n",
      "Epoch: 19, Batch number: 60, Loss: 84.35835266113281\n",
      "Epoch: 19, Batch number: 70, Loss: 88.99728393554688\n",
      "Epoch: 19, Batch number: 80, Loss: 76.06385803222656\n",
      "Epoch: 19, Batch number: 90, Loss: 89.12113952636719\n",
      "Epoch: 20, Batch number: 5, Loss: 74.83079528808594\n",
      "Epoch: 20, Batch number: 15, Loss: 90.85295104980469\n",
      "Epoch: 20, Batch number: 25, Loss: 104.99955749511719\n",
      "Epoch: 20, Batch number: 35, Loss: 88.53642272949219\n",
      "Epoch: 20, Batch number: 45, Loss: 99.42395782470703\n",
      "Epoch: 20, Batch number: 55, Loss: 77.33585357666016\n",
      "Epoch: 20, Batch number: 65, Loss: 103.9289779663086\n",
      "Epoch: 20, Batch number: 75, Loss: 85.98031616210938\n",
      "Epoch: 20, Batch number: 85, Loss: 95.2424545288086\n",
      "Epoch: 21, Batch number: 0, Loss: 87.19328308105469\n",
      "Epoch: 21, Batch number: 10, Loss: 88.64298248291016\n",
      "Epoch: 21, Batch number: 20, Loss: 90.94088745117188\n",
      "Epoch: 21, Batch number: 30, Loss: 108.44741821289062\n",
      "Epoch: 21, Batch number: 40, Loss: 98.01392364501953\n",
      "Epoch: 21, Batch number: 50, Loss: 127.40839385986328\n",
      "Epoch: 21, Batch number: 60, Loss: 89.46551513671875\n",
      "Epoch: 21, Batch number: 70, Loss: 75.45747375488281\n",
      "Epoch: 21, Batch number: 80, Loss: 92.53433227539062\n",
      "Epoch: 21, Batch number: 90, Loss: 99.5344009399414\n",
      "Epoch: 22, Batch number: 5, Loss: 77.26819610595703\n",
      "Epoch: 22, Batch number: 15, Loss: 115.556640625\n",
      "Epoch: 22, Batch number: 25, Loss: 78.323486328125\n",
      "Epoch: 22, Batch number: 35, Loss: 96.0143814086914\n",
      "Epoch: 22, Batch number: 45, Loss: 114.2325210571289\n",
      "Epoch: 22, Batch number: 55, Loss: 64.78042602539062\n",
      "Epoch: 22, Batch number: 65, Loss: 74.01130676269531\n",
      "Epoch: 22, Batch number: 75, Loss: 104.18075561523438\n",
      "Epoch: 22, Batch number: 85, Loss: 75.11589050292969\n",
      "Epoch: 23, Batch number: 0, Loss: 122.85000610351562\n",
      "Epoch: 23, Batch number: 10, Loss: 83.64083862304688\n",
      "Epoch: 23, Batch number: 20, Loss: 111.35539245605469\n",
      "Epoch: 23, Batch number: 30, Loss: 103.67162322998047\n",
      "Epoch: 23, Batch number: 40, Loss: 92.37016296386719\n",
      "Epoch: 23, Batch number: 50, Loss: 105.06843566894531\n",
      "Epoch: 23, Batch number: 60, Loss: 75.08612823486328\n",
      "Epoch: 23, Batch number: 70, Loss: 104.83280181884766\n",
      "Epoch: 23, Batch number: 80, Loss: 108.0015869140625\n",
      "Epoch: 23, Batch number: 90, Loss: 86.32456970214844\n",
      "Epoch: 24, Batch number: 5, Loss: 86.11460876464844\n",
      "Epoch: 24, Batch number: 15, Loss: 103.72559356689453\n",
      "Epoch: 24, Batch number: 25, Loss: 70.50391387939453\n",
      "Epoch: 24, Batch number: 35, Loss: 93.5270767211914\n",
      "Epoch: 24, Batch number: 45, Loss: 100.7537612915039\n",
      "Epoch: 24, Batch number: 55, Loss: 84.31997680664062\n",
      "Epoch: 24, Batch number: 65, Loss: 83.08575439453125\n",
      "Epoch: 24, Batch number: 75, Loss: 76.38744354248047\n",
      "Epoch: 24, Batch number: 85, Loss: 88.51341247558594\n",
      "Epoch: 25, Batch number: 0, Loss: 88.69709014892578\n",
      "Epoch: 25, Batch number: 10, Loss: 90.54280090332031\n",
      "Epoch: 25, Batch number: 20, Loss: 119.64630889892578\n",
      "Epoch: 25, Batch number: 30, Loss: 82.18286895751953\n",
      "Epoch: 25, Batch number: 40, Loss: 111.95301818847656\n",
      "Epoch: 25, Batch number: 50, Loss: 96.6461181640625\n",
      "Epoch: 25, Batch number: 60, Loss: 103.03349304199219\n",
      "Epoch: 25, Batch number: 70, Loss: 89.01504516601562\n",
      "Epoch: 25, Batch number: 80, Loss: 92.65205383300781\n",
      "Epoch: 25, Batch number: 90, Loss: 83.4000473022461\n",
      "Epoch: 26, Batch number: 5, Loss: 100.27418518066406\n",
      "Epoch: 26, Batch number: 15, Loss: 82.72254943847656\n",
      "Epoch: 26, Batch number: 25, Loss: 94.091064453125\n",
      "Epoch: 26, Batch number: 35, Loss: 86.65446472167969\n",
      "Epoch: 26, Batch number: 45, Loss: 84.38909912109375\n",
      "Epoch: 26, Batch number: 55, Loss: 90.15367126464844\n",
      "Epoch: 26, Batch number: 65, Loss: 77.32252502441406\n",
      "Epoch: 26, Batch number: 75, Loss: 105.05824279785156\n",
      "Epoch: 26, Batch number: 85, Loss: 99.71861267089844\n",
      "Epoch: 27, Batch number: 0, Loss: 99.15086364746094\n",
      "Epoch: 27, Batch number: 10, Loss: 86.39264678955078\n",
      "Epoch: 27, Batch number: 20, Loss: 94.45612335205078\n",
      "Epoch: 27, Batch number: 30, Loss: 79.92269897460938\n",
      "Epoch: 27, Batch number: 40, Loss: 87.888671875\n",
      "Epoch: 27, Batch number: 50, Loss: 86.5848617553711\n",
      "Epoch: 27, Batch number: 60, Loss: 81.45122528076172\n",
      "Epoch: 27, Batch number: 70, Loss: 83.39776611328125\n",
      "Epoch: 27, Batch number: 80, Loss: 99.25909423828125\n",
      "Epoch: 27, Batch number: 90, Loss: 76.77232360839844\n",
      "Epoch: 28, Batch number: 5, Loss: 114.23181915283203\n",
      "Epoch: 28, Batch number: 15, Loss: 85.72453308105469\n",
      "Epoch: 28, Batch number: 25, Loss: 90.36582946777344\n",
      "Epoch: 28, Batch number: 35, Loss: 80.37173461914062\n",
      "Epoch: 28, Batch number: 45, Loss: 73.27986145019531\n",
      "Epoch: 28, Batch number: 55, Loss: 91.28046417236328\n",
      "Epoch: 28, Batch number: 65, Loss: 97.61270141601562\n",
      "Epoch: 28, Batch number: 75, Loss: 91.12313079833984\n",
      "Epoch: 28, Batch number: 85, Loss: 81.7405776977539\n",
      "Epoch: 29, Batch number: 0, Loss: 82.95085906982422\n",
      "Epoch: 29, Batch number: 10, Loss: 87.23632049560547\n",
      "Epoch: 29, Batch number: 20, Loss: 89.92674255371094\n",
      "Epoch: 29, Batch number: 30, Loss: 87.61781311035156\n",
      "Epoch: 29, Batch number: 40, Loss: 86.65164947509766\n",
      "Epoch: 29, Batch number: 50, Loss: 114.55226135253906\n",
      "Epoch: 29, Batch number: 60, Loss: 105.83563995361328\n",
      "Epoch: 29, Batch number: 70, Loss: 91.03465270996094\n",
      "Epoch: 29, Batch number: 80, Loss: 112.715087890625\n",
      "Epoch: 29, Batch number: 90, Loss: 85.41189575195312\n",
      "Epoch: 30, Batch number: 5, Loss: 79.96092987060547\n",
      "Epoch: 30, Batch number: 15, Loss: 98.32769012451172\n",
      "Epoch: 30, Batch number: 25, Loss: 99.27214813232422\n",
      "Epoch: 30, Batch number: 35, Loss: 80.37858581542969\n",
      "Epoch: 30, Batch number: 45, Loss: 88.11170959472656\n",
      "Epoch: 30, Batch number: 55, Loss: 86.23268127441406\n",
      "Epoch: 30, Batch number: 65, Loss: 80.68494415283203\n",
      "Epoch: 30, Batch number: 75, Loss: 69.14534759521484\n",
      "Epoch: 30, Batch number: 85, Loss: 85.9291763305664\n",
      "Epoch: 31, Batch number: 0, Loss: 90.16819763183594\n",
      "Epoch: 31, Batch number: 10, Loss: 77.03504943847656\n",
      "Epoch: 31, Batch number: 20, Loss: 78.25222778320312\n",
      "Epoch: 31, Batch number: 30, Loss: 88.5344009399414\n",
      "Epoch: 31, Batch number: 40, Loss: 80.64989471435547\n",
      "Epoch: 31, Batch number: 50, Loss: 88.8011245727539\n",
      "Epoch: 31, Batch number: 60, Loss: 84.90055084228516\n",
      "Epoch: 31, Batch number: 70, Loss: 89.56156158447266\n",
      "Epoch: 31, Batch number: 80, Loss: 90.22413635253906\n",
      "Epoch: 31, Batch number: 90, Loss: 84.83857727050781\n",
      "Epoch: 32, Batch number: 5, Loss: 102.72425079345703\n",
      "Epoch: 32, Batch number: 15, Loss: 85.60669708251953\n",
      "Epoch: 32, Batch number: 25, Loss: 103.41937255859375\n",
      "Epoch: 32, Batch number: 35, Loss: 93.38648986816406\n",
      "Epoch: 32, Batch number: 45, Loss: 77.58667755126953\n",
      "Epoch: 32, Batch number: 55, Loss: 85.18338775634766\n",
      "Epoch: 32, Batch number: 65, Loss: 86.92948913574219\n",
      "Epoch: 32, Batch number: 75, Loss: 88.13363647460938\n",
      "Epoch: 32, Batch number: 85, Loss: 81.88639831542969\n",
      "Epoch: 33, Batch number: 0, Loss: 75.73905944824219\n",
      "Epoch: 33, Batch number: 10, Loss: 96.01485443115234\n",
      "Epoch: 33, Batch number: 20, Loss: 92.03073120117188\n",
      "Epoch: 33, Batch number: 30, Loss: 87.36829376220703\n",
      "Epoch: 33, Batch number: 40, Loss: 58.7072868347168\n",
      "Epoch: 33, Batch number: 50, Loss: 86.4393539428711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Batch number: 60, Loss: 83.43301391601562\n",
      "Epoch: 33, Batch number: 70, Loss: 83.62295532226562\n",
      "Epoch: 33, Batch number: 80, Loss: 83.70841979980469\n",
      "Epoch: 33, Batch number: 90, Loss: 73.794677734375\n",
      "Epoch: 34, Batch number: 5, Loss: 76.89804077148438\n",
      "Epoch: 34, Batch number: 15, Loss: 90.53467559814453\n",
      "Epoch: 34, Batch number: 25, Loss: 82.55679321289062\n",
      "Epoch: 34, Batch number: 35, Loss: 93.77931213378906\n",
      "Epoch: 34, Batch number: 45, Loss: 84.83267211914062\n",
      "Epoch: 34, Batch number: 55, Loss: 104.9332046508789\n",
      "Epoch: 34, Batch number: 65, Loss: 112.92799377441406\n",
      "Epoch: 34, Batch number: 75, Loss: 93.7670669555664\n",
      "Epoch: 34, Batch number: 85, Loss: 105.86275482177734\n",
      "Epoch: 35, Batch number: 0, Loss: 80.53984832763672\n",
      "Epoch: 35, Batch number: 10, Loss: 94.37034606933594\n",
      "Epoch: 35, Batch number: 20, Loss: 88.59504699707031\n",
      "Epoch: 35, Batch number: 30, Loss: 105.31785583496094\n",
      "Epoch: 35, Batch number: 40, Loss: 80.61067199707031\n",
      "Epoch: 35, Batch number: 50, Loss: 82.91951751708984\n",
      "Epoch: 35, Batch number: 60, Loss: 96.48036193847656\n",
      "Epoch: 35, Batch number: 70, Loss: 89.6512222290039\n",
      "Epoch: 35, Batch number: 80, Loss: 88.28177642822266\n",
      "Epoch: 35, Batch number: 90, Loss: 74.81332397460938\n",
      "Epoch: 36, Batch number: 5, Loss: 74.73572540283203\n",
      "Epoch: 36, Batch number: 15, Loss: 84.09284210205078\n",
      "Epoch: 36, Batch number: 25, Loss: 94.93536376953125\n",
      "Epoch: 36, Batch number: 35, Loss: 82.40601348876953\n",
      "Epoch: 36, Batch number: 45, Loss: 72.97494506835938\n",
      "Epoch: 36, Batch number: 55, Loss: 74.97589111328125\n",
      "Epoch: 36, Batch number: 65, Loss: 98.66535949707031\n",
      "Epoch: 36, Batch number: 75, Loss: 74.25676727294922\n",
      "Epoch: 36, Batch number: 85, Loss: 62.36836242675781\n",
      "Epoch: 37, Batch number: 0, Loss: 101.33267211914062\n",
      "Epoch: 37, Batch number: 10, Loss: 99.42713928222656\n",
      "Epoch: 37, Batch number: 20, Loss: 95.9032211303711\n",
      "Epoch: 37, Batch number: 30, Loss: 74.05825805664062\n",
      "Epoch: 37, Batch number: 40, Loss: 98.554443359375\n",
      "Epoch: 37, Batch number: 50, Loss: 77.09070587158203\n",
      "Epoch: 37, Batch number: 60, Loss: 85.61949920654297\n",
      "Epoch: 37, Batch number: 70, Loss: 107.64852905273438\n",
      "Epoch: 37, Batch number: 80, Loss: 79.02525329589844\n",
      "Epoch: 37, Batch number: 90, Loss: 90.96966552734375\n",
      "Epoch: 38, Batch number: 5, Loss: 94.45594787597656\n",
      "Epoch: 38, Batch number: 15, Loss: 93.30152893066406\n",
      "Epoch: 38, Batch number: 25, Loss: 88.05209350585938\n",
      "Epoch: 38, Batch number: 35, Loss: 101.8809814453125\n",
      "Epoch: 38, Batch number: 45, Loss: 91.11992645263672\n",
      "Epoch: 38, Batch number: 55, Loss: 83.85365295410156\n",
      "Epoch: 38, Batch number: 65, Loss: 102.37146759033203\n",
      "Epoch: 38, Batch number: 75, Loss: 112.78614807128906\n",
      "Epoch: 38, Batch number: 85, Loss: 101.64862060546875\n",
      "Epoch: 39, Batch number: 0, Loss: 111.36701965332031\n",
      "Epoch: 39, Batch number: 10, Loss: 78.42518615722656\n",
      "Epoch: 39, Batch number: 20, Loss: 80.7751693725586\n",
      "Epoch: 39, Batch number: 30, Loss: 129.41751098632812\n",
      "Epoch: 39, Batch number: 40, Loss: 86.23660278320312\n",
      "Epoch: 39, Batch number: 50, Loss: 103.52320861816406\n",
      "Epoch: 39, Batch number: 60, Loss: 81.91693115234375\n",
      "Epoch: 39, Batch number: 70, Loss: 115.60108184814453\n",
      "Epoch: 39, Batch number: 80, Loss: 81.94454193115234\n",
      "Epoch: 39, Batch number: 90, Loss: 78.684326171875\n",
      "Epoch: 40, Batch number: 5, Loss: 91.84844207763672\n",
      "Epoch: 40, Batch number: 15, Loss: 92.56436157226562\n",
      "Epoch: 40, Batch number: 25, Loss: 94.38842010498047\n",
      "Epoch: 40, Batch number: 35, Loss: 94.22564697265625\n",
      "Epoch: 40, Batch number: 45, Loss: 70.08794403076172\n",
      "Epoch: 40, Batch number: 55, Loss: 86.08831024169922\n",
      "Epoch: 40, Batch number: 65, Loss: 90.34677124023438\n",
      "Epoch: 40, Batch number: 75, Loss: 73.44559478759766\n",
      "Epoch: 40, Batch number: 85, Loss: 74.54093170166016\n",
      "Epoch: 41, Batch number: 0, Loss: 79.92241668701172\n",
      "Epoch: 41, Batch number: 10, Loss: 87.4586181640625\n",
      "Epoch: 41, Batch number: 20, Loss: 73.29217529296875\n",
      "Epoch: 41, Batch number: 30, Loss: 99.97083282470703\n",
      "Epoch: 41, Batch number: 40, Loss: 83.36019897460938\n",
      "Epoch: 41, Batch number: 50, Loss: 102.33961486816406\n",
      "Epoch: 41, Batch number: 60, Loss: 74.7984619140625\n",
      "Epoch: 41, Batch number: 70, Loss: 75.37881469726562\n",
      "Epoch: 41, Batch number: 80, Loss: 84.64435577392578\n",
      "Epoch: 41, Batch number: 90, Loss: 109.31663513183594\n",
      "Epoch: 42, Batch number: 5, Loss: 83.82046508789062\n",
      "Epoch: 42, Batch number: 15, Loss: 93.40727996826172\n",
      "Epoch: 42, Batch number: 25, Loss: 79.08516693115234\n",
      "Epoch: 42, Batch number: 35, Loss: 97.97544860839844\n",
      "Epoch: 42, Batch number: 45, Loss: 64.67732238769531\n",
      "Epoch: 42, Batch number: 55, Loss: 74.06188201904297\n",
      "Epoch: 42, Batch number: 65, Loss: 100.4211196899414\n",
      "Epoch: 42, Batch number: 75, Loss: 93.63186645507812\n",
      "Epoch: 42, Batch number: 85, Loss: 81.32642364501953\n",
      "Epoch: 43, Batch number: 0, Loss: 118.63267517089844\n",
      "Epoch: 43, Batch number: 10, Loss: 75.04986572265625\n",
      "Epoch: 43, Batch number: 20, Loss: 110.03126525878906\n",
      "Epoch: 43, Batch number: 30, Loss: 81.00556182861328\n",
      "Epoch: 43, Batch number: 40, Loss: 85.27952575683594\n",
      "Epoch: 43, Batch number: 50, Loss: 88.79557800292969\n",
      "Epoch: 43, Batch number: 60, Loss: 84.35199737548828\n",
      "Epoch: 43, Batch number: 70, Loss: 86.6180191040039\n",
      "Epoch: 43, Batch number: 80, Loss: 87.83728790283203\n",
      "Epoch: 43, Batch number: 90, Loss: 76.53810119628906\n",
      "Epoch: 44, Batch number: 5, Loss: 111.72438049316406\n",
      "Epoch: 44, Batch number: 15, Loss: 105.01927185058594\n",
      "Epoch: 44, Batch number: 25, Loss: 89.32470703125\n",
      "Epoch: 44, Batch number: 35, Loss: 91.46568298339844\n",
      "Epoch: 44, Batch number: 45, Loss: 79.68330383300781\n",
      "Epoch: 44, Batch number: 55, Loss: 93.6231689453125\n",
      "Epoch: 44, Batch number: 65, Loss: 85.6665267944336\n",
      "Epoch: 44, Batch number: 75, Loss: 68.73009490966797\n",
      "Epoch: 44, Batch number: 85, Loss: 70.0387191772461\n",
      "Epoch: 45, Batch number: 0, Loss: 86.51592254638672\n",
      "Epoch: 45, Batch number: 10, Loss: 97.8523178100586\n",
      "Epoch: 45, Batch number: 20, Loss: 85.30422973632812\n",
      "Epoch: 45, Batch number: 30, Loss: 93.36701965332031\n",
      "Epoch: 45, Batch number: 40, Loss: 88.80181121826172\n",
      "Epoch: 45, Batch number: 50, Loss: 81.48175048828125\n",
      "Epoch: 45, Batch number: 60, Loss: 81.49382019042969\n",
      "Epoch: 45, Batch number: 70, Loss: 99.3260498046875\n",
      "Epoch: 45, Batch number: 80, Loss: 98.81262969970703\n",
      "Epoch: 45, Batch number: 90, Loss: 82.81804656982422\n",
      "Epoch: 46, Batch number: 5, Loss: 85.4292221069336\n",
      "Epoch: 46, Batch number: 15, Loss: 125.97061157226562\n",
      "Epoch: 46, Batch number: 25, Loss: 96.51985931396484\n",
      "Epoch: 46, Batch number: 35, Loss: 86.55264282226562\n",
      "Epoch: 46, Batch number: 45, Loss: 74.03721618652344\n",
      "Epoch: 46, Batch number: 55, Loss: 89.779052734375\n",
      "Epoch: 46, Batch number: 65, Loss: 106.9053726196289\n",
      "Epoch: 46, Batch number: 75, Loss: 96.95125579833984\n",
      "Epoch: 46, Batch number: 85, Loss: 74.88468170166016\n",
      "Epoch: 47, Batch number: 0, Loss: 81.71941375732422\n",
      "Epoch: 47, Batch number: 10, Loss: 74.4997787475586\n",
      "Epoch: 47, Batch number: 20, Loss: 103.07345581054688\n",
      "Epoch: 47, Batch number: 30, Loss: 84.48237609863281\n",
      "Epoch: 47, Batch number: 40, Loss: 71.14205169677734\n",
      "Epoch: 47, Batch number: 50, Loss: 71.01409149169922\n",
      "Epoch: 47, Batch number: 60, Loss: 104.25403594970703\n",
      "Epoch: 47, Batch number: 70, Loss: 82.42662811279297\n",
      "Epoch: 47, Batch number: 80, Loss: 95.72935485839844\n",
      "Epoch: 47, Batch number: 90, Loss: 90.29120635986328\n",
      "Epoch: 48, Batch number: 5, Loss: 104.69556427001953\n",
      "Epoch: 48, Batch number: 15, Loss: 72.11892700195312\n",
      "Epoch: 48, Batch number: 25, Loss: 79.6788101196289\n",
      "Epoch: 48, Batch number: 35, Loss: 100.69404602050781\n",
      "Epoch: 48, Batch number: 45, Loss: 81.17850494384766\n",
      "Epoch: 48, Batch number: 55, Loss: 85.2955322265625\n",
      "Epoch: 48, Batch number: 65, Loss: 78.5479736328125\n",
      "Epoch: 48, Batch number: 75, Loss: 79.51377868652344\n",
      "Epoch: 48, Batch number: 85, Loss: 84.1279525756836\n",
      "Epoch: 49, Batch number: 0, Loss: 75.8041763305664\n",
      "Epoch: 49, Batch number: 10, Loss: 74.37088775634766\n",
      "Epoch: 49, Batch number: 20, Loss: 76.06851959228516\n",
      "Epoch: 49, Batch number: 30, Loss: 91.61890411376953\n",
      "Epoch: 49, Batch number: 40, Loss: 84.59637451171875\n",
      "Epoch: 49, Batch number: 50, Loss: 76.84638214111328\n",
      "Epoch: 49, Batch number: 60, Loss: 88.82196044921875\n",
      "Epoch: 49, Batch number: 70, Loss: 76.256591796875\n",
      "Epoch: 49, Batch number: 80, Loss: 103.815185546875\n",
      "Epoch: 49, Batch number: 90, Loss: 83.54840087890625\n",
      "Epoch: 50, Batch number: 5, Loss: 93.67399597167969\n",
      "Epoch: 50, Batch number: 15, Loss: 98.16670227050781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Batch number: 25, Loss: 79.6389389038086\n",
      "Epoch: 50, Batch number: 35, Loss: 84.31494903564453\n",
      "Epoch: 50, Batch number: 45, Loss: 106.4228286743164\n",
      "Epoch: 50, Batch number: 55, Loss: 99.58811950683594\n",
      "Epoch: 50, Batch number: 65, Loss: 89.85527038574219\n",
      "Epoch: 50, Batch number: 75, Loss: 80.50574493408203\n",
      "Epoch: 50, Batch number: 85, Loss: 78.30174255371094\n",
      "Epoch: 51, Batch number: 0, Loss: 62.8902473449707\n",
      "Epoch: 51, Batch number: 10, Loss: 78.8075942993164\n",
      "Epoch: 51, Batch number: 20, Loss: 80.14518737792969\n",
      "Epoch: 51, Batch number: 30, Loss: 92.27941131591797\n",
      "Epoch: 51, Batch number: 40, Loss: 113.03939819335938\n",
      "Epoch: 51, Batch number: 50, Loss: 113.611328125\n",
      "Epoch: 51, Batch number: 60, Loss: 91.99050903320312\n",
      "Epoch: 51, Batch number: 70, Loss: 92.78314208984375\n",
      "Epoch: 51, Batch number: 80, Loss: 94.01276397705078\n",
      "Epoch: 51, Batch number: 90, Loss: 83.09080505371094\n",
      "Epoch: 52, Batch number: 5, Loss: 94.63990783691406\n",
      "Epoch: 52, Batch number: 15, Loss: 87.8929443359375\n",
      "Epoch: 52, Batch number: 25, Loss: 93.88329315185547\n",
      "Epoch: 52, Batch number: 35, Loss: 74.89830780029297\n",
      "Epoch: 52, Batch number: 45, Loss: 73.42512512207031\n",
      "Epoch: 52, Batch number: 55, Loss: 91.82088470458984\n",
      "Epoch: 52, Batch number: 65, Loss: 88.55741119384766\n",
      "Epoch: 52, Batch number: 75, Loss: 84.21031188964844\n",
      "Epoch: 52, Batch number: 85, Loss: 97.04536437988281\n",
      "Epoch: 53, Batch number: 0, Loss: 74.14981079101562\n",
      "Epoch: 53, Batch number: 10, Loss: 84.29093933105469\n",
      "Epoch: 53, Batch number: 20, Loss: 84.13568878173828\n",
      "Epoch: 53, Batch number: 30, Loss: 94.7625732421875\n",
      "Epoch: 53, Batch number: 40, Loss: 69.3035888671875\n",
      "Epoch: 53, Batch number: 50, Loss: 91.33409118652344\n",
      "Epoch: 53, Batch number: 60, Loss: 102.91912078857422\n",
      "Epoch: 53, Batch number: 70, Loss: 87.42750549316406\n",
      "Epoch: 53, Batch number: 80, Loss: 90.57463073730469\n",
      "Epoch: 53, Batch number: 90, Loss: 83.65408325195312\n",
      "Epoch: 54, Batch number: 5, Loss: 102.95525360107422\n",
      "Epoch: 54, Batch number: 15, Loss: 85.04257202148438\n",
      "Epoch: 54, Batch number: 25, Loss: 67.9239273071289\n",
      "Epoch: 54, Batch number: 35, Loss: 79.05481719970703\n",
      "Epoch: 54, Batch number: 45, Loss: 85.83792114257812\n",
      "Epoch: 54, Batch number: 55, Loss: 64.4599609375\n",
      "Epoch: 54, Batch number: 65, Loss: 89.48237609863281\n",
      "Epoch: 54, Batch number: 75, Loss: 77.09040832519531\n",
      "Epoch: 54, Batch number: 85, Loss: 104.99857330322266\n",
      "Epoch: 55, Batch number: 0, Loss: 82.13739776611328\n",
      "Epoch: 55, Batch number: 10, Loss: 67.92398834228516\n",
      "Epoch: 55, Batch number: 20, Loss: 93.60591125488281\n",
      "Epoch: 55, Batch number: 30, Loss: 89.07220458984375\n",
      "Epoch: 55, Batch number: 40, Loss: 69.64149475097656\n",
      "Epoch: 55, Batch number: 50, Loss: 79.66322326660156\n",
      "Epoch: 55, Batch number: 60, Loss: 80.75914001464844\n",
      "Epoch: 55, Batch number: 70, Loss: 85.75982666015625\n",
      "Epoch: 55, Batch number: 80, Loss: 93.81147003173828\n",
      "Epoch: 55, Batch number: 90, Loss: 86.05535125732422\n",
      "Epoch: 56, Batch number: 5, Loss: 89.24606323242188\n",
      "Epoch: 56, Batch number: 15, Loss: 81.14258575439453\n",
      "Epoch: 56, Batch number: 25, Loss: 96.71891021728516\n",
      "Epoch: 56, Batch number: 35, Loss: 85.25809478759766\n",
      "Epoch: 56, Batch number: 45, Loss: 65.48226165771484\n",
      "Epoch: 56, Batch number: 55, Loss: 86.04655456542969\n",
      "Epoch: 56, Batch number: 65, Loss: 83.98951721191406\n",
      "Epoch: 56, Batch number: 75, Loss: 97.10999298095703\n",
      "Epoch: 56, Batch number: 85, Loss: 96.17145538330078\n",
      "Epoch: 57, Batch number: 0, Loss: 94.48252868652344\n",
      "Epoch: 57, Batch number: 10, Loss: 84.26692962646484\n",
      "Epoch: 57, Batch number: 20, Loss: 81.94771575927734\n",
      "Epoch: 57, Batch number: 30, Loss: 99.23108673095703\n",
      "Epoch: 57, Batch number: 40, Loss: 92.24481201171875\n",
      "Epoch: 57, Batch number: 50, Loss: 87.64282989501953\n",
      "Epoch: 57, Batch number: 60, Loss: 90.00484466552734\n",
      "Epoch: 57, Batch number: 70, Loss: 87.21026611328125\n",
      "Epoch: 57, Batch number: 80, Loss: 86.66777038574219\n",
      "Epoch: 57, Batch number: 90, Loss: 93.10157012939453\n",
      "Epoch: 58, Batch number: 5, Loss: 96.32160186767578\n",
      "Epoch: 58, Batch number: 15, Loss: 83.824462890625\n",
      "Epoch: 58, Batch number: 25, Loss: 85.77437591552734\n",
      "Epoch: 58, Batch number: 35, Loss: 74.07653045654297\n",
      "Epoch: 58, Batch number: 45, Loss: 78.17192077636719\n",
      "Epoch: 58, Batch number: 55, Loss: 90.52469635009766\n",
      "Epoch: 58, Batch number: 65, Loss: 69.27554321289062\n",
      "Epoch: 58, Batch number: 75, Loss: 84.85894775390625\n",
      "Epoch: 58, Batch number: 85, Loss: 69.66620635986328\n",
      "Epoch: 59, Batch number: 0, Loss: 95.12551879882812\n",
      "Epoch: 59, Batch number: 10, Loss: 112.55209350585938\n",
      "Epoch: 59, Batch number: 20, Loss: 91.10549926757812\n",
      "Epoch: 59, Batch number: 30, Loss: 102.12122344970703\n",
      "Epoch: 59, Batch number: 40, Loss: 79.69964599609375\n",
      "Epoch: 59, Batch number: 50, Loss: 77.75303649902344\n",
      "Epoch: 59, Batch number: 60, Loss: 92.49109649658203\n",
      "Epoch: 59, Batch number: 70, Loss: 75.27178955078125\n",
      "Epoch: 59, Batch number: 80, Loss: 82.32698822021484\n",
      "Epoch: 59, Batch number: 90, Loss: 86.06175994873047\n",
      "Epoch: 60, Batch number: 5, Loss: 61.710182189941406\n",
      "Epoch: 60, Batch number: 15, Loss: 91.1512451171875\n",
      "Epoch: 60, Batch number: 25, Loss: 99.59918212890625\n",
      "Epoch: 60, Batch number: 35, Loss: 93.41645050048828\n",
      "Epoch: 60, Batch number: 45, Loss: 77.88428497314453\n",
      "Epoch: 60, Batch number: 55, Loss: 75.71417236328125\n",
      "Epoch: 60, Batch number: 65, Loss: 74.33177185058594\n",
      "Epoch: 60, Batch number: 75, Loss: 90.82644653320312\n",
      "Epoch: 60, Batch number: 85, Loss: 77.52886199951172\n",
      "Epoch: 61, Batch number: 0, Loss: 83.4688720703125\n",
      "Epoch: 61, Batch number: 10, Loss: 115.09638977050781\n",
      "Epoch: 61, Batch number: 20, Loss: 64.33134460449219\n",
      "Epoch: 61, Batch number: 30, Loss: 79.65229034423828\n",
      "Epoch: 61, Batch number: 40, Loss: 95.67147827148438\n",
      "Epoch: 61, Batch number: 50, Loss: 96.20846557617188\n",
      "Epoch: 61, Batch number: 60, Loss: 90.80840301513672\n",
      "Epoch: 61, Batch number: 70, Loss: 82.34078979492188\n",
      "Epoch: 61, Batch number: 80, Loss: 106.81755065917969\n",
      "Epoch: 61, Batch number: 90, Loss: 65.08280181884766\n",
      "Epoch: 62, Batch number: 5, Loss: 83.2762451171875\n",
      "Epoch: 62, Batch number: 15, Loss: 99.38677215576172\n",
      "Epoch: 62, Batch number: 25, Loss: 82.79096221923828\n",
      "Epoch: 62, Batch number: 35, Loss: 77.08209228515625\n",
      "Epoch: 62, Batch number: 45, Loss: 105.10054016113281\n",
      "Epoch: 62, Batch number: 55, Loss: 79.26380157470703\n",
      "Epoch: 62, Batch number: 65, Loss: 81.86798858642578\n",
      "Epoch: 62, Batch number: 75, Loss: 104.30450439453125\n",
      "Epoch: 62, Batch number: 85, Loss: 78.50355529785156\n",
      "Epoch: 63, Batch number: 0, Loss: 73.6526870727539\n",
      "Epoch: 63, Batch number: 10, Loss: 89.86992645263672\n",
      "Epoch: 63, Batch number: 20, Loss: 92.72341918945312\n",
      "Epoch: 63, Batch number: 30, Loss: 92.2798843383789\n",
      "Epoch: 63, Batch number: 40, Loss: 92.6020736694336\n",
      "Epoch: 63, Batch number: 50, Loss: 96.6829605102539\n",
      "Epoch: 63, Batch number: 60, Loss: 71.79434204101562\n",
      "Epoch: 63, Batch number: 70, Loss: 75.70421600341797\n",
      "Epoch: 63, Batch number: 80, Loss: 60.06547546386719\n",
      "Epoch: 63, Batch number: 90, Loss: 87.15030670166016\n",
      "Epoch: 64, Batch number: 5, Loss: 93.09754943847656\n",
      "Epoch: 64, Batch number: 15, Loss: 85.63128662109375\n",
      "Epoch: 64, Batch number: 25, Loss: 96.89762878417969\n",
      "Epoch: 64, Batch number: 35, Loss: 97.03520202636719\n",
      "Epoch: 64, Batch number: 45, Loss: 95.1183090209961\n",
      "Epoch: 64, Batch number: 55, Loss: 66.92141723632812\n",
      "Epoch: 64, Batch number: 65, Loss: 75.65169525146484\n",
      "Epoch: 64, Batch number: 75, Loss: 87.37422943115234\n",
      "Epoch: 64, Batch number: 85, Loss: 82.79310607910156\n",
      "Epoch: 65, Batch number: 0, Loss: 71.74811553955078\n",
      "Epoch: 65, Batch number: 10, Loss: 81.24771881103516\n",
      "Epoch: 65, Batch number: 20, Loss: 74.25330352783203\n",
      "Epoch: 65, Batch number: 30, Loss: 111.70813751220703\n",
      "Epoch: 65, Batch number: 40, Loss: 75.72466278076172\n",
      "Epoch: 65, Batch number: 50, Loss: 111.49856567382812\n",
      "Epoch: 65, Batch number: 60, Loss: 108.71427917480469\n",
      "Epoch: 65, Batch number: 70, Loss: 84.39962768554688\n",
      "Epoch: 65, Batch number: 80, Loss: 94.39643859863281\n",
      "Epoch: 65, Batch number: 90, Loss: 115.73174285888672\n",
      "Epoch: 66, Batch number: 5, Loss: 87.1593246459961\n",
      "Epoch: 66, Batch number: 15, Loss: 91.03992462158203\n",
      "Epoch: 66, Batch number: 25, Loss: 86.4517822265625\n",
      "Epoch: 66, Batch number: 35, Loss: 80.65938568115234\n",
      "Epoch: 66, Batch number: 45, Loss: 97.53360748291016\n",
      "Epoch: 66, Batch number: 55, Loss: 78.08306884765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Batch number: 65, Loss: 99.34105682373047\n",
      "Epoch: 66, Batch number: 75, Loss: 93.55609130859375\n",
      "Epoch: 66, Batch number: 85, Loss: 90.90348052978516\n",
      "Epoch: 67, Batch number: 0, Loss: 63.45293045043945\n",
      "Epoch: 67, Batch number: 10, Loss: 84.65087890625\n",
      "Epoch: 67, Batch number: 20, Loss: 94.57357025146484\n",
      "Epoch: 67, Batch number: 30, Loss: 112.76271057128906\n",
      "Epoch: 67, Batch number: 40, Loss: 75.66634368896484\n",
      "Epoch: 67, Batch number: 50, Loss: 84.82411193847656\n",
      "Epoch: 67, Batch number: 60, Loss: 75.70181274414062\n",
      "Epoch: 67, Batch number: 70, Loss: 84.73512268066406\n",
      "Epoch: 67, Batch number: 80, Loss: 77.31019592285156\n",
      "Epoch: 67, Batch number: 90, Loss: 79.83334350585938\n",
      "Epoch: 68, Batch number: 5, Loss: 81.56379699707031\n",
      "Epoch: 68, Batch number: 15, Loss: 89.02253723144531\n",
      "Epoch: 68, Batch number: 25, Loss: 76.89773559570312\n",
      "Epoch: 68, Batch number: 35, Loss: 86.28173065185547\n",
      "Epoch: 68, Batch number: 45, Loss: 97.23213958740234\n",
      "Epoch: 68, Batch number: 55, Loss: 91.3693618774414\n",
      "Epoch: 68, Batch number: 65, Loss: 94.94911193847656\n",
      "Epoch: 68, Batch number: 75, Loss: 92.09464263916016\n",
      "Epoch: 68, Batch number: 85, Loss: 84.78889465332031\n",
      "Epoch: 69, Batch number: 0, Loss: 91.74681854248047\n",
      "Epoch: 69, Batch number: 10, Loss: 76.857177734375\n",
      "Epoch: 69, Batch number: 20, Loss: 103.69703674316406\n",
      "Epoch: 69, Batch number: 30, Loss: 86.26383972167969\n",
      "Epoch: 69, Batch number: 40, Loss: 91.81690216064453\n",
      "Epoch: 69, Batch number: 50, Loss: 77.51251220703125\n",
      "Epoch: 69, Batch number: 60, Loss: 78.46095275878906\n",
      "Epoch: 69, Batch number: 70, Loss: 79.43882751464844\n",
      "Epoch: 69, Batch number: 80, Loss: 83.21980285644531\n",
      "Epoch: 69, Batch number: 90, Loss: 89.11473083496094\n",
      "Epoch: 70, Batch number: 5, Loss: 85.6888656616211\n",
      "Epoch: 70, Batch number: 15, Loss: 106.15414428710938\n",
      "Epoch: 70, Batch number: 25, Loss: 101.54571533203125\n",
      "Epoch: 70, Batch number: 35, Loss: 100.08496856689453\n",
      "Epoch: 70, Batch number: 45, Loss: 93.81907653808594\n",
      "Epoch: 70, Batch number: 55, Loss: 98.38768005371094\n",
      "Epoch: 70, Batch number: 65, Loss: 134.89105224609375\n",
      "Epoch: 70, Batch number: 75, Loss: 73.57925415039062\n",
      "Epoch: 70, Batch number: 85, Loss: 96.11861419677734\n",
      "Epoch: 71, Batch number: 0, Loss: 97.32947540283203\n",
      "Epoch: 71, Batch number: 10, Loss: 110.2012939453125\n",
      "Epoch: 71, Batch number: 20, Loss: 90.39847564697266\n",
      "Epoch: 71, Batch number: 30, Loss: 90.22147369384766\n",
      "Epoch: 71, Batch number: 40, Loss: 85.92826080322266\n",
      "Epoch: 71, Batch number: 50, Loss: 102.92327117919922\n",
      "Epoch: 71, Batch number: 60, Loss: 84.53489685058594\n",
      "Epoch: 71, Batch number: 70, Loss: 75.25891876220703\n",
      "Epoch: 71, Batch number: 80, Loss: 84.72693634033203\n",
      "Epoch: 71, Batch number: 90, Loss: 82.9642562866211\n",
      "Epoch: 72, Batch number: 5, Loss: 92.96499633789062\n",
      "Epoch: 72, Batch number: 15, Loss: 82.46744537353516\n",
      "Epoch: 72, Batch number: 25, Loss: 83.49320983886719\n",
      "Epoch: 72, Batch number: 35, Loss: 72.63758087158203\n",
      "Epoch: 72, Batch number: 45, Loss: 71.54715728759766\n",
      "Epoch: 72, Batch number: 55, Loss: 93.20850372314453\n",
      "Epoch: 72, Batch number: 65, Loss: 60.33634948730469\n",
      "Epoch: 72, Batch number: 75, Loss: 77.25506591796875\n",
      "Epoch: 72, Batch number: 85, Loss: 72.00241088867188\n",
      "Epoch: 73, Batch number: 0, Loss: 100.008056640625\n",
      "Epoch: 73, Batch number: 10, Loss: 83.2435073852539\n",
      "Epoch: 73, Batch number: 20, Loss: 98.92921447753906\n",
      "Epoch: 73, Batch number: 30, Loss: 61.102333068847656\n",
      "Epoch: 73, Batch number: 40, Loss: 64.80025482177734\n",
      "Epoch: 73, Batch number: 50, Loss: 83.36260223388672\n",
      "Epoch: 73, Batch number: 60, Loss: 76.95348358154297\n",
      "Epoch: 73, Batch number: 70, Loss: 69.93060302734375\n",
      "Epoch: 73, Batch number: 80, Loss: 87.67243957519531\n",
      "Epoch: 73, Batch number: 90, Loss: 72.04142761230469\n",
      "Epoch: 74, Batch number: 5, Loss: 90.97974395751953\n",
      "Epoch: 74, Batch number: 15, Loss: 76.88191223144531\n",
      "Epoch: 74, Batch number: 25, Loss: 83.98706817626953\n",
      "Epoch: 74, Batch number: 35, Loss: 86.7469711303711\n",
      "Epoch: 74, Batch number: 45, Loss: 77.07203674316406\n",
      "Epoch: 74, Batch number: 55, Loss: 89.85253143310547\n",
      "Epoch: 74, Batch number: 65, Loss: 77.28154754638672\n",
      "Epoch: 74, Batch number: 75, Loss: 75.35039520263672\n",
      "Epoch: 74, Batch number: 85, Loss: 70.3592758178711\n",
      "Epoch: 75, Batch number: 0, Loss: 89.55209350585938\n",
      "Epoch: 75, Batch number: 10, Loss: 94.19750213623047\n",
      "Epoch: 75, Batch number: 20, Loss: 64.67450714111328\n",
      "Epoch: 75, Batch number: 30, Loss: 90.61873626708984\n",
      "Epoch: 75, Batch number: 40, Loss: 103.65133666992188\n",
      "Epoch: 75, Batch number: 50, Loss: 80.09716796875\n",
      "Epoch: 75, Batch number: 60, Loss: 88.59974670410156\n",
      "Epoch: 75, Batch number: 70, Loss: 92.17593383789062\n",
      "Epoch: 75, Batch number: 80, Loss: 75.41348266601562\n",
      "Epoch: 75, Batch number: 90, Loss: 71.92427062988281\n",
      "Epoch: 76, Batch number: 5, Loss: 97.36698150634766\n",
      "Epoch: 76, Batch number: 15, Loss: 82.4433364868164\n",
      "Epoch: 76, Batch number: 25, Loss: 94.4847640991211\n",
      "Epoch: 76, Batch number: 35, Loss: 89.43255615234375\n",
      "Epoch: 76, Batch number: 45, Loss: 94.95144653320312\n",
      "Epoch: 76, Batch number: 55, Loss: 78.88258361816406\n",
      "Epoch: 76, Batch number: 65, Loss: 75.66822052001953\n",
      "Epoch: 76, Batch number: 75, Loss: 93.19223022460938\n",
      "Epoch: 76, Batch number: 85, Loss: 87.65809631347656\n",
      "Epoch: 77, Batch number: 0, Loss: 85.02577209472656\n",
      "Epoch: 77, Batch number: 10, Loss: 83.6557846069336\n",
      "Epoch: 77, Batch number: 20, Loss: 71.34648132324219\n",
      "Epoch: 77, Batch number: 30, Loss: 88.4361343383789\n",
      "Epoch: 77, Batch number: 40, Loss: 85.00804138183594\n",
      "Epoch: 77, Batch number: 50, Loss: 74.62039947509766\n",
      "Epoch: 77, Batch number: 60, Loss: 80.63783264160156\n",
      "Epoch: 77, Batch number: 70, Loss: 82.18856811523438\n",
      "Epoch: 77, Batch number: 80, Loss: 79.23439025878906\n",
      "Epoch: 77, Batch number: 90, Loss: 79.92562866210938\n",
      "Epoch: 78, Batch number: 5, Loss: 101.9582290649414\n",
      "Epoch: 78, Batch number: 15, Loss: 79.95291137695312\n",
      "Epoch: 78, Batch number: 25, Loss: 83.90602111816406\n",
      "Epoch: 78, Batch number: 35, Loss: 100.68670654296875\n",
      "Epoch: 78, Batch number: 45, Loss: 71.37710571289062\n",
      "Epoch: 78, Batch number: 55, Loss: 85.2077865600586\n",
      "Epoch: 78, Batch number: 65, Loss: 66.80656433105469\n",
      "Epoch: 78, Batch number: 75, Loss: 97.54559326171875\n",
      "Epoch: 78, Batch number: 85, Loss: 72.13690948486328\n",
      "Epoch: 79, Batch number: 0, Loss: 71.34502410888672\n",
      "Epoch: 79, Batch number: 10, Loss: 114.31625366210938\n",
      "Epoch: 79, Batch number: 20, Loss: 83.27649688720703\n",
      "Epoch: 79, Batch number: 30, Loss: 83.15271759033203\n",
      "Epoch: 79, Batch number: 40, Loss: 96.78421783447266\n",
      "Epoch: 79, Batch number: 50, Loss: 76.87361145019531\n",
      "Epoch: 79, Batch number: 60, Loss: 73.32716369628906\n",
      "Epoch: 79, Batch number: 70, Loss: 80.43009948730469\n",
      "Epoch: 79, Batch number: 80, Loss: 84.95850372314453\n",
      "Epoch: 79, Batch number: 90, Loss: 66.7998046875\n",
      "Epoch: 80, Batch number: 5, Loss: 71.0130844116211\n",
      "Epoch: 80, Batch number: 15, Loss: 81.77062225341797\n",
      "Epoch: 80, Batch number: 25, Loss: 70.6390380859375\n",
      "Epoch: 80, Batch number: 35, Loss: 87.33472442626953\n",
      "Epoch: 80, Batch number: 45, Loss: 101.1958236694336\n",
      "Epoch: 80, Batch number: 55, Loss: 81.99449920654297\n",
      "Epoch: 80, Batch number: 65, Loss: 74.644775390625\n",
      "Epoch: 80, Batch number: 75, Loss: 84.8604736328125\n",
      "Epoch: 80, Batch number: 85, Loss: 79.96250915527344\n",
      "Epoch: 81, Batch number: 0, Loss: 68.44430541992188\n",
      "Epoch: 81, Batch number: 10, Loss: 110.08291625976562\n",
      "Epoch: 81, Batch number: 20, Loss: 63.74068069458008\n",
      "Epoch: 81, Batch number: 30, Loss: 73.6646499633789\n",
      "Epoch: 81, Batch number: 40, Loss: 93.1558609008789\n",
      "Epoch: 81, Batch number: 50, Loss: 84.74072265625\n",
      "Epoch: 81, Batch number: 60, Loss: 99.87491607666016\n",
      "Epoch: 81, Batch number: 70, Loss: 89.65850830078125\n",
      "Epoch: 81, Batch number: 80, Loss: 70.3264389038086\n",
      "Epoch: 81, Batch number: 90, Loss: 88.08374786376953\n",
      "Epoch: 82, Batch number: 5, Loss: 64.41852569580078\n",
      "Epoch: 82, Batch number: 15, Loss: 88.80854034423828\n",
      "Epoch: 82, Batch number: 25, Loss: 69.75799560546875\n",
      "Epoch: 82, Batch number: 35, Loss: 107.574951171875\n",
      "Epoch: 82, Batch number: 45, Loss: 94.4747085571289\n",
      "Epoch: 82, Batch number: 55, Loss: 71.57261657714844\n",
      "Epoch: 82, Batch number: 65, Loss: 103.93721008300781\n",
      "Epoch: 82, Batch number: 75, Loss: 86.2454833984375\n",
      "Epoch: 82, Batch number: 85, Loss: 85.7366943359375\n",
      "Epoch: 83, Batch number: 0, Loss: 87.28780364990234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83, Batch number: 10, Loss: 83.47782897949219\n",
      "Epoch: 83, Batch number: 20, Loss: 77.08331298828125\n",
      "Epoch: 83, Batch number: 30, Loss: 80.83663940429688\n",
      "Epoch: 83, Batch number: 40, Loss: 89.5784683227539\n",
      "Epoch: 83, Batch number: 50, Loss: 79.67610168457031\n",
      "Epoch: 83, Batch number: 60, Loss: 97.32134246826172\n",
      "Epoch: 83, Batch number: 70, Loss: 69.21898651123047\n",
      "Epoch: 83, Batch number: 80, Loss: 92.60472869873047\n",
      "Epoch: 83, Batch number: 90, Loss: 74.99454498291016\n",
      "Epoch: 84, Batch number: 5, Loss: 98.46205139160156\n",
      "Epoch: 84, Batch number: 15, Loss: 61.05393981933594\n",
      "Epoch: 84, Batch number: 25, Loss: 90.59532165527344\n",
      "Epoch: 84, Batch number: 35, Loss: 57.4403076171875\n",
      "Epoch: 84, Batch number: 45, Loss: 79.63774108886719\n",
      "Epoch: 84, Batch number: 55, Loss: 88.52682495117188\n",
      "Epoch: 84, Batch number: 65, Loss: 84.19482421875\n",
      "Epoch: 84, Batch number: 75, Loss: 83.8636474609375\n",
      "Epoch: 84, Batch number: 85, Loss: 95.820068359375\n",
      "Epoch: 85, Batch number: 0, Loss: 72.50437927246094\n",
      "Epoch: 85, Batch number: 10, Loss: 64.91194152832031\n",
      "Epoch: 85, Batch number: 20, Loss: 88.27296447753906\n",
      "Epoch: 85, Batch number: 30, Loss: 106.84288787841797\n",
      "Epoch: 85, Batch number: 40, Loss: 78.17027282714844\n",
      "Epoch: 85, Batch number: 50, Loss: 78.207763671875\n",
      "Epoch: 85, Batch number: 60, Loss: 87.3172607421875\n",
      "Epoch: 85, Batch number: 70, Loss: 83.77567291259766\n",
      "Epoch: 85, Batch number: 80, Loss: 98.76907348632812\n",
      "Epoch: 85, Batch number: 90, Loss: 79.86389923095703\n",
      "Epoch: 86, Batch number: 5, Loss: 83.99564361572266\n",
      "Epoch: 86, Batch number: 15, Loss: 70.82832336425781\n",
      "Epoch: 86, Batch number: 25, Loss: 107.58293151855469\n",
      "Epoch: 86, Batch number: 35, Loss: 78.47364044189453\n",
      "Epoch: 86, Batch number: 45, Loss: 82.48516845703125\n",
      "Epoch: 86, Batch number: 55, Loss: 84.65762329101562\n",
      "Epoch: 86, Batch number: 65, Loss: 104.5316390991211\n",
      "Epoch: 86, Batch number: 75, Loss: 98.44802856445312\n",
      "Epoch: 86, Batch number: 85, Loss: 93.17495727539062\n",
      "Epoch: 87, Batch number: 0, Loss: 81.41741180419922\n",
      "Epoch: 87, Batch number: 10, Loss: 74.33129119873047\n",
      "Epoch: 87, Batch number: 20, Loss: 82.40008544921875\n",
      "Epoch: 87, Batch number: 30, Loss: 91.69751739501953\n",
      "Epoch: 87, Batch number: 40, Loss: 91.71621704101562\n",
      "Epoch: 87, Batch number: 50, Loss: 91.63388061523438\n",
      "Epoch: 87, Batch number: 60, Loss: 79.90727996826172\n",
      "Epoch: 87, Batch number: 70, Loss: 66.62945556640625\n",
      "Epoch: 87, Batch number: 80, Loss: 56.667503356933594\n",
      "Epoch: 87, Batch number: 90, Loss: 76.21094512939453\n",
      "Epoch: 88, Batch number: 5, Loss: 93.13314056396484\n",
      "Epoch: 88, Batch number: 15, Loss: 92.45629119873047\n",
      "Epoch: 88, Batch number: 25, Loss: 83.8121337890625\n",
      "Epoch: 88, Batch number: 35, Loss: 108.27984619140625\n",
      "Epoch: 88, Batch number: 45, Loss: 86.1618423461914\n",
      "Epoch: 88, Batch number: 55, Loss: 69.38197326660156\n",
      "Epoch: 88, Batch number: 65, Loss: 62.48472595214844\n",
      "Epoch: 88, Batch number: 75, Loss: 69.26802062988281\n",
      "Epoch: 88, Batch number: 85, Loss: 71.19165802001953\n",
      "Epoch: 89, Batch number: 0, Loss: 94.31128692626953\n",
      "Epoch: 89, Batch number: 10, Loss: 79.63497924804688\n",
      "Epoch: 89, Batch number: 20, Loss: 94.29253387451172\n",
      "Epoch: 89, Batch number: 30, Loss: 77.80925750732422\n",
      "Epoch: 89, Batch number: 40, Loss: 84.15167999267578\n",
      "Epoch: 89, Batch number: 50, Loss: 76.73321533203125\n",
      "Epoch: 89, Batch number: 60, Loss: 65.61613464355469\n",
      "Epoch: 89, Batch number: 70, Loss: 103.53302001953125\n",
      "Epoch: 89, Batch number: 80, Loss: 83.74262237548828\n",
      "Epoch: 89, Batch number: 90, Loss: 94.3700942993164\n",
      "Epoch: 90, Batch number: 5, Loss: 71.94368743896484\n",
      "Epoch: 90, Batch number: 15, Loss: 75.14253234863281\n",
      "Epoch: 90, Batch number: 25, Loss: 67.25151824951172\n",
      "Epoch: 90, Batch number: 35, Loss: 94.899169921875\n",
      "Epoch: 90, Batch number: 45, Loss: 88.9772720336914\n",
      "Epoch: 90, Batch number: 55, Loss: 95.77870178222656\n",
      "Epoch: 90, Batch number: 65, Loss: 67.64385986328125\n",
      "Epoch: 90, Batch number: 75, Loss: 82.93501281738281\n",
      "Epoch: 90, Batch number: 85, Loss: 79.7877197265625\n",
      "Epoch: 91, Batch number: 0, Loss: 76.56623840332031\n",
      "Epoch: 91, Batch number: 10, Loss: 68.43753051757812\n",
      "Epoch: 91, Batch number: 20, Loss: 53.132476806640625\n",
      "Epoch: 91, Batch number: 30, Loss: 78.85676574707031\n",
      "Epoch: 91, Batch number: 40, Loss: 80.90608978271484\n",
      "Epoch: 91, Batch number: 50, Loss: 96.6891098022461\n",
      "Epoch: 91, Batch number: 60, Loss: 90.33966827392578\n",
      "Epoch: 91, Batch number: 70, Loss: 84.7016372680664\n",
      "Epoch: 91, Batch number: 80, Loss: 78.2782211303711\n",
      "Epoch: 91, Batch number: 90, Loss: 61.405784606933594\n",
      "Epoch: 92, Batch number: 5, Loss: 79.12455749511719\n",
      "Epoch: 92, Batch number: 15, Loss: 81.83251953125\n",
      "Epoch: 92, Batch number: 25, Loss: 83.20845031738281\n",
      "Epoch: 92, Batch number: 35, Loss: 88.00396728515625\n",
      "Epoch: 92, Batch number: 45, Loss: 84.82917022705078\n",
      "Epoch: 92, Batch number: 55, Loss: 84.17379760742188\n",
      "Epoch: 92, Batch number: 65, Loss: 75.84520721435547\n",
      "Epoch: 92, Batch number: 75, Loss: 69.7257308959961\n",
      "Epoch: 92, Batch number: 85, Loss: 87.91209411621094\n",
      "Epoch: 93, Batch number: 0, Loss: 95.0084228515625\n",
      "Epoch: 93, Batch number: 10, Loss: 84.01307678222656\n",
      "Epoch: 93, Batch number: 20, Loss: 100.95863342285156\n",
      "Epoch: 93, Batch number: 30, Loss: 81.24153137207031\n",
      "Epoch: 93, Batch number: 40, Loss: 76.71778869628906\n",
      "Epoch: 93, Batch number: 50, Loss: 81.24419403076172\n",
      "Epoch: 93, Batch number: 60, Loss: 89.1285629272461\n",
      "Epoch: 93, Batch number: 70, Loss: 81.52079772949219\n",
      "Epoch: 93, Batch number: 80, Loss: 97.62165832519531\n",
      "Epoch: 93, Batch number: 90, Loss: 68.41305541992188\n",
      "Epoch: 94, Batch number: 5, Loss: 86.51592254638672\n",
      "Epoch: 94, Batch number: 15, Loss: 76.37652587890625\n",
      "Epoch: 94, Batch number: 25, Loss: 82.87088775634766\n",
      "Epoch: 94, Batch number: 35, Loss: 76.58323669433594\n",
      "Epoch: 94, Batch number: 45, Loss: 66.39100646972656\n",
      "Epoch: 94, Batch number: 55, Loss: 73.1410140991211\n",
      "Epoch: 94, Batch number: 65, Loss: 79.55423736572266\n",
      "Epoch: 94, Batch number: 75, Loss: 67.4737777709961\n",
      "Epoch: 94, Batch number: 85, Loss: 72.28079986572266\n",
      "Epoch: 95, Batch number: 0, Loss: 77.34957885742188\n",
      "Epoch: 95, Batch number: 10, Loss: 87.85797119140625\n",
      "Epoch: 95, Batch number: 20, Loss: 91.88697814941406\n",
      "Epoch: 95, Batch number: 30, Loss: 77.83434295654297\n",
      "Epoch: 95, Batch number: 40, Loss: 77.82605743408203\n",
      "Epoch: 95, Batch number: 50, Loss: 94.70170593261719\n",
      "Epoch: 95, Batch number: 60, Loss: 81.42237091064453\n",
      "Epoch: 95, Batch number: 70, Loss: 89.04798889160156\n",
      "Epoch: 95, Batch number: 80, Loss: 92.55410766601562\n",
      "Epoch: 95, Batch number: 90, Loss: 90.52315521240234\n",
      "Epoch: 96, Batch number: 5, Loss: 67.60474395751953\n",
      "Epoch: 96, Batch number: 15, Loss: 83.77447509765625\n",
      "Epoch: 96, Batch number: 25, Loss: 65.99097442626953\n",
      "Epoch: 96, Batch number: 35, Loss: 82.59619140625\n",
      "Epoch: 96, Batch number: 45, Loss: 106.61778259277344\n",
      "Epoch: 96, Batch number: 55, Loss: 80.74266052246094\n",
      "Epoch: 96, Batch number: 65, Loss: 81.55520629882812\n",
      "Epoch: 96, Batch number: 75, Loss: 96.33147430419922\n",
      "Epoch: 96, Batch number: 85, Loss: 100.18494415283203\n",
      "Epoch: 97, Batch number: 0, Loss: 76.64520263671875\n",
      "Epoch: 97, Batch number: 10, Loss: 59.93021774291992\n",
      "Epoch: 97, Batch number: 20, Loss: 101.52758026123047\n",
      "Epoch: 97, Batch number: 30, Loss: 79.72370910644531\n",
      "Epoch: 97, Batch number: 40, Loss: 87.82178497314453\n",
      "Epoch: 97, Batch number: 50, Loss: 67.65454864501953\n",
      "Epoch: 97, Batch number: 60, Loss: 92.16837310791016\n",
      "Epoch: 97, Batch number: 70, Loss: 95.8173599243164\n",
      "Epoch: 97, Batch number: 80, Loss: 70.23245239257812\n",
      "Epoch: 97, Batch number: 90, Loss: 93.79444885253906\n",
      "Epoch: 98, Batch number: 5, Loss: 93.99949645996094\n",
      "Epoch: 98, Batch number: 15, Loss: 99.08688354492188\n",
      "Epoch: 98, Batch number: 25, Loss: 70.60474395751953\n",
      "Epoch: 98, Batch number: 35, Loss: 84.64816284179688\n",
      "Epoch: 98, Batch number: 45, Loss: 66.677734375\n",
      "Epoch: 98, Batch number: 55, Loss: 78.9242172241211\n",
      "Epoch: 98, Batch number: 65, Loss: 91.61892700195312\n",
      "Epoch: 98, Batch number: 75, Loss: 87.34654235839844\n",
      "Epoch: 98, Batch number: 85, Loss: 77.67440795898438\n",
      "Epoch: 99, Batch number: 0, Loss: 95.4435043334961\n",
      "Epoch: 99, Batch number: 10, Loss: 86.99478149414062\n",
      "Epoch: 99, Batch number: 20, Loss: 71.10090637207031\n",
      "Epoch: 99, Batch number: 30, Loss: 94.36410522460938\n",
      "Epoch: 99, Batch number: 40, Loss: 76.0078353881836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, Batch number: 50, Loss: 98.91686248779297\n",
      "Epoch: 99, Batch number: 60, Loss: 78.44194030761719\n",
      "Epoch: 99, Batch number: 70, Loss: 93.95240783691406\n",
      "Epoch: 99, Batch number: 80, Loss: 83.1590347290039\n",
      "Epoch: 99, Batch number: 90, Loss: 87.3914566040039\n",
      "Epoch: 100, Batch number: 5, Loss: 79.74016571044922\n",
      "Epoch: 100, Batch number: 15, Loss: 72.35725402832031\n",
      "Epoch: 100, Batch number: 25, Loss: 96.12049865722656\n",
      "Epoch: 100, Batch number: 35, Loss: 63.16358184814453\n",
      "Epoch: 100, Batch number: 45, Loss: 87.8233871459961\n",
      "Epoch: 100, Batch number: 55, Loss: 76.9112319946289\n",
      "Epoch: 100, Batch number: 65, Loss: 68.71159362792969\n",
      "Epoch: 100, Batch number: 75, Loss: 86.40332794189453\n",
      "Epoch: 100, Batch number: 85, Loss: 71.53943634033203\n",
      "Epoch: 101, Batch number: 0, Loss: 81.06532287597656\n",
      "Epoch: 101, Batch number: 10, Loss: 69.58871459960938\n",
      "Epoch: 101, Batch number: 20, Loss: 62.3262825012207\n",
      "Epoch: 101, Batch number: 30, Loss: 108.87956237792969\n",
      "Epoch: 101, Batch number: 40, Loss: 89.3827133178711\n",
      "Epoch: 101, Batch number: 50, Loss: 104.9366683959961\n",
      "Epoch: 101, Batch number: 60, Loss: 92.50774383544922\n",
      "Epoch: 101, Batch number: 70, Loss: 88.02787017822266\n",
      "Epoch: 101, Batch number: 80, Loss: 77.52682495117188\n",
      "Epoch: 101, Batch number: 90, Loss: 98.77748107910156\n",
      "Epoch: 102, Batch number: 5, Loss: 86.11111450195312\n",
      "Epoch: 102, Batch number: 15, Loss: 97.4813003540039\n",
      "Epoch: 102, Batch number: 25, Loss: 73.63753509521484\n",
      "Epoch: 102, Batch number: 35, Loss: 81.72721099853516\n",
      "Epoch: 102, Batch number: 45, Loss: 80.39241790771484\n",
      "Epoch: 102, Batch number: 55, Loss: 94.5544662475586\n",
      "Epoch: 102, Batch number: 65, Loss: 67.4850845336914\n",
      "Epoch: 102, Batch number: 75, Loss: 69.740478515625\n",
      "Epoch: 102, Batch number: 85, Loss: 82.0744400024414\n",
      "Epoch: 103, Batch number: 0, Loss: 87.35033416748047\n",
      "Epoch: 103, Batch number: 10, Loss: 88.08863830566406\n",
      "Epoch: 103, Batch number: 20, Loss: 81.32953643798828\n",
      "Epoch: 103, Batch number: 30, Loss: 87.11835479736328\n",
      "Epoch: 103, Batch number: 40, Loss: 83.96658325195312\n",
      "Epoch: 103, Batch number: 50, Loss: 85.3498764038086\n",
      "Epoch: 103, Batch number: 60, Loss: 70.88652038574219\n",
      "Epoch: 103, Batch number: 70, Loss: 70.63987731933594\n",
      "Epoch: 103, Batch number: 80, Loss: 65.46086883544922\n",
      "Epoch: 103, Batch number: 90, Loss: 71.97457122802734\n",
      "Epoch: 104, Batch number: 5, Loss: 83.82237243652344\n",
      "Epoch: 104, Batch number: 15, Loss: 82.8631591796875\n",
      "Epoch: 104, Batch number: 25, Loss: 99.72393798828125\n",
      "Epoch: 104, Batch number: 35, Loss: 70.99374389648438\n",
      "Epoch: 104, Batch number: 45, Loss: 96.0012435913086\n",
      "Epoch: 104, Batch number: 55, Loss: 90.62725067138672\n",
      "Epoch: 104, Batch number: 65, Loss: 80.36813354492188\n",
      "Epoch: 104, Batch number: 75, Loss: 77.9434814453125\n",
      "Epoch: 104, Batch number: 85, Loss: 95.3756332397461\n",
      "Epoch: 105, Batch number: 0, Loss: 80.78129577636719\n",
      "Epoch: 105, Batch number: 10, Loss: 86.51512145996094\n",
      "Epoch: 105, Batch number: 20, Loss: 91.90155029296875\n",
      "Epoch: 105, Batch number: 30, Loss: 72.96355438232422\n",
      "Epoch: 105, Batch number: 40, Loss: 83.81368255615234\n",
      "Epoch: 105, Batch number: 50, Loss: 71.91848754882812\n",
      "Epoch: 105, Batch number: 60, Loss: 77.7405014038086\n",
      "Epoch: 105, Batch number: 70, Loss: 80.71344757080078\n",
      "Epoch: 105, Batch number: 80, Loss: 85.01480102539062\n",
      "Epoch: 105, Batch number: 90, Loss: 67.08527374267578\n",
      "Epoch: 106, Batch number: 5, Loss: 79.15100860595703\n",
      "Epoch: 106, Batch number: 15, Loss: 102.1962661743164\n",
      "Epoch: 106, Batch number: 25, Loss: 88.96875762939453\n",
      "Epoch: 106, Batch number: 35, Loss: 79.90666198730469\n",
      "Epoch: 106, Batch number: 45, Loss: 71.84716796875\n",
      "Epoch: 106, Batch number: 55, Loss: 84.7850341796875\n",
      "Epoch: 106, Batch number: 65, Loss: 68.70037078857422\n",
      "Epoch: 106, Batch number: 75, Loss: 87.15238189697266\n",
      "Epoch: 106, Batch number: 85, Loss: 68.47257232666016\n",
      "Epoch: 107, Batch number: 0, Loss: 69.72332763671875\n",
      "Epoch: 107, Batch number: 10, Loss: 73.16461181640625\n",
      "Epoch: 107, Batch number: 20, Loss: 92.18400573730469\n",
      "Epoch: 107, Batch number: 30, Loss: 85.83468627929688\n",
      "Epoch: 107, Batch number: 40, Loss: 81.44396209716797\n",
      "Epoch: 107, Batch number: 50, Loss: 103.06763458251953\n",
      "Epoch: 107, Batch number: 60, Loss: 81.2591323852539\n",
      "Epoch: 107, Batch number: 70, Loss: 92.43113708496094\n",
      "Epoch: 107, Batch number: 80, Loss: 83.65576934814453\n",
      "Epoch: 107, Batch number: 90, Loss: 98.74969482421875\n",
      "Epoch: 108, Batch number: 5, Loss: 80.31671905517578\n",
      "Epoch: 108, Batch number: 15, Loss: 69.09242248535156\n",
      "Epoch: 108, Batch number: 25, Loss: 55.48158645629883\n",
      "Epoch: 108, Batch number: 35, Loss: 71.75370788574219\n",
      "Epoch: 108, Batch number: 45, Loss: 64.70655059814453\n",
      "Epoch: 108, Batch number: 55, Loss: 89.88040161132812\n",
      "Epoch: 108, Batch number: 65, Loss: 78.9577865600586\n",
      "Epoch: 108, Batch number: 75, Loss: 73.77781677246094\n",
      "Epoch: 108, Batch number: 85, Loss: 57.69032669067383\n",
      "Epoch: 109, Batch number: 0, Loss: 94.43991088867188\n",
      "Epoch: 109, Batch number: 10, Loss: 99.49434661865234\n",
      "Epoch: 109, Batch number: 20, Loss: 67.71832275390625\n",
      "Epoch: 109, Batch number: 30, Loss: 74.55032348632812\n",
      "Epoch: 109, Batch number: 40, Loss: 95.91230773925781\n",
      "Epoch: 109, Batch number: 50, Loss: 86.33883666992188\n",
      "Epoch: 109, Batch number: 60, Loss: 82.1160659790039\n",
      "Epoch: 109, Batch number: 70, Loss: 85.05648040771484\n",
      "Epoch: 109, Batch number: 80, Loss: 68.90213775634766\n",
      "Epoch: 109, Batch number: 90, Loss: 95.05418395996094\n",
      "Epoch: 110, Batch number: 5, Loss: 75.18894958496094\n",
      "Epoch: 110, Batch number: 15, Loss: 74.87285614013672\n",
      "Epoch: 110, Batch number: 25, Loss: 89.87225341796875\n",
      "Epoch: 110, Batch number: 35, Loss: 88.50702667236328\n",
      "Epoch: 110, Batch number: 45, Loss: 78.0513916015625\n",
      "Epoch: 110, Batch number: 55, Loss: 91.88512420654297\n",
      "Epoch: 110, Batch number: 65, Loss: 68.52295684814453\n",
      "Epoch: 110, Batch number: 75, Loss: 80.94950866699219\n",
      "Epoch: 110, Batch number: 85, Loss: 81.03572845458984\n",
      "Epoch: 111, Batch number: 0, Loss: 110.42371368408203\n",
      "Epoch: 111, Batch number: 10, Loss: 76.0794906616211\n",
      "Epoch: 111, Batch number: 20, Loss: 76.23483276367188\n",
      "Epoch: 111, Batch number: 30, Loss: 67.27188873291016\n",
      "Epoch: 111, Batch number: 40, Loss: 99.72770690917969\n",
      "Epoch: 111, Batch number: 50, Loss: 96.93964385986328\n",
      "Epoch: 111, Batch number: 60, Loss: 88.46969604492188\n",
      "Epoch: 111, Batch number: 70, Loss: 60.99046325683594\n",
      "Epoch: 111, Batch number: 80, Loss: 98.65420532226562\n",
      "Epoch: 111, Batch number: 90, Loss: 67.07242584228516\n",
      "Epoch: 112, Batch number: 5, Loss: 71.6654052734375\n",
      "Epoch: 112, Batch number: 15, Loss: 65.80371856689453\n",
      "Epoch: 112, Batch number: 25, Loss: 83.23926544189453\n",
      "Epoch: 112, Batch number: 35, Loss: 77.96487426757812\n",
      "Epoch: 112, Batch number: 45, Loss: 74.57618713378906\n",
      "Epoch: 112, Batch number: 55, Loss: 89.20391082763672\n",
      "Epoch: 112, Batch number: 65, Loss: 74.54253387451172\n",
      "Epoch: 112, Batch number: 75, Loss: 77.575439453125\n",
      "Epoch: 112, Batch number: 85, Loss: 92.86553955078125\n",
      "Epoch: 113, Batch number: 0, Loss: 91.50220489501953\n",
      "Epoch: 113, Batch number: 10, Loss: 80.17570495605469\n",
      "Epoch: 113, Batch number: 20, Loss: 78.26026916503906\n",
      "Epoch: 113, Batch number: 30, Loss: 63.02928924560547\n",
      "Epoch: 113, Batch number: 40, Loss: 103.82410430908203\n",
      "Epoch: 113, Batch number: 50, Loss: 81.33626556396484\n",
      "Epoch: 113, Batch number: 60, Loss: 69.4222183227539\n",
      "Epoch: 113, Batch number: 70, Loss: 76.41950225830078\n",
      "Epoch: 113, Batch number: 80, Loss: 82.82662963867188\n",
      "Epoch: 113, Batch number: 90, Loss: 74.40526580810547\n",
      "Epoch: 114, Batch number: 5, Loss: 74.46417999267578\n",
      "Epoch: 114, Batch number: 15, Loss: 78.58961486816406\n",
      "Epoch: 114, Batch number: 25, Loss: 89.55013275146484\n",
      "Epoch: 114, Batch number: 35, Loss: 75.61642456054688\n",
      "Epoch: 114, Batch number: 45, Loss: 83.75215148925781\n",
      "Epoch: 114, Batch number: 55, Loss: 98.158447265625\n",
      "Epoch: 114, Batch number: 65, Loss: 76.31832885742188\n",
      "Epoch: 114, Batch number: 75, Loss: 84.14952087402344\n",
      "Epoch: 114, Batch number: 85, Loss: 76.53631591796875\n",
      "Epoch: 115, Batch number: 0, Loss: 67.16592407226562\n",
      "Epoch: 115, Batch number: 10, Loss: 79.60492706298828\n",
      "Epoch: 115, Batch number: 20, Loss: 65.70806884765625\n",
      "Epoch: 115, Batch number: 30, Loss: 80.798828125\n",
      "Epoch: 115, Batch number: 40, Loss: 88.33675384521484\n",
      "Epoch: 115, Batch number: 50, Loss: 94.1746826171875\n",
      "Epoch: 115, Batch number: 60, Loss: 105.88230895996094\n",
      "Epoch: 115, Batch number: 70, Loss: 94.35952758789062\n",
      "Epoch: 115, Batch number: 80, Loss: 74.07902526855469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115, Batch number: 90, Loss: 95.95597839355469\n",
      "Epoch: 116, Batch number: 5, Loss: 94.96748352050781\n",
      "Epoch: 116, Batch number: 15, Loss: 94.63878631591797\n",
      "Epoch: 116, Batch number: 25, Loss: 67.74414825439453\n",
      "Epoch: 116, Batch number: 35, Loss: 82.57025909423828\n",
      "Epoch: 116, Batch number: 45, Loss: 63.17364501953125\n",
      "Epoch: 116, Batch number: 55, Loss: 70.49408721923828\n",
      "Epoch: 116, Batch number: 65, Loss: 96.90162658691406\n",
      "Epoch: 116, Batch number: 75, Loss: 82.82102966308594\n",
      "Epoch: 116, Batch number: 85, Loss: 67.66445922851562\n",
      "Epoch: 117, Batch number: 0, Loss: 83.67478942871094\n",
      "Epoch: 117, Batch number: 10, Loss: 85.654052734375\n",
      "Epoch: 117, Batch number: 20, Loss: 89.38822937011719\n",
      "Epoch: 117, Batch number: 30, Loss: 66.7686767578125\n",
      "Epoch: 117, Batch number: 40, Loss: 54.6955451965332\n",
      "Epoch: 117, Batch number: 50, Loss: 100.59610748291016\n",
      "Epoch: 117, Batch number: 60, Loss: 90.78466796875\n",
      "Epoch: 117, Batch number: 70, Loss: 72.78795623779297\n",
      "Epoch: 117, Batch number: 80, Loss: 69.7062759399414\n",
      "Epoch: 117, Batch number: 90, Loss: 73.38691711425781\n",
      "Epoch: 118, Batch number: 5, Loss: 74.02281188964844\n",
      "Epoch: 118, Batch number: 15, Loss: 90.06185913085938\n",
      "Epoch: 118, Batch number: 25, Loss: 93.17495727539062\n",
      "Epoch: 118, Batch number: 35, Loss: 107.637939453125\n",
      "Epoch: 118, Batch number: 45, Loss: 83.43983459472656\n",
      "Epoch: 118, Batch number: 55, Loss: 72.92378234863281\n",
      "Epoch: 118, Batch number: 65, Loss: 82.94843292236328\n",
      "Epoch: 118, Batch number: 75, Loss: 84.3504638671875\n",
      "Epoch: 118, Batch number: 85, Loss: 115.36480712890625\n",
      "Epoch: 119, Batch number: 0, Loss: 71.87115478515625\n",
      "Epoch: 119, Batch number: 10, Loss: 77.79833984375\n",
      "Epoch: 119, Batch number: 20, Loss: 83.2264633178711\n",
      "Epoch: 119, Batch number: 30, Loss: 86.24419403076172\n",
      "Epoch: 119, Batch number: 40, Loss: 98.92692565917969\n",
      "Epoch: 119, Batch number: 50, Loss: 72.58169555664062\n",
      "Epoch: 119, Batch number: 60, Loss: 96.96290588378906\n",
      "Epoch: 119, Batch number: 70, Loss: 77.15038299560547\n",
      "Epoch: 119, Batch number: 80, Loss: 86.91197967529297\n",
      "Epoch: 119, Batch number: 90, Loss: 65.7568359375\n",
      "Epoch: 120, Batch number: 5, Loss: 78.02704620361328\n",
      "Epoch: 120, Batch number: 15, Loss: 82.85194396972656\n",
      "Epoch: 120, Batch number: 25, Loss: 75.31613159179688\n",
      "Epoch: 120, Batch number: 35, Loss: 101.4277572631836\n",
      "Epoch: 120, Batch number: 45, Loss: 57.21356964111328\n",
      "Epoch: 120, Batch number: 55, Loss: 82.11248016357422\n",
      "Epoch: 120, Batch number: 65, Loss: 83.16082000732422\n",
      "Epoch: 120, Batch number: 75, Loss: 74.71914672851562\n",
      "Epoch: 120, Batch number: 85, Loss: 82.98778533935547\n",
      "Epoch: 121, Batch number: 0, Loss: 80.99626159667969\n",
      "Epoch: 121, Batch number: 10, Loss: 83.21424865722656\n",
      "Epoch: 121, Batch number: 20, Loss: 75.07080078125\n",
      "Epoch: 121, Batch number: 30, Loss: 75.51368713378906\n",
      "Epoch: 121, Batch number: 40, Loss: 76.889892578125\n",
      "Epoch: 121, Batch number: 50, Loss: 97.50169372558594\n",
      "Epoch: 121, Batch number: 60, Loss: 70.18485260009766\n",
      "Epoch: 121, Batch number: 70, Loss: 84.53144836425781\n",
      "Epoch: 121, Batch number: 80, Loss: 70.05133819580078\n",
      "Epoch: 121, Batch number: 90, Loss: 76.54627990722656\n",
      "Epoch: 122, Batch number: 5, Loss: 71.25719451904297\n",
      "Epoch: 122, Batch number: 15, Loss: 85.48302459716797\n",
      "Epoch: 122, Batch number: 25, Loss: 90.0279312133789\n",
      "Epoch: 122, Batch number: 35, Loss: 103.43763732910156\n",
      "Epoch: 122, Batch number: 45, Loss: 86.9931869506836\n",
      "Epoch: 122, Batch number: 55, Loss: 73.40787506103516\n",
      "Epoch: 122, Batch number: 65, Loss: 86.64944458007812\n",
      "Epoch: 122, Batch number: 75, Loss: 65.7652816772461\n",
      "Epoch: 122, Batch number: 85, Loss: 83.30097961425781\n",
      "Epoch: 123, Batch number: 0, Loss: 83.66380310058594\n",
      "Epoch: 123, Batch number: 10, Loss: 79.25668334960938\n",
      "Epoch: 123, Batch number: 20, Loss: 79.5259017944336\n",
      "Epoch: 123, Batch number: 30, Loss: 68.38990020751953\n",
      "Epoch: 123, Batch number: 40, Loss: 83.18634796142578\n",
      "Epoch: 123, Batch number: 50, Loss: 95.38908386230469\n",
      "Epoch: 123, Batch number: 60, Loss: 77.93463897705078\n",
      "Epoch: 123, Batch number: 70, Loss: 68.04434967041016\n",
      "Epoch: 123, Batch number: 80, Loss: 82.5771484375\n",
      "Epoch: 123, Batch number: 90, Loss: 80.932373046875\n",
      "Epoch: 124, Batch number: 5, Loss: 83.46293640136719\n",
      "Epoch: 124, Batch number: 15, Loss: 84.52245330810547\n",
      "Epoch: 124, Batch number: 25, Loss: 105.6461181640625\n",
      "Epoch: 124, Batch number: 35, Loss: 69.4649429321289\n",
      "Epoch: 124, Batch number: 45, Loss: 95.74513244628906\n",
      "Epoch: 124, Batch number: 55, Loss: 96.02324676513672\n",
      "Epoch: 124, Batch number: 65, Loss: 74.24649810791016\n",
      "Epoch: 124, Batch number: 75, Loss: 80.9657974243164\n",
      "Epoch: 124, Batch number: 85, Loss: 63.23915100097656\n",
      "Epoch: 125, Batch number: 0, Loss: 98.56295013427734\n",
      "Epoch: 125, Batch number: 10, Loss: 84.5068130493164\n",
      "Epoch: 125, Batch number: 20, Loss: 89.6832275390625\n",
      "Epoch: 125, Batch number: 30, Loss: 84.05826568603516\n",
      "Epoch: 125, Batch number: 40, Loss: 73.35688781738281\n",
      "Epoch: 125, Batch number: 50, Loss: 79.68359375\n",
      "Epoch: 125, Batch number: 60, Loss: 72.64515686035156\n",
      "Epoch: 125, Batch number: 70, Loss: 100.26528930664062\n",
      "Epoch: 125, Batch number: 80, Loss: 87.77479553222656\n",
      "Epoch: 125, Batch number: 90, Loss: 95.69924926757812\n",
      "Epoch: 126, Batch number: 5, Loss: 64.20669555664062\n",
      "Epoch: 126, Batch number: 15, Loss: 77.48970794677734\n",
      "Epoch: 126, Batch number: 25, Loss: 80.24043273925781\n",
      "Epoch: 126, Batch number: 35, Loss: 80.06103515625\n",
      "Epoch: 126, Batch number: 45, Loss: 89.40071868896484\n",
      "Epoch: 126, Batch number: 55, Loss: 89.49361419677734\n",
      "Epoch: 126, Batch number: 65, Loss: 74.64325714111328\n",
      "Epoch: 126, Batch number: 75, Loss: 92.51813507080078\n",
      "Epoch: 126, Batch number: 85, Loss: 78.41290283203125\n",
      "Epoch: 127, Batch number: 0, Loss: 87.8326644897461\n",
      "Epoch: 127, Batch number: 10, Loss: 92.6360092163086\n",
      "Epoch: 127, Batch number: 20, Loss: 90.94518280029297\n",
      "Epoch: 127, Batch number: 30, Loss: 74.9587173461914\n",
      "Epoch: 127, Batch number: 40, Loss: 71.59407043457031\n",
      "Epoch: 127, Batch number: 50, Loss: 78.83149719238281\n",
      "Epoch: 127, Batch number: 60, Loss: 79.06056213378906\n",
      "Epoch: 127, Batch number: 70, Loss: 63.22179412841797\n",
      "Epoch: 127, Batch number: 80, Loss: 91.31210327148438\n",
      "Epoch: 127, Batch number: 90, Loss: 94.50184631347656\n",
      "Epoch: 128, Batch number: 5, Loss: 95.9881362915039\n",
      "Epoch: 128, Batch number: 15, Loss: 86.93499755859375\n",
      "Epoch: 128, Batch number: 25, Loss: 92.16796875\n",
      "Epoch: 128, Batch number: 35, Loss: 64.04864501953125\n",
      "Epoch: 128, Batch number: 45, Loss: 89.29283905029297\n",
      "Epoch: 128, Batch number: 55, Loss: 84.10931396484375\n",
      "Epoch: 128, Batch number: 65, Loss: 70.47876739501953\n",
      "Epoch: 128, Batch number: 75, Loss: 77.97867584228516\n",
      "Epoch: 128, Batch number: 85, Loss: 66.17211151123047\n",
      "Epoch: 129, Batch number: 0, Loss: 58.97145080566406\n",
      "Epoch: 129, Batch number: 10, Loss: 71.79025268554688\n",
      "Epoch: 129, Batch number: 20, Loss: 92.11051940917969\n",
      "Epoch: 129, Batch number: 30, Loss: 86.50691223144531\n",
      "Epoch: 129, Batch number: 40, Loss: 82.11994934082031\n",
      "Epoch: 129, Batch number: 50, Loss: 89.65716552734375\n",
      "Epoch: 129, Batch number: 60, Loss: 94.31839752197266\n",
      "Epoch: 129, Batch number: 70, Loss: 78.00154876708984\n",
      "Epoch: 129, Batch number: 80, Loss: 68.24810791015625\n",
      "Epoch: 129, Batch number: 90, Loss: 80.27229309082031\n",
      "Epoch: 130, Batch number: 5, Loss: 58.58734130859375\n",
      "Epoch: 130, Batch number: 15, Loss: 69.8985366821289\n",
      "Epoch: 130, Batch number: 25, Loss: 77.76020050048828\n",
      "Epoch: 130, Batch number: 35, Loss: 77.85501098632812\n",
      "Epoch: 130, Batch number: 45, Loss: 83.8155517578125\n",
      "Epoch: 130, Batch number: 55, Loss: 84.49935913085938\n",
      "Epoch: 130, Batch number: 65, Loss: 94.31369018554688\n",
      "Epoch: 130, Batch number: 75, Loss: 64.20698547363281\n",
      "Epoch: 130, Batch number: 85, Loss: 90.00865173339844\n",
      "Epoch: 131, Batch number: 0, Loss: 57.57142639160156\n",
      "Epoch: 131, Batch number: 10, Loss: 80.63526916503906\n",
      "Epoch: 131, Batch number: 20, Loss: 91.00689697265625\n",
      "Epoch: 131, Batch number: 30, Loss: 80.84803771972656\n",
      "Epoch: 131, Batch number: 40, Loss: 91.12218475341797\n",
      "Epoch: 131, Batch number: 50, Loss: 77.13021087646484\n",
      "Epoch: 131, Batch number: 60, Loss: 93.85906219482422\n",
      "Epoch: 131, Batch number: 70, Loss: 81.55748748779297\n",
      "Epoch: 131, Batch number: 80, Loss: 82.43419647216797\n",
      "Epoch: 131, Batch number: 90, Loss: 70.72418975830078\n",
      "Epoch: 132, Batch number: 5, Loss: 75.43608093261719\n",
      "Epoch: 132, Batch number: 15, Loss: 73.94620513916016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132, Batch number: 25, Loss: 72.0736083984375\n",
      "Epoch: 132, Batch number: 35, Loss: 69.04593658447266\n",
      "Epoch: 132, Batch number: 45, Loss: 93.27840423583984\n",
      "Epoch: 132, Batch number: 55, Loss: 79.28173828125\n",
      "Epoch: 132, Batch number: 65, Loss: 90.8368148803711\n",
      "Epoch: 132, Batch number: 75, Loss: 89.16047668457031\n",
      "Epoch: 132, Batch number: 85, Loss: 69.5091552734375\n",
      "Epoch: 133, Batch number: 0, Loss: 90.00836944580078\n",
      "Epoch: 133, Batch number: 10, Loss: 71.88086700439453\n",
      "Epoch: 133, Batch number: 20, Loss: 83.28438568115234\n",
      "Epoch: 133, Batch number: 30, Loss: 85.89405059814453\n",
      "Epoch: 133, Batch number: 40, Loss: 72.69127655029297\n",
      "Epoch: 133, Batch number: 50, Loss: 82.69678497314453\n",
      "Epoch: 133, Batch number: 60, Loss: 69.35433197021484\n",
      "Epoch: 133, Batch number: 70, Loss: 82.71186065673828\n",
      "Epoch: 133, Batch number: 80, Loss: 73.79598236083984\n",
      "Epoch: 133, Batch number: 90, Loss: 87.19512176513672\n",
      "Epoch: 134, Batch number: 5, Loss: 66.7523193359375\n",
      "Epoch: 134, Batch number: 15, Loss: 76.53195190429688\n",
      "Epoch: 134, Batch number: 25, Loss: 82.97242736816406\n",
      "Epoch: 134, Batch number: 35, Loss: 70.43362426757812\n",
      "Epoch: 134, Batch number: 45, Loss: 69.59025573730469\n",
      "Epoch: 134, Batch number: 55, Loss: 49.798526763916016\n",
      "Epoch: 134, Batch number: 65, Loss: 97.96842956542969\n",
      "Epoch: 134, Batch number: 75, Loss: 69.57722473144531\n",
      "Epoch: 134, Batch number: 85, Loss: 69.30620574951172\n",
      "Epoch: 135, Batch number: 0, Loss: 96.68798065185547\n",
      "Epoch: 135, Batch number: 10, Loss: 81.03992462158203\n",
      "Epoch: 135, Batch number: 20, Loss: 95.40689086914062\n",
      "Epoch: 135, Batch number: 30, Loss: 99.04243469238281\n",
      "Epoch: 135, Batch number: 40, Loss: 82.70040893554688\n",
      "Epoch: 135, Batch number: 50, Loss: 93.12218475341797\n",
      "Epoch: 135, Batch number: 60, Loss: 88.58275604248047\n",
      "Epoch: 135, Batch number: 70, Loss: 65.305908203125\n",
      "Epoch: 135, Batch number: 80, Loss: 83.17652893066406\n",
      "Epoch: 135, Batch number: 90, Loss: 71.4001693725586\n",
      "Epoch: 136, Batch number: 5, Loss: 81.6054916381836\n",
      "Epoch: 136, Batch number: 15, Loss: 88.11568450927734\n",
      "Epoch: 136, Batch number: 25, Loss: 93.90174865722656\n",
      "Epoch: 136, Batch number: 35, Loss: 79.39204406738281\n",
      "Epoch: 136, Batch number: 45, Loss: 77.48563385009766\n",
      "Epoch: 136, Batch number: 55, Loss: 74.36602020263672\n",
      "Epoch: 136, Batch number: 65, Loss: 84.4953384399414\n",
      "Epoch: 136, Batch number: 75, Loss: 64.09971618652344\n",
      "Epoch: 136, Batch number: 85, Loss: 72.92803192138672\n",
      "Epoch: 137, Batch number: 0, Loss: 73.30948638916016\n",
      "Epoch: 137, Batch number: 10, Loss: 88.47709655761719\n",
      "Epoch: 137, Batch number: 20, Loss: 84.21099090576172\n",
      "Epoch: 137, Batch number: 30, Loss: 97.11713409423828\n",
      "Epoch: 137, Batch number: 40, Loss: 55.943355560302734\n",
      "Epoch: 137, Batch number: 50, Loss: 65.97901916503906\n",
      "Epoch: 137, Batch number: 60, Loss: 67.45545959472656\n",
      "Epoch: 137, Batch number: 70, Loss: 88.09469604492188\n",
      "Epoch: 137, Batch number: 80, Loss: 88.21292114257812\n",
      "Epoch: 137, Batch number: 90, Loss: 83.6003646850586\n",
      "Epoch: 138, Batch number: 5, Loss: 71.8692626953125\n",
      "Epoch: 138, Batch number: 15, Loss: 73.48841857910156\n",
      "Epoch: 138, Batch number: 25, Loss: 100.9999771118164\n",
      "Epoch: 138, Batch number: 35, Loss: 86.91967010498047\n",
      "Epoch: 138, Batch number: 45, Loss: 88.93240356445312\n",
      "Epoch: 138, Batch number: 55, Loss: 73.67204284667969\n",
      "Epoch: 138, Batch number: 65, Loss: 107.00926208496094\n",
      "Epoch: 138, Batch number: 75, Loss: 83.84412384033203\n",
      "Epoch: 138, Batch number: 85, Loss: 77.29450225830078\n",
      "Epoch: 139, Batch number: 0, Loss: 75.06193542480469\n",
      "Epoch: 139, Batch number: 10, Loss: 78.38595581054688\n",
      "Epoch: 139, Batch number: 20, Loss: 93.72136688232422\n",
      "Epoch: 139, Batch number: 30, Loss: 70.10528564453125\n",
      "Epoch: 139, Batch number: 40, Loss: 61.147769927978516\n",
      "Epoch: 139, Batch number: 50, Loss: 85.33914947509766\n",
      "Epoch: 139, Batch number: 60, Loss: 83.56665802001953\n",
      "Epoch: 139, Batch number: 70, Loss: 77.2931900024414\n",
      "Epoch: 139, Batch number: 80, Loss: 96.50218200683594\n",
      "Epoch: 139, Batch number: 90, Loss: 73.45697784423828\n",
      "Epoch: 140, Batch number: 5, Loss: 80.93927001953125\n",
      "Epoch: 140, Batch number: 15, Loss: 81.4660873413086\n",
      "Epoch: 140, Batch number: 25, Loss: 87.8558349609375\n",
      "Epoch: 140, Batch number: 35, Loss: 73.65885162353516\n",
      "Epoch: 140, Batch number: 45, Loss: 68.13543701171875\n",
      "Epoch: 140, Batch number: 55, Loss: 74.69076538085938\n",
      "Epoch: 140, Batch number: 65, Loss: 78.41732788085938\n",
      "Epoch: 140, Batch number: 75, Loss: 82.38626098632812\n",
      "Epoch: 140, Batch number: 85, Loss: 57.526771545410156\n",
      "Epoch: 141, Batch number: 0, Loss: 74.07477569580078\n",
      "Epoch: 141, Batch number: 10, Loss: 90.88001251220703\n",
      "Epoch: 141, Batch number: 20, Loss: 82.33386993408203\n",
      "Epoch: 141, Batch number: 30, Loss: 52.137142181396484\n",
      "Epoch: 141, Batch number: 40, Loss: 64.7318115234375\n",
      "Epoch: 141, Batch number: 50, Loss: 55.14013671875\n",
      "Epoch: 141, Batch number: 60, Loss: 82.67335510253906\n",
      "Epoch: 141, Batch number: 70, Loss: 67.5810546875\n",
      "Epoch: 141, Batch number: 80, Loss: 81.45690155029297\n",
      "Epoch: 141, Batch number: 90, Loss: 105.0504150390625\n",
      "Epoch: 142, Batch number: 5, Loss: 62.22654724121094\n",
      "Epoch: 142, Batch number: 15, Loss: 68.03246307373047\n",
      "Epoch: 142, Batch number: 25, Loss: 85.22550201416016\n",
      "Epoch: 142, Batch number: 35, Loss: 73.71624755859375\n",
      "Epoch: 142, Batch number: 45, Loss: 82.66505432128906\n",
      "Epoch: 142, Batch number: 55, Loss: 74.40257263183594\n",
      "Epoch: 142, Batch number: 65, Loss: 78.46104431152344\n",
      "Epoch: 142, Batch number: 75, Loss: 77.98603820800781\n",
      "Epoch: 142, Batch number: 85, Loss: 98.91313171386719\n",
      "Epoch: 143, Batch number: 0, Loss: 79.68057250976562\n",
      "Epoch: 143, Batch number: 10, Loss: 73.53357696533203\n",
      "Epoch: 143, Batch number: 20, Loss: 71.67855072021484\n",
      "Epoch: 143, Batch number: 30, Loss: 104.39436340332031\n",
      "Epoch: 143, Batch number: 40, Loss: 93.59884643554688\n",
      "Epoch: 143, Batch number: 50, Loss: 60.431663513183594\n",
      "Epoch: 143, Batch number: 60, Loss: 73.60684967041016\n",
      "Epoch: 143, Batch number: 70, Loss: 78.014892578125\n",
      "Epoch: 143, Batch number: 80, Loss: 88.26814270019531\n",
      "Epoch: 143, Batch number: 90, Loss: 68.70359802246094\n",
      "Epoch: 144, Batch number: 5, Loss: 58.45506286621094\n",
      "Epoch: 144, Batch number: 15, Loss: 80.44139862060547\n",
      "Epoch: 144, Batch number: 25, Loss: 68.52265930175781\n",
      "Epoch: 144, Batch number: 35, Loss: 77.5301742553711\n",
      "Epoch: 144, Batch number: 45, Loss: 90.74290466308594\n",
      "Epoch: 144, Batch number: 55, Loss: 75.31769561767578\n",
      "Epoch: 144, Batch number: 65, Loss: 88.57760620117188\n",
      "Epoch: 144, Batch number: 75, Loss: 76.1877212524414\n",
      "Epoch: 144, Batch number: 85, Loss: 88.41925811767578\n",
      "Epoch: 145, Batch number: 0, Loss: 86.40557098388672\n",
      "Epoch: 145, Batch number: 10, Loss: 84.25981140136719\n",
      "Epoch: 145, Batch number: 20, Loss: 87.19403839111328\n",
      "Epoch: 145, Batch number: 30, Loss: 81.50759887695312\n",
      "Epoch: 145, Batch number: 40, Loss: 102.53166961669922\n",
      "Epoch: 145, Batch number: 50, Loss: 84.91819763183594\n",
      "Epoch: 145, Batch number: 60, Loss: 73.28314208984375\n",
      "Epoch: 145, Batch number: 70, Loss: 81.00498962402344\n",
      "Epoch: 145, Batch number: 80, Loss: 106.46530151367188\n",
      "Epoch: 145, Batch number: 90, Loss: 63.73548126220703\n",
      "Epoch: 146, Batch number: 5, Loss: 95.2477798461914\n",
      "Epoch: 146, Batch number: 15, Loss: 62.884891510009766\n",
      "Epoch: 146, Batch number: 25, Loss: 77.57540130615234\n",
      "Epoch: 146, Batch number: 35, Loss: 72.77530670166016\n",
      "Epoch: 146, Batch number: 45, Loss: 75.14680480957031\n",
      "Epoch: 146, Batch number: 55, Loss: 85.7202377319336\n",
      "Epoch: 146, Batch number: 65, Loss: 71.55851745605469\n",
      "Epoch: 146, Batch number: 75, Loss: 82.59909057617188\n",
      "Epoch: 146, Batch number: 85, Loss: 66.39270782470703\n",
      "Epoch: 147, Batch number: 0, Loss: 87.58950805664062\n",
      "Epoch: 147, Batch number: 10, Loss: 67.45333862304688\n",
      "Epoch: 147, Batch number: 20, Loss: 98.9092788696289\n",
      "Epoch: 147, Batch number: 30, Loss: 99.53695678710938\n",
      "Epoch: 147, Batch number: 40, Loss: 60.65269470214844\n",
      "Epoch: 147, Batch number: 50, Loss: 75.6275634765625\n",
      "Epoch: 147, Batch number: 60, Loss: 91.39999389648438\n",
      "Epoch: 147, Batch number: 70, Loss: 77.28321838378906\n",
      "Epoch: 147, Batch number: 80, Loss: 63.082393646240234\n",
      "Epoch: 147, Batch number: 90, Loss: 76.56702423095703\n",
      "Epoch: 148, Batch number: 5, Loss: 83.50428771972656\n",
      "Epoch: 148, Batch number: 15, Loss: 82.40300750732422\n",
      "Epoch: 148, Batch number: 25, Loss: 82.52090454101562\n",
      "Epoch: 148, Batch number: 35, Loss: 76.81987762451172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148, Batch number: 45, Loss: 80.20454406738281\n",
      "Epoch: 148, Batch number: 55, Loss: 82.33171081542969\n",
      "Epoch: 148, Batch number: 65, Loss: 65.87767028808594\n",
      "Epoch: 148, Batch number: 75, Loss: 79.96477508544922\n",
      "Epoch: 148, Batch number: 85, Loss: 65.0516586303711\n",
      "Epoch: 149, Batch number: 0, Loss: 67.21102905273438\n",
      "Epoch: 149, Batch number: 10, Loss: 85.58043670654297\n",
      "Epoch: 149, Batch number: 20, Loss: 77.34324645996094\n",
      "Epoch: 149, Batch number: 30, Loss: 88.97114562988281\n",
      "Epoch: 149, Batch number: 40, Loss: 73.15645599365234\n",
      "Epoch: 149, Batch number: 50, Loss: 67.68997192382812\n",
      "Epoch: 149, Batch number: 60, Loss: 101.93679809570312\n",
      "Epoch: 149, Batch number: 70, Loss: 90.5899429321289\n",
      "Epoch: 149, Batch number: 80, Loss: 73.54829406738281\n",
      "Epoch: 149, Batch number: 90, Loss: 68.29925537109375\n",
      "Epoch: 150, Batch number: 5, Loss: 76.8200454711914\n",
      "Epoch: 150, Batch number: 15, Loss: 64.67337036132812\n",
      "Epoch: 150, Batch number: 25, Loss: 91.33263397216797\n",
      "Epoch: 150, Batch number: 35, Loss: 86.03350830078125\n",
      "Epoch: 150, Batch number: 45, Loss: 88.4287109375\n",
      "Epoch: 150, Batch number: 55, Loss: 90.1521224975586\n",
      "Epoch: 150, Batch number: 65, Loss: 82.3064193725586\n",
      "Epoch: 150, Batch number: 75, Loss: 71.4937515258789\n",
      "Epoch: 150, Batch number: 85, Loss: 87.34718322753906\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 150              # Cantidad de epochs\n",
    "learning_rate = 5e-5      # Tasa de aprendizaje\n",
    "sample_loss_every = 10    # Calcular la loss cada este n√∫mero\n",
    "algorithm = 'Adam'        # Algoritmo de optimizaci√≥n\n",
    "\n",
    "trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ‚â• 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4e4b9a3780>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainer.loss_history['iter'],trainer.loss_history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = trainer.dataloader.dataset.vocabulary\n",
    "forward = lambda x: trainer.model.out(trainer.model.emb(x))\n",
    "device = trainer.device\n",
    "log10 = torch.log(torch.tensor(10,dtype=torch.float,device=device))\n",
    "\n",
    "new_lm_file = []\n",
    "for line in lm_file:\n",
    "    ngram_line = re.search(r'([\\-\\.\\d]+)\\t([\\w<s></s>]+[ ]?[\\w<s></s>]*)([\\t]?[\\-\\.\\d]*)\\n',line)\n",
    "    if ngram_line is not None:\n",
    "        ngram = ngram_line.groups()[1]\n",
    "        if ' ' in ngram:\n",
    "            w1, w2 = ngram.split(' ')\n",
    "            score = forward(torch.tensor(vocab[w1],device=device))\n",
    "            log_prob = max(((score[vocab[w2]] - torch.logsumexp(score,dim=0))/log10).item(),-99)\n",
    "            new_line = '{:.6f}\\t{}\\n'.format(log_prob,ngram)\n",
    "        else:\n",
    "            score = forward(torch.tensor(vocab[ngram],device=device))\n",
    "            log_prob = max(((score[vocab[ngram]] - torch.logsumexp(score,dim=0))/log10).item(),-99)\n",
    "            new_line = '{:.6f}\\t{}\\t0\\n'.format(log_prob,ngram)\n",
    "    else:\n",
    "        new_line = line\n",
    "    new_lm_file.append(new_line)\n",
    "    \n",
    "text = ''.join(new_lm_file)\n",
    "with open('./lm_files/lm_l40_word_vectors_w2_cbow', 'wb') as file:\n",
    "    file.write(text.encode('iso-8859-1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba 2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from NLPUtils import *\n",
    "import re\n",
    "import fasttext\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./lm_files/lm_l40_bigram_train_test', 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "    lm_file = [line.decode('iso-8859-1') for line in lines]\n",
    "    \n",
    "# Obtenemos el corpus de entrenamiento:\n",
    "with open('trainLM2.txt', 'rb') as file:\n",
    "    lines = file.readlines()\n",
    "    corpus = [['<s>'] + line.decode('iso-8859-1').split(' ')[:-1] + ['</s>'] for line in lines]\n",
    "    \n",
    "corpus = [[token for doc in corpus for token in doc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trainer created:\n",
      "Number of training samples: 38889 (40%)\n",
      "Number of validation samples: 9723 (10%)\n",
      "Number of test samples: 48612 (50%)\n",
      "Number of train batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n"
     ]
    }
   ],
   "source": [
    "window_size = 2           # Tama√±o de la ventana del contexto.\n",
    "cutoff_freq = 0           # Palabras con una frecuencia menor o igual a cutoff_freq son exclu√≠das del vocabulario.\n",
    "batch_size = 512          # Tama√±o del batch.\n",
    "val_size = .2\n",
    "\n",
    "model = 'CBOW'            # M√©todo de entrenamiento.\n",
    "embedding_dim = 200       # Dimensi√≥n del espacio de los word vectors.\n",
    "device = 'cuda:1'         # Dispositivo sobre el cual se entrena. \n",
    "state_dict = None         # Par√°metros pre-entrenados.\n",
    "paralelize = False        # Flag para decirle al programa que use las 2 gpus\n",
    "\n",
    "train_dataset = Word2VecSamples(corpus, window_size=window_size, cutoff_freq=cutoff_freq)\n",
    "test_dataset = Word2VecSamples(corpus, window_size=window_size, cutoff_freq=cutoff_freq)\n",
    "model = CBOWModel(len(train_dataset.vocabulary),embedding_dim)\n",
    "\n",
    "trainer = ModelTrainer(train_dataset, test_dataset, batch_size=batch_size, val_size=val_size)\n",
    "trainer.InitModel(model=model, state_dict=state_dict, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 150\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0\n",
      "Accuracy on validation dataset: 1/9723 (0.01%)\n",
      "\n",
      "Epoch: 1, Batch number: 10\n",
      "Accuracy on validation dataset: 33/9723 (0.34%)\n",
      "\n",
      "Epoch: 1, Batch number: 20\n",
      "Accuracy on validation dataset: 238/9723 (2.45%)\n",
      "\n",
      "Epoch: 1, Batch number: 30\n",
      "Accuracy on validation dataset: 680/9723 (6.99%)\n",
      "\n",
      "Epoch: 1, Batch number: 40\n",
      "Accuracy on validation dataset: 1157/9723 (11.90%)\n",
      "\n",
      "Epoch: 1, Batch number: 50\n",
      "Accuracy on validation dataset: 1569/9723 (16.14%)\n",
      "\n",
      "Epoch: 1, Batch number: 60\n",
      "Accuracy on validation dataset: 1833/9723 (18.85%)\n",
      "\n",
      "Epoch: 1, Batch number: 70\n",
      "Accuracy on validation dataset: 1986/9723 (20.43%)\n",
      "\n",
      "Epoch: 2, Batch number: 4\n",
      "Accuracy on validation dataset: 2074/9723 (21.33%)\n",
      "\n",
      "Epoch: 2, Batch number: 14\n",
      "Accuracy on validation dataset: 2120/9723 (21.80%)\n",
      "\n",
      "Epoch: 2, Batch number: 24\n",
      "Accuracy on validation dataset: 2157/9723 (22.18%)\n",
      "\n",
      "Epoch: 2, Batch number: 34\n",
      "Accuracy on validation dataset: 2176/9723 (22.38%)\n",
      "\n",
      "Epoch: 2, Batch number: 44\n",
      "Accuracy on validation dataset: 2201/9723 (22.64%)\n",
      "\n",
      "Epoch: 2, Batch number: 54\n",
      "Accuracy on validation dataset: 2215/9723 (22.78%)\n",
      "\n",
      "Epoch: 2, Batch number: 64\n",
      "Accuracy on validation dataset: 2229/9723 (22.93%)\n",
      "\n",
      "Epoch: 2, Batch number: 74\n",
      "Accuracy on validation dataset: 2231/9723 (22.95%)\n",
      "\n",
      "Epoch: 3, Batch number: 8\n",
      "Accuracy on validation dataset: 2230/9723 (22.94%)\n",
      "\n",
      "Epoch: 3, Batch number: 18\n",
      "Accuracy on validation dataset: 2225/9723 (22.88%)\n",
      "\n",
      "Epoch: 3, Batch number: 28\n",
      "Accuracy on validation dataset: 2238/9723 (23.02%)\n",
      "\n",
      "Epoch: 3, Batch number: 38\n",
      "Accuracy on validation dataset: 2221/9723 (22.84%)\n",
      "\n",
      "Epoch: 3, Batch number: 48\n",
      "Accuracy on validation dataset: 2216/9723 (22.79%)\n",
      "\n",
      "Epoch: 3, Batch number: 58\n",
      "Accuracy on validation dataset: 2214/9723 (22.77%)\n",
      "\n",
      "Epoch: 3, Batch number: 68\n",
      "Accuracy on validation dataset: 2223/9723 (22.86%)\n",
      "\n",
      "Epoch: 4, Batch number: 2\n",
      "Accuracy on validation dataset: 2226/9723 (22.89%)\n",
      "\n",
      "Epoch: 4, Batch number: 12\n",
      "Accuracy on validation dataset: 2228/9723 (22.91%)\n",
      "\n",
      "Epoch: 4, Batch number: 22\n",
      "Accuracy on validation dataset: 2238/9723 (23.02%)\n",
      "\n",
      "Epoch: 4, Batch number: 32\n",
      "Accuracy on validation dataset: 2246/9723 (23.10%)\n",
      "\n",
      "Epoch: 4, Batch number: 42\n",
      "Accuracy on validation dataset: 2246/9723 (23.10%)\n",
      "\n",
      "Epoch: 4, Batch number: 52\n",
      "Accuracy on validation dataset: 2250/9723 (23.14%)\n",
      "\n",
      "Epoch: 4, Batch number: 62\n",
      "Accuracy on validation dataset: 2258/9723 (23.22%)\n",
      "\n",
      "Epoch: 4, Batch number: 72\n",
      "Accuracy on validation dataset: 2269/9723 (23.34%)\n",
      "\n",
      "Epoch: 5, Batch number: 6\n",
      "Accuracy on validation dataset: 2274/9723 (23.39%)\n",
      "\n",
      "Epoch: 5, Batch number: 16\n",
      "Accuracy on validation dataset: 2286/9723 (23.51%)\n",
      "\n",
      "Epoch: 5, Batch number: 26\n",
      "Accuracy on validation dataset: 2293/9723 (23.58%)\n",
      "\n",
      "Epoch: 5, Batch number: 36\n",
      "Accuracy on validation dataset: 2302/9723 (23.68%)\n",
      "\n",
      "Epoch: 5, Batch number: 46\n",
      "Accuracy on validation dataset: 2302/9723 (23.68%)\n",
      "\n",
      "Epoch: 5, Batch number: 56\n",
      "Accuracy on validation dataset: 2302/9723 (23.68%)\n",
      "\n",
      "Epoch: 5, Batch number: 66\n",
      "Accuracy on validation dataset: 2306/9723 (23.72%)\n",
      "\n",
      "Epoch: 6, Batch number: 0\n",
      "Accuracy on validation dataset: 2318/9723 (23.84%)\n",
      "\n",
      "Epoch: 6, Batch number: 10\n",
      "Accuracy on validation dataset: 2325/9723 (23.91%)\n",
      "\n",
      "Epoch: 6, Batch number: 20\n",
      "Accuracy on validation dataset: 2342/9723 (24.09%)\n",
      "\n",
      "Epoch: 6, Batch number: 30\n",
      "Accuracy on validation dataset: 2351/9723 (24.18%)\n",
      "\n",
      "Epoch: 6, Batch number: 40\n",
      "Accuracy on validation dataset: 2360/9723 (24.27%)\n",
      "\n",
      "Epoch: 6, Batch number: 50\n",
      "Accuracy on validation dataset: 2369/9723 (24.36%)\n",
      "\n",
      "Epoch: 6, Batch number: 60\n",
      "Accuracy on validation dataset: 2378/9723 (24.46%)\n",
      "\n",
      "Epoch: 6, Batch number: 70\n",
      "Accuracy on validation dataset: 2387/9723 (24.55%)\n",
      "\n",
      "Epoch: 7, Batch number: 4\n",
      "Accuracy on validation dataset: 2390/9723 (24.58%)\n",
      "\n",
      "Epoch: 7, Batch number: 14\n",
      "Accuracy on validation dataset: 2402/9723 (24.70%)\n",
      "\n",
      "Epoch: 7, Batch number: 24\n",
      "Accuracy on validation dataset: 2404/9723 (24.72%)\n",
      "\n",
      "Epoch: 7, Batch number: 34\n",
      "Accuracy on validation dataset: 2411/9723 (24.80%)\n",
      "\n",
      "Epoch: 7, Batch number: 44\n",
      "Accuracy on validation dataset: 2424/9723 (24.93%)\n",
      "\n",
      "Epoch: 7, Batch number: 54\n",
      "Accuracy on validation dataset: 2428/9723 (24.97%)\n",
      "\n",
      "Epoch: 7, Batch number: 64\n",
      "Accuracy on validation dataset: 2443/9723 (25.13%)\n",
      "\n",
      "Epoch: 7, Batch number: 74\n",
      "Accuracy on validation dataset: 2437/9723 (25.06%)\n",
      "\n",
      "Epoch: 8, Batch number: 8\n",
      "Accuracy on validation dataset: 2446/9723 (25.16%)\n",
      "\n",
      "Epoch: 8, Batch number: 18\n",
      "Accuracy on validation dataset: 2443/9723 (25.13%)\n",
      "\n",
      "Epoch: 8, Batch number: 28\n",
      "Accuracy on validation dataset: 2445/9723 (25.15%)\n",
      "\n",
      "Epoch: 8, Batch number: 38\n",
      "Accuracy on validation dataset: 2450/9723 (25.20%)\n",
      "\n",
      "Epoch: 8, Batch number: 48\n",
      "Accuracy on validation dataset: 2451/9723 (25.21%)\n",
      "\n",
      "Epoch: 8, Batch number: 58\n",
      "Accuracy on validation dataset: 2456/9723 (25.26%)\n",
      "\n",
      "Epoch: 8, Batch number: 68\n",
      "Accuracy on validation dataset: 2455/9723 (25.25%)\n",
      "\n",
      "Epoch: 9, Batch number: 2\n",
      "Accuracy on validation dataset: 2462/9723 (25.32%)\n",
      "\n",
      "Epoch: 9, Batch number: 12\n",
      "Accuracy on validation dataset: 2465/9723 (25.35%)\n",
      "\n",
      "Epoch: 9, Batch number: 22\n",
      "Accuracy on validation dataset: 2460/9723 (25.30%)\n",
      "\n",
      "Epoch: 9, Batch number: 32\n",
      "Accuracy on validation dataset: 2459/9723 (25.29%)\n",
      "\n",
      "Epoch: 9, Batch number: 42\n",
      "Accuracy on validation dataset: 2465/9723 (25.35%)\n",
      "\n",
      "Epoch: 9, Batch number: 52\n",
      "Accuracy on validation dataset: 2474/9723 (25.44%)\n",
      "\n",
      "Epoch: 9, Batch number: 62\n",
      "Accuracy on validation dataset: 2474/9723 (25.44%)\n",
      "\n",
      "Epoch: 9, Batch number: 72\n",
      "Accuracy on validation dataset: 2478/9723 (25.49%)\n",
      "\n",
      "Epoch: 10, Batch number: 6\n",
      "Accuracy on validation dataset: 2480/9723 (25.51%)\n",
      "\n",
      "Epoch: 10, Batch number: 16\n",
      "Accuracy on validation dataset: 2494/9723 (25.65%)\n",
      "\n",
      "Epoch: 10, Batch number: 26\n",
      "Accuracy on validation dataset: 2494/9723 (25.65%)\n",
      "\n",
      "Epoch: 10, Batch number: 36\n",
      "Accuracy on validation dataset: 2505/9723 (25.76%)\n",
      "\n",
      "Epoch: 10, Batch number: 46\n",
      "Accuracy on validation dataset: 2499/9723 (25.70%)\n",
      "\n",
      "Epoch: 10, Batch number: 56\n",
      "Accuracy on validation dataset: 2501/9723 (25.72%)\n",
      "\n",
      "Epoch: 10, Batch number: 66\n",
      "Accuracy on validation dataset: 2509/9723 (25.80%)\n",
      "\n",
      "Epoch: 11, Batch number: 0\n",
      "Accuracy on validation dataset: 2516/9723 (25.88%)\n",
      "\n",
      "Epoch: 11, Batch number: 10\n",
      "Accuracy on validation dataset: 2508/9723 (25.79%)\n",
      "\n",
      "Epoch: 11, Batch number: 20\n",
      "Accuracy on validation dataset: 2511/9723 (25.83%)\n",
      "\n",
      "Epoch: 11, Batch number: 30\n",
      "Accuracy on validation dataset: 2515/9723 (25.87%)\n",
      "\n",
      "Epoch: 11, Batch number: 40\n",
      "Accuracy on validation dataset: 2517/9723 (25.89%)\n",
      "\n",
      "Epoch: 11, Batch number: 50\n",
      "Accuracy on validation dataset: 2523/9723 (25.95%)\n",
      "\n",
      "Epoch: 11, Batch number: 60\n",
      "Accuracy on validation dataset: 2526/9723 (25.98%)\n",
      "\n",
      "Epoch: 11, Batch number: 70\n",
      "Accuracy on validation dataset: 2537/9723 (26.09%)\n",
      "\n",
      "Epoch: 12, Batch number: 4\n",
      "Accuracy on validation dataset: 2547/9723 (26.20%)\n",
      "\n",
      "Epoch: 12, Batch number: 14\n",
      "Accuracy on validation dataset: 2543/9723 (26.15%)\n",
      "\n",
      "Epoch: 12, Batch number: 24\n",
      "Accuracy on validation dataset: 2542/9723 (26.14%)\n",
      "\n",
      "Epoch: 12, Batch number: 34\n",
      "Accuracy on validation dataset: 2543/9723 (26.15%)\n",
      "\n",
      "Epoch: 12, Batch number: 44\n",
      "Accuracy on validation dataset: 2541/9723 (26.13%)\n",
      "\n",
      "Epoch: 12, Batch number: 54\n",
      "Accuracy on validation dataset: 2549/9723 (26.22%)\n",
      "\n",
      "Epoch: 12, Batch number: 64\n",
      "Accuracy on validation dataset: 2554/9723 (26.27%)\n",
      "\n",
      "Epoch: 12, Batch number: 74\n",
      "Accuracy on validation dataset: 2564/9723 (26.37%)\n",
      "\n",
      "Epoch: 13, Batch number: 8\n",
      "Accuracy on validation dataset: 2565/9723 (26.38%)\n",
      "\n",
      "Epoch: 13, Batch number: 18\n",
      "Accuracy on validation dataset: 2565/9723 (26.38%)\n",
      "\n",
      "Epoch: 13, Batch number: 28\n",
      "Accuracy on validation dataset: 2569/9723 (26.42%)\n",
      "\n",
      "Epoch: 13, Batch number: 38\n",
      "Accuracy on validation dataset: 2575/9723 (26.48%)\n",
      "\n",
      "Epoch: 13, Batch number: 48\n",
      "Accuracy on validation dataset: 2578/9723 (26.51%)\n",
      "\n",
      "Epoch: 13, Batch number: 58\n",
      "Accuracy on validation dataset: 2584/9723 (26.58%)\n",
      "\n",
      "Epoch: 13, Batch number: 68\n",
      "Accuracy on validation dataset: 2576/9723 (26.49%)\n",
      "\n",
      "Epoch: 14, Batch number: 2\n",
      "Accuracy on validation dataset: 2578/9723 (26.51%)\n",
      "\n",
      "Epoch: 14, Batch number: 12\n",
      "Accuracy on validation dataset: 2583/9723 (26.57%)\n",
      "\n",
      "Epoch: 14, Batch number: 22\n",
      "Accuracy on validation dataset: 2585/9723 (26.59%)\n",
      "\n",
      "Epoch: 14, Batch number: 32\n",
      "Accuracy on validation dataset: 2591/9723 (26.65%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Batch number: 42\n",
      "Accuracy on validation dataset: 2600/9723 (26.74%)\n",
      "\n",
      "Epoch: 14, Batch number: 52\n",
      "Accuracy on validation dataset: 2598/9723 (26.72%)\n",
      "\n",
      "Epoch: 14, Batch number: 62\n",
      "Accuracy on validation dataset: 2600/9723 (26.74%)\n",
      "\n",
      "Epoch: 14, Batch number: 72\n",
      "Accuracy on validation dataset: 2605/9723 (26.79%)\n",
      "\n",
      "Epoch: 15, Batch number: 6\n",
      "Accuracy on validation dataset: 2612/9723 (26.86%)\n",
      "\n",
      "Epoch: 15, Batch number: 16\n",
      "Accuracy on validation dataset: 2620/9723 (26.95%)\n",
      "\n",
      "Epoch: 15, Batch number: 26\n",
      "Accuracy on validation dataset: 2633/9723 (27.08%)\n",
      "\n",
      "Epoch: 15, Batch number: 36\n",
      "Accuracy on validation dataset: 2640/9723 (27.15%)\n",
      "\n",
      "Epoch: 15, Batch number: 46\n",
      "Accuracy on validation dataset: 2636/9723 (27.11%)\n",
      "\n",
      "Epoch: 15, Batch number: 56\n",
      "Accuracy on validation dataset: 2641/9723 (27.16%)\n",
      "\n",
      "Epoch: 15, Batch number: 66\n",
      "Accuracy on validation dataset: 2648/9723 (27.23%)\n",
      "\n",
      "Epoch: 16, Batch number: 0\n",
      "Accuracy on validation dataset: 2648/9723 (27.23%)\n",
      "\n",
      "Epoch: 16, Batch number: 10\n",
      "Accuracy on validation dataset: 2651/9723 (27.27%)\n",
      "\n",
      "Epoch: 16, Batch number: 20\n",
      "Accuracy on validation dataset: 2662/9723 (27.38%)\n",
      "\n",
      "Epoch: 16, Batch number: 30\n",
      "Accuracy on validation dataset: 2661/9723 (27.37%)\n",
      "\n",
      "Epoch: 16, Batch number: 40\n",
      "Accuracy on validation dataset: 2671/9723 (27.47%)\n",
      "\n",
      "Epoch: 16, Batch number: 50\n",
      "Accuracy on validation dataset: 2660/9723 (27.36%)\n",
      "\n",
      "Epoch: 16, Batch number: 60\n",
      "Accuracy on validation dataset: 2664/9723 (27.40%)\n",
      "\n",
      "Epoch: 16, Batch number: 70\n",
      "Accuracy on validation dataset: 2683/9723 (27.59%)\n",
      "\n",
      "Epoch: 17, Batch number: 4\n",
      "Accuracy on validation dataset: 2688/9723 (27.65%)\n",
      "\n",
      "Epoch: 17, Batch number: 14\n",
      "Accuracy on validation dataset: 2695/9723 (27.72%)\n",
      "\n",
      "Epoch: 17, Batch number: 24\n",
      "Accuracy on validation dataset: 2702/9723 (27.79%)\n",
      "\n",
      "Epoch: 17, Batch number: 34\n",
      "Accuracy on validation dataset: 2703/9723 (27.80%)\n",
      "\n",
      "Epoch: 17, Batch number: 44\n",
      "Accuracy on validation dataset: 2704/9723 (27.81%)\n",
      "\n",
      "Epoch: 17, Batch number: 54\n",
      "Accuracy on validation dataset: 2707/9723 (27.84%)\n",
      "\n",
      "Epoch: 17, Batch number: 64\n",
      "Accuracy on validation dataset: 2714/9723 (27.91%)\n",
      "\n",
      "Epoch: 17, Batch number: 74\n",
      "Accuracy on validation dataset: 2720/9723 (27.97%)\n",
      "\n",
      "Epoch: 18, Batch number: 8\n",
      "Accuracy on validation dataset: 2722/9723 (28.00%)\n",
      "\n",
      "Epoch: 18, Batch number: 18\n",
      "Accuracy on validation dataset: 2727/9723 (28.05%)\n",
      "\n",
      "Epoch: 18, Batch number: 28\n",
      "Accuracy on validation dataset: 2728/9723 (28.06%)\n",
      "\n",
      "Epoch: 18, Batch number: 38\n",
      "Accuracy on validation dataset: 2735/9723 (28.13%)\n",
      "\n",
      "Epoch: 18, Batch number: 48\n",
      "Accuracy on validation dataset: 2743/9723 (28.21%)\n",
      "\n",
      "Epoch: 18, Batch number: 58\n",
      "Accuracy on validation dataset: 2751/9723 (28.29%)\n",
      "\n",
      "Epoch: 18, Batch number: 68\n",
      "Accuracy on validation dataset: 2755/9723 (28.33%)\n",
      "\n",
      "Epoch: 19, Batch number: 2\n",
      "Accuracy on validation dataset: 2757/9723 (28.36%)\n",
      "\n",
      "Epoch: 19, Batch number: 12\n",
      "Accuracy on validation dataset: 2763/9723 (28.42%)\n",
      "\n",
      "Epoch: 19, Batch number: 22\n",
      "Accuracy on validation dataset: 2766/9723 (28.45%)\n",
      "\n",
      "Epoch: 19, Batch number: 32\n",
      "Accuracy on validation dataset: 2780/9723 (28.59%)\n",
      "\n",
      "Epoch: 19, Batch number: 42\n",
      "Accuracy on validation dataset: 2786/9723 (28.65%)\n",
      "\n",
      "Epoch: 19, Batch number: 52\n",
      "Accuracy on validation dataset: 2789/9723 (28.68%)\n",
      "\n",
      "Epoch: 19, Batch number: 62\n",
      "Accuracy on validation dataset: 2792/9723 (28.72%)\n",
      "\n",
      "Epoch: 19, Batch number: 72\n",
      "Accuracy on validation dataset: 2796/9723 (28.76%)\n",
      "\n",
      "Epoch: 20, Batch number: 6\n",
      "Accuracy on validation dataset: 2807/9723 (28.87%)\n",
      "\n",
      "Epoch: 20, Batch number: 16\n",
      "Accuracy on validation dataset: 2819/9723 (28.99%)\n",
      "\n",
      "Epoch: 20, Batch number: 26\n",
      "Accuracy on validation dataset: 2818/9723 (28.98%)\n",
      "\n",
      "Epoch: 20, Batch number: 36\n",
      "Accuracy on validation dataset: 2832/9723 (29.13%)\n",
      "\n",
      "Epoch: 20, Batch number: 46\n",
      "Accuracy on validation dataset: 2843/9723 (29.24%)\n",
      "\n",
      "Epoch: 20, Batch number: 56\n",
      "Accuracy on validation dataset: 2853/9723 (29.34%)\n",
      "\n",
      "Epoch: 20, Batch number: 66\n",
      "Accuracy on validation dataset: 2850/9723 (29.31%)\n",
      "\n",
      "Epoch: 21, Batch number: 0\n",
      "Accuracy on validation dataset: 2866/9723 (29.48%)\n",
      "\n",
      "Epoch: 21, Batch number: 10\n",
      "Accuracy on validation dataset: 2878/9723 (29.60%)\n",
      "\n",
      "Epoch: 21, Batch number: 20\n",
      "Accuracy on validation dataset: 2891/9723 (29.73%)\n",
      "\n",
      "Epoch: 21, Batch number: 30\n",
      "Accuracy on validation dataset: 2900/9723 (29.83%)\n",
      "\n",
      "Epoch: 21, Batch number: 40\n",
      "Accuracy on validation dataset: 2908/9723 (29.91%)\n",
      "\n",
      "Epoch: 21, Batch number: 50\n",
      "Accuracy on validation dataset: 2910/9723 (29.93%)\n",
      "\n",
      "Epoch: 21, Batch number: 60\n",
      "Accuracy on validation dataset: 2929/9723 (30.12%)\n",
      "\n",
      "Epoch: 21, Batch number: 70\n",
      "Accuracy on validation dataset: 2933/9723 (30.17%)\n",
      "\n",
      "Epoch: 22, Batch number: 4\n",
      "Accuracy on validation dataset: 2929/9723 (30.12%)\n",
      "\n",
      "Epoch: 22, Batch number: 14\n",
      "Accuracy on validation dataset: 2936/9723 (30.20%)\n",
      "\n",
      "Epoch: 22, Batch number: 24\n",
      "Accuracy on validation dataset: 2941/9723 (30.25%)\n",
      "\n",
      "Epoch: 22, Batch number: 34\n",
      "Accuracy on validation dataset: 2953/9723 (30.37%)\n",
      "\n",
      "Epoch: 22, Batch number: 44\n",
      "Accuracy on validation dataset: 2959/9723 (30.43%)\n",
      "\n",
      "Epoch: 22, Batch number: 54\n",
      "Accuracy on validation dataset: 2974/9723 (30.59%)\n",
      "\n",
      "Epoch: 22, Batch number: 64\n",
      "Accuracy on validation dataset: 2985/9723 (30.70%)\n",
      "\n",
      "Epoch: 22, Batch number: 74\n",
      "Accuracy on validation dataset: 2998/9723 (30.83%)\n",
      "\n",
      "Epoch: 23, Batch number: 8\n",
      "Accuracy on validation dataset: 3002/9723 (30.88%)\n",
      "\n",
      "Epoch: 23, Batch number: 18\n",
      "Accuracy on validation dataset: 3015/9723 (31.01%)\n",
      "\n",
      "Epoch: 23, Batch number: 28\n",
      "Accuracy on validation dataset: 3036/9723 (31.22%)\n",
      "\n",
      "Epoch: 23, Batch number: 38\n",
      "Accuracy on validation dataset: 3040/9723 (31.27%)\n",
      "\n",
      "Epoch: 23, Batch number: 48\n",
      "Accuracy on validation dataset: 3047/9723 (31.34%)\n",
      "\n",
      "Epoch: 23, Batch number: 58\n",
      "Accuracy on validation dataset: 3067/9723 (31.54%)\n",
      "\n",
      "Epoch: 23, Batch number: 68\n",
      "Accuracy on validation dataset: 3075/9723 (31.63%)\n",
      "\n",
      "Epoch: 24, Batch number: 2\n",
      "Accuracy on validation dataset: 3084/9723 (31.72%)\n",
      "\n",
      "Epoch: 24, Batch number: 12\n",
      "Accuracy on validation dataset: 3091/9723 (31.79%)\n",
      "\n",
      "Epoch: 24, Batch number: 22\n",
      "Accuracy on validation dataset: 3100/9723 (31.88%)\n",
      "\n",
      "Epoch: 24, Batch number: 32\n",
      "Accuracy on validation dataset: 3106/9723 (31.94%)\n",
      "\n",
      "Epoch: 24, Batch number: 42\n",
      "Accuracy on validation dataset: 3107/9723 (31.96%)\n",
      "\n",
      "Epoch: 24, Batch number: 52\n",
      "Accuracy on validation dataset: 3117/9723 (32.06%)\n",
      "\n",
      "Epoch: 24, Batch number: 62\n",
      "Accuracy on validation dataset: 3137/9723 (32.26%)\n",
      "\n",
      "Epoch: 24, Batch number: 72\n",
      "Accuracy on validation dataset: 3146/9723 (32.36%)\n",
      "\n",
      "Epoch: 25, Batch number: 6\n",
      "Accuracy on validation dataset: 3168/9723 (32.58%)\n",
      "\n",
      "Epoch: 25, Batch number: 16\n",
      "Accuracy on validation dataset: 3171/9723 (32.61%)\n",
      "\n",
      "Epoch: 25, Batch number: 26\n",
      "Accuracy on validation dataset: 3186/9723 (32.77%)\n",
      "\n",
      "Epoch: 25, Batch number: 36\n",
      "Accuracy on validation dataset: 3195/9723 (32.86%)\n",
      "\n",
      "Epoch: 25, Batch number: 46\n",
      "Accuracy on validation dataset: 3205/9723 (32.96%)\n",
      "\n",
      "Epoch: 25, Batch number: 56\n",
      "Accuracy on validation dataset: 3211/9723 (33.02%)\n",
      "\n",
      "Epoch: 25, Batch number: 66\n",
      "Accuracy on validation dataset: 3216/9723 (33.08%)\n",
      "\n",
      "Epoch: 26, Batch number: 0\n",
      "Accuracy on validation dataset: 3230/9723 (33.22%)\n",
      "\n",
      "Epoch: 26, Batch number: 10\n",
      "Accuracy on validation dataset: 3240/9723 (33.32%)\n",
      "\n",
      "Epoch: 26, Batch number: 20\n",
      "Accuracy on validation dataset: 3244/9723 (33.36%)\n",
      "\n",
      "Epoch: 26, Batch number: 30\n",
      "Accuracy on validation dataset: 3250/9723 (33.43%)\n",
      "\n",
      "Epoch: 26, Batch number: 40\n",
      "Accuracy on validation dataset: 3263/9723 (33.56%)\n",
      "\n",
      "Epoch: 26, Batch number: 50\n",
      "Accuracy on validation dataset: 3276/9723 (33.69%)\n",
      "\n",
      "Epoch: 26, Batch number: 60\n",
      "Accuracy on validation dataset: 3289/9723 (33.83%)\n",
      "\n",
      "Epoch: 26, Batch number: 70\n",
      "Accuracy on validation dataset: 3296/9723 (33.90%)\n",
      "\n",
      "Epoch: 27, Batch number: 4\n",
      "Accuracy on validation dataset: 3303/9723 (33.97%)\n",
      "\n",
      "Epoch: 27, Batch number: 14\n",
      "Accuracy on validation dataset: 3316/9723 (34.10%)\n",
      "\n",
      "Epoch: 27, Batch number: 24\n",
      "Accuracy on validation dataset: 3323/9723 (34.18%)\n",
      "\n",
      "Epoch: 27, Batch number: 34\n",
      "Accuracy on validation dataset: 3328/9723 (34.23%)\n",
      "\n",
      "Epoch: 27, Batch number: 44\n",
      "Accuracy on validation dataset: 3341/9723 (34.36%)\n",
      "\n",
      "Epoch: 27, Batch number: 54\n",
      "Accuracy on validation dataset: 3346/9723 (34.41%)\n",
      "\n",
      "Epoch: 27, Batch number: 64\n",
      "Accuracy on validation dataset: 3352/9723 (34.47%)\n",
      "\n",
      "Epoch: 27, Batch number: 74\n",
      "Accuracy on validation dataset: 3357/9723 (34.53%)\n",
      "\n",
      "Epoch: 28, Batch number: 8\n",
      "Accuracy on validation dataset: 3379/9723 (34.75%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Batch number: 18\n",
      "Accuracy on validation dataset: 3377/9723 (34.73%)\n",
      "\n",
      "Epoch: 28, Batch number: 28\n",
      "Accuracy on validation dataset: 3390/9723 (34.87%)\n",
      "\n",
      "Epoch: 28, Batch number: 38\n",
      "Accuracy on validation dataset: 3398/9723 (34.95%)\n",
      "\n",
      "Epoch: 28, Batch number: 48\n",
      "Accuracy on validation dataset: 3409/9723 (35.06%)\n",
      "\n",
      "Epoch: 28, Batch number: 58\n",
      "Accuracy on validation dataset: 3418/9723 (35.15%)\n",
      "\n",
      "Epoch: 28, Batch number: 68\n",
      "Accuracy on validation dataset: 3432/9723 (35.30%)\n",
      "\n",
      "Epoch: 29, Batch number: 2\n",
      "Accuracy on validation dataset: 3443/9723 (35.41%)\n",
      "\n",
      "Epoch: 29, Batch number: 12\n",
      "Accuracy on validation dataset: 3454/9723 (35.52%)\n",
      "\n",
      "Epoch: 29, Batch number: 22\n",
      "Accuracy on validation dataset: 3456/9723 (35.54%)\n",
      "\n",
      "Epoch: 29, Batch number: 32\n",
      "Accuracy on validation dataset: 3466/9723 (35.65%)\n",
      "\n",
      "Epoch: 29, Batch number: 42\n",
      "Accuracy on validation dataset: 3472/9723 (35.71%)\n",
      "\n",
      "Epoch: 29, Batch number: 52\n",
      "Accuracy on validation dataset: 3486/9723 (35.85%)\n",
      "\n",
      "Epoch: 29, Batch number: 62\n",
      "Accuracy on validation dataset: 3500/9723 (36.00%)\n",
      "\n",
      "Epoch: 29, Batch number: 72\n",
      "Accuracy on validation dataset: 3503/9723 (36.03%)\n",
      "\n",
      "Epoch: 30, Batch number: 6\n",
      "Accuracy on validation dataset: 3511/9723 (36.11%)\n",
      "\n",
      "Epoch: 30, Batch number: 16\n",
      "Accuracy on validation dataset: 3521/9723 (36.21%)\n",
      "\n",
      "Epoch: 30, Batch number: 26\n",
      "Accuracy on validation dataset: 3525/9723 (36.25%)\n",
      "\n",
      "Epoch: 30, Batch number: 36\n",
      "Accuracy on validation dataset: 3530/9723 (36.31%)\n",
      "\n",
      "Epoch: 30, Batch number: 46\n",
      "Accuracy on validation dataset: 3538/9723 (36.39%)\n",
      "\n",
      "Epoch: 30, Batch number: 56\n",
      "Accuracy on validation dataset: 3557/9723 (36.58%)\n",
      "\n",
      "Epoch: 30, Batch number: 66\n",
      "Accuracy on validation dataset: 3559/9723 (36.60%)\n",
      "\n",
      "Epoch: 31, Batch number: 0\n",
      "Accuracy on validation dataset: 3573/9723 (36.75%)\n",
      "\n",
      "Epoch: 31, Batch number: 10\n",
      "Accuracy on validation dataset: 3582/9723 (36.84%)\n",
      "\n",
      "Epoch: 31, Batch number: 20\n",
      "Accuracy on validation dataset: 3578/9723 (36.80%)\n",
      "\n",
      "Epoch: 31, Batch number: 30\n",
      "Accuracy on validation dataset: 3596/9723 (36.98%)\n",
      "\n",
      "Epoch: 31, Batch number: 40\n",
      "Accuracy on validation dataset: 3606/9723 (37.09%)\n",
      "\n",
      "Epoch: 31, Batch number: 50\n",
      "Accuracy on validation dataset: 3607/9723 (37.10%)\n",
      "\n",
      "Epoch: 31, Batch number: 60\n",
      "Accuracy on validation dataset: 3621/9723 (37.24%)\n",
      "\n",
      "Epoch: 31, Batch number: 70\n",
      "Accuracy on validation dataset: 3623/9723 (37.26%)\n",
      "\n",
      "Epoch: 32, Batch number: 4\n",
      "Accuracy on validation dataset: 3628/9723 (37.31%)\n",
      "\n",
      "Epoch: 32, Batch number: 14\n",
      "Accuracy on validation dataset: 3643/9723 (37.47%)\n",
      "\n",
      "Epoch: 32, Batch number: 24\n",
      "Accuracy on validation dataset: 3652/9723 (37.56%)\n",
      "\n",
      "Epoch: 32, Batch number: 34\n",
      "Accuracy on validation dataset: 3655/9723 (37.59%)\n",
      "\n",
      "Epoch: 32, Batch number: 44\n",
      "Accuracy on validation dataset: 3661/9723 (37.65%)\n",
      "\n",
      "Epoch: 32, Batch number: 54\n",
      "Accuracy on validation dataset: 3668/9723 (37.72%)\n",
      "\n",
      "Epoch: 32, Batch number: 64\n",
      "Accuracy on validation dataset: 3675/9723 (37.80%)\n",
      "\n",
      "Epoch: 32, Batch number: 74\n",
      "Accuracy on validation dataset: 3674/9723 (37.79%)\n",
      "\n",
      "Epoch: 33, Batch number: 8\n",
      "Accuracy on validation dataset: 3686/9723 (37.91%)\n",
      "\n",
      "Epoch: 33, Batch number: 18\n",
      "Accuracy on validation dataset: 3691/9723 (37.96%)\n",
      "\n",
      "Epoch: 33, Batch number: 28\n",
      "Accuracy on validation dataset: 3694/9723 (37.99%)\n",
      "\n",
      "Epoch: 33, Batch number: 38\n",
      "Accuracy on validation dataset: 3707/9723 (38.13%)\n",
      "\n",
      "Epoch: 33, Batch number: 48\n",
      "Accuracy on validation dataset: 3709/9723 (38.15%)\n",
      "\n",
      "Epoch: 33, Batch number: 58\n",
      "Accuracy on validation dataset: 3720/9723 (38.26%)\n",
      "\n",
      "Epoch: 33, Batch number: 68\n",
      "Accuracy on validation dataset: 3721/9723 (38.27%)\n",
      "\n",
      "Epoch: 34, Batch number: 2\n",
      "Accuracy on validation dataset: 3734/9723 (38.40%)\n",
      "\n",
      "Epoch: 34, Batch number: 12\n",
      "Accuracy on validation dataset: 3748/9723 (38.55%)\n",
      "\n",
      "Epoch: 34, Batch number: 22\n",
      "Accuracy on validation dataset: 3749/9723 (38.56%)\n",
      "\n",
      "Epoch: 34, Batch number: 32\n",
      "Accuracy on validation dataset: 3742/9723 (38.49%)\n",
      "\n",
      "Epoch: 34, Batch number: 42\n",
      "Accuracy on validation dataset: 3751/9723 (38.58%)\n",
      "\n",
      "Epoch: 34, Batch number: 52\n",
      "Accuracy on validation dataset: 3768/9723 (38.75%)\n",
      "\n",
      "Epoch: 34, Batch number: 62\n",
      "Accuracy on validation dataset: 3771/9723 (38.78%)\n",
      "\n",
      "Epoch: 34, Batch number: 72\n",
      "Accuracy on validation dataset: 3776/9723 (38.84%)\n",
      "\n",
      "Epoch: 35, Batch number: 6\n",
      "Accuracy on validation dataset: 3781/9723 (38.89%)\n",
      "\n",
      "Epoch: 35, Batch number: 16\n",
      "Accuracy on validation dataset: 3793/9723 (39.01%)\n",
      "\n",
      "Epoch: 35, Batch number: 26\n",
      "Accuracy on validation dataset: 3796/9723 (39.04%)\n",
      "\n",
      "Epoch: 35, Batch number: 36\n",
      "Accuracy on validation dataset: 3802/9723 (39.10%)\n",
      "\n",
      "Epoch: 35, Batch number: 46\n",
      "Accuracy on validation dataset: 3811/9723 (39.20%)\n",
      "\n",
      "Epoch: 35, Batch number: 56\n",
      "Accuracy on validation dataset: 3819/9723 (39.28%)\n",
      "\n",
      "Epoch: 35, Batch number: 66\n",
      "Accuracy on validation dataset: 3837/9723 (39.46%)\n",
      "\n",
      "Epoch: 36, Batch number: 0\n",
      "Accuracy on validation dataset: 3839/9723 (39.48%)\n",
      "\n",
      "Epoch: 36, Batch number: 10\n",
      "Accuracy on validation dataset: 3837/9723 (39.46%)\n",
      "\n",
      "Epoch: 36, Batch number: 20\n",
      "Accuracy on validation dataset: 3842/9723 (39.51%)\n",
      "\n",
      "Epoch: 36, Batch number: 30\n",
      "Accuracy on validation dataset: 3850/9723 (39.60%)\n",
      "\n",
      "Epoch: 36, Batch number: 40\n",
      "Accuracy on validation dataset: 3849/9723 (39.59%)\n",
      "\n",
      "Epoch: 36, Batch number: 50\n",
      "Accuracy on validation dataset: 3854/9723 (39.64%)\n",
      "\n",
      "Epoch: 36, Batch number: 60\n",
      "Accuracy on validation dataset: 3862/9723 (39.72%)\n",
      "\n",
      "Epoch: 36, Batch number: 70\n",
      "Accuracy on validation dataset: 3875/9723 (39.85%)\n",
      "\n",
      "Epoch: 37, Batch number: 4\n",
      "Accuracy on validation dataset: 3880/9723 (39.91%)\n",
      "\n",
      "Epoch: 37, Batch number: 14\n",
      "Accuracy on validation dataset: 3884/9723 (39.95%)\n",
      "\n",
      "Epoch: 37, Batch number: 24\n",
      "Accuracy on validation dataset: 3903/9723 (40.14%)\n",
      "\n",
      "Epoch: 37, Batch number: 34\n",
      "Accuracy on validation dataset: 3895/9723 (40.06%)\n",
      "\n",
      "Epoch: 37, Batch number: 44\n",
      "Accuracy on validation dataset: 3900/9723 (40.11%)\n",
      "\n",
      "Epoch: 37, Batch number: 54\n",
      "Accuracy on validation dataset: 3907/9723 (40.18%)\n",
      "\n",
      "Epoch: 37, Batch number: 64\n",
      "Accuracy on validation dataset: 3909/9723 (40.20%)\n",
      "\n",
      "Epoch: 37, Batch number: 74\n",
      "Accuracy on validation dataset: 3905/9723 (40.16%)\n",
      "\n",
      "Epoch: 38, Batch number: 8\n",
      "Accuracy on validation dataset: 3913/9723 (40.24%)\n",
      "\n",
      "Epoch: 38, Batch number: 18\n",
      "Accuracy on validation dataset: 3923/9723 (40.35%)\n",
      "\n",
      "Epoch: 38, Batch number: 28\n",
      "Accuracy on validation dataset: 3934/9723 (40.46%)\n",
      "\n",
      "Epoch: 38, Batch number: 38\n",
      "Accuracy on validation dataset: 3936/9723 (40.48%)\n",
      "\n",
      "Epoch: 38, Batch number: 48\n",
      "Accuracy on validation dataset: 3941/9723 (40.53%)\n",
      "\n",
      "Epoch: 38, Batch number: 58\n",
      "Accuracy on validation dataset: 3953/9723 (40.66%)\n",
      "\n",
      "Epoch: 38, Batch number: 68\n",
      "Accuracy on validation dataset: 3957/9723 (40.70%)\n",
      "\n",
      "Epoch: 39, Batch number: 2\n",
      "Accuracy on validation dataset: 3962/9723 (40.75%)\n",
      "\n",
      "Epoch: 39, Batch number: 12\n",
      "Accuracy on validation dataset: 3965/9723 (40.78%)\n",
      "\n",
      "Epoch: 39, Batch number: 22\n",
      "Accuracy on validation dataset: 3970/9723 (40.83%)\n",
      "\n",
      "Epoch: 39, Batch number: 32\n",
      "Accuracy on validation dataset: 3984/9723 (40.98%)\n",
      "\n",
      "Epoch: 39, Batch number: 42\n",
      "Accuracy on validation dataset: 3990/9723 (41.04%)\n",
      "\n",
      "Epoch: 39, Batch number: 52\n",
      "Accuracy on validation dataset: 3998/9723 (41.12%)\n",
      "\n",
      "Epoch: 39, Batch number: 62\n",
      "Accuracy on validation dataset: 3993/9723 (41.07%)\n",
      "\n",
      "Epoch: 39, Batch number: 72\n",
      "Accuracy on validation dataset: 3999/9723 (41.13%)\n",
      "\n",
      "Epoch: 40, Batch number: 6\n",
      "Accuracy on validation dataset: 4005/9723 (41.19%)\n",
      "\n",
      "Epoch: 40, Batch number: 16\n",
      "Accuracy on validation dataset: 4017/9723 (41.31%)\n",
      "\n",
      "Epoch: 40, Batch number: 26\n",
      "Accuracy on validation dataset: 4017/9723 (41.31%)\n",
      "\n",
      "Epoch: 40, Batch number: 36\n",
      "Accuracy on validation dataset: 4016/9723 (41.30%)\n",
      "\n",
      "Epoch: 40, Batch number: 46\n",
      "Accuracy on validation dataset: 4024/9723 (41.39%)\n",
      "\n",
      "Epoch: 40, Batch number: 56\n",
      "Accuracy on validation dataset: 4027/9723 (41.42%)\n",
      "\n",
      "Epoch: 40, Batch number: 66\n",
      "Accuracy on validation dataset: 4041/9723 (41.56%)\n",
      "\n",
      "Epoch: 41, Batch number: 0\n",
      "Accuracy on validation dataset: 4044/9723 (41.59%)\n",
      "\n",
      "Epoch: 41, Batch number: 10\n",
      "Accuracy on validation dataset: 4032/9723 (41.47%)\n",
      "\n",
      "Epoch: 41, Batch number: 20\n",
      "Accuracy on validation dataset: 4050/9723 (41.65%)\n",
      "\n",
      "Epoch: 41, Batch number: 30\n",
      "Accuracy on validation dataset: 4052/9723 (41.67%)\n",
      "\n",
      "Epoch: 41, Batch number: 40\n",
      "Accuracy on validation dataset: 4062/9723 (41.78%)\n",
      "\n",
      "Epoch: 41, Batch number: 50\n",
      "Accuracy on validation dataset: 4062/9723 (41.78%)\n",
      "\n",
      "Epoch: 41, Batch number: 60\n",
      "Accuracy on validation dataset: 4068/9723 (41.84%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Batch number: 70\n",
      "Accuracy on validation dataset: 4077/9723 (41.93%)\n",
      "\n",
      "Epoch: 42, Batch number: 4\n",
      "Accuracy on validation dataset: 4069/9723 (41.85%)\n",
      "\n",
      "Epoch: 42, Batch number: 14\n",
      "Accuracy on validation dataset: 4069/9723 (41.85%)\n",
      "\n",
      "Epoch: 42, Batch number: 24\n",
      "Accuracy on validation dataset: 4078/9723 (41.94%)\n",
      "\n",
      "Epoch: 42, Batch number: 34\n",
      "Accuracy on validation dataset: 4093/9723 (42.10%)\n",
      "\n",
      "Epoch: 42, Batch number: 44\n",
      "Accuracy on validation dataset: 4112/9723 (42.29%)\n",
      "\n",
      "Epoch: 42, Batch number: 54\n",
      "Accuracy on validation dataset: 4127/9723 (42.45%)\n",
      "\n",
      "Epoch: 42, Batch number: 64\n",
      "Accuracy on validation dataset: 4129/9723 (42.47%)\n",
      "\n",
      "Epoch: 42, Batch number: 74\n",
      "Accuracy on validation dataset: 4132/9723 (42.50%)\n",
      "\n",
      "Epoch: 43, Batch number: 8\n",
      "Accuracy on validation dataset: 4128/9723 (42.46%)\n",
      "\n",
      "Epoch: 43, Batch number: 18\n",
      "Accuracy on validation dataset: 4122/9723 (42.39%)\n",
      "\n",
      "Epoch: 43, Batch number: 28\n",
      "Accuracy on validation dataset: 4133/9723 (42.51%)\n",
      "\n",
      "Epoch: 43, Batch number: 38\n",
      "Accuracy on validation dataset: 4139/9723 (42.57%)\n",
      "\n",
      "Epoch: 43, Batch number: 48\n",
      "Accuracy on validation dataset: 4148/9723 (42.66%)\n",
      "\n",
      "Epoch: 43, Batch number: 58\n",
      "Accuracy on validation dataset: 4151/9723 (42.69%)\n",
      "\n",
      "Epoch: 43, Batch number: 68\n",
      "Accuracy on validation dataset: 4165/9723 (42.84%)\n",
      "\n",
      "Epoch: 44, Batch number: 2\n",
      "Accuracy on validation dataset: 4179/9723 (42.98%)\n",
      "\n",
      "Epoch: 44, Batch number: 12\n",
      "Accuracy on validation dataset: 4179/9723 (42.98%)\n",
      "\n",
      "Epoch: 44, Batch number: 22\n",
      "Accuracy on validation dataset: 4180/9723 (42.99%)\n",
      "\n",
      "Epoch: 44, Batch number: 32\n",
      "Accuracy on validation dataset: 4193/9723 (43.12%)\n",
      "\n",
      "Epoch: 44, Batch number: 42\n",
      "Accuracy on validation dataset: 4197/9723 (43.17%)\n",
      "\n",
      "Epoch: 44, Batch number: 52\n",
      "Accuracy on validation dataset: 4196/9723 (43.16%)\n",
      "\n",
      "Epoch: 44, Batch number: 62\n",
      "Accuracy on validation dataset: 4204/9723 (43.24%)\n",
      "\n",
      "Epoch: 44, Batch number: 72\n",
      "Accuracy on validation dataset: 4219/9723 (43.39%)\n",
      "\n",
      "Epoch: 45, Batch number: 6\n",
      "Accuracy on validation dataset: 4221/9723 (43.41%)\n",
      "\n",
      "Epoch: 45, Batch number: 16\n",
      "Accuracy on validation dataset: 4224/9723 (43.44%)\n",
      "\n",
      "Epoch: 45, Batch number: 26\n",
      "Accuracy on validation dataset: 4227/9723 (43.47%)\n",
      "\n",
      "Epoch: 45, Batch number: 36\n",
      "Accuracy on validation dataset: 4237/9723 (43.58%)\n",
      "\n",
      "Epoch: 45, Batch number: 46\n",
      "Accuracy on validation dataset: 4241/9723 (43.62%)\n",
      "\n",
      "Epoch: 45, Batch number: 56\n",
      "Accuracy on validation dataset: 4253/9723 (43.74%)\n",
      "\n",
      "Epoch: 45, Batch number: 66\n",
      "Accuracy on validation dataset: 4242/9723 (43.63%)\n",
      "\n",
      "Epoch: 46, Batch number: 0\n",
      "Accuracy on validation dataset: 4247/9723 (43.68%)\n",
      "\n",
      "Epoch: 46, Batch number: 10\n",
      "Accuracy on validation dataset: 4251/9723 (43.72%)\n",
      "\n",
      "Epoch: 46, Batch number: 20\n",
      "Accuracy on validation dataset: 4256/9723 (43.77%)\n",
      "\n",
      "Epoch: 46, Batch number: 30\n",
      "Accuracy on validation dataset: 4270/9723 (43.92%)\n",
      "\n",
      "Epoch: 46, Batch number: 40\n",
      "Accuracy on validation dataset: 4275/9723 (43.97%)\n",
      "\n",
      "Epoch: 46, Batch number: 50\n",
      "Accuracy on validation dataset: 4287/9723 (44.09%)\n",
      "\n",
      "Epoch: 46, Batch number: 60\n",
      "Accuracy on validation dataset: 4283/9723 (44.05%)\n",
      "\n",
      "Epoch: 46, Batch number: 70\n",
      "Accuracy on validation dataset: 4290/9723 (44.12%)\n",
      "\n",
      "Epoch: 47, Batch number: 4\n",
      "Accuracy on validation dataset: 4283/9723 (44.05%)\n",
      "\n",
      "Epoch: 47, Batch number: 14\n",
      "Accuracy on validation dataset: 4284/9723 (44.06%)\n",
      "\n",
      "Epoch: 47, Batch number: 24\n",
      "Accuracy on validation dataset: 4293/9723 (44.15%)\n",
      "\n",
      "Epoch: 47, Batch number: 34\n",
      "Accuracy on validation dataset: 4302/9723 (44.25%)\n",
      "\n",
      "Epoch: 47, Batch number: 44\n",
      "Accuracy on validation dataset: 4303/9723 (44.26%)\n",
      "\n",
      "Epoch: 47, Batch number: 54\n",
      "Accuracy on validation dataset: 4314/9723 (44.37%)\n",
      "\n",
      "Epoch: 47, Batch number: 64\n",
      "Accuracy on validation dataset: 4324/9723 (44.47%)\n",
      "\n",
      "Epoch: 47, Batch number: 74\n",
      "Accuracy on validation dataset: 4329/9723 (44.52%)\n",
      "\n",
      "Epoch: 48, Batch number: 8\n",
      "Accuracy on validation dataset: 4333/9723 (44.56%)\n",
      "\n",
      "Epoch: 48, Batch number: 18\n",
      "Accuracy on validation dataset: 4343/9723 (44.67%)\n",
      "\n",
      "Epoch: 48, Batch number: 28\n",
      "Accuracy on validation dataset: 4354/9723 (44.78%)\n",
      "\n",
      "Epoch: 48, Batch number: 38\n",
      "Accuracy on validation dataset: 4349/9723 (44.73%)\n",
      "\n",
      "Epoch: 48, Batch number: 48\n",
      "Accuracy on validation dataset: 4348/9723 (44.72%)\n",
      "\n",
      "Epoch: 48, Batch number: 58\n",
      "Accuracy on validation dataset: 4355/9723 (44.79%)\n",
      "\n",
      "Epoch: 48, Batch number: 68\n",
      "Accuracy on validation dataset: 4366/9723 (44.90%)\n",
      "\n",
      "Epoch: 49, Batch number: 2\n",
      "Accuracy on validation dataset: 4365/9723 (44.89%)\n",
      "\n",
      "Epoch: 49, Batch number: 12\n",
      "Accuracy on validation dataset: 4369/9723 (44.93%)\n",
      "\n",
      "Epoch: 49, Batch number: 22\n",
      "Accuracy on validation dataset: 4377/9723 (45.02%)\n",
      "\n",
      "Epoch: 49, Batch number: 32\n",
      "Accuracy on validation dataset: 4390/9723 (45.15%)\n",
      "\n",
      "Epoch: 49, Batch number: 42\n",
      "Accuracy on validation dataset: 4395/9723 (45.20%)\n",
      "\n",
      "Epoch: 49, Batch number: 52\n",
      "Accuracy on validation dataset: 4395/9723 (45.20%)\n",
      "\n",
      "Epoch: 49, Batch number: 62\n",
      "Accuracy on validation dataset: 4398/9723 (45.23%)\n",
      "\n",
      "Epoch: 49, Batch number: 72\n",
      "Accuracy on validation dataset: 4407/9723 (45.33%)\n",
      "\n",
      "Epoch: 50, Batch number: 6\n",
      "Accuracy on validation dataset: 4408/9723 (45.34%)\n",
      "\n",
      "Epoch: 50, Batch number: 16\n",
      "Accuracy on validation dataset: 4417/9723 (45.43%)\n",
      "\n",
      "Epoch: 50, Batch number: 26\n",
      "Accuracy on validation dataset: 4418/9723 (45.44%)\n",
      "\n",
      "Epoch: 50, Batch number: 36\n",
      "Accuracy on validation dataset: 4419/9723 (45.45%)\n",
      "\n",
      "Epoch: 50, Batch number: 46\n",
      "Accuracy on validation dataset: 4426/9723 (45.52%)\n",
      "\n",
      "Epoch: 50, Batch number: 56\n",
      "Accuracy on validation dataset: 4420/9723 (45.46%)\n",
      "\n",
      "Epoch: 50, Batch number: 66\n",
      "Accuracy on validation dataset: 4443/9723 (45.70%)\n",
      "\n",
      "Epoch: 51, Batch number: 0\n",
      "Accuracy on validation dataset: 4448/9723 (45.75%)\n",
      "\n",
      "Epoch: 51, Batch number: 10\n",
      "Accuracy on validation dataset: 4451/9723 (45.78%)\n",
      "\n",
      "Epoch: 51, Batch number: 20\n",
      "Accuracy on validation dataset: 4456/9723 (45.83%)\n",
      "\n",
      "Epoch: 51, Batch number: 30\n",
      "Accuracy on validation dataset: 4463/9723 (45.90%)\n",
      "\n",
      "Epoch: 51, Batch number: 40\n",
      "Accuracy on validation dataset: 4479/9723 (46.07%)\n",
      "\n",
      "Epoch: 51, Batch number: 50\n",
      "Accuracy on validation dataset: 4484/9723 (46.12%)\n",
      "\n",
      "Epoch: 51, Batch number: 60\n",
      "Accuracy on validation dataset: 4485/9723 (46.13%)\n",
      "\n",
      "Epoch: 51, Batch number: 70\n",
      "Accuracy on validation dataset: 4476/9723 (46.04%)\n",
      "\n",
      "Epoch: 52, Batch number: 4\n",
      "Accuracy on validation dataset: 4482/9723 (46.10%)\n",
      "\n",
      "Epoch: 52, Batch number: 14\n",
      "Accuracy on validation dataset: 4489/9723 (46.17%)\n",
      "\n",
      "Epoch: 52, Batch number: 24\n",
      "Accuracy on validation dataset: 4479/9723 (46.07%)\n",
      "\n",
      "Epoch: 52, Batch number: 34\n",
      "Accuracy on validation dataset: 4488/9723 (46.16%)\n",
      "\n",
      "Epoch: 52, Batch number: 44\n",
      "Accuracy on validation dataset: 4500/9723 (46.28%)\n",
      "\n",
      "Epoch: 52, Batch number: 54\n",
      "Accuracy on validation dataset: 4510/9723 (46.38%)\n",
      "\n",
      "Epoch: 52, Batch number: 64\n",
      "Accuracy on validation dataset: 4516/9723 (46.45%)\n",
      "\n",
      "Epoch: 52, Batch number: 74\n",
      "Accuracy on validation dataset: 4529/9723 (46.58%)\n",
      "\n",
      "Epoch: 53, Batch number: 8\n",
      "Accuracy on validation dataset: 4526/9723 (46.55%)\n",
      "\n",
      "Epoch: 53, Batch number: 18\n",
      "Accuracy on validation dataset: 4520/9723 (46.49%)\n",
      "\n",
      "Epoch: 53, Batch number: 28\n",
      "Accuracy on validation dataset: 4519/9723 (46.48%)\n",
      "\n",
      "Epoch: 53, Batch number: 38\n",
      "Accuracy on validation dataset: 4529/9723 (46.58%)\n",
      "\n",
      "Epoch: 53, Batch number: 48\n",
      "Accuracy on validation dataset: 4539/9723 (46.68%)\n",
      "\n",
      "Epoch: 53, Batch number: 58\n",
      "Accuracy on validation dataset: 4540/9723 (46.69%)\n",
      "\n",
      "Epoch: 53, Batch number: 68\n",
      "Accuracy on validation dataset: 4548/9723 (46.78%)\n",
      "\n",
      "Epoch: 54, Batch number: 2\n",
      "Accuracy on validation dataset: 4548/9723 (46.78%)\n",
      "\n",
      "Epoch: 54, Batch number: 12\n",
      "Accuracy on validation dataset: 4563/9723 (46.93%)\n",
      "\n",
      "Epoch: 54, Batch number: 22\n",
      "Accuracy on validation dataset: 4561/9723 (46.91%)\n",
      "\n",
      "Epoch: 54, Batch number: 32\n",
      "Accuracy on validation dataset: 4571/9723 (47.01%)\n",
      "\n",
      "Epoch: 54, Batch number: 42\n",
      "Accuracy on validation dataset: 4571/9723 (47.01%)\n",
      "\n",
      "Epoch: 54, Batch number: 52\n",
      "Accuracy on validation dataset: 4573/9723 (47.03%)\n",
      "\n",
      "Epoch: 54, Batch number: 62\n",
      "Accuracy on validation dataset: 4578/9723 (47.08%)\n",
      "\n",
      "Epoch: 54, Batch number: 72\n",
      "Accuracy on validation dataset: 4576/9723 (47.06%)\n",
      "\n",
      "Epoch: 55, Batch number: 6\n",
      "Accuracy on validation dataset: 4585/9723 (47.16%)\n",
      "\n",
      "Epoch: 55, Batch number: 16\n",
      "Accuracy on validation dataset: 4582/9723 (47.13%)\n",
      "\n",
      "Epoch: 55, Batch number: 26\n",
      "Accuracy on validation dataset: 4589/9723 (47.20%)\n",
      "\n",
      "Epoch: 55, Batch number: 36\n",
      "Accuracy on validation dataset: 4594/9723 (47.25%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Batch number: 46\n",
      "Accuracy on validation dataset: 4595/9723 (47.26%)\n",
      "\n",
      "Epoch: 55, Batch number: 56\n",
      "Accuracy on validation dataset: 4603/9723 (47.34%)\n",
      "\n",
      "Epoch: 55, Batch number: 66\n",
      "Accuracy on validation dataset: 4607/9723 (47.38%)\n",
      "\n",
      "Epoch: 56, Batch number: 0\n",
      "Accuracy on validation dataset: 4609/9723 (47.40%)\n",
      "\n",
      "Epoch: 56, Batch number: 10\n",
      "Accuracy on validation dataset: 4613/9723 (47.44%)\n",
      "\n",
      "Epoch: 56, Batch number: 20\n",
      "Accuracy on validation dataset: 4617/9723 (47.49%)\n",
      "\n",
      "Epoch: 56, Batch number: 30\n",
      "Accuracy on validation dataset: 4626/9723 (47.58%)\n",
      "\n",
      "Epoch: 56, Batch number: 40\n",
      "Accuracy on validation dataset: 4631/9723 (47.63%)\n",
      "\n",
      "Epoch: 56, Batch number: 50\n",
      "Accuracy on validation dataset: 4634/9723 (47.66%)\n",
      "\n",
      "Epoch: 56, Batch number: 60\n",
      "Accuracy on validation dataset: 4627/9723 (47.59%)\n",
      "\n",
      "Epoch: 56, Batch number: 70\n",
      "Accuracy on validation dataset: 4636/9723 (47.68%)\n",
      "\n",
      "Epoch: 57, Batch number: 4\n",
      "Accuracy on validation dataset: 4649/9723 (47.81%)\n",
      "\n",
      "Epoch: 57, Batch number: 14\n",
      "Accuracy on validation dataset: 4651/9723 (47.84%)\n",
      "\n",
      "Epoch: 57, Batch number: 24\n",
      "Accuracy on validation dataset: 4655/9723 (47.88%)\n",
      "\n",
      "Epoch: 57, Batch number: 34\n",
      "Accuracy on validation dataset: 4664/9723 (47.97%)\n",
      "\n",
      "Epoch: 57, Batch number: 44\n",
      "Accuracy on validation dataset: 4673/9723 (48.06%)\n",
      "\n",
      "Epoch: 57, Batch number: 54\n",
      "Accuracy on validation dataset: 4675/9723 (48.08%)\n",
      "\n",
      "Epoch: 57, Batch number: 64\n",
      "Accuracy on validation dataset: 4670/9723 (48.03%)\n",
      "\n",
      "Epoch: 57, Batch number: 74\n",
      "Accuracy on validation dataset: 4675/9723 (48.08%)\n",
      "\n",
      "Epoch: 58, Batch number: 8\n",
      "Accuracy on validation dataset: 4672/9723 (48.05%)\n",
      "\n",
      "Epoch: 58, Batch number: 18\n",
      "Accuracy on validation dataset: 4681/9723 (48.14%)\n",
      "\n",
      "Epoch: 58, Batch number: 28\n",
      "Accuracy on validation dataset: 4692/9723 (48.26%)\n",
      "\n",
      "Epoch: 58, Batch number: 38\n",
      "Accuracy on validation dataset: 4704/9723 (48.38%)\n",
      "\n",
      "Epoch: 58, Batch number: 48\n",
      "Accuracy on validation dataset: 4703/9723 (48.37%)\n",
      "\n",
      "Epoch: 58, Batch number: 58\n",
      "Accuracy on validation dataset: 4708/9723 (48.42%)\n",
      "\n",
      "Epoch: 58, Batch number: 68\n",
      "Accuracy on validation dataset: 4716/9723 (48.50%)\n",
      "\n",
      "Epoch: 59, Batch number: 2\n",
      "Accuracy on validation dataset: 4717/9723 (48.51%)\n",
      "\n",
      "Epoch: 59, Batch number: 12\n",
      "Accuracy on validation dataset: 4728/9723 (48.63%)\n",
      "\n",
      "Epoch: 59, Batch number: 22\n",
      "Accuracy on validation dataset: 4730/9723 (48.65%)\n",
      "\n",
      "Epoch: 59, Batch number: 32\n",
      "Accuracy on validation dataset: 4729/9723 (48.64%)\n",
      "\n",
      "Epoch: 59, Batch number: 42\n",
      "Accuracy on validation dataset: 4734/9723 (48.69%)\n",
      "\n",
      "Epoch: 59, Batch number: 52\n",
      "Accuracy on validation dataset: 4735/9723 (48.70%)\n",
      "\n",
      "Epoch: 59, Batch number: 62\n",
      "Accuracy on validation dataset: 4740/9723 (48.75%)\n",
      "\n",
      "Epoch: 59, Batch number: 72\n",
      "Accuracy on validation dataset: 4746/9723 (48.81%)\n",
      "\n",
      "Epoch: 60, Batch number: 6\n",
      "Accuracy on validation dataset: 4745/9723 (48.80%)\n",
      "\n",
      "Epoch: 60, Batch number: 16\n",
      "Accuracy on validation dataset: 4755/9723 (48.90%)\n",
      "\n",
      "Epoch: 60, Batch number: 26\n",
      "Accuracy on validation dataset: 4763/9723 (48.99%)\n",
      "\n",
      "Epoch: 60, Batch number: 36\n",
      "Accuracy on validation dataset: 4770/9723 (49.06%)\n",
      "\n",
      "Epoch: 60, Batch number: 46\n",
      "Accuracy on validation dataset: 4772/9723 (49.08%)\n",
      "\n",
      "Epoch: 60, Batch number: 56\n",
      "Accuracy on validation dataset: 4775/9723 (49.11%)\n",
      "\n",
      "Epoch: 60, Batch number: 66\n",
      "Accuracy on validation dataset: 4770/9723 (49.06%)\n",
      "\n",
      "Epoch: 61, Batch number: 0\n",
      "Accuracy on validation dataset: 4787/9723 (49.23%)\n",
      "\n",
      "Epoch: 61, Batch number: 10\n",
      "Accuracy on validation dataset: 4787/9723 (49.23%)\n",
      "\n",
      "Epoch: 61, Batch number: 20\n",
      "Accuracy on validation dataset: 4801/9723 (49.38%)\n",
      "\n",
      "Epoch: 61, Batch number: 30\n",
      "Accuracy on validation dataset: 4805/9723 (49.42%)\n",
      "\n",
      "Epoch: 61, Batch number: 40\n",
      "Accuracy on validation dataset: 4811/9723 (49.48%)\n",
      "\n",
      "Epoch: 61, Batch number: 50\n",
      "Accuracy on validation dataset: 4818/9723 (49.55%)\n",
      "\n",
      "Epoch: 61, Batch number: 60\n",
      "Accuracy on validation dataset: 4818/9723 (49.55%)\n",
      "\n",
      "Epoch: 61, Batch number: 70\n",
      "Accuracy on validation dataset: 4819/9723 (49.56%)\n",
      "\n",
      "Epoch: 62, Batch number: 4\n",
      "Accuracy on validation dataset: 4822/9723 (49.59%)\n",
      "\n",
      "Epoch: 62, Batch number: 14\n",
      "Accuracy on validation dataset: 4815/9723 (49.52%)\n",
      "\n",
      "Epoch: 62, Batch number: 24\n",
      "Accuracy on validation dataset: 4818/9723 (49.55%)\n",
      "\n",
      "Epoch: 62, Batch number: 34\n",
      "Accuracy on validation dataset: 4819/9723 (49.56%)\n",
      "\n",
      "Epoch: 62, Batch number: 44\n",
      "Accuracy on validation dataset: 4821/9723 (49.58%)\n",
      "\n",
      "Epoch: 62, Batch number: 54\n",
      "Accuracy on validation dataset: 4829/9723 (49.67%)\n",
      "\n",
      "Epoch: 62, Batch number: 64\n",
      "Accuracy on validation dataset: 4843/9723 (49.81%)\n",
      "\n",
      "Epoch: 62, Batch number: 74\n",
      "Accuracy on validation dataset: 4863/9723 (50.02%)\n",
      "\n",
      "Epoch: 63, Batch number: 8\n",
      "Accuracy on validation dataset: 4865/9723 (50.04%)\n",
      "\n",
      "Epoch: 63, Batch number: 18\n",
      "Accuracy on validation dataset: 4861/9723 (49.99%)\n",
      "\n",
      "Epoch: 63, Batch number: 28\n",
      "Accuracy on validation dataset: 4856/9723 (49.94%)\n",
      "\n",
      "Epoch: 63, Batch number: 38\n",
      "Accuracy on validation dataset: 4857/9723 (49.95%)\n",
      "\n",
      "Epoch: 63, Batch number: 48\n",
      "Accuracy on validation dataset: 4861/9723 (49.99%)\n",
      "\n",
      "Epoch: 63, Batch number: 58\n",
      "Accuracy on validation dataset: 4867/9723 (50.06%)\n",
      "\n",
      "Epoch: 63, Batch number: 68\n",
      "Accuracy on validation dataset: 4879/9723 (50.18%)\n",
      "\n",
      "Epoch: 64, Batch number: 2\n",
      "Accuracy on validation dataset: 4885/9723 (50.24%)\n",
      "\n",
      "Epoch: 64, Batch number: 12\n",
      "Accuracy on validation dataset: 4882/9723 (50.21%)\n",
      "\n",
      "Epoch: 64, Batch number: 22\n",
      "Accuracy on validation dataset: 4884/9723 (50.23%)\n",
      "\n",
      "Epoch: 64, Batch number: 32\n",
      "Accuracy on validation dataset: 4887/9723 (50.26%)\n",
      "\n",
      "Epoch: 64, Batch number: 42\n",
      "Accuracy on validation dataset: 4896/9723 (50.35%)\n",
      "\n",
      "Epoch: 64, Batch number: 52\n",
      "Accuracy on validation dataset: 4897/9723 (50.37%)\n",
      "\n",
      "Epoch: 64, Batch number: 62\n",
      "Accuracy on validation dataset: 4910/9723 (50.50%)\n",
      "\n",
      "Epoch: 64, Batch number: 72\n",
      "Accuracy on validation dataset: 4916/9723 (50.56%)\n",
      "\n",
      "Epoch: 65, Batch number: 6\n",
      "Accuracy on validation dataset: 4913/9723 (50.53%)\n",
      "\n",
      "Epoch: 65, Batch number: 16\n",
      "Accuracy on validation dataset: 4912/9723 (50.52%)\n",
      "\n",
      "Epoch: 65, Batch number: 26\n",
      "Accuracy on validation dataset: 4917/9723 (50.57%)\n",
      "\n",
      "Epoch: 65, Batch number: 36\n",
      "Accuracy on validation dataset: 4929/9723 (50.69%)\n",
      "\n",
      "Epoch: 65, Batch number: 46\n",
      "Accuracy on validation dataset: 4935/9723 (50.76%)\n",
      "\n",
      "Epoch: 65, Batch number: 56\n",
      "Accuracy on validation dataset: 4937/9723 (50.78%)\n",
      "\n",
      "Epoch: 65, Batch number: 66\n",
      "Accuracy on validation dataset: 4936/9723 (50.77%)\n",
      "\n",
      "Epoch: 66, Batch number: 0\n",
      "Accuracy on validation dataset: 4938/9723 (50.79%)\n",
      "\n",
      "Epoch: 66, Batch number: 10\n",
      "Accuracy on validation dataset: 4951/9723 (50.92%)\n",
      "\n",
      "Epoch: 66, Batch number: 20\n",
      "Accuracy on validation dataset: 4956/9723 (50.97%)\n",
      "\n",
      "Epoch: 66, Batch number: 30\n",
      "Accuracy on validation dataset: 4955/9723 (50.96%)\n",
      "\n",
      "Epoch: 66, Batch number: 40\n",
      "Accuracy on validation dataset: 4965/9723 (51.06%)\n",
      "\n",
      "Epoch: 66, Batch number: 50\n",
      "Accuracy on validation dataset: 4965/9723 (51.06%)\n",
      "\n",
      "Epoch: 66, Batch number: 60\n",
      "Accuracy on validation dataset: 4959/9723 (51.00%)\n",
      "\n",
      "Epoch: 66, Batch number: 70\n",
      "Accuracy on validation dataset: 4978/9723 (51.20%)\n",
      "\n",
      "Epoch: 67, Batch number: 4\n",
      "Accuracy on validation dataset: 4974/9723 (51.16%)\n",
      "\n",
      "Epoch: 67, Batch number: 14\n",
      "Accuracy on validation dataset: 4980/9723 (51.22%)\n",
      "\n",
      "Epoch: 67, Batch number: 24\n",
      "Accuracy on validation dataset: 4976/9723 (51.18%)\n",
      "\n",
      "Epoch: 67, Batch number: 34\n",
      "Accuracy on validation dataset: 4980/9723 (51.22%)\n",
      "\n",
      "Epoch: 67, Batch number: 44\n",
      "Accuracy on validation dataset: 4981/9723 (51.23%)\n",
      "\n",
      "Epoch: 67, Batch number: 54\n",
      "Accuracy on validation dataset: 4979/9723 (51.21%)\n",
      "\n",
      "Epoch: 67, Batch number: 64\n",
      "Accuracy on validation dataset: 4992/9723 (51.34%)\n",
      "\n",
      "Epoch: 67, Batch number: 74\n",
      "Accuracy on validation dataset: 4993/9723 (51.35%)\n",
      "\n",
      "Epoch: 68, Batch number: 8\n",
      "Accuracy on validation dataset: 5007/9723 (51.50%)\n",
      "\n",
      "Epoch: 68, Batch number: 18\n",
      "Accuracy on validation dataset: 5009/9723 (51.52%)\n",
      "\n",
      "Epoch: 68, Batch number: 28\n",
      "Accuracy on validation dataset: 5005/9723 (51.48%)\n",
      "\n",
      "Epoch: 68, Batch number: 38\n",
      "Accuracy on validation dataset: 5006/9723 (51.49%)\n",
      "\n",
      "Epoch: 68, Batch number: 48\n",
      "Accuracy on validation dataset: 5011/9723 (51.54%)\n",
      "\n",
      "Epoch: 68, Batch number: 58\n",
      "Accuracy on validation dataset: 5013/9723 (51.56%)\n",
      "\n",
      "Epoch: 68, Batch number: 68\n",
      "Accuracy on validation dataset: 5024/9723 (51.67%)\n",
      "\n",
      "Epoch: 69, Batch number: 2\n",
      "Accuracy on validation dataset: 5024/9723 (51.67%)\n",
      "\n",
      "Epoch: 69, Batch number: 12\n",
      "Accuracy on validation dataset: 5026/9723 (51.69%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Batch number: 22\n",
      "Accuracy on validation dataset: 5029/9723 (51.72%)\n",
      "\n",
      "Epoch: 69, Batch number: 32\n",
      "Accuracy on validation dataset: 5038/9723 (51.82%)\n",
      "\n",
      "Epoch: 69, Batch number: 42\n",
      "Accuracy on validation dataset: 5041/9723 (51.85%)\n",
      "\n",
      "Epoch: 69, Batch number: 52\n",
      "Accuracy on validation dataset: 5041/9723 (51.85%)\n",
      "\n",
      "Epoch: 69, Batch number: 62\n",
      "Accuracy on validation dataset: 5044/9723 (51.88%)\n",
      "\n",
      "Epoch: 69, Batch number: 72\n",
      "Accuracy on validation dataset: 5041/9723 (51.85%)\n",
      "\n",
      "Epoch: 70, Batch number: 6\n",
      "Accuracy on validation dataset: 5053/9723 (51.97%)\n",
      "\n",
      "Epoch: 70, Batch number: 16\n",
      "Accuracy on validation dataset: 5057/9723 (52.01%)\n",
      "\n",
      "Epoch: 70, Batch number: 26\n",
      "Accuracy on validation dataset: 5058/9723 (52.02%)\n",
      "\n",
      "Epoch: 70, Batch number: 36\n",
      "Accuracy on validation dataset: 5052/9723 (51.96%)\n",
      "\n",
      "Epoch: 70, Batch number: 46\n",
      "Accuracy on validation dataset: 5047/9723 (51.91%)\n",
      "\n",
      "Epoch: 70, Batch number: 56\n",
      "Accuracy on validation dataset: 5047/9723 (51.91%)\n",
      "\n",
      "Epoch: 70, Batch number: 66\n",
      "Accuracy on validation dataset: 5052/9723 (51.96%)\n",
      "\n",
      "Epoch: 71, Batch number: 0\n",
      "Accuracy on validation dataset: 5061/9723 (52.05%)\n",
      "\n",
      "Epoch: 71, Batch number: 10\n",
      "Accuracy on validation dataset: 5067/9723 (52.11%)\n",
      "\n",
      "Epoch: 71, Batch number: 20\n",
      "Accuracy on validation dataset: 5068/9723 (52.12%)\n",
      "\n",
      "Epoch: 71, Batch number: 30\n",
      "Accuracy on validation dataset: 5074/9723 (52.19%)\n",
      "\n",
      "Epoch: 71, Batch number: 40\n",
      "Accuracy on validation dataset: 5078/9723 (52.23%)\n",
      "\n",
      "Epoch: 71, Batch number: 50\n",
      "Accuracy on validation dataset: 5078/9723 (52.23%)\n",
      "\n",
      "Epoch: 71, Batch number: 60\n",
      "Accuracy on validation dataset: 5084/9723 (52.29%)\n",
      "\n",
      "Epoch: 71, Batch number: 70\n",
      "Accuracy on validation dataset: 5090/9723 (52.35%)\n",
      "\n",
      "Epoch: 72, Batch number: 4\n",
      "Accuracy on validation dataset: 5088/9723 (52.33%)\n",
      "\n",
      "Epoch: 72, Batch number: 14\n",
      "Accuracy on validation dataset: 5083/9723 (52.28%)\n",
      "\n",
      "Epoch: 72, Batch number: 24\n",
      "Accuracy on validation dataset: 5093/9723 (52.38%)\n",
      "\n",
      "Epoch: 72, Batch number: 34\n",
      "Accuracy on validation dataset: 5098/9723 (52.43%)\n",
      "\n",
      "Epoch: 72, Batch number: 44\n",
      "Accuracy on validation dataset: 5088/9723 (52.33%)\n",
      "\n",
      "Epoch: 72, Batch number: 54\n",
      "Accuracy on validation dataset: 5095/9723 (52.40%)\n",
      "\n",
      "Epoch: 72, Batch number: 64\n",
      "Accuracy on validation dataset: 5099/9723 (52.44%)\n",
      "\n",
      "Epoch: 72, Batch number: 74\n",
      "Accuracy on validation dataset: 5109/9723 (52.55%)\n",
      "\n",
      "Epoch: 73, Batch number: 8\n",
      "Accuracy on validation dataset: 5106/9723 (52.51%)\n",
      "\n",
      "Epoch: 73, Batch number: 18\n",
      "Accuracy on validation dataset: 5120/9723 (52.66%)\n",
      "\n",
      "Epoch: 73, Batch number: 28\n",
      "Accuracy on validation dataset: 5124/9723 (52.70%)\n",
      "\n",
      "Epoch: 73, Batch number: 38\n",
      "Accuracy on validation dataset: 5125/9723 (52.71%)\n",
      "\n",
      "Epoch: 73, Batch number: 48\n",
      "Accuracy on validation dataset: 5127/9723 (52.73%)\n",
      "\n",
      "Epoch: 73, Batch number: 58\n",
      "Accuracy on validation dataset: 5134/9723 (52.80%)\n",
      "\n",
      "Epoch: 73, Batch number: 68\n",
      "Accuracy on validation dataset: 5131/9723 (52.77%)\n",
      "\n",
      "Epoch: 74, Batch number: 2\n",
      "Accuracy on validation dataset: 5132/9723 (52.78%)\n",
      "\n",
      "Epoch: 74, Batch number: 12\n",
      "Accuracy on validation dataset: 5140/9723 (52.86%)\n",
      "\n",
      "Epoch: 74, Batch number: 22\n",
      "Accuracy on validation dataset: 5140/9723 (52.86%)\n",
      "\n",
      "Epoch: 74, Batch number: 32\n",
      "Accuracy on validation dataset: 5145/9723 (52.92%)\n",
      "\n",
      "Epoch: 74, Batch number: 42\n",
      "Accuracy on validation dataset: 5159/9723 (53.06%)\n",
      "\n",
      "Epoch: 74, Batch number: 52\n",
      "Accuracy on validation dataset: 5165/9723 (53.12%)\n",
      "\n",
      "Epoch: 74, Batch number: 62\n",
      "Accuracy on validation dataset: 5165/9723 (53.12%)\n",
      "\n",
      "Epoch: 74, Batch number: 72\n",
      "Accuracy on validation dataset: 5164/9723 (53.11%)\n",
      "\n",
      "Epoch: 75, Batch number: 6\n",
      "Accuracy on validation dataset: 5175/9723 (53.22%)\n",
      "\n",
      "Epoch: 75, Batch number: 16\n",
      "Accuracy on validation dataset: 5170/9723 (53.17%)\n",
      "\n",
      "Epoch: 75, Batch number: 26\n",
      "Accuracy on validation dataset: 5171/9723 (53.18%)\n",
      "\n",
      "Epoch: 75, Batch number: 36\n",
      "Accuracy on validation dataset: 5177/9723 (53.24%)\n",
      "\n",
      "Epoch: 75, Batch number: 46\n",
      "Accuracy on validation dataset: 5194/9723 (53.42%)\n",
      "\n",
      "Epoch: 75, Batch number: 56\n",
      "Accuracy on validation dataset: 5201/9723 (53.49%)\n",
      "\n",
      "Epoch: 75, Batch number: 66\n",
      "Accuracy on validation dataset: 5194/9723 (53.42%)\n",
      "\n",
      "Epoch: 76, Batch number: 0\n",
      "Accuracy on validation dataset: 5201/9723 (53.49%)\n",
      "\n",
      "Epoch: 76, Batch number: 10\n",
      "Accuracy on validation dataset: 5205/9723 (53.53%)\n",
      "\n",
      "Epoch: 76, Batch number: 20\n",
      "Accuracy on validation dataset: 5205/9723 (53.53%)\n",
      "\n",
      "Epoch: 76, Batch number: 30\n",
      "Accuracy on validation dataset: 5199/9723 (53.47%)\n",
      "\n",
      "Epoch: 76, Batch number: 40\n",
      "Accuracy on validation dataset: 5203/9723 (53.51%)\n",
      "\n",
      "Epoch: 76, Batch number: 50\n",
      "Accuracy on validation dataset: 5221/9723 (53.70%)\n",
      "\n",
      "Epoch: 76, Batch number: 60\n",
      "Accuracy on validation dataset: 5211/9723 (53.59%)\n",
      "\n",
      "Epoch: 76, Batch number: 70\n",
      "Accuracy on validation dataset: 5224/9723 (53.73%)\n",
      "\n",
      "Epoch: 77, Batch number: 4\n",
      "Accuracy on validation dataset: 5224/9723 (53.73%)\n",
      "\n",
      "Epoch: 77, Batch number: 14\n",
      "Accuracy on validation dataset: 5229/9723 (53.78%)\n",
      "\n",
      "Epoch: 77, Batch number: 24\n",
      "Accuracy on validation dataset: 5228/9723 (53.77%)\n",
      "\n",
      "Epoch: 77, Batch number: 34\n",
      "Accuracy on validation dataset: 5225/9723 (53.74%)\n",
      "\n",
      "Epoch: 77, Batch number: 44\n",
      "Accuracy on validation dataset: 5234/9723 (53.83%)\n",
      "\n",
      "Epoch: 77, Batch number: 54\n",
      "Accuracy on validation dataset: 5233/9723 (53.82%)\n",
      "\n",
      "Epoch: 77, Batch number: 64\n",
      "Accuracy on validation dataset: 5246/9723 (53.95%)\n",
      "\n",
      "Epoch: 77, Batch number: 74\n",
      "Accuracy on validation dataset: 5256/9723 (54.06%)\n",
      "\n",
      "Epoch: 78, Batch number: 8\n",
      "Accuracy on validation dataset: 5256/9723 (54.06%)\n",
      "\n",
      "Epoch: 78, Batch number: 18\n",
      "Accuracy on validation dataset: 5264/9723 (54.14%)\n",
      "\n",
      "Epoch: 78, Batch number: 28\n",
      "Accuracy on validation dataset: 5266/9723 (54.16%)\n",
      "\n",
      "Epoch: 78, Batch number: 38\n",
      "Accuracy on validation dataset: 5257/9723 (54.07%)\n",
      "\n",
      "Epoch: 78, Batch number: 48\n",
      "Accuracy on validation dataset: 5263/9723 (54.13%)\n",
      "\n",
      "Epoch: 78, Batch number: 58\n",
      "Accuracy on validation dataset: 5268/9723 (54.18%)\n",
      "\n",
      "Epoch: 78, Batch number: 68\n",
      "Accuracy on validation dataset: 5276/9723 (54.26%)\n",
      "\n",
      "Epoch: 79, Batch number: 2\n",
      "Accuracy on validation dataset: 5275/9723 (54.25%)\n",
      "\n",
      "Epoch: 79, Batch number: 12\n",
      "Accuracy on validation dataset: 5284/9723 (54.35%)\n",
      "\n",
      "Epoch: 79, Batch number: 22\n",
      "Accuracy on validation dataset: 5298/9723 (54.49%)\n",
      "\n",
      "Epoch: 79, Batch number: 32\n",
      "Accuracy on validation dataset: 5292/9723 (54.43%)\n",
      "\n",
      "Epoch: 79, Batch number: 42\n",
      "Accuracy on validation dataset: 5291/9723 (54.42%)\n",
      "\n",
      "Epoch: 79, Batch number: 52\n",
      "Accuracy on validation dataset: 5292/9723 (54.43%)\n",
      "\n",
      "Epoch: 79, Batch number: 62\n",
      "Accuracy on validation dataset: 5284/9723 (54.35%)\n",
      "\n",
      "Epoch: 79, Batch number: 72\n",
      "Accuracy on validation dataset: 5297/9723 (54.48%)\n",
      "\n",
      "Epoch: 80, Batch number: 6\n",
      "Accuracy on validation dataset: 5302/9723 (54.53%)\n",
      "\n",
      "Epoch: 80, Batch number: 16\n",
      "Accuracy on validation dataset: 5299/9723 (54.50%)\n",
      "\n",
      "Epoch: 80, Batch number: 26\n",
      "Accuracy on validation dataset: 5306/9723 (54.57%)\n",
      "\n",
      "Epoch: 80, Batch number: 36\n",
      "Accuracy on validation dataset: 5314/9723 (54.65%)\n",
      "\n",
      "Epoch: 80, Batch number: 46\n",
      "Accuracy on validation dataset: 5320/9723 (54.72%)\n",
      "\n",
      "Epoch: 80, Batch number: 56\n",
      "Accuracy on validation dataset: 5324/9723 (54.76%)\n",
      "\n",
      "Epoch: 80, Batch number: 66\n",
      "Accuracy on validation dataset: 5325/9723 (54.77%)\n",
      "\n",
      "Epoch: 81, Batch number: 0\n",
      "Accuracy on validation dataset: 5332/9723 (54.84%)\n",
      "\n",
      "Epoch: 81, Batch number: 10\n",
      "Accuracy on validation dataset: 5325/9723 (54.77%)\n",
      "\n",
      "Epoch: 81, Batch number: 20\n",
      "Accuracy on validation dataset: 5326/9723 (54.78%)\n",
      "\n",
      "Epoch: 81, Batch number: 30\n",
      "Accuracy on validation dataset: 5338/9723 (54.90%)\n",
      "\n",
      "Epoch: 81, Batch number: 40\n",
      "Accuracy on validation dataset: 5341/9723 (54.93%)\n",
      "\n",
      "Epoch: 81, Batch number: 50\n",
      "Accuracy on validation dataset: 5337/9723 (54.89%)\n",
      "\n",
      "Epoch: 81, Batch number: 60\n",
      "Accuracy on validation dataset: 5337/9723 (54.89%)\n",
      "\n",
      "Epoch: 81, Batch number: 70\n",
      "Accuracy on validation dataset: 5340/9723 (54.92%)\n",
      "\n",
      "Epoch: 82, Batch number: 4\n",
      "Accuracy on validation dataset: 5349/9723 (55.01%)\n",
      "\n",
      "Epoch: 82, Batch number: 14\n",
      "Accuracy on validation dataset: 5360/9723 (55.13%)\n",
      "\n",
      "Epoch: 82, Batch number: 24\n",
      "Accuracy on validation dataset: 5359/9723 (55.12%)\n",
      "\n",
      "Epoch: 82, Batch number: 34\n",
      "Accuracy on validation dataset: 5363/9723 (55.16%)\n",
      "\n",
      "Epoch: 82, Batch number: 44\n",
      "Accuracy on validation dataset: 5367/9723 (55.20%)\n",
      "\n",
      "Epoch: 82, Batch number: 54\n",
      "Accuracy on validation dataset: 5366/9723 (55.19%)\n",
      "\n",
      "Epoch: 82, Batch number: 64\n",
      "Accuracy on validation dataset: 5371/9723 (55.24%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82, Batch number: 74\n",
      "Accuracy on validation dataset: 5377/9723 (55.30%)\n",
      "\n",
      "Epoch: 83, Batch number: 8\n",
      "Accuracy on validation dataset: 5381/9723 (55.34%)\n",
      "\n",
      "Epoch: 83, Batch number: 18\n",
      "Accuracy on validation dataset: 5384/9723 (55.37%)\n",
      "\n",
      "Epoch: 83, Batch number: 28\n",
      "Accuracy on validation dataset: 5381/9723 (55.34%)\n",
      "\n",
      "Epoch: 83, Batch number: 38\n",
      "Accuracy on validation dataset: 5377/9723 (55.30%)\n",
      "\n",
      "Epoch: 83, Batch number: 48\n",
      "Accuracy on validation dataset: 5375/9723 (55.28%)\n",
      "\n",
      "Epoch: 83, Batch number: 58\n",
      "Accuracy on validation dataset: 5381/9723 (55.34%)\n",
      "\n",
      "Epoch: 83, Batch number: 68\n",
      "Accuracy on validation dataset: 5382/9723 (55.35%)\n",
      "\n",
      "Epoch: 84, Batch number: 2\n",
      "Accuracy on validation dataset: 5397/9723 (55.51%)\n",
      "\n",
      "Epoch: 84, Batch number: 12\n",
      "Accuracy on validation dataset: 5396/9723 (55.50%)\n",
      "\n",
      "Epoch: 84, Batch number: 22\n",
      "Accuracy on validation dataset: 5402/9723 (55.56%)\n",
      "\n",
      "Epoch: 84, Batch number: 32\n",
      "Accuracy on validation dataset: 5399/9723 (55.53%)\n",
      "\n",
      "Epoch: 84, Batch number: 42\n",
      "Accuracy on validation dataset: 5400/9723 (55.54%)\n",
      "\n",
      "Epoch: 84, Batch number: 52\n",
      "Accuracy on validation dataset: 5402/9723 (55.56%)\n",
      "\n",
      "Epoch: 84, Batch number: 62\n",
      "Accuracy on validation dataset: 5407/9723 (55.61%)\n",
      "\n",
      "Epoch: 84, Batch number: 72\n",
      "Accuracy on validation dataset: 5416/9723 (55.70%)\n",
      "\n",
      "Epoch: 85, Batch number: 6\n",
      "Accuracy on validation dataset: 5416/9723 (55.70%)\n",
      "\n",
      "Epoch: 85, Batch number: 16\n",
      "Accuracy on validation dataset: 5414/9723 (55.68%)\n",
      "\n",
      "Epoch: 85, Batch number: 26\n",
      "Accuracy on validation dataset: 5425/9723 (55.80%)\n",
      "\n",
      "Epoch: 85, Batch number: 36\n",
      "Accuracy on validation dataset: 5427/9723 (55.82%)\n",
      "\n",
      "Epoch: 85, Batch number: 46\n",
      "Accuracy on validation dataset: 5426/9723 (55.81%)\n",
      "\n",
      "Epoch: 85, Batch number: 56\n",
      "Accuracy on validation dataset: 5430/9723 (55.85%)\n",
      "\n",
      "Epoch: 85, Batch number: 66\n",
      "Accuracy on validation dataset: 5427/9723 (55.82%)\n",
      "\n",
      "Epoch: 86, Batch number: 0\n",
      "Accuracy on validation dataset: 5428/9723 (55.83%)\n",
      "\n",
      "Epoch: 86, Batch number: 10\n",
      "Accuracy on validation dataset: 5440/9723 (55.95%)\n",
      "\n",
      "Epoch: 86, Batch number: 20\n",
      "Accuracy on validation dataset: 5433/9723 (55.88%)\n",
      "\n",
      "Epoch: 86, Batch number: 30\n",
      "Accuracy on validation dataset: 5442/9723 (55.97%)\n",
      "\n",
      "Epoch: 86, Batch number: 40\n",
      "Accuracy on validation dataset: 5445/9723 (56.00%)\n",
      "\n",
      "Epoch: 86, Batch number: 50\n",
      "Accuracy on validation dataset: 5447/9723 (56.02%)\n",
      "\n",
      "Epoch: 86, Batch number: 60\n",
      "Accuracy on validation dataset: 5449/9723 (56.04%)\n",
      "\n",
      "Epoch: 86, Batch number: 70\n",
      "Accuracy on validation dataset: 5459/9723 (56.15%)\n",
      "\n",
      "Epoch: 87, Batch number: 4\n",
      "Accuracy on validation dataset: 5460/9723 (56.16%)\n",
      "\n",
      "Epoch: 87, Batch number: 14\n",
      "Accuracy on validation dataset: 5475/9723 (56.31%)\n",
      "\n",
      "Epoch: 87, Batch number: 24\n",
      "Accuracy on validation dataset: 5466/9723 (56.22%)\n",
      "\n",
      "Epoch: 87, Batch number: 34\n",
      "Accuracy on validation dataset: 5464/9723 (56.20%)\n",
      "\n",
      "Epoch: 87, Batch number: 44\n",
      "Accuracy on validation dataset: 5457/9723 (56.12%)\n",
      "\n",
      "Epoch: 87, Batch number: 54\n",
      "Accuracy on validation dataset: 5454/9723 (56.09%)\n",
      "\n",
      "Epoch: 87, Batch number: 64\n",
      "Accuracy on validation dataset: 5462/9723 (56.18%)\n",
      "\n",
      "Epoch: 87, Batch number: 74\n",
      "Accuracy on validation dataset: 5465/9723 (56.21%)\n",
      "\n",
      "Epoch: 88, Batch number: 8\n",
      "Accuracy on validation dataset: 5470/9723 (56.26%)\n",
      "\n",
      "Epoch: 88, Batch number: 18\n",
      "Accuracy on validation dataset: 5469/9723 (56.25%)\n",
      "\n",
      "Epoch: 88, Batch number: 28\n",
      "Accuracy on validation dataset: 5469/9723 (56.25%)\n",
      "\n",
      "Epoch: 88, Batch number: 38\n",
      "Accuracy on validation dataset: 5477/9723 (56.33%)\n",
      "\n",
      "Epoch: 88, Batch number: 48\n",
      "Accuracy on validation dataset: 5481/9723 (56.37%)\n",
      "\n",
      "Epoch: 88, Batch number: 58\n",
      "Accuracy on validation dataset: 5487/9723 (56.43%)\n",
      "\n",
      "Epoch: 88, Batch number: 68\n",
      "Accuracy on validation dataset: 5486/9723 (56.42%)\n",
      "\n",
      "Epoch: 89, Batch number: 2\n",
      "Accuracy on validation dataset: 5490/9723 (56.46%)\n",
      "\n",
      "Epoch: 89, Batch number: 12\n",
      "Accuracy on validation dataset: 5499/9723 (56.56%)\n",
      "\n",
      "Epoch: 89, Batch number: 22\n",
      "Accuracy on validation dataset: 5499/9723 (56.56%)\n",
      "\n",
      "Epoch: 89, Batch number: 32\n",
      "Accuracy on validation dataset: 5503/9723 (56.60%)\n",
      "\n",
      "Epoch: 89, Batch number: 42\n",
      "Accuracy on validation dataset: 5496/9723 (56.53%)\n",
      "\n",
      "Epoch: 89, Batch number: 52\n",
      "Accuracy on validation dataset: 5503/9723 (56.60%)\n",
      "\n",
      "Epoch: 89, Batch number: 62\n",
      "Accuracy on validation dataset: 5495/9723 (56.52%)\n",
      "\n",
      "Epoch: 89, Batch number: 72\n",
      "Accuracy on validation dataset: 5501/9723 (56.58%)\n",
      "\n",
      "Epoch: 90, Batch number: 6\n",
      "Accuracy on validation dataset: 5499/9723 (56.56%)\n",
      "\n",
      "Epoch: 90, Batch number: 16\n",
      "Accuracy on validation dataset: 5497/9723 (56.54%)\n",
      "\n",
      "Epoch: 90, Batch number: 26\n",
      "Accuracy on validation dataset: 5502/9723 (56.59%)\n",
      "\n",
      "Epoch: 90, Batch number: 36\n",
      "Accuracy on validation dataset: 5507/9723 (56.64%)\n",
      "\n",
      "Epoch: 90, Batch number: 46\n",
      "Accuracy on validation dataset: 5507/9723 (56.64%)\n",
      "\n",
      "Epoch: 90, Batch number: 56\n",
      "Accuracy on validation dataset: 5512/9723 (56.69%)\n",
      "\n",
      "Epoch: 90, Batch number: 66\n",
      "Accuracy on validation dataset: 5512/9723 (56.69%)\n",
      "\n",
      "Epoch: 91, Batch number: 0\n",
      "Accuracy on validation dataset: 5522/9723 (56.79%)\n",
      "\n",
      "Epoch: 91, Batch number: 10\n",
      "Accuracy on validation dataset: 5526/9723 (56.83%)\n",
      "\n",
      "Epoch: 91, Batch number: 20\n",
      "Accuracy on validation dataset: 5527/9723 (56.84%)\n",
      "\n",
      "Epoch: 91, Batch number: 30\n",
      "Accuracy on validation dataset: 5537/9723 (56.95%)\n",
      "\n",
      "Epoch: 91, Batch number: 40\n",
      "Accuracy on validation dataset: 5527/9723 (56.84%)\n",
      "\n",
      "Epoch: 91, Batch number: 50\n",
      "Accuracy on validation dataset: 5527/9723 (56.84%)\n",
      "\n",
      "Epoch: 91, Batch number: 60\n",
      "Accuracy on validation dataset: 5535/9723 (56.93%)\n",
      "\n",
      "Epoch: 91, Batch number: 70\n",
      "Accuracy on validation dataset: 5541/9723 (56.99%)\n",
      "\n",
      "Epoch: 92, Batch number: 4\n",
      "Accuracy on validation dataset: 5546/9723 (57.04%)\n",
      "\n",
      "Epoch: 92, Batch number: 14\n",
      "Accuracy on validation dataset: 5549/9723 (57.07%)\n",
      "\n",
      "Epoch: 92, Batch number: 24\n",
      "Accuracy on validation dataset: 5549/9723 (57.07%)\n",
      "\n",
      "Epoch: 92, Batch number: 34\n",
      "Accuracy on validation dataset: 5554/9723 (57.12%)\n",
      "\n",
      "Epoch: 92, Batch number: 44\n",
      "Accuracy on validation dataset: 5551/9723 (57.09%)\n",
      "\n",
      "Epoch: 92, Batch number: 54\n",
      "Accuracy on validation dataset: 5556/9723 (57.14%)\n",
      "\n",
      "Epoch: 92, Batch number: 64\n",
      "Accuracy on validation dataset: 5556/9723 (57.14%)\n",
      "\n",
      "Epoch: 92, Batch number: 74\n",
      "Accuracy on validation dataset: 5553/9723 (57.11%)\n",
      "\n",
      "Epoch: 93, Batch number: 8\n",
      "Accuracy on validation dataset: 5553/9723 (57.11%)\n",
      "\n",
      "Epoch: 93, Batch number: 18\n",
      "Accuracy on validation dataset: 5558/9723 (57.16%)\n",
      "\n",
      "Epoch: 93, Batch number: 28\n",
      "Accuracy on validation dataset: 5568/9723 (57.27%)\n",
      "\n",
      "Epoch: 93, Batch number: 38\n",
      "Accuracy on validation dataset: 5567/9723 (57.26%)\n",
      "\n",
      "Epoch: 93, Batch number: 48\n",
      "Accuracy on validation dataset: 5563/9723 (57.21%)\n",
      "\n",
      "Epoch: 93, Batch number: 58\n",
      "Accuracy on validation dataset: 5566/9723 (57.25%)\n",
      "\n",
      "Epoch: 93, Batch number: 68\n",
      "Accuracy on validation dataset: 5574/9723 (57.33%)\n",
      "\n",
      "Epoch: 94, Batch number: 2\n",
      "Accuracy on validation dataset: 5575/9723 (57.34%)\n",
      "\n",
      "Epoch: 94, Batch number: 12\n",
      "Accuracy on validation dataset: 5577/9723 (57.36%)\n",
      "\n",
      "Epoch: 94, Batch number: 22\n",
      "Accuracy on validation dataset: 5578/9723 (57.37%)\n",
      "\n",
      "Epoch: 94, Batch number: 32\n",
      "Accuracy on validation dataset: 5580/9723 (57.39%)\n",
      "\n",
      "Epoch: 94, Batch number: 42\n",
      "Accuracy on validation dataset: 5583/9723 (57.42%)\n",
      "\n",
      "Epoch: 94, Batch number: 52\n",
      "Accuracy on validation dataset: 5580/9723 (57.39%)\n",
      "\n",
      "Epoch: 94, Batch number: 62\n",
      "Accuracy on validation dataset: 5580/9723 (57.39%)\n",
      "\n",
      "Epoch: 94, Batch number: 72\n",
      "Accuracy on validation dataset: 5584/9723 (57.43%)\n",
      "\n",
      "Epoch: 95, Batch number: 6\n",
      "Accuracy on validation dataset: 5581/9723 (57.40%)\n",
      "\n",
      "Epoch: 95, Batch number: 16\n",
      "Accuracy on validation dataset: 5575/9723 (57.34%)\n",
      "\n",
      "Epoch: 95, Batch number: 26\n",
      "Accuracy on validation dataset: 5578/9723 (57.37%)\n",
      "\n",
      "Epoch: 95, Batch number: 36\n",
      "Accuracy on validation dataset: 5576/9723 (57.35%)\n",
      "\n",
      "Epoch: 95, Batch number: 46\n",
      "Accuracy on validation dataset: 5585/9723 (57.44%)\n",
      "\n",
      "Epoch: 95, Batch number: 56\n",
      "Accuracy on validation dataset: 5594/9723 (57.53%)\n",
      "\n",
      "Epoch: 95, Batch number: 66\n",
      "Accuracy on validation dataset: 5595/9723 (57.54%)\n",
      "\n",
      "Epoch: 96, Batch number: 0\n",
      "Accuracy on validation dataset: 5596/9723 (57.55%)\n",
      "\n",
      "Epoch: 96, Batch number: 10\n",
      "Accuracy on validation dataset: 5592/9723 (57.51%)\n",
      "\n",
      "Epoch: 96, Batch number: 20\n",
      "Accuracy on validation dataset: 5595/9723 (57.54%)\n",
      "\n",
      "Epoch: 96, Batch number: 30\n",
      "Accuracy on validation dataset: 5604/9723 (57.64%)\n",
      "\n",
      "Epoch: 96, Batch number: 40\n",
      "Accuracy on validation dataset: 5595/9723 (57.54%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, Batch number: 50\n",
      "Accuracy on validation dataset: 5592/9723 (57.51%)\n",
      "\n",
      "Epoch: 96, Batch number: 60\n",
      "Accuracy on validation dataset: 5603/9723 (57.63%)\n",
      "\n",
      "Epoch: 96, Batch number: 70\n",
      "Accuracy on validation dataset: 5607/9723 (57.67%)\n",
      "\n",
      "Epoch: 97, Batch number: 4\n",
      "Accuracy on validation dataset: 5607/9723 (57.67%)\n",
      "\n",
      "Epoch: 97, Batch number: 14\n",
      "Accuracy on validation dataset: 5609/9723 (57.69%)\n",
      "\n",
      "Epoch: 97, Batch number: 24\n",
      "Accuracy on validation dataset: 5609/9723 (57.69%)\n",
      "\n",
      "Epoch: 97, Batch number: 34\n",
      "Accuracy on validation dataset: 5612/9723 (57.72%)\n",
      "\n",
      "Epoch: 97, Batch number: 44\n",
      "Accuracy on validation dataset: 5608/9723 (57.68%)\n",
      "\n",
      "Epoch: 97, Batch number: 54\n",
      "Accuracy on validation dataset: 5608/9723 (57.68%)\n",
      "\n",
      "Epoch: 97, Batch number: 64\n",
      "Accuracy on validation dataset: 5615/9723 (57.75%)\n",
      "\n",
      "Epoch: 97, Batch number: 74\n",
      "Accuracy on validation dataset: 5620/9723 (57.80%)\n",
      "\n",
      "Epoch: 98, Batch number: 8\n",
      "Accuracy on validation dataset: 5636/9723 (57.97%)\n",
      "\n",
      "Epoch: 98, Batch number: 18\n",
      "Accuracy on validation dataset: 5638/9723 (57.99%)\n",
      "\n",
      "Epoch: 98, Batch number: 28\n",
      "Accuracy on validation dataset: 5635/9723 (57.96%)\n",
      "\n",
      "Epoch: 98, Batch number: 38\n",
      "Accuracy on validation dataset: 5630/9723 (57.90%)\n",
      "\n",
      "Epoch: 98, Batch number: 48\n",
      "Accuracy on validation dataset: 5633/9723 (57.93%)\n",
      "\n",
      "Epoch: 98, Batch number: 58\n",
      "Accuracy on validation dataset: 5635/9723 (57.96%)\n",
      "\n",
      "Epoch: 98, Batch number: 68\n",
      "Accuracy on validation dataset: 5639/9723 (58.00%)\n",
      "\n",
      "Epoch: 99, Batch number: 2\n",
      "Accuracy on validation dataset: 5643/9723 (58.04%)\n",
      "\n",
      "Epoch: 99, Batch number: 12\n",
      "Accuracy on validation dataset: 5638/9723 (57.99%)\n",
      "\n",
      "Epoch: 99, Batch number: 22\n",
      "Accuracy on validation dataset: 5637/9723 (57.98%)\n",
      "\n",
      "Epoch: 99, Batch number: 32\n",
      "Accuracy on validation dataset: 5640/9723 (58.01%)\n",
      "\n",
      "Epoch: 99, Batch number: 42\n",
      "Accuracy on validation dataset: 5643/9723 (58.04%)\n",
      "\n",
      "Epoch: 99, Batch number: 52\n",
      "Accuracy on validation dataset: 5640/9723 (58.01%)\n",
      "\n",
      "Epoch: 99, Batch number: 62\n",
      "Accuracy on validation dataset: 5642/9723 (58.03%)\n",
      "\n",
      "Epoch: 99, Batch number: 72\n",
      "Accuracy on validation dataset: 5646/9723 (58.07%)\n",
      "\n",
      "Epoch: 100, Batch number: 6\n",
      "Accuracy on validation dataset: 5650/9723 (58.11%)\n",
      "\n",
      "Epoch: 100, Batch number: 16\n",
      "Accuracy on validation dataset: 5655/9723 (58.16%)\n",
      "\n",
      "Epoch: 100, Batch number: 26\n",
      "Accuracy on validation dataset: 5654/9723 (58.15%)\n",
      "\n",
      "Epoch: 100, Batch number: 36\n",
      "Accuracy on validation dataset: 5650/9723 (58.11%)\n",
      "\n",
      "Epoch: 100, Batch number: 46\n",
      "Accuracy on validation dataset: 5638/9723 (57.99%)\n",
      "\n",
      "Epoch: 100, Batch number: 56\n",
      "Accuracy on validation dataset: 5640/9723 (58.01%)\n",
      "\n",
      "Epoch: 100, Batch number: 66\n",
      "Accuracy on validation dataset: 5655/9723 (58.16%)\n",
      "\n",
      "Epoch: 101, Batch number: 0\n",
      "Accuracy on validation dataset: 5655/9723 (58.16%)\n",
      "\n",
      "Epoch: 101, Batch number: 10\n",
      "Accuracy on validation dataset: 5648/9723 (58.09%)\n",
      "\n",
      "Epoch: 101, Batch number: 20\n",
      "Accuracy on validation dataset: 5653/9723 (58.14%)\n",
      "\n",
      "Epoch: 101, Batch number: 30\n",
      "Accuracy on validation dataset: 5650/9723 (58.11%)\n",
      "\n",
      "Epoch: 101, Batch number: 40\n",
      "Accuracy on validation dataset: 5650/9723 (58.11%)\n",
      "\n",
      "Epoch: 101, Batch number: 50\n",
      "Accuracy on validation dataset: 5655/9723 (58.16%)\n",
      "\n",
      "Epoch: 101, Batch number: 60\n",
      "Accuracy on validation dataset: 5654/9723 (58.15%)\n",
      "\n",
      "Epoch: 101, Batch number: 70\n",
      "Accuracy on validation dataset: 5659/9723 (58.20%)\n",
      "\n",
      "Epoch: 102, Batch number: 4\n",
      "Accuracy on validation dataset: 5655/9723 (58.16%)\n",
      "\n",
      "Epoch: 102, Batch number: 14\n",
      "Accuracy on validation dataset: 5656/9723 (58.17%)\n",
      "\n",
      "Epoch: 102, Batch number: 24\n",
      "Accuracy on validation dataset: 5665/9723 (58.26%)\n",
      "\n",
      "Epoch: 102, Batch number: 34\n",
      "Accuracy on validation dataset: 5663/9723 (58.24%)\n",
      "\n",
      "Epoch: 102, Batch number: 44\n",
      "Accuracy on validation dataset: 5663/9723 (58.24%)\n",
      "\n",
      "Epoch: 102, Batch number: 54\n",
      "Accuracy on validation dataset: 5664/9723 (58.25%)\n",
      "\n",
      "Epoch: 102, Batch number: 64\n",
      "Accuracy on validation dataset: 5672/9723 (58.34%)\n",
      "\n",
      "Epoch: 102, Batch number: 74\n",
      "Accuracy on validation dataset: 5675/9723 (58.37%)\n",
      "\n",
      "Epoch: 103, Batch number: 8\n",
      "Accuracy on validation dataset: 5664/9723 (58.25%)\n",
      "\n",
      "Epoch: 103, Batch number: 18\n",
      "Accuracy on validation dataset: 5676/9723 (58.38%)\n",
      "\n",
      "Epoch: 103, Batch number: 28\n",
      "Accuracy on validation dataset: 5671/9723 (58.33%)\n",
      "\n",
      "Epoch: 103, Batch number: 38\n",
      "Accuracy on validation dataset: 5667/9723 (58.28%)\n",
      "\n",
      "Epoch: 103, Batch number: 48\n",
      "Accuracy on validation dataset: 5660/9723 (58.21%)\n",
      "\n",
      "Epoch: 103, Batch number: 58\n",
      "Accuracy on validation dataset: 5660/9723 (58.21%)\n",
      "\n",
      "Epoch: 103, Batch number: 68\n",
      "Accuracy on validation dataset: 5671/9723 (58.33%)\n",
      "\n",
      "Epoch: 104, Batch number: 2\n",
      "Accuracy on validation dataset: 5674/9723 (58.36%)\n",
      "\n",
      "Epoch: 104, Batch number: 12\n",
      "Accuracy on validation dataset: 5676/9723 (58.38%)\n",
      "\n",
      "Epoch: 104, Batch number: 22\n",
      "Accuracy on validation dataset: 5676/9723 (58.38%)\n",
      "\n",
      "Epoch: 104, Batch number: 32\n",
      "Accuracy on validation dataset: 5674/9723 (58.36%)\n",
      "\n",
      "Epoch: 104, Batch number: 42\n",
      "Accuracy on validation dataset: 5674/9723 (58.36%)\n",
      "\n",
      "Epoch: 104, Batch number: 52\n",
      "Accuracy on validation dataset: 5680/9723 (58.42%)\n",
      "\n",
      "Epoch: 104, Batch number: 62\n",
      "Accuracy on validation dataset: 5685/9723 (58.47%)\n",
      "\n",
      "Epoch: 104, Batch number: 72\n",
      "Accuracy on validation dataset: 5681/9723 (58.43%)\n",
      "\n",
      "Epoch: 105, Batch number: 6\n",
      "Accuracy on validation dataset: 5680/9723 (58.42%)\n",
      "\n",
      "Epoch: 105, Batch number: 16\n",
      "Accuracy on validation dataset: 5678/9723 (58.40%)\n",
      "\n",
      "Epoch: 105, Batch number: 26\n",
      "Accuracy on validation dataset: 5677/9723 (58.39%)\n",
      "\n",
      "Epoch: 105, Batch number: 36\n",
      "Accuracy on validation dataset: 5683/9723 (58.45%)\n",
      "\n",
      "Epoch: 105, Batch number: 46\n",
      "Accuracy on validation dataset: 5684/9723 (58.46%)\n",
      "\n",
      "Epoch: 105, Batch number: 56\n",
      "Accuracy on validation dataset: 5681/9723 (58.43%)\n",
      "\n",
      "Epoch: 105, Batch number: 66\n",
      "Accuracy on validation dataset: 5688/9723 (58.50%)\n",
      "\n",
      "Epoch: 106, Batch number: 0\n",
      "Accuracy on validation dataset: 5690/9723 (58.52%)\n",
      "\n",
      "Epoch: 106, Batch number: 10\n",
      "Accuracy on validation dataset: 5681/9723 (58.43%)\n",
      "\n",
      "Epoch: 106, Batch number: 20\n",
      "Accuracy on validation dataset: 5677/9723 (58.39%)\n",
      "\n",
      "Epoch: 106, Batch number: 30\n",
      "Accuracy on validation dataset: 5679/9723 (58.41%)\n",
      "\n",
      "Epoch: 106, Batch number: 40\n",
      "Accuracy on validation dataset: 5683/9723 (58.45%)\n",
      "\n",
      "Epoch: 106, Batch number: 50\n",
      "Accuracy on validation dataset: 5686/9723 (58.48%)\n",
      "\n",
      "Epoch: 106, Batch number: 60\n",
      "Accuracy on validation dataset: 5695/9723 (58.57%)\n",
      "\n",
      "Epoch: 106, Batch number: 70\n",
      "Accuracy on validation dataset: 5694/9723 (58.56%)\n",
      "\n",
      "Epoch: 107, Batch number: 4\n",
      "Accuracy on validation dataset: 5703/9723 (58.65%)\n",
      "\n",
      "Epoch: 107, Batch number: 14\n",
      "Accuracy on validation dataset: 5691/9723 (58.53%)\n",
      "\n",
      "Epoch: 107, Batch number: 24\n",
      "Accuracy on validation dataset: 5697/9723 (58.59%)\n",
      "\n",
      "Epoch: 107, Batch number: 34\n",
      "Accuracy on validation dataset: 5697/9723 (58.59%)\n",
      "\n",
      "Epoch: 107, Batch number: 44\n",
      "Accuracy on validation dataset: 5692/9723 (58.54%)\n",
      "\n",
      "Epoch: 107, Batch number: 54\n",
      "Accuracy on validation dataset: 5694/9723 (58.56%)\n",
      "\n",
      "Epoch: 107, Batch number: 64\n",
      "Accuracy on validation dataset: 5705/9723 (58.68%)\n",
      "\n",
      "Epoch: 107, Batch number: 74\n",
      "Accuracy on validation dataset: 5705/9723 (58.68%)\n",
      "\n",
      "Epoch: 108, Batch number: 8\n",
      "Accuracy on validation dataset: 5702/9723 (58.64%)\n",
      "\n",
      "Epoch: 108, Batch number: 18\n",
      "Accuracy on validation dataset: 5703/9723 (58.65%)\n",
      "\n",
      "Epoch: 108, Batch number: 28\n",
      "Accuracy on validation dataset: 5703/9723 (58.65%)\n",
      "\n",
      "Epoch: 108, Batch number: 38\n",
      "Accuracy on validation dataset: 5703/9723 (58.65%)\n",
      "\n",
      "Epoch: 108, Batch number: 48\n",
      "Accuracy on validation dataset: 5711/9723 (58.74%)\n",
      "\n",
      "Epoch: 108, Batch number: 58\n",
      "Accuracy on validation dataset: 5714/9723 (58.77%)\n",
      "\n",
      "Epoch: 108, Batch number: 68\n",
      "Accuracy on validation dataset: 5711/9723 (58.74%)\n",
      "\n",
      "Epoch: 109, Batch number: 2\n",
      "Accuracy on validation dataset: 5707/9723 (58.70%)\n",
      "\n",
      "Epoch: 109, Batch number: 12\n",
      "Accuracy on validation dataset: 5715/9723 (58.78%)\n",
      "\n",
      "Epoch: 109, Batch number: 22\n",
      "Accuracy on validation dataset: 5717/9723 (58.80%)\n",
      "\n",
      "Epoch: 109, Batch number: 32\n",
      "Accuracy on validation dataset: 5708/9723 (58.71%)\n",
      "\n",
      "Epoch: 109, Batch number: 42\n",
      "Accuracy on validation dataset: 5710/9723 (58.73%)\n",
      "\n",
      "Epoch: 109, Batch number: 52\n",
      "Accuracy on validation dataset: 5707/9723 (58.70%)\n",
      "\n",
      "Epoch: 109, Batch number: 62\n",
      "Accuracy on validation dataset: 5714/9723 (58.77%)\n",
      "\n",
      "Epoch: 109, Batch number: 72\n",
      "Accuracy on validation dataset: 5713/9723 (58.76%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 6\n",
      "Accuracy on validation dataset: 5716/9723 (58.79%)\n",
      "\n",
      "Epoch: 110, Batch number: 16\n",
      "Accuracy on validation dataset: 5718/9723 (58.81%)\n",
      "\n",
      "Epoch: 110, Batch number: 26\n",
      "Accuracy on validation dataset: 5713/9723 (58.76%)\n",
      "\n",
      "Epoch: 110, Batch number: 36\n",
      "Accuracy on validation dataset: 5719/9723 (58.82%)\n",
      "\n",
      "Epoch: 110, Batch number: 46\n",
      "Accuracy on validation dataset: 5715/9723 (58.78%)\n",
      "\n",
      "Epoch: 110, Batch number: 56\n",
      "Accuracy on validation dataset: 5721/9723 (58.84%)\n",
      "\n",
      "Epoch: 110, Batch number: 66\n",
      "Accuracy on validation dataset: 5734/9723 (58.97%)\n",
      "\n",
      "Epoch: 111, Batch number: 0\n",
      "Accuracy on validation dataset: 5719/9723 (58.82%)\n",
      "\n",
      "Epoch: 111, Batch number: 10\n",
      "Accuracy on validation dataset: 5728/9723 (58.91%)\n",
      "\n",
      "Epoch: 111, Batch number: 20\n",
      "Accuracy on validation dataset: 5726/9723 (58.89%)\n",
      "\n",
      "Epoch: 111, Batch number: 30\n",
      "Accuracy on validation dataset: 5723/9723 (58.86%)\n",
      "\n",
      "Epoch: 111, Batch number: 40\n",
      "Accuracy on validation dataset: 5728/9723 (58.91%)\n",
      "\n",
      "Epoch: 111, Batch number: 50\n",
      "Accuracy on validation dataset: 5730/9723 (58.93%)\n",
      "\n",
      "Epoch: 111, Batch number: 60\n",
      "Accuracy on validation dataset: 5731/9723 (58.94%)\n",
      "\n",
      "Epoch: 111, Batch number: 70\n",
      "Accuracy on validation dataset: 5730/9723 (58.93%)\n",
      "\n",
      "Epoch: 112, Batch number: 4\n",
      "Accuracy on validation dataset: 5738/9723 (59.01%)\n",
      "\n",
      "Epoch: 112, Batch number: 14\n",
      "Accuracy on validation dataset: 5734/9723 (58.97%)\n",
      "\n",
      "Epoch: 112, Batch number: 24\n",
      "Accuracy on validation dataset: 5735/9723 (58.98%)\n",
      "\n",
      "Epoch: 112, Batch number: 34\n",
      "Accuracy on validation dataset: 5749/9723 (59.13%)\n",
      "\n",
      "Epoch: 112, Batch number: 44\n",
      "Accuracy on validation dataset: 5745/9723 (59.09%)\n",
      "\n",
      "Epoch: 112, Batch number: 54\n",
      "Accuracy on validation dataset: 5740/9723 (59.04%)\n",
      "\n",
      "Epoch: 112, Batch number: 64\n",
      "Accuracy on validation dataset: 5743/9723 (59.07%)\n",
      "\n",
      "Epoch: 112, Batch number: 74\n",
      "Accuracy on validation dataset: 5742/9723 (59.06%)\n",
      "\n",
      "Epoch: 113, Batch number: 8\n",
      "Accuracy on validation dataset: 5740/9723 (59.04%)\n",
      "\n",
      "Epoch: 113, Batch number: 18\n",
      "Accuracy on validation dataset: 5747/9723 (59.11%)\n",
      "\n",
      "Epoch: 113, Batch number: 28\n",
      "Accuracy on validation dataset: 5740/9723 (59.04%)\n",
      "\n",
      "Epoch: 113, Batch number: 38\n",
      "Accuracy on validation dataset: 5745/9723 (59.09%)\n",
      "\n",
      "Epoch: 113, Batch number: 48\n",
      "Accuracy on validation dataset: 5745/9723 (59.09%)\n",
      "\n",
      "Epoch: 113, Batch number: 58\n",
      "Accuracy on validation dataset: 5744/9723 (59.08%)\n",
      "\n",
      "Epoch: 113, Batch number: 68\n",
      "Accuracy on validation dataset: 5743/9723 (59.07%)\n",
      "\n",
      "Epoch: 114, Batch number: 2\n",
      "Accuracy on validation dataset: 5749/9723 (59.13%)\n",
      "\n",
      "Epoch: 114, Batch number: 12\n",
      "Accuracy on validation dataset: 5752/9723 (59.16%)\n",
      "\n",
      "Epoch: 114, Batch number: 22\n",
      "Accuracy on validation dataset: 5750/9723 (59.14%)\n",
      "\n",
      "Epoch: 114, Batch number: 32\n",
      "Accuracy on validation dataset: 5749/9723 (59.13%)\n",
      "\n",
      "Epoch: 114, Batch number: 42\n",
      "Accuracy on validation dataset: 5748/9723 (59.12%)\n",
      "\n",
      "Epoch: 114, Batch number: 52\n",
      "Accuracy on validation dataset: 5752/9723 (59.16%)\n",
      "\n",
      "Epoch: 114, Batch number: 62\n",
      "Accuracy on validation dataset: 5757/9723 (59.21%)\n",
      "\n",
      "Epoch: 114, Batch number: 72\n",
      "Accuracy on validation dataset: 5756/9723 (59.20%)\n",
      "\n",
      "Epoch: 115, Batch number: 6\n",
      "Accuracy on validation dataset: 5748/9723 (59.12%)\n",
      "\n",
      "Epoch: 115, Batch number: 16\n",
      "Accuracy on validation dataset: 5752/9723 (59.16%)\n",
      "\n",
      "Epoch: 115, Batch number: 26\n",
      "Accuracy on validation dataset: 5753/9723 (59.17%)\n",
      "\n",
      "Epoch: 115, Batch number: 36\n",
      "Accuracy on validation dataset: 5758/9723 (59.22%)\n",
      "\n",
      "Epoch: 115, Batch number: 46\n",
      "Accuracy on validation dataset: 5762/9723 (59.26%)\n",
      "\n",
      "Epoch: 115, Batch number: 56\n",
      "Accuracy on validation dataset: 5759/9723 (59.23%)\n",
      "\n",
      "Epoch: 115, Batch number: 66\n",
      "Accuracy on validation dataset: 5759/9723 (59.23%)\n",
      "\n",
      "Epoch: 116, Batch number: 0\n",
      "Accuracy on validation dataset: 5749/9723 (59.13%)\n",
      "\n",
      "Epoch: 116, Batch number: 10\n",
      "Accuracy on validation dataset: 5759/9723 (59.23%)\n",
      "\n",
      "Epoch: 116, Batch number: 20\n",
      "Accuracy on validation dataset: 5761/9723 (59.25%)\n",
      "\n",
      "Epoch: 116, Batch number: 30\n",
      "Accuracy on validation dataset: 5764/9723 (59.28%)\n",
      "\n",
      "Epoch: 116, Batch number: 40\n",
      "Accuracy on validation dataset: 5766/9723 (59.30%)\n",
      "\n",
      "Epoch: 116, Batch number: 50\n",
      "Accuracy on validation dataset: 5763/9723 (59.27%)\n",
      "\n",
      "Epoch: 116, Batch number: 60\n",
      "Accuracy on validation dataset: 5766/9723 (59.30%)\n",
      "\n",
      "Epoch: 116, Batch number: 70\n",
      "Accuracy on validation dataset: 5758/9723 (59.22%)\n",
      "\n",
      "Epoch: 117, Batch number: 4\n",
      "Accuracy on validation dataset: 5759/9723 (59.23%)\n",
      "\n",
      "Epoch: 117, Batch number: 14\n",
      "Accuracy on validation dataset: 5761/9723 (59.25%)\n",
      "\n",
      "Epoch: 117, Batch number: 24\n",
      "Accuracy on validation dataset: 5764/9723 (59.28%)\n",
      "\n",
      "Epoch: 117, Batch number: 34\n",
      "Accuracy on validation dataset: 5775/9723 (59.40%)\n",
      "\n",
      "Epoch: 117, Batch number: 44\n",
      "Accuracy on validation dataset: 5772/9723 (59.36%)\n",
      "\n",
      "Epoch: 117, Batch number: 54\n",
      "Accuracy on validation dataset: 5762/9723 (59.26%)\n",
      "\n",
      "Epoch: 117, Batch number: 64\n",
      "Accuracy on validation dataset: 5768/9723 (59.32%)\n",
      "\n",
      "Epoch: 117, Batch number: 74\n",
      "Accuracy on validation dataset: 5771/9723 (59.35%)\n",
      "\n",
      "Epoch: 118, Batch number: 8\n",
      "Accuracy on validation dataset: 5770/9723 (59.34%)\n",
      "\n",
      "Epoch: 118, Batch number: 18\n",
      "Accuracy on validation dataset: 5772/9723 (59.36%)\n",
      "\n",
      "Epoch: 118, Batch number: 28\n",
      "Accuracy on validation dataset: 5778/9723 (59.43%)\n",
      "\n",
      "Epoch: 118, Batch number: 38\n",
      "Accuracy on validation dataset: 5780/9723 (59.45%)\n",
      "\n",
      "Epoch: 118, Batch number: 48\n",
      "Accuracy on validation dataset: 5770/9723 (59.34%)\n",
      "\n",
      "Epoch: 118, Batch number: 58\n",
      "Accuracy on validation dataset: 5774/9723 (59.38%)\n",
      "\n",
      "Epoch: 118, Batch number: 68\n",
      "Accuracy on validation dataset: 5779/9723 (59.44%)\n",
      "\n",
      "Epoch: 119, Batch number: 2\n",
      "Accuracy on validation dataset: 5778/9723 (59.43%)\n",
      "\n",
      "Epoch: 119, Batch number: 12\n",
      "Accuracy on validation dataset: 5773/9723 (59.37%)\n",
      "\n",
      "Epoch: 119, Batch number: 22\n",
      "Accuracy on validation dataset: 5778/9723 (59.43%)\n",
      "\n",
      "Epoch: 119, Batch number: 32\n",
      "Accuracy on validation dataset: 5785/9723 (59.50%)\n",
      "\n",
      "Epoch: 119, Batch number: 42\n",
      "Accuracy on validation dataset: 5782/9723 (59.47%)\n",
      "\n",
      "Epoch: 119, Batch number: 52\n",
      "Accuracy on validation dataset: 5783/9723 (59.48%)\n",
      "\n",
      "Epoch: 119, Batch number: 62\n",
      "Accuracy on validation dataset: 5790/9723 (59.55%)\n",
      "\n",
      "Epoch: 119, Batch number: 72\n",
      "Accuracy on validation dataset: 5791/9723 (59.56%)\n",
      "\n",
      "Epoch: 120, Batch number: 6\n",
      "Accuracy on validation dataset: 5790/9723 (59.55%)\n",
      "\n",
      "Epoch: 120, Batch number: 16\n",
      "Accuracy on validation dataset: 5796/9723 (59.61%)\n",
      "\n",
      "Epoch: 120, Batch number: 26\n",
      "Accuracy on validation dataset: 5793/9723 (59.58%)\n",
      "\n",
      "Epoch: 120, Batch number: 36\n",
      "Accuracy on validation dataset: 5791/9723 (59.56%)\n",
      "\n",
      "Epoch: 120, Batch number: 46\n",
      "Accuracy on validation dataset: 5790/9723 (59.55%)\n",
      "\n",
      "Epoch: 120, Batch number: 56\n",
      "Accuracy on validation dataset: 5791/9723 (59.56%)\n",
      "\n",
      "Epoch: 120, Batch number: 66\n",
      "Accuracy on validation dataset: 5791/9723 (59.56%)\n",
      "\n",
      "Epoch: 121, Batch number: 0\n",
      "Accuracy on validation dataset: 5791/9723 (59.56%)\n",
      "\n",
      "Epoch: 121, Batch number: 10\n",
      "Accuracy on validation dataset: 5787/9723 (59.52%)\n",
      "\n",
      "Epoch: 121, Batch number: 20\n",
      "Accuracy on validation dataset: 5789/9723 (59.54%)\n",
      "\n",
      "Epoch: 121, Batch number: 30\n",
      "Accuracy on validation dataset: 5789/9723 (59.54%)\n",
      "\n",
      "Epoch: 121, Batch number: 40\n",
      "Accuracy on validation dataset: 5797/9723 (59.62%)\n",
      "\n",
      "Epoch: 121, Batch number: 50\n",
      "Accuracy on validation dataset: 5793/9723 (59.58%)\n",
      "\n",
      "Epoch: 121, Batch number: 60\n",
      "Accuracy on validation dataset: 5798/9723 (59.63%)\n",
      "\n",
      "Epoch: 121, Batch number: 70\n",
      "Accuracy on validation dataset: 5800/9723 (59.65%)\n",
      "\n",
      "Epoch: 122, Batch number: 4\n",
      "Accuracy on validation dataset: 5801/9723 (59.66%)\n",
      "\n",
      "Epoch: 122, Batch number: 14\n",
      "Accuracy on validation dataset: 5795/9723 (59.60%)\n",
      "\n",
      "Epoch: 122, Batch number: 24\n",
      "Accuracy on validation dataset: 5797/9723 (59.62%)\n",
      "\n",
      "Epoch: 122, Batch number: 34\n",
      "Accuracy on validation dataset: 5787/9723 (59.52%)\n",
      "\n",
      "Epoch: 122, Batch number: 44\n",
      "Accuracy on validation dataset: 5793/9723 (59.58%)\n",
      "\n",
      "Epoch: 122, Batch number: 54\n",
      "Accuracy on validation dataset: 5796/9723 (59.61%)\n",
      "\n",
      "Epoch: 122, Batch number: 64\n",
      "Accuracy on validation dataset: 5797/9723 (59.62%)\n",
      "\n",
      "Epoch: 122, Batch number: 74\n",
      "Accuracy on validation dataset: 5796/9723 (59.61%)\n",
      "\n",
      "Epoch: 123, Batch number: 8\n",
      "Accuracy on validation dataset: 5812/9723 (59.78%)\n",
      "\n",
      "Epoch: 123, Batch number: 18\n",
      "Accuracy on validation dataset: 5805/9723 (59.70%)\n",
      "\n",
      "Epoch: 123, Batch number: 28\n",
      "Accuracy on validation dataset: 5796/9723 (59.61%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123, Batch number: 38\n",
      "Accuracy on validation dataset: 5800/9723 (59.65%)\n",
      "\n",
      "Epoch: 123, Batch number: 48\n",
      "Accuracy on validation dataset: 5807/9723 (59.72%)\n",
      "\n",
      "Epoch: 123, Batch number: 58\n",
      "Accuracy on validation dataset: 5813/9723 (59.79%)\n",
      "\n",
      "Epoch: 123, Batch number: 68\n",
      "Accuracy on validation dataset: 5814/9723 (59.80%)\n",
      "\n",
      "Epoch: 124, Batch number: 2\n",
      "Accuracy on validation dataset: 5814/9723 (59.80%)\n",
      "\n",
      "Epoch: 124, Batch number: 12\n",
      "Accuracy on validation dataset: 5817/9723 (59.83%)\n",
      "\n",
      "Epoch: 124, Batch number: 22\n",
      "Accuracy on validation dataset: 5825/9723 (59.91%)\n",
      "\n",
      "Epoch: 124, Batch number: 32\n",
      "Accuracy on validation dataset: 5817/9723 (59.83%)\n",
      "\n",
      "Epoch: 124, Batch number: 42\n",
      "Accuracy on validation dataset: 5812/9723 (59.78%)\n",
      "\n",
      "Epoch: 124, Batch number: 52\n",
      "Accuracy on validation dataset: 5812/9723 (59.78%)\n",
      "\n",
      "Epoch: 124, Batch number: 62\n",
      "Accuracy on validation dataset: 5813/9723 (59.79%)\n",
      "\n",
      "Epoch: 124, Batch number: 72\n",
      "Accuracy on validation dataset: 5815/9723 (59.81%)\n",
      "\n",
      "Epoch: 125, Batch number: 6\n",
      "Accuracy on validation dataset: 5818/9723 (59.84%)\n",
      "\n",
      "Epoch: 125, Batch number: 16\n",
      "Accuracy on validation dataset: 5817/9723 (59.83%)\n",
      "\n",
      "Epoch: 125, Batch number: 26\n",
      "Accuracy on validation dataset: 5817/9723 (59.83%)\n",
      "\n",
      "Epoch: 125, Batch number: 36\n",
      "Accuracy on validation dataset: 5812/9723 (59.78%)\n",
      "\n",
      "Epoch: 125, Batch number: 46\n",
      "Accuracy on validation dataset: 5818/9723 (59.84%)\n",
      "\n",
      "Epoch: 125, Batch number: 56\n",
      "Accuracy on validation dataset: 5816/9723 (59.82%)\n",
      "\n",
      "Epoch: 125, Batch number: 66\n",
      "Accuracy on validation dataset: 5816/9723 (59.82%)\n",
      "\n",
      "Epoch: 126, Batch number: 0\n",
      "Accuracy on validation dataset: 5826/9723 (59.92%)\n",
      "\n",
      "Epoch: 126, Batch number: 10\n",
      "Accuracy on validation dataset: 5819/9723 (59.85%)\n",
      "\n",
      "Epoch: 126, Batch number: 20\n",
      "Accuracy on validation dataset: 5817/9723 (59.83%)\n",
      "\n",
      "Epoch: 126, Batch number: 30\n",
      "Accuracy on validation dataset: 5823/9723 (59.89%)\n",
      "\n",
      "Epoch: 126, Batch number: 40\n",
      "Accuracy on validation dataset: 5826/9723 (59.92%)\n",
      "\n",
      "Epoch: 126, Batch number: 50\n",
      "Accuracy on validation dataset: 5822/9723 (59.88%)\n",
      "\n",
      "Epoch: 126, Batch number: 60\n",
      "Accuracy on validation dataset: 5829/9723 (59.95%)\n",
      "\n",
      "Epoch: 126, Batch number: 70\n",
      "Accuracy on validation dataset: 5825/9723 (59.91%)\n",
      "\n",
      "Epoch: 127, Batch number: 4\n",
      "Accuracy on validation dataset: 5823/9723 (59.89%)\n",
      "\n",
      "Epoch: 127, Batch number: 14\n",
      "Accuracy on validation dataset: 5820/9723 (59.86%)\n",
      "\n",
      "Epoch: 127, Batch number: 24\n",
      "Accuracy on validation dataset: 5820/9723 (59.86%)\n",
      "\n",
      "Epoch: 127, Batch number: 34\n",
      "Accuracy on validation dataset: 5821/9723 (59.87%)\n",
      "\n",
      "Epoch: 127, Batch number: 44\n",
      "Accuracy on validation dataset: 5821/9723 (59.87%)\n",
      "\n",
      "Epoch: 127, Batch number: 54\n",
      "Accuracy on validation dataset: 5825/9723 (59.91%)\n",
      "\n",
      "Epoch: 127, Batch number: 64\n",
      "Accuracy on validation dataset: 5826/9723 (59.92%)\n",
      "\n",
      "Epoch: 127, Batch number: 74\n",
      "Accuracy on validation dataset: 5825/9723 (59.91%)\n",
      "\n",
      "Epoch: 128, Batch number: 8\n",
      "Accuracy on validation dataset: 5828/9723 (59.94%)\n",
      "\n",
      "Epoch: 128, Batch number: 18\n",
      "Accuracy on validation dataset: 5829/9723 (59.95%)\n",
      "\n",
      "Epoch: 128, Batch number: 28\n",
      "Accuracy on validation dataset: 5836/9723 (60.02%)\n",
      "\n",
      "Epoch: 128, Batch number: 38\n",
      "Accuracy on validation dataset: 5844/9723 (60.10%)\n",
      "\n",
      "Epoch: 128, Batch number: 48\n",
      "Accuracy on validation dataset: 5838/9723 (60.04%)\n",
      "\n",
      "Epoch: 128, Batch number: 58\n",
      "Accuracy on validation dataset: 5843/9723 (60.09%)\n",
      "\n",
      "Epoch: 128, Batch number: 68\n",
      "Accuracy on validation dataset: 5838/9723 (60.04%)\n",
      "\n",
      "Epoch: 129, Batch number: 2\n",
      "Accuracy on validation dataset: 5840/9723 (60.06%)\n",
      "\n",
      "Epoch: 129, Batch number: 12\n",
      "Accuracy on validation dataset: 5835/9723 (60.01%)\n",
      "\n",
      "Epoch: 129, Batch number: 22\n",
      "Accuracy on validation dataset: 5842/9723 (60.08%)\n",
      "\n",
      "Epoch: 129, Batch number: 32\n",
      "Accuracy on validation dataset: 5834/9723 (60.00%)\n",
      "\n",
      "Epoch: 129, Batch number: 42\n",
      "Accuracy on validation dataset: 5831/9723 (59.97%)\n",
      "\n",
      "Epoch: 129, Batch number: 52\n",
      "Accuracy on validation dataset: 5836/9723 (60.02%)\n",
      "\n",
      "Epoch: 129, Batch number: 62\n",
      "Accuracy on validation dataset: 5838/9723 (60.04%)\n",
      "\n",
      "Epoch: 129, Batch number: 72\n",
      "Accuracy on validation dataset: 5843/9723 (60.09%)\n",
      "\n",
      "Epoch: 130, Batch number: 6\n",
      "Accuracy on validation dataset: 5845/9723 (60.12%)\n",
      "\n",
      "Epoch: 130, Batch number: 16\n",
      "Accuracy on validation dataset: 5849/9723 (60.16%)\n",
      "\n",
      "Epoch: 130, Batch number: 26\n",
      "Accuracy on validation dataset: 5855/9723 (60.22%)\n",
      "\n",
      "Epoch: 130, Batch number: 36\n",
      "Accuracy on validation dataset: 5849/9723 (60.16%)\n",
      "\n",
      "Epoch: 130, Batch number: 46\n",
      "Accuracy on validation dataset: 5853/9723 (60.20%)\n",
      "\n",
      "Epoch: 130, Batch number: 56\n",
      "Accuracy on validation dataset: 5851/9723 (60.18%)\n",
      "\n",
      "Epoch: 130, Batch number: 66\n",
      "Accuracy on validation dataset: 5854/9723 (60.21%)\n",
      "\n",
      "Epoch: 131, Batch number: 0\n",
      "Accuracy on validation dataset: 5855/9723 (60.22%)\n",
      "\n",
      "Epoch: 131, Batch number: 10\n",
      "Accuracy on validation dataset: 5852/9723 (60.19%)\n",
      "\n",
      "Epoch: 131, Batch number: 20\n",
      "Accuracy on validation dataset: 5857/9723 (60.24%)\n",
      "\n",
      "Epoch: 131, Batch number: 30\n",
      "Accuracy on validation dataset: 5853/9723 (60.20%)\n",
      "\n",
      "Epoch: 131, Batch number: 40\n",
      "Accuracy on validation dataset: 5852/9723 (60.19%)\n",
      "\n",
      "Epoch: 131, Batch number: 50\n",
      "Accuracy on validation dataset: 5851/9723 (60.18%)\n",
      "\n",
      "Epoch: 131, Batch number: 60\n",
      "Accuracy on validation dataset: 5852/9723 (60.19%)\n",
      "\n",
      "Epoch: 131, Batch number: 70\n",
      "Accuracy on validation dataset: 5853/9723 (60.20%)\n",
      "\n",
      "Epoch: 132, Batch number: 4\n",
      "Accuracy on validation dataset: 5852/9723 (60.19%)\n",
      "\n",
      "Epoch: 132, Batch number: 14\n",
      "Accuracy on validation dataset: 5859/9723 (60.26%)\n",
      "\n",
      "Epoch: 132, Batch number: 24\n",
      "Accuracy on validation dataset: 5856/9723 (60.23%)\n",
      "\n",
      "Epoch: 132, Batch number: 34\n",
      "Accuracy on validation dataset: 5854/9723 (60.21%)\n",
      "\n",
      "Epoch: 132, Batch number: 44\n",
      "Accuracy on validation dataset: 5852/9723 (60.19%)\n",
      "\n",
      "Epoch: 132, Batch number: 54\n",
      "Accuracy on validation dataset: 5852/9723 (60.19%)\n",
      "\n",
      "Epoch: 132, Batch number: 64\n",
      "Accuracy on validation dataset: 5857/9723 (60.24%)\n",
      "\n",
      "Epoch: 132, Batch number: 74\n",
      "Accuracy on validation dataset: 5865/9723 (60.32%)\n",
      "\n",
      "Epoch: 133, Batch number: 8\n",
      "Accuracy on validation dataset: 5866/9723 (60.33%)\n",
      "\n",
      "Epoch: 133, Batch number: 18\n",
      "Accuracy on validation dataset: 5869/9723 (60.36%)\n",
      "\n",
      "Epoch: 133, Batch number: 28\n",
      "Accuracy on validation dataset: 5865/9723 (60.32%)\n",
      "\n",
      "Epoch: 133, Batch number: 38\n",
      "Accuracy on validation dataset: 5860/9723 (60.27%)\n",
      "\n",
      "Epoch: 133, Batch number: 48\n",
      "Accuracy on validation dataset: 5857/9723 (60.24%)\n",
      "\n",
      "Epoch: 133, Batch number: 58\n",
      "Accuracy on validation dataset: 5860/9723 (60.27%)\n",
      "\n",
      "Epoch: 133, Batch number: 68\n",
      "Accuracy on validation dataset: 5861/9723 (60.28%)\n",
      "\n",
      "Epoch: 134, Batch number: 2\n",
      "Accuracy on validation dataset: 5868/9723 (60.35%)\n",
      "\n",
      "Epoch: 134, Batch number: 12\n",
      "Accuracy on validation dataset: 5864/9723 (60.31%)\n",
      "\n",
      "Epoch: 134, Batch number: 22\n",
      "Accuracy on validation dataset: 5857/9723 (60.24%)\n",
      "\n",
      "Epoch: 134, Batch number: 32\n",
      "Accuracy on validation dataset: 5868/9723 (60.35%)\n",
      "\n",
      "Epoch: 134, Batch number: 42\n",
      "Accuracy on validation dataset: 5862/9723 (60.29%)\n",
      "\n",
      "Epoch: 134, Batch number: 52\n",
      "Accuracy on validation dataset: 5861/9723 (60.28%)\n",
      "\n",
      "Epoch: 134, Batch number: 62\n",
      "Accuracy on validation dataset: 5855/9723 (60.22%)\n",
      "\n",
      "Epoch: 134, Batch number: 72\n",
      "Accuracy on validation dataset: 5860/9723 (60.27%)\n",
      "\n",
      "Epoch: 135, Batch number: 6\n",
      "Accuracy on validation dataset: 5867/9723 (60.34%)\n",
      "\n",
      "Epoch: 135, Batch number: 16\n",
      "Accuracy on validation dataset: 5866/9723 (60.33%)\n",
      "\n",
      "Epoch: 135, Batch number: 26\n",
      "Accuracy on validation dataset: 5862/9723 (60.29%)\n",
      "\n",
      "Epoch: 135, Batch number: 36\n",
      "Accuracy on validation dataset: 5866/9723 (60.33%)\n",
      "\n",
      "Epoch: 135, Batch number: 46\n",
      "Accuracy on validation dataset: 5864/9723 (60.31%)\n",
      "\n",
      "Epoch: 135, Batch number: 56\n",
      "Accuracy on validation dataset: 5863/9723 (60.30%)\n",
      "\n",
      "Epoch: 135, Batch number: 66\n",
      "Accuracy on validation dataset: 5866/9723 (60.33%)\n",
      "\n",
      "Epoch: 136, Batch number: 0\n",
      "Accuracy on validation dataset: 5869/9723 (60.36%)\n",
      "\n",
      "Epoch: 136, Batch number: 10\n",
      "Accuracy on validation dataset: 5867/9723 (60.34%)\n",
      "\n",
      "Epoch: 136, Batch number: 20\n",
      "Accuracy on validation dataset: 5863/9723 (60.30%)\n",
      "\n",
      "Epoch: 136, Batch number: 30\n",
      "Accuracy on validation dataset: 5867/9723 (60.34%)\n",
      "\n",
      "Epoch: 136, Batch number: 40\n",
      "Accuracy on validation dataset: 5873/9723 (60.40%)\n",
      "\n",
      "Epoch: 136, Batch number: 50\n",
      "Accuracy on validation dataset: 5869/9723 (60.36%)\n",
      "\n",
      "Epoch: 136, Batch number: 60\n",
      "Accuracy on validation dataset: 5869/9723 (60.36%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136, Batch number: 70\n",
      "Accuracy on validation dataset: 5871/9723 (60.38%)\n",
      "\n",
      "Epoch: 137, Batch number: 4\n",
      "Accuracy on validation dataset: 5881/9723 (60.49%)\n",
      "\n",
      "Epoch: 137, Batch number: 14\n",
      "Accuracy on validation dataset: 5878/9723 (60.45%)\n",
      "\n",
      "Epoch: 137, Batch number: 24\n",
      "Accuracy on validation dataset: 5872/9723 (60.39%)\n",
      "\n",
      "Epoch: 137, Batch number: 34\n",
      "Accuracy on validation dataset: 5872/9723 (60.39%)\n",
      "\n",
      "Epoch: 137, Batch number: 44\n",
      "Accuracy on validation dataset: 5875/9723 (60.42%)\n",
      "\n",
      "Epoch: 137, Batch number: 54\n",
      "Accuracy on validation dataset: 5879/9723 (60.46%)\n",
      "\n",
      "Epoch: 137, Batch number: 64\n",
      "Accuracy on validation dataset: 5880/9723 (60.48%)\n",
      "\n",
      "Epoch: 137, Batch number: 74\n",
      "Accuracy on validation dataset: 5867/9723 (60.34%)\n",
      "\n",
      "Epoch: 138, Batch number: 8\n",
      "Accuracy on validation dataset: 5868/9723 (60.35%)\n",
      "\n",
      "Epoch: 138, Batch number: 18\n",
      "Accuracy on validation dataset: 5867/9723 (60.34%)\n",
      "\n",
      "Epoch: 138, Batch number: 28\n",
      "Accuracy on validation dataset: 5868/9723 (60.35%)\n",
      "\n",
      "Epoch: 138, Batch number: 38\n",
      "Accuracy on validation dataset: 5876/9723 (60.43%)\n",
      "\n",
      "Epoch: 138, Batch number: 48\n",
      "Accuracy on validation dataset: 5874/9723 (60.41%)\n",
      "\n",
      "Epoch: 138, Batch number: 58\n",
      "Accuracy on validation dataset: 5878/9723 (60.45%)\n",
      "\n",
      "Epoch: 138, Batch number: 68\n",
      "Accuracy on validation dataset: 5882/9723 (60.50%)\n",
      "\n",
      "Epoch: 139, Batch number: 2\n",
      "Accuracy on validation dataset: 5882/9723 (60.50%)\n",
      "\n",
      "Epoch: 139, Batch number: 12\n",
      "Accuracy on validation dataset: 5878/9723 (60.45%)\n",
      "\n",
      "Epoch: 139, Batch number: 22\n",
      "Accuracy on validation dataset: 5878/9723 (60.45%)\n",
      "\n",
      "Epoch: 139, Batch number: 32\n",
      "Accuracy on validation dataset: 5879/9723 (60.46%)\n",
      "\n",
      "Epoch: 139, Batch number: 42\n",
      "Accuracy on validation dataset: 5881/9723 (60.49%)\n",
      "\n",
      "Epoch: 139, Batch number: 52\n",
      "Accuracy on validation dataset: 5874/9723 (60.41%)\n",
      "\n",
      "Epoch: 139, Batch number: 62\n",
      "Accuracy on validation dataset: 5880/9723 (60.48%)\n",
      "\n",
      "Epoch: 139, Batch number: 72\n",
      "Accuracy on validation dataset: 5876/9723 (60.43%)\n",
      "\n",
      "Epoch: 140, Batch number: 6\n",
      "Accuracy on validation dataset: 5881/9723 (60.49%)\n",
      "\n",
      "Epoch: 140, Batch number: 16\n",
      "Accuracy on validation dataset: 5872/9723 (60.39%)\n",
      "\n",
      "Epoch: 140, Batch number: 26\n",
      "Accuracy on validation dataset: 5878/9723 (60.45%)\n",
      "\n",
      "Epoch: 140, Batch number: 36\n",
      "Accuracy on validation dataset: 5880/9723 (60.48%)\n",
      "\n",
      "Epoch: 140, Batch number: 46\n",
      "Accuracy on validation dataset: 5877/9723 (60.44%)\n",
      "\n",
      "Epoch: 140, Batch number: 56\n",
      "Accuracy on validation dataset: 5878/9723 (60.45%)\n",
      "\n",
      "Epoch: 140, Batch number: 66\n",
      "Accuracy on validation dataset: 5884/9723 (60.52%)\n",
      "\n",
      "Epoch: 141, Batch number: 0\n",
      "Accuracy on validation dataset: 5876/9723 (60.43%)\n",
      "\n",
      "Epoch: 141, Batch number: 10\n",
      "Accuracy on validation dataset: 5879/9723 (60.46%)\n",
      "\n",
      "Epoch: 141, Batch number: 20\n",
      "Accuracy on validation dataset: 5880/9723 (60.48%)\n",
      "\n",
      "Epoch: 141, Batch number: 30\n",
      "Accuracy on validation dataset: 5880/9723 (60.48%)\n",
      "\n",
      "Epoch: 141, Batch number: 40\n",
      "Accuracy on validation dataset: 5876/9723 (60.43%)\n",
      "\n",
      "Epoch: 141, Batch number: 50\n",
      "Accuracy on validation dataset: 5874/9723 (60.41%)\n",
      "\n",
      "Epoch: 141, Batch number: 60\n",
      "Accuracy on validation dataset: 5876/9723 (60.43%)\n",
      "\n",
      "Epoch: 141, Batch number: 70\n",
      "Accuracy on validation dataset: 5874/9723 (60.41%)\n",
      "\n",
      "Epoch: 142, Batch number: 4\n",
      "Accuracy on validation dataset: 5876/9723 (60.43%)\n",
      "\n",
      "Epoch: 142, Batch number: 14\n",
      "Accuracy on validation dataset: 5879/9723 (60.46%)\n",
      "\n",
      "Epoch: 142, Batch number: 24\n",
      "Accuracy on validation dataset: 5883/9723 (60.51%)\n",
      "\n",
      "Epoch: 142, Batch number: 34\n",
      "Accuracy on validation dataset: 5886/9723 (60.54%)\n",
      "\n",
      "Epoch: 142, Batch number: 44\n",
      "Accuracy on validation dataset: 5886/9723 (60.54%)\n",
      "\n",
      "Epoch: 142, Batch number: 54\n",
      "Accuracy on validation dataset: 5887/9723 (60.55%)\n",
      "\n",
      "Epoch: 142, Batch number: 64\n",
      "Accuracy on validation dataset: 5889/9723 (60.57%)\n",
      "\n",
      "Epoch: 142, Batch number: 74\n",
      "Accuracy on validation dataset: 5883/9723 (60.51%)\n",
      "\n",
      "Epoch: 143, Batch number: 8\n",
      "Accuracy on validation dataset: 5880/9723 (60.48%)\n",
      "\n",
      "Epoch: 143, Batch number: 18\n",
      "Accuracy on validation dataset: 5877/9723 (60.44%)\n",
      "\n",
      "Epoch: 143, Batch number: 28\n",
      "Accuracy on validation dataset: 5884/9723 (60.52%)\n",
      "\n",
      "Epoch: 143, Batch number: 38\n",
      "Accuracy on validation dataset: 5883/9723 (60.51%)\n",
      "\n",
      "Epoch: 143, Batch number: 48\n",
      "Accuracy on validation dataset: 5883/9723 (60.51%)\n",
      "\n",
      "Epoch: 143, Batch number: 58\n",
      "Accuracy on validation dataset: 5885/9723 (60.53%)\n",
      "\n",
      "Epoch: 143, Batch number: 68\n",
      "Accuracy on validation dataset: 5895/9723 (60.63%)\n",
      "\n",
      "Epoch: 144, Batch number: 2\n",
      "Accuracy on validation dataset: 5889/9723 (60.57%)\n",
      "\n",
      "Epoch: 144, Batch number: 12\n",
      "Accuracy on validation dataset: 5889/9723 (60.57%)\n",
      "\n",
      "Epoch: 144, Batch number: 22\n",
      "Accuracy on validation dataset: 5877/9723 (60.44%)\n",
      "\n",
      "Epoch: 144, Batch number: 32\n",
      "Accuracy on validation dataset: 5885/9723 (60.53%)\n",
      "\n",
      "Epoch: 144, Batch number: 42\n",
      "Accuracy on validation dataset: 5883/9723 (60.51%)\n",
      "\n",
      "Epoch: 144, Batch number: 52\n",
      "Accuracy on validation dataset: 5887/9723 (60.55%)\n",
      "\n",
      "Epoch: 144, Batch number: 62\n",
      "Accuracy on validation dataset: 5892/9723 (60.60%)\n",
      "\n",
      "Epoch: 144, Batch number: 72\n",
      "Accuracy on validation dataset: 5895/9723 (60.63%)\n",
      "\n",
      "Epoch: 145, Batch number: 6\n",
      "Accuracy on validation dataset: 5883/9723 (60.51%)\n",
      "\n",
      "Epoch: 145, Batch number: 16\n",
      "Accuracy on validation dataset: 5889/9723 (60.57%)\n",
      "\n",
      "Epoch: 145, Batch number: 26\n",
      "Accuracy on validation dataset: 5891/9723 (60.59%)\n",
      "\n",
      "Epoch: 145, Batch number: 36\n",
      "Accuracy on validation dataset: 5889/9723 (60.57%)\n",
      "\n",
      "Epoch: 145, Batch number: 46\n",
      "Accuracy on validation dataset: 5888/9723 (60.56%)\n",
      "\n",
      "Epoch: 145, Batch number: 56\n",
      "Accuracy on validation dataset: 5886/9723 (60.54%)\n",
      "\n",
      "Epoch: 145, Batch number: 66\n",
      "Accuracy on validation dataset: 5886/9723 (60.54%)\n",
      "\n",
      "Epoch: 146, Batch number: 0\n",
      "Accuracy on validation dataset: 5888/9723 (60.56%)\n",
      "\n",
      "Epoch: 146, Batch number: 10\n",
      "Accuracy on validation dataset: 5891/9723 (60.59%)\n",
      "\n",
      "Epoch: 146, Batch number: 20\n",
      "Accuracy on validation dataset: 5897/9723 (60.65%)\n",
      "\n",
      "Epoch: 146, Batch number: 30\n",
      "Accuracy on validation dataset: 5902/9723 (60.70%)\n",
      "\n",
      "Epoch: 146, Batch number: 40\n",
      "Accuracy on validation dataset: 5902/9723 (60.70%)\n",
      "\n",
      "Epoch: 146, Batch number: 50\n",
      "Accuracy on validation dataset: 5902/9723 (60.70%)\n",
      "\n",
      "Epoch: 146, Batch number: 60\n",
      "Accuracy on validation dataset: 5892/9723 (60.60%)\n",
      "\n",
      "Epoch: 146, Batch number: 70\n",
      "Accuracy on validation dataset: 5889/9723 (60.57%)\n",
      "\n",
      "Epoch: 147, Batch number: 4\n",
      "Accuracy on validation dataset: 5891/9723 (60.59%)\n",
      "\n",
      "Epoch: 147, Batch number: 14\n",
      "Accuracy on validation dataset: 5893/9723 (60.61%)\n",
      "\n",
      "Epoch: 147, Batch number: 24\n",
      "Accuracy on validation dataset: 5887/9723 (60.55%)\n",
      "\n",
      "Epoch: 147, Batch number: 34\n",
      "Accuracy on validation dataset: 5886/9723 (60.54%)\n",
      "\n",
      "Epoch: 147, Batch number: 44\n",
      "Accuracy on validation dataset: 5890/9723 (60.58%)\n",
      "\n",
      "Epoch: 147, Batch number: 54\n",
      "Accuracy on validation dataset: 5898/9723 (60.66%)\n",
      "\n",
      "Epoch: 147, Batch number: 64\n",
      "Accuracy on validation dataset: 5904/9723 (60.72%)\n",
      "\n",
      "Epoch: 147, Batch number: 74\n",
      "Accuracy on validation dataset: 5896/9723 (60.64%)\n",
      "\n",
      "Epoch: 148, Batch number: 8\n",
      "Accuracy on validation dataset: 5894/9723 (60.62%)\n",
      "\n",
      "Epoch: 148, Batch number: 18\n",
      "Accuracy on validation dataset: 5895/9723 (60.63%)\n",
      "\n",
      "Epoch: 148, Batch number: 28\n",
      "Accuracy on validation dataset: 5899/9723 (60.67%)\n",
      "\n",
      "Epoch: 148, Batch number: 38\n",
      "Accuracy on validation dataset: 5894/9723 (60.62%)\n",
      "\n",
      "Epoch: 148, Batch number: 48\n",
      "Accuracy on validation dataset: 5891/9723 (60.59%)\n",
      "\n",
      "Epoch: 148, Batch number: 58\n",
      "Accuracy on validation dataset: 5893/9723 (60.61%)\n",
      "\n",
      "Epoch: 148, Batch number: 68\n",
      "Accuracy on validation dataset: 5900/9723 (60.68%)\n",
      "\n",
      "Epoch: 149, Batch number: 2\n",
      "Accuracy on validation dataset: 5901/9723 (60.69%)\n",
      "\n",
      "Epoch: 149, Batch number: 12\n",
      "Accuracy on validation dataset: 5899/9723 (60.67%)\n",
      "\n",
      "Epoch: 149, Batch number: 22\n",
      "Accuracy on validation dataset: 5902/9723 (60.70%)\n",
      "\n",
      "Epoch: 149, Batch number: 32\n",
      "Accuracy on validation dataset: 5899/9723 (60.67%)\n",
      "\n",
      "Epoch: 149, Batch number: 42\n",
      "Accuracy on validation dataset: 5897/9723 (60.65%)\n",
      "\n",
      "Epoch: 149, Batch number: 52\n",
      "Accuracy on validation dataset: 5889/9723 (60.57%)\n",
      "\n",
      "Epoch: 149, Batch number: 62\n",
      "Accuracy on validation dataset: 5892/9723 (60.60%)\n",
      "\n",
      "Epoch: 149, Batch number: 72\n",
      "Accuracy on validation dataset: 5894/9723 (60.62%)\n",
      "\n",
      "Epoch: 150, Batch number: 6\n",
      "Accuracy on validation dataset: 5896/9723 (60.64%)\n",
      "\n",
      "Epoch: 150, Batch number: 16\n",
      "Accuracy on validation dataset: 5900/9723 (60.68%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Batch number: 26\n",
      "Accuracy on validation dataset: 5905/9723 (60.73%)\n",
      "\n",
      "Epoch: 150, Batch number: 36\n",
      "Accuracy on validation dataset: 5897/9723 (60.65%)\n",
      "\n",
      "Epoch: 150, Batch number: 46\n",
      "Accuracy on validation dataset: 5897/9723 (60.65%)\n",
      "\n",
      "Epoch: 150, Batch number: 56\n",
      "Accuracy on validation dataset: 5896/9723 (60.64%)\n",
      "\n",
      "Epoch: 150, Batch number: 66\n",
      "Accuracy on validation dataset: 5896/9723 (60.64%)\n",
      "\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 150              # Cantidad de epochs\n",
    "learning_rate = 5e-4      # Tasa de aprendizaje\n",
    "sample_loss_every = 10    # Calcular la loss cada este n√∫mero\n",
    "algorithm = 'Adam'        # Algoritmo de optimizaci√≥n\n",
    "\n",
    "trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ‚â• 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9ecc9f1cf8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainer.performance_history['iter'],trainer.performance_history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trainer created:\n",
      "Number of training samples: 38889 (40%)\n",
      "Number of validation samples: 9723 (10%)\n",
      "Number of test samples: 48612 (50%)\n",
      "Number of train batches: 76\n",
      "Number of samples per batch: 512\n",
      "\n",
      "Dispositivo seleccionado: cuda:1\n"
     ]
    }
   ],
   "source": [
    "window_size = 2           # Tama√±o de la ventana del contexto.\n",
    "cutoff_freq = 0           # Palabras con una frecuencia menor o igual a cutoff_freq son exclu√≠das del vocabulario.\n",
    "batch_size = 512          # Tama√±o del batch.\n",
    "val_size = .2\n",
    "\n",
    "model = 'CBOW'            # M√©todo de entrenamiento.\n",
    "embedding_dim = 50       # Dimensi√≥n del espacio de los word vectors.\n",
    "device = 'cuda:1'         # Dispositivo sobre el cual se entrena. \n",
    "state_dict = None         # Par√°metros pre-entrenados.\n",
    "paralelize = False        # Flag para decirle al programa que use las 2 gpus\n",
    "\n",
    "train_dataset = Word2VecSamples(corpus, window_size=window_size, cutoff_freq=cutoff_freq)\n",
    "test_dataset = Word2VecSamples(corpus, window_size=window_size, cutoff_freq=cutoff_freq)\n",
    "model = CBOWModel(len(train_dataset.vocabulary),embedding_dim)\n",
    "\n",
    "trainer = ModelTrainer(train_dataset, test_dataset, batch_size=batch_size, val_size=val_size)\n",
    "trainer.InitModel(model=model, state_dict=state_dict, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0005\n",
      "Number of epochs: 150\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0\n",
      "Accuracy on validation dataset: 3/9723 (0.03%)\n",
      "\n",
      "Epoch: 1, Batch number: 10\n",
      "Accuracy on validation dataset: 3/9723 (0.03%)\n",
      "\n",
      "Epoch: 1, Batch number: 20\n",
      "Accuracy on validation dataset: 3/9723 (0.03%)\n",
      "\n",
      "Epoch: 1, Batch number: 30\n",
      "Accuracy on validation dataset: 9/9723 (0.09%)\n",
      "\n",
      "Epoch: 1, Batch number: 40\n",
      "Accuracy on validation dataset: 16/9723 (0.16%)\n",
      "\n",
      "Epoch: 1, Batch number: 50\n",
      "Accuracy on validation dataset: 25/9723 (0.26%)\n",
      "\n",
      "Epoch: 1, Batch number: 60\n",
      "Accuracy on validation dataset: 45/9723 (0.46%)\n",
      "\n",
      "Epoch: 1, Batch number: 70\n",
      "Accuracy on validation dataset: 68/9723 (0.70%)\n",
      "\n",
      "Epoch: 2, Batch number: 4\n",
      "Accuracy on validation dataset: 108/9723 (1.11%)\n",
      "\n",
      "Epoch: 2, Batch number: 14\n",
      "Accuracy on validation dataset: 164/9723 (1.69%)\n",
      "\n",
      "Epoch: 2, Batch number: 24\n",
      "Accuracy on validation dataset: 224/9723 (2.30%)\n",
      "\n",
      "Epoch: 2, Batch number: 34\n",
      "Accuracy on validation dataset: 288/9723 (2.96%)\n",
      "\n",
      "Epoch: 2, Batch number: 44\n",
      "Accuracy on validation dataset: 374/9723 (3.85%)\n",
      "\n",
      "Epoch: 2, Batch number: 54\n",
      "Accuracy on validation dataset: 464/9723 (4.77%)\n",
      "\n",
      "Epoch: 2, Batch number: 64\n",
      "Accuracy on validation dataset: 589/9723 (6.06%)\n",
      "\n",
      "Epoch: 2, Batch number: 74\n",
      "Accuracy on validation dataset: 709/9723 (7.29%)\n",
      "\n",
      "Epoch: 3, Batch number: 8\n",
      "Accuracy on validation dataset: 815/9723 (8.38%)\n",
      "\n",
      "Epoch: 3, Batch number: 18\n",
      "Accuracy on validation dataset: 907/9723 (9.33%)\n",
      "\n",
      "Epoch: 3, Batch number: 28\n",
      "Accuracy on validation dataset: 1003/9723 (10.32%)\n",
      "\n",
      "Epoch: 3, Batch number: 38\n",
      "Accuracy on validation dataset: 1094/9723 (11.25%)\n",
      "\n",
      "Epoch: 3, Batch number: 48\n",
      "Accuracy on validation dataset: 1170/9723 (12.03%)\n",
      "\n",
      "Epoch: 3, Batch number: 58\n",
      "Accuracy on validation dataset: 1233/9723 (12.68%)\n",
      "\n",
      "Epoch: 3, Batch number: 68\n",
      "Accuracy on validation dataset: 1316/9723 (13.53%)\n",
      "\n",
      "Epoch: 4, Batch number: 2\n",
      "Accuracy on validation dataset: 1371/9723 (14.10%)\n",
      "\n",
      "Epoch: 4, Batch number: 12\n",
      "Accuracy on validation dataset: 1421/9723 (14.61%)\n",
      "\n",
      "Epoch: 4, Batch number: 22\n",
      "Accuracy on validation dataset: 1457/9723 (14.99%)\n",
      "\n",
      "Epoch: 4, Batch number: 32\n",
      "Accuracy on validation dataset: 1496/9723 (15.39%)\n",
      "\n",
      "Epoch: 4, Batch number: 42\n",
      "Accuracy on validation dataset: 1545/9723 (15.89%)\n",
      "\n",
      "Epoch: 4, Batch number: 52\n",
      "Accuracy on validation dataset: 1591/9723 (16.36%)\n",
      "\n",
      "Epoch: 4, Batch number: 62\n",
      "Accuracy on validation dataset: 1626/9723 (16.72%)\n",
      "\n",
      "Epoch: 4, Batch number: 72\n",
      "Accuracy on validation dataset: 1657/9723 (17.04%)\n",
      "\n",
      "Epoch: 5, Batch number: 6\n",
      "Accuracy on validation dataset: 1682/9723 (17.30%)\n",
      "\n",
      "Epoch: 5, Batch number: 16\n",
      "Accuracy on validation dataset: 1710/9723 (17.59%)\n",
      "\n",
      "Epoch: 5, Batch number: 26\n",
      "Accuracy on validation dataset: 1742/9723 (17.92%)\n",
      "\n",
      "Epoch: 5, Batch number: 36\n",
      "Accuracy on validation dataset: 1766/9723 (18.16%)\n",
      "\n",
      "Epoch: 5, Batch number: 46\n",
      "Accuracy on validation dataset: 1783/9723 (18.34%)\n",
      "\n",
      "Epoch: 5, Batch number: 56\n",
      "Accuracy on validation dataset: 1797/9723 (18.48%)\n",
      "\n",
      "Epoch: 5, Batch number: 66\n",
      "Accuracy on validation dataset: 1804/9723 (18.55%)\n",
      "\n",
      "Epoch: 6, Batch number: 0\n",
      "Accuracy on validation dataset: 1829/9723 (18.81%)\n",
      "\n",
      "Epoch: 6, Batch number: 10\n",
      "Accuracy on validation dataset: 1846/9723 (18.99%)\n",
      "\n",
      "Epoch: 6, Batch number: 20\n",
      "Accuracy on validation dataset: 1874/9723 (19.27%)\n",
      "\n",
      "Epoch: 6, Batch number: 30\n",
      "Accuracy on validation dataset: 1893/9723 (19.47%)\n",
      "\n",
      "Epoch: 6, Batch number: 40\n",
      "Accuracy on validation dataset: 1909/9723 (19.63%)\n",
      "\n",
      "Epoch: 6, Batch number: 50\n",
      "Accuracy on validation dataset: 1928/9723 (19.83%)\n",
      "\n",
      "Epoch: 6, Batch number: 60\n",
      "Accuracy on validation dataset: 1938/9723 (19.93%)\n",
      "\n",
      "Epoch: 6, Batch number: 70\n",
      "Accuracy on validation dataset: 1949/9723 (20.05%)\n",
      "\n",
      "Epoch: 7, Batch number: 4\n",
      "Accuracy on validation dataset: 1950/9723 (20.06%)\n",
      "\n",
      "Epoch: 7, Batch number: 14\n",
      "Accuracy on validation dataset: 1953/9723 (20.09%)\n",
      "\n",
      "Epoch: 7, Batch number: 24\n",
      "Accuracy on validation dataset: 1959/9723 (20.15%)\n",
      "\n",
      "Epoch: 7, Batch number: 34\n",
      "Accuracy on validation dataset: 1965/9723 (20.21%)\n",
      "\n",
      "Epoch: 7, Batch number: 44\n",
      "Accuracy on validation dataset: 1967/9723 (20.23%)\n",
      "\n",
      "Epoch: 7, Batch number: 54\n",
      "Accuracy on validation dataset: 1963/9723 (20.19%)\n",
      "\n",
      "Epoch: 7, Batch number: 64\n",
      "Accuracy on validation dataset: 1965/9723 (20.21%)\n",
      "\n",
      "Epoch: 7, Batch number: 74\n",
      "Accuracy on validation dataset: 1964/9723 (20.20%)\n",
      "\n",
      "Epoch: 8, Batch number: 8\n",
      "Accuracy on validation dataset: 1963/9723 (20.19%)\n",
      "\n",
      "Epoch: 8, Batch number: 18\n",
      "Accuracy on validation dataset: 1966/9723 (20.22%)\n",
      "\n",
      "Epoch: 8, Batch number: 28\n",
      "Accuracy on validation dataset: 1966/9723 (20.22%)\n",
      "\n",
      "Epoch: 8, Batch number: 38\n",
      "Accuracy on validation dataset: 1972/9723 (20.28%)\n",
      "\n",
      "Epoch: 8, Batch number: 48\n",
      "Accuracy on validation dataset: 1973/9723 (20.29%)\n",
      "\n",
      "Epoch: 8, Batch number: 58\n",
      "Accuracy on validation dataset: 1981/9723 (20.37%)\n",
      "\n",
      "Epoch: 8, Batch number: 68\n",
      "Accuracy on validation dataset: 1981/9723 (20.37%)\n",
      "\n",
      "Epoch: 9, Batch number: 2\n",
      "Accuracy on validation dataset: 1986/9723 (20.43%)\n",
      "\n",
      "Epoch: 9, Batch number: 12\n",
      "Accuracy on validation dataset: 1991/9723 (20.48%)\n",
      "\n",
      "Epoch: 9, Batch number: 22\n",
      "Accuracy on validation dataset: 1994/9723 (20.51%)\n",
      "\n",
      "Epoch: 9, Batch number: 32\n",
      "Accuracy on validation dataset: 1999/9723 (20.56%)\n",
      "\n",
      "Epoch: 9, Batch number: 42\n",
      "Accuracy on validation dataset: 2002/9723 (20.59%)\n",
      "\n",
      "Epoch: 9, Batch number: 52\n",
      "Accuracy on validation dataset: 2005/9723 (20.62%)\n",
      "\n",
      "Epoch: 9, Batch number: 62\n",
      "Accuracy on validation dataset: 2009/9723 (20.66%)\n",
      "\n",
      "Epoch: 9, Batch number: 72\n",
      "Accuracy on validation dataset: 2012/9723 (20.69%)\n",
      "\n",
      "Epoch: 10, Batch number: 6\n",
      "Accuracy on validation dataset: 2015/9723 (20.72%)\n",
      "\n",
      "Epoch: 10, Batch number: 16\n",
      "Accuracy on validation dataset: 2015/9723 (20.72%)\n",
      "\n",
      "Epoch: 10, Batch number: 26\n",
      "Accuracy on validation dataset: 2016/9723 (20.73%)\n",
      "\n",
      "Epoch: 10, Batch number: 36\n",
      "Accuracy on validation dataset: 2017/9723 (20.74%)\n",
      "\n",
      "Epoch: 10, Batch number: 46\n",
      "Accuracy on validation dataset: 2020/9723 (20.78%)\n",
      "\n",
      "Epoch: 10, Batch number: 56\n",
      "Accuracy on validation dataset: 2024/9723 (20.82%)\n",
      "\n",
      "Epoch: 10, Batch number: 66\n",
      "Accuracy on validation dataset: 2026/9723 (20.84%)\n",
      "\n",
      "Epoch: 11, Batch number: 0\n",
      "Accuracy on validation dataset: 2026/9723 (20.84%)\n",
      "\n",
      "Epoch: 11, Batch number: 10\n",
      "Accuracy on validation dataset: 2028/9723 (20.86%)\n",
      "\n",
      "Epoch: 11, Batch number: 20\n",
      "Accuracy on validation dataset: 2030/9723 (20.88%)\n",
      "\n",
      "Epoch: 11, Batch number: 30\n",
      "Accuracy on validation dataset: 2030/9723 (20.88%)\n",
      "\n",
      "Epoch: 11, Batch number: 40\n",
      "Accuracy on validation dataset: 2033/9723 (20.91%)\n",
      "\n",
      "Epoch: 11, Batch number: 50\n",
      "Accuracy on validation dataset: 2039/9723 (20.97%)\n",
      "\n",
      "Epoch: 11, Batch number: 60\n",
      "Accuracy on validation dataset: 2040/9723 (20.98%)\n",
      "\n",
      "Epoch: 11, Batch number: 70\n",
      "Accuracy on validation dataset: 2041/9723 (20.99%)\n",
      "\n",
      "Epoch: 12, Batch number: 4\n",
      "Accuracy on validation dataset: 2044/9723 (21.02%)\n",
      "\n",
      "Epoch: 12, Batch number: 14\n",
      "Accuracy on validation dataset: 2048/9723 (21.06%)\n",
      "\n",
      "Epoch: 12, Batch number: 24\n",
      "Accuracy on validation dataset: 2048/9723 (21.06%)\n",
      "\n",
      "Epoch: 12, Batch number: 34\n",
      "Accuracy on validation dataset: 2048/9723 (21.06%)\n",
      "\n",
      "Epoch: 12, Batch number: 44\n",
      "Accuracy on validation dataset: 2052/9723 (21.10%)\n",
      "\n",
      "Epoch: 12, Batch number: 54\n",
      "Accuracy on validation dataset: 2055/9723 (21.14%)\n",
      "\n",
      "Epoch: 12, Batch number: 64\n",
      "Accuracy on validation dataset: 2054/9723 (21.13%)\n",
      "\n",
      "Epoch: 12, Batch number: 74\n",
      "Accuracy on validation dataset: 2056/9723 (21.15%)\n",
      "\n",
      "Epoch: 13, Batch number: 8\n",
      "Accuracy on validation dataset: 2061/9723 (21.20%)\n",
      "\n",
      "Epoch: 13, Batch number: 18\n",
      "Accuracy on validation dataset: 2064/9723 (21.23%)\n",
      "\n",
      "Epoch: 13, Batch number: 28\n",
      "Accuracy on validation dataset: 2066/9723 (21.25%)\n",
      "\n",
      "Epoch: 13, Batch number: 38\n",
      "Accuracy on validation dataset: 2066/9723 (21.25%)\n",
      "\n",
      "Epoch: 13, Batch number: 48\n",
      "Accuracy on validation dataset: 2067/9723 (21.26%)\n",
      "\n",
      "Epoch: 13, Batch number: 58\n",
      "Accuracy on validation dataset: 2070/9723 (21.29%)\n",
      "\n",
      "Epoch: 13, Batch number: 68\n",
      "Accuracy on validation dataset: 2073/9723 (21.32%)\n",
      "\n",
      "Epoch: 14, Batch number: 2\n",
      "Accuracy on validation dataset: 2073/9723 (21.32%)\n",
      "\n",
      "Epoch: 14, Batch number: 12\n",
      "Accuracy on validation dataset: 2078/9723 (21.37%)\n",
      "\n",
      "Epoch: 14, Batch number: 22\n",
      "Accuracy on validation dataset: 2081/9723 (21.40%)\n",
      "\n",
      "Epoch: 14, Batch number: 32\n",
      "Accuracy on validation dataset: 2085/9723 (21.44%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Batch number: 42\n",
      "Accuracy on validation dataset: 2090/9723 (21.50%)\n",
      "\n",
      "Epoch: 14, Batch number: 52\n",
      "Accuracy on validation dataset: 2092/9723 (21.52%)\n",
      "\n",
      "Epoch: 14, Batch number: 62\n",
      "Accuracy on validation dataset: 2096/9723 (21.56%)\n",
      "\n",
      "Epoch: 14, Batch number: 72\n",
      "Accuracy on validation dataset: 2102/9723 (21.62%)\n",
      "\n",
      "Epoch: 15, Batch number: 6\n",
      "Accuracy on validation dataset: 2107/9723 (21.67%)\n",
      "\n",
      "Epoch: 15, Batch number: 16\n",
      "Accuracy on validation dataset: 2109/9723 (21.69%)\n",
      "\n",
      "Epoch: 15, Batch number: 26\n",
      "Accuracy on validation dataset: 2111/9723 (21.71%)\n",
      "\n",
      "Epoch: 15, Batch number: 36\n",
      "Accuracy on validation dataset: 2113/9723 (21.73%)\n",
      "\n",
      "Epoch: 15, Batch number: 46\n",
      "Accuracy on validation dataset: 2114/9723 (21.74%)\n",
      "\n",
      "Epoch: 15, Batch number: 56\n",
      "Accuracy on validation dataset: 2115/9723 (21.75%)\n",
      "\n",
      "Epoch: 15, Batch number: 66\n",
      "Accuracy on validation dataset: 2116/9723 (21.76%)\n",
      "\n",
      "Epoch: 16, Batch number: 0\n",
      "Accuracy on validation dataset: 2124/9723 (21.85%)\n",
      "\n",
      "Epoch: 16, Batch number: 10\n",
      "Accuracy on validation dataset: 2124/9723 (21.85%)\n",
      "\n",
      "Epoch: 16, Batch number: 20\n",
      "Accuracy on validation dataset: 2125/9723 (21.86%)\n",
      "\n",
      "Epoch: 16, Batch number: 30\n",
      "Accuracy on validation dataset: 2132/9723 (21.93%)\n",
      "\n",
      "Epoch: 16, Batch number: 40\n",
      "Accuracy on validation dataset: 2133/9723 (21.94%)\n",
      "\n",
      "Epoch: 16, Batch number: 50\n",
      "Accuracy on validation dataset: 2136/9723 (21.97%)\n",
      "\n",
      "Epoch: 16, Batch number: 60\n",
      "Accuracy on validation dataset: 2142/9723 (22.03%)\n",
      "\n",
      "Epoch: 16, Batch number: 70\n",
      "Accuracy on validation dataset: 2140/9723 (22.01%)\n",
      "\n",
      "Epoch: 17, Batch number: 4\n",
      "Accuracy on validation dataset: 2142/9723 (22.03%)\n",
      "\n",
      "Epoch: 17, Batch number: 14\n",
      "Accuracy on validation dataset: 2145/9723 (22.06%)\n",
      "\n",
      "Epoch: 17, Batch number: 24\n",
      "Accuracy on validation dataset: 2147/9723 (22.08%)\n",
      "\n",
      "Epoch: 17, Batch number: 34\n",
      "Accuracy on validation dataset: 2149/9723 (22.10%)\n",
      "\n",
      "Epoch: 17, Batch number: 44\n",
      "Accuracy on validation dataset: 2159/9723 (22.21%)\n",
      "\n",
      "Epoch: 17, Batch number: 54\n",
      "Accuracy on validation dataset: 2157/9723 (22.18%)\n",
      "\n",
      "Epoch: 17, Batch number: 64\n",
      "Accuracy on validation dataset: 2156/9723 (22.17%)\n",
      "\n",
      "Epoch: 17, Batch number: 74\n",
      "Accuracy on validation dataset: 2160/9723 (22.22%)\n",
      "\n",
      "Epoch: 18, Batch number: 8\n",
      "Accuracy on validation dataset: 2163/9723 (22.25%)\n",
      "\n",
      "Epoch: 18, Batch number: 18\n",
      "Accuracy on validation dataset: 2167/9723 (22.29%)\n",
      "\n",
      "Epoch: 18, Batch number: 28\n",
      "Accuracy on validation dataset: 2169/9723 (22.31%)\n",
      "\n",
      "Epoch: 18, Batch number: 38\n",
      "Accuracy on validation dataset: 2170/9723 (22.32%)\n",
      "\n",
      "Epoch: 18, Batch number: 48\n",
      "Accuracy on validation dataset: 2170/9723 (22.32%)\n",
      "\n",
      "Epoch: 18, Batch number: 58\n",
      "Accuracy on validation dataset: 2170/9723 (22.32%)\n",
      "\n",
      "Epoch: 18, Batch number: 68\n",
      "Accuracy on validation dataset: 2176/9723 (22.38%)\n",
      "\n",
      "Epoch: 19, Batch number: 2\n",
      "Accuracy on validation dataset: 2177/9723 (22.39%)\n",
      "\n",
      "Epoch: 19, Batch number: 12\n",
      "Accuracy on validation dataset: 2177/9723 (22.39%)\n",
      "\n",
      "Epoch: 19, Batch number: 22\n",
      "Accuracy on validation dataset: 2183/9723 (22.45%)\n",
      "\n",
      "Epoch: 19, Batch number: 32\n",
      "Accuracy on validation dataset: 2185/9723 (22.47%)\n",
      "\n",
      "Epoch: 19, Batch number: 42\n",
      "Accuracy on validation dataset: 2189/9723 (22.51%)\n",
      "\n",
      "Epoch: 19, Batch number: 52\n",
      "Accuracy on validation dataset: 2189/9723 (22.51%)\n",
      "\n",
      "Epoch: 19, Batch number: 62\n",
      "Accuracy on validation dataset: 2193/9723 (22.55%)\n",
      "\n",
      "Epoch: 19, Batch number: 72\n",
      "Accuracy on validation dataset: 2195/9723 (22.58%)\n",
      "\n",
      "Epoch: 20, Batch number: 6\n",
      "Accuracy on validation dataset: 2196/9723 (22.59%)\n",
      "\n",
      "Epoch: 20, Batch number: 16\n",
      "Accuracy on validation dataset: 2198/9723 (22.61%)\n",
      "\n",
      "Epoch: 20, Batch number: 26\n",
      "Accuracy on validation dataset: 2197/9723 (22.60%)\n",
      "\n",
      "Epoch: 20, Batch number: 36\n",
      "Accuracy on validation dataset: 2203/9723 (22.66%)\n",
      "\n",
      "Epoch: 20, Batch number: 46\n",
      "Accuracy on validation dataset: 2201/9723 (22.64%)\n",
      "\n",
      "Epoch: 20, Batch number: 56\n",
      "Accuracy on validation dataset: 2205/9723 (22.68%)\n",
      "\n",
      "Epoch: 20, Batch number: 66\n",
      "Accuracy on validation dataset: 2209/9723 (22.72%)\n",
      "\n",
      "Epoch: 21, Batch number: 0\n",
      "Accuracy on validation dataset: 2211/9723 (22.74%)\n",
      "\n",
      "Epoch: 21, Batch number: 10\n",
      "Accuracy on validation dataset: 2219/9723 (22.82%)\n",
      "\n",
      "Epoch: 21, Batch number: 20\n",
      "Accuracy on validation dataset: 2216/9723 (22.79%)\n",
      "\n",
      "Epoch: 21, Batch number: 30\n",
      "Accuracy on validation dataset: 2218/9723 (22.81%)\n",
      "\n",
      "Epoch: 21, Batch number: 40\n",
      "Accuracy on validation dataset: 2220/9723 (22.83%)\n",
      "\n",
      "Epoch: 21, Batch number: 50\n",
      "Accuracy on validation dataset: 2222/9723 (22.85%)\n",
      "\n",
      "Epoch: 21, Batch number: 60\n",
      "Accuracy on validation dataset: 2223/9723 (22.86%)\n",
      "\n",
      "Epoch: 21, Batch number: 70\n",
      "Accuracy on validation dataset: 2221/9723 (22.84%)\n",
      "\n",
      "Epoch: 22, Batch number: 4\n",
      "Accuracy on validation dataset: 2225/9723 (22.88%)\n",
      "\n",
      "Epoch: 22, Batch number: 14\n",
      "Accuracy on validation dataset: 2225/9723 (22.88%)\n",
      "\n",
      "Epoch: 22, Batch number: 24\n",
      "Accuracy on validation dataset: 2229/9723 (22.93%)\n",
      "\n",
      "Epoch: 22, Batch number: 34\n",
      "Accuracy on validation dataset: 2230/9723 (22.94%)\n",
      "\n",
      "Epoch: 22, Batch number: 44\n",
      "Accuracy on validation dataset: 2234/9723 (22.98%)\n",
      "\n",
      "Epoch: 22, Batch number: 54\n",
      "Accuracy on validation dataset: 2235/9723 (22.99%)\n",
      "\n",
      "Epoch: 22, Batch number: 64\n",
      "Accuracy on validation dataset: 2234/9723 (22.98%)\n",
      "\n",
      "Epoch: 22, Batch number: 74\n",
      "Accuracy on validation dataset: 2241/9723 (23.05%)\n",
      "\n",
      "Epoch: 23, Batch number: 8\n",
      "Accuracy on validation dataset: 2233/9723 (22.97%)\n",
      "\n",
      "Epoch: 23, Batch number: 18\n",
      "Accuracy on validation dataset: 2235/9723 (22.99%)\n",
      "\n",
      "Epoch: 23, Batch number: 28\n",
      "Accuracy on validation dataset: 2237/9723 (23.01%)\n",
      "\n",
      "Epoch: 23, Batch number: 38\n",
      "Accuracy on validation dataset: 2243/9723 (23.07%)\n",
      "\n",
      "Epoch: 23, Batch number: 48\n",
      "Accuracy on validation dataset: 2248/9723 (23.12%)\n",
      "\n",
      "Epoch: 23, Batch number: 58\n",
      "Accuracy on validation dataset: 2250/9723 (23.14%)\n",
      "\n",
      "Epoch: 23, Batch number: 68\n",
      "Accuracy on validation dataset: 2256/9723 (23.20%)\n",
      "\n",
      "Epoch: 24, Batch number: 2\n",
      "Accuracy on validation dataset: 2259/9723 (23.23%)\n",
      "\n",
      "Epoch: 24, Batch number: 12\n",
      "Accuracy on validation dataset: 2259/9723 (23.23%)\n",
      "\n",
      "Epoch: 24, Batch number: 22\n",
      "Accuracy on validation dataset: 2260/9723 (23.24%)\n",
      "\n",
      "Epoch: 24, Batch number: 32\n",
      "Accuracy on validation dataset: 2265/9723 (23.30%)\n",
      "\n",
      "Epoch: 24, Batch number: 42\n",
      "Accuracy on validation dataset: 2267/9723 (23.32%)\n",
      "\n",
      "Epoch: 24, Batch number: 52\n",
      "Accuracy on validation dataset: 2266/9723 (23.31%)\n",
      "\n",
      "Epoch: 24, Batch number: 62\n",
      "Accuracy on validation dataset: 2270/9723 (23.35%)\n",
      "\n",
      "Epoch: 24, Batch number: 72\n",
      "Accuracy on validation dataset: 2271/9723 (23.36%)\n",
      "\n",
      "Epoch: 25, Batch number: 6\n",
      "Accuracy on validation dataset: 2276/9723 (23.41%)\n",
      "\n",
      "Epoch: 25, Batch number: 16\n",
      "Accuracy on validation dataset: 2277/9723 (23.42%)\n",
      "\n",
      "Epoch: 25, Batch number: 26\n",
      "Accuracy on validation dataset: 2275/9723 (23.40%)\n",
      "\n",
      "Epoch: 25, Batch number: 36\n",
      "Accuracy on validation dataset: 2281/9723 (23.46%)\n",
      "\n",
      "Epoch: 25, Batch number: 46\n",
      "Accuracy on validation dataset: 2280/9723 (23.45%)\n",
      "\n",
      "Epoch: 25, Batch number: 56\n",
      "Accuracy on validation dataset: 2288/9723 (23.53%)\n",
      "\n",
      "Epoch: 25, Batch number: 66\n",
      "Accuracy on validation dataset: 2287/9723 (23.52%)\n",
      "\n",
      "Epoch: 26, Batch number: 0\n",
      "Accuracy on validation dataset: 2285/9723 (23.50%)\n",
      "\n",
      "Epoch: 26, Batch number: 10\n",
      "Accuracy on validation dataset: 2285/9723 (23.50%)\n",
      "\n",
      "Epoch: 26, Batch number: 20\n",
      "Accuracy on validation dataset: 2288/9723 (23.53%)\n",
      "\n",
      "Epoch: 26, Batch number: 30\n",
      "Accuracy on validation dataset: 2288/9723 (23.53%)\n",
      "\n",
      "Epoch: 26, Batch number: 40\n",
      "Accuracy on validation dataset: 2292/9723 (23.57%)\n",
      "\n",
      "Epoch: 26, Batch number: 50\n",
      "Accuracy on validation dataset: 2295/9723 (23.60%)\n",
      "\n",
      "Epoch: 26, Batch number: 60\n",
      "Accuracy on validation dataset: 2291/9723 (23.56%)\n",
      "\n",
      "Epoch: 26, Batch number: 70\n",
      "Accuracy on validation dataset: 2294/9723 (23.59%)\n",
      "\n",
      "Epoch: 27, Batch number: 4\n",
      "Accuracy on validation dataset: 2299/9723 (23.64%)\n",
      "\n",
      "Epoch: 27, Batch number: 14\n",
      "Accuracy on validation dataset: 2304/9723 (23.70%)\n",
      "\n",
      "Epoch: 27, Batch number: 24\n",
      "Accuracy on validation dataset: 2308/9723 (23.74%)\n",
      "\n",
      "Epoch: 27, Batch number: 34\n",
      "Accuracy on validation dataset: 2309/9723 (23.75%)\n",
      "\n",
      "Epoch: 27, Batch number: 44\n",
      "Accuracy on validation dataset: 2309/9723 (23.75%)\n",
      "\n",
      "Epoch: 27, Batch number: 54\n",
      "Accuracy on validation dataset: 2305/9723 (23.71%)\n",
      "\n",
      "Epoch: 27, Batch number: 64\n",
      "Accuracy on validation dataset: 2305/9723 (23.71%)\n",
      "\n",
      "Epoch: 27, Batch number: 74\n",
      "Accuracy on validation dataset: 2306/9723 (23.72%)\n",
      "\n",
      "Epoch: 28, Batch number: 8\n",
      "Accuracy on validation dataset: 2299/9723 (23.64%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Batch number: 18\n",
      "Accuracy on validation dataset: 2303/9723 (23.69%)\n",
      "\n",
      "Epoch: 28, Batch number: 28\n",
      "Accuracy on validation dataset: 2305/9723 (23.71%)\n",
      "\n",
      "Epoch: 28, Batch number: 38\n",
      "Accuracy on validation dataset: 2311/9723 (23.77%)\n",
      "\n",
      "Epoch: 28, Batch number: 48\n",
      "Accuracy on validation dataset: 2310/9723 (23.76%)\n",
      "\n",
      "Epoch: 28, Batch number: 58\n",
      "Accuracy on validation dataset: 2307/9723 (23.73%)\n",
      "\n",
      "Epoch: 28, Batch number: 68\n",
      "Accuracy on validation dataset: 2312/9723 (23.78%)\n",
      "\n",
      "Epoch: 29, Batch number: 2\n",
      "Accuracy on validation dataset: 2307/9723 (23.73%)\n",
      "\n",
      "Epoch: 29, Batch number: 12\n",
      "Accuracy on validation dataset: 2308/9723 (23.74%)\n",
      "\n",
      "Epoch: 29, Batch number: 22\n",
      "Accuracy on validation dataset: 2312/9723 (23.78%)\n",
      "\n",
      "Epoch: 29, Batch number: 32\n",
      "Accuracy on validation dataset: 2309/9723 (23.75%)\n",
      "\n",
      "Epoch: 29, Batch number: 42\n",
      "Accuracy on validation dataset: 2311/9723 (23.77%)\n",
      "\n",
      "Epoch: 29, Batch number: 52\n",
      "Accuracy on validation dataset: 2312/9723 (23.78%)\n",
      "\n",
      "Epoch: 29, Batch number: 62\n",
      "Accuracy on validation dataset: 2311/9723 (23.77%)\n",
      "\n",
      "Epoch: 29, Batch number: 72\n",
      "Accuracy on validation dataset: 2309/9723 (23.75%)\n",
      "\n",
      "Epoch: 30, Batch number: 6\n",
      "Accuracy on validation dataset: 2310/9723 (23.76%)\n",
      "\n",
      "Epoch: 30, Batch number: 16\n",
      "Accuracy on validation dataset: 2310/9723 (23.76%)\n",
      "\n",
      "Epoch: 30, Batch number: 26\n",
      "Accuracy on validation dataset: 2312/9723 (23.78%)\n",
      "\n",
      "Epoch: 30, Batch number: 36\n",
      "Accuracy on validation dataset: 2315/9723 (23.81%)\n",
      "\n",
      "Epoch: 30, Batch number: 46\n",
      "Accuracy on validation dataset: 2318/9723 (23.84%)\n",
      "\n",
      "Epoch: 30, Batch number: 56\n",
      "Accuracy on validation dataset: 2319/9723 (23.85%)\n",
      "\n",
      "Epoch: 30, Batch number: 66\n",
      "Accuracy on validation dataset: 2318/9723 (23.84%)\n",
      "\n",
      "Epoch: 31, Batch number: 0\n",
      "Accuracy on validation dataset: 2319/9723 (23.85%)\n",
      "\n",
      "Epoch: 31, Batch number: 10\n",
      "Accuracy on validation dataset: 2320/9723 (23.86%)\n",
      "\n",
      "Epoch: 31, Batch number: 20\n",
      "Accuracy on validation dataset: 2320/9723 (23.86%)\n",
      "\n",
      "Epoch: 31, Batch number: 30\n",
      "Accuracy on validation dataset: 2323/9723 (23.89%)\n",
      "\n",
      "Epoch: 31, Batch number: 40\n",
      "Accuracy on validation dataset: 2321/9723 (23.87%)\n",
      "\n",
      "Epoch: 31, Batch number: 50\n",
      "Accuracy on validation dataset: 2323/9723 (23.89%)\n",
      "\n",
      "Epoch: 31, Batch number: 60\n",
      "Accuracy on validation dataset: 2323/9723 (23.89%)\n",
      "\n",
      "Epoch: 31, Batch number: 70\n",
      "Accuracy on validation dataset: 2322/9723 (23.88%)\n",
      "\n",
      "Epoch: 32, Batch number: 4\n",
      "Accuracy on validation dataset: 2322/9723 (23.88%)\n",
      "\n",
      "Epoch: 32, Batch number: 14\n",
      "Accuracy on validation dataset: 2325/9723 (23.91%)\n",
      "\n",
      "Epoch: 32, Batch number: 24\n",
      "Accuracy on validation dataset: 2326/9723 (23.92%)\n",
      "\n",
      "Epoch: 32, Batch number: 34\n",
      "Accuracy on validation dataset: 2323/9723 (23.89%)\n",
      "\n",
      "Epoch: 32, Batch number: 44\n",
      "Accuracy on validation dataset: 2326/9723 (23.92%)\n",
      "\n",
      "Epoch: 32, Batch number: 54\n",
      "Accuracy on validation dataset: 2324/9723 (23.90%)\n",
      "\n",
      "Epoch: 32, Batch number: 64\n",
      "Accuracy on validation dataset: 2323/9723 (23.89%)\n",
      "\n",
      "Epoch: 32, Batch number: 74\n",
      "Accuracy on validation dataset: 2326/9723 (23.92%)\n",
      "\n",
      "Epoch: 33, Batch number: 8\n",
      "Accuracy on validation dataset: 2331/9723 (23.97%)\n",
      "\n",
      "Epoch: 33, Batch number: 18\n",
      "Accuracy on validation dataset: 2333/9723 (23.99%)\n",
      "\n",
      "Epoch: 33, Batch number: 28\n",
      "Accuracy on validation dataset: 2335/9723 (24.02%)\n",
      "\n",
      "Epoch: 33, Batch number: 38\n",
      "Accuracy on validation dataset: 2334/9723 (24.00%)\n",
      "\n",
      "Epoch: 33, Batch number: 48\n",
      "Accuracy on validation dataset: 2335/9723 (24.02%)\n",
      "\n",
      "Epoch: 33, Batch number: 58\n",
      "Accuracy on validation dataset: 2337/9723 (24.04%)\n",
      "\n",
      "Epoch: 33, Batch number: 68\n",
      "Accuracy on validation dataset: 2342/9723 (24.09%)\n",
      "\n",
      "Epoch: 34, Batch number: 2\n",
      "Accuracy on validation dataset: 2345/9723 (24.12%)\n",
      "\n",
      "Epoch: 34, Batch number: 12\n",
      "Accuracy on validation dataset: 2349/9723 (24.16%)\n",
      "\n",
      "Epoch: 34, Batch number: 22\n",
      "Accuracy on validation dataset: 2347/9723 (24.14%)\n",
      "\n",
      "Epoch: 34, Batch number: 32\n",
      "Accuracy on validation dataset: 2346/9723 (24.13%)\n",
      "\n",
      "Epoch: 34, Batch number: 42\n",
      "Accuracy on validation dataset: 2349/9723 (24.16%)\n",
      "\n",
      "Epoch: 34, Batch number: 52\n",
      "Accuracy on validation dataset: 2350/9723 (24.17%)\n",
      "\n",
      "Epoch: 34, Batch number: 62\n",
      "Accuracy on validation dataset: 2352/9723 (24.19%)\n",
      "\n",
      "Epoch: 34, Batch number: 72\n",
      "Accuracy on validation dataset: 2358/9723 (24.25%)\n",
      "\n",
      "Epoch: 35, Batch number: 6\n",
      "Accuracy on validation dataset: 2350/9723 (24.17%)\n",
      "\n",
      "Epoch: 35, Batch number: 16\n",
      "Accuracy on validation dataset: 2351/9723 (24.18%)\n",
      "\n",
      "Epoch: 35, Batch number: 26\n",
      "Accuracy on validation dataset: 2356/9723 (24.23%)\n",
      "\n",
      "Epoch: 35, Batch number: 36\n",
      "Accuracy on validation dataset: 2351/9723 (24.18%)\n",
      "\n",
      "Epoch: 35, Batch number: 46\n",
      "Accuracy on validation dataset: 2346/9723 (24.13%)\n",
      "\n",
      "Epoch: 35, Batch number: 56\n",
      "Accuracy on validation dataset: 2347/9723 (24.14%)\n",
      "\n",
      "Epoch: 35, Batch number: 66\n",
      "Accuracy on validation dataset: 2357/9723 (24.24%)\n",
      "\n",
      "Epoch: 36, Batch number: 0\n",
      "Accuracy on validation dataset: 2362/9723 (24.29%)\n",
      "\n",
      "Epoch: 36, Batch number: 10\n",
      "Accuracy on validation dataset: 2362/9723 (24.29%)\n",
      "\n",
      "Epoch: 36, Batch number: 20\n",
      "Accuracy on validation dataset: 2363/9723 (24.30%)\n",
      "\n",
      "Epoch: 36, Batch number: 30\n",
      "Accuracy on validation dataset: 2364/9723 (24.31%)\n",
      "\n",
      "Epoch: 36, Batch number: 40\n",
      "Accuracy on validation dataset: 2365/9723 (24.32%)\n",
      "\n",
      "Epoch: 36, Batch number: 50\n",
      "Accuracy on validation dataset: 2359/9723 (24.26%)\n",
      "\n",
      "Epoch: 36, Batch number: 60\n",
      "Accuracy on validation dataset: 2362/9723 (24.29%)\n",
      "\n",
      "Epoch: 36, Batch number: 70\n",
      "Accuracy on validation dataset: 2366/9723 (24.33%)\n",
      "\n",
      "Epoch: 37, Batch number: 4\n",
      "Accuracy on validation dataset: 2366/9723 (24.33%)\n",
      "\n",
      "Epoch: 37, Batch number: 14\n",
      "Accuracy on validation dataset: 2369/9723 (24.36%)\n",
      "\n",
      "Epoch: 37, Batch number: 24\n",
      "Accuracy on validation dataset: 2371/9723 (24.39%)\n",
      "\n",
      "Epoch: 37, Batch number: 34\n",
      "Accuracy on validation dataset: 2371/9723 (24.39%)\n",
      "\n",
      "Epoch: 37, Batch number: 44\n",
      "Accuracy on validation dataset: 2369/9723 (24.36%)\n",
      "\n",
      "Epoch: 37, Batch number: 54\n",
      "Accuracy on validation dataset: 2371/9723 (24.39%)\n",
      "\n",
      "Epoch: 37, Batch number: 64\n",
      "Accuracy on validation dataset: 2371/9723 (24.39%)\n",
      "\n",
      "Epoch: 37, Batch number: 74\n",
      "Accuracy on validation dataset: 2370/9723 (24.38%)\n",
      "\n",
      "Epoch: 38, Batch number: 8\n",
      "Accuracy on validation dataset: 2374/9723 (24.42%)\n",
      "\n",
      "Epoch: 38, Batch number: 18\n",
      "Accuracy on validation dataset: 2380/9723 (24.48%)\n",
      "\n",
      "Epoch: 38, Batch number: 28\n",
      "Accuracy on validation dataset: 2379/9723 (24.47%)\n",
      "\n",
      "Epoch: 38, Batch number: 38\n",
      "Accuracy on validation dataset: 2377/9723 (24.45%)\n",
      "\n",
      "Epoch: 38, Batch number: 48\n",
      "Accuracy on validation dataset: 2376/9723 (24.44%)\n",
      "\n",
      "Epoch: 38, Batch number: 58\n",
      "Accuracy on validation dataset: 2378/9723 (24.46%)\n",
      "\n",
      "Epoch: 38, Batch number: 68\n",
      "Accuracy on validation dataset: 2381/9723 (24.49%)\n",
      "\n",
      "Epoch: 39, Batch number: 2\n",
      "Accuracy on validation dataset: 2385/9723 (24.53%)\n",
      "\n",
      "Epoch: 39, Batch number: 12\n",
      "Accuracy on validation dataset: 2386/9723 (24.54%)\n",
      "\n",
      "Epoch: 39, Batch number: 22\n",
      "Accuracy on validation dataset: 2381/9723 (24.49%)\n",
      "\n",
      "Epoch: 39, Batch number: 32\n",
      "Accuracy on validation dataset: 2378/9723 (24.46%)\n",
      "\n",
      "Epoch: 39, Batch number: 42\n",
      "Accuracy on validation dataset: 2378/9723 (24.46%)\n",
      "\n",
      "Epoch: 39, Batch number: 52\n",
      "Accuracy on validation dataset: 2384/9723 (24.52%)\n",
      "\n",
      "Epoch: 39, Batch number: 62\n",
      "Accuracy on validation dataset: 2389/9723 (24.57%)\n",
      "\n",
      "Epoch: 39, Batch number: 72\n",
      "Accuracy on validation dataset: 2387/9723 (24.55%)\n",
      "\n",
      "Epoch: 40, Batch number: 6\n",
      "Accuracy on validation dataset: 2388/9723 (24.56%)\n",
      "\n",
      "Epoch: 40, Batch number: 16\n",
      "Accuracy on validation dataset: 2389/9723 (24.57%)\n",
      "\n",
      "Epoch: 40, Batch number: 26\n",
      "Accuracy on validation dataset: 2390/9723 (24.58%)\n",
      "\n",
      "Epoch: 40, Batch number: 36\n",
      "Accuracy on validation dataset: 2396/9723 (24.64%)\n",
      "\n",
      "Epoch: 40, Batch number: 46\n",
      "Accuracy on validation dataset: 2397/9723 (24.65%)\n",
      "\n",
      "Epoch: 40, Batch number: 56\n",
      "Accuracy on validation dataset: 2395/9723 (24.63%)\n",
      "\n",
      "Epoch: 40, Batch number: 66\n",
      "Accuracy on validation dataset: 2398/9723 (24.66%)\n",
      "\n",
      "Epoch: 41, Batch number: 0\n",
      "Accuracy on validation dataset: 2399/9723 (24.67%)\n",
      "\n",
      "Epoch: 41, Batch number: 10\n",
      "Accuracy on validation dataset: 2400/9723 (24.68%)\n",
      "\n",
      "Epoch: 41, Batch number: 20\n",
      "Accuracy on validation dataset: 2402/9723 (24.70%)\n",
      "\n",
      "Epoch: 41, Batch number: 30\n",
      "Accuracy on validation dataset: 2402/9723 (24.70%)\n",
      "\n",
      "Epoch: 41, Batch number: 40\n",
      "Accuracy on validation dataset: 2400/9723 (24.68%)\n",
      "\n",
      "Epoch: 41, Batch number: 50\n",
      "Accuracy on validation dataset: 2398/9723 (24.66%)\n",
      "\n",
      "Epoch: 41, Batch number: 60\n",
      "Accuracy on validation dataset: 2402/9723 (24.70%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Batch number: 70\n",
      "Accuracy on validation dataset: 2402/9723 (24.70%)\n",
      "\n",
      "Epoch: 42, Batch number: 4\n",
      "Accuracy on validation dataset: 2411/9723 (24.80%)\n",
      "\n",
      "Epoch: 42, Batch number: 14\n",
      "Accuracy on validation dataset: 2413/9723 (24.82%)\n",
      "\n",
      "Epoch: 42, Batch number: 24\n",
      "Accuracy on validation dataset: 2410/9723 (24.79%)\n",
      "\n",
      "Epoch: 42, Batch number: 34\n",
      "Accuracy on validation dataset: 2410/9723 (24.79%)\n",
      "\n",
      "Epoch: 42, Batch number: 44\n",
      "Accuracy on validation dataset: 2411/9723 (24.80%)\n",
      "\n",
      "Epoch: 42, Batch number: 54\n",
      "Accuracy on validation dataset: 2410/9723 (24.79%)\n",
      "\n",
      "Epoch: 42, Batch number: 64\n",
      "Accuracy on validation dataset: 2411/9723 (24.80%)\n",
      "\n",
      "Epoch: 42, Batch number: 74\n",
      "Accuracy on validation dataset: 2415/9723 (24.84%)\n",
      "\n",
      "Epoch: 43, Batch number: 8\n",
      "Accuracy on validation dataset: 2418/9723 (24.87%)\n",
      "\n",
      "Epoch: 43, Batch number: 18\n",
      "Accuracy on validation dataset: 2421/9723 (24.90%)\n",
      "\n",
      "Epoch: 43, Batch number: 28\n",
      "Accuracy on validation dataset: 2426/9723 (24.95%)\n",
      "\n",
      "Epoch: 43, Batch number: 38\n",
      "Accuracy on validation dataset: 2429/9723 (24.98%)\n",
      "\n",
      "Epoch: 43, Batch number: 48\n",
      "Accuracy on validation dataset: 2424/9723 (24.93%)\n",
      "\n",
      "Epoch: 43, Batch number: 58\n",
      "Accuracy on validation dataset: 2427/9723 (24.96%)\n",
      "\n",
      "Epoch: 43, Batch number: 68\n",
      "Accuracy on validation dataset: 2431/9723 (25.00%)\n",
      "\n",
      "Epoch: 44, Batch number: 2\n",
      "Accuracy on validation dataset: 2428/9723 (24.97%)\n",
      "\n",
      "Epoch: 44, Batch number: 12\n",
      "Accuracy on validation dataset: 2428/9723 (24.97%)\n",
      "\n",
      "Epoch: 44, Batch number: 22\n",
      "Accuracy on validation dataset: 2424/9723 (24.93%)\n",
      "\n",
      "Epoch: 44, Batch number: 32\n",
      "Accuracy on validation dataset: 2430/9723 (24.99%)\n",
      "\n",
      "Epoch: 44, Batch number: 42\n",
      "Accuracy on validation dataset: 2427/9723 (24.96%)\n",
      "\n",
      "Epoch: 44, Batch number: 52\n",
      "Accuracy on validation dataset: 2431/9723 (25.00%)\n",
      "\n",
      "Epoch: 44, Batch number: 62\n",
      "Accuracy on validation dataset: 2436/9723 (25.05%)\n",
      "\n",
      "Epoch: 44, Batch number: 72\n",
      "Accuracy on validation dataset: 2438/9723 (25.07%)\n",
      "\n",
      "Epoch: 45, Batch number: 6\n",
      "Accuracy on validation dataset: 2446/9723 (25.16%)\n",
      "\n",
      "Epoch: 45, Batch number: 16\n",
      "Accuracy on validation dataset: 2447/9723 (25.17%)\n",
      "\n",
      "Epoch: 45, Batch number: 26\n",
      "Accuracy on validation dataset: 2448/9723 (25.18%)\n",
      "\n",
      "Epoch: 45, Batch number: 36\n",
      "Accuracy on validation dataset: 2451/9723 (25.21%)\n",
      "\n",
      "Epoch: 45, Batch number: 46\n",
      "Accuracy on validation dataset: 2456/9723 (25.26%)\n",
      "\n",
      "Epoch: 45, Batch number: 56\n",
      "Accuracy on validation dataset: 2458/9723 (25.28%)\n",
      "\n",
      "Epoch: 45, Batch number: 66\n",
      "Accuracy on validation dataset: 2457/9723 (25.27%)\n",
      "\n",
      "Epoch: 46, Batch number: 0\n",
      "Accuracy on validation dataset: 2463/9723 (25.33%)\n",
      "\n",
      "Epoch: 46, Batch number: 10\n",
      "Accuracy on validation dataset: 2459/9723 (25.29%)\n",
      "\n",
      "Epoch: 46, Batch number: 20\n",
      "Accuracy on validation dataset: 2458/9723 (25.28%)\n",
      "\n",
      "Epoch: 46, Batch number: 30\n",
      "Accuracy on validation dataset: 2456/9723 (25.26%)\n",
      "\n",
      "Epoch: 46, Batch number: 40\n",
      "Accuracy on validation dataset: 2461/9723 (25.31%)\n",
      "\n",
      "Epoch: 46, Batch number: 50\n",
      "Accuracy on validation dataset: 2459/9723 (25.29%)\n",
      "\n",
      "Epoch: 46, Batch number: 60\n",
      "Accuracy on validation dataset: 2462/9723 (25.32%)\n",
      "\n",
      "Epoch: 46, Batch number: 70\n",
      "Accuracy on validation dataset: 2468/9723 (25.38%)\n",
      "\n",
      "Epoch: 47, Batch number: 4\n",
      "Accuracy on validation dataset: 2468/9723 (25.38%)\n",
      "\n",
      "Epoch: 47, Batch number: 14\n",
      "Accuracy on validation dataset: 2466/9723 (25.36%)\n",
      "\n",
      "Epoch: 47, Batch number: 24\n",
      "Accuracy on validation dataset: 2476/9723 (25.47%)\n",
      "\n",
      "Epoch: 47, Batch number: 34\n",
      "Accuracy on validation dataset: 2477/9723 (25.48%)\n",
      "\n",
      "Epoch: 47, Batch number: 44\n",
      "Accuracy on validation dataset: 2471/9723 (25.41%)\n",
      "\n",
      "Epoch: 47, Batch number: 54\n",
      "Accuracy on validation dataset: 2480/9723 (25.51%)\n",
      "\n",
      "Epoch: 47, Batch number: 64\n",
      "Accuracy on validation dataset: 2484/9723 (25.55%)\n",
      "\n",
      "Epoch: 47, Batch number: 74\n",
      "Accuracy on validation dataset: 2484/9723 (25.55%)\n",
      "\n",
      "Epoch: 48, Batch number: 8\n",
      "Accuracy on validation dataset: 2486/9723 (25.57%)\n",
      "\n",
      "Epoch: 48, Batch number: 18\n",
      "Accuracy on validation dataset: 2489/9723 (25.60%)\n",
      "\n",
      "Epoch: 48, Batch number: 28\n",
      "Accuracy on validation dataset: 2489/9723 (25.60%)\n",
      "\n",
      "Epoch: 48, Batch number: 38\n",
      "Accuracy on validation dataset: 2489/9723 (25.60%)\n",
      "\n",
      "Epoch: 48, Batch number: 48\n",
      "Accuracy on validation dataset: 2491/9723 (25.62%)\n",
      "\n",
      "Epoch: 48, Batch number: 58\n",
      "Accuracy on validation dataset: 2493/9723 (25.64%)\n",
      "\n",
      "Epoch: 48, Batch number: 68\n",
      "Accuracy on validation dataset: 2492/9723 (25.63%)\n",
      "\n",
      "Epoch: 49, Batch number: 2\n",
      "Accuracy on validation dataset: 2494/9723 (25.65%)\n",
      "\n",
      "Epoch: 49, Batch number: 12\n",
      "Accuracy on validation dataset: 2503/9723 (25.74%)\n",
      "\n",
      "Epoch: 49, Batch number: 22\n",
      "Accuracy on validation dataset: 2498/9723 (25.69%)\n",
      "\n",
      "Epoch: 49, Batch number: 32\n",
      "Accuracy on validation dataset: 2500/9723 (25.71%)\n",
      "\n",
      "Epoch: 49, Batch number: 42\n",
      "Accuracy on validation dataset: 2503/9723 (25.74%)\n",
      "\n",
      "Epoch: 49, Batch number: 52\n",
      "Accuracy on validation dataset: 2505/9723 (25.76%)\n",
      "\n",
      "Epoch: 49, Batch number: 62\n",
      "Accuracy on validation dataset: 2505/9723 (25.76%)\n",
      "\n",
      "Epoch: 49, Batch number: 72\n",
      "Accuracy on validation dataset: 2508/9723 (25.79%)\n",
      "\n",
      "Epoch: 50, Batch number: 6\n",
      "Accuracy on validation dataset: 2507/9723 (25.78%)\n",
      "\n",
      "Epoch: 50, Batch number: 16\n",
      "Accuracy on validation dataset: 2508/9723 (25.79%)\n",
      "\n",
      "Epoch: 50, Batch number: 26\n",
      "Accuracy on validation dataset: 2511/9723 (25.83%)\n",
      "\n",
      "Epoch: 50, Batch number: 36\n",
      "Accuracy on validation dataset: 2513/9723 (25.85%)\n",
      "\n",
      "Epoch: 50, Batch number: 46\n",
      "Accuracy on validation dataset: 2512/9723 (25.84%)\n",
      "\n",
      "Epoch: 50, Batch number: 56\n",
      "Accuracy on validation dataset: 2510/9723 (25.82%)\n",
      "\n",
      "Epoch: 50, Batch number: 66\n",
      "Accuracy on validation dataset: 2515/9723 (25.87%)\n",
      "\n",
      "Epoch: 51, Batch number: 0\n",
      "Accuracy on validation dataset: 2519/9723 (25.91%)\n",
      "\n",
      "Epoch: 51, Batch number: 10\n",
      "Accuracy on validation dataset: 2514/9723 (25.86%)\n",
      "\n",
      "Epoch: 51, Batch number: 20\n",
      "Accuracy on validation dataset: 2516/9723 (25.88%)\n",
      "\n",
      "Epoch: 51, Batch number: 30\n",
      "Accuracy on validation dataset: 2521/9723 (25.93%)\n",
      "\n",
      "Epoch: 51, Batch number: 40\n",
      "Accuracy on validation dataset: 2526/9723 (25.98%)\n",
      "\n",
      "Epoch: 51, Batch number: 50\n",
      "Accuracy on validation dataset: 2531/9723 (26.03%)\n",
      "\n",
      "Epoch: 51, Batch number: 60\n",
      "Accuracy on validation dataset: 2529/9723 (26.01%)\n",
      "\n",
      "Epoch: 51, Batch number: 70\n",
      "Accuracy on validation dataset: 2533/9723 (26.05%)\n",
      "\n",
      "Epoch: 52, Batch number: 4\n",
      "Accuracy on validation dataset: 2538/9723 (26.10%)\n",
      "\n",
      "Epoch: 52, Batch number: 14\n",
      "Accuracy on validation dataset: 2536/9723 (26.08%)\n",
      "\n",
      "Epoch: 52, Batch number: 24\n",
      "Accuracy on validation dataset: 2537/9723 (26.09%)\n",
      "\n",
      "Epoch: 52, Batch number: 34\n",
      "Accuracy on validation dataset: 2533/9723 (26.05%)\n",
      "\n",
      "Epoch: 52, Batch number: 44\n",
      "Accuracy on validation dataset: 2538/9723 (26.10%)\n",
      "\n",
      "Epoch: 52, Batch number: 54\n",
      "Accuracy on validation dataset: 2541/9723 (26.13%)\n",
      "\n",
      "Epoch: 52, Batch number: 64\n",
      "Accuracy on validation dataset: 2544/9723 (26.16%)\n",
      "\n",
      "Epoch: 52, Batch number: 74\n",
      "Accuracy on validation dataset: 2544/9723 (26.16%)\n",
      "\n",
      "Epoch: 53, Batch number: 8\n",
      "Accuracy on validation dataset: 2550/9723 (26.23%)\n",
      "\n",
      "Epoch: 53, Batch number: 18\n",
      "Accuracy on validation dataset: 2555/9723 (26.28%)\n",
      "\n",
      "Epoch: 53, Batch number: 28\n",
      "Accuracy on validation dataset: 2554/9723 (26.27%)\n",
      "\n",
      "Epoch: 53, Batch number: 38\n",
      "Accuracy on validation dataset: 2557/9723 (26.30%)\n",
      "\n",
      "Epoch: 53, Batch number: 48\n",
      "Accuracy on validation dataset: 2560/9723 (26.33%)\n",
      "\n",
      "Epoch: 53, Batch number: 58\n",
      "Accuracy on validation dataset: 2559/9723 (26.32%)\n",
      "\n",
      "Epoch: 53, Batch number: 68\n",
      "Accuracy on validation dataset: 2562/9723 (26.35%)\n",
      "\n",
      "Epoch: 54, Batch number: 2\n",
      "Accuracy on validation dataset: 2565/9723 (26.38%)\n",
      "\n",
      "Epoch: 54, Batch number: 12\n",
      "Accuracy on validation dataset: 2567/9723 (26.40%)\n",
      "\n",
      "Epoch: 54, Batch number: 22\n",
      "Accuracy on validation dataset: 2563/9723 (26.36%)\n",
      "\n",
      "Epoch: 54, Batch number: 32\n",
      "Accuracy on validation dataset: 2568/9723 (26.41%)\n",
      "\n",
      "Epoch: 54, Batch number: 42\n",
      "Accuracy on validation dataset: 2567/9723 (26.40%)\n",
      "\n",
      "Epoch: 54, Batch number: 52\n",
      "Accuracy on validation dataset: 2573/9723 (26.46%)\n",
      "\n",
      "Epoch: 54, Batch number: 62\n",
      "Accuracy on validation dataset: 2575/9723 (26.48%)\n",
      "\n",
      "Epoch: 54, Batch number: 72\n",
      "Accuracy on validation dataset: 2575/9723 (26.48%)\n",
      "\n",
      "Epoch: 55, Batch number: 6\n",
      "Accuracy on validation dataset: 2576/9723 (26.49%)\n",
      "\n",
      "Epoch: 55, Batch number: 16\n",
      "Accuracy on validation dataset: 2579/9723 (26.52%)\n",
      "\n",
      "Epoch: 55, Batch number: 26\n",
      "Accuracy on validation dataset: 2579/9723 (26.52%)\n",
      "\n",
      "Epoch: 55, Batch number: 36\n",
      "Accuracy on validation dataset: 2574/9723 (26.47%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Batch number: 46\n",
      "Accuracy on validation dataset: 2576/9723 (26.49%)\n",
      "\n",
      "Epoch: 55, Batch number: 56\n",
      "Accuracy on validation dataset: 2583/9723 (26.57%)\n",
      "\n",
      "Epoch: 55, Batch number: 66\n",
      "Accuracy on validation dataset: 2587/9723 (26.61%)\n",
      "\n",
      "Epoch: 56, Batch number: 0\n",
      "Accuracy on validation dataset: 2590/9723 (26.64%)\n",
      "\n",
      "Epoch: 56, Batch number: 10\n",
      "Accuracy on validation dataset: 2595/9723 (26.69%)\n",
      "\n",
      "Epoch: 56, Batch number: 20\n",
      "Accuracy on validation dataset: 2595/9723 (26.69%)\n",
      "\n",
      "Epoch: 56, Batch number: 30\n",
      "Accuracy on validation dataset: 2602/9723 (26.76%)\n",
      "\n",
      "Epoch: 56, Batch number: 40\n",
      "Accuracy on validation dataset: 2607/9723 (26.81%)\n",
      "\n",
      "Epoch: 56, Batch number: 50\n",
      "Accuracy on validation dataset: 2611/9723 (26.85%)\n",
      "\n",
      "Epoch: 56, Batch number: 60\n",
      "Accuracy on validation dataset: 2608/9723 (26.82%)\n",
      "\n",
      "Epoch: 56, Batch number: 70\n",
      "Accuracy on validation dataset: 2610/9723 (26.84%)\n",
      "\n",
      "Epoch: 57, Batch number: 4\n",
      "Accuracy on validation dataset: 2608/9723 (26.82%)\n",
      "\n",
      "Epoch: 57, Batch number: 14\n",
      "Accuracy on validation dataset: 2611/9723 (26.85%)\n",
      "\n",
      "Epoch: 57, Batch number: 24\n",
      "Accuracy on validation dataset: 2615/9723 (26.89%)\n",
      "\n",
      "Epoch: 57, Batch number: 34\n",
      "Accuracy on validation dataset: 2621/9723 (26.96%)\n",
      "\n",
      "Epoch: 57, Batch number: 44\n",
      "Accuracy on validation dataset: 2622/9723 (26.97%)\n",
      "\n",
      "Epoch: 57, Batch number: 54\n",
      "Accuracy on validation dataset: 2626/9723 (27.01%)\n",
      "\n",
      "Epoch: 57, Batch number: 64\n",
      "Accuracy on validation dataset: 2626/9723 (27.01%)\n",
      "\n",
      "Epoch: 57, Batch number: 74\n",
      "Accuracy on validation dataset: 2625/9723 (27.00%)\n",
      "\n",
      "Epoch: 58, Batch number: 8\n",
      "Accuracy on validation dataset: 2629/9723 (27.04%)\n",
      "\n",
      "Epoch: 58, Batch number: 18\n",
      "Accuracy on validation dataset: 2628/9723 (27.03%)\n",
      "\n",
      "Epoch: 58, Batch number: 28\n",
      "Accuracy on validation dataset: 2632/9723 (27.07%)\n",
      "\n",
      "Epoch: 58, Batch number: 38\n",
      "Accuracy on validation dataset: 2636/9723 (27.11%)\n",
      "\n",
      "Epoch: 58, Batch number: 48\n",
      "Accuracy on validation dataset: 2635/9723 (27.10%)\n",
      "\n",
      "Epoch: 58, Batch number: 58\n",
      "Accuracy on validation dataset: 2639/9723 (27.14%)\n",
      "\n",
      "Epoch: 58, Batch number: 68\n",
      "Accuracy on validation dataset: 2641/9723 (27.16%)\n",
      "\n",
      "Epoch: 59, Batch number: 2\n",
      "Accuracy on validation dataset: 2647/9723 (27.22%)\n",
      "\n",
      "Epoch: 59, Batch number: 12\n",
      "Accuracy on validation dataset: 2647/9723 (27.22%)\n",
      "\n",
      "Epoch: 59, Batch number: 22\n",
      "Accuracy on validation dataset: 2650/9723 (27.25%)\n",
      "\n",
      "Epoch: 59, Batch number: 32\n",
      "Accuracy on validation dataset: 2654/9723 (27.30%)\n",
      "\n",
      "Epoch: 59, Batch number: 42\n",
      "Accuracy on validation dataset: 2655/9723 (27.31%)\n",
      "\n",
      "Epoch: 59, Batch number: 52\n",
      "Accuracy on validation dataset: 2655/9723 (27.31%)\n",
      "\n",
      "Epoch: 59, Batch number: 62\n",
      "Accuracy on validation dataset: 2651/9723 (27.27%)\n",
      "\n",
      "Epoch: 59, Batch number: 72\n",
      "Accuracy on validation dataset: 2655/9723 (27.31%)\n",
      "\n",
      "Epoch: 60, Batch number: 6\n",
      "Accuracy on validation dataset: 2656/9723 (27.32%)\n",
      "\n",
      "Epoch: 60, Batch number: 16\n",
      "Accuracy on validation dataset: 2656/9723 (27.32%)\n",
      "\n",
      "Epoch: 60, Batch number: 26\n",
      "Accuracy on validation dataset: 2658/9723 (27.34%)\n",
      "\n",
      "Epoch: 60, Batch number: 36\n",
      "Accuracy on validation dataset: 2659/9723 (27.35%)\n",
      "\n",
      "Epoch: 60, Batch number: 46\n",
      "Accuracy on validation dataset: 2662/9723 (27.38%)\n",
      "\n",
      "Epoch: 60, Batch number: 56\n",
      "Accuracy on validation dataset: 2662/9723 (27.38%)\n",
      "\n",
      "Epoch: 60, Batch number: 66\n",
      "Accuracy on validation dataset: 2661/9723 (27.37%)\n",
      "\n",
      "Epoch: 61, Batch number: 0\n",
      "Accuracy on validation dataset: 2665/9723 (27.41%)\n",
      "\n",
      "Epoch: 61, Batch number: 10\n",
      "Accuracy on validation dataset: 2672/9723 (27.48%)\n",
      "\n",
      "Epoch: 61, Batch number: 20\n",
      "Accuracy on validation dataset: 2676/9723 (27.52%)\n",
      "\n",
      "Epoch: 61, Batch number: 30\n",
      "Accuracy on validation dataset: 2680/9723 (27.56%)\n",
      "\n",
      "Epoch: 61, Batch number: 40\n",
      "Accuracy on validation dataset: 2678/9723 (27.54%)\n",
      "\n",
      "Epoch: 61, Batch number: 50\n",
      "Accuracy on validation dataset: 2675/9723 (27.51%)\n",
      "\n",
      "Epoch: 61, Batch number: 60\n",
      "Accuracy on validation dataset: 2677/9723 (27.53%)\n",
      "\n",
      "Epoch: 61, Batch number: 70\n",
      "Accuracy on validation dataset: 2679/9723 (27.55%)\n",
      "\n",
      "Epoch: 62, Batch number: 4\n",
      "Accuracy on validation dataset: 2690/9723 (27.67%)\n",
      "\n",
      "Epoch: 62, Batch number: 14\n",
      "Accuracy on validation dataset: 2690/9723 (27.67%)\n",
      "\n",
      "Epoch: 62, Batch number: 24\n",
      "Accuracy on validation dataset: 2690/9723 (27.67%)\n",
      "\n",
      "Epoch: 62, Batch number: 34\n",
      "Accuracy on validation dataset: 2687/9723 (27.64%)\n",
      "\n",
      "Epoch: 62, Batch number: 44\n",
      "Accuracy on validation dataset: 2687/9723 (27.64%)\n",
      "\n",
      "Epoch: 62, Batch number: 54\n",
      "Accuracy on validation dataset: 2693/9723 (27.70%)\n",
      "\n",
      "Epoch: 62, Batch number: 64\n",
      "Accuracy on validation dataset: 2700/9723 (27.77%)\n",
      "\n",
      "Epoch: 62, Batch number: 74\n",
      "Accuracy on validation dataset: 2699/9723 (27.76%)\n",
      "\n",
      "Epoch: 63, Batch number: 8\n",
      "Accuracy on validation dataset: 2704/9723 (27.81%)\n",
      "\n",
      "Epoch: 63, Batch number: 18\n",
      "Accuracy on validation dataset: 2702/9723 (27.79%)\n",
      "\n",
      "Epoch: 63, Batch number: 28\n",
      "Accuracy on validation dataset: 2701/9723 (27.78%)\n",
      "\n",
      "Epoch: 63, Batch number: 38\n",
      "Accuracy on validation dataset: 2710/9723 (27.87%)\n",
      "\n",
      "Epoch: 63, Batch number: 48\n",
      "Accuracy on validation dataset: 2713/9723 (27.90%)\n",
      "\n",
      "Epoch: 63, Batch number: 58\n",
      "Accuracy on validation dataset: 2712/9723 (27.89%)\n",
      "\n",
      "Epoch: 63, Batch number: 68\n",
      "Accuracy on validation dataset: 2714/9723 (27.91%)\n",
      "\n",
      "Epoch: 64, Batch number: 2\n",
      "Accuracy on validation dataset: 2720/9723 (27.97%)\n",
      "\n",
      "Epoch: 64, Batch number: 12\n",
      "Accuracy on validation dataset: 2724/9723 (28.02%)\n",
      "\n",
      "Epoch: 64, Batch number: 22\n",
      "Accuracy on validation dataset: 2721/9723 (27.99%)\n",
      "\n",
      "Epoch: 64, Batch number: 32\n",
      "Accuracy on validation dataset: 2721/9723 (27.99%)\n",
      "\n",
      "Epoch: 64, Batch number: 42\n",
      "Accuracy on validation dataset: 2724/9723 (28.02%)\n",
      "\n",
      "Epoch: 64, Batch number: 52\n",
      "Accuracy on validation dataset: 2723/9723 (28.01%)\n",
      "\n",
      "Epoch: 64, Batch number: 62\n",
      "Accuracy on validation dataset: 2728/9723 (28.06%)\n",
      "\n",
      "Epoch: 64, Batch number: 72\n",
      "Accuracy on validation dataset: 2739/9723 (28.17%)\n",
      "\n",
      "Epoch: 65, Batch number: 6\n",
      "Accuracy on validation dataset: 2736/9723 (28.14%)\n",
      "\n",
      "Epoch: 65, Batch number: 16\n",
      "Accuracy on validation dataset: 2739/9723 (28.17%)\n",
      "\n",
      "Epoch: 65, Batch number: 26\n",
      "Accuracy on validation dataset: 2738/9723 (28.16%)\n",
      "\n",
      "Epoch: 65, Batch number: 36\n",
      "Accuracy on validation dataset: 2742/9723 (28.20%)\n",
      "\n",
      "Epoch: 65, Batch number: 46\n",
      "Accuracy on validation dataset: 2745/9723 (28.23%)\n",
      "\n",
      "Epoch: 65, Batch number: 56\n",
      "Accuracy on validation dataset: 2750/9723 (28.28%)\n",
      "\n",
      "Epoch: 65, Batch number: 66\n",
      "Accuracy on validation dataset: 2748/9723 (28.26%)\n",
      "\n",
      "Epoch: 66, Batch number: 0\n",
      "Accuracy on validation dataset: 2751/9723 (28.29%)\n",
      "\n",
      "Epoch: 66, Batch number: 10\n",
      "Accuracy on validation dataset: 2754/9723 (28.32%)\n",
      "\n",
      "Epoch: 66, Batch number: 20\n",
      "Accuracy on validation dataset: 2757/9723 (28.36%)\n",
      "\n",
      "Epoch: 66, Batch number: 30\n",
      "Accuracy on validation dataset: 2765/9723 (28.44%)\n",
      "\n",
      "Epoch: 66, Batch number: 40\n",
      "Accuracy on validation dataset: 2776/9723 (28.55%)\n",
      "\n",
      "Epoch: 66, Batch number: 50\n",
      "Accuracy on validation dataset: 2781/9723 (28.60%)\n",
      "\n",
      "Epoch: 66, Batch number: 60\n",
      "Accuracy on validation dataset: 2777/9723 (28.56%)\n",
      "\n",
      "Epoch: 66, Batch number: 70\n",
      "Accuracy on validation dataset: 2777/9723 (28.56%)\n",
      "\n",
      "Epoch: 67, Batch number: 4\n",
      "Accuracy on validation dataset: 2785/9723 (28.64%)\n",
      "\n",
      "Epoch: 67, Batch number: 14\n",
      "Accuracy on validation dataset: 2783/9723 (28.62%)\n",
      "\n",
      "Epoch: 67, Batch number: 24\n",
      "Accuracy on validation dataset: 2788/9723 (28.67%)\n",
      "\n",
      "Epoch: 67, Batch number: 34\n",
      "Accuracy on validation dataset: 2796/9723 (28.76%)\n",
      "\n",
      "Epoch: 67, Batch number: 44\n",
      "Accuracy on validation dataset: 2800/9723 (28.80%)\n",
      "\n",
      "Epoch: 67, Batch number: 54\n",
      "Accuracy on validation dataset: 2805/9723 (28.85%)\n",
      "\n",
      "Epoch: 67, Batch number: 64\n",
      "Accuracy on validation dataset: 2801/9723 (28.81%)\n",
      "\n",
      "Epoch: 67, Batch number: 74\n",
      "Accuracy on validation dataset: 2810/9723 (28.90%)\n",
      "\n",
      "Epoch: 68, Batch number: 8\n",
      "Accuracy on validation dataset: 2809/9723 (28.89%)\n",
      "\n",
      "Epoch: 68, Batch number: 18\n",
      "Accuracy on validation dataset: 2809/9723 (28.89%)\n",
      "\n",
      "Epoch: 68, Batch number: 28\n",
      "Accuracy on validation dataset: 2811/9723 (28.91%)\n",
      "\n",
      "Epoch: 68, Batch number: 38\n",
      "Accuracy on validation dataset: 2815/9723 (28.95%)\n",
      "\n",
      "Epoch: 68, Batch number: 48\n",
      "Accuracy on validation dataset: 2820/9723 (29.00%)\n",
      "\n",
      "Epoch: 68, Batch number: 58\n",
      "Accuracy on validation dataset: 2821/9723 (29.01%)\n",
      "\n",
      "Epoch: 68, Batch number: 68\n",
      "Accuracy on validation dataset: 2824/9723 (29.04%)\n",
      "\n",
      "Epoch: 69, Batch number: 2\n",
      "Accuracy on validation dataset: 2831/9723 (29.12%)\n",
      "\n",
      "Epoch: 69, Batch number: 12\n",
      "Accuracy on validation dataset: 2831/9723 (29.12%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Batch number: 22\n",
      "Accuracy on validation dataset: 2832/9723 (29.13%)\n",
      "\n",
      "Epoch: 69, Batch number: 32\n",
      "Accuracy on validation dataset: 2830/9723 (29.11%)\n",
      "\n",
      "Epoch: 69, Batch number: 42\n",
      "Accuracy on validation dataset: 2833/9723 (29.14%)\n",
      "\n",
      "Epoch: 69, Batch number: 52\n",
      "Accuracy on validation dataset: 2837/9723 (29.18%)\n",
      "\n",
      "Epoch: 69, Batch number: 62\n",
      "Accuracy on validation dataset: 2838/9723 (29.19%)\n",
      "\n",
      "Epoch: 69, Batch number: 72\n",
      "Accuracy on validation dataset: 2841/9723 (29.22%)\n",
      "\n",
      "Epoch: 70, Batch number: 6\n",
      "Accuracy on validation dataset: 2848/9723 (29.29%)\n",
      "\n",
      "Epoch: 70, Batch number: 16\n",
      "Accuracy on validation dataset: 2846/9723 (29.27%)\n",
      "\n",
      "Epoch: 70, Batch number: 26\n",
      "Accuracy on validation dataset: 2850/9723 (29.31%)\n",
      "\n",
      "Epoch: 70, Batch number: 36\n",
      "Accuracy on validation dataset: 2855/9723 (29.36%)\n",
      "\n",
      "Epoch: 70, Batch number: 46\n",
      "Accuracy on validation dataset: 2858/9723 (29.39%)\n",
      "\n",
      "Epoch: 70, Batch number: 56\n",
      "Accuracy on validation dataset: 2860/9723 (29.41%)\n",
      "\n",
      "Epoch: 70, Batch number: 66\n",
      "Accuracy on validation dataset: 2863/9723 (29.45%)\n",
      "\n",
      "Epoch: 71, Batch number: 0\n",
      "Accuracy on validation dataset: 2861/9723 (29.43%)\n",
      "\n",
      "Epoch: 71, Batch number: 10\n",
      "Accuracy on validation dataset: 2862/9723 (29.44%)\n",
      "\n",
      "Epoch: 71, Batch number: 20\n",
      "Accuracy on validation dataset: 2866/9723 (29.48%)\n",
      "\n",
      "Epoch: 71, Batch number: 30\n",
      "Accuracy on validation dataset: 2867/9723 (29.49%)\n",
      "\n",
      "Epoch: 71, Batch number: 40\n",
      "Accuracy on validation dataset: 2873/9723 (29.55%)\n",
      "\n",
      "Epoch: 71, Batch number: 50\n",
      "Accuracy on validation dataset: 2875/9723 (29.57%)\n",
      "\n",
      "Epoch: 71, Batch number: 60\n",
      "Accuracy on validation dataset: 2881/9723 (29.63%)\n",
      "\n",
      "Epoch: 71, Batch number: 70\n",
      "Accuracy on validation dataset: 2884/9723 (29.66%)\n",
      "\n",
      "Epoch: 72, Batch number: 4\n",
      "Accuracy on validation dataset: 2886/9723 (29.68%)\n",
      "\n",
      "Epoch: 72, Batch number: 14\n",
      "Accuracy on validation dataset: 2889/9723 (29.71%)\n",
      "\n",
      "Epoch: 72, Batch number: 24\n",
      "Accuracy on validation dataset: 2879/9723 (29.61%)\n",
      "\n",
      "Epoch: 72, Batch number: 34\n",
      "Accuracy on validation dataset: 2879/9723 (29.61%)\n",
      "\n",
      "Epoch: 72, Batch number: 44\n",
      "Accuracy on validation dataset: 2890/9723 (29.72%)\n",
      "\n",
      "Epoch: 72, Batch number: 54\n",
      "Accuracy on validation dataset: 2893/9723 (29.75%)\n",
      "\n",
      "Epoch: 72, Batch number: 64\n",
      "Accuracy on validation dataset: 2896/9723 (29.79%)\n",
      "\n",
      "Epoch: 72, Batch number: 74\n",
      "Accuracy on validation dataset: 2901/9723 (29.84%)\n",
      "\n",
      "Epoch: 73, Batch number: 8\n",
      "Accuracy on validation dataset: 2901/9723 (29.84%)\n",
      "\n",
      "Epoch: 73, Batch number: 18\n",
      "Accuracy on validation dataset: 2900/9723 (29.83%)\n",
      "\n",
      "Epoch: 73, Batch number: 28\n",
      "Accuracy on validation dataset: 2901/9723 (29.84%)\n",
      "\n",
      "Epoch: 73, Batch number: 38\n",
      "Accuracy on validation dataset: 2905/9723 (29.88%)\n",
      "\n",
      "Epoch: 73, Batch number: 48\n",
      "Accuracy on validation dataset: 2911/9723 (29.94%)\n",
      "\n",
      "Epoch: 73, Batch number: 58\n",
      "Accuracy on validation dataset: 2920/9723 (30.03%)\n",
      "\n",
      "Epoch: 73, Batch number: 68\n",
      "Accuracy on validation dataset: 2921/9723 (30.04%)\n",
      "\n",
      "Epoch: 74, Batch number: 2\n",
      "Accuracy on validation dataset: 2923/9723 (30.06%)\n",
      "\n",
      "Epoch: 74, Batch number: 12\n",
      "Accuracy on validation dataset: 2927/9723 (30.10%)\n",
      "\n",
      "Epoch: 74, Batch number: 22\n",
      "Accuracy on validation dataset: 2928/9723 (30.11%)\n",
      "\n",
      "Epoch: 74, Batch number: 32\n",
      "Accuracy on validation dataset: 2931/9723 (30.15%)\n",
      "\n",
      "Epoch: 74, Batch number: 42\n",
      "Accuracy on validation dataset: 2931/9723 (30.15%)\n",
      "\n",
      "Epoch: 74, Batch number: 52\n",
      "Accuracy on validation dataset: 2932/9723 (30.16%)\n",
      "\n",
      "Epoch: 74, Batch number: 62\n",
      "Accuracy on validation dataset: 2936/9723 (30.20%)\n",
      "\n",
      "Epoch: 74, Batch number: 72\n",
      "Accuracy on validation dataset: 2938/9723 (30.22%)\n",
      "\n",
      "Epoch: 75, Batch number: 6\n",
      "Accuracy on validation dataset: 2940/9723 (30.24%)\n",
      "\n",
      "Epoch: 75, Batch number: 16\n",
      "Accuracy on validation dataset: 2939/9723 (30.23%)\n",
      "\n",
      "Epoch: 75, Batch number: 26\n",
      "Accuracy on validation dataset: 2944/9723 (30.28%)\n",
      "\n",
      "Epoch: 75, Batch number: 36\n",
      "Accuracy on validation dataset: 2945/9723 (30.29%)\n",
      "\n",
      "Epoch: 75, Batch number: 46\n",
      "Accuracy on validation dataset: 2953/9723 (30.37%)\n",
      "\n",
      "Epoch: 75, Batch number: 56\n",
      "Accuracy on validation dataset: 2950/9723 (30.34%)\n",
      "\n",
      "Epoch: 75, Batch number: 66\n",
      "Accuracy on validation dataset: 2959/9723 (30.43%)\n",
      "\n",
      "Epoch: 76, Batch number: 0\n",
      "Accuracy on validation dataset: 2958/9723 (30.42%)\n",
      "\n",
      "Epoch: 76, Batch number: 10\n",
      "Accuracy on validation dataset: 2964/9723 (30.48%)\n",
      "\n",
      "Epoch: 76, Batch number: 20\n",
      "Accuracy on validation dataset: 2956/9723 (30.40%)\n",
      "\n",
      "Epoch: 76, Batch number: 30\n",
      "Accuracy on validation dataset: 2966/9723 (30.50%)\n",
      "\n",
      "Epoch: 76, Batch number: 40\n",
      "Accuracy on validation dataset: 2965/9723 (30.49%)\n",
      "\n",
      "Epoch: 76, Batch number: 50\n",
      "Accuracy on validation dataset: 2971/9723 (30.56%)\n",
      "\n",
      "Epoch: 76, Batch number: 60\n",
      "Accuracy on validation dataset: 2972/9723 (30.57%)\n",
      "\n",
      "Epoch: 76, Batch number: 70\n",
      "Accuracy on validation dataset: 2977/9723 (30.62%)\n",
      "\n",
      "Epoch: 77, Batch number: 4\n",
      "Accuracy on validation dataset: 2980/9723 (30.65%)\n",
      "\n",
      "Epoch: 77, Batch number: 14\n",
      "Accuracy on validation dataset: 2985/9723 (30.70%)\n",
      "\n",
      "Epoch: 77, Batch number: 24\n",
      "Accuracy on validation dataset: 2985/9723 (30.70%)\n",
      "\n",
      "Epoch: 77, Batch number: 34\n",
      "Accuracy on validation dataset: 2986/9723 (30.71%)\n",
      "\n",
      "Epoch: 77, Batch number: 44\n",
      "Accuracy on validation dataset: 2993/9723 (30.78%)\n",
      "\n",
      "Epoch: 77, Batch number: 54\n",
      "Accuracy on validation dataset: 2990/9723 (30.75%)\n",
      "\n",
      "Epoch: 77, Batch number: 64\n",
      "Accuracy on validation dataset: 2994/9723 (30.79%)\n",
      "\n",
      "Epoch: 77, Batch number: 74\n",
      "Accuracy on validation dataset: 2993/9723 (30.78%)\n",
      "\n",
      "Epoch: 78, Batch number: 8\n",
      "Accuracy on validation dataset: 2998/9723 (30.83%)\n",
      "\n",
      "Epoch: 78, Batch number: 18\n",
      "Accuracy on validation dataset: 3000/9723 (30.85%)\n",
      "\n",
      "Epoch: 78, Batch number: 28\n",
      "Accuracy on validation dataset: 2999/9723 (30.84%)\n",
      "\n",
      "Epoch: 78, Batch number: 38\n",
      "Accuracy on validation dataset: 2999/9723 (30.84%)\n",
      "\n",
      "Epoch: 78, Batch number: 48\n",
      "Accuracy on validation dataset: 3000/9723 (30.85%)\n",
      "\n",
      "Epoch: 78, Batch number: 58\n",
      "Accuracy on validation dataset: 3005/9723 (30.91%)\n",
      "\n",
      "Epoch: 78, Batch number: 68\n",
      "Accuracy on validation dataset: 3002/9723 (30.88%)\n",
      "\n",
      "Epoch: 79, Batch number: 2\n",
      "Accuracy on validation dataset: 3007/9723 (30.93%)\n",
      "\n",
      "Epoch: 79, Batch number: 12\n",
      "Accuracy on validation dataset: 3007/9723 (30.93%)\n",
      "\n",
      "Epoch: 79, Batch number: 22\n",
      "Accuracy on validation dataset: 3012/9723 (30.98%)\n",
      "\n",
      "Epoch: 79, Batch number: 32\n",
      "Accuracy on validation dataset: 3017/9723 (31.03%)\n",
      "\n",
      "Epoch: 79, Batch number: 42\n",
      "Accuracy on validation dataset: 3019/9723 (31.05%)\n",
      "\n",
      "Epoch: 79, Batch number: 52\n",
      "Accuracy on validation dataset: 3017/9723 (31.03%)\n",
      "\n",
      "Epoch: 79, Batch number: 62\n",
      "Accuracy on validation dataset: 3022/9723 (31.08%)\n",
      "\n",
      "Epoch: 79, Batch number: 72\n",
      "Accuracy on validation dataset: 3022/9723 (31.08%)\n",
      "\n",
      "Epoch: 80, Batch number: 6\n",
      "Accuracy on validation dataset: 3027/9723 (31.13%)\n",
      "\n",
      "Epoch: 80, Batch number: 16\n",
      "Accuracy on validation dataset: 3033/9723 (31.19%)\n",
      "\n",
      "Epoch: 80, Batch number: 26\n",
      "Accuracy on validation dataset: 3035/9723 (31.21%)\n",
      "\n",
      "Epoch: 80, Batch number: 36\n",
      "Accuracy on validation dataset: 3045/9723 (31.32%)\n",
      "\n",
      "Epoch: 80, Batch number: 46\n",
      "Accuracy on validation dataset: 3046/9723 (31.33%)\n",
      "\n",
      "Epoch: 80, Batch number: 56\n",
      "Accuracy on validation dataset: 3046/9723 (31.33%)\n",
      "\n",
      "Epoch: 80, Batch number: 66\n",
      "Accuracy on validation dataset: 3045/9723 (31.32%)\n",
      "\n",
      "Epoch: 81, Batch number: 0\n",
      "Accuracy on validation dataset: 3049/9723 (31.36%)\n",
      "\n",
      "Epoch: 81, Batch number: 10\n",
      "Accuracy on validation dataset: 3049/9723 (31.36%)\n",
      "\n",
      "Epoch: 81, Batch number: 20\n",
      "Accuracy on validation dataset: 3053/9723 (31.40%)\n",
      "\n",
      "Epoch: 81, Batch number: 30\n",
      "Accuracy on validation dataset: 3048/9723 (31.35%)\n",
      "\n",
      "Epoch: 81, Batch number: 40\n",
      "Accuracy on validation dataset: 3046/9723 (31.33%)\n",
      "\n",
      "Epoch: 81, Batch number: 50\n",
      "Accuracy on validation dataset: 3050/9723 (31.37%)\n",
      "\n",
      "Epoch: 81, Batch number: 60\n",
      "Accuracy on validation dataset: 3052/9723 (31.39%)\n",
      "\n",
      "Epoch: 81, Batch number: 70\n",
      "Accuracy on validation dataset: 3059/9723 (31.46%)\n",
      "\n",
      "Epoch: 82, Batch number: 4\n",
      "Accuracy on validation dataset: 3065/9723 (31.52%)\n",
      "\n",
      "Epoch: 82, Batch number: 14\n",
      "Accuracy on validation dataset: 3070/9723 (31.57%)\n",
      "\n",
      "Epoch: 82, Batch number: 24\n",
      "Accuracy on validation dataset: 3072/9723 (31.60%)\n",
      "\n",
      "Epoch: 82, Batch number: 34\n",
      "Accuracy on validation dataset: 3071/9723 (31.58%)\n",
      "\n",
      "Epoch: 82, Batch number: 44\n",
      "Accuracy on validation dataset: 3072/9723 (31.60%)\n",
      "\n",
      "Epoch: 82, Batch number: 54\n",
      "Accuracy on validation dataset: 3073/9723 (31.61%)\n",
      "\n",
      "Epoch: 82, Batch number: 64\n",
      "Accuracy on validation dataset: 3074/9723 (31.62%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82, Batch number: 74\n",
      "Accuracy on validation dataset: 3082/9723 (31.70%)\n",
      "\n",
      "Epoch: 83, Batch number: 8\n",
      "Accuracy on validation dataset: 3084/9723 (31.72%)\n",
      "\n",
      "Epoch: 83, Batch number: 18\n",
      "Accuracy on validation dataset: 3080/9723 (31.68%)\n",
      "\n",
      "Epoch: 83, Batch number: 28\n",
      "Accuracy on validation dataset: 3086/9723 (31.74%)\n",
      "\n",
      "Epoch: 83, Batch number: 38\n",
      "Accuracy on validation dataset: 3085/9723 (31.73%)\n",
      "\n",
      "Epoch: 83, Batch number: 48\n",
      "Accuracy on validation dataset: 3094/9723 (31.82%)\n",
      "\n",
      "Epoch: 83, Batch number: 58\n",
      "Accuracy on validation dataset: 3093/9723 (31.81%)\n",
      "\n",
      "Epoch: 83, Batch number: 68\n",
      "Accuracy on validation dataset: 3099/9723 (31.87%)\n",
      "\n",
      "Epoch: 84, Batch number: 2\n",
      "Accuracy on validation dataset: 3104/9723 (31.92%)\n",
      "\n",
      "Epoch: 84, Batch number: 12\n",
      "Accuracy on validation dataset: 3104/9723 (31.92%)\n",
      "\n",
      "Epoch: 84, Batch number: 22\n",
      "Accuracy on validation dataset: 3105/9723 (31.93%)\n",
      "\n",
      "Epoch: 84, Batch number: 32\n",
      "Accuracy on validation dataset: 3112/9723 (32.01%)\n",
      "\n",
      "Epoch: 84, Batch number: 42\n",
      "Accuracy on validation dataset: 3115/9723 (32.04%)\n",
      "\n",
      "Epoch: 84, Batch number: 52\n",
      "Accuracy on validation dataset: 3118/9723 (32.07%)\n",
      "\n",
      "Epoch: 84, Batch number: 62\n",
      "Accuracy on validation dataset: 3121/9723 (32.10%)\n",
      "\n",
      "Epoch: 84, Batch number: 72\n",
      "Accuracy on validation dataset: 3128/9723 (32.17%)\n",
      "\n",
      "Epoch: 85, Batch number: 6\n",
      "Accuracy on validation dataset: 3124/9723 (32.13%)\n",
      "\n",
      "Epoch: 85, Batch number: 16\n",
      "Accuracy on validation dataset: 3121/9723 (32.10%)\n",
      "\n",
      "Epoch: 85, Batch number: 26\n",
      "Accuracy on validation dataset: 3124/9723 (32.13%)\n",
      "\n",
      "Epoch: 85, Batch number: 36\n",
      "Accuracy on validation dataset: 3125/9723 (32.14%)\n",
      "\n",
      "Epoch: 85, Batch number: 46\n",
      "Accuracy on validation dataset: 3126/9723 (32.15%)\n",
      "\n",
      "Epoch: 85, Batch number: 56\n",
      "Accuracy on validation dataset: 3125/9723 (32.14%)\n",
      "\n",
      "Epoch: 85, Batch number: 66\n",
      "Accuracy on validation dataset: 3137/9723 (32.26%)\n",
      "\n",
      "Epoch: 86, Batch number: 0\n",
      "Accuracy on validation dataset: 3141/9723 (32.30%)\n",
      "\n",
      "Epoch: 86, Batch number: 10\n",
      "Accuracy on validation dataset: 3144/9723 (32.34%)\n",
      "\n",
      "Epoch: 86, Batch number: 20\n",
      "Accuracy on validation dataset: 3142/9723 (32.32%)\n",
      "\n",
      "Epoch: 86, Batch number: 30\n",
      "Accuracy on validation dataset: 3140/9723 (32.29%)\n",
      "\n",
      "Epoch: 86, Batch number: 40\n",
      "Accuracy on validation dataset: 3140/9723 (32.29%)\n",
      "\n",
      "Epoch: 86, Batch number: 50\n",
      "Accuracy on validation dataset: 3141/9723 (32.30%)\n",
      "\n",
      "Epoch: 86, Batch number: 60\n",
      "Accuracy on validation dataset: 3145/9723 (32.35%)\n",
      "\n",
      "Epoch: 86, Batch number: 70\n",
      "Accuracy on validation dataset: 3149/9723 (32.39%)\n",
      "\n",
      "Epoch: 87, Batch number: 4\n",
      "Accuracy on validation dataset: 3157/9723 (32.47%)\n",
      "\n",
      "Epoch: 87, Batch number: 14\n",
      "Accuracy on validation dataset: 3158/9723 (32.48%)\n",
      "\n",
      "Epoch: 87, Batch number: 24\n",
      "Accuracy on validation dataset: 3162/9723 (32.52%)\n",
      "\n",
      "Epoch: 87, Batch number: 34\n",
      "Accuracy on validation dataset: 3169/9723 (32.59%)\n",
      "\n",
      "Epoch: 87, Batch number: 44\n",
      "Accuracy on validation dataset: 3178/9723 (32.69%)\n",
      "\n",
      "Epoch: 87, Batch number: 54\n",
      "Accuracy on validation dataset: 3178/9723 (32.69%)\n",
      "\n",
      "Epoch: 87, Batch number: 64\n",
      "Accuracy on validation dataset: 3186/9723 (32.77%)\n",
      "\n",
      "Epoch: 87, Batch number: 74\n",
      "Accuracy on validation dataset: 3184/9723 (32.75%)\n",
      "\n",
      "Epoch: 88, Batch number: 8\n",
      "Accuracy on validation dataset: 3184/9723 (32.75%)\n",
      "\n",
      "Epoch: 88, Batch number: 18\n",
      "Accuracy on validation dataset: 3184/9723 (32.75%)\n",
      "\n",
      "Epoch: 88, Batch number: 28\n",
      "Accuracy on validation dataset: 3177/9723 (32.68%)\n",
      "\n",
      "Epoch: 88, Batch number: 38\n",
      "Accuracy on validation dataset: 3180/9723 (32.71%)\n",
      "\n",
      "Epoch: 88, Batch number: 48\n",
      "Accuracy on validation dataset: 3184/9723 (32.75%)\n",
      "\n",
      "Epoch: 88, Batch number: 58\n",
      "Accuracy on validation dataset: 3191/9723 (32.82%)\n",
      "\n",
      "Epoch: 88, Batch number: 68\n",
      "Accuracy on validation dataset: 3195/9723 (32.86%)\n",
      "\n",
      "Epoch: 89, Batch number: 2\n",
      "Accuracy on validation dataset: 3199/9723 (32.90%)\n",
      "\n",
      "Epoch: 89, Batch number: 12\n",
      "Accuracy on validation dataset: 3198/9723 (32.89%)\n",
      "\n",
      "Epoch: 89, Batch number: 22\n",
      "Accuracy on validation dataset: 3195/9723 (32.86%)\n",
      "\n",
      "Epoch: 89, Batch number: 32\n",
      "Accuracy on validation dataset: 3199/9723 (32.90%)\n",
      "\n",
      "Epoch: 89, Batch number: 42\n",
      "Accuracy on validation dataset: 3203/9723 (32.94%)\n",
      "\n",
      "Epoch: 89, Batch number: 52\n",
      "Accuracy on validation dataset: 3206/9723 (32.97%)\n",
      "\n",
      "Epoch: 89, Batch number: 62\n",
      "Accuracy on validation dataset: 3211/9723 (33.02%)\n",
      "\n",
      "Epoch: 89, Batch number: 72\n",
      "Accuracy on validation dataset: 3215/9723 (33.07%)\n",
      "\n",
      "Epoch: 90, Batch number: 6\n",
      "Accuracy on validation dataset: 3215/9723 (33.07%)\n",
      "\n",
      "Epoch: 90, Batch number: 16\n",
      "Accuracy on validation dataset: 3218/9723 (33.10%)\n",
      "\n",
      "Epoch: 90, Batch number: 26\n",
      "Accuracy on validation dataset: 3215/9723 (33.07%)\n",
      "\n",
      "Epoch: 90, Batch number: 36\n",
      "Accuracy on validation dataset: 3219/9723 (33.11%)\n",
      "\n",
      "Epoch: 90, Batch number: 46\n",
      "Accuracy on validation dataset: 3222/9723 (33.14%)\n",
      "\n",
      "Epoch: 90, Batch number: 56\n",
      "Accuracy on validation dataset: 3225/9723 (33.17%)\n",
      "\n",
      "Epoch: 90, Batch number: 66\n",
      "Accuracy on validation dataset: 3223/9723 (33.15%)\n",
      "\n",
      "Epoch: 91, Batch number: 0\n",
      "Accuracy on validation dataset: 3229/9723 (33.21%)\n",
      "\n",
      "Epoch: 91, Batch number: 10\n",
      "Accuracy on validation dataset: 3226/9723 (33.18%)\n",
      "\n",
      "Epoch: 91, Batch number: 20\n",
      "Accuracy on validation dataset: 3231/9723 (33.23%)\n",
      "\n",
      "Epoch: 91, Batch number: 30\n",
      "Accuracy on validation dataset: 3225/9723 (33.17%)\n",
      "\n",
      "Epoch: 91, Batch number: 40\n",
      "Accuracy on validation dataset: 3230/9723 (33.22%)\n",
      "\n",
      "Epoch: 91, Batch number: 50\n",
      "Accuracy on validation dataset: 3230/9723 (33.22%)\n",
      "\n",
      "Epoch: 91, Batch number: 60\n",
      "Accuracy on validation dataset: 3233/9723 (33.25%)\n",
      "\n",
      "Epoch: 91, Batch number: 70\n",
      "Accuracy on validation dataset: 3231/9723 (33.23%)\n",
      "\n",
      "Epoch: 92, Batch number: 4\n",
      "Accuracy on validation dataset: 3228/9723 (33.20%)\n",
      "\n",
      "Epoch: 92, Batch number: 14\n",
      "Accuracy on validation dataset: 3229/9723 (33.21%)\n",
      "\n",
      "Epoch: 92, Batch number: 24\n",
      "Accuracy on validation dataset: 3231/9723 (33.23%)\n",
      "\n",
      "Epoch: 92, Batch number: 34\n",
      "Accuracy on validation dataset: 3232/9723 (33.24%)\n",
      "\n",
      "Epoch: 92, Batch number: 44\n",
      "Accuracy on validation dataset: 3234/9723 (33.26%)\n",
      "\n",
      "Epoch: 92, Batch number: 54\n",
      "Accuracy on validation dataset: 3234/9723 (33.26%)\n",
      "\n",
      "Epoch: 92, Batch number: 64\n",
      "Accuracy on validation dataset: 3238/9723 (33.30%)\n",
      "\n",
      "Epoch: 92, Batch number: 74\n",
      "Accuracy on validation dataset: 3242/9723 (33.34%)\n",
      "\n",
      "Epoch: 93, Batch number: 8\n",
      "Accuracy on validation dataset: 3250/9723 (33.43%)\n",
      "\n",
      "Epoch: 93, Batch number: 18\n",
      "Accuracy on validation dataset: 3245/9723 (33.37%)\n",
      "\n",
      "Epoch: 93, Batch number: 28\n",
      "Accuracy on validation dataset: 3247/9723 (33.40%)\n",
      "\n",
      "Epoch: 93, Batch number: 38\n",
      "Accuracy on validation dataset: 3250/9723 (33.43%)\n",
      "\n",
      "Epoch: 93, Batch number: 48\n",
      "Accuracy on validation dataset: 3248/9723 (33.41%)\n",
      "\n",
      "Epoch: 93, Batch number: 58\n",
      "Accuracy on validation dataset: 3251/9723 (33.44%)\n",
      "\n",
      "Epoch: 93, Batch number: 68\n",
      "Accuracy on validation dataset: 3263/9723 (33.56%)\n",
      "\n",
      "Epoch: 94, Batch number: 2\n",
      "Accuracy on validation dataset: 3270/9723 (33.63%)\n",
      "\n",
      "Epoch: 94, Batch number: 12\n",
      "Accuracy on validation dataset: 3274/9723 (33.67%)\n",
      "\n",
      "Epoch: 94, Batch number: 22\n",
      "Accuracy on validation dataset: 3277/9723 (33.70%)\n",
      "\n",
      "Epoch: 94, Batch number: 32\n",
      "Accuracy on validation dataset: 3273/9723 (33.66%)\n",
      "\n",
      "Epoch: 94, Batch number: 42\n",
      "Accuracy on validation dataset: 3273/9723 (33.66%)\n",
      "\n",
      "Epoch: 94, Batch number: 52\n",
      "Accuracy on validation dataset: 3278/9723 (33.71%)\n",
      "\n",
      "Epoch: 94, Batch number: 62\n",
      "Accuracy on validation dataset: 3279/9723 (33.72%)\n",
      "\n",
      "Epoch: 94, Batch number: 72\n",
      "Accuracy on validation dataset: 3279/9723 (33.72%)\n",
      "\n",
      "Epoch: 95, Batch number: 6\n",
      "Accuracy on validation dataset: 3282/9723 (33.76%)\n",
      "\n",
      "Epoch: 95, Batch number: 16\n",
      "Accuracy on validation dataset: 3281/9723 (33.74%)\n",
      "\n",
      "Epoch: 95, Batch number: 26\n",
      "Accuracy on validation dataset: 3285/9723 (33.79%)\n",
      "\n",
      "Epoch: 95, Batch number: 36\n",
      "Accuracy on validation dataset: 3289/9723 (33.83%)\n",
      "\n",
      "Epoch: 95, Batch number: 46\n",
      "Accuracy on validation dataset: 3300/9723 (33.94%)\n",
      "\n",
      "Epoch: 95, Batch number: 56\n",
      "Accuracy on validation dataset: 3292/9723 (33.86%)\n",
      "\n",
      "Epoch: 95, Batch number: 66\n",
      "Accuracy on validation dataset: 3292/9723 (33.86%)\n",
      "\n",
      "Epoch: 96, Batch number: 0\n",
      "Accuracy on validation dataset: 3295/9723 (33.89%)\n",
      "\n",
      "Epoch: 96, Batch number: 10\n",
      "Accuracy on validation dataset: 3293/9723 (33.87%)\n",
      "\n",
      "Epoch: 96, Batch number: 20\n",
      "Accuracy on validation dataset: 3298/9723 (33.92%)\n",
      "\n",
      "Epoch: 96, Batch number: 30\n",
      "Accuracy on validation dataset: 3301/9723 (33.95%)\n",
      "\n",
      "Epoch: 96, Batch number: 40\n",
      "Accuracy on validation dataset: 3301/9723 (33.95%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, Batch number: 50\n",
      "Accuracy on validation dataset: 3304/9723 (33.98%)\n",
      "\n",
      "Epoch: 96, Batch number: 60\n",
      "Accuracy on validation dataset: 3307/9723 (34.01%)\n",
      "\n",
      "Epoch: 96, Batch number: 70\n",
      "Accuracy on validation dataset: 3307/9723 (34.01%)\n",
      "\n",
      "Epoch: 97, Batch number: 4\n",
      "Accuracy on validation dataset: 3313/9723 (34.07%)\n",
      "\n",
      "Epoch: 97, Batch number: 14\n",
      "Accuracy on validation dataset: 3314/9723 (34.08%)\n",
      "\n",
      "Epoch: 97, Batch number: 24\n",
      "Accuracy on validation dataset: 3308/9723 (34.02%)\n",
      "\n",
      "Epoch: 97, Batch number: 34\n",
      "Accuracy on validation dataset: 3304/9723 (33.98%)\n",
      "\n",
      "Epoch: 97, Batch number: 44\n",
      "Accuracy on validation dataset: 3299/9723 (33.93%)\n",
      "\n",
      "Epoch: 97, Batch number: 54\n",
      "Accuracy on validation dataset: 3306/9723 (34.00%)\n",
      "\n",
      "Epoch: 97, Batch number: 64\n",
      "Accuracy on validation dataset: 3313/9723 (34.07%)\n",
      "\n",
      "Epoch: 97, Batch number: 74\n",
      "Accuracy on validation dataset: 3326/9723 (34.21%)\n",
      "\n",
      "Epoch: 98, Batch number: 8\n",
      "Accuracy on validation dataset: 3323/9723 (34.18%)\n",
      "\n",
      "Epoch: 98, Batch number: 18\n",
      "Accuracy on validation dataset: 3319/9723 (34.14%)\n",
      "\n",
      "Epoch: 98, Batch number: 28\n",
      "Accuracy on validation dataset: 3317/9723 (34.11%)\n",
      "\n",
      "Epoch: 98, Batch number: 38\n",
      "Accuracy on validation dataset: 3328/9723 (34.23%)\n",
      "\n",
      "Epoch: 98, Batch number: 48\n",
      "Accuracy on validation dataset: 3338/9723 (34.33%)\n",
      "\n",
      "Epoch: 98, Batch number: 58\n",
      "Accuracy on validation dataset: 3344/9723 (34.39%)\n",
      "\n",
      "Epoch: 98, Batch number: 68\n",
      "Accuracy on validation dataset: 3341/9723 (34.36%)\n",
      "\n",
      "Epoch: 99, Batch number: 2\n",
      "Accuracy on validation dataset: 3340/9723 (34.35%)\n",
      "\n",
      "Epoch: 99, Batch number: 12\n",
      "Accuracy on validation dataset: 3342/9723 (34.37%)\n",
      "\n",
      "Epoch: 99, Batch number: 22\n",
      "Accuracy on validation dataset: 3338/9723 (34.33%)\n",
      "\n",
      "Epoch: 99, Batch number: 32\n",
      "Accuracy on validation dataset: 3340/9723 (34.35%)\n",
      "\n",
      "Epoch: 99, Batch number: 42\n",
      "Accuracy on validation dataset: 3348/9723 (34.43%)\n",
      "\n",
      "Epoch: 99, Batch number: 52\n",
      "Accuracy on validation dataset: 3352/9723 (34.47%)\n",
      "\n",
      "Epoch: 99, Batch number: 62\n",
      "Accuracy on validation dataset: 3349/9723 (34.44%)\n",
      "\n",
      "Epoch: 99, Batch number: 72\n",
      "Accuracy on validation dataset: 3359/9723 (34.55%)\n",
      "\n",
      "Epoch: 100, Batch number: 6\n",
      "Accuracy on validation dataset: 3365/9723 (34.61%)\n",
      "\n",
      "Epoch: 100, Batch number: 16\n",
      "Accuracy on validation dataset: 3366/9723 (34.62%)\n",
      "\n",
      "Epoch: 100, Batch number: 26\n",
      "Accuracy on validation dataset: 3373/9723 (34.69%)\n",
      "\n",
      "Epoch: 100, Batch number: 36\n",
      "Accuracy on validation dataset: 3372/9723 (34.68%)\n",
      "\n",
      "Epoch: 100, Batch number: 46\n",
      "Accuracy on validation dataset: 3371/9723 (34.67%)\n",
      "\n",
      "Epoch: 100, Batch number: 56\n",
      "Accuracy on validation dataset: 3374/9723 (34.70%)\n",
      "\n",
      "Epoch: 100, Batch number: 66\n",
      "Accuracy on validation dataset: 3372/9723 (34.68%)\n",
      "\n",
      "Epoch: 101, Batch number: 0\n",
      "Accuracy on validation dataset: 3380/9723 (34.76%)\n",
      "\n",
      "Epoch: 101, Batch number: 10\n",
      "Accuracy on validation dataset: 3380/9723 (34.76%)\n",
      "\n",
      "Epoch: 101, Batch number: 20\n",
      "Accuracy on validation dataset: 3382/9723 (34.78%)\n",
      "\n",
      "Epoch: 101, Batch number: 30\n",
      "Accuracy on validation dataset: 3380/9723 (34.76%)\n",
      "\n",
      "Epoch: 101, Batch number: 40\n",
      "Accuracy on validation dataset: 3386/9723 (34.82%)\n",
      "\n",
      "Epoch: 101, Batch number: 50\n",
      "Accuracy on validation dataset: 3395/9723 (34.92%)\n",
      "\n",
      "Epoch: 101, Batch number: 60\n",
      "Accuracy on validation dataset: 3394/9723 (34.91%)\n",
      "\n",
      "Epoch: 101, Batch number: 70\n",
      "Accuracy on validation dataset: 3396/9723 (34.93%)\n",
      "\n",
      "Epoch: 102, Batch number: 4\n",
      "Accuracy on validation dataset: 3393/9723 (34.90%)\n",
      "\n",
      "Epoch: 102, Batch number: 14\n",
      "Accuracy on validation dataset: 3389/9723 (34.86%)\n",
      "\n",
      "Epoch: 102, Batch number: 24\n",
      "Accuracy on validation dataset: 3389/9723 (34.86%)\n",
      "\n",
      "Epoch: 102, Batch number: 34\n",
      "Accuracy on validation dataset: 3397/9723 (34.94%)\n",
      "\n",
      "Epoch: 102, Batch number: 44\n",
      "Accuracy on validation dataset: 3410/9723 (35.07%)\n",
      "\n",
      "Epoch: 102, Batch number: 54\n",
      "Accuracy on validation dataset: 3418/9723 (35.15%)\n",
      "\n",
      "Epoch: 102, Batch number: 64\n",
      "Accuracy on validation dataset: 3410/9723 (35.07%)\n",
      "\n",
      "Epoch: 102, Batch number: 74\n",
      "Accuracy on validation dataset: 3412/9723 (35.09%)\n",
      "\n",
      "Epoch: 103, Batch number: 8\n",
      "Accuracy on validation dataset: 3408/9723 (35.05%)\n",
      "\n",
      "Epoch: 103, Batch number: 18\n",
      "Accuracy on validation dataset: 3407/9723 (35.04%)\n",
      "\n",
      "Epoch: 103, Batch number: 28\n",
      "Accuracy on validation dataset: 3410/9723 (35.07%)\n",
      "\n",
      "Epoch: 103, Batch number: 38\n",
      "Accuracy on validation dataset: 3411/9723 (35.08%)\n",
      "\n",
      "Epoch: 103, Batch number: 48\n",
      "Accuracy on validation dataset: 3417/9723 (35.14%)\n",
      "\n",
      "Epoch: 103, Batch number: 58\n",
      "Accuracy on validation dataset: 3421/9723 (35.18%)\n",
      "\n",
      "Epoch: 103, Batch number: 68\n",
      "Accuracy on validation dataset: 3425/9723 (35.23%)\n",
      "\n",
      "Epoch: 104, Batch number: 2\n",
      "Accuracy on validation dataset: 3433/9723 (35.31%)\n",
      "\n",
      "Epoch: 104, Batch number: 12\n",
      "Accuracy on validation dataset: 3431/9723 (35.29%)\n",
      "\n",
      "Epoch: 104, Batch number: 22\n",
      "Accuracy on validation dataset: 3429/9723 (35.27%)\n",
      "\n",
      "Epoch: 104, Batch number: 32\n",
      "Accuracy on validation dataset: 3437/9723 (35.35%)\n",
      "\n",
      "Epoch: 104, Batch number: 42\n",
      "Accuracy on validation dataset: 3439/9723 (35.37%)\n",
      "\n",
      "Epoch: 104, Batch number: 52\n",
      "Accuracy on validation dataset: 3439/9723 (35.37%)\n",
      "\n",
      "Epoch: 104, Batch number: 62\n",
      "Accuracy on validation dataset: 3437/9723 (35.35%)\n",
      "\n",
      "Epoch: 104, Batch number: 72\n",
      "Accuracy on validation dataset: 3440/9723 (35.38%)\n",
      "\n",
      "Epoch: 105, Batch number: 6\n",
      "Accuracy on validation dataset: 3440/9723 (35.38%)\n",
      "\n",
      "Epoch: 105, Batch number: 16\n",
      "Accuracy on validation dataset: 3452/9723 (35.50%)\n",
      "\n",
      "Epoch: 105, Batch number: 26\n",
      "Accuracy on validation dataset: 3446/9723 (35.44%)\n",
      "\n",
      "Epoch: 105, Batch number: 36\n",
      "Accuracy on validation dataset: 3448/9723 (35.46%)\n",
      "\n",
      "Epoch: 105, Batch number: 46\n",
      "Accuracy on validation dataset: 3445/9723 (35.43%)\n",
      "\n",
      "Epoch: 105, Batch number: 56\n",
      "Accuracy on validation dataset: 3447/9723 (35.45%)\n",
      "\n",
      "Epoch: 105, Batch number: 66\n",
      "Accuracy on validation dataset: 3454/9723 (35.52%)\n",
      "\n",
      "Epoch: 106, Batch number: 0\n",
      "Accuracy on validation dataset: 3453/9723 (35.51%)\n",
      "\n",
      "Epoch: 106, Batch number: 10\n",
      "Accuracy on validation dataset: 3462/9723 (35.61%)\n",
      "\n",
      "Epoch: 106, Batch number: 20\n",
      "Accuracy on validation dataset: 3460/9723 (35.59%)\n",
      "\n",
      "Epoch: 106, Batch number: 30\n",
      "Accuracy on validation dataset: 3458/9723 (35.57%)\n",
      "\n",
      "Epoch: 106, Batch number: 40\n",
      "Accuracy on validation dataset: 3462/9723 (35.61%)\n",
      "\n",
      "Epoch: 106, Batch number: 50\n",
      "Accuracy on validation dataset: 3457/9723 (35.55%)\n",
      "\n",
      "Epoch: 106, Batch number: 60\n",
      "Accuracy on validation dataset: 3460/9723 (35.59%)\n",
      "\n",
      "Epoch: 106, Batch number: 70\n",
      "Accuracy on validation dataset: 3462/9723 (35.61%)\n",
      "\n",
      "Epoch: 107, Batch number: 4\n",
      "Accuracy on validation dataset: 3466/9723 (35.65%)\n",
      "\n",
      "Epoch: 107, Batch number: 14\n",
      "Accuracy on validation dataset: 3463/9723 (35.62%)\n",
      "\n",
      "Epoch: 107, Batch number: 24\n",
      "Accuracy on validation dataset: 3466/9723 (35.65%)\n",
      "\n",
      "Epoch: 107, Batch number: 34\n",
      "Accuracy on validation dataset: 3472/9723 (35.71%)\n",
      "\n",
      "Epoch: 107, Batch number: 44\n",
      "Accuracy on validation dataset: 3467/9723 (35.66%)\n",
      "\n",
      "Epoch: 107, Batch number: 54\n",
      "Accuracy on validation dataset: 3476/9723 (35.75%)\n",
      "\n",
      "Epoch: 107, Batch number: 64\n",
      "Accuracy on validation dataset: 3481/9723 (35.80%)\n",
      "\n",
      "Epoch: 107, Batch number: 74\n",
      "Accuracy on validation dataset: 3477/9723 (35.76%)\n",
      "\n",
      "Epoch: 108, Batch number: 8\n",
      "Accuracy on validation dataset: 3479/9723 (35.78%)\n",
      "\n",
      "Epoch: 108, Batch number: 18\n",
      "Accuracy on validation dataset: 3493/9723 (35.93%)\n",
      "\n",
      "Epoch: 108, Batch number: 28\n",
      "Accuracy on validation dataset: 3491/9723 (35.90%)\n",
      "\n",
      "Epoch: 108, Batch number: 38\n",
      "Accuracy on validation dataset: 3496/9723 (35.96%)\n",
      "\n",
      "Epoch: 108, Batch number: 48\n",
      "Accuracy on validation dataset: 3495/9723 (35.95%)\n",
      "\n",
      "Epoch: 108, Batch number: 58\n",
      "Accuracy on validation dataset: 3502/9723 (36.02%)\n",
      "\n",
      "Epoch: 108, Batch number: 68\n",
      "Accuracy on validation dataset: 3500/9723 (36.00%)\n",
      "\n",
      "Epoch: 109, Batch number: 2\n",
      "Accuracy on validation dataset: 3500/9723 (36.00%)\n",
      "\n",
      "Epoch: 109, Batch number: 12\n",
      "Accuracy on validation dataset: 3495/9723 (35.95%)\n",
      "\n",
      "Epoch: 109, Batch number: 22\n",
      "Accuracy on validation dataset: 3500/9723 (36.00%)\n",
      "\n",
      "Epoch: 109, Batch number: 32\n",
      "Accuracy on validation dataset: 3502/9723 (36.02%)\n",
      "\n",
      "Epoch: 109, Batch number: 42\n",
      "Accuracy on validation dataset: 3498/9723 (35.98%)\n",
      "\n",
      "Epoch: 109, Batch number: 52\n",
      "Accuracy on validation dataset: 3501/9723 (36.01%)\n",
      "\n",
      "Epoch: 109, Batch number: 62\n",
      "Accuracy on validation dataset: 3506/9723 (36.06%)\n",
      "\n",
      "Epoch: 109, Batch number: 72\n",
      "Accuracy on validation dataset: 3514/9723 (36.14%)\n",
      "\n",
      "Epoch: 110, Batch number: 6\n",
      "Accuracy on validation dataset: 3514/9723 (36.14%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Batch number: 16\n",
      "Accuracy on validation dataset: 3512/9723 (36.12%)\n",
      "\n",
      "Epoch: 110, Batch number: 26\n",
      "Accuracy on validation dataset: 3519/9723 (36.19%)\n",
      "\n",
      "Epoch: 110, Batch number: 36\n",
      "Accuracy on validation dataset: 3516/9723 (36.16%)\n",
      "\n",
      "Epoch: 110, Batch number: 46\n",
      "Accuracy on validation dataset: 3522/9723 (36.22%)\n",
      "\n",
      "Epoch: 110, Batch number: 56\n",
      "Accuracy on validation dataset: 3526/9723 (36.26%)\n",
      "\n",
      "Epoch: 110, Batch number: 66\n",
      "Accuracy on validation dataset: 3528/9723 (36.29%)\n",
      "\n",
      "Epoch: 111, Batch number: 0\n",
      "Accuracy on validation dataset: 3526/9723 (36.26%)\n",
      "\n",
      "Epoch: 111, Batch number: 10\n",
      "Accuracy on validation dataset: 3517/9723 (36.17%)\n",
      "\n",
      "Epoch: 111, Batch number: 20\n",
      "Accuracy on validation dataset: 3524/9723 (36.24%)\n",
      "\n",
      "Epoch: 111, Batch number: 30\n",
      "Accuracy on validation dataset: 3523/9723 (36.23%)\n",
      "\n",
      "Epoch: 111, Batch number: 40\n",
      "Accuracy on validation dataset: 3521/9723 (36.21%)\n",
      "\n",
      "Epoch: 111, Batch number: 50\n",
      "Accuracy on validation dataset: 3519/9723 (36.19%)\n",
      "\n",
      "Epoch: 111, Batch number: 60\n",
      "Accuracy on validation dataset: 3523/9723 (36.23%)\n",
      "\n",
      "Epoch: 111, Batch number: 70\n",
      "Accuracy on validation dataset: 3538/9723 (36.39%)\n",
      "\n",
      "Epoch: 112, Batch number: 4\n",
      "Accuracy on validation dataset: 3540/9723 (36.41%)\n",
      "\n",
      "Epoch: 112, Batch number: 14\n",
      "Accuracy on validation dataset: 3540/9723 (36.41%)\n",
      "\n",
      "Epoch: 112, Batch number: 24\n",
      "Accuracy on validation dataset: 3540/9723 (36.41%)\n",
      "\n",
      "Epoch: 112, Batch number: 34\n",
      "Accuracy on validation dataset: 3543/9723 (36.44%)\n",
      "\n",
      "Epoch: 112, Batch number: 44\n",
      "Accuracy on validation dataset: 3545/9723 (36.46%)\n",
      "\n",
      "Epoch: 112, Batch number: 54\n",
      "Accuracy on validation dataset: 3542/9723 (36.43%)\n",
      "\n",
      "Epoch: 112, Batch number: 64\n",
      "Accuracy on validation dataset: 3546/9723 (36.47%)\n",
      "\n",
      "Epoch: 112, Batch number: 74\n",
      "Accuracy on validation dataset: 3547/9723 (36.48%)\n",
      "\n",
      "Epoch: 113, Batch number: 8\n",
      "Accuracy on validation dataset: 3553/9723 (36.54%)\n",
      "\n",
      "Epoch: 113, Batch number: 18\n",
      "Accuracy on validation dataset: 3555/9723 (36.56%)\n",
      "\n",
      "Epoch: 113, Batch number: 28\n",
      "Accuracy on validation dataset: 3558/9723 (36.59%)\n",
      "\n",
      "Epoch: 113, Batch number: 38\n",
      "Accuracy on validation dataset: 3555/9723 (36.56%)\n",
      "\n",
      "Epoch: 113, Batch number: 48\n",
      "Accuracy on validation dataset: 3558/9723 (36.59%)\n",
      "\n",
      "Epoch: 113, Batch number: 58\n",
      "Accuracy on validation dataset: 3557/9723 (36.58%)\n",
      "\n",
      "Epoch: 113, Batch number: 68\n",
      "Accuracy on validation dataset: 3558/9723 (36.59%)\n",
      "\n",
      "Epoch: 114, Batch number: 2\n",
      "Accuracy on validation dataset: 3563/9723 (36.65%)\n",
      "\n",
      "Epoch: 114, Batch number: 12\n",
      "Accuracy on validation dataset: 3564/9723 (36.66%)\n",
      "\n",
      "Epoch: 114, Batch number: 22\n",
      "Accuracy on validation dataset: 3571/9723 (36.73%)\n",
      "\n",
      "Epoch: 114, Batch number: 32\n",
      "Accuracy on validation dataset: 3565/9723 (36.67%)\n",
      "\n",
      "Epoch: 114, Batch number: 42\n",
      "Accuracy on validation dataset: 3567/9723 (36.69%)\n",
      "\n",
      "Epoch: 114, Batch number: 52\n",
      "Accuracy on validation dataset: 3570/9723 (36.72%)\n",
      "\n",
      "Epoch: 114, Batch number: 62\n",
      "Accuracy on validation dataset: 3568/9723 (36.70%)\n",
      "\n",
      "Epoch: 114, Batch number: 72\n",
      "Accuracy on validation dataset: 3572/9723 (36.74%)\n",
      "\n",
      "Epoch: 115, Batch number: 6\n",
      "Accuracy on validation dataset: 3572/9723 (36.74%)\n",
      "\n",
      "Epoch: 115, Batch number: 16\n",
      "Accuracy on validation dataset: 3577/9723 (36.79%)\n",
      "\n",
      "Epoch: 115, Batch number: 26\n",
      "Accuracy on validation dataset: 3581/9723 (36.83%)\n",
      "\n",
      "Epoch: 115, Batch number: 36\n",
      "Accuracy on validation dataset: 3581/9723 (36.83%)\n",
      "\n",
      "Epoch: 115, Batch number: 46\n",
      "Accuracy on validation dataset: 3585/9723 (36.87%)\n",
      "\n",
      "Epoch: 115, Batch number: 56\n",
      "Accuracy on validation dataset: 3584/9723 (36.86%)\n",
      "\n",
      "Epoch: 115, Batch number: 66\n",
      "Accuracy on validation dataset: 3586/9723 (36.88%)\n",
      "\n",
      "Epoch: 116, Batch number: 0\n",
      "Accuracy on validation dataset: 3587/9723 (36.89%)\n",
      "\n",
      "Epoch: 116, Batch number: 10\n",
      "Accuracy on validation dataset: 3589/9723 (36.91%)\n",
      "\n",
      "Epoch: 116, Batch number: 20\n",
      "Accuracy on validation dataset: 3595/9723 (36.97%)\n",
      "\n",
      "Epoch: 116, Batch number: 30\n",
      "Accuracy on validation dataset: 3596/9723 (36.98%)\n",
      "\n",
      "Epoch: 116, Batch number: 40\n",
      "Accuracy on validation dataset: 3591/9723 (36.93%)\n",
      "\n",
      "Epoch: 116, Batch number: 50\n",
      "Accuracy on validation dataset: 3599/9723 (37.02%)\n",
      "\n",
      "Epoch: 116, Batch number: 60\n",
      "Accuracy on validation dataset: 3596/9723 (36.98%)\n",
      "\n",
      "Epoch: 116, Batch number: 70\n",
      "Accuracy on validation dataset: 3592/9723 (36.94%)\n",
      "\n",
      "Epoch: 117, Batch number: 4\n",
      "Accuracy on validation dataset: 3600/9723 (37.03%)\n",
      "\n",
      "Epoch: 117, Batch number: 14\n",
      "Accuracy on validation dataset: 3597/9723 (36.99%)\n",
      "\n",
      "Epoch: 117, Batch number: 24\n",
      "Accuracy on validation dataset: 3598/9723 (37.01%)\n",
      "\n",
      "Epoch: 117, Batch number: 34\n",
      "Accuracy on validation dataset: 3601/9723 (37.04%)\n",
      "\n",
      "Epoch: 117, Batch number: 44\n",
      "Accuracy on validation dataset: 3607/9723 (37.10%)\n",
      "\n",
      "Epoch: 117, Batch number: 54\n",
      "Accuracy on validation dataset: 3607/9723 (37.10%)\n",
      "\n",
      "Epoch: 117, Batch number: 64\n",
      "Accuracy on validation dataset: 3606/9723 (37.09%)\n",
      "\n",
      "Epoch: 117, Batch number: 74\n",
      "Accuracy on validation dataset: 3607/9723 (37.10%)\n",
      "\n",
      "Epoch: 118, Batch number: 8\n",
      "Accuracy on validation dataset: 3615/9723 (37.18%)\n",
      "\n",
      "Epoch: 118, Batch number: 18\n",
      "Accuracy on validation dataset: 3616/9723 (37.19%)\n",
      "\n",
      "Epoch: 118, Batch number: 28\n",
      "Accuracy on validation dataset: 3615/9723 (37.18%)\n",
      "\n",
      "Epoch: 118, Batch number: 38\n",
      "Accuracy on validation dataset: 3623/9723 (37.26%)\n",
      "\n",
      "Epoch: 118, Batch number: 48\n",
      "Accuracy on validation dataset: 3622/9723 (37.25%)\n",
      "\n",
      "Epoch: 118, Batch number: 58\n",
      "Accuracy on validation dataset: 3627/9723 (37.30%)\n",
      "\n",
      "Epoch: 118, Batch number: 68\n",
      "Accuracy on validation dataset: 3629/9723 (37.32%)\n",
      "\n",
      "Epoch: 119, Batch number: 2\n",
      "Accuracy on validation dataset: 3634/9723 (37.38%)\n",
      "\n",
      "Epoch: 119, Batch number: 12\n",
      "Accuracy on validation dataset: 3635/9723 (37.39%)\n",
      "\n",
      "Epoch: 119, Batch number: 22\n",
      "Accuracy on validation dataset: 3638/9723 (37.42%)\n",
      "\n",
      "Epoch: 119, Batch number: 32\n",
      "Accuracy on validation dataset: 3643/9723 (37.47%)\n",
      "\n",
      "Epoch: 119, Batch number: 42\n",
      "Accuracy on validation dataset: 3645/9723 (37.49%)\n",
      "\n",
      "Epoch: 119, Batch number: 52\n",
      "Accuracy on validation dataset: 3646/9723 (37.50%)\n",
      "\n",
      "Epoch: 119, Batch number: 62\n",
      "Accuracy on validation dataset: 3647/9723 (37.51%)\n",
      "\n",
      "Epoch: 119, Batch number: 72\n",
      "Accuracy on validation dataset: 3644/9723 (37.48%)\n",
      "\n",
      "Epoch: 120, Batch number: 6\n",
      "Accuracy on validation dataset: 3650/9723 (37.54%)\n",
      "\n",
      "Epoch: 120, Batch number: 16\n",
      "Accuracy on validation dataset: 3653/9723 (37.57%)\n",
      "\n",
      "Epoch: 120, Batch number: 26\n",
      "Accuracy on validation dataset: 3652/9723 (37.56%)\n",
      "\n",
      "Epoch: 120, Batch number: 36\n",
      "Accuracy on validation dataset: 3652/9723 (37.56%)\n",
      "\n",
      "Epoch: 120, Batch number: 46\n",
      "Accuracy on validation dataset: 3656/9723 (37.60%)\n",
      "\n",
      "Epoch: 120, Batch number: 56\n",
      "Accuracy on validation dataset: 3660/9723 (37.64%)\n",
      "\n",
      "Epoch: 120, Batch number: 66\n",
      "Accuracy on validation dataset: 3660/9723 (37.64%)\n",
      "\n",
      "Epoch: 121, Batch number: 0\n",
      "Accuracy on validation dataset: 3664/9723 (37.68%)\n",
      "\n",
      "Epoch: 121, Batch number: 10\n",
      "Accuracy on validation dataset: 3662/9723 (37.66%)\n",
      "\n",
      "Epoch: 121, Batch number: 20\n",
      "Accuracy on validation dataset: 3666/9723 (37.70%)\n",
      "\n",
      "Epoch: 121, Batch number: 30\n",
      "Accuracy on validation dataset: 3664/9723 (37.68%)\n",
      "\n",
      "Epoch: 121, Batch number: 40\n",
      "Accuracy on validation dataset: 3662/9723 (37.66%)\n",
      "\n",
      "Epoch: 121, Batch number: 50\n",
      "Accuracy on validation dataset: 3664/9723 (37.68%)\n",
      "\n",
      "Epoch: 121, Batch number: 60\n",
      "Accuracy on validation dataset: 3669/9723 (37.74%)\n",
      "\n",
      "Epoch: 121, Batch number: 70\n",
      "Accuracy on validation dataset: 3667/9723 (37.71%)\n",
      "\n",
      "Epoch: 122, Batch number: 4\n",
      "Accuracy on validation dataset: 3675/9723 (37.80%)\n",
      "\n",
      "Epoch: 122, Batch number: 14\n",
      "Accuracy on validation dataset: 3683/9723 (37.88%)\n",
      "\n",
      "Epoch: 122, Batch number: 24\n",
      "Accuracy on validation dataset: 3690/9723 (37.95%)\n",
      "\n",
      "Epoch: 122, Batch number: 34\n",
      "Accuracy on validation dataset: 3688/9723 (37.93%)\n",
      "\n",
      "Epoch: 122, Batch number: 44\n",
      "Accuracy on validation dataset: 3695/9723 (38.00%)\n",
      "\n",
      "Epoch: 122, Batch number: 54\n",
      "Accuracy on validation dataset: 3695/9723 (38.00%)\n",
      "\n",
      "Epoch: 122, Batch number: 64\n",
      "Accuracy on validation dataset: 3695/9723 (38.00%)\n",
      "\n",
      "Epoch: 122, Batch number: 74\n",
      "Accuracy on validation dataset: 3696/9723 (38.01%)\n",
      "\n",
      "Epoch: 123, Batch number: 8\n",
      "Accuracy on validation dataset: 3695/9723 (38.00%)\n",
      "\n",
      "Epoch: 123, Batch number: 18\n",
      "Accuracy on validation dataset: 3697/9723 (38.02%)\n",
      "\n",
      "Epoch: 123, Batch number: 28\n",
      "Accuracy on validation dataset: 3692/9723 (37.97%)\n",
      "\n",
      "Epoch: 123, Batch number: 38\n",
      "Accuracy on validation dataset: 3689/9723 (37.94%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123, Batch number: 48\n",
      "Accuracy on validation dataset: 3692/9723 (37.97%)\n",
      "\n",
      "Epoch: 123, Batch number: 58\n",
      "Accuracy on validation dataset: 3700/9723 (38.05%)\n",
      "\n",
      "Epoch: 123, Batch number: 68\n",
      "Accuracy on validation dataset: 3699/9723 (38.04%)\n",
      "\n",
      "Epoch: 124, Batch number: 2\n",
      "Accuracy on validation dataset: 3707/9723 (38.13%)\n",
      "\n",
      "Epoch: 124, Batch number: 12\n",
      "Accuracy on validation dataset: 3703/9723 (38.08%)\n",
      "\n",
      "Epoch: 124, Batch number: 22\n",
      "Accuracy on validation dataset: 3707/9723 (38.13%)\n",
      "\n",
      "Epoch: 124, Batch number: 32\n",
      "Accuracy on validation dataset: 3713/9723 (38.19%)\n",
      "\n",
      "Epoch: 124, Batch number: 42\n",
      "Accuracy on validation dataset: 3713/9723 (38.19%)\n",
      "\n",
      "Epoch: 124, Batch number: 52\n",
      "Accuracy on validation dataset: 3717/9723 (38.23%)\n",
      "\n",
      "Epoch: 124, Batch number: 62\n",
      "Accuracy on validation dataset: 3718/9723 (38.24%)\n",
      "\n",
      "Epoch: 124, Batch number: 72\n",
      "Accuracy on validation dataset: 3717/9723 (38.23%)\n",
      "\n",
      "Epoch: 125, Batch number: 6\n",
      "Accuracy on validation dataset: 3728/9723 (38.34%)\n",
      "\n",
      "Epoch: 125, Batch number: 16\n",
      "Accuracy on validation dataset: 3727/9723 (38.33%)\n",
      "\n",
      "Epoch: 125, Batch number: 26\n",
      "Accuracy on validation dataset: 3726/9723 (38.32%)\n",
      "\n",
      "Epoch: 125, Batch number: 36\n",
      "Accuracy on validation dataset: 3735/9723 (38.41%)\n",
      "\n",
      "Epoch: 125, Batch number: 46\n",
      "Accuracy on validation dataset: 3732/9723 (38.38%)\n",
      "\n",
      "Epoch: 125, Batch number: 56\n",
      "Accuracy on validation dataset: 3736/9723 (38.42%)\n",
      "\n",
      "Epoch: 125, Batch number: 66\n",
      "Accuracy on validation dataset: 3730/9723 (38.36%)\n",
      "\n",
      "Epoch: 126, Batch number: 0\n",
      "Accuracy on validation dataset: 3728/9723 (38.34%)\n",
      "\n",
      "Epoch: 126, Batch number: 10\n",
      "Accuracy on validation dataset: 3729/9723 (38.35%)\n",
      "\n",
      "Epoch: 126, Batch number: 20\n",
      "Accuracy on validation dataset: 3734/9723 (38.40%)\n",
      "\n",
      "Epoch: 126, Batch number: 30\n",
      "Accuracy on validation dataset: 3734/9723 (38.40%)\n",
      "\n",
      "Epoch: 126, Batch number: 40\n",
      "Accuracy on validation dataset: 3738/9723 (38.44%)\n",
      "\n",
      "Epoch: 126, Batch number: 50\n",
      "Accuracy on validation dataset: 3739/9723 (38.46%)\n",
      "\n",
      "Epoch: 126, Batch number: 60\n",
      "Accuracy on validation dataset: 3740/9723 (38.47%)\n",
      "\n",
      "Epoch: 126, Batch number: 70\n",
      "Accuracy on validation dataset: 3742/9723 (38.49%)\n",
      "\n",
      "Epoch: 127, Batch number: 4\n",
      "Accuracy on validation dataset: 3748/9723 (38.55%)\n",
      "\n",
      "Epoch: 127, Batch number: 14\n",
      "Accuracy on validation dataset: 3751/9723 (38.58%)\n",
      "\n",
      "Epoch: 127, Batch number: 24\n",
      "Accuracy on validation dataset: 3751/9723 (38.58%)\n",
      "\n",
      "Epoch: 127, Batch number: 34\n",
      "Accuracy on validation dataset: 3749/9723 (38.56%)\n",
      "\n",
      "Epoch: 127, Batch number: 44\n",
      "Accuracy on validation dataset: 3747/9723 (38.54%)\n",
      "\n",
      "Epoch: 127, Batch number: 54\n",
      "Accuracy on validation dataset: 3746/9723 (38.53%)\n",
      "\n",
      "Epoch: 127, Batch number: 64\n",
      "Accuracy on validation dataset: 3760/9723 (38.67%)\n",
      "\n",
      "Epoch: 127, Batch number: 74\n",
      "Accuracy on validation dataset: 3755/9723 (38.62%)\n",
      "\n",
      "Epoch: 128, Batch number: 8\n",
      "Accuracy on validation dataset: 3758/9723 (38.65%)\n",
      "\n",
      "Epoch: 128, Batch number: 18\n",
      "Accuracy on validation dataset: 3760/9723 (38.67%)\n",
      "\n",
      "Epoch: 128, Batch number: 28\n",
      "Accuracy on validation dataset: 3757/9723 (38.64%)\n",
      "\n",
      "Epoch: 128, Batch number: 38\n",
      "Accuracy on validation dataset: 3758/9723 (38.65%)\n",
      "\n",
      "Epoch: 128, Batch number: 48\n",
      "Accuracy on validation dataset: 3766/9723 (38.73%)\n",
      "\n",
      "Epoch: 128, Batch number: 58\n",
      "Accuracy on validation dataset: 3765/9723 (38.72%)\n",
      "\n",
      "Epoch: 128, Batch number: 68\n",
      "Accuracy on validation dataset: 3767/9723 (38.74%)\n",
      "\n",
      "Epoch: 129, Batch number: 2\n",
      "Accuracy on validation dataset: 3765/9723 (38.72%)\n",
      "\n",
      "Epoch: 129, Batch number: 12\n",
      "Accuracy on validation dataset: 3761/9723 (38.68%)\n",
      "\n",
      "Epoch: 129, Batch number: 22\n",
      "Accuracy on validation dataset: 3764/9723 (38.71%)\n",
      "\n",
      "Epoch: 129, Batch number: 32\n",
      "Accuracy on validation dataset: 3765/9723 (38.72%)\n",
      "\n",
      "Epoch: 129, Batch number: 42\n",
      "Accuracy on validation dataset: 3764/9723 (38.71%)\n",
      "\n",
      "Epoch: 129, Batch number: 52\n",
      "Accuracy on validation dataset: 3763/9723 (38.70%)\n",
      "\n",
      "Epoch: 129, Batch number: 62\n",
      "Accuracy on validation dataset: 3766/9723 (38.73%)\n",
      "\n",
      "Epoch: 129, Batch number: 72\n",
      "Accuracy on validation dataset: 3777/9723 (38.85%)\n",
      "\n",
      "Epoch: 130, Batch number: 6\n",
      "Accuracy on validation dataset: 3777/9723 (38.85%)\n",
      "\n",
      "Epoch: 130, Batch number: 16\n",
      "Accuracy on validation dataset: 3781/9723 (38.89%)\n",
      "\n",
      "Epoch: 130, Batch number: 26\n",
      "Accuracy on validation dataset: 3780/9723 (38.88%)\n",
      "\n",
      "Epoch: 130, Batch number: 36\n",
      "Accuracy on validation dataset: 3782/9723 (38.90%)\n",
      "\n",
      "Epoch: 130, Batch number: 46\n",
      "Accuracy on validation dataset: 3784/9723 (38.92%)\n",
      "\n",
      "Epoch: 130, Batch number: 56\n",
      "Accuracy on validation dataset: 3784/9723 (38.92%)\n",
      "\n",
      "Epoch: 130, Batch number: 66\n",
      "Accuracy on validation dataset: 3791/9723 (38.99%)\n",
      "\n",
      "Epoch: 131, Batch number: 0\n",
      "Accuracy on validation dataset: 3793/9723 (39.01%)\n",
      "\n",
      "Epoch: 131, Batch number: 10\n",
      "Accuracy on validation dataset: 3798/9723 (39.06%)\n",
      "\n",
      "Epoch: 131, Batch number: 20\n",
      "Accuracy on validation dataset: 3799/9723 (39.07%)\n",
      "\n",
      "Epoch: 131, Batch number: 30\n",
      "Accuracy on validation dataset: 3799/9723 (39.07%)\n",
      "\n",
      "Epoch: 131, Batch number: 40\n",
      "Accuracy on validation dataset: 3795/9723 (39.03%)\n",
      "\n",
      "Epoch: 131, Batch number: 50\n",
      "Accuracy on validation dataset: 3803/9723 (39.11%)\n",
      "\n",
      "Epoch: 131, Batch number: 60\n",
      "Accuracy on validation dataset: 3805/9723 (39.13%)\n",
      "\n",
      "Epoch: 131, Batch number: 70\n",
      "Accuracy on validation dataset: 3807/9723 (39.15%)\n",
      "\n",
      "Epoch: 132, Batch number: 4\n",
      "Accuracy on validation dataset: 3810/9723 (39.19%)\n",
      "\n",
      "Epoch: 132, Batch number: 14\n",
      "Accuracy on validation dataset: 3810/9723 (39.19%)\n",
      "\n",
      "Epoch: 132, Batch number: 24\n",
      "Accuracy on validation dataset: 3810/9723 (39.19%)\n",
      "\n",
      "Epoch: 132, Batch number: 34\n",
      "Accuracy on validation dataset: 3809/9723 (39.18%)\n",
      "\n",
      "Epoch: 132, Batch number: 44\n",
      "Accuracy on validation dataset: 3813/9723 (39.22%)\n",
      "\n",
      "Epoch: 132, Batch number: 54\n",
      "Accuracy on validation dataset: 3815/9723 (39.24%)\n",
      "\n",
      "Epoch: 132, Batch number: 64\n",
      "Accuracy on validation dataset: 3815/9723 (39.24%)\n",
      "\n",
      "Epoch: 132, Batch number: 74\n",
      "Accuracy on validation dataset: 3818/9723 (39.27%)\n",
      "\n",
      "Epoch: 133, Batch number: 8\n",
      "Accuracy on validation dataset: 3818/9723 (39.27%)\n",
      "\n",
      "Epoch: 133, Batch number: 18\n",
      "Accuracy on validation dataset: 3822/9723 (39.31%)\n",
      "\n",
      "Epoch: 133, Batch number: 28\n",
      "Accuracy on validation dataset: 3818/9723 (39.27%)\n",
      "\n",
      "Epoch: 133, Batch number: 38\n",
      "Accuracy on validation dataset: 3825/9723 (39.34%)\n",
      "\n",
      "Epoch: 133, Batch number: 48\n",
      "Accuracy on validation dataset: 3825/9723 (39.34%)\n",
      "\n",
      "Epoch: 133, Batch number: 58\n",
      "Accuracy on validation dataset: 3825/9723 (39.34%)\n",
      "\n",
      "Epoch: 133, Batch number: 68\n",
      "Accuracy on validation dataset: 3825/9723 (39.34%)\n",
      "\n",
      "Epoch: 134, Batch number: 2\n",
      "Accuracy on validation dataset: 3829/9723 (39.38%)\n",
      "\n",
      "Epoch: 134, Batch number: 12\n",
      "Accuracy on validation dataset: 3833/9723 (39.42%)\n",
      "\n",
      "Epoch: 134, Batch number: 22\n",
      "Accuracy on validation dataset: 3839/9723 (39.48%)\n",
      "\n",
      "Epoch: 134, Batch number: 32\n",
      "Accuracy on validation dataset: 3828/9723 (39.37%)\n",
      "\n",
      "Epoch: 134, Batch number: 42\n",
      "Accuracy on validation dataset: 3840/9723 (39.49%)\n",
      "\n",
      "Epoch: 134, Batch number: 52\n",
      "Accuracy on validation dataset: 3842/9723 (39.51%)\n",
      "\n",
      "Epoch: 134, Batch number: 62\n",
      "Accuracy on validation dataset: 3849/9723 (39.59%)\n",
      "\n",
      "Epoch: 134, Batch number: 72\n",
      "Accuracy on validation dataset: 3851/9723 (39.61%)\n",
      "\n",
      "Epoch: 135, Batch number: 6\n",
      "Accuracy on validation dataset: 3841/9723 (39.50%)\n",
      "\n",
      "Epoch: 135, Batch number: 16\n",
      "Accuracy on validation dataset: 3845/9723 (39.55%)\n",
      "\n",
      "Epoch: 135, Batch number: 26\n",
      "Accuracy on validation dataset: 3854/9723 (39.64%)\n",
      "\n",
      "Epoch: 135, Batch number: 36\n",
      "Accuracy on validation dataset: 3854/9723 (39.64%)\n",
      "\n",
      "Epoch: 135, Batch number: 46\n",
      "Accuracy on validation dataset: 3850/9723 (39.60%)\n",
      "\n",
      "Epoch: 135, Batch number: 56\n",
      "Accuracy on validation dataset: 3854/9723 (39.64%)\n",
      "\n",
      "Epoch: 135, Batch number: 66\n",
      "Accuracy on validation dataset: 3860/9723 (39.70%)\n",
      "\n",
      "Epoch: 136, Batch number: 0\n",
      "Accuracy on validation dataset: 3870/9723 (39.80%)\n",
      "\n",
      "Epoch: 136, Batch number: 10\n",
      "Accuracy on validation dataset: 3865/9723 (39.75%)\n",
      "\n",
      "Epoch: 136, Batch number: 20\n",
      "Accuracy on validation dataset: 3866/9723 (39.76%)\n",
      "\n",
      "Epoch: 136, Batch number: 30\n",
      "Accuracy on validation dataset: 3867/9723 (39.77%)\n",
      "\n",
      "Epoch: 136, Batch number: 40\n",
      "Accuracy on validation dataset: 3876/9723 (39.86%)\n",
      "\n",
      "Epoch: 136, Batch number: 50\n",
      "Accuracy on validation dataset: 3872/9723 (39.82%)\n",
      "\n",
      "Epoch: 136, Batch number: 60\n",
      "Accuracy on validation dataset: 3873/9723 (39.83%)\n",
      "\n",
      "Epoch: 136, Batch number: 70\n",
      "Accuracy on validation dataset: 3880/9723 (39.91%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137, Batch number: 4\n",
      "Accuracy on validation dataset: 3887/9723 (39.98%)\n",
      "\n",
      "Epoch: 137, Batch number: 14\n",
      "Accuracy on validation dataset: 3894/9723 (40.05%)\n",
      "\n",
      "Epoch: 137, Batch number: 24\n",
      "Accuracy on validation dataset: 3893/9723 (40.04%)\n",
      "\n",
      "Epoch: 137, Batch number: 34\n",
      "Accuracy on validation dataset: 3894/9723 (40.05%)\n",
      "\n",
      "Epoch: 137, Batch number: 44\n",
      "Accuracy on validation dataset: 3889/9723 (40.00%)\n",
      "\n",
      "Epoch: 137, Batch number: 54\n",
      "Accuracy on validation dataset: 3887/9723 (39.98%)\n",
      "\n",
      "Epoch: 137, Batch number: 64\n",
      "Accuracy on validation dataset: 3893/9723 (40.04%)\n",
      "\n",
      "Epoch: 137, Batch number: 74\n",
      "Accuracy on validation dataset: 3900/9723 (40.11%)\n",
      "\n",
      "Epoch: 138, Batch number: 8\n",
      "Accuracy on validation dataset: 3893/9723 (40.04%)\n",
      "\n",
      "Epoch: 138, Batch number: 18\n",
      "Accuracy on validation dataset: 3895/9723 (40.06%)\n",
      "\n",
      "Epoch: 138, Batch number: 28\n",
      "Accuracy on validation dataset: 3897/9723 (40.08%)\n",
      "\n",
      "Epoch: 138, Batch number: 38\n",
      "Accuracy on validation dataset: 3895/9723 (40.06%)\n",
      "\n",
      "Epoch: 138, Batch number: 48\n",
      "Accuracy on validation dataset: 3900/9723 (40.11%)\n",
      "\n",
      "Epoch: 138, Batch number: 58\n",
      "Accuracy on validation dataset: 3900/9723 (40.11%)\n",
      "\n",
      "Epoch: 138, Batch number: 68\n",
      "Accuracy on validation dataset: 3907/9723 (40.18%)\n",
      "\n",
      "Epoch: 139, Batch number: 2\n",
      "Accuracy on validation dataset: 3913/9723 (40.24%)\n",
      "\n",
      "Epoch: 139, Batch number: 12\n",
      "Accuracy on validation dataset: 3915/9723 (40.27%)\n",
      "\n",
      "Epoch: 139, Batch number: 22\n",
      "Accuracy on validation dataset: 3912/9723 (40.23%)\n",
      "\n",
      "Epoch: 139, Batch number: 32\n",
      "Accuracy on validation dataset: 3916/9723 (40.28%)\n",
      "\n",
      "Epoch: 139, Batch number: 42\n",
      "Accuracy on validation dataset: 3910/9723 (40.21%)\n",
      "\n",
      "Epoch: 139, Batch number: 52\n",
      "Accuracy on validation dataset: 3913/9723 (40.24%)\n",
      "\n",
      "Epoch: 139, Batch number: 62\n",
      "Accuracy on validation dataset: 3917/9723 (40.29%)\n",
      "\n",
      "Epoch: 139, Batch number: 72\n",
      "Accuracy on validation dataset: 3924/9723 (40.36%)\n",
      "\n",
      "Epoch: 140, Batch number: 6\n",
      "Accuracy on validation dataset: 3928/9723 (40.40%)\n",
      "\n",
      "Epoch: 140, Batch number: 16\n",
      "Accuracy on validation dataset: 3934/9723 (40.46%)\n",
      "\n",
      "Epoch: 140, Batch number: 26\n",
      "Accuracy on validation dataset: 3936/9723 (40.48%)\n",
      "\n",
      "Epoch: 140, Batch number: 36\n",
      "Accuracy on validation dataset: 3937/9723 (40.49%)\n",
      "\n",
      "Epoch: 140, Batch number: 46\n",
      "Accuracy on validation dataset: 3940/9723 (40.52%)\n",
      "\n",
      "Epoch: 140, Batch number: 56\n",
      "Accuracy on validation dataset: 3942/9723 (40.54%)\n",
      "\n",
      "Epoch: 140, Batch number: 66\n",
      "Accuracy on validation dataset: 3935/9723 (40.47%)\n",
      "\n",
      "Epoch: 141, Batch number: 0\n",
      "Accuracy on validation dataset: 3942/9723 (40.54%)\n",
      "\n",
      "Epoch: 141, Batch number: 10\n",
      "Accuracy on validation dataset: 3946/9723 (40.58%)\n",
      "\n",
      "Epoch: 141, Batch number: 20\n",
      "Accuracy on validation dataset: 3949/9723 (40.62%)\n",
      "\n",
      "Epoch: 141, Batch number: 30\n",
      "Accuracy on validation dataset: 3951/9723 (40.64%)\n",
      "\n",
      "Epoch: 141, Batch number: 40\n",
      "Accuracy on validation dataset: 3955/9723 (40.68%)\n",
      "\n",
      "Epoch: 141, Batch number: 50\n",
      "Accuracy on validation dataset: 3951/9723 (40.64%)\n",
      "\n",
      "Epoch: 141, Batch number: 60\n",
      "Accuracy on validation dataset: 3956/9723 (40.69%)\n",
      "\n",
      "Epoch: 141, Batch number: 70\n",
      "Accuracy on validation dataset: 3958/9723 (40.71%)\n",
      "\n",
      "Epoch: 142, Batch number: 4\n",
      "Accuracy on validation dataset: 3957/9723 (40.70%)\n",
      "\n",
      "Epoch: 142, Batch number: 14\n",
      "Accuracy on validation dataset: 3961/9723 (40.74%)\n",
      "\n",
      "Epoch: 142, Batch number: 24\n",
      "Accuracy on validation dataset: 3956/9723 (40.69%)\n",
      "\n",
      "Epoch: 142, Batch number: 34\n",
      "Accuracy on validation dataset: 3965/9723 (40.78%)\n",
      "\n",
      "Epoch: 142, Batch number: 44\n",
      "Accuracy on validation dataset: 3969/9723 (40.82%)\n",
      "\n",
      "Epoch: 142, Batch number: 54\n",
      "Accuracy on validation dataset: 3971/9723 (40.84%)\n",
      "\n",
      "Epoch: 142, Batch number: 64\n",
      "Accuracy on validation dataset: 3968/9723 (40.81%)\n",
      "\n",
      "Epoch: 142, Batch number: 74\n",
      "Accuracy on validation dataset: 3965/9723 (40.78%)\n",
      "\n",
      "Epoch: 143, Batch number: 8\n",
      "Accuracy on validation dataset: 3970/9723 (40.83%)\n",
      "\n",
      "Epoch: 143, Batch number: 18\n",
      "Accuracy on validation dataset: 3974/9723 (40.87%)\n",
      "\n",
      "Epoch: 143, Batch number: 28\n",
      "Accuracy on validation dataset: 3973/9723 (40.86%)\n",
      "\n",
      "Epoch: 143, Batch number: 38\n",
      "Accuracy on validation dataset: 3972/9723 (40.85%)\n",
      "\n",
      "Epoch: 143, Batch number: 48\n",
      "Accuracy on validation dataset: 3980/9723 (40.93%)\n",
      "\n",
      "Epoch: 143, Batch number: 58\n",
      "Accuracy on validation dataset: 3984/9723 (40.98%)\n",
      "\n",
      "Epoch: 143, Batch number: 68\n",
      "Accuracy on validation dataset: 3982/9723 (40.95%)\n",
      "\n",
      "Epoch: 144, Batch number: 2\n",
      "Accuracy on validation dataset: 3975/9723 (40.88%)\n",
      "\n",
      "Epoch: 144, Batch number: 12\n",
      "Accuracy on validation dataset: 3973/9723 (40.86%)\n",
      "\n",
      "Epoch: 144, Batch number: 22\n",
      "Accuracy on validation dataset: 3974/9723 (40.87%)\n",
      "\n",
      "Epoch: 144, Batch number: 32\n",
      "Accuracy on validation dataset: 3978/9723 (40.91%)\n",
      "\n",
      "Epoch: 144, Batch number: 42\n",
      "Accuracy on validation dataset: 3982/9723 (40.95%)\n",
      "\n",
      "Epoch: 144, Batch number: 52\n",
      "Accuracy on validation dataset: 3981/9723 (40.94%)\n",
      "\n",
      "Epoch: 144, Batch number: 62\n",
      "Accuracy on validation dataset: 3986/9723 (41.00%)\n",
      "\n",
      "Epoch: 144, Batch number: 72\n",
      "Accuracy on validation dataset: 3987/9723 (41.01%)\n",
      "\n",
      "Epoch: 145, Batch number: 6\n",
      "Accuracy on validation dataset: 3994/9723 (41.08%)\n",
      "\n",
      "Epoch: 145, Batch number: 16\n",
      "Accuracy on validation dataset: 3992/9723 (41.06%)\n",
      "\n",
      "Epoch: 145, Batch number: 26\n",
      "Accuracy on validation dataset: 3992/9723 (41.06%)\n",
      "\n",
      "Epoch: 145, Batch number: 36\n",
      "Accuracy on validation dataset: 3995/9723 (41.09%)\n",
      "\n",
      "Epoch: 145, Batch number: 46\n",
      "Accuracy on validation dataset: 3993/9723 (41.07%)\n",
      "\n",
      "Epoch: 145, Batch number: 56\n",
      "Accuracy on validation dataset: 3997/9723 (41.11%)\n",
      "\n",
      "Epoch: 145, Batch number: 66\n",
      "Accuracy on validation dataset: 4002/9723 (41.16%)\n",
      "\n",
      "Epoch: 146, Batch number: 0\n",
      "Accuracy on validation dataset: 4008/9723 (41.22%)\n",
      "\n",
      "Epoch: 146, Batch number: 10\n",
      "Accuracy on validation dataset: 4005/9723 (41.19%)\n",
      "\n",
      "Epoch: 146, Batch number: 20\n",
      "Accuracy on validation dataset: 4005/9723 (41.19%)\n",
      "\n",
      "Epoch: 146, Batch number: 30\n",
      "Accuracy on validation dataset: 4001/9723 (41.15%)\n",
      "\n",
      "Epoch: 146, Batch number: 40\n",
      "Accuracy on validation dataset: 4004/9723 (41.18%)\n",
      "\n",
      "Epoch: 146, Batch number: 50\n",
      "Accuracy on validation dataset: 4010/9723 (41.24%)\n",
      "\n",
      "Epoch: 146, Batch number: 60\n",
      "Accuracy on validation dataset: 4020/9723 (41.35%)\n",
      "\n",
      "Epoch: 146, Batch number: 70\n",
      "Accuracy on validation dataset: 4020/9723 (41.35%)\n",
      "\n",
      "Epoch: 147, Batch number: 4\n",
      "Accuracy on validation dataset: 4018/9723 (41.32%)\n",
      "\n",
      "Epoch: 147, Batch number: 14\n",
      "Accuracy on validation dataset: 4018/9723 (41.32%)\n",
      "\n",
      "Epoch: 147, Batch number: 24\n",
      "Accuracy on validation dataset: 4026/9723 (41.41%)\n",
      "\n",
      "Epoch: 147, Batch number: 34\n",
      "Accuracy on validation dataset: 4021/9723 (41.36%)\n",
      "\n",
      "Epoch: 147, Batch number: 44\n",
      "Accuracy on validation dataset: 4020/9723 (41.35%)\n",
      "\n",
      "Epoch: 147, Batch number: 54\n",
      "Accuracy on validation dataset: 4026/9723 (41.41%)\n",
      "\n",
      "Epoch: 147, Batch number: 64\n",
      "Accuracy on validation dataset: 4022/9723 (41.37%)\n",
      "\n",
      "Epoch: 147, Batch number: 74\n",
      "Accuracy on validation dataset: 4021/9723 (41.36%)\n",
      "\n",
      "Epoch: 148, Batch number: 8\n",
      "Accuracy on validation dataset: 4025/9723 (41.40%)\n",
      "\n",
      "Epoch: 148, Batch number: 18\n",
      "Accuracy on validation dataset: 4025/9723 (41.40%)\n",
      "\n",
      "Epoch: 148, Batch number: 28\n",
      "Accuracy on validation dataset: 4026/9723 (41.41%)\n",
      "\n",
      "Epoch: 148, Batch number: 38\n",
      "Accuracy on validation dataset: 4030/9723 (41.45%)\n",
      "\n",
      "Epoch: 148, Batch number: 48\n",
      "Accuracy on validation dataset: 4034/9723 (41.49%)\n",
      "\n",
      "Epoch: 148, Batch number: 58\n",
      "Accuracy on validation dataset: 4037/9723 (41.52%)\n",
      "\n",
      "Epoch: 148, Batch number: 68\n",
      "Accuracy on validation dataset: 4033/9723 (41.48%)\n",
      "\n",
      "Epoch: 149, Batch number: 2\n",
      "Accuracy on validation dataset: 4036/9723 (41.51%)\n",
      "\n",
      "Epoch: 149, Batch number: 12\n",
      "Accuracy on validation dataset: 4043/9723 (41.58%)\n",
      "\n",
      "Epoch: 149, Batch number: 22\n",
      "Accuracy on validation dataset: 4046/9723 (41.61%)\n",
      "\n",
      "Epoch: 149, Batch number: 32\n",
      "Accuracy on validation dataset: 4048/9723 (41.63%)\n",
      "\n",
      "Epoch: 149, Batch number: 42\n",
      "Accuracy on validation dataset: 4041/9723 (41.56%)\n",
      "\n",
      "Epoch: 149, Batch number: 52\n",
      "Accuracy on validation dataset: 4041/9723 (41.56%)\n",
      "\n",
      "Epoch: 149, Batch number: 62\n",
      "Accuracy on validation dataset: 4042/9723 (41.57%)\n",
      "\n",
      "Epoch: 149, Batch number: 72\n",
      "Accuracy on validation dataset: 4043/9723 (41.58%)\n",
      "\n",
      "Epoch: 150, Batch number: 6\n",
      "Accuracy on validation dataset: 4046/9723 (41.61%)\n",
      "\n",
      "Epoch: 150, Batch number: 16\n",
      "Accuracy on validation dataset: 4044/9723 (41.59%)\n",
      "\n",
      "Epoch: 150, Batch number: 26\n",
      "Accuracy on validation dataset: 4035/9723 (41.50%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Batch number: 36\n",
      "Accuracy on validation dataset: 4041/9723 (41.56%)\n",
      "\n",
      "Epoch: 150, Batch number: 46\n",
      "Accuracy on validation dataset: 4044/9723 (41.59%)\n",
      "\n",
      "Epoch: 150, Batch number: 56\n",
      "Accuracy on validation dataset: 4045/9723 (41.60%)\n",
      "\n",
      "Epoch: 150, Batch number: 66\n",
      "Accuracy on validation dataset: 4044/9723 (41.59%)\n",
      "\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 150              # Cantidad de epochs\n",
    "learning_rate = 5e-4      # Tasa de aprendizaje\n",
    "sample_loss_every = 10    # Calcular la loss cada este n√∫mero\n",
    "algorithm = 'Adam'        # Algoritmo de optimizaci√≥n\n",
    "\n",
    "trainer.Train(algorithm=algorithm, epochs=epochs, sample_loss_every=sample_loss_every, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainer.performance_history['iter'],trainer.performance_history['loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
