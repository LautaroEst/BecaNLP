{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(sys.path[0].split('Documents')[0],'Documents/BecaNLP/Utils'))\n",
    "\n",
    "import NLPUtils as nlp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLPUtils.classifiers import SVCClassifier as svm\n",
    "from NLPUtils.classifiers import MultinomialNB\n",
    "from NLPUtils.datasets import imdb\n",
    "\n",
    "def label_fn(labels):\n",
    "    labels[labels < 5] = 0\n",
    "    labels[labels > 6] = 1\n",
    "    return labels\n",
    "\n",
    "train_dataset = imdb.get_train_dataframe()\n",
    "vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,token_pattern=r'\\b\\w+\\b')\n",
    "#X_train, y_train = vectorizer.fit_transform(train_dataset)\n",
    "#train_dataset = vectorizer.fit_transform(train_dataset)\n",
    "#dev_dataset = vectorizer.transform(dev_dataset)\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 13/20 (65.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.train_dev_validation(classifier,train_dataset,vectorizer,dev_size=.1,random_state=0,metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 4235/5000 (84.70%)\n",
      "Total accuracy: 4259/5000 (85.18%)\n",
      "Total accuracy: 4177/5000 (83.54%)\n",
      "Total accuracy: 4204/5000 (84.08%)\n",
      "Total accuracy: 4228/5000 (84.56%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.847, 0.8518, 0.8354, 0.8408, 0.8456]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.k_fold_validation(classifier,train_dataset,vectorizer,k_folds=5,random_state=0,metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10000. Total accuracy: 296/581 (50.95%)\n",
      "Vocabulary size: 20000. Total accuracy: 309/581 (53.18%)\n",
      "Vocabulary size: 50000. Total accuracy: 322/581 (55.42%)\n",
      "Vocabulary size: 80000. Total accuracy: 328/581 (56.45%)\n",
      "Vocabulary size: 100000. Total accuracy: 331/581 (56.97%)\n"
     ]
    }
   ],
   "source": [
    "from NLPUtils.datasets import tass\n",
    "from NLPUtils.classifiers import MultinomialNB, BernoulliNB, SVCClassifier as SVM, LinearSVCClassifier as LinearSVM\n",
    "\n",
    "def label_fn(labels):\n",
    "    labels_dict = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "    return np.array([labels_dict[label] for label in labels])\n",
    "\n",
    "train_dataset = tass.get_train_dataframe()\n",
    "dev_dataset = tass.get_dev_dataframe()\n",
    "classifier = MultinomialNB()\n",
    "#classifier = BernoulliNB()\n",
    "#classifier = SVM()\n",
    "#classifier = LinearSVM()\n",
    "\n",
    "for vocab_size in [10000, 20000, 50000, 80000, 100000]:\n",
    "    vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                       ngram_range=(1,20),max_features=vocab_size)\n",
    "    print('Vocabulary size: {}.'.format(vocab_size),end=' ')\n",
    "    nlp.train_dev_validation(classifier,train_dataset,vectorizer,dev_dataset=dev_dataset,metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 120000. Total accuracy: 329/581 (56.63%)\n",
      "Vocabulary size: 150000. Total accuracy: 324/581 (55.77%)\n",
      "Vocabulary size: 200000. Total accuracy: 322/581 (55.42%)\n",
      "Vocabulary size: 500000. Total accuracy: 311/581 (53.53%)\n"
     ]
    }
   ],
   "source": [
    "for vocab_size in [120000, 150000, 200000, 500000]:\n",
    "    vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                       ngram_range=(1,20),max_features=vocab_size)\n",
    "    print('Vocabulary size: {}.'.format(vocab_size),end=' ')\n",
    "    nlp.train_dev_validation(classifier,train_dataset,vectorizer,dev_dataset=dev_dataset,metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLPUtils.datasets import tass2018 as tass\n",
    "from NLPUtils.classifiers import MultinomialNB\n",
    "\n",
    "train_df = tass.get_train_dataframe(lang=['es'])\n",
    "dev_df = tass.get_dev_dataframe(lang=['es'])\n",
    "test_df = tass.get_test_dataframe(lang=['es'])\n",
    "test_df['label'] = 'N'\n",
    "\n",
    "def label_fn(labels):\n",
    "    labels_dict = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "    return np.array([labels_dict[label] for label in labels])\n",
    "\n",
    "vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                       ngram_range=(1,20),max_features=100000)\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "train_dataset = vectorizer.fit_transform(train_df)\n",
    "test_dataset = vectorizer.transform(test_df.loc[:,['text','label']])\n",
    "\n",
    "classifier.train(train_dataset)\n",
    "_, y_predict = classifier.predict(test_dataset)\n",
    "for i in range(4):\n",
    "    print((y_predict == i).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-Me caes muy bien \\n-Tienes que jugar más partidas al lol con Russel y conmigo\\n-Por qué tan Otako, deja de ser otako\\n-Haber si me muero'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, (text, label) = next(train_df.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_idx = {label: idx for idx, label in enumerate(np.unique(train_df['label']))}\n",
    "idx_to_labels = {idx:label for label, idx in labels_to_idx.items()}\n",
    "labels_predict = [idx_to_labels[idx] for idx in y_predict]\n",
    "test_df['label'] = labels_predict\n",
    "test_df.loc[:,['tweet_id','label']].to_csv('./text_results.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.train_dev_validation(classifier,train_df,vectorizer,dev_dataset=dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 288/506 (56.92%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5691699604743083"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261\n",
      "1\n",
      "2\n",
      "635\n"
     ]
    }
   ],
   "source": [
    "classifier.train(train_dataset)\n",
    "y_test, y_predict = classifier.predict(test_dataset)\n",
    "for i in range(4):\n",
    "    print((y_predict == i).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769930322721013760</td>\n",
       "      <td>@JPelirrojo me encantan los VAPES gracias por ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>769934500159688705</td>\n",
       "      <td>@yddeon la Universidad es fácil porque estudia...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>769937561590652928</td>\n",
       "      <td>@_cuteresa Son dos frases. La una complementa ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769985604725637121</td>\n",
       "      <td>@ratgull @Vespacityman @Kellydeharo @ELpuebloM...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>769993102442524674</td>\n",
       "      <td>@ImFebrer @MalagaCF Ninguno de los clubes lo h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  769930322721013760  @JPelirrojo me encantan los VAPES gracias por ...   \n",
       "1  769934500159688705  @yddeon la Universidad es fácil porque estudia...   \n",
       "2  769937561590652928  @_cuteresa Son dos frases. La una complementa ...   \n",
       "3  769985604725637121  @ratgull @Vespacityman @Kellydeharo @ELpuebloM...   \n",
       "4  769993102442524674  @ImFebrer @MalagaCF Ninguno de los clubes lo h...   \n",
       "\n",
       "   label  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'] = np.nan\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
