{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 1: Ciclo de trabajo\n",
    "\n",
    "El objetivo ahora es describir con un ejemplo el ciclo de trabajo que se usa para entrenar un algoritmo de NLP. En este caso se hará **clasificación de texto sobre el corpus AG NEWS**: se desea predecir, a partir de una frase perteneciente al corpus, el tipo de noticia (Internacional, Deportes, Negocios o Ciencia/Tecnología) a la que pertenece. La idea no es implementar un modelo muy complicado, sino estudiar todo el proceso de programación al rededor del mismo. Esto incluye:\n",
    "\n",
    "1. Definir las muestras a partir de del corpus de texto en una forma eficiente. En este caso se dispone del corpus *AG NEWS*, conformado por una colección de noticias pertenecientes a distintas categorías. De cada noticia se conoce a qué categoría pertenece. Con esto, se definen los conjuntos de entrenamiento, validación y testeo. \n",
    "\n",
    "2. Crear un objeto que permita manejar las muestras en un formato \"utilizable\". Este objeto se conoce como Dataloader y hay uno por cada conjunto de muestras. \n",
    "\n",
    "3. Definir un modelo simple y el grafo computacional que permita ejecutar el algoritmo de *backpropagation* para encontrar los parámetros del modelo.\n",
    "\n",
    "4. Crear las funciones para visualizar que el entrenamiento se está realizando con éxito. Esto generalmente incluye el loop principal del algoritmo y el cálculo de la cantidad de aciertos en el conjunto de validación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creación de las muestras\n",
    "\n",
    "Nuestro dataset es conjunto de muestras, cada una de ellas conformada por una secuencia de palabras o *tokens*, que conforman una frase de una noticia del corpus, y un label que indica la categoría a la que pertenece esa secuencia de tokens. \n",
    "\n",
    "    sample1 = ( ['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.', 'wall st', 'st .', '. bears', 'bears claw', 'claw back', 'back into', 'into the', 'the black', 'black (', '( reuters', 'reuters )', ') reuters', 'reuters -', '- short-sellers', 'short-sellers ,', ', wall', 'wall street', \"street '\", \"' s\", 's dwindling\\\\band', 'dwindling\\\\band of', 'of ultra-cynics', 'ultra-cynics ,', ', are', 'are seeing', 'seeing green', 'green again', 'again .'], 'Business' )\n",
    "    \n",
    "    sample2 = ( ['european', 'union', 'extends', 'microsoft-time', 'warner', 'review', 'brussels', ',', 'belgium', '(', 'ap', ')', '--', 'european', 'antitrust', 'regulators', 'said', 'monday', 'they', 'have', 'extended', 'their', 'review', 'of', 'a', 'deal', 'between', 'microsoft', 'corp', '.', '(', 'msft', ')', 'and', 'time', 'warner', 'inc', '.', '.', '.', 'european union', 'union extends', 'extends microsoft-time', 'microsoft-time warner', 'warner review', 'review brussels', 'brussels ,', ', belgium', 'belgium (', '( ap', 'ap )', ') --', '-- european', 'european antitrust', 'antitrust regulators', 'regulators said', 'said monday', 'monday they', 'they have', 'have extended', 'extended their', 'their review', 'review of', 'of a', 'a deal', 'deal between', 'between microsoft', 'microsoft corp', 'corp .', '. (', '( msft', 'msft )', ') and', 'and time', 'time warner', 'warner inc', 'inc .', '. .', '. .'], 'Sci/Tec')\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    sampleN = ( ['patriots', 'sign', 'top', 'pick', 'watson', '(', 'reuters', ')', 'reuters', '-', 'the', 'new', 'england', 'patriots\\\\monday', 'announced', 'the', 'signing', 'of', 'first-round', 'draft', 'pick', 'benjamin\\\\watson', '.', 'as', 'per', 'team', 'policy', ',', 'terms', 'of', 'the', 'tight', 'end', \"'\", 's', 'deal', 'were\\\\not', 'released', '.', 'patriots sign', 'sign top', 'top pick', 'pick watson', 'watson (', '( reuters', 'reuters )', ') reuters', 'reuters -', '- the', 'the new', 'new england', 'england patriots\\\\monday', 'patriots\\\\monday announced', 'announced the', 'the signing', 'signing of', 'of first-round', 'first-round draft', 'draft pick', 'pick benjamin\\\\watson', 'benjamin\\\\watson .', '. as', 'as per', 'per team', 'team policy', 'policy ,', ', terms', 'terms of', 'of the', 'the tight', 'tight end', \"end '\", \"' s\", 's deal', 'deal were\\\\not', 'were\\\\not released', 'released .'], 'Sports')\n",
    "\n",
    "Para hacer más eficiente la definición de las muestras se define el **vocabulario**, que contiene todas las palabras que aparecen en el corpus. De esta forma, la secuencia de palabras va a pasar a componerse del índice del vocabulario de cada una de estas palabras, y la categoría, a ser el índice en la lista de categorías `['World', 'Sports', 'Business', 'Sci/Tec']`.\n",
    "\n",
    "    sample1 = (tensor([    572,     564,       2,    2326,   49106,     150,      88,       3,\n",
    "                          1143,      14,      32,      15,      32,      16,  443749,       4,\n",
    "                           572,     499,      17,      10,  741769,       7,  468770,       4,\n",
    "                            52,    7019,    1050,     442,       2,   14341,     673,  141447,\n",
    "                        326092,   55044,    7887,     411,    9870,  628642,      43,      44,\n",
    "                           144,     145,  299709,  443750,   51274,     703,   14312,      23,\n",
    "                       1111134,  741770,  411508,  468771,    3779,   86384,  135944,  371666,\n",
    "                          4052], 2)\n",
    "\n",
    "    sample2 = (tensor([   227,    377,   4085,  81800,   1910,   1790,   3038,      4,   6645,\n",
    "                           14,     36,     15,     67,    227,   2631,   1384,     31,     74,\n",
    "                           90,     49,   2393,     50,   1790,      7,      6,    164,    312,\n",
    "                          101,    115,      2,     14,   4406,     15,      9,    134,   1910,\n",
    "                           85,      2,      2,      2,   1068, 469452, 358665,  81801, 474085,\n",
    "                       433611,  18201,  16373,  62492,     62,     63,    584,  71591,  44508,\n",
    "                        26665,  25055,    979,  19427,   1845,  52443,  17357, 165870,  10476,\n",
    "                          107,   1187,  23580,  51777,    981,    126,    384,  13942,  12119,\n",
    "                         2404,  16413,   3225,   9773,     89,     37,     37]), 3 )\n",
    "\n",
    "    ...\n",
    "\n",
    "    sampleN = (tensor([   1968,    1025,     181,    3153,   22347,      14,      32,      15,\n",
    "                            32,      16,       3,      27,     430, 1029946,     184,       3,\n",
    "                          4162,       7,    7000,    3061,    3153,  622440,       2,      21,\n",
    "                           677,     148,    1247,       4,    2358,       7,       3,    3389,\n",
    "                           208,      17,      10,     164, 1283369,     466,       2,  418788,\n",
    "                        205275,   84380,  420603,  474767,      43,      44,     144,     145,\n",
    "                           119,     324,    2872,  753763, 1029947,    3056,   38172,   30591,\n",
    "                        158144,   49428,   26084, 1037969,  622441,    3782,   54761,   75502,\n",
    "                         70592,   15745,  170329,    7607,      29,   84113,   18112,  355484,\n",
    "                            23,   32659,  713718, 1283370,   23833]), 1 )\n",
    "                            \n",
    "De tener el corpus distribuído en varios archivos, se debería hacer un preprocesamiento en el cual esos archivos pasan a ser muestras como las que se muestran a continuación. Este preprocesamiento incluye la tokenización, el conteo de frecuencias de cada palabra, la definición del vocabulario y el relleno con ceros para que todas tengan el mismo largo, entre otras cosas. Este paso tiene bastante importancia en el resultado final, por lo que juega un papel bastante importante, pero lo vamos a dejar para otro tutorial.\n",
    "\n",
    "El dataset va a ser representado por una instancia de la clase `AgNewsDataset`, definida por nosotros, que es a su vez una subclase de la clase `torch.utils.data.Dataset` (que es la madre de todas las clases para entrenar redes neuronales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000lines [00:04, 26133.95lines/s]\n",
      "120000lines [00:08, 14288.85lines/s]\n",
      "7600lines [00:00, 14704.91lines/s]\n",
      "120000lines [00:04, 26369.68lines/s]\n",
      "120000lines [00:08, 14214.49lines/s]\n",
      "7600lines [00:00, 11527.20lines/s]\n",
      "120000lines [00:04, 26434.21lines/s]\n",
      "120000lines [00:08, 14219.97lines/s]\n",
      "7600lines [00:00, 14646.98lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import text_classification\n",
    "NGRAMS = 2\n",
    "import os\n",
    "if not os.path.isdir('../AG_NEWS'):\n",
    "    os.mkdir('../AG_NEWS')\n",
    "\n",
    "\n",
    "class AgNewsDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    unk_token = 'UNK_TOKEN'\n",
    "    pad_token = 'PAD_TOKEN'\n",
    "    \n",
    "    def __init__(self, root_dir='./AG_NEWS', n_grams=2, train=True):\n",
    "        \n",
    "        super(AgNewsDataset, self).__init__()\n",
    "        train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
    "            root=root_dir, ngrams=n_grams, vocab=None)\n",
    "        \n",
    "        if train:\n",
    "            self.samples = train_dataset._data\n",
    "            self.vocabulary = list(dict(train_dataset._vocab.freqs).keys())\n",
    "            self.freqs = dict(train_dataset._vocab.freqs)\n",
    "        else:\n",
    "            self.samples = test_dataset._data\n",
    "            self.vocabulary = list(dict(test_dataset._vocab.freqs).keys())\n",
    "            self.freqs = dict(test_dataset._vocab.freqs)\n",
    "            \n",
    "        self.vocabulary.insert(0,self.pad_token)\n",
    "        self.vocabulary.insert(1,self.unk_token)\n",
    "        self.word_to_index = {w: idx for (idx, w) in enumerate(self.vocabulary)}\n",
    "        self.index_to_word = {idx: w for (idx, w) in enumerate(self.vocabulary)}\n",
    "        self.size_of_longest_sentence = max([len(sample[1]) for sample in self.samples])\n",
    "        self.categories = ['World', 'Sports', 'Business', 'Sci/Tec']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label, text = self.samples[idx]\n",
    "        text = torch.nn.functional.pad(text, \n",
    "                                       pad=(0,self.size_of_longest_sentence - len(text)),\n",
    "                                       mode='constant', \n",
    "                                       value=self.word_to_index[self.pad_token])\n",
    "        return text, label\n",
    "    \n",
    "train_dataset = AgNewsDataset(root_dir='../AG_NEWS', n_grams=2, train=True)\n",
    "val_dataset = AgNewsDataset(root_dir='../AG_NEWS', n_grams=2, train=True)\n",
    "test_dataset = AgNewsDataset(root_dir='../AG_NEWS', n_grams=2, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la clase anterior se sobreescribieron los métodos `__len__` y `__getitem__` que sirven, respectivamente, para obtener el tamaño del dataset con la función `len()` de Python y para indexar a las instancias de la clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de muestras de entrenamiento: 120000\n",
      "Cantidad de muestras de testeo: 7600\n",
      "\n",
      "Ejemplo de muestra:\n",
      "(tensor([    572,     564,       2,    2326,   49106,     150,      88,       3,\n",
      "           1143,      14,      32,      15,      32,      16,  443749,       4,\n",
      "            572,     499,      17,      10,  741769,       7,  468770,       4,\n",
      "             52,    7019,    1050,     442,       2,   14341,     673,  141447,\n",
      "         326092,   55044,    7887,     411,    9870,  628642,      43,      44,\n",
      "            144,     145,  299709,  443750,   51274,     703,   14312,      23,\n",
      "        1111134,  741770,  411508,  468771,    3779,   86384,  135944,  371666,\n",
      "           4052,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0,       0,       0,       0,\n",
      "              0,       0,       0,       0,       0]), 2)\n",
      "\n",
      "Misma muestra con las palabras del vocabulario: \n",
      "([', 000', 'at an', 'wall', 'knew', 'internationally', 'soaring crude', 'aerospace (', 'st', '12-nation', '-', 'back into', 'short-sellers', 'back into', ',', 'camara is', '.', ', 000', 'work', 'street', 'black', 'elyria ,', 'back', 'qqq ,', '.', 'seeing green', 'the environmental', '19 to', 'midsummer', 'wall', 'arizona ,', 'tehran (', 'and relief', 'two cortisone', 'blocs', 'demonstrates', '#36 849', '26 ,', 'spacecraft roared', 'wall street', \"street '\", 'economy cloud', 'cloud stocks', 'ofcom says', 'play alongside', 'challenged the', 's opec', 'wannabe', 'are', 'its difficult', 'their animosity', 'http deltas', 'nasdaq sooner', 'go anyway', 'despite russia', 'upheld four', 'ecology and', 'surrenders', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN', 'PAD_TOKEN'], 'Business')\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de muestras de entrenamiento:', len(train_dataset) )\n",
    "print('Cantidad de muestras de testeo:', len(test_dataset) )\n",
    "print()\n",
    "\n",
    "text, label = train_dataset[0]\n",
    "print('Ejemplo de muestra:')\n",
    "print( (text, label) )\n",
    "print()\n",
    "print('Misma muestra con las palabras del vocabulario: ')\n",
    "print( ([train_dataset.index_to_word[int(idx)] for idx in text], train_dataset.categories[label]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Batch de muestras\n",
    "\n",
    "Una vez definido el dataset, se obtiene el dataloader, el cual es una subclase de la clase `torch.utils.data.DataLoader` y recibe como argumentos:\n",
    "\n",
    "* una función para muestrear aleatoriamente, \n",
    "* el tamaño del batch y \n",
    "* la instancia de `torch.utils.data.Dataset` definida anteriormente.\n",
    "\n",
    "Además, en este paso definimos cuántas y cuáles muestras del conjunto de entrenamiento se van a usar como validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 # Tamaño del batch\n",
    "val_size = .05 # Proporción de muestras utilizadas para validación \n",
    "NUM_TRAIN = int((1 - val_size) * len(train_dataset)) # Cantidad de muestras de entrenamiento\n",
    "NUM_VAL = len(train_dataset) - NUM_TRAIN # Cantidad de muestras para validación\n",
    "sampler = lambda start, end: torch.utils.data.SubsetRandomSampler(range(start, end)) # Función para mezclar aleatoriamente las muestras\n",
    "\n",
    "\n",
    "# Dataloader para las muestras de entrenamiento:\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                               batch_size=batch_size, \n",
    "                                               sampler=sampler(0, NUM_TRAIN))\n",
    "\n",
    "# Dataloader para las muestras de validación:\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                             batch_size=batch_size, \n",
    "                                             sampler=sampler(NUM_TRAIN, NUM_TRAIN+NUM_VAL))\n",
    "\n",
    "# Dataloader para las muestras de testeo:\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Definición del modelo\n",
    "\n",
    "Para este ejemplo vamos a usar implementar simplemente una red de una capa, con salida Softmax, y el *Negative Log Likelihood* como función de costo. Esto es equivalente minimizar la *Cross Entropy* entre las puntuaciones de cada clase.\n",
    "\n",
    "![alt text](model.png)\n",
    "\n",
    "Los modelos en Pytorch pueden hacerse de muchas formas, pero la más cómoda es la que implica hacer una sublcase de `torch.nn.Module` (que es la madre de todos los modelos) y definir dentro de ella el método `forward()` y el método `loss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SoftmaxClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vectors, n_classes):\n",
    "        \n",
    "        super(SoftmaxClassifier, self).__init__()\n",
    "        self.emb = nn.Embedding(n_vectors, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        scores = self.emb(x).mean(dim=1)\n",
    "        return scores\n",
    "    \n",
    "    def loss(self, scores, target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        return lf(scores, target)\n",
    "    \n",
    "n_classes = len(train_dataset.categories) # Cantidad de categorías\n",
    "n_vectors = len(train_dataset.vocabulary) # Cantidad de palabras que contiene la frase\n",
    "model = SoftmaxClassifier(n_vectors, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmbeddingSoftmaxClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vectors, embedding_dim, n_classes):\n",
    "        \n",
    "        super(EmbeddingSoftmaxClassifier, self).__init__()\n",
    "        self.emb = nn.Embedding(n_vectors, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x).mean(dim=1)\n",
    "        scores = self.linear(emb)\n",
    "        return scores\n",
    "    \n",
    "    def loss(self, scores, target):\n",
    "        lf = nn.CrossEntropyLoss()\n",
    "        return lf(scores, target)\n",
    "    \n",
    "n_classes = len(train_dataset.categories) # Cantidad de categorías\n",
    "n_vectors = len(train_dataset.vocabulary) # Cantidad de palabras que contiene la frase\n",
    "embedding_dim = 100\n",
    "model = EmbeddingSoftmaxClassifier(n_vectors, embedding_dim, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def CheckAccuracy(loader, model, device, input_dtype, target_dtype):  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=input_dtype)  \n",
    "            y = y.to(device=device, dtype=target_dtype)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "        return num_correct, num_samples\n",
    "        \n",
    "\n",
    "def TrainModel(model, data, epochs=1, learning_rate=1e-2, sample_loss_every=100):\n",
    "    \n",
    "    input_dtype = data['input_dtype'] \n",
    "    target_dtype = data['target_dtype']\n",
    "    device = data['device']\n",
    "    train_dataloader = data['train_dataloader']\n",
    "    val_dataloader = data['val_dataloader']\n",
    "    \n",
    "    performance_history = {'iter': [], 'loss': [], 'accuracy': []}\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    batch_size = len(train_dataloader)\n",
    "    for e in range(epochs):\n",
    "        for t, (x,y) in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            x = x.to(device=device, dtype=input_dtype)\n",
    "            y = y.to(device=device, dtype=target_dtype)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x) \n",
    "            \n",
    "            # Backward pass\n",
    "            loss = model.loss(scores,y)                 \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (e * batch_size + t) % sample_loss_every == 0:\n",
    "                num_correct, num_samples = CheckAccuracy(val_dataloader, model, device, input_dtype, target_dtype)\n",
    "                performance_history['iter'].append(t)\n",
    "                performance_history['loss'].append(loss.item())\n",
    "                performance_history['accuracy'].append(float(num_correct) / num_samples)\n",
    "                print('Epoch: %d, Iteration: %d, Accuracy: %d/%d ' % (e, t, num_correct, num_samples))\n",
    "                \n",
    "    num_correct, num_samples = CheckAccuracy(val_dataloader, model, device, input_dtype, target_dtype)\n",
    "    print('Final accuracy: %.2f%%' % (100 * float(num_correct) / num_samples) )\n",
    "    \n",
    "    return performance_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Accuracy: 1479/6000 \n",
      "Epoch: 1, Iteration: 77, Accuracy: 1473/6000 \n",
      "Epoch: 2, Iteration: 154, Accuracy: 1465/6000 \n",
      "Epoch: 4, Iteration: 8, Accuracy: 1481/6000 \n",
      "Epoch: 5, Iteration: 85, Accuracy: 1485/6000 \n",
      "Epoch: 6, Iteration: 162, Accuracy: 1481/6000 \n",
      "Epoch: 8, Iteration: 16, Accuracy: 1491/6000 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fd6377dd6f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Entrenamiento:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mperformance_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_loss_every\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-ba210f9a0902>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, data, epochs, learning_rate, sample_loss_every)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TorchEnv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TorchEnv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TorchEnv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-32b5d0a0d0a5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                        \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_of_longest_sentence\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                        \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                        value=self.word_to_index[self.pad_token])\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TorchEnv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   2846\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding length too large'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2848\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_pad_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2849\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding mode \"{}\"\" doesn\\'t take in value argument'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Especificaciones de cómo adquirir los datos para entrenamiento:\n",
    "use_gpu = True\n",
    "if torch.cuda.is_available() and use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "data = {\n",
    "    'device': device,\n",
    "    'input_dtype': torch.long,\n",
    "    'target_dtype': torch.long,\n",
    "    'train_dataloader': train_dataloader,\n",
    "    'val_dataloader': val_dataloader\n",
    "}\n",
    "\n",
    "# Hiperparámetros del modelo y otros:\n",
    "epochs = 200 # Cantidad de epochs\n",
    "sample_loss_every = 300 # Cantidad de iteraciones para calcular la cantidad de aciertos\n",
    "learning_rate = 1e-4 # Tasa de aprendizaje\n",
    "\n",
    "# Entrenamiento:\n",
    "performance_history = TrainModel(model, data, epochs, learning_rate, sample_loss_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario:  1308844\n",
      "Cantidad de muestras de entrenamiento:  114000\n"
     ]
    }
   ],
   "source": [
    "print('Tamaño del vocabulario: ', len(train_dataset.vocabulary))\n",
    "print('Cantidad de muestras de entrenamiento: ', NUM_TRAIN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
