{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas generales de Sentiment Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Introducción al tema..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas a tener en cuenta\n",
    "\n",
    "* En los reviews de productos suele haber una tendencia al sesgo de los comentarios positivos (p 100 P&L)\n",
    "\n",
    "* P&L recomiendan extraer las frases subjetivas y no incluir las objetivas pero yo creo que eso es hacer un poco de trampa.\n",
    "\n",
    "* Una posibilidad es seleccionar por tópicos o tipos de productos\n",
    "\n",
    "* Podría considerarse el problema de resumen de sentimientos, además de la categorización, y para eso usar el título del review.\n",
    "\n",
    "* Considerar diferentes momentos para obtener los reviews [ver](https://www.aaai.org/Papers/Symposia/Spring/2004/SS-04-07/SS04-07-003.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO list:\n",
    "\n",
    "* Armar el datasheet del dataset MeLiSA e ir definiendo las características del mismo a partir de éste. Para eso, sería recomendable leer P&L, el paper de IMDb y el paper de datasheets for datasets\n",
    "\n",
    "* Ver la [clase de sesgos en NLP](https://www.youtube.com/watch?v=XR8YSRcuVLE&feature=youtu.be) y las de evaluation metrics [1](https://youtu.be/3UGti9Ju5j8) y [2](https://youtu.be/YygGzfkhtJc) y estudiarlas bien bien.\n",
    "\n",
    "* Analizar los posibles sesgos del dataset y modificar el datasheet del primer punto hasta que quede bien armado.\n",
    "\n",
    "* Ir armando el paper. Tratar de separar las tareas para darle cosas para hacer a Mati y a Leo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen cap 3, 4 y 5 de Pang & Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capítulo 3: Desafíos generales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El capítulo habla de por qué las tarea de clasificación de sentimientos es distinta a la de clasificación de texto en general. Se argumenta que extraer palabras relacionadas con el significado o la connotación (positiva o negativa) no es un gran indicativo de si el documento pertenece a una categoría determinada, debido a que los sentimientos pueden expresarse de manera mucho más sutil que simplemente explicitando una palabra clave y a que las oraciones suelen ser muy dependientes del contexto. Además el orden en que se dicen las cosas importan mucho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejercicio podemos probar clasificar texto con NaiveBayes+BOW y con LogisticRegression+BODocs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    262074\n",
       "and    141788\n",
       "a      141404\n",
       "of     129873\n",
       "to     121115\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Utilizo el dataset IMDb\n",
    "ds, ds_info = tfds.load('imdb_reviews',\n",
    "                        split=None, # Descargo todos los splits\n",
    "                        download=True, # Si no está descargado, que se descargue\n",
    "                        with_info=True, # Quiero que devuelva info del dataset\n",
    "                       )\n",
    "\n",
    "# Decodifico a dataframes con strings comunes\n",
    "df_train = tfds.as_dataframe(ds['train'], ds_info)\n",
    "df_train['text'] = df_train['text'].str.decode('utf-8')\n",
    "df_test = tfds.as_dataframe(ds['test'], ds_info)\n",
    "df_test['text'] = df_test['text'].str.decode('utf-8')\n",
    "\n",
    "# Divido en train, val, test \n",
    "random_seed = 16254872\n",
    "rs = np.random.RandomState(random_seed)\n",
    "val_size = .1\n",
    "mask = rs.rand(len(df_train)) < val_size\n",
    "df_val = df_train[mask].copy()\n",
    "df_train = df_train[~mask].copy()\n",
    "\n",
    "# Tokenizo\n",
    "df_train['text'] = df_train['text'].str.findall(r'[a-zA-Z0-9]+')\n",
    "df_val['text'] = df_val['text'].str.findall(r'[a-zA-Z0-9]+')\n",
    "df_test['text'] = df_test['text'].str.findall(r'[a-zA-Z0-9]+')\n",
    "\n",
    "# Obtengo el vocabulario\n",
    "vocab = df_train['text'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from itertools import tee, islice\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_ngrams(doc, ngram_range=(1,1)):\n",
    "\n",
    "    for n in range(ngram_range[0],ngram_range[1]+1):\n",
    "        tlst = doc\n",
    "        while True:\n",
    "            a, b = tee(tlst)\n",
    "            l = tuple(islice(a, n))\n",
    "            if len(l) == n:\n",
    "                yield ' '.join(l)\n",
    "                next(b)\n",
    "                tlst = b\n",
    "            else:\n",
    "                break\n",
    "\n",
    "def count_bag_of_ngrams(corpus, ngram_range=(1,1), tokenizer=None):\n",
    "\n",
    "    if tokenizer is None:\n",
    "        tokenizer = lambda x: x\n",
    "\n",
    "    data = []\n",
    "    indices = []\n",
    "    indptr = [0]\n",
    "\n",
    "    full_vocab = defaultdict()\n",
    "    full_vocab.default_factory = full_vocab.__len__\n",
    "\n",
    "    for doc in tqdm(corpus):\n",
    "        features = dict(Counter(get_ngrams(tokenizer(doc),ngram_range)))\n",
    "        data.extend(features.values())\n",
    "        indices.extend([full_vocab[tk] for tk in features])\n",
    "        indptr.append(len(indices))\n",
    "\n",
    "    vocab_len = len(full_vocab)\n",
    "    X = csr_matrix((data,indices,indptr),shape=(len(corpus),vocab_len))\n",
    "    \n",
    "    return X, dict(full_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
