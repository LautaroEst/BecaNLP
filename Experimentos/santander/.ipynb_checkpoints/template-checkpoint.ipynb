{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
>>>>>>> 838bcdc64af5c11cac9f8baf11ebdca86afdca9f
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(sys.path[0].split('Documents')[0],'Documents/BecaNLP/Utils'))\n",
    "\n",
    "import NLPUtils as nlp\n",
    "import pandas as pd\n",
<<<<<<< HEAD
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
=======
>>>>>>> 838bcdc64af5c11cac9f8baf11ebdca86afdca9f
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv',sep = '|')\n",
    "df.columns = ['Pregunta', 'Intencion']\n",
    "df = pd.read_csv('train.csv',sep = '|')\n",
    "df['Intencion'] = df.Intencion.str.findall(r'\\d+').apply(lambda x: int(x[0]))\n",
    "categories = set(df['Intencion'].values)\n",
    "name2idx = {name:idx for idx, name in enumerate(categories)}\n",
    "idx2name = {idx:name for idx, name in enumerate(categories)}\n",
    "_ = plt.hist(df['Intencion'].values,bins=max(df['Intencion']))\n",
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregunta</th>\n",
       "      <th>Intencion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>como puedo trabajar en santander rio</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pagar tarjeta visa querer reintegro</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pagar tarjeta naranja sistema</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no se debitó la primera cuota del plan de bien...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abonar tarjeta credito</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pregunta  Intencion\n",
       "0               como puedo trabajar en santander rio          5\n",
       "1                pagar tarjeta visa querer reintegro        272\n",
       "2                      pagar tarjeta naranja sistema         32\n",
       "3  no se debitó la primera cuota del plan de bien...         28\n",
       "4                             abonar tarjeta credito        263"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv',sep = '|')\n",
    "df.columns = ['Pregunta', 'Intencion']\n",
    "name2idx = {name:idx for idx, name in enumerate(sorted(list(df['Intencion'].unique())))}\n",
    "idx2name = {idx:name for idx, name in enumerate(sorted(list(df['Intencion'].unique())))}\n",
    "df['Intencion'] = df['Intencion'].apply(lambda name: name2idx[name])\n",
>>>>>>> 838bcdc64af5c11cac9f8baf11ebdca86afdca9f
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificamos\n",
    "\n",
    "Modelo baseline de clasificación"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 838bcdc64af5c11cac9f8baf11ebdca86afdca9f
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Separamos en Train y Test:\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.Pregunta, df.Intencion, random_state = 0)\n",
    "\n",
    "# Vectorizamos:\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer(sublinear_tf=True)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\n",
    "\n",
    "# Entrenamos:\n",
    "clf = SVC(C=2)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecimos:\n",
    "y_train_pred = clf.predict(X_train_tfidf)\n",
    "y_test_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluamos los resultados"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para train:\n",
      "{'accuracy': 0.9982093115797851, 'f1_macro': 0.9975977650111755, 'balanced_accuracy': 0.9963028504610097}\n",
      "Resultados para test:\n",
      "{'accuracy': 0.7361719060883406, 'f1_macro': 0.5912111017796756, 'balanced_accuracy': 0.5391156984294679}\n"
     ]
    }
   ],
>>>>>>> 838bcdc64af5c11cac9f8baf11ebdca86afdca9f
   "source": [
    "from NLPUtils.classification import get_score\n",
    "\n",
    "metrics = ['accuracy','f1_macro', 'balanced_accuracy']\n",
    "train_score = get_score(y_train,y_train_pred,metrics)\n",
    "test_score = get_score(y_test,y_test_pred,metrics)\n",
    "print('Resultados para train:')\n",
    "print(train_score)\n",
    "print('Resultados para test:')\n",
    "print(test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
