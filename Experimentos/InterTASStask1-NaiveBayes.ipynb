{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lestien/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd().split('Documents')[0],'Documents/BecaNLP/Utils'))\n",
    "\n",
    "import NLPUtils as nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes + clasificación N, P, NONE, NEU + InterTASS \n",
    "\n",
    "Se hacen experimentos para la tarea de clasificación de sentimientos en las categorías N, P, None y Neu con el dataset InterTASSTask1. El modelo usado es Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas en una grilla de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram range: (2,10). Max features: 60000. alpha: 0.01\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9946666666666667, 'f1_macro': 0.9951367247345098}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5524956970740104, 'f1_macro': 0.36450770421621004}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-780d3075ac55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                            ngram_range=(min_ngram,max_ngram),max_features=max_features)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mvectorized_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/BecaNLP/Utils/NLPUtils/classification/vectorizers.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, data_df)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv-cpu/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0mn_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv-cpu/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[0;34m(self, X, vocabulary)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreordered\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodifies\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \"\"\"\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0msorted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mmap_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from NLPUtils.datasets import tass2018 as tass8\n",
    "from NLPUtils.datasets import tass2019 as tass9\n",
    "from NLPUtils.classification import MultinomialNB, BagOfNgramsVectorizer, get_score\n",
    "\n",
    "#train_dataset = pd.concat([tass8.get_train_dataframe(lang=['es']), tass9.get_train_dataframe(lang=['es'])],ignore_index=True)\n",
    "train_dataset = tass9.get_train_dataframe(lang=['es'])\n",
    "dev_dataset = tass9.get_dev_dataframe(lang=['es'])\n",
    "\n",
    "def label_fn(labels):\n",
    "    labels_dict = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "    return np.array([labels_dict[label] for label in labels])\n",
    "\n",
    "def parameter_grid(*params):\n",
    "    params = [param.reshape(-1) for param in np.meshgrid(*params)]\n",
    "    for param_tuple in zip(*params):\n",
    "        yield param_tuple\n",
    "\n",
    "min_ngrams = [2,3,4,5,6]\n",
    "max_ngrams = [10,13,15,17,20]\n",
    "maxs_features = [60000,65000,70000,75000,80000]\n",
    "alphas = alphas = [.01, .02, .04, .08, .09, .1, .2, .4, .8, 1., 2., 4., 8.]\n",
    "scores_train = {'acc': [], 'f1': [], 'params': []}\n",
    "scores_dev = {'acc': [], 'f1': [], 'params': []}\n",
    "\n",
    "for max_ngram, min_ngram, max_features, alpha in parameter_grid(max_ngrams,min_ngrams,maxs_features, alphas):\n",
    "    \n",
    "    classifier = MultinomialNB(alpha=alpha)\n",
    "    vectorizer = BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.preprocessing.tokenize_characters,\n",
    "                                           ngram_range=(min_ngram,max_ngram),max_features=max_features)\n",
    "\n",
    "    vectorized_train_dataset = vectorizer.fit_transform(train_dataset)\n",
    "    classifier.train(vectorized_train_dataset)\n",
    "    y_dev, y_predict = classifier.predict(vectorized_train_dataset)\n",
    "    score_train = get_score(y_dev,y_predict,metrics=['accuracy','f1_macro'])\n",
    "    scores_train['acc'].append(score_train['accuracy'])\n",
    "    scores_train['f1'].append(score_train['f1_macro'])\n",
    "    scores_train['params'].append({'ngram_range': (min_ngram,max_ngram), 'max_features': max_features, 'alpha': alpha})\n",
    "\n",
    "    print('Ngram range: ({},{}). Max features: {}. alpha: {}'.format(min_ngram,max_ngram,max_features,alpha))\n",
    "    print('Scores for the train dataset evaluation:')\n",
    "    print(score_train)\n",
    "\n",
    "    vectorized_dev_dataset = vectorizer.transform(dev_dataset)\n",
    "    y_dev, y_predict = classifier.predict(vectorized_dev_dataset)\n",
    "    score_dev = get_score(y_dev,y_predict,metrics=['accuracy','f1_macro'])\n",
    "    scores_dev['acc'].append(score_dev['accuracy'])\n",
    "    scores_dev['f1'].append(score_dev['f1_macro'])\n",
    "    scores_dev['params'].append({'ngram_range': (min_ngram,max_ngram), 'max_features': max_features, 'alpha': alpha})\n",
    "\n",
    "    print('Scores for the development dataset evaluation:')\n",
    "    print(score_dev)\n",
    "    print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ngram_range': (3, 15), 'max_features': 75000, 'alpha': 0.09}, {'ngram_range': (3, 15), 'max_features': 80000, 'alpha': 0.08}, {'ngram_range': (3, 15), 'max_features': 80000, 'alpha': 0.09}, {'ngram_range': (3, 15), 'max_features': 80000, 'alpha': 0.1}, {'ngram_range': (3, 15), 'max_features': 75000, 'alpha': 0.08}]\n",
      "[0.553360007740573, 0.5532091692280057, 0.5527347653282385, 0.5527347653282385, 0.5504142877190095]\n",
      "[0.986404125644632, 0.9878105954055321, 0.9868729488982654, 0.9868729488982654, 0.986404125644632]\n",
      "[0.6454388984509466, 0.6454388984509466, 0.6437177280550774, 0.6437177280550774, 0.6437177280550774]\n"
     ]
    }
   ],
   "source": [
    "idx = np.argsort(scores_dev['f1'])[::-1]\n",
    "best_params = list(np.array(scores_dev['params'])[idx])\n",
    "best_f1_dev = list(np.array(scores_dev['f1'])[idx])\n",
    "best_acc_train = list(np.array(scores_train['acc'])[idx])\n",
    "best_acc_dev = list(np.array(scores_dev['acc'])[idx])\n",
    "print(best_params[:5])\n",
    "print(best_f1_dev[:5])\n",
    "print(best_acc_train[:5])\n",
    "print(best_acc_dev[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección de la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[220.  13.  10.  23.]\n",
      " [ 39.  24.   1.  19.]\n",
      " [ 30.   1.  24.   9.]\n",
      " [ 44.  12.   5. 107.]]\n",
      "0.553360007740573\n",
      "0.6454388984509466\n"
     ]
    }
   ],
   "source": [
    "ngram_range = (3,15)\n",
    "max_features = 75000\n",
    "alpha = 0.09\n",
    "\n",
    "vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                           ngram_range=ngram_range,max_features=max_features)\n",
    "\n",
    "score = nlp.train_dev_validation(model=MultinomialNB(alpha=alpha),\n",
    "                                     train_dataset=train_dataset,\n",
    "                                     dev_dataset=dev_dataset,\n",
    "                                     vectorizer=vectorizer,\n",
    "                                     metric=['accuracy','f1_macro','confusion_matrix'])\n",
    "\n",
    "print(score['confusion_matrix'])\n",
    "print(score['f1_macro'])\n",
    "print(score['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volvemos a inspeccionar el espacio de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram range: (2,14). Max features: 74000. alpha: 0.08\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5456110154905336, 'f1_macro': 0.40769933405239656}\n",
      "\n",
      "Ngram range: (2,14). Max features: 74000. alpha: 0.09\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5438898450946644, 'f1_macro': 0.4063623463016557}\n",
      "\n",
      "Ngram range: (2,14). Max features: 74000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5473321858864028, 'f1_macro': 0.4115388096105933}\n",
      "\n",
      "Ngram range: (2,14). Max features: 74000. alpha: 0.11\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5456110154905336, 'f1_macro': 0.4102724325519902}\n",
      "\n",
      "Ngram range: (2,14). Max features: 74000. alpha: 0.12\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5456110154905336, 'f1_macro': 0.40751151810005637}\n",
      "\n",
      "Ngram range: (2,14). Max features: 75000. alpha: 0.08\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5473321858864028, 'f1_macro': 0.41451195945812713}\n",
      "\n",
      "Ngram range: (2,14). Max features: 75000. alpha: 0.09\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5473321858864028, 'f1_macro': 0.4141607464917225}\n",
      "\n",
      "Ngram range: (2,14). Max features: 75000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5490533562822719, 'f1_macro': 0.41559593138813805}\n",
      "\n",
      "Ngram range: (2,14). Max features: 75000. alpha: 0.11\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5490533562822719, 'f1_macro': 0.4155667925149887}\n",
      "\n",
      "Ngram range: (2,14). Max features: 75000. alpha: 0.12\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9866666666666667, 'f1_macro': 0.9848781784804247}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5490533562822719, 'f1_macro': 0.412888858397365}\n",
      "\n",
      "Ngram range: (2,14). Max features: 76000. alpha: 0.08\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5456110154905336, 'f1_macro': 0.41379931125704733}\n",
      "\n",
      "Ngram range: (2,14). Max features: 76000. alpha: 0.09\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5456110154905336, 'f1_macro': 0.4134971349417038}\n",
      "\n",
      "Ngram range: (2,14). Max features: 76000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5473321858864028, 'f1_macro': 0.41490103760988095}\n",
      "\n",
      "Ngram range: (2,14). Max features: 76000. alpha: 0.11\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5473321858864028, 'f1_macro': 0.4148752025453665}\n",
      "\n",
      "Ngram range: (2,14). Max features: 76000. alpha: 0.12\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5473321858864028, 'f1_macro': 0.412217960816212}\n",
      "\n",
      "Ngram range: (2,14). Max features: 77000. alpha: 0.08\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5507745266781411, 'f1_macro': 0.41736534930465863}\n",
      "\n",
      "Ngram range: (2,14). Max features: 77000. alpha: 0.09\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5507745266781411, 'f1_macro': 0.4170215300750144}\n",
      "\n",
      "Ngram range: (2,14). Max features: 77000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5490533562822719, 'f1_macro': 0.4162536433041205}\n",
      "\n",
      "Ngram range: (2,14). Max features: 77000. alpha: 0.11\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5473321858864028, 'f1_macro': 0.41221864687685383}\n",
      "\n",
      "Ngram range: (2,14). Max features: 77000. alpha: 0.12\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9866666666666667, 'f1_macro': 0.9848781784804247}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5490533562822719, 'f1_macro': 0.4137239849125976}\n",
      "\n",
      "Ngram range: (2,15). Max features: 74000. alpha: 0.08\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5542168674698795, 'f1_macro': 0.41211369886374394}\n",
      "\n",
      "Ngram range: (2,15). Max features: 74000. alpha: 0.09\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5542168674698795, 'f1_macro': 0.41224868103310275}\n",
      "\n",
      "Ngram range: (2,15). Max features: 74000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5559380378657487, 'f1_macro': 0.4201864889941984}\n",
      "\n",
      "Ngram range: (2,15). Max features: 74000. alpha: 0.11\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5524956970740104, 'f1_macro': 0.4210127554062649}\n",
      "\n",
      "Ngram range: (2,15). Max features: 74000. alpha: 0.12\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5524956970740104, 'f1_macro': 0.41836615751089434}\n",
      "\n",
      "Ngram range: (2,15). Max features: 75000. alpha: 0.08\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5542168674698795, 'f1_macro': 0.41317011738720955}\n",
      "\n",
      "Ngram range: (2,15). Max features: 75000. alpha: 0.09\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5524956970740104, 'f1_macro': 0.41182345191040837}\n",
      "\n",
      "Ngram range: (2,15). Max features: 75000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5507745266781411, 'f1_macro': 0.4130176909106552}\n",
      "\n",
      "Ngram range: (2,15). Max features: 75000. alpha: 0.11\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5507745266781411, 'f1_macro': 0.41694654648630347}\n",
      "\n",
      "Ngram range: (2,15). Max features: 75000. alpha: 0.12\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5507745266781411, 'f1_macro': 0.4167410533421967}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram range: (2,15). Max features: 76000. alpha: 0.08\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5507745266781411, 'f1_macro': 0.41426801385969214}\n",
      "\n",
      "Ngram range: (2,15). Max features: 76000. alpha: 0.09\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5507745266781411, 'f1_macro': 0.4142036541254914}\n",
      "\n",
      "Ngram range: (2,15). Max features: 76000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5490533562822719, 'f1_macro': 0.4124181750841823}\n",
      "\n",
      "Ngram range: (2,15). Max features: 76000. alpha: 0.11\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9884444444444445, 'f1_macro': 0.9871410085043102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5456110154905336, 'f1_macro': 0.4073994037805594}\n",
      "\n",
      "Ngram range: (2,15). Max features: 76000. alpha: 0.12\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9875555555555555, 'f1_macro': 0.9859134072215894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5490533562822719, 'f1_macro': 0.4128208052957109}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-19d220939f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                            ngram_range=(min_ngram,max_ngram),max_features=max_features)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mvectorized_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disco.mafalda/home/lestien/Documents/BecaNLP/Utils/NLPUtils/vectorizers.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, data_df)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv-gpu/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0mn_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpenv-gpu/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[0;34m(self, X, vocabulary)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreordered\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodifies\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \"\"\"\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0msorted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mmap_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from NLPUtils.datasets import tass2018 as tass8\n",
    "from NLPUtils.datasets import tass2019 as tass9\n",
    "from NLPUtils.classifiers import MultinomialNB\n",
    "\n",
    "#train_dataset = pd.concat([tass8.get_train_dataframe(lang=['es']), tass9.get_train_dataframe(lang=['es'])],ignore_index=True)\n",
    "train_dataset = tass9.get_train_dataframe(lang=['es'])\n",
    "dev_dataset = tass9.get_dev_dataframe(lang=['es'])\n",
    "\n",
    "def label_fn(labels):\n",
    "    labels_dict = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "    return np.array([labels_dict[label] for label in labels])\n",
    "\n",
    "def parameter_grid(*params):\n",
    "    params = [param.reshape(-1) for param in np.meshgrid(*params)]\n",
    "    for param_tuple in zip(*params):\n",
    "        yield param_tuple\n",
    "\n",
    "min_ngrams = [2,3,4]\n",
    "max_ngrams = [14,15,16,17]\n",
    "maxs_features = [74000,75000,76000,77000]\n",
    "alphas = alphas = [.08, .09, .1, .11, .12]\n",
    "scores_train = {'acc': [], 'f1': [], 'params': []}\n",
    "scores_dev = {'acc': [], 'f1': [], 'params': []}\n",
    "\n",
    "for max_ngram, min_ngram, max_features, alpha in parameter_grid(max_ngrams,min_ngrams,maxs_features, alphas):\n",
    "    \n",
    "    classifier = MultinomialNB(alpha=alpha)\n",
    "    vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                           ngram_range=(min_ngram,max_ngram),max_features=max_features)\n",
    "\n",
    "    vectorized_train_dataset = vectorizer.fit_transform(train_dataset)\n",
    "    classifier.train(vectorized_train_dataset)\n",
    "    y_dev, y_predict = classifier.predict(vectorized_train_dataset)\n",
    "    score_train = nlp.get_score(y_dev,y_predict,metrics=['accuracy','f1_macro'])\n",
    "    scores_train['acc'].append(score_train['accuracy'])\n",
    "    scores_train['f1'].append(score_train['f1_macro'])\n",
    "    scores_train['params'].append({'ngram_range': (min_ngram,max_ngram), 'max_features': max_features, 'alpha': alpha})\n",
    "\n",
    "    print('Ngram range: ({},{}). Max features: {}. alpha: {}'.format(min_ngram,max_ngram,max_features,alpha))\n",
    "    print('Scores for the train dataset evaluation:')\n",
    "    print(score_train)\n",
    "    \n",
    "    vectorized_dev_dataset = vectorizer.transform(dev_dataset)\n",
    "    y_dev, y_predict = classifier.predict(vectorized_dev_dataset)\n",
    "    score_dev = nlp.get_score(y_dev,y_predict,metrics=['accuracy','f1_macro'])\n",
    "    scores_dev['acc'].append(score_dev['accuracy'])\n",
    "    scores_dev['f1'].append(score_dev['f1_macro'])\n",
    "    scores_dev['params'].append({'ngram_range': (min_ngram,max_ngram), 'max_features': max_features, 'alpha': alpha})\n",
    "    \n",
    "    print('Scores for the development dataset evaluation:')\n",
    "    print(score_dev)\n",
    "    print()\n",
    "    \n",
    "idx = np.argsort(scores_dev['f1'])[::-1]\n",
    "best_params = list(np.array(scores_dev['params'])[idx])\n",
    "best_f1_dev = list(np.array(scores_dev['f1'])[idx])\n",
    "best_acc_train = list(np.array(scores_train['acc'])[idx])\n",
    "best_acc_dev = list(np.array(scores_dev['acc'])[idx])\n",
    "print(best_params[:5])\n",
    "print(best_f1_dev[:5])\n",
    "print(best_acc_train[:5])\n",
    "print(best_acc_dev[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram range: (5,15). Max features: 100\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.46554149085794655, 'f1_macro': 0.405476566671487}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.3958691910499139, 'f1_macro': 0.31392837118091027}\n",
      "\n",
      "Ngram range: (5,15). Max features: 500\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.5185185185185185, 'f1_macro': 0.4941167280795279}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.39759036144578314, 'f1_macro': 0.3382958260798199}\n",
      "\n",
      "Ngram range: (5,15). Max features: 700\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.540084388185654, 'f1_macro': 0.5189529520476128}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.40963855421686746, 'f1_macro': 0.3522487589460433}\n",
      "\n",
      "Ngram range: (5,15). Max features: 1000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.577121425222691, 'f1_macro': 0.5534589503713618}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.4199655765920826, 'f1_macro': 0.36668623138222467}\n",
      "\n",
      "Ngram range: (5,15). Max features: 2000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.6615096108766995, 'f1_macro': 0.6312875677532229}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.4802065404475043, 'f1_macro': 0.395753026000622}\n",
      "\n",
      "Ngram range: (5,15). Max features: 5000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.7557430848570089, 'f1_macro': 0.7341884468364971}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5283993115318416, 'f1_macro': 0.4466351167082682}\n",
      "\n",
      "Ngram range: (5,15). Max features: 7000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.810126582278481, 'f1_macro': 0.7901020258294545}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5266781411359724, 'f1_macro': 0.4314104842340567}\n",
      "\n",
      "Ngram range: (5,15). Max features: 10000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.8485700890764182, 'f1_macro': 0.8355325791519796}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5542168674698795, 'f1_macro': 0.46338946671112013}\n",
      "\n",
      "Ngram range: (5,15). Max features: 20000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.8992030004688233, 'f1_macro': 0.8899111985778884}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5611015490533563, 'f1_macro': 0.4519429597904128}\n",
      "\n",
      "Ngram range: (5,15). Max features: 50000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9563994374120957, 'f1_macro': 0.9538327991972162}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.5053955004063401}\n",
      "\n",
      "Ngram range: (5,15). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9685888420065635, 'f1_macro': 0.966444516018133}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.5109108843580422}\n",
      "\n",
      "Ngram range: (5,15). Max features: 100000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9737458977965308, 'f1_macro': 0.9714288493623571}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.47461750752132714}\n",
      "\n",
      "Ngram range: (5,15). Max features: 120000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9737458977965308, 'f1_macro': 0.9709049137458297}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.4515801310964178}\n",
      "\n",
      "Ngram range: (5,15). Max features: 150000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9676511954992968, 'f1_macro': 0.963745114528102}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.4396904010151973}\n",
      "\n",
      "Ngram range: (5,15). Max features: 170000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9681200187529302, 'f1_macro': 0.9630600636725619}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.612736660929432, 'f1_macro': 0.4238361006082525}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_range = (3,10)\n",
    "train_error = []\n",
    "dev_error = []\n",
    "num_features = [100, 500, 700, 1000, 2000, 5000, 7000, 10000, 20000, 50000, 70000, 100000, 120000, 150000, 170000]\n",
    "\n",
    "for max_features in num_features:\n",
    "    \n",
    "    vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                           ngram_range=ngram_range,max_features=max_features)\n",
    "\n",
    "    score = nlp.train_dev_validation(model=classifier,\n",
    "                                     train_dataset=train_dataset,\n",
    "                                     dev_dataset=train_dataset,\n",
    "                                     vectorizer=vectorizer,\n",
    "                                     metric=['accuracy','f1_macro'])\n",
    "\n",
    "    print('Ngram range: ({},{}). Max features: {}'.format(min_ngram,max_ngram,max_features))\n",
    "    print('Scores for the train dataset evaluation:')\n",
    "    print(score)\n",
    "    train_error.append(1-score['accuracy'])\n",
    "    \n",
    "    score = nlp.train_dev_validation(model=classifier,\n",
    "                                     train_dataset=train_dataset,\n",
    "                                     dev_dataset=dev_dataset,\n",
    "                                     vectorizer=vectorizer,\n",
    "                                     metric=['accuracy','f1_macro'])\n",
    "\n",
    "    print('Scores for the development dataset evaluation:')\n",
    "    print(score)\n",
    "    print()\n",
    "    \n",
    "    dev_error.append(1-score['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf99325390>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(num_features, train_error)\n",
    "ax.plot(num_features, dev_error)\n",
    "#ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram range: (2,10). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9601500234411627, 'f1_macro': 0.9574014845575349}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.49387456650761347}\n",
      "\n",
      "Ngram range: (2,10). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9633518105292926}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.4958457134870682}\n",
      "\n",
      "Ngram range: (2,10). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9681200187529302, 'f1_macro': 0.966299758060716}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6299483648881239, 'f1_macro': 0.5012785423829246}\n",
      "\n",
      "Ngram range: (2,10). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9699953117674637, 'f1_macro': 0.9687121207723728}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.4883852952835562}\n",
      "\n",
      "Ngram range: (2,10). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9714017815283638, 'f1_macro': 0.9695788442528297}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.4796667628191289}\n",
      "\n",
      "Ngram range: (2,13). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9582747304266291, 'f1_macro': 0.9556074378025117}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.4923594464331262}\n",
      "\n",
      "Ngram range: (2,13). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9596812001875293, 'f1_macro': 0.9571086710516665}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.48303995202181205}\n",
      "\n",
      "Ngram range: (2,13). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9643694327238631, 'f1_macro': 0.961837284878011}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.4735266187904327}\n",
      "\n",
      "Ngram range: (2,13). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.96671354899203, 'f1_macro': 0.9645918032526036}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.48235722528016106}\n",
      "\n",
      "Ngram range: (2,13). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9699953117674637, 'f1_macro': 0.9679889536326127}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6299483648881239, 'f1_macro': 0.4815983891030795}\n",
      "\n",
      "Ngram range: (2,15). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.956868260665729, 'f1_macro': 0.9540833401272943}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.4852637817342397}\n",
      "\n",
      "Ngram range: (2,15). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9610876699484294, 'f1_macro': 0.9589075238978779}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.4748736964316933}\n",
      "\n",
      "Ngram range: (2,15). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9639006094702297, 'f1_macro': 0.9612287161269532}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.472716350127798}\n",
      "\n",
      "Ngram range: (2,15). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9653070792311299, 'f1_macro': 0.9633752718732265}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.47890181286534056}\n",
      "\n",
      "Ngram range: (2,15). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9676511954992968, 'f1_macro': 0.9660330315003851}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.480445419617056}\n",
      "\n",
      "Ngram range: (2,17). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9554617909048289, 'f1_macro': 0.9526685423684373}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.48438691365293274}\n",
      "\n",
      "Ngram range: (2,17). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9596812001875293, 'f1_macro': 0.9574170407226283}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.4865868401453085}\n",
      "\n",
      "Ngram range: (2,17). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9615564932020628, 'f1_macro': 0.9598550240533346}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.47502894718026367}\n",
      "\n",
      "Ngram range: (2,17). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.96671354899203, 'f1_macro': 0.9648698039885232}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.4703591647533061}\n",
      "\n",
      "Ngram range: (2,17). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9690576652601969, 'f1_macro': 0.9667928505205894}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6247848537005164, 'f1_macro': 0.4778456113874909}\n",
      "\n",
      "Ngram range: (2,20). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9535864978902954, 'f1_macro': 0.9506369908558153}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.478679611180316}\n",
      "\n",
      "Ngram range: (2,20). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9578059071729957, 'f1_macro': 0.9555404345122751}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.4722676294422473}\n",
      "\n",
      "Ngram range: (2,20). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9629629629629629, 'f1_macro': 0.9611070524975627}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.47721911764243996}\n",
      "\n",
      "Ngram range: (2,20). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.96671354899203, 'f1_macro': 0.9645757751819364}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.47268662802335276}\n",
      "\n",
      "Ngram range: (2,20). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9676511954992968, 'f1_macro': 0.9658097038947966}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.47946484472452455}\n",
      "\n",
      "Ngram range: (3,10). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9624941397093296, 'f1_macro': 0.9599965215188622}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6333907056798623, 'f1_macro': 0.5092725357179566}\n",
      "\n",
      "Ngram range: (3,10). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9657759024847632, 'f1_macro': 0.9631065106175707}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.5066612082669906}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9685888420065635, 'f1_macro': 0.966444516018133}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.5109108843580422}\n",
      "\n",
      "Ngram range: (3,10). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9718706047819972, 'f1_macro': 0.9697315523543035}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6299483648881239, 'f1_macro': 0.5054389587459247}\n",
      "\n",
      "Ngram range: (3,10). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9723394280356306, 'f1_macro': 0.9703546892065098}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6299483648881239, 'f1_macro': 0.49809560823778554}\n",
      "\n",
      "Ngram range: (3,13). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9559306141584623, 'f1_macro': 0.953163783462821}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.4978630132210805}\n",
      "\n",
      "Ngram range: (3,13). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9615564932020628, 'f1_macro': 0.9594395664711248}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6247848537005164, 'f1_macro': 0.4932671455210217}\n",
      "\n",
      "Ngram range: (3,13). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9639006094702297, 'f1_macro': 0.9623865327844359}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.49246714552102167}\n",
      "\n",
      "Ngram range: (3,13). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9704641350210971, 'f1_macro': 0.9682445026802171}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.49810334610941687}\n",
      "\n",
      "Ngram range: (3,13). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9718706047819972, 'f1_macro': 0.9692630095813499}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.4977530532685549}\n",
      "\n",
      "Ngram range: (3,15). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.956868260665729, 'f1_macro': 0.9538239645288309}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.4973053587512877}\n",
      "\n",
      "Ngram range: (3,15). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9634317862165963, 'f1_macro': 0.9603963804233099}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.4906384592994446}\n",
      "\n",
      "Ngram range: (3,15). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9657759024847632, 'f1_macro': 0.9625437817299374}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.4880884012539185}\n",
      "\n",
      "Ngram range: (3,15). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9699953117674637, 'f1_macro': 0.9670688059008815}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6247848537005164, 'f1_macro': 0.49040338890775725}\n",
      "\n",
      "Ngram range: (3,15). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9714017815283638, 'f1_macro': 0.9686299678286898}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.493845034768881}\n",
      "\n",
      "Ngram range: (3,17). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.956868260665729, 'f1_macro': 0.9536052751629002}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.4948082916824353}\n",
      "\n",
      "Ngram range: (3,17). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9653070792311299, 'f1_macro': 0.9624778368243343}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.4880928418719618}\n",
      "\n",
      "Ngram range: (3,17). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9643694327238631, 'f1_macro': 0.9609971821866555}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.4792047458714125}\n",
      "\n",
      "Ngram range: (3,17). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9681200187529302, 'f1_macro': 0.9658594592262368}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.48892653181013973}\n",
      "\n",
      "Ngram range: (3,17). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9699953117674637, 'f1_macro': 0.9668520538085755}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.4793476987594415}\n",
      "\n",
      "Ngram range: (3,20). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9549929676511955, 'f1_macro': 0.9518676587615236}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.49929583762500823}\n",
      "\n",
      "Ngram range: (3,20). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9610876699484294, 'f1_macro': 0.9581500105283203}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.508161226125653}\n",
      "\n",
      "Ngram range: (3,20). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.96671354899203, 'f1_macro': 0.9640753570225086}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.4999001266686154}\n",
      "\n",
      "Ngram range: (3,20). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9690576652601969, 'f1_macro': 0.9669904013177819}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.49866374591355683}\n",
      "\n",
      "Ngram range: (3,20). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9714017815283638, 'f1_macro': 0.9686299678286898}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.5054221040986914}\n",
      "\n",
      "Ngram range: (4,10). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9648382559774965, 'f1_macro': 0.9621307135050216}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5122355081509284}\n",
      "\n",
      "Ngram range: (4,10). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9622603231396137}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.5149695298827266}\n",
      "\n",
      "Ngram range: (4,10). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9676511954992968, 'f1_macro': 0.9640056457018354}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6299483648881239, 'f1_macro': 0.5173059629909146}\n",
      "\n",
      "Ngram range: (4,10). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9695264885138303, 'f1_macro': 0.9660114464396284}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.5192913926450529}\n",
      "\n",
      "Ngram range: (4,10). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9714017815283638, 'f1_macro': 0.9678490132268384}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.5164938729415764}\n",
      "\n",
      "Ngram range: (4,13). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9639006094702297, 'f1_macro': 0.9605604758032501}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.5033926992547682}\n",
      "\n",
      "Ngram range: (4,13). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9630389589639168}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.5175674076685165}\n",
      "\n",
      "Ngram range: (4,13). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9685888420065635, 'f1_macro': 0.9650291024317585}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.5167356338866015}\n",
      "\n",
      "Ngram range: (4,13). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9690576652601969, 'f1_macro': 0.9650587005630497}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.5155412922695706}\n",
      "\n",
      "Ngram range: (4,13). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9681200187529302, 'f1_macro': 0.964262169195015}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.5047584031591832}\n",
      "\n",
      "Ngram range: (4,15). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9610876699484294, 'f1_macro': 0.957291866174403}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.5039483871456852}\n",
      "\n",
      "Ngram range: (4,15). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9634317862165963, 'f1_macro': 0.9601839996182615}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5090007171849195}\n",
      "\n",
      "Ngram range: (4,15). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9633861721687912}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5092621332156215}\n",
      "\n",
      "Ngram range: (4,15). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9690576652601969, 'f1_macro': 0.9660639112899876}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.5162845681450332}\n",
      "\n",
      "Ngram range: (4,15). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9685888420065635, 'f1_macro': 0.9648307044724538}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6265060240963856, 'f1_macro': 0.5111968869284345}\n",
      "\n",
      "Ngram range: (4,17). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9615564932020628, 'f1_macro': 0.9580822946160453}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5014529735156539}\n",
      "\n",
      "Ngram range: (4,17). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9634002440036915}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.508415840214353}\n",
      "\n",
      "Ngram range: (4,17). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9690576652601969, 'f1_macro': 0.96630898055396}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.5182553907255072}\n",
      "\n",
      "Ngram range: (4,17). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9695264885138303, 'f1_macro': 0.9663649845386952}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6247848537005164, 'f1_macro': 0.5117174984964975}\n",
      "\n",
      "Ngram range: (4,17). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9681200187529302, 'f1_macro': 0.9644784693636673}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.508918705136405}\n",
      "\n",
      "Ngram range: (4,20). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9592123769338959, 'f1_macro': 0.9549335933599504}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5023325268091323}\n",
      "\n",
      "Ngram range: (4,20). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9624941397093296, 'f1_macro': 0.9580395676705278}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.4952782817747797}\n",
      "\n",
      "Ngram range: (4,20). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9671823722456634, 'f1_macro': 0.9636671817608449}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.621342512908778, 'f1_macro': 0.5083718934465202}\n",
      "\n",
      "Ngram range: (4,20). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9699953117674637, 'f1_macro': 0.9668252671200473}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6247848537005164, 'f1_macro': 0.514517770479338}\n",
      "\n",
      "Ngram range: (4,20). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9695264885138303, 'f1_macro': 0.9657830093438701}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6299483648881239, 'f1_macro': 0.5215327847020924}\n",
      "\n",
      "Ngram range: (5,10). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9634317862165963, 'f1_macro': 0.9588005539735662}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.5176073240469244}\n",
      "\n",
      "Ngram range: (5,10). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9616697843216322}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5145026565546936}\n",
      "\n",
      "Ngram range: (5,10). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.96671354899203, 'f1_macro': 0.9620698156635888}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5063765290900494}\n",
      "\n",
      "Ngram range: (5,10). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9681200187529302, 'f1_macro': 0.9639800252809831}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6230636833046471, 'f1_macro': 0.5086189467153054}\n",
      "\n",
      "Ngram range: (5,10). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9685888420065635, 'f1_macro': 0.9645213536298491}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6247848537005164, 'f1_macro': 0.5097037639142903}\n",
      "\n",
      "Ngram range: (5,13). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9587435536802625, 'f1_macro': 0.9542451800530046}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6110154905335629, 'f1_macro': 0.5100003128791487}\n",
      "\n",
      "Ngram range: (5,13). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.960618846694796, 'f1_macro': 0.9560458375721126}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5110514469602432}\n",
      "\n",
      "Ngram range: (5,13). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9620253164556962, 'f1_macro': 0.9573298822560172}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5153882830745139}\n",
      "\n",
      "Ngram range: (5,13). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9648382559774965, 'f1_macro': 0.9602388279544587}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.5082066879087141}\n",
      "\n",
      "Ngram range: (5,13). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9676511954992968, 'f1_macro': 0.9630060978088626}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5039238436731397}\n",
      "\n",
      "Ngram range: (5,15). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9587435536802625, 'f1_macro': 0.9538135340278353}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.5120427754377095}\n",
      "\n",
      "Ngram range: (5,15). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9610876699484294, 'f1_macro': 0.9560072608274872}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.5120405888609771}\n",
      "\n",
      "Ngram range: (5,15). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9615564932020628, 'f1_macro': 0.9569533762319208}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5107619148194865}\n",
      "\n",
      "Ngram range: (5,15). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9657759024847632, 'f1_macro': 0.9612036104084218}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6179001721170396, 'f1_macro': 0.5076925996807748}\n",
      "\n",
      "Ngram range: (5,15). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9617304603086742}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6196213425129088, 'f1_macro': 0.5097499928217006}\n",
      "\n",
      "Ngram range: (5,17). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9578059071729957, 'f1_macro': 0.9531616033698868}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.612736660929432, 'f1_macro': 0.5098841619720273}\n",
      "\n",
      "Ngram range: (5,17). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9596812001875293, 'f1_macro': 0.9548474610191492}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.612736660929432, 'f1_macro': 0.5120219187608365}\n",
      "\n",
      "Ngram range: (5,17). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9610876699484294, 'f1_macro': 0.9560922497985493}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.612736660929432, 'f1_macro': 0.5094233543317551}\n",
      "\n",
      "Ngram range: (5,17). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9620253164556962, 'f1_macro': 0.9577776807946}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5054560263261215}\n",
      "\n",
      "Ngram range: (5,17). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9653070792311299, 'f1_macro': 0.9616563253721266}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5073070113905869}\n",
      "\n",
      "Ngram range: (5,20). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9582747304266291, 'f1_macro': 0.9537155994943424}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.5177187250652348}\n",
      "\n",
      "Ngram range: (5,20). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9592123769338959, 'f1_macro': 0.9548545749183495}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5136739986290839}\n",
      "\n",
      "Ngram range: (5,20). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9615564932020628, 'f1_macro': 0.9569533762319208}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.612736660929432, 'f1_macro': 0.5113637784741937}\n",
      "\n",
      "Ngram range: (5,20). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9629629629629629, 'f1_macro': 0.9588245476877039}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6161790017211703, 'f1_macro': 0.5097238072353218}\n",
      "\n",
      "Ngram range: (5,20). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9643694327238631, 'f1_macro': 0.9605179327383156}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6144578313253012, 'f1_macro': 0.5065449138074223}\n",
      "\n",
      "Ngram range: (6,10). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9648382559774965, 'f1_macro': 0.9591292065644448}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5920826161790017, 'f1_macro': 0.49891633554847437}\n",
      "\n",
      "Ngram range: (6,10). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9662447257383966, 'f1_macro': 0.9611918825678142}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5955249569707401, 'f1_macro': 0.5001956325163672}\n",
      "\n",
      "Ngram range: (6,10). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9685888420065635, 'f1_macro': 0.9639174331595137}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6006884681583476, 'f1_macro': 0.5031324117131946}\n",
      "\n",
      "Ngram range: (6,10). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9690576652601969, 'f1_macro': 0.9645069722182132}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6058519793459552, 'f1_macro': 0.5110013834871616}\n",
      "\n",
      "Ngram range: (6,10). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9714017815283638, 'f1_macro': 0.967394317721239}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6092943201376936, 'f1_macro': 0.5106834975369459}\n",
      "\n",
      "Ngram range: (6,13). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9596812001875293, 'f1_macro': 0.9539198429411353}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5783132530120482, 'f1_macro': 0.4890596279723809}\n",
      "\n",
      "Ngram range: (6,13). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9582747304266291, 'f1_macro': 0.9523769846078426}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5851979345955249, 'f1_macro': 0.48576506173149864}\n",
      "\n",
      "Ngram range: (6,13). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9601500234411627, 'f1_macro': 0.9550295958177915}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5869191049913941, 'f1_macro': 0.48888240557046725}\n",
      "\n",
      "Ngram range: (6,13). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9624941397093296, 'f1_macro': 0.9574517266918349}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5955249569707401, 'f1_macro': 0.4947820614116626}\n",
      "\n",
      "Ngram range: (6,13). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9629629629629629, 'f1_macro': 0.9577778794536953}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5938037865748709, 'f1_macro': 0.4893765345311888}\n",
      "\n",
      "Ngram range: (6,15). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9587435536802625, 'f1_macro': 0.9530155592402866}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.576592082616179, 'f1_macro': 0.4869034883446243}\n",
      "\n",
      "Ngram range: (6,15). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9582747304266291, 'f1_macro': 0.9530485735319663}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5869191049913941, 'f1_macro': 0.49154589128288695}\n",
      "\n",
      "Ngram range: (6,15). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9610876699484294, 'f1_macro': 0.9561611723255417}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5920826161790017, 'f1_macro': 0.4916118873340702}\n",
      "\n",
      "Ngram range: (6,15). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9610876699484294, 'f1_macro': 0.9561611723255417}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5955249569707401, 'f1_macro': 0.4946594568067615}\n",
      "\n",
      "Ngram range: (6,15). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9620253164556962, 'f1_macro': 0.957355210292857}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5920826161790017, 'f1_macro': 0.4904572873173588}\n",
      "\n",
      "Ngram range: (6,17). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9563994374120957, 'f1_macro': 0.9501639537529956}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.576592082616179, 'f1_macro': 0.4872826366155083}\n",
      "\n",
      "Ngram range: (6,17). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9601500234411627, 'f1_macro': 0.9544847638315171}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5869191049913941, 'f1_macro': 0.4935531056317962}\n",
      "\n",
      "Ngram range: (6,17). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9592123769338959, 'f1_macro': 0.9540792518691439}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5851979345955249, 'f1_macro': 0.48533076535522335}\n",
      "\n",
      "Ngram range: (6,17). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9592123769338959, 'f1_macro': 0.9543674948335144}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5903614457831325, 'f1_macro': 0.48896833078574325}\n",
      "\n",
      "Ngram range: (6,17). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9620253164556962, 'f1_macro': 0.957295039120349}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5886402753872634, 'f1_macro': 0.48670230024648375}\n",
      "\n",
      "Ngram range: (6,20). Max features: 60000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9554617909048289, 'f1_macro': 0.9491618476029388}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5748709122203098, 'f1_macro': 0.4874871276644359}\n",
      "\n",
      "Ngram range: (6,20). Max features: 65000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.960618846694796, 'f1_macro': 0.9554265861160539}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5817555938037866, 'f1_macro': 0.49136367947736537}\n",
      "\n",
      "Ngram range: (6,20). Max features: 70000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.960618846694796, 'f1_macro': 0.9553379166984379}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5817555938037866, 'f1_macro': 0.49042333547772643}\n",
      "\n",
      "Ngram range: (6,20). Max features: 75000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9615564932020628, 'f1_macro': 0.9564924814600178}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5886402753872634, 'f1_macro': 0.4918929583141961}\n",
      "\n",
      "Ngram range: (6,20). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9615564932020628, 'f1_macro': 0.956506717207819}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5920826161790017, 'f1_macro': 0.4936379221071811}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_ngram = [2,3,4,5,6]\n",
    "max_ngram = [10,13,15,17,20]\n",
    "max_features = [60000,65000,70000,75000,80000]\n",
    "        \n",
    "classifier = MultinomialNB()\n",
    "    \n",
    "for max_ngram, min_ngram, max_features in parameter_grid(max_ngram,min_ngram,max_features):\n",
    "    \n",
    "    vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                           ngram_range=(min_ngram,max_ngram),max_features=max_features)\n",
    "\n",
    "    score = nlp.train_dev_validation(model=classifier,\n",
    "                                     train_dataset=train_dataset,\n",
    "                                     dev_dataset=train_dataset,\n",
    "                                     vectorizer=vectorizer,\n",
    "                                     metric=['accuracy','f1_macro'])\n",
    "\n",
    "    print('Ngram range: ({},{}). Max features: {}'.format(min_ngram,max_ngram,max_features))\n",
    "    print('Scores for the train dataset evaluation:')\n",
    "    print(score)\n",
    "\n",
    "    score = nlp.train_dev_validation(model=classifier,\n",
    "                                     train_dataset=train_dataset,\n",
    "                                     dev_dataset=dev_dataset,\n",
    "                                     vectorizer=vectorizer,\n",
    "                                     metric=['accuracy','f1_macro'])\n",
    "\n",
    "    print('Scores for the development dataset evaluation:')\n",
    "    print(score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variando el parámetro de regularización alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram range: (3,10). Max features: 70000. alpha: 0.01\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9957805907172996, 'f1_macro': 0.9961120815052038}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6437177280550774, 'f1_macro': 0.5280215396888711}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 0.02\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9948429442100328, 'f1_macro': 0.9951436929763909}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6419965576592083, 'f1_macro': 0.5289097266054207}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 0.04\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9929676511954993, 'f1_macro': 0.992870351917353}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6368330464716007, 'f1_macro': 0.5335897682924771}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 0.06\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.992498827941866, 'f1_macro': 0.9922805650505627}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.528614519522799}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 0.1\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9887482419127989, 'f1_macro': 0.9879094721472731}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6333907056798623, 'f1_macro': 0.5407117828351217}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 0.5\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.974214721050164, 'f1_macro': 0.9715644549870731}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6282271944922547, 'f1_macro': 0.5271848938934366}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 1.0\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9685888420065635, 'f1_macro': 0.966444516018133}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6316695352839932, 'f1_macro': 0.5109108843580422}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 2.0\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9474917955930614, 'f1_macro': 0.941469512249661}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.6058519793459552, 'f1_macro': 0.41690826915765733}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 4.0\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.8757618377871542, 'f1_macro': 0.8422050369284764}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5955249569707401, 'f1_macro': 0.3465321632574029}\n",
      "\n",
      "Ngram range: (3,10). Max features: 70000. alpha: 10.0\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.6962025316455697, 'f1_macro': 0.4890649020492708}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5593803786574871, 'f1_macro': 0.3020754716981132}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from NLPUtils.datasets import tass2018 as tass8\n",
    "from NLPUtils.datasets import tass2019 as tass9\n",
    "from NLPUtils.classifiers import MultinomialNB\n",
    "\n",
    "train_dataset = pd.concat([tass8.get_train_dataframe(lang=['es']), tass9.get_train_dataframe(lang=['es'])],ignore_index=True)\n",
    "dev_dataset = tass9.get_dev_dataframe(lang=['es'])\n",
    "\n",
    "def label_fn(labels):\n",
    "    labels_dict = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "    return np.array([labels_dict[label] for label in labels])\n",
    "\n",
    "alphas = [.01, .02, .04, .06, .1, .5, 1., 2., 4., 10.]\n",
    "ngram_range=(3,10)\n",
    "max_features = 70000\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    classifier = MultinomialNB(alpha=alpha)\n",
    "    vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                           ngram_range=ngram_range,max_features=max_features)\n",
    "\n",
    "    vectorized_train_dataset = vectorizer.fit_transform(train_dataset)\n",
    "    classifier.train(vectorized_train_dataset)\n",
    "    y_dev, y_predict = classifier.predict(vectorized_train_dataset)\n",
    "    score = nlp.get_score(y_dev,y_predict,metrics=['accuracy','f1_macro'])\n",
    "\n",
    "    print('Ngram range: ({},{}). Max features: {}. alpha: {}'.format(ngram_range[0],ngram_range[1],max_features,alpha))\n",
    "    print('Scores for the train dataset evaluation:')\n",
    "    print(score)\n",
    "    \n",
    "    vectorized_dev_dataset = vectorizer.transform(dev_dataset)\n",
    "    y_dev, y_predict = classifier.predict(vectorized_dev_dataset)\n",
    "    score = nlp.get_score(y_dev,y_predict,metrics=['accuracy','f1_macro'])\n",
    "    \n",
    "    print('Scores for the development dataset evaluation:')\n",
    "    print(score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armamos los resultados para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram range: (6,20). Max features: 80000\n",
      "Scores for the train dataset evaluation:\n",
      "{'accuracy': 0.9695264885138303, 'f1_macro': 0.9657830093438701}\n",
      "Scores for the development dataset evaluation:\n",
      "{'accuracy': 0.5869565217391305, 'f1_macro': 0.48072937254898174}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.concat([tass8.get_train_dataframe(lang=['es']), tass9.get_train_dataframe(lang=['es'])],ignore_index=True)\n",
    "dev_dataset = tass8.get_dev_dataframe(lang=['es'])\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn,tokenizer=nlp.tokenize_characters,\n",
    "                                       ngram_range=(4,20),max_features=80000)\n",
    "\n",
    "score = nlp.train_dev_validation(model=classifier,\n",
    "                                 train_dataset=train_dataset,\n",
    "                                 dev_dataset=train_dataset,\n",
    "                                 vectorizer=vectorizer,\n",
    "                                 metric=['accuracy','f1_macro'])\n",
    "\n",
    "print('Ngram range: ({},{}). Max features: {}'.format(min_ngram,max_ngram,max_features))\n",
    "print('Scores for the train dataset evaluation:')\n",
    "print(score)\n",
    "\n",
    "score = nlp.train_dev_validation(model=classifier,\n",
    "                                 train_dataset=train_dataset,\n",
    "                                 dev_dataset=dev_dataset,\n",
    "                                 vectorizer=vectorizer,\n",
    "                                 metric=['accuracy','f1_macro'])\n",
    "\n",
    "print('Scores for the development dataset evaluation:')\n",
    "print(score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tass.get_train_dataframe(lang=['es'])\n",
    "test_df = tass.get_test_dataframe(lang=['es'])\n",
    "test_df['label'] = 'N'\n",
    "\n",
    "def label_fn(labels):\n",
    "    labels_dict = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "    return np.array([labels_dict[label] for label in labels])\n",
    "\n",
    "vectorizer = nlp.BagOfNgramsVectorizer(label_fn=label_fn)\n",
    "X_train,y_train = vectorizer.fit_transform(train_df)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.train((X_train,y_train))\n",
    "\n",
    "X_test, y_test = vectorizer.transform(test_df.loc[:,['text','label']])\n",
    "_, y_predict = classifier.predict((X_test,y_test))\n",
    "\n",
    "labels_to_idx = {label: idx for idx, label in enumerate(np.unique(train_df['label']))}\n",
    "idx_to_labels = {idx:label for label, idx in labels_to_idx.items()}\n",
    "labels_predict = [idx_to_labels[idx] for idx in y_predict]\n",
    "test_df['label'] = labels_predict\n",
    "test_df.loc[:,['tweet_id','label']].to_csv('./test_results.tsv',sep='\\t',index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770567971701940224</td>\n",
       "      <td>@LonelySoad mientras que no te pillen la prime...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770503386789711872</td>\n",
       "      <td>@ceemeese ya era hora de volver al csgo y deja...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770502863017635840</td>\n",
       "      <td>@mireiaescribano justo cuando se terminan las ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>770599972102348800</td>\n",
       "      <td>@LuisMartinez22_ pensba q iba a hacer @wxplosi...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770599962216390656</td>\n",
       "      <td>@Vic_Phantomhive Si lo encuentro, sin compañer...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text label\n",
       "0  770567971701940224  @LonelySoad mientras que no te pillen la prime...     N\n",
       "1  770503386789711872  @ceemeese ya era hora de volver al csgo y deja...     N\n",
       "2  770502863017635840  @mireiaescribano justo cuando se terminan las ...     N\n",
       "3  770599972102348800  @LuisMartinez22_ pensba q iba a hacer @wxplosi...     N\n",
       "4  770599962216390656  @Vic_Phantomhive Si lo encuentro, sin compañer...     N"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
