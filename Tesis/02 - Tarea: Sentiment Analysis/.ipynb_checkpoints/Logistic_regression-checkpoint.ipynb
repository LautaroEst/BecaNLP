{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión losgística para análisis de sentimientos\n",
    "\n",
    "En este notebook se va a estudiar el modelo de Regresión Logística aplicado a análisis de sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "                \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema general\n",
    "\n",
    "Vamos a formular el problema de análisis de sentimientos como un problema de clasificación binaria. Se dispondrá de un conjunto de datos de entrenamiento que consisten en una serie de comentarios conformados por una secuencia de palabras, y su respectiva connotación (positiva o negativa). El objetivo de esta parte será estudiar el modelo de **regresión logística** utilizado para resolver este problema.\n",
    "\n",
    "Antes de continuar, detallamos la notación que vamos a utilizar:\n",
    "\n",
    "* El texto de entrada va a ser mapeado a un ejemplo de un vector aleatorio $\\mathbf{x}=\\begin{bmatrix} x_1 & x_2 & \\ldots & x_n \\end{bmatrix}^T$ que representa el conjunto de features de ese texto.\n",
    "\n",
    "* La clase a la que pertenece cada comentario se denota con un ejemplo de una variable aleatoria $y$, con realizaciones en el conjunto $\\{ 0,1 \\}$. De esta manera, hacemos corresponder a $y=1$ cuando el texto tiene una connotación positiva y a $y=0$ cuando ésta es negativa.\n",
    "\n",
    "* El conjunto de $N$ muestras de entrenamiento se representa por $\\left\\{ \\left(\\mathbf{x}^{(i)}, y^{(i)}\\right) \\right\\}_{i=1}^N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo\n",
    "\n",
    "El modelo de regresión logística es un modelo discriminativo que forma parte de la familia de modelos discriminativos paramétricos conocida como **Modelos Lineales Generalizados** (*Generalized Linear Models*, GLM). Un modelo de este tipo puede construirse de la siguiente manera:\n",
    "\n",
    "1. Se define que la variable aleatoria $y|\\mathbf{x}$ que relaciona la entrada con la salida depende de un conjunto de parámetros $\\theta$ y pertenece a la familia de exponenciales de parámetro $\\eta$ de tal manera que $\\eta = \\theta^T \\mathbf{x}$. Esto es:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y|\\mathbf{x} &\\sim \\mathrm{ExpFamily}\\left(\\eta\\right) \\\\[.5em]\n",
    "P(y|\\mathbf{x}) &= b(y)\\exp\\left( \\eta^T y - a\\left(\\eta\\right)\\right) \\\\[.5em]\n",
    "P(y|\\mathbf{x};\\theta) &= b(y)\\exp\\left( \\mathbf{x}^T \\theta y - a(\\theta^T \\mathbf{x})\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "2. La salida del modelo se obtiene por medio de\n",
    "\n",
    "$$\n",
    "h_\\theta(\\mathbf{x}) = E\\left[ y|\\mathbf{x}\\right]\n",
    "$$\n",
    "\n",
    "El modelo de regresión logistica consiste en definir la probabilidad a posteriori \n",
    "\n",
    "$$\n",
    "P(y|\\mathbf{x};\\theta) = \\sigma\\left( \\theta^T \\mathbf{x} \\right)^y \\left( 1 - \\sigma\\left( \\theta^T \\mathbf{x} \\right) \\right)^{(1-y)}\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+ e^{-z}}\n",
    "$$ \n",
    "\n",
    "y puede mostrarse que forma parte de los modelos GLM para el caso en que $T(y)=y$, $b(y)=1$ y $a(\\theta^T\\mathbf{x})=\\log\\left(1+e^{\\theta^T\\mathbf{x}}\\right)$. \n",
    "\n",
    "También puede verse que \n",
    "\n",
    "$$\n",
    "h_\\theta(\\mathbf{x}) = E\\left[ y|\\mathbf{x}\\right] = P(y=1|\\mathbf{x};\\theta)\\cdot 1 + P(y=0|\\mathbf{x};\\theta)\\cdot 0 = \\sigma\\left( \\theta^T \\mathbf{x} \\right)\n",
    "$$\n",
    "\n",
    "por lo que la salida del modelo da la probabilidad de pertenecer a la clase $y=1$, y por lo tanto, aporta todo lo necesario para realizar una nueva predicción.\n",
    "\n",
    "En lo que sigue, adoptaremos el criterio de **máxima verosimilitud** para estimar los parámetros del modelo. De esta forma:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{\\theta} &= \\mathrm{argmax}_\\theta \\prod_{i=1}^N P\\left(y^{(i)}|\\mathbf{x}^{(i)};\\theta\\right) \\\\\n",
    "&= \\mathrm{argmax}_\\theta \\prod_{i=1}^N \\sigma\\left( \\theta^T \\mathbf{x}^{(i)} \\right)^{y^{(i)}} \\left( 1 - \\sigma\\left( \\theta^T \\mathbf{x}^{(i)} \\right) \\right)^{(1-y^{(i)})}\\\\\n",
    "&= \\mathrm{argmax}_\\theta \\log\\left(\\prod_{i=1}^N \\sigma\\left( \\theta^T \\mathbf{x}^{(i)} \\right)^{y^{(i)}} \\left( 1 - \\sigma\\left( \\theta^T \\mathbf{x}^{(i)} \\right) \\right)^{(1-y^{(i)})}\\right)\\\\\n",
    "&= \\mathrm{argmax}_\\theta \\sum_{i=1}^N y^{(i)} \\log\\left(\\sigma\\left( \\theta^T \\mathbf{x}^{(i)} \\right)\\right) + \\left(1 - y^{(i)}\\right) \\log\\left(1 - \\sigma\\left( \\theta^T \\mathbf{x}^{(i)} \\right)\\right)\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de features\n",
    "\n",
    "Si bien extraer características es el principal problema en procesamiento de lenguaje, en este caso sólo se experimentará con una serie de variantes en la tarea de representar un texto como una serie de características o *features*. Sin embargo, la parte en la que se comprende lo que se está diciendo en el texto está incluída, sin duda, en la extracción de features del texto. \n",
    "\n",
    "### Bolsa de Palabras\n",
    "\n",
    "Una forma muy común de representar un texto es con una **Bolsa de Palabras** (*Bag of Words*, BOW). Este método consiste en definir un vocabulario de palabras $V=\\{ w_1, w_2,\\ldots, w_n\\}$ y contar la cantidad de veces que apareció cada una de estas palabras en el texto. De esta manera, la $i$-ésima coordenada del vector $\\mathbf{x}$ corresponde a la cantidad de veces que apareció la palabra $w_i$ en el texto.\n",
    "\n",
    "Por ejemplo, supongamos que se tiene el siguiente texto:\n",
    "\n",
    "```\n",
    "<START> I am Sam. Sam I am. I do not like green eggs and ham. <END>\n",
    "```\n",
    "\n",
    "y se define un vocabulario `V = ['I', 'am', 'Sam', 'do', 'not', 'like', 'green', 'eggs', 'and', 'ham', '.', '<START>', '<END>']`. Entonces, el vector de features que representa el texto anterior es\n",
    "\n",
    "$$\n",
    "x = \\begin{bmatrix}\n",
    "count(I) \\\\\n",
    "count(am) \\\\\n",
    "count(Sam) \\\\\n",
    "\\vdots \\\\\n",
    "count(.) \\\\\n",
    "count(<START>) \\\\\n",
    "count(<END>) \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "3 \\\\ 2 \\\\ 2 \\\\ \\vdots \\\\ 3 \\\\ 1 \\\\ 1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Notemos varias cosas:\n",
    "\n",
    "* Esta representación es equivalente a representar un histograma de las palabras de que aparecen en cada muestra.\n",
    "\n",
    "* No se tiene en cuenta el orden en el que aparecen las palabras, por lo que se está perdiendo información (¡y muy valiosa!)\n",
    "\n",
    "* Existen elementos del vocabulario, como el punto y los signos de comienzo y fin del texto, que no son palabras pero que, sin embargo, forma parte del texto. Esto se hace porque aportan información valiosa sobre el texto, y descartarlos, muchas veces disminuye el desempeño del algoritmo. Por otro lado, se verá que tener muchos componentes en el vocabulario también puede jugar en contra de la cantidad de aciertos. Es común denominar a los integrantes del vocabulario ***tokens*** cuando se refiere a los ejemplos de estos elementos en el texto, y ***types*** cuando se refieren a los elementos en sí.\n",
    "\n",
    "* Existe la posibilidad de que en el texto aparezcan tokens (como por ejemplo `green`) que no forman parte del vocabulario. En este caso se suelen ignorar estas apariciones, aunque a veces se suele incorporar un token especial de tipo desconocido (representado como `<UNK>`) que contabilice las palabras que están fuera del vocabulario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos y separamos en train / dev / test:\n",
    "df_train, df_dev, df_test, vocab = read_and_split_dataset()\n",
    "idx_to_tk = {idx: tk for idx, tk in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Tokenizamos:\n",
    "samples = {}\n",
    "unk_tk = '<UNK>'\n",
    "unk_idx = vocab_size\n",
    "for data, df in zip(['train', 'dev'],[df_train, df_dev]):\n",
    "    samples[data] = tokenize_dataframe(df, vocab, unk_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el dataset y el batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IMDbBOWDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, samples, vocab_size):\n",
    "        \n",
    "        num_samples = len(samples)\n",
    "        self.x = torch.zeros(num_samples,vocab_size, dtype=torch.float)\n",
    "        for i, sample in enumerate(samples):\n",
    "            for j in sample[0]:\n",
    "                if j!= vocab_size:\n",
    "                    self.x[i,j] += 1.\n",
    "            \n",
    "        self.y = torch.tensor([sample[1] for sample in samples], dtype=torch.float).view(-1,1)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "padding_idx = vocab_size\n",
    "train_dataset = IMDbBOWDataset(samples['train'],padding_idx)\n",
    "dev_dataset = IMDbBOWDataset(samples['dev'], padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(vocab_size,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "\n",
    "model = LogisticRegression(vocab_size)\n",
    "device = 'cuda:1'\n",
    "LRTrainer = Trainer(train_loader,dev_loader,model,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training...\n",
      "Loss function: BCE\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0001\n",
      "Number of epochs: 100\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 0.12122833728790283\n",
      "Accuracy on validation dataset: 2541/5000 (50.82%)\n",
      "Accuracy on training dataset: 10008/20000 (50.04%)\n",
      "\n",
      "Epoch: 1, Batch number: 20, Loss: 0.1729176640510559\n",
      "Accuracy on validation dataset: 2540/5000 (50.80%)\n",
      "Accuracy on training dataset: 10025/20000 (50.12%)\n",
      "\n",
      "Epoch: 2, Batch number: 0, Loss: -0.12073114514350891\n",
      "Accuracy on validation dataset: 2544/5000 (50.88%)\n",
      "Accuracy on training dataset: 10040/20000 (50.20%)\n",
      "\n",
      "Epoch: 2, Batch number: 20, Loss: -0.5830476880073547\n",
      "Accuracy on validation dataset: 2545/5000 (50.90%)\n",
      "Accuracy on training dataset: 10048/20000 (50.24%)\n",
      "\n",
      "Epoch: 3, Batch number: 0, Loss: -0.5701159834861755\n",
      "Accuracy on validation dataset: 2545/5000 (50.90%)\n",
      "Accuracy on training dataset: 10055/20000 (50.27%)\n",
      "\n",
      "Epoch: 3, Batch number: 20, Loss: 0.6103765964508057\n",
      "Accuracy on validation dataset: 2548/5000 (50.96%)\n",
      "Accuracy on training dataset: 10069/20000 (50.34%)\n",
      "\n",
      "Epoch: 4, Batch number: 0, Loss: 0.40630289912223816\n",
      "Accuracy on validation dataset: 2554/5000 (51.08%)\n",
      "Accuracy on training dataset: 10071/20000 (50.35%)\n",
      "\n",
      "Epoch: 4, Batch number: 20, Loss: -0.00574088841676712\n",
      "Accuracy on validation dataset: 2555/5000 (51.10%)\n",
      "Accuracy on training dataset: 10081/20000 (50.41%)\n",
      "\n",
      "Epoch: 5, Batch number: 0, Loss: 0.33104562759399414\n",
      "Accuracy on validation dataset: 2558/5000 (51.16%)\n",
      "Accuracy on training dataset: 10087/20000 (50.44%)\n",
      "\n",
      "Epoch: 5, Batch number: 20, Loss: -0.34462839365005493\n",
      "Accuracy on validation dataset: 2558/5000 (51.16%)\n",
      "Accuracy on training dataset: 10103/20000 (50.52%)\n",
      "\n",
      "Epoch: 6, Batch number: 0, Loss: -0.246038556098938\n",
      "Accuracy on validation dataset: 2562/5000 (51.24%)\n",
      "Accuracy on training dataset: 10112/20000 (50.56%)\n",
      "\n",
      "Epoch: 6, Batch number: 20, Loss: 0.25862592458724976\n",
      "Accuracy on validation dataset: 2564/5000 (51.28%)\n",
      "Accuracy on training dataset: 10129/20000 (50.65%)\n",
      "\n",
      "Epoch: 7, Batch number: 0, Loss: 0.12167805433273315\n",
      "Accuracy on validation dataset: 2565/5000 (51.30%)\n",
      "Accuracy on training dataset: 10140/20000 (50.70%)\n",
      "\n",
      "Epoch: 7, Batch number: 20, Loss: -0.2494291067123413\n",
      "Accuracy on validation dataset: 2569/5000 (51.38%)\n",
      "Accuracy on training dataset: 10143/20000 (50.72%)\n",
      "\n",
      "Epoch: 8, Batch number: 0, Loss: -0.30615848302841187\n",
      "Accuracy on validation dataset: 2569/5000 (51.38%)\n",
      "Accuracy on training dataset: 10147/20000 (50.73%)\n",
      "\n",
      "Epoch: 8, Batch number: 20, Loss: 0.2642941474914551\n",
      "Accuracy on validation dataset: 2572/5000 (51.44%)\n",
      "Accuracy on training dataset: 10156/20000 (50.78%)\n",
      "\n",
      "Epoch: 9, Batch number: 0, Loss: 0.04528224468231201\n",
      "Accuracy on validation dataset: 2574/5000 (51.48%)\n",
      "Accuracy on training dataset: 10165/20000 (50.83%)\n",
      "\n",
      "Epoch: 9, Batch number: 20, Loss: -1.0950729846954346\n",
      "Accuracy on validation dataset: 2573/5000 (51.46%)\n",
      "Accuracy on training dataset: 10171/20000 (50.85%)\n",
      "\n",
      "Exiting training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuración del entrenamiento:\n",
    "loss_fn = 'BCE'\n",
    "optim_algorithm = 'Adam'\n",
    "epochs = 100\n",
    "sample_loss_every = 20\n",
    "check_on_train = True\n",
    "learning_rate = 1e-4\n",
    "\n",
    "LRTrainer.train(loss_fn,optim_algorithm,epochs,sample_loss_every,check_on_train,lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LRTrainer.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me dio underfitting. Vamos a agregarle un layer intermedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,h_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(vocab_size,h_dim)\n",
    "        self.linear2 = nn.Linear(h_dim,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "h_dim = 1000\n",
    "model2 = TwoLayerNet(vocab_size,h_dim)\n",
    "device = 'cuda:1'\n",
    "TwoLayerNetTrainer = Trainer(train_loader,dev_loader,model2,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Loss function: BCE\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.0001\n",
      "Number of epochs: 100\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 0.6930274963378906\n",
      "Accuracy on validation dataset: 1949/5000 (38.98%)\n",
      "Accuracy on training dataset: 7979/20000 (39.90%)\n",
      "\n",
      "Epoch: 2, Batch number: 0, Loss: 0.25974240899086\n",
      "Accuracy on validation dataset: 2528/5000 (50.56%)\n",
      "Accuracy on training dataset: 9998/20000 (49.99%)\n",
      "\n",
      "Epoch: 3, Batch number: 0, Loss: 0.2372168004512787\n",
      "Accuracy on validation dataset: 2538/5000 (50.76%)\n",
      "Accuracy on training dataset: 10014/20000 (50.07%)\n",
      "\n",
      "Epoch: 4, Batch number: 0, Loss: -0.6233561635017395\n",
      "Accuracy on validation dataset: 2565/5000 (51.30%)\n",
      "Accuracy on training dataset: 10101/20000 (50.51%)\n",
      "\n",
      "Epoch: 5, Batch number: 0, Loss: -0.12244324386119843\n",
      "Accuracy on validation dataset: 2630/5000 (52.60%)\n",
      "Accuracy on training dataset: 10429/20000 (52.15%)\n",
      "\n",
      "Epoch: 6, Batch number: 0, Loss: -1.1425628662109375\n",
      "Accuracy on validation dataset: 2725/5000 (54.50%)\n",
      "Accuracy on training dataset: 10818/20000 (54.09%)\n",
      "\n",
      "Epoch: 7, Batch number: 0, Loss: -0.9646027684211731\n",
      "Accuracy on validation dataset: 2788/5000 (55.76%)\n",
      "Accuracy on training dataset: 11109/20000 (55.55%)\n",
      "\n",
      "Epoch: 8, Batch number: 0, Loss: -2.055283546447754\n",
      "Accuracy on validation dataset: 2790/5000 (55.80%)\n",
      "Accuracy on training dataset: 11118/20000 (55.59%)\n",
      "\n",
      "Epoch: 9, Batch number: 0, Loss: -1.750929832458496\n",
      "Accuracy on validation dataset: 2825/5000 (56.50%)\n",
      "Accuracy on training dataset: 11234/20000 (56.17%)\n",
      "\n",
      "Epoch: 10, Batch number: 0, Loss: -3.4832468032836914\n",
      "Accuracy on validation dataset: 2830/5000 (56.60%)\n",
      "Accuracy on training dataset: 11224/20000 (56.12%)\n",
      "\n",
      "Epoch: 11, Batch number: 0, Loss: -5.0467095375061035\n",
      "Accuracy on validation dataset: 2828/5000 (56.56%)\n",
      "Accuracy on training dataset: 11257/20000 (56.28%)\n",
      "\n",
      "Epoch: 12, Batch number: 0, Loss: -2.9449892044067383\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11336/20000 (56.68%)\n",
      "\n",
      "Epoch: 13, Batch number: 0, Loss: -4.2401862144470215\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11322/20000 (56.61%)\n",
      "\n",
      "Epoch: 14, Batch number: 0, Loss: -6.8724188804626465\n",
      "Accuracy on validation dataset: 2839/5000 (56.78%)\n",
      "Accuracy on training dataset: 11307/20000 (56.53%)\n",
      "\n",
      "Epoch: 15, Batch number: 0, Loss: -4.173383712768555\n",
      "Accuracy on validation dataset: 2837/5000 (56.74%)\n",
      "Accuracy on training dataset: 11296/20000 (56.48%)\n",
      "\n",
      "Epoch: 16, Batch number: 0, Loss: -8.280184745788574\n",
      "Accuracy on validation dataset: 2852/5000 (57.04%)\n",
      "Accuracy on training dataset: 11371/20000 (56.85%)\n",
      "\n",
      "Epoch: 17, Batch number: 0, Loss: -11.077707290649414\n",
      "Accuracy on validation dataset: 2849/5000 (56.98%)\n",
      "Accuracy on training dataset: 11361/20000 (56.80%)\n",
      "\n",
      "Epoch: 18, Batch number: 0, Loss: -10.854331970214844\n",
      "Accuracy on validation dataset: 2856/5000 (57.12%)\n",
      "Accuracy on training dataset: 11398/20000 (56.99%)\n",
      "\n",
      "Epoch: 19, Batch number: 0, Loss: -11.474161148071289\n",
      "Accuracy on validation dataset: 2846/5000 (56.92%)\n",
      "Accuracy on training dataset: 11345/20000 (56.73%)\n",
      "\n",
      "Epoch: 20, Batch number: 0, Loss: -16.579111099243164\n",
      "Accuracy on validation dataset: 2841/5000 (56.82%)\n",
      "Accuracy on training dataset: 11305/20000 (56.52%)\n",
      "\n",
      "Epoch: 21, Batch number: 0, Loss: -13.028992652893066\n",
      "Accuracy on validation dataset: 2852/5000 (57.04%)\n",
      "Accuracy on training dataset: 11379/20000 (56.90%)\n",
      "\n",
      "Epoch: 22, Batch number: 0, Loss: -17.679019927978516\n",
      "Accuracy on validation dataset: 2854/5000 (57.08%)\n",
      "Accuracy on training dataset: 11386/20000 (56.93%)\n",
      "\n",
      "Epoch: 23, Batch number: 0, Loss: -22.502239227294922\n",
      "Accuracy on validation dataset: 2856/5000 (57.12%)\n",
      "Accuracy on training dataset: 11401/20000 (57.01%)\n",
      "\n",
      "Epoch: 24, Batch number: 0, Loss: -18.088687896728516\n",
      "Accuracy on validation dataset: 2858/5000 (57.16%)\n",
      "Accuracy on training dataset: 11403/20000 (57.02%)\n",
      "\n",
      "Epoch: 25, Batch number: 0, Loss: -12.12723159790039\n",
      "Accuracy on validation dataset: 2849/5000 (56.98%)\n",
      "Accuracy on training dataset: 11362/20000 (56.81%)\n",
      "\n",
      "Epoch: 26, Batch number: 0, Loss: -27.14358139038086\n",
      "Accuracy on validation dataset: 2845/5000 (56.90%)\n",
      "Accuracy on training dataset: 11332/20000 (56.66%)\n",
      "\n",
      "Epoch: 27, Batch number: 0, Loss: -26.276742935180664\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11351/20000 (56.76%)\n",
      "\n",
      "Epoch: 28, Batch number: 0, Loss: -38.29875564575195\n",
      "Accuracy on validation dataset: 2858/5000 (57.16%)\n",
      "Accuracy on training dataset: 11415/20000 (57.08%)\n",
      "\n",
      "Epoch: 29, Batch number: 0, Loss: -25.169614791870117\n",
      "Accuracy on validation dataset: 2864/5000 (57.28%)\n",
      "Accuracy on training dataset: 11449/20000 (57.24%)\n",
      "\n",
      "Epoch: 30, Batch number: 0, Loss: -62.33893966674805\n",
      "Accuracy on validation dataset: 2860/5000 (57.20%)\n",
      "Accuracy on training dataset: 11399/20000 (56.99%)\n",
      "\n",
      "Epoch: 31, Batch number: 0, Loss: -25.579723358154297\n",
      "Accuracy on validation dataset: 2869/5000 (57.38%)\n",
      "Accuracy on training dataset: 11454/20000 (57.27%)\n",
      "\n",
      "Epoch: 32, Batch number: 0, Loss: -30.487308502197266\n",
      "Accuracy on validation dataset: 2864/5000 (57.28%)\n",
      "Accuracy on training dataset: 11438/20000 (57.19%)\n",
      "\n",
      "Epoch: 33, Batch number: 0, Loss: -39.68431854248047\n",
      "Accuracy on validation dataset: 2859/5000 (57.18%)\n",
      "Accuracy on training dataset: 11401/20000 (57.01%)\n",
      "\n",
      "Epoch: 34, Batch number: 0, Loss: -54.528045654296875\n",
      "Accuracy on validation dataset: 2864/5000 (57.28%)\n",
      "Accuracy on training dataset: 11413/20000 (57.06%)\n",
      "\n",
      "Epoch: 35, Batch number: 0, Loss: -44.06672668457031\n",
      "Accuracy on validation dataset: 2865/5000 (57.30%)\n",
      "Accuracy on training dataset: 11454/20000 (57.27%)\n",
      "\n",
      "Epoch: 36, Batch number: 0, Loss: -54.756797790527344\n",
      "Accuracy on validation dataset: 2861/5000 (57.22%)\n",
      "Accuracy on training dataset: 11431/20000 (57.16%)\n",
      "\n",
      "Epoch: 37, Batch number: 0, Loss: -71.57633972167969\n",
      "Accuracy on validation dataset: 2861/5000 (57.22%)\n",
      "Accuracy on training dataset: 11430/20000 (57.15%)\n",
      "\n",
      "Epoch: 38, Batch number: 0, Loss: -62.52044677734375\n",
      "Accuracy on validation dataset: 2861/5000 (57.22%)\n",
      "Accuracy on training dataset: 11429/20000 (57.15%)\n",
      "\n",
      "Epoch: 39, Batch number: 0, Loss: -62.107994079589844\n",
      "Accuracy on validation dataset: 2871/5000 (57.42%)\n",
      "Accuracy on training dataset: 11472/20000 (57.36%)\n",
      "\n",
      "Epoch: 40, Batch number: 0, Loss: -62.619728088378906\n",
      "Accuracy on validation dataset: 2868/5000 (57.36%)\n",
      "Accuracy on training dataset: 11461/20000 (57.30%)\n",
      "\n",
      "Epoch: 41, Batch number: 0, Loss: -75.04025268554688\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11498/20000 (57.49%)\n",
      "\n",
      "Epoch: 42, Batch number: 0, Loss: -81.6015396118164\n",
      "Accuracy on validation dataset: 2871/5000 (57.42%)\n",
      "Accuracy on training dataset: 11473/20000 (57.37%)\n",
      "\n",
      "Epoch: 43, Batch number: 0, Loss: -100.4404525756836\n",
      "Accuracy on validation dataset: 2872/5000 (57.44%)\n",
      "Accuracy on training dataset: 11466/20000 (57.33%)\n",
      "\n",
      "Epoch: 44, Batch number: 0, Loss: -81.52525329589844\n",
      "Accuracy on validation dataset: 2871/5000 (57.42%)\n",
      "Accuracy on training dataset: 11466/20000 (57.33%)\n",
      "\n",
      "Epoch: 45, Batch number: 0, Loss: -58.657230377197266\n",
      "Accuracy on validation dataset: 2871/5000 (57.42%)\n",
      "Accuracy on training dataset: 11453/20000 (57.27%)\n",
      "\n",
      "Epoch: 46, Batch number: 0, Loss: -107.90834045410156\n",
      "Accuracy on validation dataset: 2866/5000 (57.32%)\n",
      "Accuracy on training dataset: 11427/20000 (57.13%)\n",
      "\n",
      "Epoch: 47, Batch number: 0, Loss: -82.94672393798828\n",
      "Accuracy on validation dataset: 2873/5000 (57.46%)\n",
      "Accuracy on training dataset: 11477/20000 (57.38%)\n",
      "\n",
      "Epoch: 48, Batch number: 0, Loss: -119.59503173828125\n",
      "Accuracy on validation dataset: 2873/5000 (57.46%)\n",
      "Accuracy on training dataset: 11453/20000 (57.27%)\n",
      "\n",
      "Epoch: 49, Batch number: 0, Loss: -98.46298217773438\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11486/20000 (57.43%)\n",
      "\n",
      "Epoch: 50, Batch number: 0, Loss: -114.75825500488281\n",
      "Accuracy on validation dataset: 2864/5000 (57.28%)\n",
      "Accuracy on training dataset: 11386/20000 (56.93%)\n",
      "\n",
      "Epoch: 51, Batch number: 0, Loss: -125.70240783691406\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11479/20000 (57.40%)\n",
      "\n",
      "Epoch: 52, Batch number: 0, Loss: -104.17420959472656\n",
      "Accuracy on validation dataset: 2872/5000 (57.44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset: 11429/20000 (57.15%)\n",
      "\n",
      "Epoch: 53, Batch number: 0, Loss: -139.82244873046875\n",
      "Accuracy on validation dataset: 2873/5000 (57.46%)\n",
      "Accuracy on training dataset: 11450/20000 (57.25%)\n",
      "\n",
      "Epoch: 54, Batch number: 0, Loss: -128.30020141601562\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11505/20000 (57.52%)\n",
      "\n",
      "Epoch: 55, Batch number: 0, Loss: -111.06503295898438\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11473/20000 (57.37%)\n",
      "\n",
      "Epoch: 56, Batch number: 0, Loss: -168.22274780273438\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11489/20000 (57.45%)\n",
      "\n",
      "Epoch: 57, Batch number: 0, Loss: -206.28118896484375\n",
      "Accuracy on validation dataset: 2871/5000 (57.42%)\n",
      "Accuracy on training dataset: 11410/20000 (57.05%)\n",
      "\n",
      "Epoch: 58, Batch number: 0, Loss: -168.37181091308594\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11501/20000 (57.51%)\n",
      "\n",
      "Epoch: 59, Batch number: 0, Loss: -194.78602600097656\n",
      "Accuracy on validation dataset: 2873/5000 (57.46%)\n",
      "Accuracy on training dataset: 11438/20000 (57.19%)\n",
      "\n",
      "Epoch: 60, Batch number: 0, Loss: -165.8206787109375\n",
      "Accuracy on validation dataset: 2878/5000 (57.56%)\n",
      "Accuracy on training dataset: 11513/20000 (57.56%)\n",
      "\n",
      "Epoch: 61, Batch number: 0, Loss: -190.68673706054688\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11455/20000 (57.27%)\n",
      "\n",
      "Epoch: 62, Batch number: 0, Loss: -210.1436767578125\n",
      "Accuracy on validation dataset: 2868/5000 (57.36%)\n",
      "Accuracy on training dataset: 11378/20000 (56.89%)\n",
      "\n",
      "Epoch: 63, Batch number: 0, Loss: -243.33184814453125\n",
      "Accuracy on validation dataset: 2870/5000 (57.40%)\n",
      "Accuracy on training dataset: 11395/20000 (56.98%)\n",
      "\n",
      "Epoch: 64, Batch number: 0, Loss: -180.91510009765625\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11512/20000 (57.56%)\n",
      "\n",
      "Epoch: 65, Batch number: 0, Loss: -141.4734649658203\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11505/20000 (57.52%)\n",
      "\n",
      "Epoch: 66, Batch number: 0, Loss: -224.20144653320312\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11493/20000 (57.47%)\n",
      "\n",
      "Epoch: 67, Batch number: 0, Loss: -218.1966552734375\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11478/20000 (57.39%)\n",
      "\n",
      "Epoch: 68, Batch number: 0, Loss: -172.1482391357422\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11441/20000 (57.20%)\n",
      "\n",
      "Epoch: 69, Batch number: 0, Loss: -274.7476501464844\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11466/20000 (57.33%)\n",
      "\n",
      "Epoch: 70, Batch number: 0, Loss: -213.01805114746094\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11445/20000 (57.23%)\n",
      "\n",
      "Epoch: 71, Batch number: 0, Loss: -135.18617248535156\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11495/20000 (57.48%)\n",
      "\n",
      "Epoch: 72, Batch number: 0, Loss: -219.23146057128906\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11460/20000 (57.30%)\n",
      "\n",
      "Epoch: 73, Batch number: 0, Loss: -216.5315399169922\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11461/20000 (57.30%)\n",
      "\n",
      "Epoch: 74, Batch number: 0, Loss: -304.54156494140625\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11431/20000 (57.16%)\n",
      "\n",
      "Epoch: 75, Batch number: 0, Loss: -275.0845642089844\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11524/20000 (57.62%)\n",
      "\n",
      "Epoch: 76, Batch number: 0, Loss: -243.609130859375\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11449/20000 (57.24%)\n",
      "\n",
      "Epoch: 77, Batch number: 0, Loss: -180.26486206054688\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11513/20000 (57.56%)\n",
      "\n",
      "Epoch: 78, Batch number: 0, Loss: -406.70794677734375\n",
      "Accuracy on validation dataset: 2873/5000 (57.46%)\n",
      "Accuracy on training dataset: 11378/20000 (56.89%)\n",
      "\n",
      "Epoch: 79, Batch number: 0, Loss: -167.93251037597656\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11472/20000 (57.36%)\n",
      "\n",
      "Epoch: 80, Batch number: 0, Loss: -211.50076293945312\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11507/20000 (57.53%)\n",
      "\n",
      "Epoch: 81, Batch number: 0, Loss: -274.96630859375\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11497/20000 (57.48%)\n",
      "\n",
      "Epoch: 82, Batch number: 0, Loss: -282.9083251953125\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11473/20000 (57.37%)\n",
      "\n",
      "Epoch: 83, Batch number: 0, Loss: -348.6310729980469\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11479/20000 (57.40%)\n",
      "\n",
      "Epoch: 84, Batch number: 0, Loss: -423.6070556640625\n",
      "Accuracy on validation dataset: 2877/5000 (57.54%)\n",
      "Accuracy on training dataset: 11462/20000 (57.31%)\n",
      "\n",
      "Epoch: 85, Batch number: 0, Loss: -244.50057983398438\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11473/20000 (57.37%)\n",
      "\n",
      "Epoch: 86, Batch number: 0, Loss: -227.03387451171875\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11454/20000 (57.27%)\n",
      "\n",
      "Epoch: 87, Batch number: 0, Loss: -346.5586853027344\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11418/20000 (57.09%)\n",
      "\n",
      "Epoch: 88, Batch number: 0, Loss: -459.62860107421875\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11462/20000 (57.31%)\n",
      "\n",
      "Epoch: 89, Batch number: 0, Loss: -426.8961181640625\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11485/20000 (57.42%)\n",
      "\n",
      "Epoch: 90, Batch number: 0, Loss: -477.2727355957031\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11449/20000 (57.24%)\n",
      "\n",
      "Epoch: 91, Batch number: 0, Loss: -363.71905517578125\n",
      "Accuracy on validation dataset: 2877/5000 (57.54%)\n",
      "Accuracy on training dataset: 11502/20000 (57.51%)\n",
      "\n",
      "Epoch: 92, Batch number: 0, Loss: -412.54632568359375\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11473/20000 (57.37%)\n",
      "\n",
      "Epoch: 93, Batch number: 0, Loss: -300.1685791015625\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11470/20000 (57.35%)\n",
      "\n",
      "Epoch: 94, Batch number: 0, Loss: -479.2504577636719\n",
      "Accuracy on validation dataset: 2875/5000 (57.50%)\n",
      "Accuracy on training dataset: 11399/20000 (56.99%)\n",
      "\n",
      "Epoch: 95, Batch number: 0, Loss: -403.5462646484375\n",
      "Accuracy on validation dataset: 2874/5000 (57.48%)\n",
      "Accuracy on training dataset: 11404/20000 (57.02%)\n",
      "\n",
      "Epoch: 96, Batch number: 0, Loss: -560.9255981445312\n",
      "Accuracy on validation dataset: 2877/5000 (57.54%)\n",
      "Accuracy on training dataset: 11513/20000 (57.56%)\n",
      "\n",
      "Epoch: 97, Batch number: 0, Loss: -500.5032043457031\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11425/20000 (57.12%)\n",
      "\n",
      "Epoch: 98, Batch number: 0, Loss: -502.3585510253906\n",
      "Accuracy on validation dataset: 2877/5000 (57.54%)\n",
      "Accuracy on training dataset: 11489/20000 (57.45%)\n",
      "\n",
      "Epoch: 99, Batch number: 0, Loss: -553.1286010742188\n",
      "Accuracy on validation dataset: 2876/5000 (57.52%)\n",
      "Accuracy on training dataset: 11420/20000 (57.10%)\n",
      "\n",
      "Epoch: 100, Batch number: 0, Loss: -621.3609619140625\n",
      "Accuracy on validation dataset: 2877/5000 (57.54%)\n",
      "Accuracy on training dataset: 11516/20000 (57.58%)\n",
      "\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuración del entrenamiento:\n",
    "loss_fn = 'BCE'\n",
    "optim_algorithm = 'Adam'\n",
    "epochs = 100\n",
    "sample_loss_every = 20\n",
    "check_on_train = True\n",
    "learning_rate = 1e-4\n",
    "\n",
    "TwoLayerNetTrainer.train(loss_fn,optim_algorithm,epochs,sample_loss_every,check_on_train,lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un layer intermedio no se puede hacer porque son muchos parámetros. Vamos a reducir el vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos y separamos en train / dev / test:\n",
    "df_train, df_dev, df_test, vocab = read_and_split_dataset()\n",
    "idx_to_tk = {idx: tk for idx, tk in enumerate(vocab)}\n",
    "\n",
    "\n",
    "# Nos quedamos con las palabras más frecuentes:\n",
    "\n",
    "import nltk\n",
    "df = df_train\n",
    "df = df.copy()\n",
    "df['comment'] = df['comment'].str.lower().apply(nltk.tokenize.word_tokenize,args=('english', False))\n",
    "\n",
    "tk_to_freq = {tk: 0 for tk in vocab}\n",
    "for comment in df['comment']:\n",
    "    for tk in comment:\n",
    "        try:\n",
    "            tk_to_freq[tk] += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "freqs = np.array(list(tk_to_freq.values()))\n",
    "arg_freqs = np.argsort(freqs)[::-1]\n",
    "vocab = [vocab[i] for i in arg_freqs[:10000]]\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizamos:\n",
    "samples = {}\n",
    "unk_tk = '<UNK>'\n",
    "unk_idx = vocab_size\n",
    "for data, df in zip(['train', 'dev'],[df_train, df_dev]):\n",
    "    samples[data] = tokenize_dataframe(df, vocab, unk_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IMDbBOWDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, samples, vocab_size):\n",
    "        \n",
    "        num_samples = len(samples)\n",
    "        self.x = torch.zeros(num_samples,vocab_size, dtype=torch.float)\n",
    "        for i, sample in enumerate(samples):\n",
    "            for j in sample[0]:\n",
    "                if j!= vocab_size:\n",
    "                    self.x[i,j] += 1.\n",
    "            \n",
    "        self.y = torch.tensor([sample[1] for sample in samples], dtype=torch.float).view(-1,1)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "padding_idx = vocab_size\n",
    "train_dataset = IMDbBOWDataset(samples['train'],padding_idx)\n",
    "dev_dataset = IMDbBOWDataset(samples['dev'], padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(vocab_size,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "\n",
    "model = LogisticRegression(vocab_size)\n",
    "device = 'cuda:1'\n",
    "LRTrainer = Trainer(train_loader,dev_loader,model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Loss function: BCE\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.001\n",
      "Number of epochs: 100\n",
      "Running on device (cuda:1)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 0.7051641941070557\n",
      "Accuracy on validation dataset: 1982/5000 (39.64%)\n",
      "Accuracy on training dataset: 8092/20000 (40.46%)\n",
      "\n",
      "Epoch: 2, Batch number: 0, Loss: 0.2502511739730835\n",
      "Accuracy on validation dataset: 2521/5000 (50.42%)\n",
      "Accuracy on training dataset: 9989/20000 (49.95%)\n",
      "\n",
      "Epoch: 3, Batch number: 0, Loss: 0.07242456078529358\n",
      "Accuracy on validation dataset: 2539/5000 (50.78%)\n",
      "Accuracy on training dataset: 10010/20000 (50.05%)\n",
      "\n",
      "Epoch: 4, Batch number: 0, Loss: 0.21413671970367432\n",
      "Accuracy on validation dataset: 2563/5000 (51.26%)\n",
      "Accuracy on training dataset: 10066/20000 (50.33%)\n",
      "\n",
      "Epoch: 5, Batch number: 0, Loss: -0.2427576780319214\n",
      "Accuracy on validation dataset: 2595/5000 (51.90%)\n",
      "Accuracy on training dataset: 10234/20000 (51.17%)\n",
      "\n",
      "Epoch: 6, Batch number: 0, Loss: -0.13706590235233307\n",
      "Accuracy on validation dataset: 2629/5000 (52.58%)\n",
      "Accuracy on training dataset: 10371/20000 (51.85%)\n",
      "\n",
      "Epoch: 7, Batch number: 0, Loss: -0.45216310024261475\n",
      "Accuracy on validation dataset: 2678/5000 (53.56%)\n",
      "Accuracy on training dataset: 10565/20000 (52.83%)\n",
      "\n",
      "Epoch: 8, Batch number: 0, Loss: -0.5465776920318604\n",
      "Accuracy on validation dataset: 2716/5000 (54.32%)\n",
      "Accuracy on training dataset: 10701/20000 (53.51%)\n",
      "\n",
      "Epoch: 9, Batch number: 0, Loss: -0.8770203590393066\n",
      "Accuracy on validation dataset: 2730/5000 (54.60%)\n",
      "Accuracy on training dataset: 10786/20000 (53.93%)\n",
      "\n",
      "Epoch: 10, Batch number: 0, Loss: -0.5439810752868652\n",
      "Accuracy on validation dataset: 2748/5000 (54.96%)\n",
      "Accuracy on training dataset: 10845/20000 (54.23%)\n",
      "\n",
      "Epoch: 11, Batch number: 0, Loss: -0.6939297914505005\n",
      "Accuracy on validation dataset: 2779/5000 (55.58%)\n",
      "Accuracy on training dataset: 10975/20000 (54.88%)\n",
      "\n",
      "Epoch: 12, Batch number: 0, Loss: -1.0047197341918945\n",
      "Accuracy on validation dataset: 2789/5000 (55.78%)\n",
      "Accuracy on training dataset: 10998/20000 (54.99%)\n",
      "\n",
      "Epoch: 13, Batch number: 0, Loss: -0.8000127077102661\n",
      "Accuracy on validation dataset: 2782/5000 (55.64%)\n",
      "Accuracy on training dataset: 10959/20000 (54.80%)\n",
      "\n",
      "Epoch: 14, Batch number: 0, Loss: -1.1668834686279297\n",
      "Accuracy on validation dataset: 2795/5000 (55.90%)\n",
      "Accuracy on training dataset: 11010/20000 (55.05%)\n",
      "\n",
      "Epoch: 15, Batch number: 0, Loss: -0.9273906350135803\n",
      "Accuracy on validation dataset: 2804/5000 (56.08%)\n",
      "Accuracy on training dataset: 11055/20000 (55.27%)\n",
      "\n",
      "Epoch: 16, Batch number: 0, Loss: -1.1220664978027344\n",
      "Accuracy on validation dataset: 2799/5000 (55.98%)\n",
      "Accuracy on training dataset: 11019/20000 (55.09%)\n",
      "\n",
      "Epoch: 17, Batch number: 0, Loss: -1.6131081581115723\n",
      "Accuracy on validation dataset: 2804/5000 (56.08%)\n",
      "Accuracy on training dataset: 11047/20000 (55.23%)\n",
      "\n",
      "Epoch: 18, Batch number: 0, Loss: -1.4112944602966309\n",
      "Accuracy on validation dataset: 2810/5000 (56.20%)\n",
      "Accuracy on training dataset: 11063/20000 (55.31%)\n",
      "\n",
      "Epoch: 19, Batch number: 0, Loss: -0.29964759945869446\n",
      "Accuracy on validation dataset: 2820/5000 (56.40%)\n",
      "Accuracy on training dataset: 11104/20000 (55.52%)\n",
      "\n",
      "Epoch: 20, Batch number: 0, Loss: -1.6572473049163818\n",
      "Accuracy on validation dataset: 2815/5000 (56.30%)\n",
      "Accuracy on training dataset: 11072/20000 (55.36%)\n",
      "\n",
      "Epoch: 21, Batch number: 0, Loss: -1.1273150444030762\n",
      "Accuracy on validation dataset: 2817/5000 (56.34%)\n",
      "Accuracy on training dataset: 11089/20000 (55.45%)\n",
      "\n",
      "Epoch: 22, Batch number: 0, Loss: -1.7877657413482666\n",
      "Accuracy on validation dataset: 2824/5000 (56.48%)\n",
      "Accuracy on training dataset: 11127/20000 (55.63%)\n",
      "\n",
      "Epoch: 23, Batch number: 0, Loss: -3.212980270385742\n",
      "Accuracy on validation dataset: 2821/5000 (56.42%)\n",
      "Accuracy on training dataset: 11095/20000 (55.48%)\n",
      "\n",
      "Epoch: 24, Batch number: 0, Loss: -1.9959115982055664\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11134/20000 (55.67%)\n",
      "\n",
      "Epoch: 25, Batch number: 0, Loss: -0.2658688426017761\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11133/20000 (55.66%)\n",
      "\n",
      "Epoch: 26, Batch number: 0, Loss: -2.645481586456299\n",
      "Accuracy on validation dataset: 2824/5000 (56.48%)\n",
      "Accuracy on training dataset: 11132/20000 (55.66%)\n",
      "\n",
      "Epoch: 27, Batch number: 0, Loss: -2.1632392406463623\n",
      "Accuracy on validation dataset: 2828/5000 (56.56%)\n",
      "Accuracy on training dataset: 11140/20000 (55.70%)\n",
      "\n",
      "Epoch: 28, Batch number: 0, Loss: -1.313934564590454\n",
      "Accuracy on validation dataset: 2830/5000 (56.60%)\n",
      "Accuracy on training dataset: 11146/20000 (55.73%)\n",
      "\n",
      "Epoch: 29, Batch number: 0, Loss: -2.343421220779419\n",
      "Accuracy on validation dataset: 2827/5000 (56.54%)\n",
      "Accuracy on training dataset: 11150/20000 (55.75%)\n",
      "\n",
      "Epoch: 30, Batch number: 0, Loss: -1.8736892938613892\n",
      "Accuracy on validation dataset: 2823/5000 (56.46%)\n",
      "Accuracy on training dataset: 11113/20000 (55.56%)\n",
      "\n",
      "Epoch: 31, Batch number: 0, Loss: -3.0798532962799072\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11127/20000 (55.63%)\n",
      "\n",
      "Epoch: 32, Batch number: 0, Loss: -4.257862091064453\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11114/20000 (55.57%)\n",
      "\n",
      "Epoch: 33, Batch number: 0, Loss: -2.120298147201538\n",
      "Accuracy on validation dataset: 2815/5000 (56.30%)\n",
      "Accuracy on training dataset: 11091/20000 (55.45%)\n",
      "\n",
      "Epoch: 34, Batch number: 0, Loss: -3.1774702072143555\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11151/20000 (55.76%)\n",
      "\n",
      "Epoch: 35, Batch number: 0, Loss: -1.9427452087402344\n",
      "Accuracy on validation dataset: 2825/5000 (56.50%)\n",
      "Accuracy on training dataset: 11142/20000 (55.71%)\n",
      "\n",
      "Epoch: 36, Batch number: 0, Loss: -4.884182929992676\n",
      "Accuracy on validation dataset: 2825/5000 (56.50%)\n",
      "Accuracy on training dataset: 11145/20000 (55.73%)\n",
      "\n",
      "Epoch: 37, Batch number: 0, Loss: -2.355991840362549\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11150/20000 (55.75%)\n",
      "\n",
      "Epoch: 38, Batch number: 0, Loss: -2.296626091003418\n",
      "Accuracy on validation dataset: 2823/5000 (56.46%)\n",
      "Accuracy on training dataset: 11133/20000 (55.66%)\n",
      "\n",
      "Epoch: 39, Batch number: 0, Loss: -3.603098154067993\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11148/20000 (55.74%)\n",
      "\n",
      "Epoch: 40, Batch number: 0, Loss: -4.709354400634766\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11149/20000 (55.74%)\n",
      "\n",
      "Epoch: 41, Batch number: 0, Loss: -2.2236993312835693\n",
      "Accuracy on validation dataset: 2825/5000 (56.50%)\n",
      "Accuracy on training dataset: 11144/20000 (55.72%)\n",
      "\n",
      "Epoch: 42, Batch number: 0, Loss: -4.567106246948242\n",
      "Accuracy on validation dataset: 2825/5000 (56.50%)\n",
      "Accuracy on training dataset: 11157/20000 (55.78%)\n",
      "\n",
      "Epoch: 43, Batch number: 0, Loss: -2.5759987831115723\n",
      "Accuracy on validation dataset: 2823/5000 (56.46%)\n",
      "Accuracy on training dataset: 11143/20000 (55.72%)\n",
      "\n",
      "Epoch: 44, Batch number: 0, Loss: -3.434969425201416\n",
      "Accuracy on validation dataset: 2823/5000 (56.46%)\n",
      "Accuracy on training dataset: 11150/20000 (55.75%)\n",
      "\n",
      "Epoch: 45, Batch number: 0, Loss: -5.243112087249756\n",
      "Accuracy on validation dataset: 2827/5000 (56.54%)\n",
      "Accuracy on training dataset: 11164/20000 (55.82%)\n",
      "\n",
      "Epoch: 46, Batch number: 0, Loss: -4.160979270935059\n",
      "Accuracy on validation dataset: 2823/5000 (56.46%)\n",
      "Accuracy on training dataset: 11154/20000 (55.77%)\n",
      "\n",
      "Epoch: 47, Batch number: 0, Loss: -5.461456298828125\n",
      "Accuracy on validation dataset: 2823/5000 (56.46%)\n",
      "Accuracy on training dataset: 11151/20000 (55.76%)\n",
      "\n",
      "Epoch: 48, Batch number: 0, Loss: -5.0168304443359375\n",
      "Accuracy on validation dataset: 2815/5000 (56.30%)\n",
      "Accuracy on training dataset: 11111/20000 (55.55%)\n",
      "\n",
      "Epoch: 49, Batch number: 0, Loss: -5.504678726196289\n",
      "Accuracy on validation dataset: 2820/5000 (56.40%)\n",
      "Accuracy on training dataset: 11151/20000 (55.76%)\n",
      "\n",
      "Epoch: 50, Batch number: 0, Loss: -3.869520902633667\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11144/20000 (55.72%)\n",
      "\n",
      "Epoch: 51, Batch number: 0, Loss: -5.380892276763916\n",
      "Accuracy on validation dataset: 2823/5000 (56.46%)\n",
      "Accuracy on training dataset: 11166/20000 (55.83%)\n",
      "\n",
      "Epoch: 52, Batch number: 0, Loss: -3.86971378326416\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training dataset: 11158/20000 (55.79%)\n",
      "\n",
      "Epoch: 53, Batch number: 0, Loss: -4.003573417663574\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11159/20000 (55.80%)\n",
      "\n",
      "Epoch: 54, Batch number: 0, Loss: -3.9952917098999023\n",
      "Accuracy on validation dataset: 2818/5000 (56.36%)\n",
      "Accuracy on training dataset: 11156/20000 (55.78%)\n",
      "\n",
      "Epoch: 55, Batch number: 0, Loss: -6.253493309020996\n",
      "Accuracy on validation dataset: 2817/5000 (56.34%)\n",
      "Accuracy on training dataset: 11134/20000 (55.67%)\n",
      "\n",
      "Epoch: 56, Batch number: 0, Loss: -5.852270126342773\n",
      "Accuracy on validation dataset: 2817/5000 (56.34%)\n",
      "Accuracy on training dataset: 11141/20000 (55.70%)\n",
      "\n",
      "Epoch: 57, Batch number: 0, Loss: -4.244622230529785\n",
      "Accuracy on validation dataset: 2815/5000 (56.30%)\n",
      "Accuracy on training dataset: 11143/20000 (55.72%)\n",
      "\n",
      "Epoch: 58, Batch number: 0, Loss: -6.939418792724609\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11159/20000 (55.80%)\n",
      "\n",
      "Epoch: 59, Batch number: 0, Loss: -5.395369052886963\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11150/20000 (55.75%)\n",
      "\n",
      "Epoch: 60, Batch number: 0, Loss: -4.782454490661621\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11151/20000 (55.76%)\n",
      "\n",
      "Epoch: 61, Batch number: 0, Loss: -4.20786714553833\n",
      "Accuracy on validation dataset: 2814/5000 (56.28%)\n",
      "Accuracy on training dataset: 11127/20000 (55.63%)\n",
      "\n",
      "Epoch: 62, Batch number: 0, Loss: -1.511182427406311\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11153/20000 (55.77%)\n",
      "\n",
      "Epoch: 63, Batch number: 0, Loss: -4.94550085067749\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11165/20000 (55.83%)\n",
      "\n",
      "Epoch: 64, Batch number: 0, Loss: -5.536791801452637\n",
      "Accuracy on validation dataset: 2825/5000 (56.50%)\n",
      "Accuracy on training dataset: 11173/20000 (55.87%)\n",
      "\n",
      "Epoch: 65, Batch number: 0, Loss: -6.15117073059082\n",
      "Accuracy on validation dataset: 2812/5000 (56.24%)\n",
      "Accuracy on training dataset: 11132/20000 (55.66%)\n",
      "\n",
      "Epoch: 66, Batch number: 0, Loss: -6.005308151245117\n",
      "Accuracy on validation dataset: 2816/5000 (56.32%)\n",
      "Accuracy on training dataset: 11142/20000 (55.71%)\n",
      "\n",
      "Epoch: 67, Batch number: 0, Loss: -6.828183650970459\n",
      "Accuracy on validation dataset: 2810/5000 (56.20%)\n",
      "Accuracy on training dataset: 11126/20000 (55.63%)\n",
      "\n",
      "Epoch: 68, Batch number: 0, Loss: -5.10382080078125\n",
      "Accuracy on validation dataset: 2816/5000 (56.32%)\n",
      "Accuracy on training dataset: 11142/20000 (55.71%)\n",
      "\n",
      "Epoch: 69, Batch number: 0, Loss: -5.290642261505127\n",
      "Accuracy on validation dataset: 2815/5000 (56.30%)\n",
      "Accuracy on training dataset: 11139/20000 (55.70%)\n",
      "\n",
      "Epoch: 70, Batch number: 0, Loss: -8.728625297546387\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11118/20000 (55.59%)\n",
      "\n",
      "Epoch: 71, Batch number: 0, Loss: -7.733748435974121\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11127/20000 (55.63%)\n",
      "\n",
      "Epoch: 72, Batch number: 0, Loss: -9.28969669342041\n",
      "Accuracy on validation dataset: 2806/5000 (56.12%)\n",
      "Accuracy on training dataset: 11120/20000 (55.60%)\n",
      "\n",
      "Epoch: 73, Batch number: 0, Loss: -7.972284317016602\n",
      "Accuracy on validation dataset: 2805/5000 (56.10%)\n",
      "Accuracy on training dataset: 11115/20000 (55.58%)\n",
      "\n",
      "Epoch: 74, Batch number: 0, Loss: -6.129477500915527\n",
      "Accuracy on validation dataset: 2805/5000 (56.10%)\n",
      "Accuracy on training dataset: 11118/20000 (55.59%)\n",
      "\n",
      "Epoch: 75, Batch number: 0, Loss: -7.018082618713379\n",
      "Accuracy on validation dataset: 2809/5000 (56.18%)\n",
      "Accuracy on training dataset: 11126/20000 (55.63%)\n",
      "\n",
      "Epoch: 76, Batch number: 0, Loss: -6.022342681884766\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11131/20000 (55.66%)\n",
      "\n",
      "Epoch: 77, Batch number: 0, Loss: -4.324767112731934\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11126/20000 (55.63%)\n",
      "\n",
      "Epoch: 78, Batch number: 0, Loss: -9.545323371887207\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11125/20000 (55.62%)\n",
      "\n",
      "Epoch: 79, Batch number: 0, Loss: -8.680150985717773\n",
      "Accuracy on validation dataset: 2804/5000 (56.08%)\n",
      "Accuracy on training dataset: 11121/20000 (55.60%)\n",
      "\n",
      "Epoch: 80, Batch number: 0, Loss: -9.250089645385742\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11127/20000 (55.63%)\n",
      "\n",
      "Epoch: 81, Batch number: 0, Loss: -8.099594116210938\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11127/20000 (55.63%)\n",
      "\n",
      "Epoch: 82, Batch number: 0, Loss: -10.378290176391602\n",
      "Accuracy on validation dataset: 2802/5000 (56.04%)\n",
      "Accuracy on training dataset: 11113/20000 (55.56%)\n",
      "\n",
      "Epoch: 83, Batch number: 0, Loss: -13.317201614379883\n",
      "Accuracy on validation dataset: 2802/5000 (56.04%)\n",
      "Accuracy on training dataset: 11110/20000 (55.55%)\n",
      "\n",
      "Epoch: 84, Batch number: 0, Loss: -6.958621978759766\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11119/20000 (55.59%)\n",
      "\n",
      "Epoch: 85, Batch number: 0, Loss: -3.165130138397217\n",
      "Accuracy on validation dataset: 2806/5000 (56.12%)\n",
      "Accuracy on training dataset: 11122/20000 (55.61%)\n",
      "\n",
      "Epoch: 86, Batch number: 0, Loss: -4.149637222290039\n",
      "Accuracy on validation dataset: 2803/5000 (56.06%)\n",
      "Accuracy on training dataset: 11122/20000 (55.61%)\n",
      "\n",
      "Epoch: 87, Batch number: 0, Loss: -5.354043960571289\n",
      "Accuracy on validation dataset: 2808/5000 (56.16%)\n",
      "Accuracy on training dataset: 11134/20000 (55.67%)\n",
      "\n",
      "Epoch: 88, Batch number: 0, Loss: -9.539375305175781\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11116/20000 (55.58%)\n",
      "\n",
      "Epoch: 89, Batch number: 0, Loss: -8.058160781860352\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11119/20000 (55.59%)\n",
      "\n",
      "Epoch: 90, Batch number: 0, Loss: -6.947601318359375\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11120/20000 (55.60%)\n",
      "\n",
      "Epoch: 91, Batch number: 0, Loss: -5.4433817863464355\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11117/20000 (55.59%)\n",
      "\n",
      "Epoch: 92, Batch number: 0, Loss: -9.217570304870605\n",
      "Accuracy on validation dataset: 2802/5000 (56.04%)\n",
      "Accuracy on training dataset: 11104/20000 (55.52%)\n",
      "\n",
      "Epoch: 93, Batch number: 0, Loss: -8.89522647857666\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11106/20000 (55.53%)\n",
      "\n",
      "Epoch: 94, Batch number: 0, Loss: -9.571593284606934\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11111/20000 (55.55%)\n",
      "\n",
      "Epoch: 95, Batch number: 0, Loss: -6.242730140686035\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11112/20000 (55.56%)\n",
      "\n",
      "Epoch: 96, Batch number: 0, Loss: -10.58833122253418\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11115/20000 (55.58%)\n",
      "\n",
      "Epoch: 97, Batch number: 0, Loss: -4.85727596282959\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11113/20000 (55.56%)\n",
      "\n",
      "Epoch: 98, Batch number: 0, Loss: -10.099958419799805\n",
      "Accuracy on validation dataset: 2802/5000 (56.04%)\n",
      "Accuracy on training dataset: 11122/20000 (55.61%)\n",
      "\n",
      "Epoch: 99, Batch number: 0, Loss: -10.722900390625\n",
      "Accuracy on validation dataset: 2801/5000 (56.02%)\n",
      "Accuracy on training dataset: 11119/20000 (55.59%)\n",
      "\n",
      "Epoch: 100, Batch number: 0, Loss: -6.279279708862305\n",
      "Accuracy on validation dataset: 2805/5000 (56.10%)\n",
      "Accuracy on training dataset: 11130/20000 (55.65%)\n",
      "\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuración del entrenamiento:\n",
    "loss_fn = 'BCE'\n",
    "optim_algorithm = 'Adam'\n",
    "epochs = 100\n",
    "sample_loss_every = 20\n",
    "check_on_train = True\n",
    "learning_rate = 1e-3\n",
    "\n",
    "LRTrainer.train(loss_fn,optim_algorithm,epochs,sample_loss_every,check_on_train,lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigue dando underfitting. Vamos a ver si podemos aumentar la cantidad de parámetros ahora sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,h_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(vocab_size,h_dim)\n",
    "        self.linear2 = nn.Linear(h_dim,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "h_dim = 50000\n",
    "model2 = TwoLayerNet(vocab_size,h_dim)\n",
    "device = 'cpu'\n",
    "TwoLayerNetTrainer = Trainer(train_loader,dev_loader,model2,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Loss function: BCE\n",
      "Optimization method: Adam\n",
      "Learning Rate: 0.001\n",
      "Number of epochs: 100\n",
      "Running on device (cpu)\n",
      "\n",
      "Epoch: 1, Batch number: 0, Loss: 0.6697266697883606\n",
      "Accuracy on validation dataset: 2526/5000 (50.52%)\n",
      "Accuracy on training dataset: 9974/20000 (49.87%)\n",
      "\n",
      "Epoch: 2, Batch number: 0, Loss: -16.05726432800293\n",
      "Accuracy on validation dataset: 2736/5000 (54.72%)\n",
      "Accuracy on training dataset: 10805/20000 (54.02%)\n",
      "\n",
      "Epoch: 3, Batch number: 0, Loss: -171.23428344726562\n",
      "Accuracy on validation dataset: 2796/5000 (55.92%)\n",
      "Accuracy on training dataset: 11051/20000 (55.26%)\n",
      "\n",
      "Epoch: 4, Batch number: 0, Loss: -432.89459228515625\n",
      "Accuracy on validation dataset: 2800/5000 (56.00%)\n",
      "Accuracy on training dataset: 11035/20000 (55.17%)\n",
      "\n",
      "Epoch: 5, Batch number: 0, Loss: -941.2314453125\n",
      "Accuracy on validation dataset: 2849/5000 (56.98%)\n",
      "Accuracy on training dataset: 11234/20000 (56.17%)\n",
      "\n",
      "Epoch: 6, Batch number: 0, Loss: -1632.5648193359375\n",
      "Accuracy on validation dataset: 2797/5000 (55.94%)\n",
      "Accuracy on training dataset: 11000/20000 (55.00%)\n",
      "\n",
      "Epoch: 7, Batch number: 0, Loss: -2046.6234130859375\n",
      "Accuracy on validation dataset: 2841/5000 (56.82%)\n",
      "Accuracy on training dataset: 11210/20000 (56.05%)\n",
      "\n",
      "Epoch: 8, Batch number: 0, Loss: -4739.703125\n",
      "Accuracy on validation dataset: 2795/5000 (55.90%)\n",
      "Accuracy on training dataset: 10987/20000 (54.94%)\n",
      "\n",
      "Epoch: 9, Batch number: 0, Loss: -7088.6181640625\n",
      "Accuracy on validation dataset: 2829/5000 (56.58%)\n",
      "Accuracy on training dataset: 11176/20000 (55.88%)\n",
      "\n",
      "Epoch: 10, Batch number: 0, Loss: -5994.685546875\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11216/20000 (56.08%)\n",
      "\n",
      "Epoch: 11, Batch number: 0, Loss: -7981.1015625\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11144/20000 (55.72%)\n",
      "\n",
      "Epoch: 12, Batch number: 0, Loss: -20127.34765625\n",
      "Accuracy on validation dataset: 2814/5000 (56.28%)\n",
      "Accuracy on training dataset: 11091/20000 (55.45%)\n",
      "\n",
      "Epoch: 13, Batch number: 0, Loss: -14315.5888671875\n",
      "Accuracy on validation dataset: 2834/5000 (56.68%)\n",
      "Accuracy on training dataset: 11206/20000 (56.03%)\n",
      "\n",
      "Epoch: 14, Batch number: 0, Loss: -19273.66796875\n",
      "Accuracy on validation dataset: 2826/5000 (56.52%)\n",
      "Accuracy on training dataset: 11150/20000 (55.75%)\n",
      "\n",
      "Epoch: 15, Batch number: 0, Loss: -31201.740234375\n",
      "Accuracy on validation dataset: 2839/5000 (56.78%)\n",
      "Accuracy on training dataset: 11204/20000 (56.02%)\n",
      "\n",
      "Epoch: 16, Batch number: 0, Loss: -24980.2578125\n",
      "Accuracy on validation dataset: 2819/5000 (56.38%)\n",
      "Accuracy on training dataset: 11117/20000 (55.59%)\n",
      "\n",
      "Epoch: 17, Batch number: 0, Loss: -18437.416015625\n",
      "Accuracy on validation dataset: 2850/5000 (57.00%)\n",
      "Accuracy on training dataset: 11230/20000 (56.15%)\n",
      "\n",
      "Epoch: 18, Batch number: 0, Loss: -14488.33984375\n",
      "Accuracy on validation dataset: 2839/5000 (56.78%)\n",
      "Accuracy on training dataset: 11207/20000 (56.03%)\n",
      "\n",
      "Epoch: 19, Batch number: 0, Loss: -37852.58984375\n",
      "Accuracy on validation dataset: 2839/5000 (56.78%)\n",
      "Accuracy on training dataset: 11202/20000 (56.01%)\n",
      "\n",
      "Epoch: 20, Batch number: 0, Loss: -49732.5\n",
      "Accuracy on validation dataset: 2830/5000 (56.60%)\n",
      "Accuracy on training dataset: 11168/20000 (55.84%)\n",
      "\n",
      "Epoch: 21, Batch number: 0, Loss: -82110.484375\n",
      "Accuracy on validation dataset: 2845/5000 (56.90%)\n",
      "Accuracy on training dataset: 11206/20000 (56.03%)\n",
      "\n",
      "Epoch: 22, Batch number: 0, Loss: -31816.1484375\n",
      "Accuracy on validation dataset: 2843/5000 (56.86%)\n",
      "Accuracy on training dataset: 11202/20000 (56.01%)\n",
      "\n",
      "Epoch: 23, Batch number: 0, Loss: -67722.75\n",
      "Accuracy on validation dataset: 2851/5000 (57.02%)\n",
      "Accuracy on training dataset: 11231/20000 (56.16%)\n",
      "\n",
      "Epoch: 24, Batch number: 0, Loss: -47183.265625\n",
      "Accuracy on validation dataset: 2856/5000 (57.12%)\n",
      "Accuracy on training dataset: 11262/20000 (56.31%)\n",
      "\n",
      "Epoch: 25, Batch number: 0, Loss: -102339.703125\n",
      "Accuracy on validation dataset: 2836/5000 (56.72%)\n",
      "Accuracy on training dataset: 11180/20000 (55.90%)\n",
      "\n",
      "Epoch: 26, Batch number: 0, Loss: -48342.39453125\n",
      "Accuracy on validation dataset: 2848/5000 (56.96%)\n",
      "Accuracy on training dataset: 11216/20000 (56.08%)\n",
      "\n",
      "Epoch: 27, Batch number: 0, Loss: -75803.2890625\n",
      "Accuracy on validation dataset: 2851/5000 (57.02%)\n",
      "Accuracy on training dataset: 11218/20000 (56.09%)\n",
      "\n",
      "Epoch: 28, Batch number: 0, Loss: -100523.1796875\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11197/20000 (55.98%)\n",
      "\n",
      "Epoch: 29, Batch number: 0, Loss: -82346.9375\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11196/20000 (55.98%)\n",
      "\n",
      "Epoch: 30, Batch number: 0, Loss: -155119.21875\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11195/20000 (55.98%)\n",
      "\n",
      "Epoch: 31, Batch number: 0, Loss: -148283.75\n",
      "Accuracy on validation dataset: 2834/5000 (56.68%)\n",
      "Accuracy on training dataset: 11162/20000 (55.81%)\n",
      "\n",
      "Epoch: 32, Batch number: 0, Loss: -94909.296875\n",
      "Accuracy on validation dataset: 2848/5000 (56.96%)\n",
      "Accuracy on training dataset: 11209/20000 (56.05%)\n",
      "\n",
      "Epoch: 33, Batch number: 0, Loss: -92118.453125\n",
      "Accuracy on validation dataset: 2850/5000 (57.00%)\n",
      "Accuracy on training dataset: 11209/20000 (56.05%)\n",
      "\n",
      "Epoch: 34, Batch number: 0, Loss: -201387.3125\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11184/20000 (55.92%)\n",
      "\n",
      "Epoch: 35, Batch number: 0, Loss: -122485.3984375\n",
      "Accuracy on validation dataset: 2850/5000 (57.00%)\n",
      "Accuracy on training dataset: 11198/20000 (55.99%)\n",
      "\n",
      "Epoch: 36, Batch number: 0, Loss: -146459.375\n",
      "Accuracy on validation dataset: 2849/5000 (56.98%)\n",
      "Accuracy on training dataset: 11209/20000 (56.05%)\n",
      "\n",
      "Epoch: 37, Batch number: 0, Loss: -187085.421875\n",
      "Accuracy on validation dataset: 2850/5000 (57.00%)\n",
      "Accuracy on training dataset: 11217/20000 (56.09%)\n",
      "\n",
      "Epoch: 38, Batch number: 0, Loss: -111568.2578125\n",
      "Accuracy on validation dataset: 2849/5000 (56.98%)\n",
      "Accuracy on training dataset: 11201/20000 (56.01%)\n",
      "\n",
      "Epoch: 39, Batch number: 0, Loss: -149162.578125\n",
      "Accuracy on validation dataset: 2852/5000 (57.04%)\n",
      "Accuracy on training dataset: 11238/20000 (56.19%)\n",
      "\n",
      "Epoch: 40, Batch number: 0, Loss: -249887.328125\n",
      "Accuracy on validation dataset: 2836/5000 (56.72%)\n",
      "Accuracy on training dataset: 11170/20000 (55.85%)\n",
      "\n",
      "Epoch: 41, Batch number: 0, Loss: -130183.046875\n",
      "Accuracy on validation dataset: 2845/5000 (56.90%)\n",
      "Accuracy on training dataset: 11182/20000 (55.91%)\n",
      "\n",
      "Epoch: 42, Batch number: 0, Loss: -129604.53125\n",
      "Accuracy on validation dataset: 2845/5000 (56.90%)\n",
      "Accuracy on training dataset: 11191/20000 (55.95%)\n",
      "\n",
      "Epoch: 43, Batch number: 0, Loss: -160798.859375\n",
      "Accuracy on validation dataset: 2837/5000 (56.74%)\n",
      "Accuracy on training dataset: 11171/20000 (55.85%)\n",
      "\n",
      "Epoch: 44, Batch number: 0, Loss: -252349.203125\n",
      "Accuracy on validation dataset: 2840/5000 (56.80%)\n",
      "Accuracy on training dataset: 11181/20000 (55.91%)\n",
      "\n",
      "Epoch: 45, Batch number: 0, Loss: -207140.75\n",
      "Accuracy on validation dataset: 2846/5000 (56.92%)\n",
      "Accuracy on training dataset: 11195/20000 (55.98%)\n",
      "\n",
      "Epoch: 46, Batch number: 0, Loss: -250796.609375\n",
      "Accuracy on validation dataset: 2846/5000 (56.92%)\n",
      "Accuracy on training dataset: 11195/20000 (55.98%)\n",
      "\n",
      "Epoch: 47, Batch number: 0, Loss: -371659.75\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11199/20000 (55.99%)\n",
      "\n",
      "Epoch: 48, Batch number: 0, Loss: -345789.0625\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11204/20000 (56.02%)\n",
      "\n",
      "Epoch: 49, Batch number: 0, Loss: -199727.09375\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11191/20000 (55.95%)\n",
      "\n",
      "Epoch: 50, Batch number: 0, Loss: -260368.34375\n",
      "Accuracy on validation dataset: 2850/5000 (57.00%)\n",
      "Accuracy on training dataset: 11212/20000 (56.06%)\n",
      "\n",
      "Epoch: 51, Batch number: 0, Loss: -361699.875\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11193/20000 (55.97%)\n",
      "\n",
      "Epoch: 52, Batch number: 0, Loss: -439123.71875\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11199/20000 (55.99%)\n",
      "\n",
      "Epoch: 53, Batch number: 0, Loss: -438297.65625\n",
      "Accuracy on validation dataset: 2840/5000 (56.80%)\n",
      "Accuracy on training dataset: 11168/20000 (55.84%)\n",
      "\n",
      "Epoch: 54, Batch number: 0, Loss: -304092.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation dataset: 2839/5000 (56.78%)\n",
      "Accuracy on training dataset: 11183/20000 (55.91%)\n",
      "\n",
      "Epoch: 55, Batch number: 0, Loss: -460320.25\n",
      "Accuracy on validation dataset: 2845/5000 (56.90%)\n",
      "Accuracy on training dataset: 11186/20000 (55.93%)\n",
      "\n",
      "Epoch: 56, Batch number: 0, Loss: -441035.0\n",
      "Accuracy on validation dataset: 2846/5000 (56.92%)\n",
      "Accuracy on training dataset: 11204/20000 (56.02%)\n",
      "\n",
      "Epoch: 57, Batch number: 0, Loss: -270629.46875\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11206/20000 (56.03%)\n",
      "\n",
      "Epoch: 58, Batch number: 0, Loss: -249320.5\n",
      "Accuracy on validation dataset: 2849/5000 (56.98%)\n",
      "Accuracy on training dataset: 11219/20000 (56.09%)\n",
      "\n",
      "Epoch: 59, Batch number: 0, Loss: -447226.59375\n",
      "Accuracy on validation dataset: 2846/5000 (56.92%)\n",
      "Accuracy on training dataset: 11199/20000 (55.99%)\n",
      "\n",
      "Epoch: 60, Batch number: 0, Loss: -305880.375\n",
      "Accuracy on validation dataset: 2843/5000 (56.86%)\n",
      "Accuracy on training dataset: 11177/20000 (55.88%)\n",
      "\n",
      "Epoch: 61, Batch number: 0, Loss: -500553.75\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11209/20000 (56.05%)\n",
      "\n",
      "Epoch: 62, Batch number: 0, Loss: -590905.9375\n",
      "Accuracy on validation dataset: 2846/5000 (56.92%)\n",
      "Accuracy on training dataset: 11193/20000 (55.97%)\n",
      "\n",
      "Epoch: 63, Batch number: 0, Loss: -745995.625\n",
      "Accuracy on validation dataset: 2846/5000 (56.92%)\n",
      "Accuracy on training dataset: 11195/20000 (55.98%)\n",
      "\n",
      "Epoch: 64, Batch number: 0, Loss: -356769.0625\n",
      "Accuracy on validation dataset: 2847/5000 (56.94%)\n",
      "Accuracy on training dataset: 11201/20000 (56.01%)\n",
      "\n",
      "Epoch: 65, Batch number: 0, Loss: -465743.90625\n",
      "Accuracy on validation dataset: 2848/5000 (56.96%)\n",
      "Accuracy on training dataset: 11210/20000 (56.05%)\n",
      "\n",
      "Epoch: 66, Batch number: 0, Loss: -336959.46875\n",
      "Accuracy on validation dataset: 2843/5000 (56.86%)\n",
      "Accuracy on training dataset: 11175/20000 (55.88%)\n",
      "\n",
      "Epoch: 67, Batch number: 0, Loss: -367466.875\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11182/20000 (55.91%)\n",
      "\n",
      "Epoch: 68, Batch number: 0, Loss: -580201.125\n",
      "Accuracy on validation dataset: 2840/5000 (56.80%)\n",
      "Accuracy on training dataset: 11174/20000 (55.87%)\n",
      "\n",
      "Epoch: 69, Batch number: 0, Loss: -710332.0\n",
      "Accuracy on validation dataset: 2838/5000 (56.76%)\n",
      "Accuracy on training dataset: 11165/20000 (55.83%)\n",
      "\n",
      "Epoch: 70, Batch number: 0, Loss: -964124.125\n",
      "Accuracy on validation dataset: 2840/5000 (56.80%)\n",
      "Accuracy on training dataset: 11176/20000 (55.88%)\n",
      "\n",
      "Epoch: 71, Batch number: 0, Loss: -812886.3125\n",
      "Accuracy on validation dataset: 2843/5000 (56.86%)\n",
      "Accuracy on training dataset: 11179/20000 (55.90%)\n",
      "\n",
      "Epoch: 72, Batch number: 0, Loss: -1095831.375\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11193/20000 (55.97%)\n",
      "\n",
      "Epoch: 73, Batch number: 0, Loss: -537538.75\n",
      "Accuracy on validation dataset: 2840/5000 (56.80%)\n",
      "Accuracy on training dataset: 11182/20000 (55.91%)\n",
      "\n",
      "Epoch: 74, Batch number: 0, Loss: -372375.40625\n",
      "Accuracy on validation dataset: 2845/5000 (56.90%)\n",
      "Accuracy on training dataset: 11205/20000 (56.02%)\n",
      "\n",
      "Epoch: 75, Batch number: 0, Loss: -630822.5\n",
      "Accuracy on validation dataset: 2844/5000 (56.88%)\n",
      "Accuracy on training dataset: 11189/20000 (55.95%)\n",
      "\n",
      "Epoch: 76, Batch number: 0, Loss: -847817.0625\n",
      "Accuracy on validation dataset: 2839/5000 (56.78%)\n",
      "Accuracy on training dataset: 11174/20000 (55.87%)\n",
      "\n",
      "Epoch: 77, Batch number: 0, Loss: -456002.78125\n",
      "Accuracy on validation dataset: 2842/5000 (56.84%)\n",
      "Accuracy on training dataset: 11194/20000 (55.97%)\n",
      "\n",
      "Exiting training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuración del entrenamiento:\n",
    "loss_fn = 'BCE'\n",
    "optim_algorithm = 'Adam'\n",
    "epochs = 100\n",
    "sample_loss_every = 20\n",
    "check_on_train = True\n",
    "learning_rate = 1e-3\n",
    "\n",
    "TwoLayerNetTrainer.train(loss_fn,optim_algorithm,epochs,sample_loss_every,check_on_train,lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
